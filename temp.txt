Mon 30 Jul 2018 05:51:17 AM IST AMM
11 JAN



1-333275181
Summary: Lack_of_free_swap_space_on_LBDMP1App00.imzcloud.ibmammsap.local[PROBLEM:534677]
10.8.8.73
LBDMP1App00.imzcloud.ibmammsap.local	
[ibmrmalik@LBDMP1App00 ~]$ free -g
             total       used       free     shared    buffers     cached
Mem:            31         27          3          6          0          8
-/+ buffers/cache:         19         12
Swap:            7          6          1



1-333273621
10.198.0.209
/sybase  space  by 40Gb
Summary: Free_disk_space_is_less_than_20%_on_volume_/sybase

[root@CLDBOBIADWD1 ibmrmalik]# vgs
  VG            #PV #LV #SN Attr   VSize  VFree
  mounvg          1   1   0 wz--n- 11.00t       0
  vg00            1   2   0 wz--n- 39.51g       0
  vg_app          2   2   0 wz--n- 80.99g 1016.00m
  vg_data         3   1   0 wz--n-  1.27t  100.99g
  vg_monitoring   1   1   0 wz--n-  4.99g       0



1-333297796
Hello Team 

Please create a new filesystem of 4GB on server PL2SAPPRD ( 10.7.33.13 )
New FS should be for /usr/sap/DAB
There is free space on this VG : pipappvg        2  17   0 wz--n- 145.97g   6.97g


[root@PL2SAPPRD ibmrmalik]# vgs
  VG            #PV #LV #SN Attr   VSize   VFree
  pipappvg        2  17   0 wz--n- 145.97g   6.97g

-------------------------------------------------------------------------------------------------------------------------------------

12 Jan


1-333338481
Summary: Zabbix_agent_on_judSNG01web01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:546892] Date: Jan 12,2018 3:8 CUT Severity: Critical ResourceId: judsng01web01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judSNG01web01.imzcloud.ibmammsap.local NodeAlias: 10.198.10.100 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3362135:jud


1-333335501
Summary: Zabbix_agent_on_ms3wdclapp30.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:546728] Date: Jan 12,2018 2:47 CUT Severity: Critical ResourceId: ms3wdclapp30 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ms3wdclapp30.imzcloud.ibmammsap.local NodeAlias: 10.12.7.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3362092:ms3
  



1-333335371
Summary: Zabbix_agent_on_MGGGBJPECCX10.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:546655] Date: Jan 12,2018 2:38 CUT Severity: Critical ResourceId: mgggbjpeccx10 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPECCX10.imzcloud.ibmammsap.local NodeAlias: 10.133.18.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3362077:mgg



1-333357901
Summary: Processor_load_is_too_high_on_HKG02AMMADC001[PROBLEM:550047] Date: Jan 12,2018 11:8 CUT Severity: Minor ResourceId: hkg02ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 9.758333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: HKG02AMMADC001 NodeAlias: 146.89.141.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3363070:amm




1-332773811
Summary: Lack_of_free_swap_space_on_sved1srv0.imzcloud.ibmammsap.local[PROBLEM:347235] Date: Dec 21,2017 8:9 CUT Severity: Major ResourceId: sved1srv0 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.07 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: sved1srv0.imzcloud.ibmammsap.local NodeAlias: 10.6.1.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3307317:age

-----------------------------------------------------------------------------------

15 Jan

1-333438331
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var



1-333252351
Summary: Zabbix_agent_on_AFRFIORIDEV.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:531128] Date: Jan 10,2018 9:16 CUT Severity: Critical ResourceId: afrfioridev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRFIORIDEV.imzcloud.ibmammsap.local NodeAlias: 10.197.1.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3357661:afr

[ibmrmalik@AFRFIORIDEV ~]$ uptime
 10:10:29 up 42 days, 13:36,  1 user,  load average: 0.00, 0.00, 0.00
[ibmrmalik@AFRFIORIDEV ~]$ /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9412) is running...



1-333253271
Summary: Zabbix_agent_on_MGGGBJVECCX08.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:531199] Date: Jan 10,2018 9:18 CUT Severity: Critical ResourceId: mgggbjveccx08 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJVECCX08.imzcloud.ibmammsap.local NodeAlias: 10.133.18.178 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3357735:mgg


[ibmrmalik@MGGGBJVECCX08 ~]$ uptime
 09:42:35 up 203 days, 19:29,  1 user,  load average: 0.69, 0.71, 0.45
[ibmrmalik@MGGGBJVECCX08 ~]$ /etc/init.d/zabbix-agent status
zabbix_agentd (pid  15612) is running...




1-333253751
Summary: Zabbix_agent_on_MGGGBJPECCX09.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:531201] Date: Jan 10,2018 9:18 CUT Severity: Critical ResourceId: mgggbjpeccx09 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPECCX09.imzcloud.ibmammsap.local NodeAlias: 10.133.18.36 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3357737:mgg

[ibmrmalik@MGGGBJPECCX09 ~]$ uptime
 10:12:27 up 10 days,  6:29,  1 user,  load average: 0.32, 0.28, 0.20
[ibmrmalik@MGGGBJPECCX09 ~]$ /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4535) is running...
[ibmrmalik@MGGGBJPECCX09 ~]$



1-333253101
Summary: Zabbix_agent_on_MGGGBJQECCX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:531188] Date: Jan 10,2018 9:18 CUT Severity: Critical ResourceId: mgggbjqeccx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJQECCX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.168 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3357727:mgg


1-333253081
Summary: Zabbix_agent_on_MGGGBJQECCY02.imzcloud.ibmammsap.local_is_unavailable

[ibmrmalik@MGGGBJQECCY02 ~]$ uptime
 10:27:12 up 11 days, 14:49,  1 user,  load average: 0.00, 0.01, 0.00
[ibmrmalik@MGGGBJQECCY02 ~]$ /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4029) is running...


--------------------------------------------------------------------------------------------------------------------------------------

16 Jan

ip -  	10.198.0.222 
1-333418625
add 3 gb to /home/sm5uma 

check the mounted systems using df -hT
[root@CLDIAASAPP1 ibmrmalik]# df -hT /home
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_home
                     ext4  2.4G  1.8G  484M  80% /home

[root@CLDIAASAPP1 ibmrmalik]# lvs
  LV           VG        Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  lv_home      VolGroup  -wi-ao----   2.49g
  lv_mon       VolGroup  -wi-ao----   5.00g
  lv_opt       VolGroup  -wi-ao----   5.00g
  lv_root      VolGroup  -wi-ao----  10.00g
  lv_swap      VolGroup  -wi-ao----   8.00g
  lv_tmp       VolGroup  -wi-ao----   4.00g
  lv_var       VolGroup  -wi-ao----   5.00g
  SOLMANCDS_lv sap_vg    -wi-ao----  70.00g
  sapccms_lv   sap_vg    -wi-ao----  10.00g
  sapdaa_lv    sap_vg    -wi-ao----  10.00g
  sapmntsmp_lv sap_vg    -wi-ao----   5.00g
  sapsmp_lv    sap_vg    -wi-ao----  20.00g
  saptrans_lv  sap_vg    -wi-ao----  10.00g
  sapdata1_lv  sybase_vg -wi-ao---- 500.00g
  sapdiag_lv   sybase_vg -wi-ao----  10.00g
  saplog1_lv   sybase_vg -wi-ao----  30.00g
  saptemp_lv   sybase_vg -wi-ao----   5.00g
  sybaseSMP_lv sybase_vg -wi-ao---- 150.00g
  sybsystem_lv sybase_vg -wi-ao----   5.00g
  sybtemp_lv   sybase_vg -wi-ao----   5.00g


check for the space availability on the VG identified in last step
 --- Volume group ---
  VG Name               VolGroup
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  11
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                7
  Open LV               7
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               39.51 GiB
  PE Size               4.00 MiB
  Total PE              10114
  Alloc PE / Size       10112 / 39.50 GiB
  Free  PE / Size       2 / 8.00 MiB
  VG UUID               f9xfio-9zIo-4i4f-qWP3-aZVQ-OKpU-B3kzQk

now check if the VG has space for extension





[root@CLDIAASAPP1 ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g 508.00m
  sap_vg      1   6   0 wz--n- 128.00g   3.00g
  sybase_vg   3   7   0 wz--n- 713.99g   8.99g


/dev/mapper/VolGroup-lv_home
                      2.0G  1.8G   17M 100% /home

--- Logical volume ---
  LV Path                /dev/VolGroup/lv_home
  LV Name                lv_home
  VG Name                VolGroup
  LV UUID                McfjgW-u2BB-v5og-x0do-fiey-rBDm-KARLnE
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2016-05-18 01:52:44 +0800
  LV Status              available
  # open                 1
  LV Size                2.00 GiB
  Current LE             512
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           253:6


/dev/mapper/VolGroup-lv_home
                      2.0G  1.8G   17M 100% /home


/dev/mapper/VolGroup-lv_home
                      2.4G  1.8G  484M  80% /home



1-333449031	sev2
Summary: High inodes used (85%) for /sapmnt/DE1 Date: 01/15/2018 Severity: Major ResourceId: bi1lr113 TicketGroup: ApsSAPTechnical CustomerCode: zoe InstanceId: /sapmnt/DE1 InstanceValue: 85% InstanceSituation: Percent inodes used ComponentType: ComputerSystem Component: LINUX SubComponent: FileSystem ApplId: LINUX MsgId: LINUXTSA018E Node: bi1lr113 NodeAlias: 10.245.131.24 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_ins_rlzc_sap_nprd AlertGroup: ITM_Linux_Disk EventKey: USRD0P0MSDP:3368959:zoe




1-333295231
Summary: Free_disk_space_is_less_than_20%_on_volume_F:[PROBLEM:539338] Date: Jan 11,2018 7:57 CUT Severity: Minor ResourceId: ri3lr020 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: InstanceValue: 19.81 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: DAL09AMMTS002 NodeAlias: 146.89.140.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3359988:mic



1-333438331
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:574947] Date: Jan 15,2018 5:1 CUT Severity: Minor ResourceId: dal09ammsrtr001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: dal09ammsrtr001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3368236:amm


------------------------------------------------------------------------------------------------------------------------------

17 Jan


1-333514881 has been assigned to you.

Customer: Mitsui-Soko Holdings Co. Ltd (MT5) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: Processor_load_is_too_high_on_WINT331[PROBLEM:592529] Date: Jan 17,2018 4:15 CUT Severity:
Severity: 3-Standard
Long Description: Summary: Processor_load_is_too_high_on_WINT331[PROBLEM:592529] Date: Jan 17,2018 4:15 CUT Severity: Minor ResourceId: wint331 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 8.733333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT331 NodeAlias: 10.136.0.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3373308:mt5

10.136.0.11



1-333514241
Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:592921] Date: Jan 17,2018 5:2 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 11 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3373375:mt5


1-333507481
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:590700] Date: Jan 16,2018 22:4 CUT Severity: Major ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 9.86 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3372655:pnc

du -mch â€“max-depth=1 /


1-333506591
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:590688] Date: Jan 16,2018 22:3 CUT Severity: Minor ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 18.37 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3372652:pnc




1-333507411
Summary: Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.local[PROBLEM:590596] Date: Jan 16,2018 21:57 CUT Severity: Major ResourceId: tdmprdecc TicketGroup: AMM-DELIVERY-TECH CustomerCode: tdm InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 49.39 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: TDMprdecc.imzcloud.ibmammsap.local NodeAlias: 10.4.20.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3372639:tdm

[ibmrmalik@TDMprdecc ~]$ free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          4          0          5
-/+ buffers/cache:          5          5
Swap:           13          7          6


top - 02:08:34 up 480 days, 19:24,  3 users,  load average: 0.07, 0.03, 0.00
Tasks: 310 total,   1 running, 309 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.1%us,  0.5%sy,  0.0%ni, 99.4%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    11.682G total,   11.377G used,  311.793M free,   46.871M buffers
Swap:   13.766G total, 7339.402M used, 6756.594M free, 5510.781M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
57009 hp1adm    20   0 1504m 9328 1840 S  0.0  0.1  20:28.48 790m en.sapHP1_ASCS0
59049 hp1adm    20   0 2484m  20m 9600 S  0.0  0.2  20:53.38 102m icman
37267 hp1adm    20   0 12.2g 2.4g 2.3g S  0.0 20.4   6:00.44  72m HP1_00_DIA_W7
51442 hp1adm    20   0 12.3g 2.0g 1.8g S  0.0 17.0   1:00.47  63m HP1_00_DIA_W26
11231 root      20   0  296m 2120 1336 S  0.0  0.0 232:04.05  62m vmtoolsd
27082 hp1adm    20   0  912m  19m  14m S  0.0  0.2  43:27.50  59m sapstartsrv




1-333505701
Summary: NTP_time_is_driffted_on_S4HANA-DEV.imzcloud.ibmammsap.local[PROBLEM:589659] Date: Jan 16,2018 20:28 CUT Severity: Major ResourceId: s4hana-dev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mi4 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 5.14 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: S4HANA-DEV.imzcloud.ibmammsap.local NodeAlias: 10.71.5.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3372508:mi4



1-332696131
Summary: Free_disk_space_is_less_than_20%_on_volume_/sybase/PBO[PROBLEM:329630] Date: Dec 19,2017 9:53 CUT Severity: Minor ResourceId: emcboprd TicketGroup: ApsSAPTechnical CustomerCode: emc InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sybase/PBO InstanceValue: 19.98 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: EMCBOPRD.imzcloud.ibmammsap.local NodeAlias: 10.14.5.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sybase/PBO AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3302356:emc


[root@EMCBOPRD ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g    2.50g
  pboappvg    1  13   0 wz--n- 128.00g   17.00g
  pboarchvg   1   1   0 wz--n-  64.00g   14.00g
  pbodatavg   1   7   0 wz--n- 128.00g 1020.00m
  pbologvg    1   4   0 wz--n-  32.00g 1020.00m



[root@EMCBOPRD ibmrmalik]# lvdisplay |grep -i pbosybase_lv
  LV Path                /dev/pbodatavg/pbosybase_lv
  LV Name                pbosybase_lv

[root@EMCBOPRD ibmrmalik]# df -hT grep /sybase/PBO
df: `grep': No such file or directory
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/pbodatavg-pbosybase_lv
                     ext3  7.9G  6.2G  1.4G  83% /sybase/PBO


1-333465851
Summary: Lack_of_free_swap_space_on_LBDMP1App00.imzcloud.ibmammsap.local[PROBLEM:580734] Date: Jan 15,2018 19:31 CUT Severity: Major ResourceId: lbdmp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 33.96 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: LBDMP1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.73 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3369787:lbd

[ibmrmalik@LBDMP1App00 ~]$ free -g
             total       used       free     shared    buffers     cached
Mem:            31         29          2          5          0          6
-/+ buffers/cache:         22          8
Swap:            7          7          0

top - 03:37:37 up 88 days, 21:00,  1 user,  load average: 0.93, 1.19, 1.15
Tasks: 392 total,   1 running, 391 sleeping,   0 stopped,   0 zombie
Cpu(s):  8.6%us,  0.5%sy,  0.0%ni, 90.9%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.349G total,   29.563G used, 1829.176M free,   93.367M buffers
Swap: 8191.996M total, 8191.168M used,  848.000k free, 6936.973M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
10136 sapadm    20   0 5336m 570m 3868 S  0.0  1.8 154:31.23 2.2g sapstartsrv
 5578 mp1adm    20   0 11.9g 3.4g 2.7g S  0.0 11.0   3:19.54 487m MP1_00_DIA_W11
64358 mp1adm    20   0 8582m 2.9g  11m S 55.2  9.4  73921:52 213m jlaunch
64359 mp1adm    20   0 3113m  30m  972 S  0.0  0.1  99:44.97 181m jlaunch
 6772 daaadm    20   0 3810m 117m 2968 S  0.0  0.4 314:55.10 160m jstart
64357 mp1adm    20   0 5826m 361m 6240 S  6.3  1.1   5801:08 138m jlaunch
 6774 daaadm    20   0 4732m 156m 4256 S  0.0  0.5 351:28.50 132m jstart
62781 mp1adm    20   0 1080m  59m  632 S  0.0  0.2  18:59.32 119m igspw_mt
62811 mp1adm    20   0 4701m  44m 9736 S  0.0  0.1 104:23.36 111m icman
 4043 dacadm    20   0 5148m 224m 6380 S  0.0  0.7 627:31.25 110m jstart
35973 daaadm    20   0 5730m 1.2g 2396 S  1.3  3.8   2346:05  75m java




1-333498611	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_C:[PROBLEM:588611] Date: Jan 16,2018 17:0 CUT Severity: Major ResourceId: ri3lr019 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 9.98 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: DAL09AMMTS001 NodeAlias: 146.89.140.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3372183:mic

1.89 GB free of 2 GB on C drive




1-333512852
10.13.1.16 
Hello Team, 

Need add to space 24 GB in FS  /usr/sap/PBI and  add 10 GB in FS - /usr/sap/trans  as below system details
IP - 10.13.1.16

Thanks
Shrikant

[root@DLBPBIDA00 ibmrmalik]# df -hT /usr/sap/PBI
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/pbiappvg-pbiusrPBI_lv
                     ext3   30G   21G  7.6G  74% /usr/sap/PBI		add 16GB

/usr/sap/PBI - 16 GB




[root@DLBPBIDA00 ibmrmalik]# df -hT /usr/sap/trans
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/pbiappvg-usrtrans_lv
                     ext3   40G   12G   26G  31% /usr/sap/trans

[root@DLBPBIDA00 ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g    2.50g
  pbiappvg    1  13   0 wz--n- 128.00g   18.00g
  pbiarchvg   1   1   0 wz--n-  64.00g   14.00g
  pbidatavg   1   7   0 wz--n- 128.00g 1020.00m
  pbilogvg    1   4   0 wz--n-  32.00g 1020.00m


ok add 16 GB  - usr/sap 
[root@DLBPBIDA00 ibmrmalik]# lvs
  LV             VG        Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  lv_home        VolGroup  -wi-ao----  2.00g
  lv_mon         VolGroup  -wi-ao----  5.00g
  lv_opt         VolGroup  -wi-ao----  5.00g
  lv_root        VolGroup  -wi-ao---- 10.00g
  lv_swap        VolGroup  -wi-ao----  8.00g
  lv_tmp         VolGroup  -wi-ao----  2.00g
  lv_var         VolGroup  -wi-ao----  5.00g
  backup_lv      pbiappvg  -wi-ao----  5.00g
  daaadm_lv      pbiappvg  -wi-ao----  1.00g
  pbi3rdprty_lv  pbiappvg  -wi-ao----  1.00g
  pbiIntface_lv  pbiappvg  -wi-ao----  1.00g
  pbiadm_lv      pbiappvg  -wi-ao----  1.00g
  pbisapmnt_lv   pbiappvg  -wi-ao---- 16.00g
  pbiusrPBI_lv   pbiappvg  -wi-ao---- 30.00g
  sapadm_lv      pbiappvg  -wi-ao----  1.00g
  sapstage_lv    pbiappvg  -wi-ao----  5.00g
  usrsap_lv      pbiappvg  -wi-ao----  1.00g
  usrsapccms_lv  pbiappvg  -wi-ao----  4.00g
  usrsapdaa_lv   pbiappvg  -wi-ao----  4.00g
  usrtrans_lv    pbiappvg  -wi-ao---- 40.00g
  pbilogarch_lv  pbiarchvg -wi-ao---- 50.00g
  pbisapdata1_lv pbidatavg -wi-ao---- 23.00g
  pbisapdata2_lv pbidatavg -wi-ao---- 23.00g
  pbisapdata3_lv pbidatavg -wi-ao---- 23.00g
  pbisapdata4_lv pbidatavg -wi-ao---- 23.00g
  pbisaptemp_lv  pbidatavg -wi-ao---- 22.00g
  pbisybase_lv   pbidatavg -wi-ao----  8.00g
  pbisybtemp_lv  pbidatavg -wi-ao----  5.00g
  pbisybdiag_lv  pbilogvg  -wi-ao----  5.00g
  pbisyblog1_lv  pbilogvg  -wi-ao---- 22.00g
  pbisybsystm_lv pbilogvg  -wi-ao----  3.00g
  sybase_lv      pbilogvg  -wi-ao----  1.00g


[root@DLBPBIDA00 ibmrmalik]# lvdisplay |grep -i usrtrans_lv
  LV Path                /dev/pbiappvg/usrtrans_lv
  LV Name                usrtrans_lv


lvextend -L +16G /dev/pbiappvg/usrtrans_lv		usrtrans_lv    pbiappvg  -wi-ao---- 56.00g

df -hT 
/dev/mapper/pbiappvg-usrtrans_lv
                     ext3   40G   12G   26G  31% /usr/sap/trans

resize2fs /dev/pbiappvg/usrtrans_lv
[root@DLBPBIDA00 ibmrmalik]# resize2fs /dev/pbiappvg/usrtrans_lv
resize2fs 1.41.12 (17-May-2010)
Filesystem at /dev/pbiappvg/usrtrans_lv is mounted on /usr/sap/trans; on-line resizing required
old desc_blocks = 3, new_desc_blocks = 4
Performing an on-line resize of /dev/pbiappvg/usrtrans_lv to 14680064 (4k) blocks.
The filesystem on /dev/pbiappvg/usrtrans_lv is now 14680064 blocks long.


[root@DLBPBIDA00 ibmrmalik]# df -hT /dev/pbiappvg/usrtrans_lv
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/pbiappvg-usrtrans_lv
                     ext3   56G   12G   41G  22% /usr/sap/trans




10.6.7.22	[ibmrmalik@PBBffpapdb00 ~]$ date
Wed Jan 17 19:39:14 SGT 2018

10.6.7.19 - PBBbwhpdb00 that is incorrect time zone - ICT 


10.6.7.20 - PBBbwhpap00  that is incorrect time zone - ICT





1-333512852	10.13.1.16
Please add in /usr/sap/PBI - 32 GB more

/dev/mapper/pbiappvg-pbiusrPBI_lv


-------------------------------------------------------------------------------------------------------------------

18 Jan

1-333555611  -   -   IBM AMM Infrastructure sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/TSMLOGS/TLOG[PROBLEM:601916] Date: Jan 18,2018 3:58 CUT Severity: Critical ResourceId: sng01ammtsm001 TicketGroup: ApsSAPTechnical CustomerCode: amm InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/TSMLOGS/TLOG InstanceValue: 4.54 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: sng01ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.178 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/TSMLOGS/TLOG AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3375784:amm
[root@sng01ammtsm001 TSMLOGS]# du -mch --max-depth=1 .
295G    ./ALOG
392G    ./TLOG
686G    .
686G    total


[root@sng01ammtsm001 ALOG]# du -mch --max-depth=1 .
4.0K    ./lost+found
295G    ./NODE0000
295G    .
295G    total


[root@sng01ammtsm001 TLOG]#  du -mch --max-depth=1 .
391G    ./tsminst1
20K     ./NODE0000
4.0K    ./lost+found
391G    .
391G    total



[root@sng01ammtsm001 ibmrmalik]# df -hT /TSMLOGS/TLOG		add 5GB
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/tsmlog01_vg-tsmtlog_lv
                     ext4  413G  392G  181M 100% /TSMLOGS/TLOG

lvextend -L +5G  /dev/mapper/tsmlog01_vg-tsmtlog_lv
resize2fs /dev/mapper/tsmlog01_vg-tsmtlog_lv


[root@sng01ammtsm001 ibmrmalik]# fdisk -l /dev/mapper/tsmlog01_vg-tsmtlog_lv

Disk /dev/mapper/tsmlog01_vg-tsmtlog_lv: 455.3 GB, 455266533376 bytes
255 heads, 63 sectors/track, 55349 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 262144 bytes / 262144 bytes
Disk identifier: 0x00000000


[root@sng01ammtsm001 ibmrmalik]# fdisk -l /dev/mapper/tsmlog01_vg-tsmtlog_lv

Disk /dev/mapper/tsmlog01_vg-tsmtlog_lv: 455.3 GB, 455266533376 bytes
255 heads, 63 sectors/track, 55349 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 262144 bytes / 262144 bytes
Disk identifier: 0x00000000





Disk /dev/mapper/tsmlog01_vg-tsmalog_lv: 338.2 GB, 338228674560 bytes
255 heads, 63 sectors/track, 41120 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 262144 bytes / 262144 bytes
Disk identifier: 0x00000000


Disk /dev/mapper/tsmlog01_vg-tsmtlog_lv: 449.9 GB, 449897824256 bytes
255 heads, 63 sectors/track, 54696 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 262144 bytes / 262144 bytes
Disk identifier: 0x00000000


[root@sng01ammtsm001 ibmrmalik]# vgs
  VG          #PV #LV #SN Attr   VSize   VFree
  tsmdb01_vg    1   1   0 wz--n- 744.68g     0
  tsmdb02_vg    1   1   0 wz--n- 744.68g     0
  tsmdb03_vg    1   1   0 wz--n- 744.68g     0
  tsmdb04_vg    1   1   0 wz--n- 744.68g     0
  tsmlog01_vg   1   2   0 wz--n- 744.68g 10.68g
  tsmqst01_vg   3   5   0 wz--n-  84.27t     0
  tsmqst02_vg   3   5   0 wz--n-  84.27t 68.00m
  tsmstg01_vg   1   5   0 wz--n-  50.94t     0
  tsmstg02_vg   1   6   0 wz--n-  50.94t     0




1-333555591  -    -  IBM AMM Infrastructure		sev2 for same issue as above






1-333554606 	time zone change	sev3
*** Details of Generic Service Request - DO NOT CHANGE ***

Need to change time zone to UTC +7  as below systems

IP - 10.6.7.19 - PBBbwhpdb00 that is incorrect time zone - ICT
IP - 10.6.7.20 - PBBbwhpap00  that is incorrect time zone - ICT 

Before change call to me 8586857871or ping me shrikant.jain@in.ibm.com

Thanks
Shrikant

Ravi nikal gaye kya? 
6:44:50 PM: asingh2@us.ibm.com - Ajay Singh 2/Raleigh/Contr/IBM: /usr/share/zoneinfo/Asia/Bangkok 
6:44:57 PM: asingh2@us.ibm.com - Ajay Singh 2/Raleigh/Contr/IBM: please provide him this TZ 
6:45:03 PM: asingh2@us.ibm.com - Ajay Singh 2/Raleigh/Contr/IBM: to be used on server   





1-333559641	sev1
Summary: Zabbix_agent_on_tor01ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:603008] Date: Jan 18,2018 7:9 CUT Severity: Critical ResourceId: tor01ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: tor01ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.141.91 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3376105:amm

[root@tor01ammsol01 ibmrmalik]# uptime
 01:32:39 up 132 days, 15:47,  1 user,  load average: 2.60, 6.50, 11.55


[root@tor01ammsol01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  2265) is running...





1-333566031	sev3
Summary: Processor_load_is_too_high_on_WINT330[PROBLEM:604572] Date: Jan 18,2018 10:38 CUT Severity: Minor ResourceId: wint330 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 22.083333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT330 NodeAlias: 10.136.0.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3376638:mt5




1-333554506
umount /TemporaryBackup
mount  10.11.2.32:/TemporaryBackup /TemporaryBackup
IPLSAFIDX01 	10.138.2.32	10.11.2.32





1-333571031	NTP_time_is_driffted_on_LONMAGSPO0001.imzcloud.ibmammsap.local[PROBLEM:605179]	2	Sandeep
1-333571011	NTP_time_is_driffted_on_AFRS4HPRDDB.imzcloud.ibmammsap.local[PROBLEM:605167]	2	Sandeep
1-333571561	NTP_time_is_driffted_on_LONMAGSLM0007.imzcloud.ibmammsap.local[PROBLEM:605178]	2	Sandeep
1-333555591	Processor_load_is_too_high_on_WINT330[PROBLEM:602890]	3	Sandeep


--------------------------------------------------------------------------------------

19 Jan

1-333594231
Customer: Mitsui-Soko Holdings Co. Ltd (MT5) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: Processor_load_is_too_high_on_WINT331[PROBLEM:611239] Date: Jan 19,2018 5:2 CUT Severity:
Severity: 3-Standard
Long Description: Summary: Processor_load_is_too_high_on_WINT331[PROBLEM:611239] Date: Jan 19,2018 5:2 CUT Severity: Minor ResourceId: wint331 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 10.283333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT331 NodeAlias: 10.136.0.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3378450:mt5



1-333594141
Summary: Zabbix_agent_on_iplsafidt01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:611217] Date: Jan 19,2018 4:56 CUT Severity: Critical ResourceId: iplsafidt01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ipl InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: iplsafidt01.imzcloud.ibmammsap.local NodeAlias: 10.138.3.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3378436:ipl




1-333591681
Summary: Zabbix_agent_on_WNXECCDBP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:609822] Date: Jan 19,2018 0:50 CUT Severity: Critical ResourceId: wnxeccdbp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: wnx InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: WNXECCDBP01.imzcloud.ibmammsap.local NodeAlias: 10.143.21.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3378061:wnx




1-333596511
Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:611499] Date: Jan 19,2018 5:43 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 14.116667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3378527:mt5




1-333601701
Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:612612] Date: Jan 19,2018 8:34 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 15.45 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3378963:mt5




1-333602031
Description: Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:612879] Date: Jan 19,2018 9:26 CUT Severity:
Severity: 3-Standard
Long Description: Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:612879] Date: Jan 19,2018 9:26 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 4.15 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3379048:mt5




1-333605131
Summary: Processor_load_is_too_high_on_HKG02AMMADC001[PROBLEM:613250] Date: Jan 19,2018 10:39 CUT Severity: Minor ResourceId: hkg02ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 6.4 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: HKG02AMMADC001 NodeAlias: 146.89.141.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3379172:amm



1-333591681
Summary: Zabbix_agent_on_WNXECCDBP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:609822] Date: Jan 19,2018 0:50 CUT Severity: Critical ResourceId: wnxeccdbp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: wnx InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: WNXECCDBP01.imzcloud.ibmammsap.local NodeAlias: 10.143.21.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3378061:wnx


1-333605341
Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:613451] Date: Jan 19,2018 11:5 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 5.35 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3379214:mt5


1-333607611	sev2
Description: Summary: Lack_of_free_swap_space_on_SK3SLTPRD01.imzcloud.ibmammsap.local[PROBLEM:613442] Date: Jan
Severity: 2-Urgent
Long Description: Summary: Lack_of_free_swap_space_on_SK3SLTPRD01.imzcloud.ibmammsap.local[PROBLEM:613442] Date: Jan 19,2018 11:4 CUT Severity: Major ResourceId: sk3sltprd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.84 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3SLTPRD01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.34 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3379209:sk3

[root@SK3SLTPRD01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         31          0          1          0          1
-/+ buffers/cache:         29          1
Swap:           47         23         24


top - 14:46:12 up 133 days, 22:33,  1 user,  load average: 1.17, 1.33, 1.42
Tasks: 360 total,   2 running, 358 sleeping,   0 stopped,   0 zombie
Cpu(s): 23.1%us,  0.9%sy,  0.0%ni, 74.3%id,  1.3%wa,  0.0%hi,  0.4%si,  0.0%st
Mem:    31.350G total,   31.128G used,  227.566M free, 9100.000k buffers
Swap:   48.000G total,   23.970G used,   24.030G free, 1521.441M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
51079 slpadm    20   0 1429m  11m 1148 S  1.3  0.0   2531:44 785m en.sapSLP_ASCS0
42954 slpadm    20   0 39.8g 9.6g 121m S  2.0 30.8   6966:37 431m SLP_00_BTC_W51
53671 slpadm    20   0 30.1g 354m 327m S  0.0  1.1  37:26.30 221m SLP_00_DIA_W23
53674 slpadm    20   0 30.1g 414m 363m S  0.0  1.3  55:00.94 213m SLP_00_DIA_W26
53668 slpadm    20   0 30.1g 410m 356m S  0.0  1.3  55:37.53 206m SLP_00_DIA_W20
53649 slpadm    20   0 30.1g 372m 334m S  0.0  1.2  11:40.56 206m SLP_00_DIA_W1
53675 slpadm    20   0 30.1g 411m 351m S  0.0  1.3  53:33.74 200m SLP_00_DIA_W27
53665 slpadm    20   0 30.1g 388m 343m S  0.0  1.2  29:08.84 200m SLP_00_DIA_W17
58431 daaadm    20   0 5141m 174m 4500 S  0.0  0.5  20:29.49 199m jstart
53676 slpadm    20   0 30.1g 421m 353m S  2.7  1.3  46:49.65 199m SLP_00_DIA_W28
53653 slpadm    20   0 30.0g 345m 324m S  0.0  1.1  20:19.12 196m SLP_00_DIA_W5
53670 slpadm    20   0 30.1g 397m 345m S  0.0  1.2  50:04.00 196m SLP_00_DIA_W22
53677 slpadm    20   0 30.1g 422m 354m S  0.0  1.3  55:43.27 195m SLP_00_DIA_W29
53664 slpadm    20   0 30.1g 406m 364m S  0.0  1.3  32:06.97 194m SLP_00_DIA_W16
53672 slpadm    20   0 30.1g 393m 342m S  0.0  1.2  59:29.31 194m SLP_00_DIA_W24
53660 slpadm    20   0 30.1g 387m 344m S  0.0  1.2  27:32.92 189m SLP_00_DIA_W12
53662 slpadm    20   0 30.0g 433m 376m S  0.0  1.4  24:28.09 186m SLP_00_DIA_W14
53667 slpadm    20   0 30.0g 442m 385m S  0.0  1.4  50:25.42 185m SLP_00_DIA_W19
53673 slpadm    20   0 30.0g 402m 340m S  0.0  1.3  56:38.82 182m SLP_00_DIA_W25
53661 slpadm    20   0 30.1g 428m 364m S  0.0  1.3  21:46.27 179m SLP_00_DIA_W13
53663 slpadm    20   0 30.1g 418m 356m S  0.0  1.3  35:11.76 179m SLP_00_DIA_W15


---------------------------------------------------------------------------------------------------------------------------------------------------------------

22 Jan

SR 1-333691821 has been assigned:
Short Description:  Summary: Processor_load_is_too_high_on_SNG01AMMADC001[PROBLEM:640626] Date: Jan 22,2018 5:5 CUT Sev
Long Description: Summary: Processor_load_is_too_high_on_SNG01AMMADC001[PROBLEM:640626] Date: Jan 22,2018 5:5 CUT Severity: Minor ResourceId: sng01ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 5.916667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SNG01AMMADC001 NodeAlias: 146.89.140.140 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3385604:amm
Severity: 3-Standard
Source:  TEC



1-333691991
Customer: American Airlines SAP HEC-AMM 
Performer: AMM-DELIVERY-TECH 
Description: Summary: Zabbix_agent_on_ahecphdb01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:640774] Date: J
Severity: 1-Critical
Long Description: Summary: Zabbix_agent_on_ahecphdb01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:640774] Date: Jan 22,2018 5:30 CUT Severity: Critical ResourceId: ahecphdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: a1a InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ahecphdb01.imzcloud.ibmammsap.local NodeAlias: 10.4.9.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3385640:a1a



1-333692341	sev2	
Summary: NTP_time_is_driffted_on_LBDCD1App00.imzcloud.ibmammsap.local[PROBLEM:640965] Date: Jan 22,2018 5:52 CUT Severity: Major ResourceId: lbdcd1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -5.13 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDCD1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3385695:lbd


AMM-DELIVERY-TECH,
SR 1-333694921 has been assigned:
Short Description:  Summary: NTP_time_is_driffted_on_ms3wdcwapp08.imzcloud.ibmammsap.local[PROBLEM:641216] Date: Jan 22
Long Description: Summary: NTP_time_is_driffted_on_ms3wdcwapp08.imzcloud.ibmammsap.local[PROBLEM:641216] Date: Jan 22,2018 6:13 CUT Severity: Major ResourceId: ms3wdcwapp08 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -5.2 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: ms3wdcwapp08.imzcloud.ibmammsap.local NodeAlias: 10.12.6.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3385756:ms3
Severity: 2-Urgent
Source:  TEC


1-333590156
Unable to connect to server
AFRS4HPRDDB - 10.197.0.11 , Unable to connect to this server with IMZ user. Please check
AFRS4HPRDDB 	DB 	RedHat 6.5 	10.65.1.11 	10.197.0.11 	lonhana-1024-5 



SR No: 1-333695191 has been assigned to you.	

Customer: SMRT Corp - SAP HEC-AMM 
Performer: AMM-DELIVERY-TECH 
Description: Summary: NTP_time_is_driffted_on_CLDBOBIADWP1.imzcloud.ibmammsap.local[PROBLEM:641318] Date: Jan 22
Severity: 2-Urgent
Long Description: Summary: NTP_time_is_driffted_on_CLDBOBIADWP1.imzcloud.ibmammsap.local[PROBLEM:641318] Date: Jan 22,2018 6:26 CUT Severity: Major ResourceId: cldbobiadwp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.06 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CLDBOBIADWP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.70 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3385789:sm5

[root@CLDBOBIADWP1 ibmrmalik]# /etc/init.d/ntpd status
ntpd (pid  3565) is running...
[root@CLDBOBIADWP1 ibmrmalik]# ntpstat
synchronised to unspecified at stratum 8
   time correct to within 2045 ms
   polling server every 1024 s
[root@CLDBOBIADWP1 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 sng01ammadc001. 146.89.140.138   7 u 1005 1024  377    0.713  -15585. 2262.29
 sng01ammadc002. 146.89.140.138   7 u  763 1024  377    0.686  -15696. 2247.86
[root@CLDBOBIADWP1 ibmrmalik]# uptime
 20:53:02 up 41 days,  4:07,  1 user,  load average: 0.00, 0.01, 0.00
[root@CLDBOBIADWP1 ibmrmalik]#


SR No: 1-333704551 has been assigned to you.

Customer: IBM MSD Infras - Cloud MONITORING 
Performer: AMM-DELIVERY-TECH 
Description: Summary: NTP_time_is_driffted_on_DAL09AMMCHEF01.imzcloud.ibmammsap.local[PROBLEM:643406] Date: Jan
Severity: 2-Urgent
Long Description: Summary: NTP_time_is_driffted_on_DAL09AMMCHEF01.imzcloud.ibmammsap.local[PROBLEM:643406] Date: Jan 22,2018 12:29 CUT Severity: Major ResourceId: ri3lr022 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: 8.11 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: DAL09AMMCHEF01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3386385:mic




SR No: 1-333703061 has been assigned to you.

Customer: Suncor Energy Inc. (SNC) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: NTP_time_is_driffted_on_snchepjqa14.imzcloud.ibmammsap.local[PROBLEM:643272] Date: Jan 22,
Severity: 2-Urgent
Long Description: Summary: NTP_time_is_driffted_on_snchepjqa14.imzcloud.ibmammsap.local[PROBLEM:643272] Date: Jan 22,2018 12:0 CUT Severity: Major ResourceId: snchepjqa14 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.03 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: snchepjqa14.imzcloud.ibmammsap.local NodeAlias: 10.73.12.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3386333:snc
--------------------------------------------------------------------------------------------------------------------------

23 Jan


1-333711791	sev2 wait for clear event
Summary: NTP_time_is_driffted_on_smtmquaqt3.imzcloud.ibmammsap.local[PROBLEM:644928] Date: Jan 22,2018 16:14 CUT Severity: Major ResourceId: smtmquaqt3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.01 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: smtmquaqt3.imzcloud.ibmammsap.local NodeAlias: 10.78.24.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3386763:cma


1-333692741	sev2	wait for clear event
Summary: NTP_time_is_driffted_on_smdbdevdw3.imzcloud.ibmammsap.local[PROBLEM:640998] Date: Jan 22,2018 5:57 CUT Severity: Major ResourceId: smdbdevdw3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.11 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: smdbdevdw3.imzcloud.ibmammsap.local NodeAlias: 10.78.22.45 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3385704:cma


1-333699791	sev2 awaiting clearing event
Summary: NTP_time_is_driffted_on_smdbsbxsm1.imzcloud.ibmammsap.local[PROBLEM:642452] Date: Jan 22,2018 9:24 CUT Severity: Major ResourceId: smdbsbxsm1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.2 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: smdbsbxsm1.imzcloud.ibmammsap.local NodeAlias: 10.78.20.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3386060:cma



SR No: 1-333749691 has been assigned to you.		du -mch --max-depth=1 .
Customer: Suncor Energy Inc. (SNC) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: Free_disk_space_is_less_than_20%_on_DB_volume_/backup[PROBLEM:651059] Date: Jan 23,2018 4:
Severity: 3-Standard
Long Description: Summary: Free_disk_space_is_less_than_20%_on_DB_volume_/backup[PROBLEM:651059] Date: Jan 23,2018 4:48 CUT Severity: Minor ResourceId: snchtnadd11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup InstanceValue: 10.05 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: snchtnadd11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3388696:snc



SR No: 1-333749391 has been assigned to you.   sev1

Customer: Suncor Energy Inc. (SNC) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: Free_disk_space_is_less_than_5%_on_DB_volume_/backup[PROBLEM:651062] Date: Jan 23,2018 4:5
Severity: 1-Critical
Long Description: Summary: Free_disk_space_is_less_than_5%_on_DB_volume_/backup[PROBLEM:651062] Date: Jan 23,2018 4:50 CUT Severity: Critical ResourceId: snchtnadd11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: snchtnadd11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3388700:snc

[root@snchtnadd11 backup]# du -mch --max-depth=1 .
1.3G    ./SWPM10SP21_7_Linux
4.0K    ./Bkp_230118
1004K   ./c++
206M    ./tmp_import
22G     ./export
16K     ./lost+found
23G     .
23G     total

-rwxrwxrwx 1 tchandraseka domain users   21367703 Jan 22 11:07 SAPEXEDB_400-70000607.SAR
-rwxrwxrwx 1 tchandraseka domain users  294258301 Jan 22 11:08 SAPEXE_400-70000596.SAR
-rwxrwxrwx 1 tchandraseka domain users 1381671955 Jan 22 14:00 51052426_4.ZIP
drwxrwxrwx 3 tchandraseka domain users       4096 Jan 22 14:20 SYBASE_ASE_16.0.02.07_RDBMS_for_BS_
-rwxrwxrwx 1 tchandraseka domain users 1221284771 Jan 22 15:59 51051432_3.ZIP
[root@snchtnadd11 export]# pwd
/backup/export




SR No: 1-333745731 has been assigned to you.	

Customer: Toyota Financial Services - SAP HEC-AMM 
Performer: AMM-DELIVERY-TECH 
Description: Summary: ITM Agent Offline: DALTFSBDSP001HTTPdp:UAGENT00 Date: 01/22/2018 Severity: Major ResourceI
Severity: 2-Urgent
Long Description: Summary: ITM Agent Offline: DALTFSBDSP001HTTPdp:UAGENT00 Date: 01/22/2018 Severity: Major ResourceId: daltfsbdsp001 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: toy InstanceId: DALTFSBDSP001:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: daltfsbdsp001 NodeAlias: 10.82.177.194 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3388330:toy

DALTFSBDSP001 	SAP BOBJ PROD Data Services Server 	Redhat 	App+DB 	PRD 	DSP 	10.82.177.194 	10.4.1.194




SR No: 1-333746411 has been assigned to you.	wait for clearing event

Customer: Bombardier Recreational Products Inc. (BR3) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: NTP_time_is_driffted_on_BRPCAMLVSA07D.imzcloud.ibmammsap.local[PROBLEM:650452] Date: Jan 2
Severity: 2-Urgent
Long Description: Summary: NTP_time_is_driffted_on_BRPCAMLVSA07D.imzcloud.ibmammsap.local[PROBLEM:650452] Date: Jan 23,2018 3:0 CUT Severity: Major ResourceId: brpcamlvsa07d TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: br3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 5.14 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: BRPCAMLVSA07D.imzcloud.ibmammsap.local NodeAlias: 10.138.10.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3388514:br3



AMM-DELIVERY-TECH,	sev3
SR 1-333758001 has been assigned:
Short Description:  Summary: Drive_with_Errors_on_dalhana-1024-2.xsportal.local[PROBLEM:653193] Date: Jan 23,2018 9:49
Long Description: Summary: Drive_with_Errors_on_dalhana-1024-2.xsportal.local[PROBLEM:653193] Date: Jan 23,2018 9:49 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local InstanceValue: Media Error Count = 2 Media Error Count = 121 Media Error Count ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_dalhana-1024-2.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3389320:amm
Severity: 3-Standard
Source:  TEC


root / 10.121.75.5	Cnsas6h9	Ticket 54435351 has been successfully created.




SR No: 1-333757271 has been assigned to you.

Customer: Mitsui-Soko Holdings Co. Ltd (MT5) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: Processor_load_is_too_high_on_WINT330[PROBLEM:653918] Date: Jan 23,2018 11:43 CUT Severity
Severity: 3-Standard
Long Description: Summary: Processor_load_is_too_high_on_WINT330[PROBLEM:653918] Date: Jan 23,2018 11:43 CUT Severity: Minor ResourceId: wint330 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 22.633333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT330 NodeAlias: 10.136.0.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3389496:mt5
------------------------------------------------------------------------------------------------------------------------------------------------


24 Jan

1-333786471	Summary: Processor_load_is_too_high_on_WINT330
sev3



SR No: 1-333785861 has been assigned to you.	sev2
Customer: PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC) 
Performer: AMM-DELIVERY-TECH 
Description: Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local[PROBLEM:659456] Date: Jan 24,2018 1:36 C
Severity: 2-Urgent
Long Description: Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local[PROBLEM:659456] Date: Jan 24,2018 1:36 CUT Severity: Major ResourceId: c1bwd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWD.imzcloud.ibmammsap.local NodeAlias: 10.199.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3390982:pnc


1-333788881	sev3	
Description: Summary: Processor_load_is_too_high_on_WINT330[PROBLEM:660720] Date: Jan 24,2018 4:55 CUT Severity:
Severity: 3-Standard
Long Description: Summary: Processor_load_is_too_high_on_WINT330[PROBLEM:660720] Date: Jan 24,2018 4:55 CUT Severity: Minor ResourceId: wint330 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 22.7 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT330 NodeAlias: 10.136.0.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3391337:mt5




10.121.75.5	dalhana-1024-2.xsportal.local



1-333787881
Description: Summary: NTP_time_is_driffted_on_CI2DEVAPP.imzcloud.ibmammsap.local[PROBLEM:660587] Date: Jan 24,20
Severity: 2-Urgent
Long Description: Summary: NTP_time_is_driffted_on_CI2DEVAPP.imzcloud.ibmammsap.local[PROBLEM:660587] Date: Jan 24,2018 4:35 CUT Severity: Major ResourceId: ci2devapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci2 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 5.22 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CI2DEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.5.242.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3391300:ci2



1-333796651	sev1
Summary: Zabbix_agent_on_smdbdevd41.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:662351] Date: Jan 24,2018 8:49 CUT Severity: Critical ResourceId: smdbdevd41 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: smdbdevd41.imzcloud.ibmammsap.local NodeAlias: 10.78.22.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3391808:cma


10.127.155.70	parhana-1024-15.xsportal.local		root AFl3BqkNnv



1-333797401
Lack_of_free_swap_space_on_LBDSP1App00.imzcloud.ibmammsap.local	sev2




1-333796901
Summary: Zabbix_agent_on_WINT330_is_unavailable   sev2
Long Description: Summary: Zabbix_agent_on_WINT330_is_unavailable[PROBLEM:662548] Date: Jan 24,2018 9:17 CUT Severity: Major ResourceId: wint330 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Agent_availability Node: WINT330 NodeAlias: 10.136.0.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3391850:mt5



1-333799411
Description: Summary: Processor_load_is_too_high_on_WINT333[PROBLEM:663832] Date: Jan 24,2018 12:40 CUT Severity
Severity: 3-Standard
Long Description: Summary: Processor_load_is_too_high_on_WINT333[PROBLEM:663832] Date: Jan 24,2018 12:40 CUT Severity: Minor ResourceId: wint333 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 9.766667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT333 NodeAlias: 10.136.0.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3392216:mt5

----------------------------------------------------------------------------------------------------------------------------------------

25 Jan

1-333528361	
Summary: NTP_time_is_driffted_on_cldbpcdtbp1dr.imzcloud.ibmammsap.local[PROBLEM:595635] Date: Jan 17,2018 11:55 CUT Severity: Major ResourceId: cldbpcdtbp1dr TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 5.22 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: cldbpcdtbp1dr.imzcloud.ibmammsap.local NodeAlias: 10.204.0.142 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3374104:sm5

[root@cldbpcdtbp1dr ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 sng01ammadc001. 146.89.140.138   7 u   32   64    1  215.266    4.433   1.711
 sng01ammadc002. 146.89.140.138   7 u   30   64    1  214.807  -16.918   0.755





1-333681541	sev3
Summary: TSM: fra02ammtsm001 ANE4047E There is a read error on '/var/opt/ds_agent/am/icrc$oth.915'. The file is skipped.~~ Date: 01/21/18 15:46 CST Severity: Minor ResourceId: fra02ammtsm001 TicketGroup: AMM-BUR CustomerCode: amm InstanceId: 4047MAG_FRAMAGBWH0006_FIL>FRA02AMMTSM001:DLY_INC_2230 InstanceValue: ANE4047E There is a read error on '/var/opt/ds_agent/am/icrc$oth ComponentType: ManagementInfrastructure Component: TSM Node: fra02ammtsm001 NodeAlias: framagbwh0006.imzcloud.ibmammsap.local Manager: fra02ammtsm001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: TSM:ADSM_BACKUP_ARCHIVE_CLIENT:MAG_FRAMAGBWH0006_FIL>FRA02AMMTSM001 AlertGroup: TSM_CLIENT_EVENT EventKey: USRD0P0MSDP:3384846:amm
Frankfurt 	IBM MGMT 	Physical 	NA 	fra02ammtsm001.ibmammsap.local 	146.89.140.242 	10.134.17.79 	TSM 	RHEL 6
Site 	Zone 	Type 	VM Name 	Hostname 	IMZ IP 	SL IP 	Notes 	OS

[root@fra02ammtsm001 am]# ls -ltr
total 308
drwxr-xr-x. 6 root root     59 Aug 25 15:37 vsapi
-rw-r--r--. 1 root root    173 Aug 25 15:37 log.ini
-rw-r--r--. 1 root root     32 Jan 15 06:12 cache.dat
-rw-------. 1 root root  36864 Jan 15 06:13 am.db
-rw-r--r--. 1 root root 251338 Jan 15 06:13 curl-ca-bundle.crt
-rw-r--r--. 1 root root      5 Jan 15 06:13 ds_am.pid
-rw-r--r--. 1 root root      0 Jan 15 06:13 icrc_diagnostic.log
srwxr-xr-x. 1 root root      0 Jan 15 06:13 am_cmd_socket
-rw-r--r--. 1 root root     12 Jan 15 06:13 ds_agent.version
-rw-r--r--. 1 root root   1066 Jan 23 22:02 amgblcfg.xml
lrwxrwxrwx. 1 root root     23 Jan 24 22:46 tmwhite.473 -> ../patterns/tmwhite.473
lrwxrwxrwx. 1 root root     23 Jan 24 22:46 tmblack.235 -> ../patterns/tmblack.235
lrwxrwxrwx. 1 root root     22 Jan 24 22:46 ssaptn.911 -> ../patterns/ssaptn.911
lrwxrwxrwx. 1 root root     23 Jan 24 22:46 lpt$vpn.923 -> ../patterns/lpt$vpn.923
lrwxrwxrwx. 1 root root     24 Jan 24 22:46 icrc$oth.923 -> ../patterns/icrc$oth.923
-rw-r--r--. 1 root root     47 Jan 24 22:46 pattern.info
[root@fra02ammtsm001 am]# pwd
/var/opt/ds_agent/am


--------------------------------------------------------------------------------------------------------------------------------------------


29 Jan


1-333923561	sev3
Summary: Processor_load_is_too_high_on_GRC01[PROBLEM:713811] Date: Jan 29,2018 4:17 CUT Severity: Minor ResourceId: grc01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cng InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 6.625 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: GRC01 NodeAlias: 10.68.210.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3402286:cng




RE: MAG - 594536 / 2017 - Install Diagnostics Agent (LONMAGSWD0001 / WP1) ; 1-332516652 - New disk required...
WP1 - LONMAGSWD0001 / 10.69.3.10 
/dev/mapper/vg_app-lv_usrsap
                     ext4    44G  6.1G   35G  15% /usr/sap

/usr/sap/DAA 

vg_app   2   2   0 wz--n- 55.99g   1.99g

[root@LONMAGSWD0001 ibmrmalik]# df -hT
Filesystem           Type   Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                     ext4    26G  6.9G   18G  29% /
tmpfs                tmpfs  3.9G  8.0K  3.9G   1% /dev/shm
/dev/sda1            ext4   477M  106M  347M  24% /boot
/dev/mapper/vg_app-lv_usrsap
                     ext4    44G  6.1G   35G  15% /usr/sap
/dev/mapper/vg_app-lv_sapmnt
                     ext4   9.8G  420M  8.9G   5% /sapmnt
/dev/mapper/vg01-ITMLV
                     ext4   5.2G  305M  4.6G   7% /opt/monitor/IBM
146.89.140.30:/storage/library
                     nfs    3.6T  2.5T  960G  73% /storage/library

A new filesystem needs to be created in this system :
Filesystem name :  /usr/sap/DAA
Filesystem side : 4 GB 





1-333909051		sev3	transferred to SAP
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/DAA[PROBLEM:705770] Date: Jan 28,2018 12:12 CUT Severity: Minor ResourceId: lbdpd1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Free_disk_space_on_/usr/sap/DAA_(percentage) InstanceValue: 20 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_disk_space_on_/usr/sap/DAA_ Node: LBDPD1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_disk_space_on_/usr/sap/DAA_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3401016:lbd

[root@LBDPD1App00 DAA]# du -mch --max-depth=1 .
16K     ./lost+found
679M    ./SYS
2.3G    ./SMDA98
3.0G    .
3.0G    total
[root@LBDPD1App00 DAA]# cd ./SMDA98
[root@LBDPD1App00 SMDA98]# ls -ltr
total 20
drwxr-xr-x 4 daaadm sapsys 4096 Sep 22  2016 exe
drwx------ 2 daaadm sapsys 4096 Sep 22  2016 sec
drwxr-xr-x 9 daaadm sapsys 4096 Oct  5 21:04 SMDAgent
drwxr-xr-x 2 daaadm sapsys 4096 Oct  5 23:53 work
drwxr-xr-x 2 daaadm sapsys 4096 Jan 24 10:29 script





1-333922831	sev2	move to SAP	
Summary: Free_inodes_is_less_than_20%_on_volume_/sapmnt/shared[PROBLEM:713344] Date: Jan 29,2018 3:31 CUT Severity: Major ResourceId: ms3wdclvhdb02 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_OS_Linux:Free_inodes_on_/sapmnt/shared_(percentage) InstanceValue: 1.56 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_inodes_on_/sapmnt/shared_(p Node: ms3wdclvhdb02.imzcloud.ibmammsap.local NodeAlias: 10.12.6.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_inodes_on_/sapmnt/shared_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3402228:ms3





1-333908691	sev3	Private IP: 10.121.75.5	UXyz6qWTGm / root
Summary: Drive_with_Errors_on_dalhana-1024-2.xsportal.local[PROBLEM:705217] Date: Jan 28,2018 11:10 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local InstanceValue: Media Error Count = 2 Media Error Count = 121 Media Error Count ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_dalhana-1024-2.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3400940:amm



1-333900171	sev3
Summary: Drive_with_Media_Errors_on_host_SNJERPDB01.imzcloud.ibmammsap.local[PROBLEM:699908] Date: Jan 27,2018 23:19 CUT Severity: Minor ResourceId: snjerpdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snj InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Check_vmtools_config_file Node: SNJERPDB01.imzcloud.ibmammsap.local NodeAlias: 10.8.10.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3400111:snj




1-333895841	sev2	access denied
Summary: Lack_of_free_swap_space_on_AFRFIORIPRD.imzcloud.ibmammsap.local[PROBLEM:695237] Date: Jan 27,2018 12:41 CUT Severity: Major ResourceId: afrfioriprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: AFRFIORIPRD.imzcloud.ibmammsap.local NodeAlias: 10.197.0.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3399386:afr




1-333889411	sev2	access denied
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:693622] Date: Jan 27,2018 9:8 CUT Severity: Major ResourceId: clderpappq1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 9.99 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPQ1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.211 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3399165:sm5



1-333837131		sev3
Jump Server 169.53.60.88:33891 E: and X: drives RED. Please see attached document for user directories.  Can we increase the size of E: or add another disk?





1-333810281	sev2
Summary: Last backup too old on DB: SX8. Days since last backup: Date: 01/24/2018 Severity: Major ResourceId: smposbxsx8 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: :SX8 InstanceSituation: Last backup too old ComponentType: Database Component: DB2 SubComponent: Backup ApplId: DB2 MsgId: DB2TSA134E Node: smposbxsx8 NodeAlias: 10.78.20.20 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_lastbkp_gudc_sapdb2bk_nprd AlertGroup: ITM_KUDDBASEGROUP01 EventKey: USRD0P0MSDP:3392814:cma



1-333869771	sev3	moved to SAP
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:684641] Date: Jan 26,2018 13:23 CUT Severity: Minor ResourceId: clderpappq1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPQ1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.211 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3397510:sm5

[root@CLDERPAPPQ1 /]# du -mch --max-depth=1 .
6.4G    ./sapmnt
3.4G    ./oracle



1-333472521	sev2	10.135.1.103	WIndows unable to login
Summary: ITM Agent Offline: REXBFCWEB01N:INTERNET00 Date: 01/15/2018 Severity: Major ResourceId: rexbfcweb01n TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: rxl InstanceId: REXBFCWEB01N:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: rexbfcweb01n NodeAlias: 10.134.1.103 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3370102:rxl




1-333930621	sev3	
Summary: Processor_load_is_too_high_on_AQAERPAPPPRD[PROBLEM:716161] Date: Jan 29,2018 9:10 CUT Severity: Minor ResourceId: aqaerpappprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: aqa InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 17.233333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: AQAERPAPPPRD NodeAlias: 10.135.26.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3402736:aqa



1-333931051	sev3	
Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:716724] Date: Jan 29,2018 10:31 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 25.166667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3402859:mt5



1-333931071	sev3
Summary: Processor_load_is_too_high_on_WINT333[PROBLEM:716768] Date: Jan 29,2018 10:33 CUT Severity: Minor ResourceId: wint333 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 11.216667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT333 NodeAlias: 10.136.0.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3402863:mt5





AV notification: AMM - Trend agent offline / out of date / not installed

10.70.110.34	SVGI1SRV0	Windows	AGEAS (AGE) AGE		10.6.2.34	DONE
10.70.111.17	SPSVBPDBHDB01	RedHat	AGEAS (AGE) AGE		10.6.3.17	DONE
10.70.111.12	SPHVEPAEAPP02-DR	RedHat	AGEAS (AGE) AGE		10.6.3.12	DONE
10.70.111.13	SPHVEPAJAPP02-DR	RedHat	AGEAS (AGE) AGE	 	10.6.3.13	DONE
10.70.111.15	SPHVCPACAPP02-DR	RedHat	AGEAS (AGE) AGE		10.6.3.15	DONE
10.70.111.16	SPHVSPAHAPP02-DR	RedHat	AGEAS (AGE) AGE		10.6.3.16	DONE


10.70.111.24	SPHVPPAOAPP02-DR	RedHat	AGEAS (AGE) AGE		10.6.3.24	Done
10.70.111.27	SPHVEPDPASE02-DR	RedHat	AGEAS (AGE) AGE		10.6.3.27	DONE
10.70.111.28	SPHVEPAPAPP02-DR	RedHat	AGEAS (AGE) AGE		10.6.3.28




1-333935811	sev3
Summary: Processor_load_is_too_high_on_WINT333[PROBLEM:717583] Date: Jan 29,2018 12:10 CUT Severity: Minor ResourceId: wint333 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 15.616667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT333 NodeAlias: 10.136.0.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3403020:mt5
-----------------------------------------------------------------------------------------------------------------------------------------------------


30 Jan

1-333895841	sev2
Summary: Lack_of_free_swap_space_on_AFRFIORIPRD.imzcloud.ibmammsap.local[PROBLEM:695237] Date: Jan 27,2018 12:41 CUT Severity: Major ResourceId: afrfioriprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: AFRFIORIPRD.imzcloud.ibmammsap.local NodeAlias: 10.197.0.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3399386:afr
DPE: MARLINA
PDL: RPAVEL



10.73.10.114	snchtnapd61
[ibmrmalik@snchtnapd61 ~]$ sudo su
[root@snchtnapd61 ibmrmalik]# hostname
snchtnapd61
[root@snchtnapd61 ibmrmalik]# hostname -f
snchtnapd61
[root@snchtnapd61 ibmrmalik]# hostname -s
snchtnapd61



127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4

10.73.10.114    snchtnapd61
146.89.141.87 TOR01AMMCHEF01.imzcloud.ibmammsap.local TOR01AMMCHEF01
#Added by IBM automation, do not modify
169.55.28.72   fmsprdtren001.prdcloud.fms.ibmcloud.com
#Added by IBM automation, do not modify
169.55.28.73   fmsprdtren002.prdcloud.fms.ibmcloud.com

10.73.10.114    snchtnapd61.hec.network.lan     snchtnapd61
10.72.0.114     snchtnapd61.hec.network.lan     snchtnapd61

10.73.10.114    snchtnapd61     snchtnapd61.hec.network.lan


corrected the above to



[root@snchtnapd61 ibmrmalik]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
10.73.10.114    snchtnapd61.hec.network.lan     snchtnapd61
#10.73.10.114   snchtnapd61
146.89.141.87 TOR01AMMCHEF01.imzcloud.ibmammsap.local TOR01AMMCHEF01
#Added by IBM automation, do not modify
169.55.28.72   fmsprdtren001.prdcloud.fms.ibmcloud.com
#Added by IBM automation, do not modify
169.55.28.73   fmsprdtren002.prdcloud.fms.ibmcloud.com

10.72.0.114     snchtnapd61.hec.network.lan     snchtnapd61





1-333968851	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:728201] Date: Jan 30,2018 10:21 CUT Severity: Minor ResourceId: bi1bwhdbprd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: bi1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 6.26 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: BI1BWHDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3405221:bi1

[root@BI1BWHDBPRD01 ibmrmalik]# df -h
Filesystem                             Size  Used Avail Use% Mounted on
/dev/sda3                               50G   44G  3.0G  94% /
tmpfs                                  253G  8.0K  253G   1% /dev/shm
/dev/sda1                              194M   30M  155M  16% /boot
/dev/mapper/vghanadata-lv_hana_data    1.5T  275G  1.3T  18% /hana/data
/dev/mapper/vghanadata-lv_hana_shared  512G   87G  426G  17% /hana/shared
/dev/mapper/vghanadata-lv_usr_sap       50G  1.7G   49G   4% /usr/sap
/dev/sdd1                              514G   15G  500G   3% /hana/log
//10.199.20.26/F                       1.0T  968G   57G  95% /mnt/F


[root@BI1BWHDBPRD01 ibmrmalik]# du -mch --max-depth=1 /
53M     /root
164M    /lib
0       /sys
18M     /sbin
6.0G    /sapmnt
30G     /tmp
4.0K    /media
4.0K    /cgroup
27M     /lib64
3.6G    /usr
1.3G    /var
4.0K    /selinux


-----------------------------------------------------------------------------------------------------------------------------------------------


31 January

1-333983960
Please provide with current OS version we have on each servers listed in the attachment. ( marked in yellow )
cat /etc/redhat-release
10.70.1.143
10.70.2.161
10.70.2.165
10.70.1.87


1-333993311	sev3
Summary: Processor_load_is_too_high_on_AQAERPAPPPRD[PROBLEM:736910] Date: Jan 31,2018 5:1 CUT Severity: Minor ResourceId: aqaerpappprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: aqa InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 13.4 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: AQAERPAPPPRD NodeAlias: 10.135.26.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3406892:aqa


1-333982661 sev3
Summary: Processor_load_is_too_high_on_AQAERPAPPPRD[PROBLEM:732071] Date: Jan 30,2018 17:51 CUT Severity: Minor ResourceId: aqaerpappprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: aqa InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 20.033333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: AQAERPAPPPRD NodeAlias: 10.135.26.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3405931:aqa




1-334003251	sev3
Long Description: Summary: FS_is_read_only_on_APLHRHP1.imzcloud.ibmammsap.local[PROBLEM:739960] Date: Jan 31,2018 12:0 CUT Severity: Minor ResourceId: aplhrhp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ap5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /db2/db2hr3 /db2/db2hr3/db2_software /db2/HR3/log_dir ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: APLHRHP1.imzcloud.ibmammsap.local NodeAlias: 170.225.68.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3407651:ap5


[root@APLHRHP1 ibmrmalik]# df -h /db2/db2hr3
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hr3appvg-db2_lv
                      976M  1.3M  924M   1% /db2


[root@APLHRHP1 ibmrmalik]# df -h /db2/db2hr3/db2_software
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hr3appvg-db2_lv
                      976M  1.3M  924M   1% /db2

[root@APLHRHP1 ibmrmalik]# df -h /db2/HR3/log_dir
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hr3datavg-HR3_lv
                      976M  1.3M  924M   1% /db2/HR3




Check df -h to see if the mount /mnt/sapexchangeIT is available,if not showing, unmount and remount. If mount command is failing, run mount -a which will refresh the mounts as per the fstab entry. Ensure the fstab entry is correct only then will mount -a work properly. First check the fstab entry for the mount point that is read only 
cat /etc/fstab|grep sapexchangeIT
//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/  cifs username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003   then run umount /mnt/sapexchangeIT/ and then mount it using mount //10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/  cifs username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003
---------------------------------------------------------------------------------------------------------------------------------------------


1 Feb

1-334023651	sev3	
Summary: Free_disk_space_is_less_than_20%_on_DB_volume_/backup[PROBLEM:745396] Date: Jan 31,2018 23:0 CUT Severity: Minor ResourceId: ia1poprddb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup InstanceValue: 19.86 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: IA1POPRDDB.imzcloud.ibmammsap.local NodeAlias: 10.133.15.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3408982:ia1

[root@IA1POPRDDB ibmrmalik]# df -h /backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pp1archvg-backup_lv
                      5.0G  3.8G  951M  81% /backup

[root@IA1POPRDDB backup]# du -mch --max-depth=1 .
52K     ./tsm
16K     ./lost+found
124K    ./scripts
3.7G    ./full_backup
3.7G    .
3.7G    total





1-333996721





10.4.27.14  fitbit 	clear cache	1-334026181	sev2
Summary: Lack_of_free_swap_space_on_fbtprdhanapp2.imzcloud.ibmammsap.local
[root@fbtprdhanapp2 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         62          0         10          0         11
-/+ buffers/cache:         51         11
Swap:           63         33         30


[root@fbtprdhanapp2 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         61          1         10          0         10
-/+ buffers/cache:         51         11
Swap:           63         33         30






1-334030641	sev2
Summary: Lack_of_free_swap_space_on_SK3SLTDEV01.imzcloud.ibmammsap.local[PROBLEM:748191] Date: Feb 1,2018 5:36 CUT Severity: Major ResourceId: sk3sltdev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.9 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3SLTDEV01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3409534:sk3


[root@SK3SLTDEV01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         31          0          1          0          1
-/+ buffers/cache:         29          1
Swap:           39         20         19


top - 09:21:12 up 467 days, 23:14,  1 user,  load average: 3.59, 3.87, 4.04
Tasks: 336 total,   5 running, 331 sleeping,   0 stopped,   0 zombie
Cpu(s): 42.5%us,  1.0%sy,  0.0%ni, 55.9%id,  0.0%wa,  0.0%hi,  0.6%si,  0.0%st
Mem:    31.626G total,   31.327G used,  305.801M free, 8468.000k buffers
Swap:   40.000G total,   20.542G used,   19.458G free, 1389.395M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
23483 sldadm    20   0 1507m  10m 1356 S  2.0  0.0   2899:04 789m en.sapSLD_ASCS0
 4914 daaadm    20   0 5196m 256m 4528 S  0.3  0.8 107:23.08 231m jstart
25002 sldadm    20   0 30.2g 505m 455m S  0.0  1.6  29:50.62 178m SLD_00_DIA_W2
25016 sldadm    20   0 30.3g 643m 508m S  0.0  2.0  97:58.28 163m SLD_00_DIA_W16
61788 root      20   0 2195m  31m 1604 S  0.0  0.1 382:17.38 159m ds_am
25009 sldadm    20   0 30.3g 620m 524m S  3.6  1.9  48:04.65 158m SLD_00_DIA_W9
25003 sldadm    20   0 30.2g 541m 474m S  0.0  1.7  27:18.27 153m SLD_00_DIA_W3
25008 sldadm    20   0 30.2g 584m 492m S  0.0  1.8  52:03.66 152m SLD_00_DIA_W8
25001 sldadm    20   0 30.2g 528m 462m S  0.0  1.6  20:32.21 151m SLD_00_DIA_W1
25007 sldadm    20   0 30.3g 615m 525m S  0.0  1.9  38:18.39 150m SLD_00_DIA_W7
25005 sldadm    20   0 30.3g 560m 476m S  0.0  1.7  32:29.77 150m SLD_00_DIA_W5
25000 sldadm    20   0 30.2g 577m 477m S  0.0  1.8  22:20.38 145m SLD_00_DIA_W0
25004 sldadm    20   0 30.3g 555m 472m S  0.0  1.7  22:06.87 144m SLD_00_DIA_W4
25013 sldadm    20   0 30.3g 600m 448m S  0.0  1.9  67:20.79 139m SLD_00_DIA_W13
25011 sldadm    20   0 30.2g 672m 544m S  0.0  2.1  51:23.62 135m SLD_00_DIA_W11
25010 sldadm    20   0 30.3g 616m 494m S  0.0  1.9  63:21.07 134m SLD_00_DIA_W10
25017 sldadm    20   0 30.3g 628m 497m S  0.0  1.9  94:06.80 132m SLD_00_DIA_W17
25015 sldadm    20   0 30.3g 648m 490m S  0.0  2.0  77:31.47 129m SLD_00_DIA_W15
25012 sldadm    20   0 30.3g 644m 492m S  0.0  2.0  70:32.45 128m SLD_00_DIA_W12
25006 sldadm    20   0 30.3g 593m 478m S  0.0  1.8  22:52.57 128m SLD_00_DIA_W6
24999 sldadm    20   0 1875m 8604 3892 S  0.0  0.0   3:12.93 124m icman
25014 sldadm    20   0 30.3g 648m 482m S  0.0  2.0  74:10.69 119m SLD_00_DIA_W14
31060 sldadm    20   0 30.4g 348m 125m S  0.0  1.1  64:38.50 100m SLD_00_BTC_W28
60742 sldadm    20   0 30.4g 663m 364m R  2.0  2.0 131:11.78  96m SLD_00_BTC_W26
22857 sldadm    20   0 40.1g  10g 359m R 28.5 32.3  14433:22  96m SLD_00_BTC_W21
 1303 sldadm    20   0 30.4g 599m 380m R 14.3  1.9  52:08.38  92m SLD_00_BTC_W25




1-334030731	sev2
Summary: Lack_of_free_swap_space_on_MG2ERPDEVCAPP.imzcloud.ibmammsap.local[PROBLEM:748281] Date: Feb 1,2018 5:46 CUT Severity: Major ResourceId: mg2erpdevcapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mg2 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 42.64 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: MG2ERPDEVCAPP.imzcloud.ibmammsap.local NodeAlias: 10.198.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3409548:mg2

[root@MG2ERPDEVCAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11         10          0          6          0          7
-/+ buffers/cache:          3          8
Swap:            7          4          3


top - 13:34:19 up 51 days, 23:49,  1 user,  load average: 0.06, 0.05, 0.03
Tasks: 324 total,   2 running, 322 sleeping,   0 stopped,   0 zombie
Cpu(s):  9.7%us,  1.7%sy,  0.1%ni, 87.2%id,  1.1%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    11.618G total,   10.988G used,  645.141M free,  104.883M buffers
Swap: 8191.996M total, 4302.559M used, 3889.438M free, 7723.906M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 80227 mrdadm    20   0 1506m  16m 1796 S  0.5  0.1   8:23.73 785m en.sapMRD_ASCS0
 81680 mrdadm    20   0 1665m 5928 2476 S  0.0  0.0   0:37.99 119m icman
 81681 mrdadm    20   0 11.7g 3.4g 3.3g S  0.0 29.5 106:20.72  84m MRD_00_DIA_W0
 81684 mrdadm    20   0 11.7g 3.0g 2.9g S  0.0 25.9 147:20.96  76m MRD_00_DIA_W3
 81685 mrdadm    20   0 11.7g 3.0g 2.9g S  0.0 25.9 142:20.25  69m MRD_00_DIA_W4
 81683 mrdadm    20   0 11.7g 3.8g 3.6g S  0.0 32.6 117:31.42  64m MRD_00_DIA_W2
 81690 mrdadm    20   0 11.7g 3.5g 3.3g D  2.5 30.0 202:18.65  53m MRD_00_DIA_W9
  2791 root      20   0  253m 8176 1048 S  0.0  0.1   0:05.39  47m chef-client
 81696 mrdadm    20   0 11.6g  88m  72m S  0.0  0.7   0:11.78  45m MRD_00_UP2_W15
 81695 mrdadm    20   0 11.5g  83m  66m S  0.0  0.7   1:25.85  42m MRD_00_SPO_W14
 48802 mrdadm    20   0 11.7g 3.4g 3.3g S  0.0 29.6  19:54.64  39m MRD_00_DIA_W6
 34515 mrdadm    20   0 11.6g 186m 117m S  0.0  1.6   0:05.12  37m MRD_00_UPD_W10
 99370 root      20   0  991m  55m 4804 S  0.0  0.5  16:00.81  33m ds_agent
 51057 root      39  19 1080m  34m 1016 S  0.0  0.3  17:04.46  33m java
 81646 mrdadm    20   0 11.4g  14m  11m S  0.2  0.1   4:59.54  30m MRD_00_DP
 80226 mrdadm    20   0 89256 1284  956 S  0.0  0.0   0:11.71  28m ms.sapMRD_ASCS0
 81651 mrdadm    20   0 1258m 3384  932 S  0.2  0.0   3:27.17  25m igspw_mt
 81652 mrdadm    20   0 1258m 3388  932 S  0.0  0.0   3:28.52  25m igspw_mt
 27980 mrdadm    20   0  810m  32m  23m S  0.0  0.3   6:41.00  24m sapstartsrv
 70751 mrdadm    20   0  819m 3812 1228 S  0.0  0.0   2:54.08  24m igsmux_mt
 18448 mrdadm    20   0 11.5g  61m  36m S  0.0  0.5   0:02.01  23m MRD_00_UPD_W19
103666 mrdadm    20   0 11.6g 252m 161m R 17.9  2.1  15:22.73  22m MRD_00_BTC_W13
125513 mrdadm    20   0 11.6g 244m 153m S 14.2  2.1   8:12.84  22m MRD_00_BTC_W12
126930 mrdadm    20   0 11.6g 252m 164m S 13.0  2.1   7:11.33  22m MRD_00_BTC_W11
 28061 root      20   0 2191m  72m 3276 S  0.0  0.6 114:07.05  21m ksaagent
 56069 mrdadm    20   0 11.7g 3.5g 3.3g S  0.7 30.1  28:23.62  20m MRD_00_DIA_W7
 57307 mrdadm    20   0 11.7g 3.9g 3.8g S  0.0 33.8  22:43.34  20m MRD_00_DIA_W8
  8287 root      20   0  339m  21m 4400 S  0.0  0.2   8:42.62  15m sssd_be

------------------------------------------------------------------------------------------------------------------------------------------


2 Feb

1-334063311 sev1
Summary: Zabbix_agent_on_dal09ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:759652] Date: Feb 2,2018 5:27 CUT Severity: Critical ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dal09ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3412317:cia


[ibmrmalik@dal09ammsol01 ~]$ sudo su
[root@dal09ammsol01 ibmrmalik]# uptime
 00:04:26 up 143 days, 14:35,  1 user,  load average: 6.39, 5.87, 9.07
[root@dal09ammsol01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4279) is running...




1-334063031	sev2
Long Description: Summary: NTP_time_is_driffted_on_IA1FIOQASAPP.imzcloud.ibmammsap.local[PROBLEM:759050] Date: Feb 2,2018 4:18 CUT Severity: Major ResourceId: ia1fioqasapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.12 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: IA1FIOQASAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.17.142 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3412233:ia1

[root@IA1FIOQASAPP ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 lon02ammadc001. 146.89.140.75    7 u  296 1024  377    0.687  -8516.7 2368.06
 lon02ammadc002. 146.89.140.75    7 u  142 1024  377    0.867  -8045.2 1922.88
[root@IA1FIOQASAPP ibmrmalik]# ntpstat
synchronised to unspecified at stratum 8
   time correct to within 1490 ms
   polling server every 1024 s

[root@IA1FIOQASAPP ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 lon02ammadc001. 146.89.140.75    7 u    1   64    1    0.891   -3.034   0.708
 lon02ammadc002. 146.89.140.75    7 u    1   64    1    0.874   10.075   0.732




1-334072911    sev3
sjmpgpdb01	10.198.10.8

/dev/mapper/pgplogvg-pgpsybdiag_lv	/sybase/PGP/sapdiag		add 5Gb		5.99Gb free can be added
[root@sjmpgpdb01 ibmrmalik]# df -k /dev/mapper/pgplogvg-pgpsybdiag_lv
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/pgplogvg-pgpsybdiag_lv
                       5160576 3270568   1627864  67% /sybase/PGP/sapdiag

[root@sjmpgpdb01 ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g  2.50g
  pgpappvg    1  13   0 wz--n- 128.00g 36.00g
  pgparchvg   1   1   0 wz--n-  64.00g 14.00g
  pgpdatavg   3   7   0 wz--n- 172.99g  5.99g
  pgplogvg    2   4   0 wz--n-  56.99g  5.99g
	


sjmpmpdb01	10.198.10.10

/dev/mapper/pmpdatavg-pmpsapdata1_lv	/sybase/PMP/sapdata1	add 5GB
[root@sjmpmpdb01 ibmrmalik]# df -k /dev/mapper/pmpdatavg-pmpsapdata1_lv
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pmpdatavg-pmpsapdata1_lv
                      53670396 32721896  18222576  65% /sybase/PMP/sapdata1

[root@sjmpmpdb01 ibmrmalik]# vgs pmpdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  pmpdatavg   2   7   0 wz--n- 377.99g 144.99g



/dev/mapper/pmpdatavg-pmpsapdata2_lv	/sybase/PMP/sapdata2	add 5GB
[root@sjmpmpdb01 ibmrmalik]# df -k /dev/mapper/pmpdatavg-pmpsapdata2_lv
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pmpdatavg-pmpsapdata2_lv
                      53670396 32721896  18222576  65% /sybase/PMP/sapdata2
[root@sjmpmpdb01 ibmrmalik]#  vgs pmpdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  pmpdatavg   2   7   0 wz--n- 377.99g 144.99g



/dev/mapper/pmpdatavg-pmpsapdata3_lv	/sybase/PMP/sapdata3	add 10GB

[root@sjmpmpdb01 ibmrmalik]# df -k /dev/mapper/pmpdatavg-pmpsapdata3_lv
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pmpdatavg-pmpsapdata3_lv
                      48509808 33771548  12274416  74% /sybase/PMP/sapdata3
[root@sjmpmpdb01 ibmrmalik]#  vgs pmpdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  pmpdatavg   2   7   0 wz--n- 377.99g 144.99g



/dev/mapper/pmpdatavg-pmpsapdata4_lv	/sybase/PMP/sapdata4	add 10GB
[root@sjmpmpdb01 ibmrmalik]# df -k /dev/mapper/pmpdatavg-pmpsapdata4_lv
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pmpdatavg-pmpsapdata4_lv
                      48509808 33771548  12274416  74% /sybase/PMP/sapdata4

[root@sjmpmpdb01 ibmrmalik]#  vgs pmpdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  pmpdatavg   2   7   0 wz--n- 377.99g 144.99g




sapdgpaa01	10.198.11.18			NO DISK space available to extend
	
/dev/mapper/dgplogvg-dgpsybdiag_lv	/sybase/DGP/sapdiag		add 5GB

[root@sapdgpaa01 ibmrmalik]# df -k /dev/mapper/dgplogvg-dgpsybdiag_lv
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/dgplogvg-dgpsybdiag_lv
                       5160576 3270568   1627864  67% /sybase/DGP/sapdiag

[root@sapdgpaa01 ibmrmalik]# vgs dgplogvg
  VG       #PV #LV #SN Attr   VSize  VFree	
  dgplogvg   3   4   0 wz--n- 52.99g    0




sjmdmpdb01	10.198.11.12

/dev/mapper/dmplogvg-dmpsybdiag_lv	/sybase/DMP/sapdiag	add 10GB
[root@sjmdmpdb01 ibmrmalik]# df -k /dev/mapper/dmplogvg-dmpsybdiag_lv
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/dmplogvg-dmpsybdiag_lv
                      15477744 11350136   3341712  78% /sybase/DMP/sapdiag

[root@sjmdmpdb01 ibmrmalik]# vgs dmplogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  dmplogvg   7   4   0 wz--n- 91.97g 15.00g



/dev/mapper/dmpdatavg-dmpsaptemp_lv	/sybase/DMP/saptemp	add 5GB

[root@sjmdmpdb01 ibmrmalik]# df -k /dev/mapper/dmpdatavg-dmpsaptemp_lv
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/dmpdatavg-dmpsaptemp_lv
                      33027952 19483360  11867000  63% /sybase/DMP/saptemp

[root@sjmdmpdb01 ibmrmalik]# vgs dmpdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  dmpdatavg  11   7   0 wz--n- 311.96g 24.99g






sapdpqdb01	10.198.11.20

/dev/mapper/dpqlogvg-dpqsybdiag_lv	/sybase/DPQ/sapdiag	add 5 GB	no space available to extend
[root@sapdpqdb01 ibmrmalik]# df -k /dev/mapper/dpqlogvg-dpqsybdiag_lv
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/dpqlogvg-dpqsybdiag_lv
                       5160576 3270568   1627864  67% /sybase/DPQ/sapdiag

[root@sapdpqdb01 ibmrmalik]# vgs dpqlogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  dpqlogvg   1   4   0 wz--n- 32.00g 120.00m




/dev/mapper/dpqlogvg-dpqsybsystm_lv	/sybase/DPQ/sybsystem	add 5 GB	no space available to extend
	
[root@sapdpqdb01 ibmrmalik]# df -k /dev/mapper/dpqlogvg-dpqsybsystm_lv
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/dpqlogvg-dpqsybsystm_lv
                       4001472 2583016   1215104  69% /sybase/DPQ/sybsystem

[root@sapdpqdb01 ibmrmalik]# vgs dpqlogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  dpqlogvg   1   4   0 wz--n- 32.00g 120.00m





1-334073901	sev3
Long Description: Summary: Processor_load_is_too_high_on_SNG01AMMADC001[PROBLEM:762120] Date: Feb 2,2018 11:17 CUT Severity: Minor ResourceId: sng01ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 6.183333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SNG01AMMADC001 NodeAlias: 146.89.140.140 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3412810:amm
Severity: 3-Standard
Source:  TEC

	
------------------------------------------------------------------------------------------------------------------------------------------

5 Feb


1-334092271		sev2
Summary: Lack_of_free_swap_space_on_ERP-QAS.imzcloud.ibmammsap.local[PROBLEM:766712] Date: Feb 2,2018 21:15 CUT Severity: Major ResourceId: erp-qas TicketGroup: AMM-DELIVERY-TECH CustomerCode: tqa InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 49.92 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: ERP-QAS.imzcloud.ibmammsap.local NodeAlias: 10.7.2.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3413693:tqa

[root@ERP-QAS ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            23         23          0         15          0         17
-/+ buffers/cache:          4         18
Swap:           13          7          6



-------------------------------------------------------------------------------------

6 Feb

1-334187091



1-334180391

-------------------------------------------------------------------------------------------------

8 Feb

1-334029087
Manchaster city airport
Customer: MANCHESTER AIRPORT PLC
Reported by: SUPPORT BASIS
Phone: +44 (8703660742)
E-Mail: shonali.kellogg@capgemini.com
Priority: 	2: High
SAP Incident Number: 054565 / 2018


Description:

Business Consequences
02/01/2018   06:22:58   S0014339176

Critical for major business work development
____________________
Description
02/01/2018   06:22:57   S0014339176

Hi Team,
 
Can you please reset the password of user: MAGADMIN in VIM server
LONMAGSSP0003 and share the new password with us.
 
Regards,
SAP Basis

sev3
LONMAGSSP0003 	Windows 2012 R2 	Iaas+(OS only) 	London 	172.22.0.42 	10.69.0.42
immvamsi@in.ibm.com




1-334281161   sev3
Summary: Processor_load_is_too_high_on_HKG02AMMADC001[PROBLEM:831026] Date: Feb 8,2018 12:27 CUT Severity: Minor ResourceId: hkg02ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 7.6 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: HKG02AMMADC001 NodeAlias: 146.89.141.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) 



-----------------------------------------------------------------------------------------------------------------------

9 Feb

1-333756137	sev3
Please create backup FS





1-334030731	sev2
Summary: Lack_of_free_swap_space_on_MG2ERPDEVCAPP.imzcloud.ibmammsap.local[PROBLEM:748281] Date: Feb 1,2018 5:46 CUT Severity: Major ResourceId: mg2erpdevcapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mg2 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 42.64 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: MG2ERPDEVCAPP.imzcloud.ibmammsap.local NodeAlias: 10.198.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3409548:mg2

top - 10:40:20 up 59 days, 20:54,  1 user,  load average: 0.10, 0.08, 0.02
Tasks: 324 total,   2 running, 322 sleeping,   0 stopped,   0 zombie
Cpu(s):  9.4%us,  1.9%sy,  0.0%ni, 88.6%id,  0.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    11.618G total,   11.253G used,  373.156M free,  262.496M buffers
Swap: 8191.996M total, 4481.316M used, 3710.680M free, 7855.621M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 80227 mrdadm    20   0 1506m  17m 2172 S  0.0  0.1  11:02.81 784m en.sapMRD_ASCS0
 81680 mrdadm    20   0 1665m 6040 2544 S  0.0  0.0   0:50.25 119m icman
 81681 mrdadm    20   0 11.8g 3.7g 3.5g S  1.0 32.0 155:53.62  94m MRD_00_DIA_W0
 48802 mrdadm    20   0 11.7g 3.7g 3.5g S  0.0 31.8  87:00.03  54m MRD_00_DIA_W6
 81695 mrdadm    20   0 11.5g  85m  80m S  0.0  0.7   1:53.17  53m MRD_00_SPO_W14
 81696 mrdadm    20   0 11.6g  98m  87m S  0.0  0.8   0:14.62  51m MRD_00_UP2_W15
  2791 root      20   0  253m  13m 1052 S  0.0  0.1   0:06.09  41m chef-client
 52397 mrdadm    20   0 11.7g 3.2g 3.0g S  0.0 27.5  77:11.72  37m MRD_00_DIA_W5
 81646 mrdadm    20   0 11.4g  15m  12m S  0.0  0.1   6:40.55  30m MRD_00_DP
 80226 mrdadm    20   0 89256 1420 1028 S  0.0  0.0   0:15.67  28m ms.sapMRD_ASCS0
 93075 mrdadm    20   0 11.7g 2.8g 2.6g S  0.0 24.1  37:32.75  27m MRD_00_DIA_W4
 57307 mrdadm    20   0 11.7g 4.4g 4.2g S  0.0 37.9  95:12.00  27m MRD_00_DIA_W8
 99370 root      20   0  991m  60m 5392 S  0.0  0.5  23:12.42  25m ds_agent
 81651 mrdadm    20   0 1258m 3432  976 S  0.0  0.0   4:37.88  25m igspw_mt
 81652 mrdadm    20   0 1258m 3444  976 S  0.0  0.0   4:37.43  25m igspw_mt
 27980 mrdadm    20   0  810m  33m  24m S  0.0  0.3   7:53.56  24m sapstartsrv
 70751 mrdadm    20   0  819m 3868 1268 S  0.3  0.0   4:30.52  24m igsmux_mt
 43134 mrdadm    20   0 11.6g 226m 149m S  0.0  1.9   0:07.04  24m MRD_00_UPD_W10
 19333 mrdadm    20   0 11.6g 208m 128m S 13.6  1.8   0:18.30  22m MRD_00_BTC_W11
129794 mrdadm    20   0 11.6g 237m 149m R 13.6  2.0   8:38.23  22m MRD_00_BTC_W12
 56960 mrdadm    20   0 11.6g 252m 160m S 14.6  2.1  35:13.43  22m MRD_00_BTC_W13
 28061 root      20   0 2191m  80m 3312 S  0.0  0.7 152:02.08  21m ksaagent
 13619 mrdadm    20   0 11.7g 2.0g 1.8g S  0.0 17.0   6:39.28  21m MRD_00_DIA_W1
 46522 mrdadm    20   0 11.7g 2.4g 2.2g S  0.0 20.5  11:32.58  20m MRD_00_DIA_W2

[root@MG2ERPDEVCAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          6          0          7
-/+ buffers/cache:          3          8
Swap:            7          4          3

sync; echo 1 > /proc/sys/vm/drop_caches

	
1-334240421	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/data[PROBLEM:817799] Date: Feb 7,2018 10:58 CUT Severity: Minor ResourceId: bi1bwhdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 18.77 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1BWHDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3423396:bi1 

[root@BI1BWHDBQAS01 ibmrmalik]# df -h /hana/data
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_data  384G  315G   70G  82% /hana/data

[root@BI1BWHDBQAS01 data]# du -mch --max-depth=1 .
12G     ./softs
39G     ./mnt00001
3.4G    ./BOQ
172G    ./new
0       ./sharesolman
2.8G    ./new1001
22G     ./new1001new
33G     ./back06FEB
33G     ./WholeBackup
315G    .
315G    total

/dev/mapper/vghanadata-lv_hana_data    402452480  329457420  72995060  82% /hana/data




1-334269091	sev2		PDL FPEREZCA	Unique S.A.	DPE	FVALVERD	
*** Details of Generic Service Request - DO NOT CHANGE ***

Please review the use of SWAP memory to identify the process that causes consumption.

Servidor:  yanbalbodev

IP:   10.28.25.13
A0ERUS014XVM001 	yanbalbodev 	IMZ 10.4.7.13 	10.28.25.13

[root@yanbalbodev ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         14          0          0          0          1
-/+ buffers/cache:         13          2
Swap:           13         10          3

top - 02:33:28 up 518 days, 13:06,  1 user,  load average: 0.30, 0.32, 0.34
Tasks: 346 total,   1 running, 345 sleeping,   0 stopped,   0 zombie
Cpu(s):  4.0%us,  2.9%sy,  0.0%ni, 60.7%id, 32.2%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    15.572G total,   14.952G used,  634.922M free,  341.660M buffers
Swap:   13.766G total,   10.060G used, 3794.051M free, 1432.629M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
20802 bodadm    20   0 5419m 669m 3308 S  0.0  4.2 249:27.44 1.5g java
 2086 bodadm    20   0 3416m 674m 6516 S  0.0  4.2 119:38.01 1.4g java
 7013 bodadm    20   0 5407m 685m 3304 S  0.0  4.3 292:44.67 1.2g java
54462 bodadm    20   0 5557m 719m 5016 S  0.0  4.5 354:18.78 924m java
60687 bodadm    20   0 3237m 1.9g  15m S  3.3 12.3   6678:59 684m boe_cmsd
61573 bodadm    20   0 3603m 425m 7996 S  0.3  2.7 111:56.69 641m java
60854 bodadm    20   0 3659m 1.1g 8156 S  0.0  6.8  40:04.66 520m java
61560 bodadm    20   0 5587m 518m 8368 S  0.3  3.3  38:27.58 443m java
61495 bodadm    20   0 11.4g 207m 3732 S  0.0  1.3  33:40.63 228m java
61453 bodadm    20   0 1956m  25m 8472 S  0.0  0.2  23:18.48 188m boe_xccached
64966 bodadm    20   0 3122m 140m 6960 S  0.0  0.9  19:58.20 175m java
61384 bodadm    20   0 3183m  30m 8432 S  0.0  0.2  26:19.02 173m boe_crcached.bi
61476 bodadm    20   0 3191m 516m 7744 S  0.0  3.2  31:16.72 159m java
19661 root      20   0 1178m  616  600 S  0.0  0.0   0:00.11 139m db2syscr
19663 root      20   0 1178m  612  596 S  0.0  0.0   0:00.09 139m db2syscr
19662 root      20   0 1178m  616  596 S  0.0  0.0   0:00.13 139m db2syscr
19569 root      20   0 1168m 1204 1200 S  0.0  0.0   0:00.12 139m db2syscr
12208 bodadm    20   0 1803m 109m 6924 S  0.0  0.7  19:43.85 129m java
49371 bodadm    20   0 5302m 912m 9240 S  0.3  5.7  83:05.30 115m java
61501 bodadm    20   0 1998m 297m 7600 S  0.0  1.9  26:11.67 103m java
61443 bodadm    20   0 3216m 499m 7820 S  0.0  3.1  29:40.43 100m java
60641 bodadm    20   0 1107m 130m 7160 S  0.0  0.8  34:29.88  87m java
61492 bodadm    20   0 1999m 292m 7652 S  0.0  1.8  26:13.86  84m java
19571 db2bod    20   0 4119m 186m 144m S 23.5  1.2  92954:41  74m db2sysc
53389 root      20   0  302m 3844 1396 S  0.3  0.0 283:40.41  66m vmtoolsd
36944 bodadm    20   0 3629m 101m  14m S  0.0  0.6  16:15.13  50m WIReportServer
61473 bodadm    20   0  233m 6996 4932 S  0.0  0.0  36:43.73  50m boe_crystalras
11545 bodadm    20   0  246m  14m 4264 S  0.0  0.1  10:26.47  37m boe_crprocd.bin
32485 root      20   0  257m  23m 1056 S  0.0  0.1   1:12.71  31m chef-client
47540 root      35  15 2801m  52m 1892 S  0.0  0.3  26:14.39  28m java
12453 root      20   0  991m  58m 5056 S  0.0  0.4  29:54.23  26m ds_agent
44623 root      20   0  415m  70m 7536 S  0.0  0.4 612:23.60  24m sssd_be
24719 root      20   0  138m 9.8m 1500 S  0.0  0.1   8:22.52  20m Xvnc
61457 bodadm    20   0  648m 6884 4972 S  0.0  0.0   3:21.12  20m ConnectionServe




1-334298841	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/home[PROBLEM:834015] Date: Feb 8,2018 18:4 CUT Severity: Minor ResourceId: snchsmada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home InstanceValue: 19.37 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: snchsmada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3427378:snc

[root@snchsmada11 ibmrmalik]# df -k /home
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_home
                       1998672 1536580    357236  82% /home


[root@snchsmada11 home]# du -a . |sort -n -r |head -n 15
1533868 .
1528796 ./ibmbmailman
1528756 ./ibmbmailman/51051408
1528700 ./ibmbmailman/51051408/DATA_UNITS
764916  ./ibmbmailman/51051408/DATA_UNITS/STOST_200_DELT
764908  ./ibmbmailman/51051408/DATA_UNITS/STOST_200_DELT/DATA
764904  ./ibmbmailman/51051408/DATA_UNITS/STOST_200_DELT/DATA/K-200BGINSTOST.SAR
763772  ./ibmbmailman/51051408/DATA_UNITS/STOST_200_INST
763764  ./ibmbmailman/51051408/DATA_UNITS/STOST_200_INST/DATA
763760  ./ibmbmailman/51051408/DATA_UNITS/STOST_200_INST/DATA/K-200AGINSTOST.SAR




1-334299621	sev3
Summary: FS_is_read_only_on_snchecada11.imzcloud.ibmammsap.local[PROBLEM:833708] Date: Feb 8,2018 17:29 CUT Severity: Minor ResourceId: snchecada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/LFP/SAP_DATA/DR1 filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchecada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.99 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3427326:snc

[root@snchecada11 ibmrmalik]# df -h /SHARE/LFP/SAP_DATA/DR1
Filesystem            Size  Used Avail Use% Mounted on
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01/DR1
                      197G  173G   25G  88% /SHARE/LFP/SAP_DATA/DR1

Check df -h to see if the mount /mnt/sapexchangeIT is available,if not showing, unmount and remount. If mount command is failing, run mount -a which will refresh the mounts as per the fstab entry. Ensure the fstab entry is correct only then will mount -a work properly. First check the fstab entry for the mount point that is read only cat /etc/fstab|grep sapexchangeIT
//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/  cifs username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003   then run umount /mnt/sapexchangeIT/ and then mount it using mount //10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/  cifs username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

[root@snchecada11 DR1]# cat /etc/fstab|grep /SAP_DATA_nonprd01/SAP_DATA_nonprd01/DR1
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01/DR1 /SHARE/LFP/SAP_DATA/DR1 nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0





1-334300021	sev3
Summary: FS_is_read_only_on_snchmdada11.imzcloud.ibmammsap.local[PROBLEM:834372] Date: Feb 8,2018 18:53 CUT Severity: Minor ResourceId: snchmdada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/LFP/SAP_DATA/D1M /SHARE/LFP/SAP_ARCH/D1M files ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchmdada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.104 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3427450:snc




1-334300824	sev3	approved by DPE
Requesting to add additional storage to the servers and FS listed below:

Hostname: snchbibpd11
IMZ IP: 10.73.10.46
Directory: /sybase/P1B
Size: 30 GB	available space is only 5GB  need additional 30 GB added

[root@snchbibpd11 ibmrmalik]# df -k /sybase/P1B
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/p1bdatavg-p1bsybase_lv
                      62951356 52809440   6945264  89% /sybase/P1B
[root@snchbibpd11 ibmrmalik]# vgs p1bdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  p1bdatavg   3   7   0 wz--n- 184.99g 5.00g



Hostname: snchbibpd51
IMZ IP: 10.73.10.111
Directory: /sybase/P1B
Size: 30 GB	available space is only 19.99g need additional 15GB disk added

[root@snchbibpd51 ibmrmalik]# vgs p1bdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  p1bdatavg   3   7   0 wz--n- 401.99g 19.99g




1-333996721 sev1	DONE
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:738472] Date: Jan 31,2018 8:51 CUT Severity: Critical ResourceId: bi1bwhdbprd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: bi1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: BI1BWHDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3407322:bi1

[root@BI1BWHDBPRD01 ibmrmalik]# df -k /
Filesystem     1K-blocks     Used Available Use% Mounted on
/dev/sda3       51402372 21014740  27776484  44% /

[root@BI1BWHDBPRD01 /]# du -mch --max-depth=1 .
53M     ./root
164M    ./lib
0       ./sys
18M     ./sbin
6.0G    ./sapmnt
4.6G    ./tmp
4.0K    ./media
4.0K    ./cgroup
27M     ./lib64
3.6G    ./usr
1.4G    ./var
4.0K    ./selinux




1-334305821    swap space	sev2		DONE
Summary: Lack_of_free_swap_space_on_SK3ERPAPPRD01.imzcloud.ibmammsap.local[PROBLEM:835351] Date: Feb 8,2018 21:9 CUT Severity: Major ResourceId: sk3erpapprd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 43.56 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3ERPAPPRD01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3427791:sk3


-------------------------------------------------------------------------------------------------------------------------------------------


12 Feb


1-334389941	sev2
Summary: Lack_of_free_swap_space_on_ms3wdcladb14.imzcloud.ibmammsap.local[PROBLEM:849145] Date: Feb 10,2018 0:19 CUT Severity: Major ResourceId: ms3wdcladb14 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 49.99 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: ms3wdcladb14.imzcloud.ibmammsap.local NodeAlias: 10.12.6.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3432033:ms3

[root@ms3wdcladb14 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          0          0          2
-/+ buffers/cache:          8          3
Swap:            7          4          3


top - 04:45:30 up 206 days, 22:24,  1 user,  load average: 0.01, 0.02, 0.00
Tasks: 254 total,   1 running, 253 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.2%us,  0.3%sy,  0.0%ni, 98.3%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    11.626G total,   11.251G used,  383.457M free,  683.344M buffers
Swap: 8191.996M total, 4125.504M used, 4066.492M free, 2120.238M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
61538 ad1adm    20   0 6992m 2.5g  11m S  0.3 21.3 293:07.21 230m jstart
60556 ad1adm    20   0 7072m 2.7g  12m S  0.0 22.9 310:09.41 105m jstart
 5355 daaadm    20   0 1856m  68m 3580 S  0.7  0.6 332:55.66  89m jstart
61492 ad1adm    20   0 1682m  41m 4964 S  0.0  0.4   1:49.10  76m icman
30539 root      20   0  254m  35m 8572 S  0.0  0.3 228:53.94  39m koy15col
 2416 root      20   0  295m  27m 1828 S  0.0  0.2 138:36.22  25m vmtoolsd
41119 root      20   0  257m  31m 1848 S  0.0  0.3   0:17.36  24m chef-client
60499 ad1adm    20   0  823m 3572 1792 S  0.0  0.0   7:58.85  23m igspw_mt
60500 ad1adm    20   0  823m 3576 1792 S  0.0  0.0   7:50.82  23m igspw_mt
  307 ad1adm    20   0 1002m 8728  164 S  0.0  0.1   0:00.00  15m sapstartsrv
58868 ad1adm    20   0  823m  13m 1788 S  0.0  0.1   7:52.87  14m igspw_mt
58869 ad1adm    20   0  823m  15m 1788 S  0.2  0.1   7:55.05  14m igspw_mt
 4280 sapadm    20   0  707m  15m 3876 S  0.0  0.1  13:18.63  13m sapstartsrv
 4439 daaadm    20   0  394m 6768 1964 S  0.0  0.1   2:40.33  12m sapstartsrv
30866 root      20   0 1739m  15m 8720 S  0.0  0.1   7:09.25  11m kuma620
30541 root      20   0 1473m  14m 8372 S  0.0  0.1   5:48.80  10m koyagent
 4247 root      20   0  170m 1264  984 S  0.0  0.0   2:09.51 6388 saphostexec






1-334427651	sev2
Summary: Lack_of_free_swap_space_on_SK3ERPAPPRD01.imzcloud.ibmammsap.local[PROBLEM:870000] Date: Feb 11,2018 21:4 CUT Severity: Major ResourceId: sk3erpapprd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 45.43 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3ERPAPPRD01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3435678:sk3






1-334432851  -- NTPD was restarted

------------------------------------------------------------------------------------------------------------------------------


13 Feb


1-334474321	sv2
Summary: Lack_of_free_swap_space_on_APLBREDE1.imzcloud.ibmammsap.local[PROBLEM:883566] Date: Feb 12,2018 23:29 CUT Severity: Major ResourceId: aplbrede1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ap5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.89 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: APLBREDE1.imzcloud.ibmammsap.local NodeAlias: 170.225.68.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3439956:ap5

[root@APLBREDE1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0         10          0         26
-/+ buffers/cache:          4         27
Swap:            7          4          3

top - 04:38:33 up 96 days, 12:33,  1 user,  load average: 0.02, 0.06, 0.02
Tasks: 375 total,   1 running, 374 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.2%us,  0.2%sy,  0.0%ni, 99.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   30.988G used,  362.766M free,  298.980M buffers
Swap: 8191.996M total, 4131.766M used, 4060.230M free,   26.590G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
100568 de1adm    20   0 1427m  13m 2828 S  0.0  0.0   2:42.96 784m en.sapDE1_ASCS0
 38630 db2de1    20   0 19.5g 9.9g 9.4g S  0.0 31.7 291:44.80 121m db2sysc
 50836 daaadm    20   0 2913m  83m 3480 S  0.3  0.3 120:07.32 115m jstart
102145 de1adm    20   0 2161m  19m  14m S  0.0  0.1   0:26.95 107m icman
 49444 root      20   0  257m 6004 1116 S  0.0  0.0   0:08.46  49m chef-client
 38628 root      20   0 1245m 7020 6596 S  0.0  0.0   0:00.10  45m db2syscr
 38637 root      20   0 1248m 6140 1552 S  0.0  0.0   0:03.95  41m db2syscr
 38638 root      20   0 1248m 6140 1552 S  0.0  0.0   0:03.93  41m db2syscr
 38639 root      20   0 1248m 6136 1548 S  0.0  0.0   0:03.94  41m db2syscr
 38657 db2de1    20   0 2329m  45m  14m S  0.0  0.1   9:47.91  36m db2fmp
107237 root      20   0  991m  52m 5312 S  0.0  0.2  24:40.05  33m ds_agent
107500 root      20   0 2661m 171m 3296 S  0.0  0.5 106:58.61  30m ds_am
102124 de1adm    20   0 1192m 4964 2064 S  0.0  0.0   0:59.21  25m igsmux_mt
102178 de1adm    20   0 13.0g 481m 424m S  0.0  1.5   0:34.48  24m DE1_00_DIA_W16
  5852 root      35  15 1080m  43m 1048 S  0.0  0.1   3:59.55  24m java
102122 de1adm    20   0 12.8g  36m  27m S  0.0  0.1   1:01.15  23m DE1_00_DP
108877 de1adm    20   0 13.0g 455m 396m S  0.0  1.4   0:44.87  23m DE1_00_DIA_W12
100567 de1adm    20   0 90164 4244 1916 S  0.0  0.0   0:02.24  23m ms.sapDE1_ASCS0
 95600 root      20   0 2127m  37m 3672 S  0.0  0.1   9:25.95  22m ksaagent
102126 de1adm    20   0  825m 6168 1888 S  0.0  0.0   0:31.81  22m igspw_mt
102125 de1adm    20   0  825m 6168 1888 S  0.0  0.0   0:32.01  22m igspw_mt
100106 de1adm    20   0 13.0g 487m 433m S  0.0  1.5   0:39.59  22m DE1_00_DIA_W18
 50539 daaadm    20   0  186m 1680 1516 S  0.0  0.0   0:01.63  20m jc.sapDAA_SMDA9
111475 de1adm    20   0 13.0g 452m 400m S  0.0  1.4   0:27.78  20m DE1_00_DIA_W4
111483 de1adm    20   0 13.0g 461m 401m S  0.0  1.4   0:35.11  20m DE1_00_DIA_W5
108127 de1adm    20   0 13.0g 402m 357m S  0.0  1.3   0:13.48  20m DE1_00_DIA_W0
111491 de1adm    20   0 13.0g 420m 368m S  0.0  1.3   0:27.77  20m DE1_00_DIA_W6
114865 de1adm    20   0 13.0g 449m 394m S  0.0  1.4   0:23.31  19m DE1_00_DIA_W2
115104 de1adm    20   0 13.0g  87m  55m S  0.0  0.3   0:15.15  19m DE1_00_UPD_W24
114903 de1adm    20   0 13.0g 475m 409m S  0.0  1.5   0:26.08  18m DE1_00_DIA_W11
115102 de1adm    20   0 13.0g  81m  47m S  0.0  0.3   0:18.27  17m DE1_00_UPD_W23
114115 de1adm    20   0 13.0g 490m 436m S  0.0  1.5   0:28.31  17m DE1_00_DIA_W1
111511 de1adm    20   0 13.0g  78m  46m S  0.0  0.2   0:09.21  17m DE1_00_UPD_W20
100872 de1adm    20   0 13.0g 491m 432m S  0.0  1.5   0:26.06  17m DE1_00_DIA_W7
108885 de1adm    20   0 13.0g 493m 421m S  0.0  1.5   0:43.97  17m DE1_00_DIA_W13
115083 de1adm    20   0 13.0g 449m 385m S  0.0  1.4   0:29.62  17m DE1_00_DIA_W19
115112 de1adm    20   0 13.0g  79m  46m S  0.0  0.2   0:23.15  17m DE1_00_UPD_W25
 17728 de1adm    20   0 13.0g  97m  66m S  0.0  0.3   0:02.24  16m DE1_00_BTC_W27
114809 de1adm    20   0 13.0g 155m 102m S  0.0  0.5   1:13.19  16m DE1_00_BTC_W32




1-334403291	sev2
Summary: Lack_of_free_swap_space_on_CI2DEVAPP.imzcloud.ibmammsap.local[PROBLEM:855616] Date: Feb 10,2018 14:16 CUT Severity: Major ResourceId: ci2devapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci2 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: CI2DEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.5.242.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on 


[root@CI2DEVAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          6          0          1          0          2
-/+ buffers/cache:          4          3
Swap:            7          4          3


top - 06:05:21 up 208 days, 17:13,  2 users,  load average: 0.00, 0.00, 0.00
Tasks: 283 total,   1 running, 282 sleeping,   0 stopped,   0 zombie
Cpu(s):  6.2%us,  6.2%sy,  0.0%ni, 87.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7857.414M total, 6999.488M used,  857.926M free,  229.348M buffers
Swap: 8191.996M total, 4256.488M used, 3935.508M free, 2525.590M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 75933 m2dadm    20   0 1429m  11m 2516 S  0.0  0.1   6:56.84 784m en.sapM2D_ASCS0
123817 root      20   0 2294m 463m 3092 S  0.0  5.9 227:57.92 307m python
 77395 m2dadm    20   0 1711m  83m 7596 S  0.0  1.1   1:07.98 153m icman
113753 root      20   0  561m 186m 1032 S  0.0  2.4 231:21.79 105m vmtoolsd
 77401 m2dadm    20   0  9.9g 1.4g 1.4g S  0.0 18.8  36:24.45  72m M2D_00_DIA_W5
 77400 m2dadm    20   0  9.9g 1.5g 1.4g S  0.0 19.3  37:14.43  65m M2D_00_DIA_W4
  1144 root      20   0 1789m  59m 6696 S  0.0  0.8 103:43.67  62m Web Content
 77398 m2dadm    20   0  9.9g 1.5g 1.3g S  0.0 19.2  39:10.12  57m M2D_00_DIA_W2
 77402 m2dadm    20   0  9.9g 1.5g 1.3g S  0.0 18.9  36:37.47  55m M2D_00_DIA_W6
 77399 m2dadm    20   0  9.9g 1.4g 1.3g S  0.0 18.7  37:21.96  47m M2D_00_DIA_W3
 77397 m2dadm    20   0  9.9g 1.5g 1.3g S  0.0 18.9  39:27.54  43m M2D_00_DIA_W1
 77396 m2dadm    20   0  9.9g 1.5g 1.3g S  0.0 19.3  41:56.82  41m M2D_00_DIA_W0
   852 root      20   0 2083m 183m  11m S  0.0  2.3 107:34.61  41m firefox
  1821 root      20   0  285m  12m 1404 S  0.0  0.2 113:20.80  40m vmtoolsd
 77405 m2dadm    20   0  9.9g 1.5g 1.4g S  0.0 19.8  38:21.40  35m M2D_00_DIA_W9
 77403 m2dadm    20   0  9.9g 1.5g 1.4g S  0.0 20.1  37:48.36  35m M2D_00_DIA_W7
 38435 m2dadm    20   0  200m 1180  696 S  0.0  0.0 117:47.13  29m SAPup_real
 16192 root      20   0 1557m  55m 3936 S  0.0  0.7  11:39.72  29m ksaagent
 77374 m2dadm    20   0 1351m 2612 1752 S  0.0  0.0   9:47.02  28m igsmux_mt
 77375 m2dadm    20   0  943m 3820 1520 S  0.0  0.0   5:51.41  27m igspw_mt





1-333738341	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_C:[PROBLEM:648629] Date: Jan 22,2018 21:27 CUT Severity: Major ResourceId: ri3lr019 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 9.98 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: DAL09AMMTS001 NodeAlias: 146.89.140.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3387972:mic





AMM-DELIVERY-TECH

----------------------------------------------------------------------------------------------------------------------

14 Feb

1-334410851	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/hana/shared[PROBLEM:861365] Date: Feb 11,2018 2:26 CUT Severity: Critical ResourceId: bi1erpdbdev01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/shared InstanceValue: 5 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/shared AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3434136:bi1

[root@BI1ERPDBDEV01 ibmrmalik]# df -k /hana/shared
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/mapper/vghanadata-lv_hana_shared
                     134148096 134148076        20 100% /hana/shared


[root@BI1ERPDBDEV01 HDB02]# du -mch --max-depth=1 .
4.0K    ./work
2.6G    ./bi1erpdbdev01
118G    ./backup
120G    .
120G    total

[root@BI1ERPDBDEV01 backup]# du -mch --max-depth=1 .
76G     ./data
42G     ./log
118G    .
118G    total


[root@BI1ERPDBDEV01 log]# pwd
/hana/shared/HED/HDB02/backup/log






1-334236061	sev3		esx Private IP: 10.134.17.112	AK5NUNFg	Frankfurt 2
Summary: Drive_with_Errors_on_fraha-1024-9.xsportal.local[PROBLEM:816293] Date: Feb 7,2018 8:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_fraha-1024-9.xsportal.local InstanceValue: Media Error Count = 4 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_fraha-1024-9.xsp Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_fraha-1024-9.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3423058:amm





1-334519731	sev3
Hello team, 

Please assist to provide the exact detailed storage usage for these 3 servers.
------------------------------------------------------------------------------------------------------------------------------------


15 Feb

1-334419321	sev3	Private IP: 10.121.75.5	root/Cnsas6h9
Summary: Drive_with_Errors_on_dalhana-1024-2.xsportal.local[PROBLEM:864503] Date: Feb 11,2018 9:9 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local InstanceValue: Media Error Count = 2 Media Error Count = 138 Media Error Count ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_dalhana-1024-2.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3434741:amm





1-334514111	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/shared[PROBLEM:895036] Date: Feb 13,2018 22:58 CUT Severity: Minor ResourceId: bi1crmdbdev01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/shared InstanceValue: 19.99 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1CRMDBDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/shared AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3442362:bi1

Filesystem                             Size  Used Avail Use% Mounted on
/dev/sda3                               50G   33G   15G  70% /
tmpfs                                   64G   12K   64G   1% /dev/shm
/dev/sda1                              194M   30M  155M  16% /boot
/dev/mapper/vghanadata-lv_hana_data    384G  104G  281G  27% /hana/data
/dev/mapper/vghanadata-lv_hana_shared  128G  115G   14G  90% /hana/shared
/dev/mapper/vghanadata-lv_usr_sap       50G  1.7G   49G   4% /usr/sap
/dev/sdd1                              130G  4.2G  126G   4% /hana/log
//10.199.20.26/F                       1.0T  911G  114G  89% /mnt/F


[root@BI1CRMDBDEV01 shared]# du -mch --max-depth=1 .
115G    ./HCD
115G    .
115G    total

[root@BI1CRMDBDEV01 HCD]# du -mch --max-depth=1 .
8.0K    ./profile
1.7G    ./global
6.0G    ./exe
108G    ./HDB06
115G    .
115G    total

[root@BI1CRMDBDEV01 HCD]# cd HDB06/
[root@BI1CRMDBDEV01 HDB06]# du -mch --max-depth=1 .
4.0K    ./work
1.4G    ./bi1crmdbdev01
106G    ./backup
108G    .
108G    total



1-334533671	sev 2
Summary: Free_disk_space_is_less_than_10%_on_volume_F:[PROBLEM:901422] Date: Feb 14,2018 12:10 CUT Severity: Major ResourceId: ri3lr020 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: InstanceValue: 9.91 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: DAL09AMMTS002 NodeAlias: 146.89.140.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3443723:mic





1-334519731   sev3
Hello team, 

Please assist to provide the exact detailed storage usage for these 3 servers.

SU6SUNECD00 / 10.13.3.11
SU6SUNECQ00 / 10.13.3.12
SU6SUNECP00 / 10.13.3.13




1-334568971	sev2
Summary: Lack_of_free_swap_space_on_r3devapp.imzcloud.ibmammsap.local[PROBLEM:913352] Date: Feb 15,2018 9:47 CUT Severity: Major ResourceId: r3devapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 38.08 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: r3devapp.imzcloud.ibmammsap.local NodeAlias: 10.74.6.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3450859:mtb


[root@r3devapp ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         28          3         10          0         10
-/+ buffers/cache:         17         13
Swap:            7          4          3

top - 04:27:16 up 411 days, 15:22,  1 user,  load average: 0.63, 0.67, 0.69
Tasks: 368 total,   1 running, 367 sleeping,   0 stopped,   0 zombie
Cpu(s): 23.1%us,  0.3%sy,  0.0%ni, 76.6%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   28.338G used, 3076.922M free,   44.465M buffers
Swap: 8191.996M total, 5071.332M used, 3120.664M free,   10.916G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
  7583 hd6adm    20   0 3943m 3.0g  816 S  0.0  9.5 143:20.99 829m SAPup_real
  2403 root      20   0  341m  63m 1200 S  0.6  0.2 244:32.90  35m vmtoolsd
 63975 root      20   0 2110m  15m 2928 S  0.0  0.0  69:06.73  23m ksaagent
 12862 daaadm    20   0 3185m 370m 4708 S  1.1  1.2 392:00.68  15m jstart
  7594 hd6adm    20   0  120m  51m  508 S  0.0  0.2   2:41.35  10m SAPup_real
115630 root      20   0 2987m 1.1g 1324 S  0.6  3.4 249:46.06 6144 python
128179 hd6adm    20   0 27.1g 142m  94m S  0.0  0.4   0:20.24 6144 HD6_00_UP2_W54
112640 root      20   0  199m  23m 2032 S  0.0  0.1   2:06.33 5836 Xvnc
  4534 root      20   0  226m    8    4 S  0.0  0.0   0:00.06 5796 firstboot
 92120 root      20   0  233m 9288  644 S  0.0  0.0   0:16.82 4096 smbd
121648 hd6adm    20   0 27.2g 2.0g 1.9g S  0.0  6.5   7:14.43 4096 HD6_00_DIA_W36
126386 daaadm    20   0  487m 9.9m 1392 S  0.0  0.0   1:49.20 4096 sapstartsrv
126529 daaadm    20   0  185m  18m 1436 S  0.0  0.1   0:01.42 4096 jc.sapDAA_SMDA9
  2458 root      20   0 51004    8    4 S  0.0  0.0   0:00.02 3120 VGAuthService
  4354 sapadm    20   0 1356m  49m 4028 S  0.6  0.2 141:22.96 2048 sapstartsrv
121616 hd6adm    20   0 27.2g 4.3g 4.2g S  0.0 13.8  10:02.40 2048 HD6_00_DIA_W4
121618 hd6adm    20   0 27.2g 3.7g 3.5g S  0.0 11.8   7:24.67 2048 HD6_00_DIA_W6
121619 hd6adm    20   0 27.2g 2.9g 2.8g S  0.0  9.4   8:04.26 2048 HD6_00_DIA_W7
121620 hd6adm    20   0 27.2g 2.4g 2.2g S  0.0  7.6   7:46.86 2048 HD6_00_DIA_W8
121638 hd6adm    20   0 27.2g 6.6g 6.4g S  0.0 21.0  11:20.19 2048 HD6_00_DIA_W26
121642 hd6adm    20   0 27.2g 4.0g 3.8g S  0.0 12.7   9:53.03 2048 HD6_00_DIA_W30
121647 hd6adm    20   0 27.2g 3.7g 3.6g S  0.0 11.9  10:11.23 2048 HD6_00_DIA_W35
121650 hd6adm    20   0 27.2g 2.2g 2.1g S  0.0  7.1   7:32.97 2048 HD6_00_DIA_W38
128178 hd6adm    20   0 27.1g 170m 112m S  0.0  0.5   3:28.78 2048 HD6_00_SPO_W53
121643 hd6adm    20   0 27.2g 6.4g 6.2g S  0.0 20.4  22:21.74 2044 HD6_00_DIA_W31
 25312 root      20   0 2661m 196m 2528 S  0.0  0.6 144:36.87 2028 ds_am
121627 hd6adm    20   0 27.2g 4.3g 4.1g S  0.0 13.8  11:37.53 1720 HD6_00_DIA_W15





1-334572731	sev3
Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:914032] Date: Feb 15,2018 11:32 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 10.183333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3451160:mt5




1-334570991	sev2
[PROBLEM:913997] Date: Feb 15,2018 11:22 CUT Severity: Major ResourceId: yanbalbodev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: unq InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 10 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: yanbalbodev.imzcloud.ibmammsap.local NodeAlias: 10.4.7.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3451143:unq

[root@yanbalbodev ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                      478G  411G   43G  91% /

[root@yanbalbodev /]# du -mch --max-depth=1 .
4.0K    ./mnt
0       ./misc
16K     ./lost+found
12K     ./.dbus
4.0K    ./srv
77G     ./install
2.2G    ./var
4.0K    ./media
43M     ./etc
106M    ./boot
4.0K    ./.pulse
du: cannot access `./proc/15128/task/15128/fd/4': No such file or directory
du: cannot access `./proc/15128/task/15128/fdinfo/4': No such file or directory
du: cannot access `./proc/15128/fd/4': No such file or directory
du: cannot access `./proc/15128/fdinfo/4': No such file or directory
0       ./proc
5.2G    ./home
9.1M    ./bin
466M    ./root
0       ./sys


[root@yanbalbodev install]# du -mch --max-depth=1 .
17G     ./BO41SP6
28K     ./FILES_CH100969_UNIQUE
9.3G    ./BO42
4.9G    ./CH100969
3.0G    ./lumira
9.1G    ./BO42SP02PATCH11
273M    ./HDB_CLIENT_LINUX_X86_64
3.8G    ./desing16
4.0K    ./UNI14
9.6G    ./BO42SP02
12G     ./BOPATCH
1.7G    ./LTS4BIP
77G     .
77G     total
[root@yanbalbodev install]# pwd
/install

-----------------------------------------------------------------------------------------------------------------------------

19 Feb

1-334582431	sev3
Summary: FS_is_read_only_on_snchmdada11.imzcloud.ibmammsap.local[PROBLEM:916990] Date: Feb 15,2018 16:27 CUT Severity: Minor ResourceId: snchmdada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE0 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchmdada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.104 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3452089:snc

[root@snchmdada11 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01 filesystems are read-only


[root@snchmdada11 ibmrmalik]# df -h /SHARE/MNT/FILE056/SAP_ARCH_nonprd01
Filesystem            Size  Used Avail Use% Mounted on
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01
                      197G  174G   24G  88% /SHARE/MNT/FILE056/SAP_ARCH_nonprd01


[root@snchmdada11 ibmrmalik]# df -h /SHARE/MNT/FILE056/SAP_LOAD_nonprd01
Filesystem            Size  Used Avail Use% Mounted on
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01
                      197G  174G   24G  88% /SHARE/MNT/FILE056/SAP_LOAD_nonprd01

[root@snchmdada11 ibmrmalik]# cat /etc/fstab|grep /SHARE/MNT/FILE056
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_ARCH_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0




CLDERPAPPP1          10.198.0.71	access denied
CLDGRCAPPP1        10.198.0.73		access denied
CLDPROAPPP1        10.198.0.75		pw prompt not coming
CLDENPAPPP1        10.198.0.74		accessdenied
CLDBOBIADWP1     10.198.0.70	able to login	
[ibmrmalik@CLDBOBIADWP1 ~]$ uptime
 18:49:46 up 19 min,  1 user,  load average: 0.03, 0.09, 0.21

CLDWDPWEBP1      10.198.1.70		Access denied
CLDWDPWEBP2     10.198.1.71		access denied


root
Set44now@ 
or May55now#


1st Priority -- **critical**:
SJMPEPAA01	10.198.10.4	10.195.1.4	access denied
SJMPEPAA02	10.198.10.5	10.195.1.5	accessable
[ibmrmalik@sjmpepaa02 ~]$ uptime
 11:11:27 up 5 min,  1 user,  load average: 3.53, 1.43, 0.57

sjmpcpaa01	10.198.10.13	10.195.1.13	access denied
sjmpcpaa02	10.198.10.14	10.195.1.14	access denied
sjmppqaa01	10.198.10.9	10.195.1.9	access denied
sjmppqaa02	10.198.10.11	10.195.1.11	access denied
sjmppqdb01	10.198.10.12	10.195.1.12	access denied
sjmpwdaa01	10.198.13.12	10.195.0.12	access denied

2nd priority:
sjmpxpaa01	10.198.10.19	10.195.1.19	access denied
sjmpxpdb01	10.198.10.20	10.195.1.20	access denied
sjmpgpdb01	10.198.10.8	10.195.1.8	accessible
[ibmrmalik@sjmpgpdb01 ~]$ uptime
 11:20:22 up 24 min,  1 user,  load average: 0.03, 0.76, 0.83

sjmpmpdb01	10.198.10.10	10.195.1.10	access denied
sjmpbjdb01	10.198.10.21	10.195.1.21	not even connecting seems down
sjmpfpaa01	10.198.10.7	10.195.1.7 	access denied



AGEAS (AGE)	SPSVEPDEHDB01	10.6.3.11	10.70.111.11	Production	Ravi
[ibmrmalik@spsvepdehdb01 ~]$ uptime
 20:20:29 up 93 days,  7:10,  1 user,  load average: 1.09, 0.87, 0.71
[root@spsvepdehdb01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVEPAEAPP01	10.6.3.12	10.70.111.12	Production	Ravi
[root@spsvepaeapp01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVCPDCHDB01	10.6.3.14	10.70.111.14	Production	Ravi
[root@spsvcpdchdb01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVCPACAPP01	10.6.3.15	10.70.111.15	Production	Ravi	access denied

AGEAS (AGE)	SPSVSPAHAPP01	10.6.3.16	10.70.111.16	Production	Ravi
[root@spsvspahapp01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVBPABAPP01	10.6.3.18	10.70.111.18	Production	Ravi	access denied

AGEAS (AGE)	SPSVBPDAASE01	10.6.3.19	10.70.111.19	Production	Ravi
[root@spsvbpdaase01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVBPAAAPP01	10.6.3.20	10.70.111.20	Production	Ravi	access denied

AGEAS (AGE)	SPSVPPDOASE01	10.6.3.23	10.70.111.23	Production	Ravi	access denied

AGEAS (AGE)	SPSVEPDPASE01	10.6.3.27	10.70.111.27	Production	Ravi
[root@spsvepdpase01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVEPAPAPP01	10.6.3.28	10.70.111.28	Production	Ravi	access denied

AGEAS (AGE)	SPSVWPAWAPP11	10.6.3.30	10.70.111.30	Production	Ravi	access denied

AGEAS (AGE)	SPSVWPAWAPP12	10.6.3.31	10.70.111.31	Production	Ravi	access denied

AGEAS (AGE)	SPSVSPDSASE01	10.6.3.32	10.70.111.32	Production	Ravi
[root@spsvspdsase01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVSPASAPP01	10.6.3.33	10.70.111.33	Production	Ravi
[root@spsvspasapp01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

AGEAS (AGE)	SPSVWPAYSQL01	10.6.3.21	10.70.111.21	Production	Ravi	Windows login success

AGEAS (AGE)	SPSVIPDISQL01	10.6.3.25	10.70.111.25	Production	Ravi	Windows login success


sh /var/lib/zabbix/check_rw_mounts.sh




CRPRDApp1	10.70.2.76	A0DIML014XVM038	PRD	access denied

eCPRDWeb2	10.70.1.202	PRD	access denied
	
eCPRDApp1	10.70.2.151	PRD	access denied

eCPRDApp2	10.70.2.152	PRD	access denied

eCPRDApp3	10.70.2.153	PRD
[root@eCPRDApp3 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /opt/data/cerebos/files /opt/data/cerebos/media /opt/data/cerebos/_ui filesystems are read-only

mount -a
reboot 

eCPRDApp4	10.70.2.154	PRD	access denied

eCPRDSolr1	10.70.2.155	PRD	cannot get password prompt

eCPRDDHApp1	10.70.2.156	PRD	access denied
	
eCPRDLog1	10.70.1.87	PRD	access denied






SMRT : HIGH PRIORITY SERVER LIST





PP1  - CLDENPAPPP1	   10.198.0.74	
[root@CLDENPAPPP1 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

Read-Only AD (10.168.1.5)   
GP1    CLDGRCAPPP1	    10.198.0.73	
[root@CLDGRCAPPP1 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /usr/sap/trans filesystems are read-only

OP1    CLDPROAPPP1	    10.198.0.75	

RP1     CLDBOBIADWP1	  10.198.0.70
[root@CLDBOBIADWP1 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

SD1     CLDSLDAPPP1	      10.198.0.213	
DP1     CLDWDPWEBP1	   10.198.1.70




CLDENPDTBP1	10.198.0.144	access denied
             CLDPRODTBP1	10.198.0.145




10.6.4.206
[root@YHIEPS01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

10.6.4.208	access denied




SM5DERPAPP01	10.198.0.236	access denied
CLDERPAPPX5	10.198.0.235	access denied
CLDENPAPDT1	10.198.0.216
[root@CLDENPAPDT1 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

CLDPROAPDT1	10.198.0.217	access denied
CLDBOBIADWT1	10.198.0.218	cannot get login prompt
CLDBOBIADWP1	10.198.0.70
[root@CLDBOBIADWP1 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

CLDERPAPPQ3  	10.198.0.72
[root@CLDERPAPPQ3 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK






QFP	IaaS/SFTP Server	N/A	RedHat Linux	sjmqfpaa01	
10.198.12.14 

10.198.12.13
[root@sjmqepaa01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK


10.198.12.11
[root@sjmqcpdb01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

10.198.12.12
[root@sjmqbdba01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK


10.198.12.15
[root@sjmqgpdb01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK


10.198.12.16
[root@sjmqpqja01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK


10.198.12.17
[root@sjmqpqdb01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK





1-334712941
Summary: Zabbix_agent_on_spsvbpabapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:964297] Date: Feb 19,2018 13:0 CUT Severity: Critical ResourceId: spsvbpabapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: spsvbpabapp01.imzcloud.ibmammsap.local NodeAlias: 10.6.3.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3463391:age
10.198.12.18
[root@sjmqcpaa01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK


10.198.12.21
[root@sjmqxpaa01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK


10.198.12.22
[root@sjmqxpdb01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK
--------------------------------------------------------------------------------------------------------------------------------------------


20 Feb


1-334582431	sev3
Summary: FS_is_read_only_on_snchmdada11.imzcloud.ibmammsap.local[PROBLEM:916990] Date: Feb 15,2018 16:27 CUT Severity: Minor ResourceId: snchmdada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE0 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchmdada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.104 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3452089:snc

[root@snchmdada11 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01 filesystems are read-only


[root@snchmdada11 ibmrmalik]# df -h /SHARE/MNT/FILE056/SAP_ARCH_nonprd01
Filesystem            Size  Used Avail Use% Mounted on
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01
                      197G  174G   24G  88% /SHARE/MNT/FILE056/SAP_ARCH_nonprd01


[root@snchmdada11 ibmrmalik]# df -h /SHARE/MNT/FILE056/SAP_LOAD_nonprd01
Filesystem            Size  Used Avail Use% Mounted on
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01
                      197G  174G   24G  88% /SHARE/MNT/FILE056/SAP_LOAD_nonprd01

[root@snchmdada11 ibmrmalik]# cat /etc/fstab|grep /SHARE/MNT/FILE056
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_ARCH_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0





1-334582461	sev3
Summary: FS_is_read_only_on_snchpijda11.imzcloud.ibmammsap.local[PROBLEM:916995] Date: Feb 15,2018 16:28 CUT Severity: Minor ResourceId: snchpijda11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE0 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchpijda11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.114 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3452091:snc

[root@snchpijda11 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01 filesystems are read-only

[root@snchpijda11 ibmrmalik]# cat /etc/fstab|grep /SHARE/MNT/FILE056
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_ARCH_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0





1-334750401	sev2
Summary: NTP_time_is_driffted_on_PBBwdpap00.imzcloud.ibmammsap.local[PROBLEM:971565] Date: Feb 20,2018 2:18 CUT Severity: Major ResourceId: pbbwdpap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pbb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 5.4 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: PBBwdpap00.imzcloud.ibmammsap.local NodeAlias: 10.6.7.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3465876:pbb

[root@PBBwdpap00 ibmrmalik]# /etc/init.d/ntpd status
ntpd (pid  3558) is running...
[root@PBBwdpap00 ibmrmalik]# uptime
 11:26:43 up 13:09,  2 users,  load average: 0.06, 0.04, 0.00
[root@PBBwdpap00 ibmrmalik]# ntpstat
synchronised to NTP server (146.89.140.141) at stratum 8
   time correct to within 6105 ms
   polling server every 1024 s

[root@PBBwdpap00 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
+sng01ammadc001. 146.89.140.139   7 u  598 1024  377    0.512  5409.96  52.078
*sng01ammadc002. 146.89.140.138   7 u   47 1024  377    0.532  5450.97  23.274




1-334617951	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_C:[PROBLEM:928124] Date: Feb 16,2018 13:53 CUT Severity: Major ResourceId: ri3pa046 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 9.5 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: AMMDAL09VCS001 NodeAlias: 146.89.140.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3454426:ibs




1-334563161	sev3	Private IP: 10.114.60.250	root/DzPgea7a	SL ticket 55984430	

Summary: Drive_with_Errors_on_dollar-atb-vhana.xsportal.local[PROBLEM:912377] Date: Feb 15,2018 8:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_dollar-atb-vhana.xsportal.local InstanceValue: Media Error Count = 1 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_dollar-atb-vhana Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_dollar-atb-vhana.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3448331:amm



1-334759611	sev1
Summary: Zabbix_agent_on_0f.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:972995] Date: Feb 20,2018 5:17 CUT Severity: Critical ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: 0f.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3466311:cia

top - 23:33:05 up 161 days, 14:04,  1 user,  load average: 18.90, 26.61, 27.66
Tasks: 535 total,   4 running, 531 sleeping,   0 stopped,   0 zombie
Cpu(s): 30.3%us,  1.1%sy,  0.0%ni, 27.0%id, 40.6%wa,  0.0%hi,  0.9%si,  0.0%st
Mem:    31.316G total,   30.727G used,  602.277M free, 2059.312M buffers
Swap:   12.000G total, 4095.801M used, 8192.195M free,   17.823G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 2943 dsmadm    20   0 8599m 3.1g  15m S  2.7  9.8   2215:30 292m jlaunch
31633 dsmadm    20   0 1451m 418m 4044 S  0.0  1.3  34:25.14 182m igspw_mt
24518 db2dsm    20   0 1224m  75m  16m S  0.0  0.2 190:25.09 181m db2fmp
24490 db2dsm    20   0 12.6g 3.1g 2.7g S 19.9  9.9  15419:57 165m db2sysc
31634 dsmadm    20   0 1196m 249m 4044 S  0.0  0.8  24:16.69 144m igspw_mt
31891 db2dsm    20   0  835m  50m  15m S  0.0  0.2   5:55.82 112m db2fmp
31963 dsmadm    20   0 5055m  47m  20m S  0.0  0.1  15:54.07  89m icman
 2944 dsmadm    20   0 3117m  52m 8500 S  0.0  0.2 135:52.18  77m jlaunch
 2942 dsmadm    20   0 5556m 263m  20m S  1.0  0.8   2108:21  74m jlaunch
15455 dsmadm    20   0 6901m 216m 207m R 100.0  0.7  57221:36  73m DSM_50_BTC_W23
17660 dabadm    20   0 5265m 558m 9664 S  0.0  1.7   1319:44  69m jstart
27562 dsmadm    20   0 6899m 118m 109m R 100.0  0.4  57240:08  67m DSM_50_BTC_W24
13652 dsmadm    20   0 6867m  33m  32m S  0.0  0.1   0:02.16  44m DSM_50_UP2_W28
24488 root      20   0 1222m  19m  19m S  0.0  0.1   0:00.17  43m db2syscr
24497 root      20   0 1225m  12m  10m S  0.0  0.0  13:51.83  40m db2syscr
24498 root      20   0 1225m  12m  10m S  0.0  0.0  13:52.90  40m db2syscr
24499 root      20   0 1225m  12m  10m S  0.0  0.0  13:52.31  40m db2syscr
31983 dsmadm    20   0 6864m  38m  33m S  0.0  0.1   0:02.60  38m DSM_50_ENQ_W18
31982 dsmadm    20   0 6864m  38m  33m S  0.0  0.1   0:02.62  38m DSM_50_ENQ_W17
15826 dsmadm    20   0 5602m 752m 4812 S  0.7  2.3   2798:29  32m java
31542 dsmadm    20   0 6665m  54m  53m S  0.0  0.2  97:20.01  30m DSM_50_DP
17236 root      20   0 1056m  70m 5820 S  0.0  0.2  25:16.01  30m ds_agent



1-334563201	sev3	Private IP: 10.148.24.147	root/RdLmRf9G	esx console cred root/GANy2caC7R		unknown state	SL ticket 55989466
Summary: Drive_with_Errors_on_wdc04hana-1024-13.xsportal.local[PROBLEM:912384] Date: Feb 15,2018 8:8 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_wdc04hana-1024-13.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_wdc04hana-1024-1 Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_wdc04hana-1024-13.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3448338:amm



1-334760911	sev1
Summary: Zabbix_agent_on_clderpdtbd1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:973475] Date: Feb 20,2018 6:16 CUT Severity: Critical ResourceId: clderpdtbd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: clderpdtbd1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.207 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3466400:sm5

[root@clderpdtbd1 ibmrmalik]# uptime
 15:18:48 up 749 days,  1:30,  1 user,  load average: 15.77, 15.80, 15.62
[root@clderpdtbd1 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  35558) is running...



1-334745727	sev3
Please run the script  UXSCR_POS_TO_SAP on EP1
A0CTSG014XVM029 	CLDERPAPPP1 	10.168.1.71 	10.198.0.71



1-334725041	sev3
*** Details of Generic Service Request - DO NOT CHANGE ***

Hi Team,

We are planning to install SAP Personas 3.0 SP06 in ST1-blx system based on SR 3000023676.
Could you please perform the data transfer of installation files to ST1-blx server?
Total number of files: 12
Source location of files: SQ1-on premise server.
Files path: /sapcd/GW_750/Personas/EPS/in
Target location: ST1-bluemix
Files Path: /usr/sap/trans/EPS/in
I will move the files to /migrations folder and let you know the status via email.

Can we get the files in /migrations/DATATRANSFER/in - NFS to our server SMTMSBXST1 - App >> 10.78.20.13  

Source : /migrations/DATATRANSFER/in
Target Path : /usr/sap/trans/EPS/in  >> SMTMSBXST1 - App >> 10.78.20.13
 

Source : 10.5.22.12, user : leg2dev     






1-334768521	sev2	100.126.32.19
Summary: FS_is_read_only_on_Pepsapgpsdi00.imzcloud.ibmammsap.local[PROBLEM:974216] Date: Feb 20,2018 7:45 CUT Severity: Minor ResourceId: pepsapgpsdi00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /run/user/0/gvfs filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: Pepsapgpsdi00.imzcloud.ibmammsap.local NodeAlias: 100.126.32.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3466612:pep




1-334771371	sev3
Summary: Processor_load_is_too_high_on_REXQBFCAPP1[PROBLEM:976443] Date: Feb 20,2018 12:0 CUT Severity: Minor ResourceId: rexqbfcapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: rxl InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 5.05 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: REXQBFCAPP1 NodeAlias: 10.135.2.200 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467190:rxl



1-334771821	sev1
Summary: Zabbix_agent_on_clderpdtbd1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:975736] Date: Feb 20,2018 10:57 CUT Severity: Critical ResourceId: clderpdtbd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: clderpdtbd1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.207 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467102:sm5

------------------------------------------------------------------------------------------


21 Feb


1-334781211	sev2	Summary: Free_disk_space_is_less_than_5%_on_volume_/home

ntpdate -d 146.89.140.139



	1-334786701	sev2		restarted
Summary: NTP_time_is_driffted_on_YHIBIDS01.imzcloud.ibmammsap.local[PROBLEM:979229] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: yhibids01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: yhi InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -123.02 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: YHIBIDS01.imzcloud.ibmammsap.local NodeAlias: 10.6.4.203 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: 


	1-334783451	sev2
Summary: NTP_time_is_driffted_on_YHIBIPS01.imzcloud.ibmammsap.local[PROBLEM:979094] Date: Feb 20,2018 17:3 CUT Severity: Major ResourceId: yhibips01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: yhi InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.95 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: YHIBIPS01.imzcloud.ibmammsap.local NodeAlias: 10.6.4.208 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467781:yhi

	1-334783491	sev2
Summary: NTP_time_is_driffted_on_YHIEDS01.imzcloud.ibmammsap.local[PROBLEM:979233] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: yhieds01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: yhi InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -123.16 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: YHIEDS01.imzcloud.ibmammsap.local NodeAlias: 10.6.4.201 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467810:yhi

	1-334789081	sev2
Summary: NTP_time_is_driffted_on_YHISMDS01.imzcloud.ibmammsap.local[PROBLEM:979228] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: yhismds01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: yhi InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -123.03 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: YHISMDS01.imzcloud.ibmammsap.local NodeAlias: 10.6.4.204 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467808:yhi

	1-334788501  sev2
Summary: NTP_time_is_driffted_on_sjmqwdaa01.imzcloud.ibmammsap.local[PROBLEM:979315] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: sjmqwdaa01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.87 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmqwdaa01.imzcloud.ibmammsap.local NodeAlias: 10.198.13.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467828:ju1

	1-334788811	sev2
Summary: NTP_time_is_driffted_on_SJMPEPDB01DR.imzcloud.ibmammsap.local[PROBLEM:980868] Date: Feb 20,2018 17:24 CUT Severity: Major ResourceId: sjmpepdb01dr TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.72 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: SJMPEPDB01DR.imzcloud.ibmammsap.local NodeAlias: 10.204.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468331:ju1

	1-334787721	sev2
Summary: NTP_time_is_driffted_on_sapdpqdb01.imzcloud.ibmammsap.local[PROBLEM:979303] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: sapdpqdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -123.01 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sapdpqdb01.imzcloud.ibmammsap.local NodeAlias: 10.198.11.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467821:ju1

	1-334787421	sev2
Summary: NTP_time_is_driffted_on_sjmdcpdb01.imzcloud.ibmammsap.local[PROBLEM:979291] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: sjmdcpdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.97 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmdcpdb01.imzcloud.ibmammsap.local NodeAlias: 10.198.11.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467816:ju1

	1-334787181	sev2
Summary: NTP_time_is_driffted_on_sjmdmpdb01.imzcloud.ibmammsap.local[PROBLEM:979305] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: sjmdmpdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.95 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmdmpdb01.imzcloud.ibmammsap.local NodeAlias: 10.198.11.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467823:ju1


	1-334787971	sev2
Summary: NTP_time_is_driffted_on_sjmdwdwd01.imzcloud.ibmammsap.local[PROBLEM:979606] Date: Feb 20,2018 17:9 CUT Severity: Major ResourceId: sjmdwdwd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.88 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmdwdwd01.imzcloud.ibmammsap.local NodeAlias: 10.198.13.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467941:ju1

	1-334787671    sev2
Summary: NTP_time_is_driffted_on_sjmpepaa02.imzcloud.ibmammsap.local[PROBLEM:979735] Date: Feb 20,2018 17:10 CUT Severity: Major ResourceId: sjmpepaa02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -123.01 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmpepaa02.imzcloud.ibmammsap.local NodeAlias: 10.198.10.5 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent 

	1-334786891	sev2
Summary: NTP_time_is_driffted_on_sjmpwdaa01.imzcloud.ibmammsap.local[PROBLEM:979720] Date: Feb 20,2018 17:10 CUT Severity: Major ResourceId: sjmpwdaa01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -123.06 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmpwdaa01.imzcloud.ibmammsap.local NodeAlias: 10.198.13.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467955:ju1

	1-334786741	sev2
Summary: NTP_time_is_driffted_on_sjmqgpdb01.imzcloud.ibmammsap.local[PROBLEM:979324] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: sjmqgpdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.96 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmqgpdb01.imzcloud.ibmammsap.local NodeAlias: 10.198.12.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467832:ju1

1-334788001	sev2
Summary: NTP_time_is_driffted_on_sjmqxpaa01.imzcloud.ibmammsap.local[PROBLEM:979314] Date: Feb 20,2018 17:5 CUT Severity: Major ResourceId: sjmqxpaa01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.9 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmqxpaa01.imzcloud.ibmammsap.local NodeAlias: 10.198.12.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467827:ju1


1-334790161	sev2
Summary: NTP_time_is_driffted_on_LBDSD1App00.imzcloud.ibmammsap.local[PROBLEM:981226] Date: Feb 20,2018 17:27 CUT Severity: Major ResourceId: lbdsd1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -253.71 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDSD1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468445:lbd



1-334791131	sev2
Summary: NTP_time_is_driffted_on_LBDPD1DEVDB1.imzcloud.ibmammsap.local[PROBLEM:981281] Date: Feb 20,2018 17:28 CUT Severity: Major ResourceId: lbdpd1devdb1 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -253.8 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDPD1DEVDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.25 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468471:lbd

1-334791121	sev2
Summary: NTP_time_is_driffted_on_LBDSQ1DB06.imzcloud.ibmammsap.local[PROBLEM:981287] Date: Feb 20,2018 17:28 CUT Severity: Major ResourceId: lbdsq1db06 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -253.78 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDSQ1DB06.imzcloud.ibmammsap.local NodeAlias: 10.8.8.34 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468473:lbd


1-334791921	sev2
Summary: NTP_time_is_driffted_on_LBDCQ1App00.imzcloud.ibmammsap.local[PROBLEM:981334] Date: Feb 20,2018 17:28 CUT Severity: Major ResourceId: lbdcq1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -253.68 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDCQ1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.43 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468494:lbd


1-334791691	sev2
Summary: NTP_time_is_driffted_on_LBDCD1App00.imzcloud.ibmammsap.local[PROBLEM:981264] Date: Feb 20,2018 17:27 CUT Severity: Major ResourceId: lbdcd1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -253.82 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDCD1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468462:lbd




1-334791621	sev2
Summary: NTP_time_is_driffted_on_LBDSQ1App01.imzcloud.ibmammsap.local[PROBLEM:981301] Date: Feb 20,2018 17:28 CUT Severity: Major ResourceId: lbdsq1app01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -253.73 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDSQ1App01.imzcloud.ibmammsap.local NodeAlias: 10.8.8.36 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468484:lbd



1-334791521	sev2
Summary: NTP_time_is_driffted_on_LBDSP1App01.imzcloud.ibmammsap.local[PROBLEM:981750] Date: Feb 20,2018 17:33 CUT Severity: Major ResourceId: lbdsp1app01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.86 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDSP1App01.imzcloud.ibmammsap.local NodeAlias: 10.8.8.64 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468639:lbd



		1-334791511	sev2
Summary: NTP_time_is_driffted_on_LBDCP1App00.imzcloud.ibmammsap.local[PROBLEM:981795] Date: Feb 20,2018 17:33 CUT Severity: Major ResourceId: lbdcp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.76 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDCP1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468649:lbd



		1-334790401	sev2
Summary: NTP_time_is_driffted_on_LBDBOQQASApp1.imzcloud.ibmammsap.local[PROBLEM:981691] Date: Feb 20,2018 17:32 CUT Severity: Major ResourceId: lbdboqqasapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.8 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDBOQQASApp1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.57 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468621:lbd



1-334820731	sev3
Summary: Processor_load_is_too_high_on_A0B4HK012VUM002[PROBLEM:993041] Date: Feb 21,2018 11:42 CUT Severity: Minor ResourceId: ri3vw057 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 7.333333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: A0B4HK012VUM002 NodeAlias: 146.89.141.43 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3471305:ibs

NTP issue fixed so closing ticket Zabbix didnt trigger the clear event

----------------------------------------------------------------------------------------------------------------------------------------

22 Feb


1-334825671	sev2
Summary: Lack_of_free_swap_space_on_crdevhanadb1.imzcloud.ibmammsap.local[PROBLEM:994402] Date: Feb 21,2018 14:16 CUT Severity: Major ResourceId: crdevhanadb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cb4 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 30.5 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: crdevhanadb1.imzcloud.ibmammsap.local NodeAlias: 10.70.1.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3471657:cb4

top - 13:16:46 up 230 days, 19:40,  1 user,  load average: 0.22, 0.73, 1.10
Tasks: 877 total,   1 running, 876 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.7%us,  0.4%sy,  0.0%ni, 96.8%id,  0.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:   252.276G total,  157.402G used,   94.873G free,  179.496M buffers
Swap:   50.000G total,   32.439G used,   17.561G free, 7951.848M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
29507 crdadm    20   0  148g 114g 5.3g S 46.7 45.5   3318:20  14g hdbindexserver
29511 crdadm    20   0 19.3g 9.2g  32m S 60.2  3.6   2278:33 1.6g hdbxsengine
29509 crdadm    20   0 14.7g 6.8g  21m S  1.7  2.7  90:33.10 1.2g hdbscriptserver
28920 crdadm    20   0 9860m 2.6g  18m S  1.4  1.0 128:04.32 1.0g hdbnameserver
 
[root@crdevhanadb1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:           252        157         94          5          0          7
-/+ buffers/cache:        149        102
Swap:           49         32         17



1-334622781	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/home[PROBLEM:931503] Date: Feb 16,2018 19:34 CUT Severity: Critical ResourceId: pepsapg1sdi00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home InstanceValue: 4.48 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: Pepsapg1sdi00.imzcloud.ibmammsap.local NodeAlias: 100.126.32.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3455273:pep

--------------------------------------------------------------------------------------------------------------------------------------

23 Feb


1-334882561	sev1
Summary: Zabbix_agent_on_loncfgcep0001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1013569] Date: Feb 23,2018 2:22 CUT Severity: Critical ResourceId: loncfgcep0001 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cf9 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: loncfgcep0001.imzcloud.ibmammsap.local NodeAlias: 10.69.2.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3476530:cf9




1-334875201	sev2
Summary: Lack_of_free_swap_space_on_fbtprdhanapp2.imzcloud.ibmammsap.local[PROBLEM:1011623] Date: Feb 22,2018 22:30 CUT Severity: Major ResourceId: fbtprdhanapp2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.46 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: fbtprdhanapp2.imzcloud.ibmammsap.local NodeAlias: 10.4.27.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3476125:fbt

top - 19:13:49 up 240 days,  4:33,  1 user,  load average: 0.05, 0.01, 0.00
Tasks: 432 total,   1 running, 431 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.2%us,  0.1%sy,  0.0%ni, 99.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.909G total,   62.127G used,  801.598M free,   87.699M buffers
Swap:   64.000G total,   32.521G used,   31.479G free,   13.944G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 3612 s4padm    20   0 66.0g  34g  32m S  0.0 55.2   7:59.41  22g icman
 6105 s4padm    20   0 53.3g 717m 647m S  0.0  1.1   0:49.19 182m S4P_02_DIA_W11
 6107 s4padm    20   0 53.3g 779m 710m S  0.0  1.2   0:50.52 143m S4P_02_DIA_W13
 6097 s4padm    20   0 53.3g 673m 599m S  0.0  1.0   0:25.49 141m S4P_02_DIA_W3
 6095 s4padm    20   0 53.3g 579m 511m S  0.0  0.9   0:29.75 140m S4P_02_DIA_W1
 6098 s4padm    20   0 53.3g 824m 731m S  0.0  1.3   0:41.88 130m S4P_02_DIA_W4

[root@fbtprdhanapp2 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         62          0         13          0         13
-/+ buffers/cache:         48         14
Swap:           63         32         31




1-334306121   sev2
Summary: Lack_of_free_swap_space_on_ERP-QAS.imzcloud.ibmammsap.local[PROBLEM:835762] Date: Feb 8,2018 22:0 CUT Severity: Major ResourceId: erp-qas TicketGroup: AMM-DELIVERY-TECH CustomerCode: tqa InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 49.97 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: ERP-QAS.imzcloud.ibmammsap.local NodeAlias: 10.7.2.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3427873:tqa

top - 05:35:52 up 60 days, 12:38,  1 user,  load average: 0.07, 0.02, 0.00
Tasks: 360 total,   1 running, 359 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.3%us,  0.7%sy,  0.0%ni, 99.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    23.462G total,   23.055G used,  416.988M free,  235.379M buffers
Swap:   13.766G total,   10.137G used, 3715.535M free,   17.572G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
65461 tqqadm    20   0 25.2g 589m 283m S  0.0  2.5  32:25.26 2056 TQQ_00_BTC_W10
42612 tqqadm    20   0  525m  37m  24m S  0.0  0.2   0:47.85   16 gwrd
42619 tqqadm    20   0 25.1g 344m 176m S  0.0  1.4   0:31.99   16 TQQ_00_UPD_W5


[root@ERP-QAS ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            23         23          0         15          0         17
-/+ buffers/cache:          5         18
Swap:           13         10          3




1-334560881	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_S:[PROBLEM:911694] Date: Feb 15,2018 6:40 CUT Severity: Major ResourceId: ri3pa046 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_S: InstanceValue: 10 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: AMMDAL09VCS001 NodeAlias: 146.89.140.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_S: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3446023:ibs




1-333742631	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/TSMLOGS/TLOG[PROBLEM:648919] Date: Jan 22,2018 22:25 CUT Severity: Critical ResourceId: sng01ammtsm001 TicketGroup: ApsSAPTechnical CustomerCode: amm InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/TSMLOGS/TLOG InstanceValue: 4.91 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: sng01ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.178 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/TSMLOGS/TLOG AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3388084:amm

[root@sng01ammtsm001 ibmrmalik]# df -k /TSMLOGS/TLOG
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/tsmlog01_vg-tsmtlog_lv
                     437489184 40980220 374279220  10% /TSMLOGS/TLOG

[root@sng01ammtsm001 TLOG]# du -mch --max-depth=1 .
41G     ./tsminst1
20K     ./NODE0000
4.0K    ./lost+found
41G     .
41G     total
[root@sng01ammtsm001 TLOG]# cd tsminst1/
[root@sng01ammtsm001 tsminst1]# du -mch --max-depth=1 .
41G     ./TSMDB1
41G     .
41G     total
[root@sng01ammtsm001 tsminst1]# cd TSMDB1/
[root@sng01ammtsm001 TSMDB1]# du -mch --max-depth=1 .
41G     ./NODE0000
41G     .
41G     total
[root@sng01ammtsm001 TSMDB1]# cd NODE0000/
[root@sng01ammtsm001 NODE0000]# du -mch --max-depth=1 .
41G     ./LOGSTREAM0000
41G     .
41G     total
[root@sng01ammtsm001 NODE0000]# cd LOGSTREAM0000/
[root@sng01ammtsm001 LOGSTREAM0000]# du -mch --max-depth=1 .
41G     ./C0000002
41G     .
41G     total
[root@sng01ammtsm001 LOGSTREAM0000]# cd C0000002/
[root@sng01ammtsm001 C0000002]# du -mch --max-depth=1 .
41G     .
41G     total




1-334584801	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_C:[PROBLEM:917689] Date: Feb 15,2018 17:25 CUT Severity: Critical ResourceId: ri3lr019 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 4.98 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: DAL09AMMTS001 NodeAlias: 146.89.140.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3452192:mic





1-334564931	sev 3	root/TNPuz2l6	10.164.30.190	sl ticket for hotswap  56118496
Summary: Drive_with_Errors_on_lonhana-1024-25.xsportal.local[PROBLEM:912380] Date: Feb 15,2018 8:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_lonhana-1024-25.xsportal.local InstanceValue: Media Error Count = 4 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_lonhana-1024-25. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_lonhana-1024-25.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3448334:amm

------------------------------------------------------------------------------------------------------------------------------------------------------


26 Feb


1-334967051	sev3
Summary: Processor_load_is_too_high_on_WINT334[PROBLEM:1048791] Date: Feb 26,2018 3:51 CUT Severity: Minor ResourceId: wint334 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 2.616667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT334 NodeAlias: 10.136.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3483899:mt5


1-334968541	sev3
Summary: Processor_load_is_too_high_on_ECCDEMO[PROBLEM:1049043] Date: Feb 26,2018 4:25 CUT Severity: Minor ResourceId: eccdemo TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mkm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 5.783333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: ECCDEMO NodeAlias: 10.7.9.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3483958:mkm



1-333740381	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sybase[PROBLEM:648670] Date: Jan 22,2018 21:37 CUT Severity: Minor ResourceId: daltfsbdsp001 TicketGroup: ApsSAPTechnical CustomerCode: toy InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sybase InstanceValue: 16.44 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: DALTFSBDSP001.imzcloud.ibmammsap.local NodeAlias: 10.4.1.194 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sybase AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3387991:toy

[root@DALTFSBDSP001 ibmrmalik]# df -k /sybase
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/mapper/vg_data-lv_db
                     361112164 276445100  66316984  81% /sybase

[root@DALTFSBDSP001 DSP]# du -mch --max-depth=1 .
241G    ./data
1.5G    ./ASE-15_0
244G    .
244G    total

[root@DALTFSBDSP001 data]# pwd
/sybase/DSP/data


[root@DALTFSBDSP001 sybase]# du -mch --max-depth=1 .
244G    ./DSP
4.0K    ./SWBKP
16K     ./lost+found
21G     ./backup
264G    .
264G    total


	
1-334968871	sev2
Summary: Lack_of_free_swap_space_on_WDC04AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:1049570] Date: Feb 26,2018 5:23 CUT Severity: Major ResourceId: wdc04ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.99 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: WDC04AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.142.36 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3484043:amm

[root@WDC04AMMSOL04 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          5          0          7
-/+ buffers/cache:          7          8
Swap:            7          4          3


top - 00:33:15 up 171 days, 15:09,  1 user,  load average: 1.35, 1.06, 0.95
Tasks: 371 total,   1 running, 370 sleeping,   0 stopped,   0 zombie
Cpu(s):  6.0%us,  1.8%sy,  0.0%ni, 74.7%id, 16.9%wa,  0.0%hi,  0.5%si,  0.0%st
Mem:    15.577G total,   15.400G used,  181.074M free,   31.812M buffers
Swap: 8191.996M total, 4096.270M used, 4095.727M free, 8126.258M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
22382 sapadm    20   0 4427m 489m 2836 S  0.0  3.1  29:24.35 464m sapstartsrv
28615 wm1adm    20   0 5937m 2.1g 8564 S  0.0 13.2 118:03.57 257m jlaunch
17306 wm1adm    20   0 3133m 233m 8232 S  0.3  1.5 408:56.20 207m jlaunch
23630 daaadm    20   0 3667m 1.2g 2380 S  0.7  7.4   1320:59 152m java
17770 db2wm1    20   0 1310m  19m 4452 S  0.0  0.1  16:19.48 148m db2fmp
28557 db2wm1    20   0 10.7g 3.9g 3.5g S 12.6 24.9   8880:28 135m db2sysc
10729 daaadm    20   0 3239m 365m 4264 S  0.3  2.3   1272:04 122m jstart
16659 wm1adm    20   0 2143m  17m 5780 S  0.0  0.1  20:41.35  96m icman
17308 wm1adm    20   0 2747m 140m 1624 S  0.0  0.9 242:56.79  83m jlaunch
14347 wm1adm    20   0 6900m  26m  25m S  0.0  0.2   0:02.63  60m WM1_00_UPD_W21
14319 wm1adm    20   0 6903m  18m  17m S  0.0  0.1   0:02.72  58m WM1_00_UPD_W25
14316 wm1adm    20   0 6898m  18m  17m S  0.0  0.1   0:02.97  55m WM1_00_UPD_W23
16700 wm1adm    20   0 6891m  16m  10m S  0.0  0.1   0:02.71  44m WM1_00_UP2_W39
16701 wm1adm    20   0 6891m  16m  10m S  0.0  0.1   0:02.71  44m WM1_00_UP2_W40
16696 wm1adm    20   0 6891m  16m  10m S  0.0  0.1   0:02.71  44m WM1_00_SPO_W35
16698 wm1adm    20   0 6891m  16m  10m S  0.0  0.1   0:02.70  44m WM1_00_SPO_W37
16702 wm1adm    20   0 6891m  22m  16m S  0.0  0.1   0:02.79  44m WM1_00_UP2_W41



1-334624231	sev2
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/opt[PROBLEM:931449] Date: Feb 16,2018 19:29 CUT Severity: Minor ResourceId: pepsapg1sdi00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/opt InstanceValue: 16.49 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: Pepsapg1sdi00.imzcloud.ibmammsap.local NodeAlias: 100.126.32.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/opt AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3455244:pep



1-334624481	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/boot[PROBLEM:931510] Date: Feb 16,2018 19:34 CUT Severity: Critical ResourceId: pepsapg1sdi00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/boot InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: Pepsapg1sdi00.imzcloud.ibmammsap.local NodeAlias: 100.126.32.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/boot AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3455277:pep



1-334975421	sev2
Summary: Lack_of_free_swap_space_on_IA1S4HPRDAPP.imzcloud.ibmammsap.local[PROBLEM:1052199] Date: Feb 26,2018 11:1 CUT Severity: Major ResourceId: ia1s4hprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.4 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: IA1S4HPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3484535:ia1

[root@IA1S4HPRDAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         31          0         19          0         19
-/+ buffers/cache:         11         19
Swap:            7          7          0


top - 13:43:10 up 2 days, 18:32,  2 users,  load average: 0.16, 0.26, 0.44
Tasks: 330 total,   2 running, 328 sleeping,   0 stopped,   0 zombie
Cpu(s):  4.2%us,  0.7%sy,  0.0%ni, 95.2%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   30.522G used,  839.824M free, 6180.000k buffers
Swap: 8191.996M total, 4981.230M used, 3210.766M free,   18.676G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 43258 sp1adm    20   0 52.3g 1.6g 1.4g S  0.0  5.2  12:57.65  14m SP1_00_DIA_W50
 36419 sp1adm    20   0 52.4g 1.8g 1.5g S  0.0  5.6  20:36.52   12 SP1_00_DIA_W48
     1 root      20   0 33672  680  328 S  0.0  0.0   0:01.28    0 init






1-334582461	sev3
Summary: FS_is_read_only_on_snchpijda11.imzcloud.ibmammsap.local[PROBLEM:916995] Date: Feb 15,2018 16:28 CUT Severity: Minor ResourceId: snchpijda11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE0 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchpijda11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.114 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3452091:snc

[root@snchpijda11 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01 filesystems are read-only

[root@snchpijda11 ibmrmalik]# cat /etc/fstab|grep /SHARE/MNT/FILE056
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_ARCH_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0





1-334236061		esx Private IP: 10.134.17.112	AK5NUNFg	Frankfurt 2
Summary: Drive_with_Errors_on_fraha-1024-9.xsportal.local[PROBLEM:816293] Date: Feb 7,2018 8:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_fraha-1024-9.xsportal.local InstanceValue: Media Error Count = 4 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_fraha-1024-9.xsp Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_fraha-1024-9.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3423058:amm


----------------------------------------------------------------------------------------------------------------------------------

27 Feb
	
1-334906281 	sev2	LIVIU.CHIRITA	
FRAMAGSPO0003   10.69.0.155 , DF is hung on this server. Please check
10.71.0.155

(Lon migration

10.69.0.155)	VM name A0D8DE014XVM006 hostname is FRAMAGSPO0003


Summary: TSM: lon02ammtsm001 ANR2578W Schedule SYBLOG_LIN_0115 in domain DFL_P_SYBLOG for node MAG_FRAMAGSPO0003_SYBLOG has missed its scheduled start up window.~ Date: 02/23/18 11:15 CST Severity: Minor ResourceId: framagspo0003 TicketGroup: AMM-BUR CustomerCode: mng InstanceId: 2578 InstanceValue: ANR2578W Schedule SYBLOG_LIN_0115 in domain DFL_P_SYBLOG for nod ComponentType: ManagementInfrastructure Component: TSM Node: FRAMAGSPO0003 NodeAlias: 146.89.140.114 Manager: lon02ammtsm001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: TSM:TSM_SERVER:LON02AMMTSM001 AlertGroup: TSM_SERVER_EVENT EventKey: USRD0P0MSDP:3478414:mng

/usr/sap/CTS

[root@FRAMAGSPO0003 ibmrmalik]# cat /etc/fstab |grep /usr/sap/CTS
172.22.0.140:/usr/sap/CTS     /usr/sap/CTS nfs   defaults       0 0

mounted ip vm name A0D8DE014XVM007



1-334639221	sev3	10.148.24.132	root/Jtkh9qk4		Washington4	Ticket 55911783
Summary: Drive_with_Errors_on_wdc04hana-1024-20.xsportal.local[PROBLEM:938362] Date: Feb 17,2018 8:8 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_wdc04hana-1024-20.xsportal.local InstanceValue: Media Error Count = 4 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_wdc04hana-1024-2 Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_wdc04hana-1024-20.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3456926:amm




1-334582431	sev3
Summary: FS_is_read_only_on_snchmdada11.imzcloud.ibmammsap.local[PROBLEM:916990] Date: Feb 15,2018 16:27 CUT Severity: Minor ResourceId: snchmdada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE0 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchmdada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.104 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3452089:snc

[root@snchmdada11 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01 filesystems are read-only


/dev/mapper/sumvg-sumlv     /usr/sap/D1M/SUM     ext4      _netdev,defaults        1       2
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_ARCH_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0


/dev/mapper/sumvg-sumlv     /usr/sap/D1M/SUM     ext4      _netdev,defaults        1       2
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_ARCH_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0
file056:/SAP_DATA_nonprd01/SAP_LOAD_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0

[root@snchmdada11 ibmrmalik]# df -h |grep  /SHARE/MNT/FILE056*
                      197G  174G   24G  89% /SHARE/MNT/FILE056/SAP_DATA_nonprd01
                      197G  174G   24G  89% /SHARE/MNT/FILE056/SAP_ARCH_nonprd01
                      197G  174G   24G  89% /SHARE/MNT/FILE056/SAP_LOAD_nonprd01




1-334299621 chk clear event recd already
Summary: FS_is_read_only_on_snchecada11.imzcloud.ibmammsap.local[PROBLEM:833708] Date: Feb 8,2018 17:29 CUT Severity: Minor ResourceId: snchecada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/LFP/SAP_DATA/DR1 filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchecada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.99 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3427326:snc

[root@snchecada11 ibmrmalik]# df -k /SHARE/LFP/SAP_DATA/DR1
Filesystem           1K-blocks      Used Available Use% Mounted on
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01
                     206515200 181856992  24658208  89% /SHARE/MNT/FILE056/SAP_DATA_nonprd01



1-334519731   sev3
exact detailed storage usage for these 3 servers.


-----------------------------------------------------------------------------------------------------------------------------------

28 Feb

1-334639841	sev3	10.116.103.221	root/LY62WJvs	Singapore 1
Summary: Drive_with_Errors_on_sng01ammhana005.xsportal.local[PROBLEM:938367] Date: Feb 17,2018 8:9 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_sng01ammhana005.xsportal.local InstanceValue: 8:18 30 UBad - 558.406 GB SAS HDD N N 512B ST3600057SS D - ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_sng01ammhana005. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_sng01ammhana005.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3456931:amm





1-335030551	sev2
Summary: NTP_time_is_driffted_on_PEPDA00.imzcloud.ibmammsap.local[PROBLEM:1068223] Date: Feb 27,2018 18:55 CUT Severity: Major ResourceId: pepda00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.09 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: PEPDA00.imzcloud.ibmammsap.local NodeAlias: 10.13.1.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3488028:dlb

[root@DLBPEPDA00 ibmrmalik]# ntpstat
synchronised to unspecified at stratum 8
   time correct to within 2008 ms
   polling server every 1024 s
[root@DLBPEPDA00 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 che01ammadc001. 10.254.36.11     7 u  894 1024  377    0.542  -13872. 1028.57
 che01ammadc002. 10.254.36.11     7 u  912 1024  377    0.598  -14736. 709.111




1-335030521	sev2
Summary: NTP_time_is_driffted_on_DLBPEPDA00.imzcloud.ibmammsap.local[PROBLEM:1068207] Date: Feb 27,2018 18:52 CUT Severity: Major ResourceId: dlbpepda00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.04 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: DLBPEPDA00.imzcloud.ibmammsap.local NodeAlias: 10.13.1.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3488025:dlb




1-334741301	sev3	IBM AoD Business Systems
Summary: Free_disk_space_is_less_than_20%_on_volume_/var[PROBLEM:969045] Date: Feb 19,2018 21:0 CUT Severity: Minor ResourceId: ri3vw054 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-Template_OS_Linux:Free_disk_space_on_/var_(percentage) InstanceValue: 15.48 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_disk_space_on_/var_(percent Node: DAL09AMMVPN01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.60 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_disk_space_on_/var_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3465262:ibs



1-334582431	sev3
Summary: FS_is_read_only_on_snchmdada11.imzcloud.ibmammsap.local[PROBLEM:916990] Date: Feb 15,2018 16:27 CUT Severity: Minor ResourceId: snchmdada11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE0 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: snchmdada11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.104 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3452089:snc

[root@snchmdada11 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /SHARE/MNT/FILE056/SAP_ARCH_nonprd01 /SHARE/MNT/FILE056/SAP_LOAD_nonprd01 filesystems are read-only






1-334886131	sev3
DEV - AFRFIORIDEV/10.197.1.16 we have 8 GB of Swap and we need to have the Swap increased to 16 GB ( Another 8 GB should be added )
[root@AFRFIORIDEV ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g   2.50g
  fdvappvg    1  13   0 wz--n- 128.00g  26.00g
  fdvarchvg   1   1   0 wz--n-  64.00g  14.00g
  fdvdatavg   2   7   0 wz--n- 277.99g 122.99g
  fdvlogvg    1   4   0 wz--n-  32.00g      0

[root@AFRFIORIDEV ibmrmalik]# lvdisplay |grep lv_swap
  LV Path                /dev/VolGroup/lv_swap
  LV Name                lv_swap


QUAL - AFRFIORIQA/10.197.1.15  we have 8 GB of Swap and we need to have Swap increased to 32 ( Another 24 GB should be added )
[root@AFRFIORIQA ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g    2.50g
  fqaappvg    1  13   0 wz--n- 128.00g   24.00g
  fqaarchvg   1   1   0 wz--n-  64.00g   14.00g
  fqadatavg   1   7   0 wz--n- 128.00g 1020.00m
  fqalogvg    1   4   0 wz--n-  32.00g 1020.00m

[root@AFRFIORIQA ibmrmalik]# lvdisplay |grep  lv_swap
  LV Path                /dev/VolGroup/lv_swap
  LV Name                lv_swap


ROD -  AFRFIORIPRD/10.197.0.13 we have 8 GB of Swap and we need to have Swap increased to 32 ( Another 24 GB should be added )
[root@AFRFIORIPRD ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g  2.50g
  fpdappvg    1  13   0 wz--n- 128.00g 24.00g
  fpdarchvg   1   1   0 wz--n-  64.00g 14.00g
  fpddatavg   2   7   0 wz--n- 189.99g  2.99g
  fpdlogvg    3   4   0 wz--n-  61.49g 14.49g
[root@AFRFIORIPRD ibmrmalik]# lvdisplay |grep  lv_swap
  LV Path                /dev/VolGroup/lv_swap
  LV Name                lv_swap




Right now on S4HANA:

DEV - AFRS4HDEV/10.197.1.14 we have 8 GB of Swap and we need to have the Swap increased to 32 GB ( Another 24 GB should be added )
[root@AFRS4HDEV ibmrmalik]# vgs
  VG       #PV #LV #SN Attr   VSize   VFree
  VolGroup   1   7   0 wz--n-  39.51g  2.50g
  hdvappvg   1  13   0 wz--n- 128.00g 36.00g

[root@AFRS4HDEV ibmrmalik]# lvdisplay |grep  lv_swap
  LV Path                /dev/VolGroup/lv_swap
  LV Name                lv_swap


QUAL - AFRS4HQA /10.197.1.12  we have 8 GB of SWAP and we need to have Swap increased to 64 GB ( Another 56 GB should be added )
[root@AFRS4HQA ibmrmalik]# vgs
  VG       #PV #LV #SN Attr   VSize   VFree
  VolGroup   1   7   0 wz--n-  39.51g  2.40g
  hqaappvg   1  13   0 wz--n- 128.00g 24.00g



PROD - AFRSH4PRD / 10.197.0.12 we have 8 GB  of SWAP and we need to have Swap increased to 64 GB ( Another 56 GB should be added )
[root@AFRSH4PRD ibmrmalik]# vgs
  VG       #PV #LV #SN Attr   VSize   VFree
  VolGroup   1   7   0 wz--n-  39.51g  2.50g
  hpdappvg   1  13   0 wz--n- 128.00g 22.00g

[root@AFRSH4PRD ibmrmalik]# lvdisplay |grep  lv_swap
  LV Path                /dev/VolGroup/lv_swap
  LV Name                lv_swap



1-335039883	sev2	10.78.22.38	parhana-1024-18.xsportal.local	IPMI root/F8c5phk9pQ	
smdbdevdm1      10.78.22.38 , Backup of this server is missing & its not reachable. Please check.

[ibmrpradyumnan@par01ammtsm001 ~]$ ping 10.78.22.38
PING 10.78.22.38 (10.78.22.38) 56(84) bytes of data.
^C
--- 10.78.22.38 ping statistics ---
4 packets transmitted, 0 received, 100% packet loss, time 2999ms

[ibmrpradyumnan@par01ammtsm001 ~]$ date
Wed Feb 28 09:52:03 CET 2018
[ibmrpradyumnan@par01ammtsm001 ~]$





1-335040371	sev3	PBBs4hdap00
Add new Disk of 48 GB to  FS - /usr/sap/S4D of IP - 10.6.7.12

[root@PBBs4hdap00 ibmrmalik]# df -k /usr/sap/S4D
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/s4dappvg-s4dusrS4D_lv
                      24770940 22766668    745984  97% /usr/sap/S4D


[root@PBBs4hdap00 ibmrmalik]# vgs s4dappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  s4dappvg   1  13   0 wz--n- 128.00g 22.00g

lvextend -r -L +48G /dev/mapper/s4dappvg-s4dusrS4D_lv


------------------------------------------------------------------------------------------------------------------------


1st March


1-335053071  sev2

Summary: Lack_of_free_swap_space_on_MG2ERPDEVCAPP.imzcloud.ibmammsap.local[PROBLEM:1077242] Date: Feb 28,2018 12:42 CUT Severity: Major ResourceId: mg2erpdevcapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mg2 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.6 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: MG2ERPDEVCAPP.imzcloud.ibmammsap.local NodeAlias: 10.198.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3489873:mg2


[root@MG2ERPDEVCAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11          9          1          5          0          5
-/+ buffers/cache:          4          7
Swap:            7          3          4




1-334781251	sev2	Zabbix agent running fine
Summary: Zabbix_agent_on_DAL09AMMTS001_is_unavailable[PROBLEM:978406] Date: Feb 20,2018 16:13 CUT Severity: Major ResourceId: ri3lr019 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Agent_availability Node: DAL09AMMTS001 NodeAlias: 146.89.140.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467645:mic



1-334935341	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/S4D[PROBLEM:1032532] Date: Feb 24,2018 17:38 CUT Severity: Critical ResourceId: tqaerpdev TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/S4D InstanceValue: 3.56 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQAERPDEV.imzcloud.ibmammsap.local NodeAlias: 10.7.1.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/S4D AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3480770:tqa
/dev/mapper/s4dappvg-s4dusrS4D_lv
                      24770940 21027512   2485140  90% /usr/sap/S4D

[root@TQAERPDEV S4D]# find . -xdev -type f -size +1000000
./SUM/abap/system/S4D/D02/work/core.88991
./SUM/abap/log/SAPK-757A2INBICONT.S4D
./SUM/abap/log/SAPI-75101INSAPUI.S4D
./SUM/abap/data/R-75101INSAPUI.SAP.reduced
./SUM/abap/data/R-75101INSAPUI.SAP

[root@TQAERPDEV abap]# du -mch --max-depth=1 .
1.4G    ./system
6.7G    ./log
8.2G    ./data
18G     .
18G     total
[root@TQAERPDEV abap]# pwd
/usr/sap/S4D/SUM/abap

[root@TQAERPDEV ibmrmalik]# cd  /usr/sap/S4D
[root@TQAERPDEV S4D]# du -mch --max-depth=1 .
253M    ./ASCS01
24K     ./SYS
1.4G    ./D20
16K     ./lost+found
664M    ./hdbclient
18G     ./SUM
20G     .
20G     total
[root@TQAERPDEV S4D]# cd SUM/
[root@TQAERPDEV SUM]# du -mch --max-depth=1 .
290M    ./sdt
18G     ./abap
96M     ./jvm
6.1M    ./sapcrypto
18G     .
18G     total




[root@TQAERPDEV ibmrmalik]# df -k /usr/sap/S4D
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/s4dappvg-s4dusrS4D_lv
                      24770940 21138520   2374132  90% /usr/sap/S4D








1-334837951    IBM AoD Business Systems   Sev1	Zabbix agent running fine
Summary: Free_disk_space_is_less_than_5%_on_volume_C:[PROBLEM:998898] Date: Feb 21,2018 21:33 CUT Severity: Critical ResourceId: ri3pa046 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 4.57 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: AMMDAL09VCS001 NodeAlias: 146.89.140.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3472697:ibs




1-334893491    IBM MSD Infras - Cloud MONITORING   Sev1		Zabbix agent running fine
Summary: Free_disk_space_is_less_than_5%_on_volume_C:[PROBLEM:1018391] Date: Feb 23,2018 11:37 CUT Severity: Critical ResourceId: ri3lr019 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 4.99 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: DAL09AMMTS001 NodeAlias: 146.89.140.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3477703:mic





1-335075741		sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/db2/DI1/log_dir[PROBLEM:1085127] Date: Mar 1,2018 2:31 CUT Severity: Critical ResourceId: aplbcsdi1 TicketGroup: ApsSAPTechnical CustomerCode: ap5 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/db2/DI1/log_dir InstanceValue: 2.87 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: APLBCSDI1.imzcloud.ibmammsap.local NodeAlias: 170.225.68.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/db2/DI1/log_dir AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3491708:ap5


[root@APLBCSDI1 ibmrmalik]# df -k /db2/DI1/log_dir
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/di1logvg-di1db2logdirlv
                      25803068 23788608    703740  98% /db2/DI1/log_dir
only 2GB is available on VG
please add 2GB

[root@APLBCSDI1 ibmrmalik]# vgs di1logvg
  VG       #PV #LV #SN Attr   VSize  VFree
  di1logvg   1   4   0 wz--n- 32.00g 2.00g

lvextend -L +1900M /dev/mapper/di1logvg-di1db2logdirlv

resize2fs /dev/mapper/di1logvg-di1db2logdirlv

Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/di1logvg-di1db2logdirlv
                      27717828 23788608   2521244  91% /db2/DI1/log_dir



1-334783341	sev2   ntp restarted awaiting clear event   
Summary: NTP_time_is_driffted_on_SC8SANWDD21.imzcloud.ibmammsap.local[PROBLEM:978838] Date: Feb 20,2018 17:0 CUT Severity: Major ResourceId: sc8sanwdd21 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: zdd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.9 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: SC8SANWDD21.imzcloud.ibmammsap.local NodeAlias: 10.15.31.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467736:zdd




1-334786581	sev2	SNG
Summary: NTP_time_is_driffted_on_SSGSA0121.imzcloud.ibmammsap.local[PROBLEM:978867] Date: Feb 20,2018 17:1 CUT Severity: Major ResourceId: ssgsa0121 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mmd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.92 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: SSGSA0121.imzcloud.ibmammsap.local NodeAlias: 100.126.0.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467739:mmd

/dev/mapper/mmpdatavg-mmpsapdata1_lv
                      23738812 22533068         0 100% /sybase/MMP/sapdata1
/dev/mapper/mmpdatavg-mmpsapdata2_lv
                      23738812 22533068         0 100% /sybase/MMP/sapdata2
/dev/mapper/mmpdatavg-mmpsapdata3_lv
                      23738812 22533092         0 100% /sybase/MMP/sapdata3
/dev/mapper/mmpdatavg-mmpsapdata4_lv
                      23738812 22533068         0 100% /sybase/MMP/sapdata4

[root@SSGSA0121 ibmrmalik]# vgs |grep mmpdatavg
  mmpdatavg   1   7   0 wz--n- 128.00g 1020.00m


[root@SSGSA0121 ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g 1020.00m
  mmpappvg    2  13   0 wz--n- 191.99g   22.99g
  mmparchvg   1   1   0 wz--n-  64.00g    4.00g
  mmpdatavg   1   7   0 wz--n- 128.00g 1020.00m
  mmplogvg    1   4   0 wz--n-  32.00g  200.00m

[root@SSGSA0121 ibmrmalik]# lsblk |grep disk
sda                                  8:0    0   40G  0 disk
sdb                                  8:16   0  300G  0 disk
sdc                                  8:32   0  128G  0 disk
sdf                                  8:80   0   64G  0 disk
sdd                                  8:48   0  128G  0 disk
sdg                                  8:96   0   32G  0 disk
sde                                  8:64   0   64G  0 disk

vgextend mmpdatavg /dev/sdb

lvextend -L +50G /dev/mapper/mmpdatavg-mmpsapdata1_lv
resize2fs /dev/mapper/mmpdatavg-mmpsapdata1_lv


lvextend -L +50G /dev/mapper/mmpdatavg-mmpsapdata2_lv
resize2fs /dev/mapper/mmpdatavg-mmpsapdata2_lv


lvextend -L +50G /dev/mapper/mmpdatavg-mmpsapdata3_lv

lvextend -L +50G /dev/mapper/mmpdatavg-mmpsapdata4_lv


[root@SSGSA0121 ibmrmalik]# df -hT |grep /sybase/MMP/sapdata
                     ext3    72G   22G   47G  32% /sybase/MMP/sapdata1
                     ext3    72G   22G   47G  32% /sybase/MMP/sapdata2
                     ext3    72G   22G   47G  32% /sybase/MMP/sapdata3
                     ext3    72G   22G   47G  32% /sybase/MMP/sapdata4





1-335075151   - /db2/DI1     - di1datavg   1   9   0 wz--n- 500.00g  75.00g		DONE
need to add 1GB of space..that i s enough for this FS
please add 1GB 
Summary: Free_disk_space_is_less_than_5%_on_volume_/db2/DI1[PROBLEM:1085196] Date: Mar 1,2018 2:37 CUT Severity: Critical ResourceId: aplbcsdi1 TicketGroup: ApsSAPTechnical CustomerCode: ap5 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/db2/DI1 InstanceValue: 3.97 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: APLBCSDI1.imzcloud.ibmammsap.local NodeAlias: 170.225.68.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/db2/DI1 AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3491722:ap5

[root@APLBCSDI1 ibmrmalik]# df -k /db2/DI1
Filesystem           1K-blocks   Used Available Use% Mounted on
/dev/mapper/di1datavg-di1db2_lv
                       1032088 940576     39084  97% /db2/DI1


[root@APLBCSDI1 ibmrmalik]# vgs di1datavg
  VG        #PV #LV #SN Attr   VSize   VFree
  di1datavg   1   9   0 wz--n- 500.00g 75.00g


lvextend -L +70G /dev/mapper/di1datavg-di1db2_lv

resize2fs /dev/mapper/di1datavg-di1db2_lv







1-334788331		sev2		ntp restarted
Summary: NTP_time_is_driffted_on_ctuwdpnpap01.imzcloud.ibmammsap.local[PROBLEM:981020] Date: Feb 20,2018 17:26 CUT Severity: Major ResourceId: ctuwdpnpap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.99 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: ctuwdpnpap01.imzcloud.ibmammsap.local NodeAlias: 10.12.12.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468403:ctu





1-335087391	sev1
Summary: Zabbix_agent_on_R3QATapp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1088947] Date: Mar 1,2018 8:26 CUT Severity: Critical ResourceId: r3qatapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: R3QATapp.imzcloud.ibmammsap.local NodeAlias: 10.74.6.43 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492411:mtb

------------------------------------------------------------------------------------------------------------------------------------------------------------

5 March


1-335208421    sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/hana/data[PROBLEM:1130596] Date: Mar 4,2018 20:33 CUT Severity: Critical ResourceId: bi1crmdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 4.76 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1CRMDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3502267:bi1

[root@BI1CRMDBQAS01 ibmrmalik]# df -k /hana/data
Filesystem                          1K-blocks      Used Available Use% Mounted on
/dev/mapper/vghanadata-lv_hana_data 809099264 766598116  42501148  95% /hana/data

[root@BI1CRMDBQAS01 data]# du -mch --max-depth=1 .
11G     ./51051151
94G     ./new
127G    ./mnt00001
126G    ./back1001
376G    ./WholeBackup
732G    .
732G    total
[root@BI1CRMDBQAS01 data]# pwd
/hana/data




1-334788331	sev2
Summary: NTP_time_is_driffted_on_ctuwdpnpap01.imzcloud.ibmammsap.local[PROBLEM:981020] Date: Feb 20,2018 17:26 CUT Severity: Major ResourceId: ctuwdpnpap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.99 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: ctuwdpnpap01.imzcloud.ibmammsap.local NodeAlias: 10.12.12.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468403:ctu

[root@ctuwdpnpap01 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
*wdc04ammadc001. 10.254.32.10     7 u 1042 1024  377    0.745    7.987   9.950
+wdc04ammadc002. 10.254.32.11     7 u  779 1024  377    0.754  -11.346  23.346
[root@ctuwdpnpap01 ibmrmalik]# ntpstat
synchronised to NTP server (146.89.142.12) at stratum 8
   time correct to within 619 ms
   polling server every 1024 s





1-334998401	sev2
Short Description:Hybris Commerce Dev Server is donw. Unab


Customer: Cerebos Pacific Limited
Reported by: Magesh K Ramamoorthy
Phone:+65 6212 0100
E-Mail:	
magesh.kumar@sai-digital.com
Priority:2: High
SAP Incident Number:0105198/2018


Description:

Reconstruction
02/27/2018   04:38:50   S0017410223

Ping 10.60.1.142
 
or
 
Try logging into the server via SSH
____________________
Business Consequences
02/27/2018   04:38:49   S0017410223

Without Dev servers development and build process are impacted causing
urgent production fixed to be delayed.
____________________
Description
02/27/2018   04:38:48   S0017410223		10.70.1.142  RHEL    DPE kautsar@my.ibm.com

server was  in maintenance mode  after  recent  MCO,so had to fsck on it . Server  is up and running now

we are not able to root into the Dev servers VM/Host/IP below 
 A0DIML014XVM002/eCDEVWebApp/10.60.1.142 please check if the host is
up PLease refer screenshot for error   My teams POC : Arun - +91
9566186870 skype: arunkumar_sivaraman

[root@SNG01AMMCHEF01 ~]# ssh 10.70.1.142
ssh: connect to host 10.70.1.142 port 22: No route to host




1-335196341   sev1	done
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1125439] Date: Mar 4,2018 9:46 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3501013:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      26437900 12890444  12197824  52% /




1-334786531	sev2	restarted NTP awaiting clear event
Summary: NTP_time_is_driffted_on_SC8SANFID20.imzcloud.ibmammsap.local[PROBLEM:978831] Date: Feb 20,2018 16:59 CUT Severity: Major ResourceId: sc8sanfid20 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: zdd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -122.94 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: SC8SANFID20.imzcloud.ibmammsap.local NodeAlias: 10.15.31.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3467733:zdd




1-335212763   sev3	DONE
 se
List of servers below:
spsvopitsql01	10.6.3.34	10.70.111.34	OpenText : DB	Win2012R2		System Boot Time:          2/19/2018, 3:32:51 PM
spsvopltapp01	10.6.3.35	10.70.111.35	OpenText : Apps	Win2012R2		System Boot Time:          2/19/2018, 3:32:52 PM
spsvcpivsql01	10.6.3.36	10.70.111.36	Primary DNS	Win2012R2		System Boot Time:          11/18/2017, 2:09:17 PM
spsvcpivsql01	10.6.3.37	10.70.111.37	Secondary DNS and SMTP Relay Win2012R2	System Boot Time:          11/18/2017, 2:07:10 PM
spsvhpigsql01	10.6.3.38	10.70.111.38	Hybris DB	Win2012R2		System Boot Time:          11/17/2017, 9:59:02 PM
spsvwplwapp11	10.6.3.39	10.70.111.39	Hybris Web Server	Win2012R2	System Boot Time:          11/18/2017, 2:31:02 PM
spsvwplwapp12	10.6.3.40	10.70.111.40	Hybris Web Server	Win2012R2	System Boot Time:          11/18/2017, 2:31:34 PM
spsvcpicapp11	10.6.3.41	10.70.111.41	Hybris Commerce App	Win2012R2	System Boot Time:          11/18/2017, 2:22:51 PM
spsvcpicapp12	10.6.3.42	10.70.111.42	Hybris Commerce App	Win2012R2	System Boot Time:          2/19/2018, 3:33:45 PM
spsvdpidapp01	10.6.3.43	10.70.111.43	Hybris Bank Office	Win2012R2	System Boot Time:          2/19/2018, 3:33:32 PM
spsvtplnapp01	10.6.3.44	10.70.111.44	Tomatosx Runtime	Win2012R2	System Boot Time:          2/19/2018, 3:32:37 PM
spsvmplmase01	10.6.3.45	10.70.111.45	MSG.PM Designer	Win2012R2		System Boot Time:          2/19/2018, 3:33:37 PM
spsvmplmapp01	10.6.3.46	10.70.111.46	MSG.PM Designer	RHEL			System Boot Time:          2/19/2018, 06:49:47 PM
cccp1srv0	10.6.3.47	10.70.111.47	Win2k12					System Boot Time:          8/6/2017, 4:32:33 PM

sar -f /var/log/sa/sa19 -r |grep -i restart 
sa19  = sar report  of  19 th Feb

CPU Utilization % ->  run sar -u 1 7





dal09ammsol01.imzcloud.ibmammsap.local
IPMI pw  root/J7RgAQTjXU	10.120.28.125







1-335212953 Raised for HANA System Host details 
3 systems details are required : Allocated, CPU's, RAM & DISK 

Hi team 

Please share number of CPUs, DISK allocation & RAM Allocaiton of below hosts.
svcd1hdbsrv01	10.6.1.15
Mem:   126.034G total,  124.692G used, 1374.258M free,  356.262M buffers
Swap:   50.000G total,  325.160M used,   49.682G free,   29.020G cached

CPU 30

[root@svcd1hdbsrv01 ibmrmalik]# lsblk
NAME                                 MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0                                   11:0    1 1024M  0 rom
sda                                    8:0    0  100G  0 disk
Ã¢Ã¢sda1                                 8:1    0  200M  0 part /boot
Ã¢Ã¢sda2                                 8:2    0   50G  0 part [SWAP]
Ã¢Ã¢sda3                                 8:3    0 49.8G  0 part /
sdb                                    8:16   0   10G  0 disk
Ã¢Ã¢toolsvg-monitoring_lv (dm-3)       253:3    0    5G  0 lvm  /opt/monitor/IBM
sdc                                    8:32   0  283G  0 disk
Ã¢Ã¢sdc1                                 8:33   0  283G  0 part
  Ã¢Ã¢vghanadata-lv_hana_data (dm-0)   253:0    0  384G  0 lvm  /hana/data
  Ã¢Ã¢vghanadata-lv_usr_sap (dm-1)     253:1    0   50G  0 lvm  /usr/sap
  Ã¢Ã¢vghanadata-lv_hana_shared (dm-2) 253:2    0  128G  0 lvm  /hana/shared
sde                                    8:64   0  130G  0 disk
Ã¢Ã¢sde1                                 8:65   0  130G  0 part /hana/log
sdd                                    8:48   0  284G  0 disk
Ã¢Ã¢sdd1                                 8:49   0  284G  0 part
  Ã¢Ã¢vghanadata-lv_hana_data (dm-0)   253:0    0  384G  0 lvm  /hana/data
  Ã¢Ã¢vghanadata-lv_usr_sap (dm-1)     253:1    0   50G  0 lvm  /usr/sap
  Ã¢Ã¢vghanadata-lv_hana_shared (dm-2) 253:2    0  128G  0 lvm  /hana/shared



svcq1hdbsrv01	10.6.2.15	A0EASG014XVM106
spsvcpdchdb01	10.6.3.14	A0EASG014XVM107







1-334790551	sev2	rng clear eventestarted NTP awaiti
Summary: NTP_time_is_driffted_on_CTUBOSR1AP01.imzcloud.ibmammsap.local[PROBLEM:980878] Date: Feb 20,2018 17:24 CUT Severity: Major ResourceId: ctubosr1ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.93 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CTUBOSR1AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468338:ctu







1-335220061	sev3
Summary: Processor_load_is_too_high_on_SNG01AMMADC001[PROBLEM:1134893] Date: Mar 5,2018 6:53 CUT Severity: Minor ResourceId: sng01ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 5.033333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SNG01AMMADC001 NodeAlias: 146.89.140.140 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3503151:amm



1-334790661	sev2
Summary: NTP_time_is_driffted_on_BI1ERPDBDEV01.imzcloud.ibmammsap.local[PROBLEM:980795] Date: Feb 20,2018 17:23 CUT Severity: Major ResourceId: bi1erpdbdev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: bi1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -254.06 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: BI1ERPDBDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468292:bi1





1-335091081
*** Details of Generic Service Request - DO NOT CHANGE ***

Hello,

Please take the following actions to be performed for this request:

1/ Copy [ONP] DQ1:/usr/sap/trans/ only subfolder ( log, buffer, data, cofiles ) to [BLX] DQ1:/ usr/sap/trans/ - PLEASE SHARE THE LOCATION TO TRANSFER THE FILES FROM ONPREMISE SYSTEM.

2/ Archive [BLX] UQ3:/usr/sap/trans/ (to save logs and some files if required in future)

3/ Copy [BLX] UQ3:/usr/sap/trans/ only subfolder (buffer/UQ3 ) to [BLX] DQ1:/ usr/sap/trans/

4/ Mount [BLX] UQ3:/usr/sap/trans/bin/TP_DOMAIN_UQ3.PFL on [BLX] DQ1:/ usr/sap/trans/

5/ Repeat step 2 to 3 for [BLX]TQ1 if required.

Note:

[ONP] : system on premise

[BLX] : system on Bluemix

Due date: 5th of March, 2018.

Behalf of  3000024174, Copy usr/sap/trans DQ1 ONP to DQ1 BLX
-----------------------------------------------------------------------------------------------------------------------------------------------


6 Mar


1-335252371	sev1	A0D8DE014XVM006
Summary: MSD:URL: URL Status: Timeout occurred while obtaining URL status Date: 03/05/2018 Severity: Critical ResourceId: framagspo0003 TicketGroup: ApsSAPTechnical CustomerCode: mng InstanceId: Timeout occurred while obtaining URL status[http://FRAMAGSPO0003:50000] InstanceValue: http://FRAMAGSPO0003:50000 InstanceSituation: URL Status - Generic URL ComponentType: Application Component: URL SubComponent: URL ApplId: URL Node: FRAMAGSPO0003 NodeAlias: FRAMAGSPO0003 Manager: FRAMAGSPO0003 Agent: EIF Probe on ri3pa010 AlertKey: hec_urldown_gumf_msa_nprd AlertGroup: ITM_INTERNETMANAGED_URL00 EventKey: USRD0P0MSDP:3505448:mng

10.71.0.155

(Lon migration

10.69.0.155)





1-335257881	sev1
Summary: MSD:URL: URL Status: URI authority not found Date: 03/05/2018 Severity: Critical ResourceId: framagspo0003 TicketGroup: ApsSAPTechnical CustomerCode: mng InstanceId: URI authority not found[http://FRAMAGSPO0003:50000/dir] InstanceValue: http://FRAMAGSPO0003:50000/dir InstanceSituation: URL Status - Generic URL ComponentType: Application Component: URL SubComponent: URL ApplId: URL Node: FRAMAGSPO0003 NodeAlias: FRAMAGSPO0003 Manager: FRAMAGSPO0003 Agent: EIF Probe on ri3pa010 AlertKey: hec_urldown_gumf_msa_nprd AlertGroup: ITM_INTERNETMANAGED_URL00 EventKey: USRD0P0MSDP:3505894:mng





1-335258701	sev1
Summary: Dataserver_process_is_not_running[PROBLEM:1145429] Date: Mar 6,2018 1:55 CUT Severity: Critical ResourceId: framagspo0003 TicketGroup: ApsSAPTechnical CustomerCode: mng InstanceId: Zabbix-AMM_Sybase_Linux:Sybase_Dataserver ComponentType: ZABBIX Component: AMM_Sybase_Linux SubComponent: Sybase_Dataserver Node: FRAMAGSPO0003.imzcloud.ibmammsap.local NodeAlias: 10.69.0.155 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_Sybase_Linux:Sybase_Dataserver AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3505887:mng





1-335254651   sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1143939] Date: Mar 5,2018 23:1 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3505519:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      26437900 12903516  12184752  52% /




1-334790731    sev2
Summary: NTP_time_is_driffted_on_CTUBWSB3AP01.imzcloud.ibmammsap.local[PROBLEM:980604] Date: Feb 20,2018 17:20 CUT Severity: Major ResourceId: ctubwsb3ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -253.67 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CTUBWSB3AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3468181:ctu

[root@CTUBWSB3AP01 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
*wdc04ammadc001. 10.254.32.10     7 u    1   64    1    0.606  -16.571   0.105
 wdc04ammadc002. 10.254.32.11     7 u    -   64    1    0.633  -17.812   0.391
[root@CTUBWSB3AP01 ibmrmalik]# ntpstat
synchronised to NTP server (146.89.142.12) at stratum 8
   time correct to within 721 ms
   polling server every 64 s





1-334854541	sev3	Honk Kong	10.110.7.122	root/Jk7bsDg8		SL ticket 56304917
Summary: Drive_with_Errors_on_honhana-1024-7.xsportal.local[PROBLEM:1004057] Date: Feb 22,2018 8:9 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_honhana-1024-7.xsportal.local InstanceValue: Status = Failure ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_honhana-1024-7.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_honhana-1024-7.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3474104:amm




1-335255181   sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_C:[PROBLEM:1144779] Date: Mar 6,2018 0:33 CUT Severity: Major ResourceId: ri3lr020 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 9.53 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: DAL09AMMTS002 NodeAlias: 146.89.140.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3505719:mic



1-334964991	sev2
Summary: Lack_of_free_swap_space_on_SK3SLTPRD01.imzcloud.ibmammsap.local[PROBLEM:1047754] Date: Feb 26,2018 2:12 CUT Severity: Major ResourceId: sk3sltprd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3SLTPRD01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.34 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3483752:sk3

top - 06:02:42 up 179 days, 13:50,  1 user,  load average: 6.74, 6.28, 5.68
Tasks: 360 total,   2 running, 358 sleeping,   0 stopped,   0 zombie
Cpu(s): 14.6%us, 10.0%sy,  0.0%ni, 39.2%id, 35.7%wa,  0.0%hi,  0.4%si,  0.0%st
Mem:    31.350G total,   29.944G used, 1439.715M free, 1584.000k buffers
Swap:   48.000G total,   29.939G used,   18.061G free,  821.465M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
25319 slpadm    20   0 43.2g 8.8g  22m D  0.3 28.0  11814:35 4.6g SLP_00_BTC_W39
51079 slpadm    20   0 1507m  11m 1124 S  0.0  0.0   3640:00 789m en.sapSLP_ASCS0
11137 slpadm    20   0 34.7g 4.4g 109m D  6.3 14.1   3346:48 511m SLP_00_BTC_W49
38172 slpadm    20   0 37.9g 7.8g  63m D  0.3 24.9   6040:00 331m SLP_00_BTC_W44
58431 daaadm    20   0 5193m 211m 5840 S  0.0  0.7 507:34.87 281m jstart
53677 slpadm    20   0 30.1g 358m 321m S  0.0  1.1  99:11.13 227m SLP_00_DIA_W29
53649 slpadm    20   0 30.0g 348m 323m S  0.0  1.1  32:50.51 226m SLP_00_DIA_W1
53676 slpadm    20   0 30.1g 378m 328m S  0.0  1.2  90:47.67 224m SLP_00_DIA_W28
53661 slpadm    20   0 30.1g 338m 317m S  0.0  1.1  47:37.61 222m SLP_00_DIA_W13
53668 slpadm    20   0 30.1g 367m 326m S  0.0  1.1  92:14.29 219m SLP_00_DIA_W20
53669 slpadm    20   0 30.1g 351m 326m S  0.0  1.1  81:47.34 216m SLP_00_DIA_W21


[root@SK3SLTPRD01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         29          1          0          0          0
-/+ buffers/cache:         28          2
Swap:           47         30         17







1-335247401	sev3
Request to provide Storage space available ( Free space and used space on all Servers for MMD IC4SAP-SL ( Windows & Linux)






1-335178341	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1115436] Date: Mar 3,2018 11:56 CUT Severity: Minor ResourceId: ci3s4hanaprda TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 16.31 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CI3S4HANAPRDA.imzcloud.ibmammsap.local NodeAlias: 10.210.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3499143:ci3



[root@CI3S4HANAPRDA sources]# du -mch --max-depth=1 .
8.0M    ./sapdownload
4.0K    ./share
17M     ./saprouter
100G    ./Export21022018_PRD
112M    ./kernel
18M     ./UpdateR3
14G     ./sources
16K     ./lost+found
2.1M    ./downloadmanager
7.3G    ./51047708
7.5M    ./olddownload
121G    .
121G    total


[root@CI3S4HANAPRDA usr]# du -mch --max-depth=1 .
1.3G    ./share
23M     ./include
519M    ./lib
16G     ./sap
234M    ./bin
896M    ./lib64
51M     ./src
4.0K    ./etc
65M     ./libexec
40M     ./sbin
160K    ./local
4.0K    ./games
19G     .
19G     total
[root@CI3S4HANAPRDA usr]# pwd
/usr






1-334786581	2/20/2018 9:01	2-Urgent	MSD_TEC	AMM-DELIVERY-TECH	NTP_time_is_driffted_on_SSGSA0121	"Team connected via chef and  found the datavg is 100% occupied.
Added 50 gb each sapdata1,2,3,4 which makes a total of  200 gb in total. Ravi malik to confirm if he is able to connect."	Ravi Malik	2-Mar-18	In Progress
100.126.0.15

[root@SSGSA0121 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
*sng01ammadc001. 146.89.140.139   7 u  778 1024  377    0.546  -47.046  23.106
+sng01ammadc002. 146.89.140.138   7 u  530 1024  377    0.567   -7.669  27.204
[root@SSGSA0121 ibmrmalik]# ntpstat
synchronised to NTP server (146.89.140.140) at stratum 8
   time correct to within 708 ms
   polling server every 1024 s





1-335023321	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/trans[PROBLEM:1066940] Date: Feb 27,2018 16:27 CUT Severity: Critical ResourceId: tqaerpqa TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans InstanceValue: 4.55 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQAERPQA.imzcloud.ibmammsap.local NodeAlias: 10.7.1.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3487723:tqa

[root@TQAERPQA ibmrmalik]# df -k /usr/sap/trans
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/s4qappvg-usrtrans_lv
                      41284928 11330724  27857052  29% /usr/sap/trans





1-335091421	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1090347] Date: Mar 1,2018 11:0 CUT Severity: Minor ResourceId: daltfsdsd0001 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: toy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DALTFSDSD0001.imzcloud.ibmammsap.local NodeAlias: 10.4.1.183 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492759:toy

[root@DALTFSDSD0001 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      26437900 20121240   4967028  81% /

326G    ./sybase
46G     ./usr
1.9G    ./opt
377G    .
377G    total


[root@DALTFSDSD0001 data]# du -mch --max-depth=1 .
322G    .
322G    total
[root@DALTFSDSD0001 data]# pwd
/sybase/data




1-335199841	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var[PROBLEM:1126043] Date: Mar 4,2018 11:6 CUT Severity: Major ResourceId: dlbdwdap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 10 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLBDWDAP00.imzcloud.ibmammsap.local NodeAlias: 10.13.2.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3501276:dlb



--------------------------------------------------------------------------------------------------

7 March



1-335295241	sev1	Ageas	10.6.2.12	A0EASG014XVM004	SNG
Summary: MSD:URL: URL Status: 500: unspecified server error Date: 03/06/2018 Severity: Critical ResourceId: svjq1srv0 TicketGroup: ApsSAPTechnical CustomerCode: age InstanceId: 500: unspecified server error[http://svjq1srv0:50000] InstanceValue: http://svjq1srv0:50000 InstanceSituation: URL Status - Generic URL ComponentType: Application Component: URL SubComponent: URL ApplId: URL Node: svjq1srv0 NodeAlias: svjq1srv0 Manager: svjq1srv0 Agent: EIF Probe on ri3pa010 AlertKey: hec_urldown_gumf_msa_nprd AlertGroup: ITM_INTERNETMANAGED_URL00 EventKey: USRD0P0MSDP:3508761:age

[root@svjq1srv0 ibmrmalik]# uptime
 09:10:25 up 15 days, 14:31,  2 users,  load average: 0.00, 0.00, 0.00

[root@svjq1srv0 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         11          4          0          1          3
-/+ buffers/cache:          6          9
Swap:           13          0         13





*1-335266991  -  1  -  CONTROLADORA DE NEGOCIOS   sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/db/db2inst2/db2data[PROBLEM:1148100] Date: M
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/db/db2inst2/db2data[PROBLEM:1148100] Date: Mar 6,2018 7:8 CUT Severity: Critical ResourceId: crosfliem01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data InstanceValue: 3.63 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: crosfliem01.imzcloud.ibmammsap.local NodeAlias: 10.68.210.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3506615:cng

[root@crosfliem01 ibmrmalik]# df -k /db/db2inst2/db2data
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/vg_db2inst2-lv_db_db2inst2_db2data
                      10190136 3303340   6362508  35% /db/db2inst2/db2data



*1-335271751  -  1  -  St Jude Medical  Dallas - SAP HEC	JUDHDMART02T
Summary: Zabbix_agent_on_JUDHDMART02T.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1149337] Date: Mar 6,2018 9:14 CUT Severity: Critical ResourceId: judhdmart02t TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: JUDHDMART02T.imzcloud.ibmammsap.local NodeAlias: 10.196.4.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3506859:jud

[root@judhdmart02 ibmrmalik]# uptime
 01:55:10 up 13:17,  1 user,  load average: 0.09, 0.19, 0.25
[root@judhdmart02 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  5779) is running...




 sev1
1-335293431	sev 1
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/S4P[PROBLEM:1155495] Date: Mar 6,2018 19:45 CUT Severity: Critical ResourceId: tqaerpprd1 TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/S4P InstanceValue: 3.52 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQAERPPRD1.imzcloud.ibmammsap.local NodeAlias: 10.7.1.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/S4P AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3508312:tqa

[root@TQAERPPRD1 ibmrmalik]# df -k /usr/sap/S4P
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/s4pappvg-s4pusrS4P_lv
                      24770940 23158624    354028  99% /usr/sap/S4P


[root@TQAERPPRD1 S4P]# du -mch --max-depth=1 .
24K     ./SYS
1.2G    ./D00
243M    ./ASCS01
664M    ./hdbclient
15G     ./soft1
16K     ./lost+found
5.7G    ./PATCHES
22G     .
22G     total

[root@TQAERPPRD1 soft1]# du -mch --max-depth=1 .
15G     ./Export
15G     .
15G     total




1-335302731 	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/S4P[PROBLEM:1155495] Date: Mar 6,2018 19:45 CUT Severity: Critical ResourceId: tqaerpprd1 TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/S4P InstanceValue: 3.52 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQAERPPRD1.imzcloud.ibmammsap.local NodeAlias: 10.7.1.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/S4P AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3508312:tqa

[root@TQAERPPRD1 ibmrmalik]# df -k /usr/sap/S4P
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/s4pappvg-s4pusrS4P_lv
                      24770940 23147552    365100  99% /usr/sap/S4P




1-334639841	sev3	10.116.103.221	root/LY62WJvs	Singapore 1	SL ticket 56368533
Summary: Drive_with_Errors_on_sng01ammhana005.xsportal.local[PROBLEM:938367] Date: Feb 17,2018 8:9 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_sng01ammhana005.xsportal.local InstanceValue: 8:18 30 UBad - 558.406 GB SAS HDD N N 512B ST3600057SS D - ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_sng01ammhana005. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_sng01ammhana005.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3456931:amm

ID: 54294607
Type: Unplanned Event
Subject: SNG01 Network Disruption
Start Date: 20-Jan-2018 16:46 UTC (Jan 20, 2018 10:16PM IST)



1-335311921	sev1	A0EASG014XVM107		10.6.2.16
Summary: MSD:URL: URL Status: 500: unspecified server error Date: 03/07/2018 Severity: Critical ResourceId: svcq1srv0 TicketGroup: ApsSAPTechnical CustomerCode: age InstanceId: 500: unspecified server error[http://svcq1srv0:50500] InstanceValue: http://svcq1srv0:50500 InstanceSituation: URL Status - Generic URL ComponentType: Application Component: URL SubComponent: URL ApplId: URL Node: svcq1srv0 NodeAlias: svcq1srv0 Manager: svcq1srv0 Agent: EIF Probe on ri3pa010 AlertKey: hec_urldown_gumf_msa_nprd AlertGroup: ITM_INTERNETMANAGED_URL00 EventKey: USRD0P0MSDP:3510236:age

[root@svcq1srv0 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          1          1          4
-/+ buffers/cache:          9          6
Swap:           13          0         13
[root@svcq1srv0 ibmrmalik]# uptime
 17:09:10 up 15 days, 18:38,  2 users,  load average: 0.15, 0.03, 0.01




1-335266941	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/PFE[PROBLEM:1148040] Date: Mar 6,2018 7:3 CUT Severity: Minor ResourceId: dcgpfeapp10 TicketGroup: ApsSAPTechnical CustomerCode: cpw InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/PFE InstanceValue: 19.19 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: DCGPFEAPP10.imzcloud.ibmammsap.local NodeAlias: 10.197.5.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/PFE AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3506601:cpw

[root@DCGPFEAPP10 ibmrmalik]# df -k /usr/sap/PFE
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pfeappvg-pfeusrPFE_lv
                      24770940 22824476    688176  98% /usr/sap/PFE



[root@DCGPFEAPP10 PFE]# du -mch --max-depth=1 .
16K     ./lost+found
1.6G    ./D20
24K     ./SYS
1.2G    ./ASCS21
19G     ./SUM
22G     .
22G     total


[root@DCGPFEAPP10 SUM]# du -mch --max-depth=1 .
6.1M    ./sapcrypto
19G     ./abap
96M     ./jvm
290M    ./sdt
19G     .
19G     total

[root@DCGPFEAPP10 abap]# du -mch --max-depth=1 .
48K     ./trc
12G     ./log


-----------------------------------------------------------------------------------------------------------------------------------------------

8 March


1-335302731	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/ES1[PROBLEM:1159499] Date: Mar 7,2018 2:22 CUT Severity: Critical ResourceId: ms3wdcwapp08 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_OS_Linux:Free_disk_space_on_/usr/sap/ES1_(percentage) InstanceValue: 1.12 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_disk_space_on_/usr/sap/ES1_ Node: ms3wdcwapp08.imzcloud.ibmammsap.local NodeAlias: 10.12.6.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_disk_space_on_/usr/sap/ES1_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3509576:ms3

[root@ms3wdcwapp08 ibmrmalik]# df -k /usr/sap/ES1
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/es1appvg-es1usrES1_lv
                      23738812 15486036   7046952  69% /usr/sap/ES1



1-335271841	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1149411] Date: Mar 6,2018 9:31 CUT Severity: Minor ResourceId: dlbqecap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLBQECAP01.imzcloud.ibmammsap.local NodeAlias: 10.13.2.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3506898:dlb

[root@DLBQECAP01 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 3963476    807688  84% /var

[root@DLBQECAP01 var]# du -mch --max-depth=1 .
401M    ./cache
151M    ./lib
2.5G    ./log
752M    ./opt
14M     ./chef
3.8G    .
3.8G    total

[root@DLBQECAP01 log]# du -mch --max-depth=1 .
5.4M    ./ntpstats
7.5M    ./audit
33M     ./sa
2.5G    .
2.5G    total




1-335329611	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sapmnt/RPA[PROBLEM:1166629] Date: Mar 7,2018 16:8 CUT Severity: Minor ResourceId: iplsas4ap01 TicketGroup: ApsSAPTechnical CustomerCode: ipl InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/RPA InstanceValue: 19.96 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: iplsas4ap01.imzcloud.ibmammsap.local NodeAlias: 10.138.1.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/RPA AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3511166:ipl

[root@iplsas4ap01 ibmrmalik]# df -k /sapmnt/RPA
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/rpaappvg-rpasapmnt_lv
                      16513960 12867588   2807512  83% /sapmnt/RPA

[root@iplsas4ap01 ibmrmalik]# vgs rpaappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  rpaappvg   1  13   0 wz--n- 128.00g 20.00




1-335334301	sev1
IP - 10.13.2.24
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var[PROBLEM:1169220] Date: Mar 7,2018 20:56 CUT Severity: Critical ResourceId: dlbdwdap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 1.17 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLBDWDAP00.imzcloud.ibmammsap.local NodeAlias: 10.13.2.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3511770:dlb

[root@DLBDWDAP00 /]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 4482464    288700  94% /var

[root@DLBDWDAP00 /]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 4482720    288444  94% /var





SSGSA0121
100.126.0.15

[root@SSGSA0121 ibmrmalik]# pvs
  PV         VG        Fmt  Attr PSize   PFree
  /dev/sda2  VolGroup  lvm2 a--u  39.51g 1020.00m
  /dev/sdb   mmpdatavg lvm2 a--u 300.00g  100.99g
  /dev/sdc   mmpappvg  lvm2 a--u 128.00g       0
  /dev/sdd   mmpdatavg lvm2 a--u 128.00g       0
  /dev/sde   mmparchvg lvm2 a--u  64.00g    4.00g
  /dev/sdf   mmpappvg  lvm2 a--u  64.00g   22.99g
  /dev/sdg   mmplogvg  lvm2 a--u  32.00g  200.00m


NAME                             MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0                               11:0    1 1024M  0 rom
sda                                8:0    0   40G  0 disk
sda1                               8:1    0  500M  0 part /boot
sda2                               8:2    0 39.5G  0 part
VolGroup-lv_root (dm-0)          253:0    0   10G  0 lvm  /
VolGroup-lv_swap (dm-1)          253:1    0    8G  0 lvm  [SWAP]
VolGroup-lv_var (dm-27)          253:27   0    5G  0 lvm  /var
VolGroup-lv_mon (dm-28)          253:28   0    5G  0 lvm  /opt/monitor/IBM
VolGroup-lv_opt (dm-29)          253:29   0    5G  0 lvm  /opt
VolGroup-lv_tmp (dm-30)          253:30   0    2G  0 lvm  /tmp
VolGroup-lv_home (dm-31)         253:31   0  3.5G  0 lvm  /home  


VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g 1020.00m
  mmpappvg    2  13   0 wz--n- 191.99g   22.99g
  mmparchvg   1   1   0 wz--n-  64.00g    4.00g
  mmpdatavg   2   7   0 wz--n- 427.99g  100.99g
  mmplogvg    1   4   0 wz--n-  32.00g  200.00m




SSGSA0118
100.126.0.12

ssgsa0118:/home/ibmrmalik # df -k
Filesystem                       1K-blocks       Used  Available Use% Mounted on
devtmpfs                         528363068          0  528363068   0% /dev
tmpfs                            528372160          8  528372152   1% /dev/shm
tmpfs                            528372160    3493824  524878336   1% /run
tmpfs                            528372160          0  528372160   0% /sys/fs/cgroup
/dev/sda2                        242806952    9299504  233507448   4% /
/dev/sdc1                       3121912452   90913180 3030999272   3% /hana/data
/dev/sdb1                       1560952132  103122488 1457829644   7% /hana/shared
/dev/sda3                        536616956    2479556  534137400   1% /hana/log
/dev/sda1                          1035084      52920     929584   6% /boot
146.89.140.157:/storage/library 3845038080 2686640128  963075072  74% /sds
tmpfs                            105674436          8  105674428   1% /run/user/0
tmpfs                            105674436          0  105674436   0% /run/user/20100
146.89.140.30:/storage/library  3845038080 2686640128  963075072  74% /sds





SSGSA0119
100.126.0.13

[root@SSGSA0119 ibmrmalik]# pvs
  PV         VG        Fmt  Attr PSize   PFree
  /dev/sda2  VolGroup  lvm2 a--u  39.51g  2.50g
  /dev/sdb   misappvg  lvm2 a--u 128.00g     0
  /dev/sdc   misdatavg lvm2 a--u 128.00g     0
  /dev/sdd   misarchvg lvm2 a--u  64.00g 14.00g
  /dev/sde   mislogvg  lvm2 a--u  32.00g 20.00m
  /dev/sdg1  misappvg  lvm2 a--u  25.00g  3.99g



[root@SSGSA0119 ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g  2.50g
  misappvg    2  13   0 wz--n- 152.99g  3.99g
  misarchvg   1   1   0 wz--n-  64.00g 14.00g
  misdatavg   1   7   0 wz--n- 128.00g     0
  mislogvg    1   4   0 wz--n-  32.00g 20.00m


[root@SSGSA0119 ibmrmalik]# lsblk -l
NAME                             MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0                               11:0    1 1024M  0 rom
sda                                8:0    0   40G  0 disk
sda1                               8:1    0  500M  0 part /boot
sda2                               8:2    0 39.5G  0 part
VolGroup-lv_root (dm-0)          253:0    0   10G  0 lvm  /
VolGroup-lv_swap (dm-1)          253:1    0    8G  0 lvm  [SWAP]
VolGroup-lv_var (dm-2)           253:2    0    5G  0 lvm  /var
VolGroup-lv_mon (dm-3)           253:3    0    5G  0 lvm  /opt/monitor/IBM
VolGroup-lv_opt (dm-4)           253:4    0    5G  0 lvm  /opt
VolGroup-lv_tmp (dm-5)           253:5    0    2G  0 lvm  /tmp
VolGroup-lv_home (dm-6)          253:6    0    2G  0 lvm  /home




SSGSA0122
100.126.0.16

[root@SSGSA0122 ibmrmalik]# pvs
  PV         VG        Fmt  Attr PSize   PFree
  /dev/sda2  VolGroup  lvm2 a--u  39.51g    2.50g
  /dev/sdb   mnpappvg  lvm2 a--u 128.00g       0
  /dev/sdc   mnpdatavg lvm2 a--u 128.00g 1020.00m
  /dev/sdd   mnparchvg lvm2 a--u  64.00g   14.00g
  /dev/sde   mnpappvg  lvm2 a--u  64.00g   42.99g
  /dev/sdf   mnplogvg  lvm2 a--u  32.00g 1020.00m

[root@SSGSA0122 ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  VolGroup    1   7   0 wz--n-  39.51g    2.50g
  mnpappvg    2  13   0 wz--n- 191.99g   42.99g
  mnparchvg   1   1   0 wz--n-  64.00g   14.00g
  mnpdatavg   1   7   0 wz--n- 128.00g 1020.00m
  mnplogvg    1   4   0 wz--n-  32.00g 1020.00m


[root@SSGSA0122 ibmrmalik]# lsblk -l
NAME                             MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0                               11:0    1 1024M  0 rom
sda                                8:0    0   40G  0 disk
sda1                               8:1    0  500M  0 part /boot
sda2                               8:2    0 39.5G  0 part
VolGroup-lv_root (dm-0)          253:0    0   10G  0 lvm  /
VolGroup-lv_swap (dm-1)          253:1    0    8G  0 lvm  [SWAP]
VolGroup-lv_var (dm-2)           253:2    0    5G  0 lvm  /var
VolGroup-lv_mon (dm-3)           253:3    0    5G  0 lvm  /opt/monitor/IBM
VolGroup-lv_opt (dm-4)           253:4    0    5G  0 lvm  /opt
VolGroup-lv_tmp (dm-5)           253:5    0    2G  0 lvm  /tmp
VolGroup-lv_home (dm-6)          253:6    0    2G  0 lvm  /home




1-334406281	sev1

Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:858200] Date: Feb 10,2018 19:49 CUT Severity: Critical ResourceId: bi1bwhapprd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: bi1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0.17 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: BI1BWHAPPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3433545:bi1

[root@BI1BWHAPPRD01 ibmrmalik]# df -k /
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      10190136 3863816   5802032  40% /




1-335349441	sev3	Frankfurt	root/AHcWe59j		10.134.53.162		SL ticket for hot swap Ticket 56440097 
Summary: Drive_with_Errors_on_frahana-1024-9.xsportal.local[PROBLEM:1175076] Date: Mar 8,2018 8:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_frahana-1024-9.xsportal.local InstanceValue: Media Error Count = 5 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_frahana-1024-9.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_frahana-1024-9.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3513084:amm

------------------------------------------------------------------------------------------------------------------------------------------------------------------

9 March

1-335346493   sev3
Please unlock user - qbwadm of IP - 10.13.2.18



1-335374861	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1181835] Date: Mar 8,2018 20:56 CUT Severity: Minor ResourceId: ci3s4hanadeva TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 15.27 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CI3S4HANADEVA.imzcloud.ibmammsap.local NodeAlias: 10.210.1.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3514554:ci3

[root@CI3S4HANADEVA ibmrmalik]# df -k /tmp
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                       1998672 1612056    281760  86% /tmp

[root@CI3S4HANADEVA tmp]# ls -lt
total 560
-rw-r--r-- 1 devadm     sapsys       32768 Mar  9 04:39 sap_jvm_monitoringboard_20100_97096
-rw-r----- 1 root       sapinst      32768 Mar  9 04:39 sap_jvm_monitoringboard_0_38690
-rw-r----- 1 root       sapinst      32768 Mar  9 04:39 sap_jvm_monitoringboard_0_38603
-rw-r----- 1 root       sapinst      32768 Mar  9 04:39 sap_jvm_monitoringboard_0_38617
-rw------- 1 devadm     sapsys       53248 Mar  9 04:39 sap_jvm_20100_97096
-rw------- 1 root       sapinst      53248 Mar  9 04:39 sap_jvm_0_38617
-rw------- 1 root       sapinst      53248 Mar  9 04:39 sap_jvm_0_38603
-rw------- 1 root       sapinst      53248 Mar  9 04:39 sap_jvm_0_38690




1-335380591	sev1	
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1184889] Date: Mar 9,2018 2:24 CUT Severity: Critical ResourceId: ahecpsap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: a1a InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: AHECPSAP01.imzcloud.ibmammsap.local NodeAlias: 10.4.9.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3515270:a1a

Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      26437900 25527044         0 100% /

[root@AHECPSAP01 /]# du -mch --max-depth=1 .
4.0G    ./sapmnt
20G     ./var
du: cannot access `./proc/59749/task/59749/fd/4': No such file or directory
du: cannot access `./proc/59749/task/59749/fdinfo/4': No such file or directory
du: cannot access `./proc/59749/fd/4': No such file or directory
du: cannot access `./proc/59749/fdinfo/4': No such file or directory


[root@AHECPSAP01 var]# du -mch --max-depth=1 .
18G     ./spool
20G     .
20G     total

/spool/abrt
18G     ./abrt

-rw-r-----. 1 root abrt 31279378432 Mar  8 20:25 coredump

deleted core dump file

[root@AHECPSAP01 ccpp-2018-03-08-20:23:59-49454]# df -k /
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      26437900 7623844  17464424  31% /




1-335379151	sev1
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1186296] Date: Mar 9,2018 4:8 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3515509:amm




1-335056431	sev2
*** Details of Generic Service Request - DO NOT CHANGE ***

Hello,

Activate remote desktop service

Hostname: ICROUTER
IP: 10.10.12.200	IMZ ip  10.4.252.200

Best regards,
Edith Paredes



1-335362121 - Transfer datafiles and cofiles 
*** Details of Generic Service Request - DO NOT CHANGE ***

Hello Team

Can you please transfer the cofiles and data files to QQ1 BLX system

Source Location /migrations/QQ1_USERS_100/ to /usr/sap/trans

Permission : qq1adm:sapsys


1st Files : 
Source : /migrations/QQ1_USERS_100/data/RT00008.QQ1, VM : MMGRAS, IMZ : 10.78.22.12 (NFS)
Target :   /usr/sap/trans/data  , VM : SMGWQUAQQ1, IMZ : 10.78.24.14 

2nd Files : 
Source : /migrations/QQ1_USERS_100/cofiles/ KT00008.QQ1, VM : MMGRAS, IMZ : 10.78.22.12 (NFS)
Target :  /usr/sap/trans/cofiles  , VM : SMGWQUAQQ1, IMZ : 10.78.24.14

10.5.26.11:/usr/sap/trans

vi  /etc/idmapd.conf

---------------------------------------------------------------------------------------------------------------------------------------

12 March

1-335468201	sev2
Summary: Lack_of_free_swap_space_on_vsapde6-ci.imzcloud.ibmammsap.local[PROBLEM:1216773] Date: Mar 11,2018 23:23 CUT Severity: Major ResourceId: vsapde6-ci TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ca3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.95 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: vsapde6-ci.imzcloud.ibmammsap.local NodeAlias: 10.9.5.201 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3522832:ca3

top - 19:04:03 up 549 days, 12:43,  1 user,  load average: 0.62, 0.53, 0.56
Tasks: 216 total,   1 running, 214 sleeping,   0 stopped,   1 zombie
Cpu(s): 45.1%us,  6.3%sy,  0.0%ni, 47.7%id,  0.7%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:  7865.586M total, 7669.621M used,  195.965M free,   72.355M buffers
Swap:   13.766G total, 7066.531M used, 7029.465M free, 3638.082M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
20429 de6adm    20   0 1507m  10m 1764 S  0.0  0.1  45:27.64 787m en.sapDE6_ASCS0
22204 de6adm    20   0 8418m 2.2g 2.1g S  1.4 28.3   2598:33 163m DE6_01_DIA_W3
  451 daaadm    20   0 2161m 265m 7600 S  0.4  3.4 782:41.97 158m jstart
22206 de6adm    20   0 8413m 2.2g 2.1g S  0.0 28.8   2770:33 135m DE6_01_DIA_W5
22205 de6adm    20   0 8402m 2.3g 2.1g S  2.1 29.6   2661:39 133m DE6_01_DIA_W4
22209 de6adm    20   0 8402m 2.2g 2.1g S  0.0 29.1   3019:50 129m DE6_01_DIA_W8
35543 root      20   0  356m 2644 1356 S  0.4  0.0 457:09.45 121m vmtoolsd
22200 de6adm    20   0 1853m 9.9m 4096 S  0.0  0.1   7:08.12 120m icman
22203 de6adm    20   0 8386m 2.2g 2.1g S  0.0 29.0   2359:20 115m DE6_01_DIA_W2
16253 de6adm    20   0 8376m 2.3g 2.1g S  0.0 29.5   2932:04 105m DE6_01_DIA_W9
22211 de6adm    20   0 8302m 284m 225m S  0.0  3.6  14:32.55 100m DE6_01_UPD_W10
62821 de6adm    20   0 8371m 2.3g 2.1g S  2.1 29.4   2832:16  98m DE6_01_DIA_W7
22201 de6adm    20   0 8359m 2.2g 2.1g S  0.0 28.5   1800:41  95m DE6_01_DIA_W0
22212 de6adm    20   0 8298m 292m 229m S  0.0  3.7  20:02.10  92m DE6_01_UPD_W11
22202 de6adm    20   0 8391m 2.2g 2.0g S  0.0 28.4   1972:52  90m DE6_01_DIA_W1
 5825 de6adm    20   0 8360m 2.3g 2.2g S  1.4 29.8   2653:57  83m DE6_01_DIA_W6


[root@vsapde6-ci ibmrmalik]# fre -g
bash: fre: command not found
[root@vsapde6-ci ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          7          0          2          0          3
-/+ buffers/cache:          3          3
Swap:           13          6          6




1-335450851	sev1
Summary: Zabbix_agent_on_lon02ammtsm001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1210484] Date: Mar 11,2018 7:41 CUT Severity: Critical ResourceId: lon02ammtsm001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: lon02ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.114 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3521360:amm	




1-335469311	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/hana/log[PROBLEM:1216715] Date: Mar 11,2018 23:11 CUT Severity: Major ResourceId: loncfgcep0002 TicketGroup: ApsSAPTechnical CustomerCode: cf9 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 9.97 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: loncfgcep0002.imzcloud.ibmammsap.local NodeAlias: 10.69.2.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3522816:cf9

[root@loncfgcep0002 ibmrmalik]# df -k /hana/log
Filesystem     1K-blocks      Used Available Use% Mounted on
/dev/sde1      270396416 255777020  14619396  95% /hana/log

[root@loncfgcep0002 mnt00001]# du -mch --max-depth=1 .
1.8G    ./hdb00003
227G    ./hdb00004
2.1G    ./hdb00002
15G     ./hdb00001
244G    .
244G    total




1-335474411
Summary: Free_disk_space_is_less_than_10%_on_volume_F:[PROBLEM:1218835] Date: Mar 12,2018 4:25 CUT Severity: Major ResourceId: ri3lr020 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: InstanceValue: 9.83 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: DAL09AMMTS002 NodeAlias: 146.89.140.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523339:mic



1-335476881	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1219489] Date: Mar 12,2018 5:46 CUT Severity: Minor ResourceId: ia2bpcdevapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 10.71 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: IA2BPCDEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.48 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523474:ia1

[root@IA2BPCDEVAPP ibmrmalik]# df -k /
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      10190136 8797016    868832  92% /

[root@IA2BPCDEVAPP /]# du -mch --max-depth=1 .
2.4G    ./usr
72M     ./tmp
1.4G    ./var


[root@IA2BPCDEVAPP /]# find / -xdev -type f -size +1000000
/Staging/SUM/SWPM10SP20_1-20009701.SAR




1-335476271	sev2	ntp service restart awaiting clear event
Summary: NTP_time_is_driffted_on_PBBwdpap00.imzcloud.ibmammsap.local[PROBLEM:1219518] Date: Mar 12,2018 5:48 CUT Severity: Warning ResourceId: pbbwdpap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pbb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 10.68 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: PBBwdpap00.imzcloud.ibmammsap.local NodeAlias: 10.6.7.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523488:pbb




1-335476991	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1219513] Date: Mar 12,2018 5:47 CUT Severity: Major ResourceId: ia2bpcdevapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 8.64 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: IA2BPCDEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.48 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523487:ia1



1-335475961	sev3
Summary: Processor_load_is_too_high_on_SNCHCIIPA12[PROBLEM:1219274] Date: Mar 12,2018 5:31 CUT Severity: Minor ResourceId: snchciipa12 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 5.8 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SNCHCIIPA12 NodeAlias: 10.73.10.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523442:snc



1-335479001	sev3	10.116.35.150	root/A9bgMdvV		 Ticket 56618003hot swap
Summary: Drive_with_Errors_on_snghana-1024-6.xsportal.local[PROBLEM:1220172] Date: Mar 12,2018 7:8 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_snghana-1024-6.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_snghana-1024-6.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_snghana-1024-6.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523623:amm



1-335477371	sev3	10.164.238.183	root/Xhfd92Nh		no media error SL ticket Ticket # 56620503 	
Summary: Drive_with_Errors_on_lonhana-1024-43.xsportal.local[PROBLEM:1220166] Date: Mar 12,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_lonhana-1024-43.xsportal.local InstanceValue: 10:17 43 UBad - 558.406 GB SAS HDD N N 512B ST3600057SS U - ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_lonhana-1024-43. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_lonhana-1024-43.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523622:amm



1-335477531	sev3
Summary: NTP_time_is_driffted_on_PBBwdpap00.imzcloud.ibmammsap.local[PROBLEM:1220406] Date: Mar 12,2018 7:38 CUT Severity: Warning ResourceId: pbbwdpap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pbb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 7.33 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: PBBwdpap00.imzcloud.ibmammsap.local NodeAlias: 10.6.7.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523665:pbb


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

13 March


1-335492021	sev3
Summary: FS_is_read_only_on_DLBQBWAP01.imzcloud.ibmammsap.local[PROBLEM:1223815] Date: Mar 12,2018 15:11 CUT Severity: Minor ResourceId: dlbqbwap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /usr/sap/trans filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: DLBQBWAP01.imzcloud.ibmammsap.local NodeAlias: 10.13.2.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3524440:dlb

[root@DLBQBWAP01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /usr/sap/trans filesystems are read-only

[root@DLBQBWAP01 ibmrmalik]# df -h  /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
10.13.2.20:/usr/sap/trans
                       40G   23G   15G  61% /usr/sap/trans

//10.13.2.20:/usr/sap/trans /usr/sap/trans    nfs  default 0 0

[root@DLBQBWAP01 ~]# /etc/init.d/nfs status
rpc.svcgssd is stopped
rpc.mountd (pid 27537) is running...
nfsd (pid 27554 27553 27552 27551 27550 27549 27548 27547) is running...
rpc.rquotad (pid 27532) is running...

[root@DLBQBWAP01 ibmrmalik]# ps -ef |grep /usr/sap/trans
root      84580  82701  0 08:34 pts/3    00:00:00 grep /usr/sap/trans





1-335513121   LSPI (LSP)   Sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_E:[PROBLEM:1228774] Date: Mar 13,2018 2:18 CUT Severity: Critical ResourceId: lzagrcdev0 TicketGroup: ApsSAPTechnical CustomerCode: lsp InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_E: InstanceValue: 4.99 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: LZAGRCDEV0 NodeAlias: 10.4.3.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_E: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3525876:lsp

E:\usr\sap




1-335512371  Manchester City Airport Group - SAP HEC-AMM  SEV1
Summary: Zabbix_agent_on_lonmaghan0007.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1228959] Date: Mar 13,2018 2:41 CUT Severity: Critical ResourceId: lonmaghan0007 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: lonmaghan0007.imzcloud.ibmammsap.local NodeAlias: 10.69.0.50 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3525906:mng

[root@lonmaghan0007 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  5303) is running...
[root@lonmaghan0007 ibmrmalik]# uptime
 03:16:40 up 117 days, 17:05,  1 user,  load average: 0.77, 0.68, 0.48





1-335512581	sev1		Done
Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local[PROBLEM:1229295] Date: Mar 13,2018 3:18 CUT Severity: Critical ResourceId: c1bwp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3525960:pnc

[root@C1BWP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /mnt/sapexchangePT filesystems are read-only

[root@C1BWP ibmrmalik]# cat /etc/fstab|grep sapexchangePT
//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  credentials=/etc/sapexchangePT_credential,uid=908,gid=5003

[root@C1BWP ibmrmalik]# cat /etc/fstab|grep sapexchange
//10.254.201.40/SAPEXCHANGE /mnt/sapexchange/ cifs username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003
//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/  cifs username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003
//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  credentials=/etc/sapexchangePT_credential,uid=908,gid=5003




//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003
mount  //10.7.1.171/sapexchange /mnt/sapexchangePT  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003
              



1-335513491	sev1	Done
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1229242] Date: Mar 13,2018 3:8 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3525949:amm



1-335333141	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap[PROBLEM:1169251] Date: Mar 7,2018 20:59 CUT Severity: Major ResourceId: tqaerpprdh TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap InstanceValue: 6.38 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQAERPPRDH.imzcloud.ibmammsap.local NodeAlias: 10.7.1.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3511778:tqa

[root@TQAERPPRDH ibmrmalik]# df -k /usr/sap
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vghanadata-lv_usr_sap
                      52399104 49153268   3245836  94% /usr/sap


[root@TQAERPPRDH sap]# du -mch --max-depth=1 .
92K     ./S4P
197M    ./hostctrl
47G     ./backup
0       ./lib
47G     .
47G     total



1-335483291	sev3		DONE
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1221495] Date: Mar 12,2018 10:0 CUT Severity: Minor ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3523881:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      53273100 13097640  37463420  26% /





1-335386714		sev3		SMRT SNG	10.198.0.71
Hello Asmita, 

Please proceed to add space in to CLDERPAPPP1.
(Please add additional space - like double it for time being ROOT FS - space.- As per mail by Naveen)
[root@CLDERPAPPP1 ibmrmalik]# df -k
Filesystem           1K-blocks      Used Available Use% Mounted on

/dev/mapper/vg00-lv_root
                      53273100  13098528  37462532  26% /
tmpfs                 66080908         8  66080900   1% /dev/shm
/dev/sda1               487652     65252    396800  15% /boot
/dev/mapper/vg_app-lv_usrsap
                     227964220 124373584  92007624  58% /usr/sap
/dev/mapper/vg_app-lv_sapmnt
                      15350768   7559372   7005028  52% /sapmnt
/dev/mapper/vg01-lv_IDEAL
                       1998672    591756   1302060  32% /usr/IDEALConnect
/dev/mapper/vg01-lv_interfaces
                     207321720  74158848 122627024  38% /usr/interfaces
/dev/mapper/vg_app-lv_monitoring
                       5029504    962644   3804716  21% /opt/monitor/IBM
10.168.1.208:/usr/sap/trans
                      92755968  37672960  50365440  43% /usr/sap/trans


[root@CLDERPAPPP1 ibmrmalik]# vgs vg00
  VG   #PV #LV #SN Attr   VSize  VFree
  vg00   2   2   0 wz--n- 69.50g 4.00g







1-334532501		sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:900783] Date: Feb 14,2018 11:6 CUT Severity: Critical ResourceId: ssgsa0119 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mmd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 4.63 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: SSGSA0119.imzcloud.ibmammsap.local NodeAlias: 100.126.0.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3443569:mmd

[root@SSGSA0119 ibmrmalik]# df -k /
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      10190136 7606996   2058852  79% /




1-335084441
Summary: FS_is_read_only_on_Pepsapgbsdi01.imzcloud.ibmammsap.local[PROBLEM:1088380] Date: Mar 1,2018 7:18 CUT Severity: Minor ResourceId: pepsapgbsdi01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /home/gbsadm/.gvfs filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: Pepsapgbsdi01.imzcloud.ibmammsap.local NodeAlias: 100.126.32.44 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492260:pep

Pepsapgbsdi01:~ # sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /home/gbsadm/.gvfs filesystems are read-only

Pepsapgbsdi01:~ # cat /etc/fstab |grep gbsadm
/dev/gbsappvg/gbsadm_lv /home/gbsadm    ext3    _netdev,defaults        1       2

Pepsapgbsdi01:~ # cat /etc/SuSE-release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 2
# This file is deprecated and will be removed in a future service pack or release.
# Please check /etc/os-release for details about this release.




1-335503271	sev3		10.12.7.28
RE: RED :ms3wdcladb41:File System Full

/dev/mapper/bp1appvg-usrsapdaa_lv

[root@ms3wdcladb41 ibmrmalik]# vgs bp1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  bp1appvg   4  13   0 wz--n- 227.98g 12.98g

/dev/mapper/bp1appvg-usrsapdaa_lv
                      2.0G  1.9G   27M  99% /usr/sap/DAA

#vgs 
#lvextend -L +40G  /dev/mapper/bp1appvg-usrsapdaa_lv 
# resize2fs /dev/mapper/bp1appvg-usrsapdaa_lv

                       2064208  1932388     26964  99% /usr/sap/DAA




1-335517531	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/db/db2inst2/db2data[PROBLEM:1230956] Date: Mar 13,2018 7:6 CUT Severity: Critical ResourceId: crosfliem01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data InstanceValue: 0.31 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: crosfliem01.imzcloud.ibmammsap.local NodeAlias: 10.68.210.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3526424:cng

[root@crosfliem01 ibmrmalik]# df -k /db/db2inst2/db2data
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/vg_db2inst2-lv_db_db2inst2_db2data
                      10190136 3303740   6362108  35% /db/db2inst2/db2data

-------------------------------------------------------------------------------------------------------------------------------------------------------

14 March


1-335554181	sev2
Summary: Lack_of_free_swap_space_on_SK3CARAPPRD02.imzcloud.ibmammsap.local[PROBLEM:1238409] Date: Mar 13,2018 22:56 CUT Severity: Major ResourceId: sk3carapprd02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 45.6 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3CARAPPRD02.imzcloud.ibmammsap.local NodeAlias: 10.5.241.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3528362:sk3

[root@SK3CARAPPRD02 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            63         51         11         23          0         24
-/+ buffers/cache:         27         36
Swap:           57         31         26


top - 03:42:48 up 481 days, 12:50,  1 user,  load average: 6.04, 5.76, 5.83
Tasks: 380 total,   7 running, 373 sleeping,   0 stopped,   0 zombie
Cpu(s): 76.0%us,  0.2%sy,  0.0%ni, 23.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    63.350G total,   51.380G used,   11.970G free,   60.328M buffers
Swap:   58.000G total,   31.540G used,   26.460G free,   24.162G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
51190 sepadm    20   0 58.9g  10g 9.8g S  0.0 16.0   1091:30 744m SEP_00_DIA_W36
26407 sepadm    20   0 58.7g  10g  10g S  0.0 16.1   1014:35 693m SEP_00_DIA_W45
20625 sepadm    20   0 58.7g 9.6g 9.5g S  0.0 15.1 669:54.74 671m SEP_00_DIA_W23
62105 sepadm    20   0 58.4g   9g 9.8g S  0.0 15.7 405:51.87 266m SEP_00_DIA_W35
63721 sepadm    20   0 60.1g 2.0g 131m R 100.0  3.2 235:19.48 215m SEP_00_BTC_W71
33120 sepadm    20   0 60.1g 2.0g  81m R 99.8  3.2 234:00.12 208m SEP_00_BTC_W67
49516 sepadm    20   0 60.1g 2.2g 274m R 100.0  3.5 235:32.28 207m SEP_00_BTC_W58
44289 sepadm    20   0 59.9g 1.9g  57m R 99.8  2.9 235:25.60 205m SEP_00_BTC_W69
57077 sepadm    20   0 58.2g 9.8g 9.8g S  0.0 15.5 187:14.80 163m SEP_00_DIA_W37
27005 daaadm    20   0 5180m 305m 9332 S  1.0  0.5  43:24.63 163m jstart
20616 sepadm    20   0 58.2g 8.5g 8.4g S  0.0 13.4 284:13.51 162m SEP_00_DIA_W14



1-335521661	sev2
Summary: Lack_of_free_swap_space_on_DLBQECAP01.imzcloud.ibmammsap.local[PROBLEM:1231303] Date: Mar 13,2018 7:41 CUT Severity: Major ResourceId: dlbqecap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.05 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: DLBQECAP01.imzcloud.ibmammsap.local NodeAlias: 10.13.2.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3526476:dlb

[root@DLBQECAP01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          8          0          9
-/+ buffers/cache:          5          9
Swap:            7          5          2

top - 13:46:39 up 211 days, 16:39,  1 user,  load average: 0.03, 0.12, 0.10
Tasks: 272 total,   1 running, 271 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.5%us,  0.2%sy,  0.0%ni, 99.2%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.248G used,  321.211M free,   20.910M buffers
Swap: 8191.996M total, 5392.992M used, 2799.004M free, 9870.586M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
128479 qecadm    20   0 1429m  15m 2828 S  0.3  0.1   7:10.08 782m en.sapQEC_ASC
129953 qecadm    20   0 2073m  28m  16m S  0.0  0.2   0:35.90 116m icman
 16261 qecadm    20   0 1281m  16m 9628 S  0.0  0.1   4:05.46  57m sapstartsrv



1-335552111	sev2
Summary: Lack_of_free_swap_space_on_IA1FIOPRDAPP.imzcloud.ibmammsap.local[PROBLEM:1237435] Date: Mar 13,2018 20:39 CUT Severity: Major ResourceId: ia1fioprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.76 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: IA1FIOPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3528113:ia1

[root@IA1FIOPRDAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          1          0          2
-/+ buffers/cache:         12          2
Swap:            7          4          3

top - 03:49:44 up 142 days, 19:54,  1 user,  load average: 0.57, 0.18, 0.06
Tasks: 259 total,   1 running, 258 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.8%us,  0.3%sy,  0.0%ni, 98.0%id,  0.8%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.097G used,  475.992M free,  165.305M buffers
Swap: 8191.996M total, 4195.688M used, 3996.309M free, 2327.988M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
  2495 fp1adm    20   0 1507m  23m 2632 S  0.0  0.1   9:55.59 777m en.sapFP1_AS
  4499 fp1adm    20   0 15.4g 1.0g 682m S  0.0  6.7  10:14.86 128m FP1_00_DIA_W
  4493 fp1adm    20   0 15.2g 909m 659m S  0.0  5.7   5:49.88  98m FP1_00_DIA_W
  4496 fp1adm    20   0 15.2g 951m 709m S  0.0  6.0   4:46.83  97m FP1_00_DIA_W
  4497 fp1adm    20   0 15.2g 891m 644m S  0.0  5.6   4:39.62  91m FP1_00_DIA_W
  4492 fp1adm    20   0 1811m  61m  12m S  0.0  0.4  10:13.96  80m icman
  4510 fp1adm    20   0 15.4g 1.7g 1.3g S  0.0 11.2 103:40.33  71m FP1_00_DIA_W
  4495 fp1adm    20   0 15.3g 949m 668m S  0.0  6.0   5:01.56  70m FP1_00_DIA_W  
  4526 fp1adm    20   0 15.5g 838m 315m S  0.0  5.3  86:00.44  61m FP1_00_BTC_W
  4500 fp1adm    20   0 15.2g 1.1g 835m S  1.3  7.1  11:58.59  55m FP1_00_DIA_W
  4498 fp1adm    20   0 15.2g 1.0g 721m S  0.0  6.3   7:47.09  53m FP1_00_DIA_W
  4506 fp1adm    20   0 15.4g 1.7g 1.2g S  0.0 11.1  54:53.15  52m FP1_00_DIA_W
  4494 fp1adm    20   0 15.2g 923m 693m S  0.0  5.8   4:33.31  51m FP1_00_DIA_W
  4502 fp1adm    20   0 15.2g 1.2g 929m S  0.0  7.7  16:51.43  47m FP1_00_DIA_W
  4501 fp1adm    20   0 15.2g 1.1g 808m S  0.0  7.0  14:26.85  45m FP1_00_DIA_W
  4523 fp1adm    20   0 15.4g 730m 301m S  0.0  4.6  31:52.33  35m FP1_00_BTC_W111037 
       fp1adm    20   0 15.3g 1.3g 927m S  0.0  8.5  41:56.54  35m FP1_00_DIA_W



1-335534501   sev2
Summary: Lack_of_free_swap_space_on_dal09ammsrtr001.imzcloud.ibmammsap.local[PROBLEM:1233901] Date: Mar 13,2018 13:44 CUT Severity: Major ResourceId: dal09ammsrtr001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.97 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: dal09ammsrtr001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3527169:amm

[root@dal09ammsrtr001 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             3          3          0          0          0          0
-/+ buffers/cache:          3          0
Swap:            7          4          3


top - 21:56:54 up 183 days, 10:22,  1 user,  load average: 0.05, 0.01, 0.00
Tasks: 139 total,   1 running, 138 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.0%us,  0.2%sy,  0.0%ni, 99.8%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  3953.715M total, 3635.719M used,  317.996M free,   21.773M buffers
Swap: 8191.996M total, 4539.168M used, 3652.828M free,  273.043M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
49741 root      20   0 8517m 2.6g 3788 S  0.0 66.9 169:42.40 4.1g python
 2311 root      20   0  257m 7572 1112 S  0.0  0.2   0:38.57  48m chef-client
10209 root      20   0  996m  39m 5120 S  0.0  1.0  58:14.91  42m ds_agent
39030 root      39  19 1079m  33m  728 S  0.0  0.8  21:20.03  33m java
10339 root      20   0 1637m 175m 3444 S  0.0  4.4 174:03.94  21m ds_am
15250 root      20   0  341m  20m 5252 S  0.0  0.5   3:10.96  16m sssd_be
 2276 root      20   0  258m 3284  820 S  0.0  0.1   0:34.87  10m smbd
10208 root      20   0  188m  868  492 S  0.0  0.0   0:00.00 5036 ds_agent
22158 root      20   0  509m 2088 1436 S  0.0  0.1 116:54.91 2924 ManagementAgen
22127 root      20   0 59980 1096 1092 S  0.0  0.0   0:00.05 2888 VGAuthService
22007 root      18  -2 12700  324  320 S  0.0  0.0   0:00.01 2420 udevd
22102 root      20   0  245m 2792 1664 S  0.0  0.1 130:11.67 2420 vmtoolsd
 2197 root      20   0  178m  780  776 S  0.0  0.0   0:00.00  980 abrtd
 2250 root      20   0  246m 2688 2460 S  0.0  0.1   0:03.61  968 smbd
  488 root      16  -4 11120  336  332 S  0.0  0.0   0:00.23  888 udevd
22006 root      18  -2 11116  212  208 S  0.0  0.0   0:00.02  884 udevd



1-335531501 sev2
Summary: Lack_of_free_swap_space_on_ms3wdcladb23.imzcloud.ibmammsap.local[PROBLEM:1233811] Date: Mar 13,2018 13:22 CUT Severity: Major ResourceId: ms3wdcladb23 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: ms3wdcladb23.imzcloud.ibmammsap.local NodeAlias: 10.12.6.42 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3527128:ms3

[root@ms3wdcladb23 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          2          0          2
-/+ buffers/cache:          8          3
Swap:            7          4          3


top - 03:12:42 up 236 days, 17:16,  1 user,  load average: 0.19, 0.09, 0.02
Tasks: 262 total,   1 running, 261 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.2%us,  0.7%sy,  0.0%ni, 96.9%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    11.626G total,   11.271G used,  362.957M free,  167.527M buffers
Swap: 8191.996M total, 4402.012M used, 3789.984M free, 3010.672M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
31385 jq1adm    20   0 1429m  12m 1660 S  0.0  0.1   4:43.39 783m en.sapJQ1_SCS1
33996 jq1adm    20   0 7020m 4.2g  14m S  0.3 36.5 957:08.80 344m jstart
33914 jq1adm    20   0 1682m  29m 6164 S  0.0  0.2   3:08.26  91m icman
40314 root      20   0 4001m 2.2g 4612 S  0.3 18.9  20:08.57  71m python
 5563 root      20   0  266m  35m 3304 S  0.0  0.3 264:40.42  45m koy15col
 2306 root      20   0  292m  28m 2460 S  0.0  0.2 152:21.48  33m vmtoolsd
33053 jq1adm    20   0  823m 7616 1764 S  0.0  0.1  11:32.65  20m igspw_mt
33054 jq1adm    20   0  823m 7744 1760 S  0.0  0.1  11:35.64  20m igspw_mt
35786 root      20   0  257m  36m 1944 S  0.0  0.3   0:21.33  19m chef-client
33048 jq1adm    20   0  265m 6448 2268 S  0.0  0.1   0:02.79  17m jc.sapJQ1_J01
38179 jq1adm    20   0  747m 2120   68 S  0.0  0.0   0:00.00  17m sapstartsrv
 3824 sapadm    20   0  642m  14m 3496 S  0.0  0.1  14:59.76  13m sapstartsrv
 5878 root      20   0 1739m 9196 3276 S  0.3  0.1   7:56.55  12m kuma620



1-335508701	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/hana/log[PROBLEM:1226904] Date: Mar 12,2018 21:37 CUT Severity: Major ResourceId: bi1crmdbprd01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 10 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1CRMDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3525352:bi1

[ibmrmalik@BI1CRMDBPRD01 ~]$ sudo su
df -k [root@BI1CRMDBPRD01 ibmrmalik]# df -k /hana/log
Filesystem     1K-blocks      Used Available Use% Mounted on
/dev/sdd1      538696704 497437644  41259060  93% /hana/log

3.2G    ./mnt00001
472G    ./backuplog
475G    .
475G    total





1-335564981	sev2
Summary: Lack_of_free_swap_space_on_ms3wdcladb17.imzcloud.ibmammsap.local[PROBLEM:1241300] Date: Mar 14,2018 6:6 CUT Severity: Major ResourceId: ms3wdcladb17 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 49.76 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: ms3wdcladb17.imzcloud.ibmammsap.local NodeAlias: 10.12.6.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3529098:ms3

[root@ms3wdcladb17 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          2          0          3
-/+ buffers/cache:          8          3
Swap:            7          4          3


top - 06:15:49 up 3 days, 10:46,  1 user,  load average: 0.00, 0.02, 0.00
Tasks: 291 total,   1 running, 290 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.0%us,  0.5%sy,  0.0%ni, 99.3%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    11.633G total,   11.295G used,  345.973M free,   96.949M buffers
Swap: 8191.996M total, 4113.527M used, 4078.469M free, 3167.672M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 9989 root      20   0 4065m 2.5g 3048 S  0.5 21.2  22:52.00  97m python
13061 id1adm    20   0 2100m  51m 3548 S  0.0  0.4   0:06.73  81m icman
11480 id1adm    20   0 1492m 728m 1764 S  0.0  6.1   0:20.05  69m en.sapID1_ASCS
 9882 daaadm    20   0 2017m 214m 6648 S  0.5  1.8   4:18.96  30m jstart
 2812 root      20   0  851m  40m 4956 S  0.0  0.3   3:36.22  22m ds_agent
10938 root      20   0 1519m  24m 3748 S  0.0  0.2   0:12.84  15m ksaagent
 9131 sapadm    20   0  578m  12m 2356 S  0.0  0.1   0:26.03  14m sapstartsrv
10638 root      20   0 1442m 5796 2616 S  0.0  0.0   0:07.32  12m koyagent
 9684 daaadm    20   0  493m 7848 1388 S  0.0  0.1   0:03.78  11m sapstartsrv
 9514 id1adm    20   0  810m  28m 9392 S  0.0  0.2   0:23.71  11m sapstartsrv
 9327 id1adm    20   0  875m  23m 3120 S  0.0  0.2   0:33.09  10m sapstartsrv
 3043 root      20   0 1637m 191m 3096 S  0.0  1.6  19:26.38 8576 ds_am


1-335553821	sev2
Summary: Lack_of_free_swap_space_on_APLBREDE1.imzcloud.ibmammsap.local[PROBLEM:1237956] Date: Mar 13,2018 22:6 CUT Severity: Major ResourceId: aplbrede1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ap5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.76 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: APLBREDE1.imzcloud.ibmammsap.local NodeAlias: 170.225.68.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3528254:ap5

[root@APLBREDE1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0         10          0         25
-/+ buffers/cache:          4         26
Swap:            7          5          2

top - 07:25:28 up 125 days, 15:20,  1 user,  load average: 0.01, 0.20, 0.66
Tasks: 380 total,   1 running, 379 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.0%us,  1.4%sy,  0.3%ni, 97.0%id,  0.3%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   30.380G used,  985.160M free,  454.496M buffers
Swap: 8191.996M total, 5324.648M used, 2867.348M free,   25.419G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
100568 de1adm    20   0 1427m  13m 2832 S  0.0  0.0  17:02.85 784m en.sapDE1_ASCS0
 38630 db2de1    20   0 19.6g 9.5g 9.0g S  0.4 30.2   2110:40 204m db2sysc
 50836 daaadm    20   0 2913m  83m 3476 S  0.0  0.3 162:22.30 115m jstart
102145 de1adm    20   0 2161m  11m 6096 S  0.0  0.0   2:51.14 107m icman

---------------------------------------------------------------------------------------------------------------------------------------------------------

15 March

1-335084441	sev2	Dallas		SUSE
Summary: FS_is_read_only_on_Pepsapgbsdi01.imzcloud.ibmammsap.local[PROBLEM:1088380] Date: Mar 1,2018 7:18 CUT Severity: Minor ResourceId: pepsapgbsdi01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /home/gbsadm/.gvfs filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: Pepsapgbsdi01.imzcloud.ibmammsap.local NodeAlias: 100.126.32.44 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492260:pep


1-335590161	sev1
Summary: Zabbix_agent_on_fmsprdrtem002.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1251871] Date: Mar 14,2018 21:5 CUT Severity: Critical ResourceId: fmsprdrtem002 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: fmsprdrtem002.imzcloud.ibmammsap.local NodeAlias: 169.55.192.103 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3531032:amm

[root@fmsprdrtem002 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  2337) is running...
[root@fmsprdrtem002 ibmrmalik]# uptime
 22:35:06 up  5:06,  1 user,  load average: 0.13, 0.17, 0.25




performance report  of HANA server

eCDEVHANADB1	10.60.1.13	10.70.1.13 = Cerebos-eCDEVHANADB1-SMRT-CLDERPDTBD1.xsportal.local	
BJDEVHANADB1	10.60.1.11	10.70.1.11 = Cerebos-BJDEVHANADB1-CHDEVHANADB1.xsportal.local
CRDEVHANADB1	10.60.1.18	10.70.1.18 =  	sng01ammhana004.xsportal.local				10.116.103.217	SNG	root/NFXLL8Ae
eCQAHANADB1	10.60.1.15	10.70.1.15 = Cerebos-eCQAHANADB1-AGEAS-SVED1HDBSRV01.xsportal.local 

sng01ammhana002.xsportal.local	10.116.103.238	root/FhUhfn8v

C:\Users\IBM_ADMIN\Documents\A0DIML014XVM016-performance.xls




1-335586811	sev1
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1250919] Date: Mar 14,2018 18:54 CUT Severity: Minor ResourceId: sahodmsd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ch5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 17.99 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: SAHODMSD.imzcloud.ibmammsap.local NodeAlias: 10.7.12.50 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3530771:ch5

[root@SAHODMSD ibmrmalik]# df -k /
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      10190136 8077744   1588104  84% /

[root@SAHODMSD /]# find . -xdev -type f -size +1000000
./sapstage/tmp/SWPM10SP10_3-20009701.SAR
./sapstage/tmp/70SWPM10SP10_3-20009701.sar
./sapstage/tmp/70SWPM10SP09_8-20009701.sar





1-335586751  sev2
Summary: Lack_of_free_swap_space_on_prdsap1app.imzcloud.ibmammsap.local[PROBLEM:1250830] Date: Mar 14,2018 18:41 CUT Severity: Major ResourceId: prdsap1app TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.73 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: prdsap1app.imzcloud.ibmammsap.local NodeAlias: 10.74.5.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3530755:mtb

[root@prdsap1app ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         57          5         27          0         28
-/+ buffers/cache:         28         34
Swap:            7          4          3


top - 01:11:13 up 272 days, 20:26,  2 users,  load average: 0.40, 0.45, 0.52
Tasks: 514 total,   2 running, 512 sleeping,   0 stopped,   0 zombie
Cpu(s): 21.6%us,  1.5%sy,  0.0%ni, 76.7%id,  0.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    62.903G total,   57.547G used, 5484.113M free,  315.473M buffers
Swap: 8191.996M total, 4268.145M used, 3923.852M free,   28.975G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 82304 hp6adm    20   0 2555m 996m  528 S  0.0  1.5   5:23.72 1.5g sapxpg
 19225 root      20   0  652m  460  456 S  0.0  0.0   0:02.28 278m sapinstexe
 19241 root      20   0 3368m 190m 2180 S  0.0  0.3 196:31.77 114m java
 19302 root      20   0 3138m 174m 2208 S  0.0  0.3 219:23.62  49m java
 29834 daaadm    20   0 5162m 304m 4708 S  0.0  0.5   1130:58  40m jstart
  4602 root      20   0  284m 1736 1152 S  0.0  0.0   6:20.72  27m gnome-screens
  2483 root      20   0  301m  45m 1592 S  0.0  0.1 158:26.67  23m vmtoolsd
 30192 root      20   0 2176m  66m 3788 S  0.0  0.1  70:06.53  19m ksaagent
 29547 daaadm    20   0  185m 2912  688 S  0.0  0.0   0:01.73  18m jc.sapDAA_SMD
 66562 root      20   0  257m  38m 1016 S  0.0  0.1   0:21.84  16m chef-client
 73607 hp6adm    20   0  971m  63m  22m S  0.0  0.1  24:05.09  11m sapstartsrv
125974 sapadm    20   0  926m  23m 2768 S  0.0  0.0 150:55.60  11m sapstartsrv



1-335596481	sev2	DOne
Summary: NTP_time_is_driffted_on_LONMAGHAN0001.imzcloud.ibmammsap.local[PROBLEM:1255656] Date: Mar 15,2018 6:33 CUT Severity: Warning ResourceId: lonmaghan0001 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.27 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LONMAGHAN0001.imzcloud.ibmammsap.local NodeAlias: 10.69.0.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3532177:mng

[root@LONMAGHAN0001 ibmrmalik]# ntpstat
unsynchronised
   polling server every 64 s
[root@LONMAGHAN0001 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
+lon02ammadc001. 146.89.140.75    7 u    1   64    1    0.571  -19.137  19.498
*lon02ammadc002. 146.89.140.74    7 u    1   64    1    0.483  135.105   1.060



1-335602761	sev3
 [PROBLEM:1255543] Date: Mar 15,2018 6:16 CUT Severity: Warning ResourceId: cldproappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.19 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CLDPROAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.75 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3532125:sm5

[root@CLDPROAPPP1 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 sng01ammadc001. 146.89.140.139   7 u    2   64    1    1.635   -2.144   0.607
 sng01ammadc002. 146.89.140.138   7 u    2   64    1    0.787   23.767   0.388
[root@CLDPROAPPP1 ibmrmalik]# ntpstat
unsynchronised
   polling server every 64 s



1-335607731	sev1
Summary: Zabbix_agent_on_DASWEBDPDEV.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1259427] Date: Mar 15,2018 7:59 CUT Severity: Critical ResourceId: daswebdpdev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dst InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DASWEBDPDEV.imzcloud.ibmammsap.local NodeAlias: 10.14.6.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3532745:dst

------------------------------------------------------------------------------------------------------------------------------------------------

16 March


1-331386547	sev3
TSCM Healthcheck Linux OS Deviations for this customer are in the attachments tab. Please remediate any findings.




1-335622261    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBOQR1DB01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263585] Date: Mar 15,2018 16:12 CUT Severity: Critical ResourceId: ctuboqr1db01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOQR1DB01

.imzcloud.ibmammsap.local NodeAlias: 10.12.10.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534090:ctu

1-335622271    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBOSR1AP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263587] Date: Mar 15,2018 16:12 CUT Severity: Critical ResourceId: ctubosr1ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOSR1AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534091:ctu


1-335622301    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBOSR1DB01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263602] Date: Mar 15,2018 16:12 CUT Severity: Critical ResourceId: ctubosr1db01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOSR1DB01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534100:ctu


1-335622321    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBWDB3AP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263606] Date: Mar 15,2018 16:13 CUT Severity: Critical ResourceId: ctubwdb3ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBWDB3AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534105:ctu

1-335622361    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBOQR1AP03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263614] Date: Mar 15,2018 16:14 CUT Severity: Critical ResourceId: ctuboqr1ap03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOQR1AP03.imzcloud.ibmammsap.local NodeAlias: 10.12.10.27 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534112:ctu

1-335622371    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBWSB3AP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263615] Date: Mar 15,2018 16:14 CUT Severity: Critical ResourceId: ctubwsb3ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBWSB3AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534113:ctu

1-335624311    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBOSR1SP02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263586] Date: Mar 15,2018 16:12 CUT Severity: Critical ResourceId: ctubosr1sp02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOSR1SP02.imzcloud.ibmammsap.local NodeAlias: 10.12.10.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534089:ctu

1-335624321    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBODR1AP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263588] Date: Mar 15,2018 16:12 CUT Severity: Critical ResourceId: ctubodr1ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBODR1AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534092:ctu


1-335624341    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUWDPNPAP02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263593] Date: Mar 15,2018 16:12 CUT Severity: Critical ResourceId: ctuwdpnpap02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUWDPNPAP02.imzcloud.ibmammsap.local NodeAlias: 10.12.12.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534094:ctu

1-335624411    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBOQR1AP02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263601] Date: Mar 15,2018 16:12 CUT Severity: Critical ResourceId: ctuboqr1ap02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOQR1AP02.imzcloud.ibmammsap.local NodeAlias: 10.12.10.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534099:ctu


1-335624491    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBODR1AP02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263605] Date: Mar 15,2018 16:13 CUT Severity: Critical ResourceId: ctubodr1ap02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBODR1AP02.imzcloud.ibmammsap.local NodeAlias: 10.12.10.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534104:ctu


1-335624521    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBODR1DB01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263608] Date: Mar 15,2018 16:13 CUT Severity: Critical ResourceId: ctubodr1db01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBODR1DB01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534108:ctu


1-335624531    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_ctuwdpnpap01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263610] Date: Mar 15,2018 16:13 CUT Severity: Critical ResourceId: ctuwdpnpap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ctuwdpnpap01.imzcloud.ibmammsap.local NodeAlias: 10.12.12.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534109:ctu

1-335624591    COTY Inc (CTU)    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_CTUBOQR1AP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1263613] Date: Mar 15,2018 16:14 CUT Severity: Critical ResourceId: ctuboqr1ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOQR1AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.25 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534111:ctu



1-335641341	sev1
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1269070] Date: Mar 16,2018 3:9 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3535766:amm

top - 22:14:14 up 128 days, 15:22,  1 user,  load average: 51.26, 49.08, 30.36
Tasks: 502 total,   1 running, 501 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.4%us,  0.6%sy,  0.0%ni, 45.7%id, 52.8%wa,  0.0%hi,  0.5%si,  0.0%st
Mem:    31.316G total,   30.720G used,  610.312M free, 2150.824M buffers
Swap: 1023.996M total, 1023.996M used,    0.000k free,   15.982G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
27514 db2wsm    20   0 17.2g 7.9g 7.3g S  2.1 25.2   9476:27  56m db2sysc
14874 wsmadm    20   0 9600m 4.5g  15m S  0.0 14.5 719:21.26  46m jlaunch
27512 root      20   0 1237m  34m  16m S  0.0  0.1   0:00.18  26m db2syscr
27521 root      20   0 1239m  30m  12m S  0.0  0.1  11:14.87  25m db2syscr
27522 root      20   0 1239m  30m  12m S  0.0  0.1  11:14.90  25m db2syscr
27523 root      20   0 1239m  30m  12m S  0.0  0.1  11:15.23  25m db2syscr
 5716 daaadm    20   0 4978m 363m 7940 S  0.0  1.1 885:43.95  17m jstart
 5738 root      20   0  257m  42m 2032 S  0.0  0.1   0:08.61  13m chef-client
 4611 sapadm    20   0 1100m  46m 5000 S  0.0  0.1 287:18.54  13m sapstartsrv
14875 wsmadm    20   0 2888m 196m 5712 S  0.0  0.6  77:39.25  13m jlaunch
 6052 root      20   0 2778m  82m 4596 S  0.0  0.3  19:58.50  12m ksaagent
 5477 daaadm    20   0  459m 6968 2024 S  0.0  0.0   1:36.50  11m sapstartsrv
13437 wsmadm    20   0 6894m  67m  33m S  0.0  0.2   0:02.32  10m WSM_50_UP2_W39
 5349 wsmadm    20   0 1069m  46m  28m S  0.0  0.1  14:27.61   9m sapstartsrv
13418 wsmadm    20   0 6894m  67m  32m S  0.0  0.2   0:02.36 9240 WSM_50_UPD_W20
 5108 wsmadm    20   0  824m  23m 3896 S  0.0  0.1  12:41.49 9196 sapstartsrv
 4853 wsmadm    20   0  824m  22m 3828 S  0.0  0.1  12:42.74 9172 sapstartsrv
13436 wsmadm    20   0 6894m  68m  32m S  0.0  0.2   0:02.31 8044 WSM_50_UP2_W38


[root@wdc04ammsol01 ~]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0         10          2         15
-/+ buffers/cache:         12         18
Swap:            0          0          0
[root@wdc04ammsol01 ~]#

[root@wdc04ammsol01 ~]# date
Thu Mar 15 22:17:00 CDT 2018

[root@wdc04ammsol01 ~]# vmstat
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0 15 1048572 618532 2203792 16759740    0    0   218   105    0    0 15  0 80  5  0
[root@wdc04ammsol01 ~]#

[root@wdc04ammsol01 ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4544) is running...
[root@wdc04ammsol01 ~]# uptime
 22:13:22 up 128 days, 15:21,  1 user,  load average: 52.87, 48.91, 29.27




1-335629111	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_D:[PROBLEM:1264899] Date: Mar 15,2018 18:22 CUT Severity: Major ResourceId: ri3lr020 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_D: InstanceValue: 10 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: DAL09AMMTS002 NodeAlias: 146.89.140.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_D: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3534528:mic



1-335649691	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1270104] Date: Mar 16,2018 5:48 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3536127:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      53273100 13042452  37518608  26% /



1-335609791	sev2
fmsprdlipa002.imzcust.ibmammsap.local   10.143.109.111 ,  Unable to connect to this server with IMZ user/password.  Backup failed. Please check





1-335647491
Summary: Free_disk_space_is_less_than_5%_on_volume_C:[PROBLEM:1270062] Date: Mar 16,2018 5:44 CUT Severity: Critical ResourceId: bi1intgrprdvm TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: bi1 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 5 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: BI1INTGRPRDVM NodeAlias: 10.135.3.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3536117:bi1




1-335324321
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/log[PROBLEM:1166469] Date: Mar 7,2018 15:52 CUT Severity: Minor ResourceId: bi1crmdbprd01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 19.94 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1CRMDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3511108:bi1

[root@BI1CRMDBPRD01 ibmrmalik]# cd  /hana/log
[root@BI1CRMDBPRD01 log]# du -mch --max-depth=1 .
3.2G    ./mnt00001
486G    ./backuplog
489G    .
489G    total


[root@BI1CRMDBPRD01 ibmrmalik]# df -k /hana/log
Filesystem     1K-blocks      Used Available Use% Mounted on
/dev/sdd1      538696704 512077524  26619180  96% /hana/log


--------------------------------------------------------------------------------------------------------------------------------------
19 March

1-335613231
Hi Team, Please validate or reconfigure monitoring. The account is going live and we need quick help:
CI3S4HANADEVA  10.201.0.16
CI3S4HANADEV  10.201.0.15



1-335617981	sev3
*** Details of Generic Service Request - DO NOT CHANGE ***

Please grand access to HR FTP server from DEC

FTP server detail "FTP:182.74.223.121"
Folder from FTP server \DBL_empclock/Development

DEC folder is \DBL_EMPCLOCK\New

We want to move all the data from FTP server to DEC twice in day 
1.1:30 AM
2.4:30 AM

Please let me know is any additional information is required..

FTP:182.74.223.121
USERNAME:Â Administrator
PASSWORD: dblams@12345


Please find detail fro DEC system..
Hostname	DLBDECAP01
CFN IP		172.16.22.13		IMZ 10.13.2.13

DEC folder is \DBL_EMPCLOCK\New

Please add this in conntab jobs

"move *.* from DBL_empclock/Development to DBL_empclock/new"
Source directory is of ftp server & target directory is of SAP server directory..




1-335007691	sev3
Summary: FS_is_read_only_on_CTUBWQB1AP01.imzcloud.ibmammsap.local[PROBLEM:1061717] Date: Feb 27,2018 5:43 CUT Severity: Minor ResourceId: ctubwqb1ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /run/user/0/gvfs /run/user/0/gvfs filesystems are rea ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: CTUBWQB1AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3486605:ctu

CTUBWQB1AP01:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /run/user/0/gvfs /run/user/0/gvfs filesystems are read-only

CTUBWQB1AP01:/home/ibmrmalik # df -k /run/user/0/gvfs
Filesystem     1K-blocks  Used Available Use% Mounted on
gvfsd-fuse             0     0         0    - /run/user/0/gvfs

CTUBWQB1AP01:/etc/init.d # cat /etc/SuSE-release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 2
# This file is deprecated and will be removed in a future service pack or release.
# Please check /etc/os-release for details about this release.

CTUBWQB1AP01:/home/ibmrmalik # cat /etc/fstab |grep gvfs
CTUBWQB1AP01:/home/ibmrmalik #

/dev/qb1appvg/sapstage_lv       /sapstage       ext3    _netdev,defaults       1                                                                                                                     2


CTUBWQB1AP01:/home/ibmrmalik # df -k /run/user/0
Filesystem     1K-blocks  Used Available Use% Mounted on
tmpfs            3294764    44   3294720   1% /run/user/0
CTUBWQB1AP01:/home/ibmrmalik # df -k /run/user/0/gvfs
Filesystem     1K-blocks  Used Available Use% Mounted on
gvfsd-fuse             0     0         0    - /run/user/0/gvfs





1-335669961 sev1	DONE
Summary: SAP: HostActive: no and HostStatus: error on host tqabwprdh Date: 03/16/2018 Severity: Critical ResourceId: tqabwprdh TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: tqa InstanceId: HostActive: no - HostStatus: error InstanceValue: ? InstanceSituation: Host Status not Ok ComponentType: ComputerSystem Component: ITM6Agent SubComponent: HANASTATUS ApplId: SAP Node: TQABWPRDH NodeAlias: TQABWPRDH Manager: TQABWPRDH Agent: EIF Probe on ri3pa010 AlertKey: msd_hanastat1_g5hf_stdv1 AlertGroup: ITM_K5H_HANA_STATUS EventKey: USRD0P0MSDP:3537119:tqa







1-335007691	sev3
NodeAlias: 10.12.10.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3486605:ctu
CTUBWQB1AP01:/etc/init.d # cat /etc/SuSE-release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 2
# This file is deprecated and will be removed in a future service pack or release.
# Please check /etc/os-release for details about this release.






1-335660691	sev3	DLBPCSDA00
Need to create FS - /usr/sap/DAA with 6GB space of IP 10.13.1.18
[root@DLBPCSDA00 usr]# df -k /usr
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      10190136 2295772   7370076  24% /

[root@DLBPCSDA00 usr]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   1   7   0 wz--n- 39.51g 2.50g

[root@DLBPCSDA00 usr]# vgs
  VG         #PV #LV #SN Attr   VSize   VFree
  VolGroup     1   7   0 wz--n-  39.51g   2.50g
  pcssapdbvg   1  11   0 wz--n- 800.00g 571.00g

[root@DLBPCSDA00 usr]# df -hT /usr
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                     ext4  9.8G  2.2G  7.1G  24% /

vgextend VolGroup /dev/sdc

lvcreate -L 6G -n usrsapdaa_lv VolGroup

mount -t ext4 /dev/mapper/VolGroup/usrsapdaa_lv /usr/sap/DAA

mount -t ext4 block_device /mount/point 

/dev/mapper/VolGroup-usrsapdaa_lv /usr/sap/DAA ext4 defaults 1 2



For ref system IP - 10.13.1.21, FS -/usr/sap/DAA already created
[root@DLBPEPDA00 ibmrmalik]# df -k /usr/sap/DAA
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/pepappvg-usrsapdaa_lv
                       4128448 1699240   2219496  44% /usr/sap/DAA

[root@DLBPEPDA00 ibmrmalik]# lsblk |grep usrsapdaa_lv
Ã¢Ã¢pepappvg-usrsapdaa_lv (dm-19)    253:19   0    4G  0 lvm  /usr/sap/DAA

[root@DLBPEPDA00 ibmrmalik]# df -hT /usr/sap/DAA
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/pepappvg-usrsapdaa_lv
                     ext3  4.0G  1.7G  2.2G  44% /usr/sap/DAA

drwxrwxr-x  5 daaadm sapsys  4096 Mar 13 17:24 DAA


[root@DLBPEPDA00 usr]# ls -ltr |grep sap
drwxr-xr-x    9 pepadm sapsys  4096 Mar 13 17:24 sap

--------------------------------------------------------------------------------------------------------------------------------------------

20 Mar


1-335194831	sev3	10.140.48.172	root/L7a7d92Q		Ticket 57044785 
Summary: Drive_with_Errors_on_monhana-1024-25.xsportal.local[PROBLEM:1124629] Date: Mar 4,2018 8:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_monhana-1024-25.xsportal.local InstanceValue: 8:9 32 UBad - 558.406 GB SAS HDD N N 512B ST600MP0005 U - ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_monhana-1024-25. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_monhana-1024-25.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3500811:amm


1-335426461	sev3	10.164.30.138	root/K5Fzym54		TICKET 57057743
Summary: Drive_with_Errors_on_lonhana-1024-16.xsportal.local[PROBLEM:1200500] Date: Mar 10,2018 8:10 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_lonhana-1024-16.xsportal.local InstanceValue: Media Error Count = 3 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_lonhana-1024-16. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_lonhana-1024-16.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3519106:amm


1-335451801	sev3	10.164.30.155	root/YFu4mc6l	ticket 57057145 
Summary: Drive_with_Errors_on_lonhana-1024-10.xsportal.local[PROBLEM:1210578] Date: Mar 11,2018 8:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_lonhana-1024-10.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_lonhana-1024-10. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_lonhana-1024-10.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3521430:amm


1-335496091	sev3	asked in AMM delivery 
Summary: Chef_Client_is_not_running_on_LON02AMMZAB001.imzcloud.ibmammsap.local[PROBLEM:1223817] Date: Mar 12,2018 15:12 CUT Severity: Minor ResourceId: lon02ammzab001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Chef_status ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Chef_status Node: LON02AMMZAB001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.84 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Chef_status AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3524442:amm


1-335519271	sev3	10.116.103.238	root/FhUhfn8v	ticket 57054637
Summary: Drive_with_Errors_on_sng01ammhana002.xsportal.local[PROBLEM:1230911] Date: Mar 13,2018 7:0 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_sng01ammhana002.xsportal.local InstanceValue: Media Error Count = 11 Media Error Count = 4 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_sng01ammhana002. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_sng01ammhana002.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3526405:amm


1-335519341	sev3	10.113.60.236     root/RmQCqHb4	Ticket 57050913
Summary: Drive_with_Errors_on_CFG-LONCFGCEQ0001-LONCFGCCQ0002.xsportal.local[PROBLEM:1230952] Date: Mar 13,2018 7:6 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_CFG-LONCFGCEQ0001-LONCFGCCQ0002.xsportal.local InstanceValue: Media Error Count = 1 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_CFG-LONCFGCEQ000 Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_CFG-LONCFGCEQ0001-LONCFGCCQ0002.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3526421:amm



1-335519411	sev3	10.166.156.223	root/T3M3Slfy	Ticket 57047763
Summary: Drive_with_Errors_on_torhana-1024-19.xsportal.local[PROBLEM:1230964] Date: Mar 13,2018 7:8 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_torhana-1024-19.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_torhana-1024-19. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_torhana-1024-19.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3526431:amm



1-335533921
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/data[PROBLEM:1233687] Date: Mar 13,2018 12:57 CUT Severity: Minor ResourceId: lon02ammzab001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/data InstanceValue: 19.72 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: LON02AMMZAB001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.84 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3527075:amm

[root@LON02AMMZAB001 ~]# df -k /data
Filesystem                1K-blocks      Used Available Use% Mounted on
/dev/mapper/datavg-datalv 723497988 643086964  80411024  89% /data

[root@LON02AMMZAB001 data]# find . -xdev -type f -size +1000000
./mysql/ibdata1






1-335539701	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_E:[PROBLEM:1234696] Date: Mar 13,2018 14:58 CUT Severity: Minor ResourceId: ri3lr019 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_E: InstanceValue: 19.93 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: DAL09AMMTS001 NodeAlias: 146.89.140.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_E: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3527325:mic



1-335580701	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sapmnt/shared[PROBLEM:1245307] Date: Mar 14,2018 14:18 CUT Severity: Minor ResourceId: tqaerpprdh TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/shared InstanceValue: 10.73 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQAERPPRDH.imzcloud.ibmammsap.local NodeAlias: 10.7.1.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/shared AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3530192:tqa

[root@TQAERPPRDH ibmrmalik]# df -k /sapmnt/shared
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/mapper/vghanadata-lv_hana_shared
                     268300288 248602008  19698280  93% /sapmnt/shared



1-335738131	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1300275] Date: Mar 19,2018 9:30 CUT Severity: Critical ResourceId: su6sunecq00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: su6 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0.16 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: SU6SUNECQ00.imzcloud.ibmammsap.local NodeAlias: 10.13.3.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3544722:su6


[root@SU6SUNECQ00 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      31864752 30191924     47804 100% /


[root@SU6SUNECQ00 oracle]# du -mch --max-depth=1 .
16K     ./lost+found
293M    ./client
8.1G    ./stage
710G    ./ECQ
1.2M    ./oraInventory
718G    .
718G    total

[root@SU6SUNECQ00 oralce]# du -mch --max-depth=1 .
26G     ./ECQ
26G     .
26G     total

[root@SU6SUNECQ00 /]# find . -xdev -type f -size +1000000
./oralce/ECQ/sapdata5/sr3_15/sr3.data15
./oralce/ECQ/sapdata5/sr3_5/sr3.data5
./oralce/ECQ/sapdata5/sr3_27/sr3.data27
./oralce/ECQ/sapdata5/sr3_34/sr3.data34
./oralce/ECQ/sapdata5/sr3_21/sr3.data21

-----------------------------------------------------------------------------------------------------------------------------------------

21 March


1-335788031	sev3
Summary: NTP_time_is_driffted_on_IA2SCCDEVAGE.imzcloud.ibmammsap.local[PROBLEM:1317268] Date: Mar 20,2018 23:17 CUT Severity: Warning ResourceId: ia2sccdevage TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 5.05 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: IA2SCCDEVAGE.imzcloud.ibmammsap.local NodeAlias: 10.133.16.51 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3550739:ia1


[root@IA2SCCDEVAGE ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
*lon02ammadc001. 146.89.140.75    7 u 1019 1024  377    0.701  5138.38  62.948
 lon02ammadc002. 146.89.140.74    7 u  975 1024  377    0.741  5100.20  76.779
[root@IA2SCCDEVAGE ibmrmalik]# ntpstat
synchronised to NTP server (146.89.140.76) at stratum 8
   time correct to within 5780 ms
   polling server every 1024 s

[root@IA2SCCDEVAGE ibmrmalik]# /etc/init.d/ntpd restart
Shutting down ntpd:                                        [  OK  ]
Starting ntpd:                                             [  OK  ]


[root@IA2SCCDEVAGE ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 lon02ammadc001. 146.89.140.75    7 u    2   64    1    0.750   -1.887   0.000
 lon02ammadc002. 146.89.140.74    7 u    2   64    1    0.729    1.942   0.000
[root@IA2SCCDEVAGE ibmrmalik]# ntpstat
unsynchronised
   polling server every 64 s



1-335782651	sev2
Summary: Lack_of_free_swap_space_on_fbtprdhanapp2.imzcloud.ibmammsap.local[PROBLEM:1316529] Date: Mar 20,2018 21:49 CUT Severity: Major ResourceId: fbtprdhanapp2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.94 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: fbtprdhanapp2.imzcloud.ibmammsap.local NodeAlias: 10.4.27.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3550505:fbt

[root@fbtprdhanapp2 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         62          0         10          0         10
-/+ buffers/cache:         51         11
Swap:           63         32         31

top - 18:47:43 up 266 days,  3:06,  1 user,  load average: 0.03, 0.01, 0.00
Tasks: 433 total,   1 running, 432 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.1%us,  0.1%sy,  0.0%ni, 99.8%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.909G total,   62.491G used,  428.805M free,   33.992M buffers
Swap:   64.000G total,   32.660G used,   31.340G free,   10.595G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
24618 s4padm    20   0 79.7g  34g  18m S  0.0 54.4  10:43.21  20g icman
29147 s4padm    20   0 53.7g 3.0g 2.7g S  0.0  4.7   9:24.97 350m S4P_02_DIA_W26
 6096 s4padm    20   0 53.3g 967m 913m S  0.0  1.5   0:47.44 195m S4P_02_DIA_W2





1-334722521	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_C:[PROBLEM:965339] Date: Feb 19,2018 14:23 CUT Severity: Minor ResourceId: dlthdbbsi02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: DLTHDBBSI02 NodeAlias: 10.4.5.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3464009:dal



1-335784001	sev3
Summary: NTP_time_is_driffted_on_sjmqpqdb01.imzcloud.ibmammsap.local[PROBLEM:1316063] Date: Mar 20,2018 20:45 CUT Severity: Warning ResourceId: sjmqpqdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -6.25 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmqpqdb01.imzcloud.ibmammsap.local NodeAlias: 10.198.12.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3550304:ju1

[root@sjmqpqdb01 ibmrmalik]# ntpstat
synchronised to unspecified at stratum 8
   time correct to within 1343 ms
   polling server every 1024 s
[root@sjmqpqdb01 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 sng01ammadc001. 146.89.140.139   7 u  599 1024  377    0.499  -12803. 1069.28
 sng01ammadc002. 146.89.140.138   7 u  372 1024  377    0.545  -12895. 1085.09
[root@sjmqpqdb01 ibmrmalik]# /etc/init.d/ntpd restart
Shutting down ntpd:                                        [  OK  ]
Starting ntpd:                                             [  OK  ]
[root@sjmqpqdb01 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 sng01ammadc001. 146.89.140.139   7 u    1   64    1    0.505   -1.760   0.145
 sng01ammadc002. 146.89.140.138   7 u    1   64    1    0.537  -29.034   0.136
[root@sjmqpqdb01 ibmrmalik]# ntpstat
unsynchronised
   polling server every 64 s
[root@sjmqpqdb01 ibmrmalik]# ntpstat
unsynchronised
   polling server every 64 s




1-335691941    IBM MSD Infras - Cloud MONITORING    2-Urgent    AMM-DELIVERY-TECH
Summary: Free_disk_space_is_less_than_10%_on_volume_F:[PROBLEM:1280386] Date: Mar 17,2018 7:15 CUT Severity: Major ResourceId: ri3lr020 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: InstanceValue: 9.56 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: DAL09AMMTS002 NodeAlias: 146.89.140.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3538822:mic

F:\Balaji	10.7 GB
F:\BOBJ 4.2 SP05 - Linux	5.39 GB
F:\Bojangles	9.83 GB
F:\Cerebos	5.26 GB
F:\ERC_Solman_72	12.5GB
F:\IAG	4.72 GB
F:\ibmgkunadharaju	8.71 GB
F:\ibmklin	4.79 GB
F:\Mohan	9.41 GB
F:\Sancor	30 GB
F:\shrikant_do_not_delete	3.8 GB
F:\SMRT	9.43 GB
F:\Solman72SP06	11.6 GB
F:\Suncor	8.3 GB



1-335684371 
Summary: Lack_of_free_swap_space_on_CHE01AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:1278340] Date: Mar 17,2018 1:41 CUT Severity: Major ResourceId: ri3pa004 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: psf InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: CHE01AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.142.100 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3538372:psf

[root@CHE01AMMSOL04 ~]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          4          0         10
-/+ buffers/cache:          4         11
Swap:            7          3          4


top - 03:47:58 up 195 days, 12:15,  1 user,  load average: 0.05, 0.10, 0.06
Tasks: 360 total,   1 running, 359 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.9%us,  0.7%sy,  0.0%ni, 98.3%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.379G used,  187.234M free,  507.941M buffers
Swap: 8191.996M total, 3994.938M used, 4197.059M free,   10.628G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 19198 db2cm1    20   0 10.2g 3.7g 3.4g S  0.0 23.8   6886:40 137m db2sysc
 25915 db2cm1    20   0 1327m  69m 5392 S  0.0  0.4  16:53.01 114m db2fmp
 31773 daaadm    20   0 3662m 1.2g 4576 S  0.3  7.7   1165:11 104m java
 24230 cm1adm    20   0 1821m  18m 9028 S  0.0  0.1  22:58.69  95m icman
 57220 cm1adm    20   0 6956m  57m  57m S  0.0  0.4   0:03.15  65m CM1_00_UPD_W2
 89902 cm1adm    20   0 6953m  37m  34m S  0.0  0.2   0:04.07  63m CM1_00_UPD_W2





1-335617981	sev3
*** Details of Generic Service Request - DO NOT CHANGE ***

Please grand access to HR FTP server from DEC

FTP server detail "FTP:182.74.223.121"
Folder from FTP server \DBL_empclock/Development

DEC folder is \DBL_EMPCLOCK\New

We want to move all the data from FTP server to DEC twice in day 
1.1:30 AM
2.4:30 AM

Please let me know is any additional information is required..

FTP:182.74.223.121
USERNAME: Administrator
PASSWORD: dblams@12345


Please find detail fro DEC system..
Hostname	DLBDECAP01
CFN IP		172.16.22.13		IMZ 10.13.2.13

DEC folder is \DBL_EMPCLOCK\New

Please add this in conntab jobs

"move *.* from DBL_empclock/Development to DBL_empclock/new"
Source directory is of ftp server & target directory is of SAP server directory.. 

------------------------------------------------------------------------------------------


22 Mar


	1-335806971	sev3
Dilip: Info needed for Pre Go live checks
lscpu



1-335837541	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1325147] Date: Mar 22,2018 2:50 CUT Severity: Critical ResourceId: tqaerpdevh TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: tqa InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 5 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: TQAERPDEVH.imzcloud.ibmammsap.local NodeAlias: 10.7.1.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3554010:tqa


[root@TQAERPDEVH ibmrmalik]# df -k /
Filesystem     1K-blocks     Used Available Use% Mounted on
/dev/sda3       51271300 48073508    586644  99% /

[root@TQAERPDEVH /]# find . -xdev -type f -size +1000000
./opt/monitor/tivoli/client/jacclient.log.1
./swdeploy/hanadb/IMDB_SERVER100_95_0-10009569.SAR
./swdeploy/hanadb/IMC_STUDIO2_95_0-80000321.SAR

-rw-------  1 root root 39945698478 Mar 22 05:29 jacclient.log.1
[root@TQAERPDEVH client]# pwd
/opt/monitor/tivoli/client


[root@TQAERPDEVH client]# ps -ef|grep jacclient
root      3333     1  0 Feb20 ?        00:00:00 /bin/sh /opt/monitor/tivoli/client/jacclient start




1-335791611  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)  Sev1
Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local[PROBLEM:1318122] Date: Mar 21,2018 1:36 CUT Severity: Critical ResourceId: c1bwp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3551013:pnc

[root@C1BWP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK





1-335837421  - Sev1 - FBT - SAP HEC-AMM - Siebel - Not Validated - Free_disk_space_is_less_than_5%_on_OS_volume_/var
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var[PROBLEM:1325056] Date: Mar 22,2018 2:25 CUT Severity: Critical ResourceId: fbtprdhanapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: fbtprdhanapp1.imzcloud.ibmammsap.local NodeAlias: 10.4.27.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3553970:fbt

[root@fbtprdhanapp1 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 1763792   3007372  37% /var



1-335792141	sev2
Summary: Lack_of_free_swap_space_on_DLBPSMDA00.imzcloud.ibmammsap.local[PROBLEM:1318717] Date: Mar 21,2018 3:2 CUT Severity: Major ResourceId: dlbpsmda00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.8 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: DLBPSMDA00.imzcloud.ibmammsap.local NodeAlias: 10.13.1.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3551151:dlb

[root@DLBPSMDA00 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          8          0         11
-/+ buffers/cache:         18         12
Swap:            7          4          3


top - 12:30:22 up 407 days,  4:46,  2 users,  load average: 0.90, 0.35, 0.29
Tasks: 456 total,   2 running, 454 sleeping,   0 stopped,   0 zombie
Cpu(s): 91.9%us,  5.6%sy,  0.0%ni,  1.3%id,  0.7%wa,  0.0%hi,  0.5%si,  0.0%st
Mem:    31.358G total,   28.070G used, 3366.965M free,   41.887M buffers
Swap: 8191.996M total, 4752.480M used, 3439.516M free, 9478.578M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 9942 psaadm    20   0 2056m 373m  20m S  0.0  1.2   0:34.96 209m icman
 8649 root      20   0  305m  57m 1564 S  0.0  0.2 446:02.11  61m koy15col
28674 root      20   0  324m  40m 1272 S  0.0  0.1 229:53.06  51m vmtoolsd
22046 psjadm    20   0 7133m 2.8g  36m S  0.7  8.8  55:01.39  40m jstart
27095 daaadm    20   0 2134m 332m 8324 S  0.3  1.0   1129:03  26m jstart
 7547 root      20   0 1554m  57m 3872 S  0.0  0.2  33:15.04  22m ksaagent
11973 root      20   0  257m  34m 1104 S  0.0  0.1   0:21.26  22m chef-client
19299 daaadm    20   0  185m  924  476 S  0.0  0.0   0:01.96  20m jc.sapDAA_SMDA
 7921 root      20   0 1730m  10m 2596 S  0.0  0.0  12:59.57  13m kuma620
 8650 root      20   0 1465m 9744 2488 S  0.0  0.0  12:08.58  13m koyagent
 9905 psaadm    20   0  888m  28m 1960 S  0.0  0.1   1:01.66 6144 igspw_mt
 9904 psaadm    20   0  888m  29m 1960 S  0.0  0.1   1:01.71 5028 igspw_mt
21089 psjadm    20   0  835m  27m 1912 S  0.0  0.1   0:57.16 4096 igspw_mt
21090 psjadm    20   0  835m  27m 1912 S  0.3  0.1   0:57.75 4096 igspw_mt

[root@DLBPSMDA00 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         27          4          8          0          8
-/+ buffers/cache:         18         13
Swap:            7          4          3




1-334842972	
Customer: Ageas B.V.
Reported by: A. A. Thombare
Phone: +31 302525304
E-Mail: amit.anil.thombare@sap.com
Priority: 2: High
SAP Incident Number: 0000090824/2018


Description:
02/22/2018   01:04:22   S0017935590

User Creation in SAP CC Production server
____________________
Business Consequences
02/22/2018   01:04:21   S0017935590

User Creation in SAP CC Production server
____________________
Description
02/22/2018   01:04:20   S0017935590

Hi Team,
User need to be created in SAP Contact center server.
Host - 
cccp2srv0  
cccp3srv0

10.6.3.48
10.6.3.49

 
Attached User request form.
 
Regards
Vivek


---------------------------------------------------------------------------------------------------------------------------------------------

23 March

MSC Industrial Supply Co.
1-335550555
Please add 1GB to mount point on BP1:
/dev/mapper/bp1appvg-usrsapdaa_lv
                      2.0G  1.9G   14M 100% /usr/sap/DAA
[root@ms3wdcladb41 ibmrmalik]# df -k /usr/sap/DAA
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/bp1appvg-usrsapdaa_lv
                       6192704 1957444   3920740  34% /usr/sap/DAA



ms3wdcladb41:File System Full	10.12.7.28





1-335423581 | Lack_of_free_swap_space_on_SSGSA0121
Summary: Lack_of_free_swap_space_on_SSGSA0121.imzcloud.ibmammsap.local[PROBLEM:1198284] Date: Mar 10,2018 3:10 CUT Severity: Major ResourceId: ssgsa0121 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mmd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.2 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SSGSA0121.imzcloud.ibmammsap.local NodeAlias: 100.126.0.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3518615:mmd


[root@SSGSA0121 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          5          0          6
-/+ buffers/cache:          8          7
Swap:            7          6          1

top - 03:09:23 up 21 days, 22:56,  1 user,  load average: 0.20, 0.19, 0.18
Tasks: 309 total,   1 running, 308 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.9%us,  0.9%sy,  0.0%ni, 98.2%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.223G used,  347.652M free,  232.859M buffers
Swap: 8191.996M total, 6406.059M used, 1785.938M free, 6800.562M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 99411 mmpadm    20   0 1429m  24m 2444 S  0.0  0.2   8:19.06 772m en.sapMMP_ASCS
  4591 daaadm    20   0 2110m 187m 6704 S  0.0  1.2  81:57.59 120m jstart
101567 mmpadm    20   0 2376m  29m 7080 S  0.0  0.2   0:42.40 105m icman
  4256 mmpadm    20   0 1086m  38m  20m S  0.0  0.2   3:53.20  43m sapstartsrv
101538 mmpadm    20   0 10.8g  18m  15m S  0.0  0.1   3:07.01  28m MMP_00_DP
  4595 root      20   0  250m  23m 1704 S  0.0  0.1   0:01.82  27m chef-client
108954 root      20   0 1526m  22m 3792 S  0.0  0.1   1:17.70  26m ksaagent
101542 mmpadm    20   0 1218m 6968 1632 S  0.0  0.0   3:18.98  26m igsmux_mt
  2403 root      20   0  927m  53m 5440 S  0.0  0.3  18:37.58  22m ds_agent
 62218 mmpadm    20   0 10.8g  52m  35m S  0.0  0.3   0:02.04  21m MMP_00_UPD_W20
 64903 mmpadm    20   0 10.8g  52m  35m S  0.0  0.3   0:02.05  21m MMP_00_UPD_W22
 64924 mmpadm    20   0 10.8g  53m  35m S  0.0  0.3   0:02.05  21m MMP_00_UPD_W21
 64934 mmpadm    20   0 10.8g  54m  35m S  0.0  0.3   0:02.05  21m MMP_00_UPD_W23
 64945 mmpadm    20   0 10.8g  52m  35m S  0.0  0.3   0:02.06  21m MMP_00_UPD_W24
 64974 mmpadm    20   0 10.8g  52m  35m S  0.0  0.3   0:02.05  21m MMP_00_UP2_W37
 64977 mmpadm    20   0 10.8g  53m  35m S  0.0  0.3   0:02.05  21m MMP_00_UP2_W38
 64986 mmpadm    20   0 10.8g  52m  35m S  0.0  0.3   0:02.06  21m MMP_00_UP2_W39



1-335519710	sev3
Request that Violations in the attachment be remediated for SSGSA0118.
If you require downtime to restart apps and OS, let us know how much downtime you require from your end.


Please complete this urgently and if you have any questions, please send email to
janakip@au1.ibm.com




1-335882031	sev1
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1330808] Date: Mar 23,2018 3:8 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3556747:amm

[root@wdc04ammsol01 ibmrmalik]# uptime
 00:03:20 up 135 days, 17:11,  1 user,  load average: 0.69, 0.47, 0.35
[root@wdc04ammsol01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4544) is running...



1-335881481	sev3
Summary: Processor_load_is_too_high_on_AQAERPAPPPRD[PROBLEM:1330933] Date: Mar 23,2018 3:44 CUT Severity: Minor ResourceId: aqaerpappprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: aqa InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 10.5 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: AQAERPAPPPRD NodeAlias: 10.135.26.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3556827:aqa




1-335886311	sev1
*** Details of Generic Service Request - DO NOT CHANGE ***

Please update Server ERP-PRD (10.200.0.11) OS C++ runtime version according to SAP Note 2195019 (image attached)
10.7.1.11

[root@erp-prd ibmrmalik]# rpm -qa |grep -i C++
libstdc++-devel-4.4.7-18.el6.x86_64
dbus-c++-0.5.0-0.10.20090203git13281b3.1.el6.x86_64
libsigc++20-2.2.4.2-1.el6.x86_64
compat-libstdc++-33-3.2.3-69.el6.x86_64
libstdc++-4.4.7-18.el6.x86_64
compat-libstdc++-33-3.2.3-69.el6.i686


[root@oc5566852027 Desktop]# rpm -qa |grep -i C++
compat-libstdc++-33-3.2.3-69.el6.i686
libstdc++-devel-4.4.7-18.el6_9.2.x86_64
libsigc++20-2.2.4.2-1.el6.x86_64
compat-libstdc++-33-3.2.3-69.el6.x86_64
gcc-c++-4.4.7-18.el6_9.2.x86_64
libstdc++-4.4.7-18.el6_9.2.i686
dbus-c++-0.5.0-0.10.20090203git13281b3.1.el6.x86_64
compat-libstdc++-296-2.96-144.el6.i686
libstdc++-4.4.7-18.el6_9.2.x86_64
libstdc++-docs-4.4.7-18.el6_9.2.x86_64


libstdc++.so.6(GLIBCXX_3.4.14)(64bit)
libstdc++.so.6(GLIBCXX_3.4.15)(64bit)
libsecret-1.so.0()(64bit) 

scp /root/compat-sap-c++-4.8.2-16.el6.x86_64.rpm x.x.x.x:/root

   rpm -Uvh compat-sap-c++-4.8.2-16.el6.x86_64.rpm

   ln -s -f /opt/rh/SAP/lib64/compat-sap-c++.so /usr/lib64/libstdc++.so.6


---------------------------------------------------------------------------------------------------------------------------------------------------

26 March


1-335886311	sev1

Package: compat-sap-c++-4.8.2-16.el6.x86_64  

Servers:
BO-DEV (10.201.0.10)	10.7.2.10
[root@bo-dev ibmrmalik]# rpm -qa |grep -i compat-sap
compat-sap-c++-4.8.2-16.el6.x86_64


ERP-DEV (10.201.0.11)	10.7.2.11
[root@erp-dev ibmrmalik]# rpm -qa |grep -i compat-sap
compat-sap-c++-4.8.2-16.el6.x86_64



ERP-QAS (10.201.0.14)	10.7.2.14
[root@ERP-QAS tmp]# rpm -qa |grep compat-sap
compat-sap-c++-4.8.2-16.el6.x86_64

BW-PRD (10.200.0.12)	10.7.1.12
[root@bw-prd ibmrmalik]# rpm -qa |grep compat-sap
compat-sap-c++-4.8.2-16.el6.x86_64





1-336038301	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/hana/log[PROBLEM:1354037] Date: Mar 25,2018 19:47 CUT Severity: Critical ResourceId: bi1bwhdbprd01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 4.83 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1BWHDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3568859:bi1

[root@BI1BWHDBPRD01 ibmrmalik]# df -k /hana/log
Filesystem     1K-blocks      Used Available Use% Mounted on
/dev/sdd1      538696704 525407440  13289264  98% /hana/log

[root@BI1BWHDBPRD01 log]# du -mch --max-depth=1 .
15G     ./mnt00001
2.1G    ./BOP
456G    ./backuplog
502G    .
502G    total

[root@BI1BWHDBPRD01 backuplog]# du -mch --max-depth=1 .
54G     ./SYSTEMDB
374G    ./DB_HBP
28G     ./BOP
456G    .
456G    total





1-335014541	sev3
Scan for AV1 has 23 deviations review posted file at http://9.58.92.198/reports/3xHCD/2018_Q1_AV1_health_check_results.zip



1-336015931	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/hana/log[PROBLEM:1348529] Date: Mar 24,2018 19:49 CUT Severity: Major ResourceId: bi1bwhdbprd01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 9.8 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1BWHDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3566122:bi1


1-336034967	sev2
Add 20GB space to /usr/sap/PBJ FS

Details:
Server: 10.198.10.21
Hostname: sjmpbjdb01
Account:St Jude Medical Singapore - SAP HEC
DC: Singapore
FS: /usr/sap/PBJ

[root@sjmpbjdb01 ibmrmalik]# df -k /usr/sap/PBJ FS
df: `FS': No such file or directory
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pbjappvg-pbjusrPBJ_lv
                      56766780 41243868  12639712  77% /usr/sap/PBJ


[root@sjmpbjdb01 ibmrmalik]# vgs pbjappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  pbjappvg   2  13   0 wz--n- 147.99g 8.99g




1-336049011		sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var[PROBLEM:1356144] Date: Mar 26,2018 5:43 CUT Severity: Major ResourceId: dal09ammsrtr001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 7.93 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: dal09ammsrtr001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3569889:amm

[root@dal09ammsrtr001 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/vg00-var   1998672 1741124    152692  92% /var

[root@dal09ammsrtr001 var]# du -mch --max-depth=1 .
1.1G    ./opt
48K     ./tmp
39M     ./log
4.0K    ./games
58M     ./chef
140K    ./run
12K     ./lock
260K    ./spool
4.0K    ./nis
313M    ./cache
1.7G    .
1.7G    total




1-336024871	sev1
Summary: Zabbix_agent_on_ms3wdcladb48.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1351031] Date: Mar 25,2018 6:10 CUT Severity: Critical ResourceId: ms3wdcladb48 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ms3wdcladb48.imzcloud.ibmammsap.local NodeAlias: 10.12.7.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3567441:ms3

[ibmrmalik@ms3wdcladb48 ~]$ sudo su
[root@ms3wdcladb48 ibmrmalik]# uptime
 06:45:30 up 1 day, 11:14,  1 user,  load average: 23.04, 22.91, 22.80
[root@ms3wdcladb48 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9547) is running...

--------------------------------------------------------------------------------------------------------------------------------

27 Mar

1-336034967	sev2
Add 20GB space to /usr/sap/PBJ FS

Details:
Server: 10.198.10.21
Hostname: sjmpbjdb01	A0FGSG014XVM028
Account:St Jude Medical Singapore - SAP HEC
DC: Singapore
FS: /usr/sap/PBJ

[root@sjmpbjdb01 ibmrmalik]# df -k /usr/sap/PBJ 
[root@sjmpbjdb01 ibmrmalik]# df -k /usr/sap/PBJ
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pbjappvg-pbjusrPBJ_lv
                      56766780 41345296  12538284  77% /usr/sap/PBJ


[root@sjmpbjdb01 ibmrmalik]# vgs pbjappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  pbjappvg   2  13   0 wz--n- 147.99g 8.99g

[root@sjmpbjdb01 ibmrmalik]# lsblk |grep disk
sda                                  8:0    0   40G  0 disk
sdb                                  8:16   0  128G  0 disk
sdc                                  8:32   0  128G  0 disk
sde                                  8:64   0   32G  0 disk
sdd                                  8:48   0   64G  0 disk
sdf                                  8:80   0   45G  0 disk
sdg                                  8:96   0   20G  0 disk
sdh                                  8:112  0   16G  0 disk
sdi                                  8:128  0   16G  0 disk

vgextend pbjappvg /dev/sdi

lvextend -L +20G /dev/mapper/pbjappvg-pbjusrPBJ_lv
resize2fs /dev/mapper/pbjappvg-pbjusrPBJ_lv

[root@sjmpbjdb01 ibmrmalik]# df -k /usr/sap/PBJ
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/pbjappvg-pbjusrPBJ_lv
                      77409288 41343384  32134384  57% /usr/sap/PBJ

[root@sjmpbjdb01 ibmrmalik]# vgs pbjappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  pbjappvg   3  13   0 wz--n- 163.99g 4.99g





1-336084371	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1361446] Date: Mar 27,2018 0:22 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3572701:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      53273100 13466868  37094192  27% /





1-336082661	sev2
Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local[PROBLEM:1361532] Date: Mar 27,2018 0:36 CUT Severity: Major ResourceId: c1bwd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWD.imzcloud.ibmammsap.local NodeAlias: 10.199.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3572718:pnc

[root@C1BWD ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /mnt/sapexchangeIT filesystems are read-only

[root@C1BWD sapexchangeIT]# cat /etc/fstab |grep sapexchangeIT
//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/  cifs username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

mount //10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/ -t  cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

[root@C1BWD ~]# sh /var/lib/zabbix/check_rw_mounts.sh                           
OK



1-336086121	sev1
Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local[PROBLEM:1361938] Date: Mar 27,2018 2:19 CUT Severity: Critical ResourceId: c1bwp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3572895:pnc

[root@C1BWP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /mnt/sapexchangePT filesystems are read-only

[root@C1BWP ibmrmalik]# cat /etc/fstab |grep sapexchangePT
//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  credentials=/etc/sapexchangePT_credential,uid=908,gid=5003

mount //10.7.1.171/sapexchange /mnt/sapexchangePT -t cifs -o  username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

mount //10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/ -t  cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

[root@C1BWP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK




1-336077621   sev2
Summary: Lack_of_free_swap_space_on_SK3CARAPPRD02.imzcloud.ibmammsap.local[PROBLEM:1360606] Date: Mar 26,2018 21:35 CUT Severity: Major ResourceId: sk3carapprd02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.04 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3CARAPPRD02.imzcloud.ibmammsap.local NodeAlias: 10.5.241.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3572335:sk3

[root@SK3CARAPPRD02 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            63         39         23         20          0         20
-/+ buffers/cache:         19         44
Swap:           57         31         26

top - 06:33:13 up 494 days, 14:41,  1 user,  load average: 0.01, 0.04, 0.08
Tasks: 381 total,   1 running, 380 sleeping,   0 stopped,   0 zombie
Cpu(s):  3.7%us,  0.4%sy,  0.0%ni, 96.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    63.350G total,   39.716G used,   23.634G free, 2372.000k buffers
Swap:   58.000G total,   31.576G used,   26.424G free,   20.695G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
20625 sepadm    20   0 58.7g  15g  15g S  0.0 24.7 845:43.73 643m SEP_00_DIA_W23
26543 sepadm    20   0 58.4g  18g  17g S  0.0 28.7 974:50.27 286m SEP_00_DIA_W49
20115 sepadm    20   0 58.3g  17g  17g S  0.0 27.3 605:58.83 265m SEP_00_DIA_W29
20616 sepadm    20   0 58.2g  12g  11g S  0.0 19.1 346:12.18 140m SEP_00_DIA_W14
20618 sepadm    20   0 58.2g  12g  12g S  0.0 20.3 464:37.98 127m SEP_00_DIA_W16
20607 sepadm    20   0 58.2g 7.7g 7.6g S  0.0 12.1 120:14.52 126m SEP_00_DIA_W5
20612 sepadm    20   0 58.2g 9.9g 9.8g S  0.0 15.6 191:07.55 124m SEP_00_DIA_W10
32709 sepadm    20   0 58.2g  15g  15g S  0.0 24.2 663:32.73 118m SEP_00_DIA_W22
20606 sepadm    20   0 58.1g 7.2g 7.1g S  0.0 11.4 353:49.45 116m SEP_00_DIA_W4



1-336086331	sev1
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1362128] Date: Mar 27,2018 3:8 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3572963:amm

[root@wdc04ammsol01 ibmrmalik]# uptime
 22:38:14 up 139 days, 15:46,  1 user,  load average: 0.66, 6.32, 14.60
[root@wdc04ammsol01 ibmrmalik]# service zabbix-agent status
zabbix_agentd (pid  4544) is running...




fraha-1024-9.xsportal.local




1-336071231 sev2
*** Details of Generic Service Request - DO NOT CHANGE ***

Unlockedn of users:

unqipat1
IBMJARIVERA

Servers:

unqsapbpcqas   10.4.7.17
[root@unqsapbpcqas ~]# id IBMJARIVERA
uid=82267(ibmjarivera) gid=1513(domain users) groups=1513(domain users)

[root@unqsapbpcqas ~]# pam_tally2 --user=ibmjarivera
Login           Failures Latest failure     From
ibmjarivera         0



unqsapbpcdev	10.4.7.18  user not locked on this server
[root@unqsapbpcdev ~]# id ibmjarivera
uid=82267(ibmjarivera) gid=1513(domain users) groups=1513(domain users)
[root@unqsapbpcdev ~]#  pam_tally2 --user=ibmjarivera
Login           Failures Latest failure     From
ibmjarivera         0
[root@unqsapbpcdev ~]#  pam_tally2 --user=ibmjarivera --reset
Login           Failures Latest failure     From
ibmjarivera         0




1-335898721	sev1
Summary: Zabbix_agent_on_dal09ammmonit001_is_unavailable[PROBLEM:1335595] Date: Mar 23,2018 12:3 CUT Severity: Critical ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3557971:amm




1-335898941    Business Innovation    AMM-DELIVERY-TECH    1-Critical
Summary: Zabbix_agent_on_a0b4de013bivyatta002_is_unavailable[PROBLEM:1336077] Date: Mar 23,2018 12:5 CUT Severity: Critical ResourceId: a0b4de013bivyatta002 TicketGroup: AMM-DELIVERY-TECH CustomerCode: bi1 InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: a0b4de013bivyatta002 NodeAlias: 159.122.123.68 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3558148:bi1



1-335900781    Business Innovation    AMM-DELIVERY-TECH    1-Critical
Summary: Zabbix_agent_on_a0b4de013bivyatta001_is_unavailable[PROBLEM:1336790] Date: Mar 23,2018 12:10 CUT Severity: Critical ResourceId: a0b4de013bivyatta001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: bi1 InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: a0b4de013bivyatta001 NodeAlias: 159.122.123.73 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3558723:bi1


----------------------------------------------------------------------------------------------------------------------------------------------------

28 March

1-336120871	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/interface/BIP[PROBLEM:1367639] Date: Mar 27,2018 21:2 CUT Severity: Critical ResourceId: bmtmon1lapp03 TicketGroup: ApsSAPTechnical CustomerCode: bmt InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/interface/BIP InstanceValue: 3.45 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: bmtmon1lapp03.imzcloud.ibmammsap.local NodeAlias: 10.206.0.43 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/interface/BIP AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3575650:bmt

[root@bmtmon1lapp03 ibmrmalik]# df -k /interface/BIP
Filesystem           1K-blocks   Used Available Use% Mounted on
/dev/mapper/bipappvg-bipIntface_lv
                       1032088 980136         0 100% /interface/BIP

[root@bmtmon1lapp03 ibmrmalik]# vgs bipappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  bipappvg   1  13   0 wz--n- 128.00g 18.00g

add 1 GB space

lvextend -L +1G /dev/bipappvg/bipIntface_lv

[root@bmtmon1lapp03 ibmrmalik]# df -hT |grep /interface/BIP
                     ext3  1008M  958M     0 100% /interface/BIP

 --- Logical volume ---
  LV Path                /dev/bipappvg/bipIntface_lv
  LV Name                bipIntface_lv
  VG Name                bipappvg
  LV UUID                uF3dU3-4sMR-F2Dd-65Bh-dxI3-113H-h4Hipv
  LV Write Access        read/write
  LV Creation host, time bmtmon1lapp03, 2016-10-20 20:19:21 -0400
  LV Status              available
  # open                 1
  LV Size                1.00 GiB
  Current LE             256
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           253:12

[root@bmtmon1lapp03 ibmrmalik]# df -hT |grep /interface/BIP
                     ext3   2.0G  958M  957M  51% /interface/BIP



1-336111821    St Jude Medical  Dallas - SAP HEC    CMS-SQ-SAP-TRIO-11	sev1
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1365952] Date: Mar 27,2018 15:45 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3574804:jud

/etc/init.d/zab [root@judhdmart02 ibmrmalik]# uptime
 02:42:47 up 13 days,  2:39,  1 user,  load average: 0.42, 0.33, 0.37
[root@judhdmart02 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  31148) is running...




1-335084441	sev2
Summary: FS_is_read_only_on_Pepsapgbsdi01.imzcloud.ibmammsap.local[PROBLEM:1088380] Date: Mar 1,2018 7:18 CUT Severity: Minor ResourceId: pepsapgbsdi01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /home/gbsadm/.gvfs filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: Pepsapgbsdi01.imzcloud.ibmammsap.local NodeAlias: 100.126.32.44 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492260:pep




1-335855291 sev3	hkhana-1024-2.xsportal.local	root/
Summary: Drive_with_Media_Errors_on_host_clderpdtbp1dr.imzcloud.ibmammsap.local[PROBLEM:1327555] Date: Mar 22,2018 13:3 CUT Severity: Minor ResourceId: clderpdtbp1dr TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Check_vmtools_config_file Node: clderpdtbp1dr.imzcloud.ibmammsap.local NodeAlias: 10.204.0.141 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3555137:sm5




1-336092536	sev3		SMRT Singapore
please take a VM snapshot on OD1 - cldproapdd1	A0CTSG014XVM006
For change - 1-336092464
27th March 7:30 pm PST - Please trigger a VM backup required for change
Please trigger a VM snap shot at above mentioned time line...



1-336128081  SMRT Corp - SAP HEC-AMM  Sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1370173] Date: Mar 28,2018 5:24 CUT Severity: Major ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3576550:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      53273100 13475500  37085560  27% /



1-336123201	
*** Details of Generic Service Request - DO NOT CHANGE ***

Hello,

We require you to add disk space to the following servers:

Server 1
Hostname: ICPORPRD    	wiki has a diff name ICSPOPRD      
IP: 10.10.12.167  	10.4.252.167		ICSPOPRD 	10.4.252.167 	10.10.12.167
Disk drive: I
Space required: 10 GB

Server 2
Hostname: ICSOLMAN                   
IP: 10.10.12.5  	10.4.252.5		ICSOLMAN 	10.4.252.5 	10.10.12.5
Disk drive: I and F
Space required: add 10 GB of disk space in unit F and add 5 GB of disk space in unit I

Best Regard,
Edith Paredes

https://pubs.vmware.com/fusion-4/index.jsp?topic=%2Fcom.vmware.fusion.help.doc%2FGUID-2CE88716-DB0B-4612-AEFE-726E737E347B.html 
https://pubs.vmware.com/fusion-4/index.jsp?topic=%2Fcom.vmware.fusion.help.doc%2FGUID-CFBFC91E-C682-4C04-9202-359A67C53300.html 



1-335880301	sev2
Summary: Lack_of_free_swap_space_on_SK3SLTDEV01.imzcloud.ibmammsap.local[PROBLEM:1330451] Date: Mar 23,2018 1:25 CUT Severity: Major ResourceId: sk3sltdev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.13 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3SLTDEV01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3556545:sk3


top - 09:38:56 up 522 days, 22:32,  1 user,  load average: 4.86, 4.95, 5.01
Tasks: 336 total,   3 running, 333 sleeping,   0 stopped,   0 zombie
Cpu(s): 43.0%us,  1.1%sy,  0.0%ni, 48.9%id,  6.3%wa,  0.0%hi,  0.7%si,  0.0%st
Mem:    31.626G total,   31.040G used,  600.180M free, 8320.000k buffers
Swap:   40.000G total,   23.652G used,   16.348G free, 1135.914M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
22857 sldadm    20   0 42.5g  11g 127m D  2.0 35.1  25282:55 1.5g SLD_00_BTC_W21
23483 sldadm    20   0 1507m  10m 1276 S  2.0  0.0   4146:22 789m en.sapSLD_ASCS
27521 daaadm    20   0 5152m 172m 4240 S  0.0  0.5 148:26.74 256m jstart
25014 sldadm    20   0 30.3g 377m 316m S  0.0  1.2 122:47.46 234m SLD_00_DIA_W14
25016 sldadm    20   0 30.4g 438m 364m S  0.0  1.4 155:05.78 225m SLD_00_DIA_W16
25013 sldadm    20   0 30.4g 539m 467m S  0.0  1.7 112:27.59 225m SLD_00_DIA_W13
25006 sldadm    20   0 30.3g 469m 431m S  0.0  1.4  55:39.55 221m SLD_00_DIA_W6
25015 sldadm    20   0 30.4g 526m 442m S  0.0  1.6 131:09.95 220m SLD_00_DIA_W15
25009 sldadm    20   0 30.3g 466m 418m S  0.0  1.4  83:07.85 218m SLD_00_DIA_W9
25011 sldadm    20   0 30.3g 384m 326m S  0.0  1.2  92:04.68 217m SLD_00_DIA_W11
25000 sldadm    20   0 30.3g 458m 419m S  0.0  1.4  55:33.53 212m SLD_00_DIA_W0
25012 sldadm    20   0 30.3g 524m 445m S  0.0  1.6 117:45.97 211m SLD_00_DIA_W12
25010 sldadm    20   0 30.3g 518m 455m S  0.0  1.6 101:52.92 208m SLD_00_DIA_W10
25008 sldadm    20   0 30.2g 369m 324m S  0.0  1.1  85:09.82 207m SLD_00_DIA_W8
25002 sldadm    20   0 30.3g 364m 327m S  0.0  1.1  57:36.13 200m SLD_00_DIA_W2
25003 sldadm    20   0 30.3g 453m 419m S  0.0  1.4  55:19.83 200m SLD_00_DIA_W3
25005 sldadm    20   0 30.3g 370m 326m S  0.0  1.1  63:19.23 198m SLD_00_DIA_W5


[root@SK3SLTDEV01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         31          0          0          0          1
-/+ buffers/cache:         30          1
Swap:           39         23         16





1-336052311	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1356931] Date: Mar 26,2018 9:21 CUT Severity: Critical ResourceId: clderpappd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 3.27 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPD1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.208 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3570343:sm5

[root@CLDERPAPPD1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      26437900 19503892   5584376  78% /




1-336048611	sev2
Summary: Lack_of_free_swap_space_on_smeditrntu1.imzcloud.ibmammsap.local[PROBLEM:1356531] Date: Mar 26,2018 7:27 CUT Severity: Major ResourceId: smeditrntu1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.77 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: smeditrntu1.imzcloud.ibmammsap.local NodeAlias: 10.78.28.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3570102:cma

[root@smeditrntu1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          1          0          2
-/+ buffers/cache:         27          4
Swap:            7          4          3

top - 07:28:27 up 216 days, 23:55,  2 users,  load average: 0.18, 0.07, 0.01
Tasks: 450 total,   1 running, 449 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.6%us,  0.2%sy,  0.0%ni, 99.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   30.771G used,  584.715M free,  823.125M buffers
Swap: 8191.996M total, 4140.152M used, 4051.844M free, 2835.461M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 40399 tu1adm    20   0 19.5g  18g  960 S  0.0 57.6 279:42.73 1.4g SAPup_real




1-336129671	sev3	10.121.75.5	root/Cnsas6h9		Ticket 57744543 
Summary: Drive_with_Errors_on_dalhana-1024-2.xsportal.local[PROBLEM:1370593] Date: Mar 28,2018 7:9 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local InstanceValue: Media Error Count = 1 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_dalhana-1024-2.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3576738:amm




1-336128071
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1370172] Date: Mar 28,2018 5:24 CUT Severity: Minor ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3576549:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      53273100 13473728  37087332  27% /





1-336129031	sev3
Summary: Processor_load_is_too_high_on_HKG02AMMADC001[PROBLEM:1370157] Date: Mar 28,2018 5:20 CUT Severity: Minor ResourceId: hkg02ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 2.85 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: HKG02AMMADC001 NodeAlias: 146.89.141.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3576539:amm



1-336123551	sev3
Summary: Processor_load_is_too_high_on_SSGSA0120[PROBLEM:1368429] Date: Mar 28,2018 0:38 CUT Severity: Minor ResourceId: ssgsa0120 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mmd InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 16.083333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SSGSA0120 NodeAlias: 100.126.0.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3576022:mmd





MSC Industrial Supply Co.
1-335550555
Please add 1GB to mount point on BP1:
/dev/mapper/bp1appvg-usrsapdaa_lv
                      2.0G  1.9G   14M 100% /usr/sap/DAA
[root@ms3wdcladb41 ibmrmalik]# df -k /usr/sap/DAA
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/bp1appvg-usrsapdaa_lv
                       6192704 1957444   3920740  34% /usr/sap/DAA

ms3wdcladb41:File System Full	10.12.7.28





1-336056521	sev2
Summary: Lack_of_free_swap_space_on_smgwdevdq1.imzcloud.ibmammsap.local[PROBLEM:1357196] Date: Mar 26,2018 10:35 CUT Severity: Major ResourceId: smgwdevdq1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.77 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: smgwdevdq1.imzcloud.ibmammsap.local NodeAlias: 10.78.22.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3570493:cma

[root@smgwdevdq1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          5          0         17
-/+ buffers/cache:         12         19
Swap:            7          4          3

top - 09:51:23 up 195 days, 19:28,  1 user,  load average: 0.00, 0.04, 0.06
Tasks: 465 total,   1 running, 464 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.4%us,  0.2%sy,  0.0%ni, 98.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   30.735G used,  621.117M free,  970.703M buffers
Swap: 8191.996M total, 4378.871M used, 3813.125M free,   17.601G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 99702 dq1adm    20   0 6155m 4.1g 1648 S  0.0 13.1 259:53.76 1.7g SAPup_real
 99977 dq1adm    20   0  260m 3656 1784 S  0.0  0.0   0:43.87  87m SAPup_real
106127 root      20   0 2254m  39m 4536 S  0.0  0.1  14:08.23  23m ksaagent
 93237 sapadm    20   0 1288m  23m 4548 S  0.0  0.1 247:01.77  17m sapstartsrv

---------------------------------------------------------------------------------------------------------------------------------------------------------------

29 March

Master ticket ref 1-336169241
1-336168341
		10.8.8.67	not accessible from putty access denied
Summary: Zabbix_agent_on_LBDFP1App00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1375285] Date: Mar 28,2018 23:24 CUT Severity: Critical ResourceId: lbdfp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDFP1App00.imzcloud.ibmammsap.local NodeAlias: ssh  Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3579118:lbd

[root@LBDFP1App00 ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9737) is running...
[root@LBDFP1App00 ~]# uptime
 21:07:35 up 4 days, 14:46,  0 users,  load average: 0.03, 0.05, 1.19
[root@LBDFP1App00 ~]#  /etc/init.d/ntpd status
ntpd (pid  9670) is running...
[root@LBDFP1App00 ~]#  /etc/init.d/sssd status
sssd dead but pid file exists

[root@LBDFP1App00 ~]#  /etc/init.d/sssd restart
Stopping sssd:                                             [FAILED]
rm: cannot remove `/var/lock/subsys/sssd': Read-only file system
Starting sssd:                                             [FAILED]
[root@LBDFP1App00 ~]#  /etc/init.d/sssd status
sssd dead but pid file exists

Bug 512733 - SSSD: Services are dead but pid file exists 

https://access.redhat.com/solutions/258943

[root@LBDFP1App00 db]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / / /boot /opt /var /tmp /home /opt/monitor/IBM /home/fp1adm /home/daaadm /home/sapadm /usr/sap /usr/sap/FP1 /usr/sap/DAC /usr/sap/ccms /sapmnt/FP1 /usr/sap/local_trans /3rdPartySoftware/FP1 /interface/FP1 /sapstage /backup filesystems are read-only



LBDMP1PRDDB1	10.8.8.72


LBDFP1APP00    10.8.8.67
[root@LBDFP1App00 ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / / /boot /opt /var /tmp /home /opt/monitor/IBM /home/fp1adm /home/daaadm /home/sapadm /usr/sap /usr/sap/FP1 /usr/sap/DAC /usr/sap/ccms /sapmnt/FP1 /usr/sap/local_trans /3rdPartySoftware/FP1 /interface/FP1 /sapstage /backup filesystems are read-only
[root@LBDFP1App00 ~]# /etc/init.d/sssd status
sssd dead but pid file exists


LBDFP1APP01    10.8.8.68
[root@LBDFP1App01 ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / / /boot /opt /var /tmp /home /opt/monitor/IBM /sapmnt/FP1 /home/fp1adm /home/daaadm /home/sapadm /usr/sap /usr/sap/ccms /usr/sap/local_trans /3rdPartySoftware/FP1 /interface/FP1 /sapstage /backup filesystems are read-only
[root@LBDFP1App01 ~]#  /etc/init.d/sssd status
sssd dead but pid file exists

LBDMP1PRDDB1    10.8.8.72

LBDBIPPRDApp1    10.8.8.183

[root@LBDBIPPRDApp1 ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / / /boot /opt /opt/monitor/IBM /var /tmp /home /home/bipadm /home/daaadm /home/sapadm /usr/sap /usr/sap/DAA /usr/sap/ccms /sapmnt/BIP /usr/sap/trans /3rdPartySoftware/BIP /interface/BIP /sapstage /backup /BOPUBLIC filesystems are read-only
[root@LBDBIPPRDApp1 ~]#  /etc/init.d/sssd status
sssd dead but pid file exists


LBDWP1App80	10.8.8.65


[root@LBDBIPPRDApp3 ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /BOPUBLIC filesystems are read-only
sssd running

		

esx a0b4hk013esx017
Public IP: 119.81.190.68 (Hong Kong 2)
Private IP: 10.110.230.108

root/LMBabr9m


[root@LBDMP1PRDDB1 ~]# service sssd status
sssd dead but pid file exists
[root@LBDMP1PRDDB1 ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / / /boot /opt /var /tmp /home /opt/monitor/IBM /sybase /sybase/MP1/sybtemp /sybase/MP1/log_archive /sybase/MP1/sapdiag /sybase/MP1/saplog1 /sybase/MP1/sapdata1 /sybase/MP1/sapdata2 /sybase/MP1/sapdata3 /sybase/MP1/sapdata4 /sybase/MP1/saptemp /backup /Staging filesystems are read-only


LBDWD2App80
CRITICAL |  /var /tmp /usr/sap /usr/sap/WD2 /usr/sap/DAA filesystems are read-only
sssd dead but pid file exists

LBDFP1App01
CRITICAL |  / / /boot /opt /var /tmp /home /opt/monitor/IBM /sapmnt/FP1 /home/fp1adm /home/daaadm /home/sapadm /usr/sap /usr/sap/ccms /usr/sap/local_trans /3rdPartySoftware/FP1 /interface/FP1 /sapstage /backup filesystems are read-only
sssd dead but pid file exists

LBDFP1App00
CRITICAL |  / / /boot /opt /var /tmp /home /opt/monitor/IBM /home/fp1adm /home/daaadm /home/sapadm /usr/sap /usr/sap/FP1 /usr/sap/DAC /usr/sap/ccms /sapmnt/FP1 /usr/sap/local_trans /3rdPartySoftware/FP1 /interface/FP1 /sapstage /backup filesystems are read-only
sssd dead but pid file exists

LBDBIPPRDApp1
CRITICAL |  / / /boot /opt /opt/monitor/IBM /var /tmp /home /home/bipadm /home/daaadm /home/sapadm /usr/sap /usr/sap/DAA /usr/sap/ccms /sapmnt/BIP /usr/sap/trans /3rdPartySoftware/BIP /interface/BIP /sapstage /backup /BOPUBLIC filesystems are read-only
sssd dead but pid file exists




1-336128431	sev1
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1370507] Date: Mar 28,2018 6:44 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3576680:jud

[root@judhdmart02 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  31148) is running...
[root@judhdmart02 ibmrmalik]# uptime
 06:54:11 up 14 days,  6:50,  1 user,  load average: 0.53, 0.32, 0.43

top - 06:55:04 up 14 days,  6:51,  1 user,  load average: 0.37, 0.30, 0.42
Tasks: 2663 total,   2 running, 2661 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.2%us,  0.1%sy,  0.0%ni, 99.8%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  1009.597G total,  812.464G used,  197.133G free,  252.438M buffers
Swap:   50.000G total,    0.000k used,   50.000G free,   18.650G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  9559 root      20   0 2467m 200m  11m S  6.9  0.0 934:39.92 ds_am
 20964 root      20   0 46324  13m 2304 R  4.9  0.0   0:00.15 sapcimb
 14758 qh1adm    20   0  919g 782g 7.8g S  3.9 77.5  20503:07 hdbindexserver
 20950 root      20   0 29540 3396 1020 R  2.3  0.0   0:00.18 top
 32884 root      20   0  577m  25m 9908 S  2.0  0.0 115:05.06 BESClient
 14760 qh1adm    20   0 10.0g 3.2g 312m S  1.3  0.3 271:18.70 hdbxsengine
 10777 sapadm    20   0  650m  87m  45m S  1.0  0.0  96:56.13 sapstartsrv
 14467 qh1adm    20   0 25.3g 5.2g 515m S  0.3  0.5  88:07.70 hdbnameserver
 14658 qh1adm    20   0 4185m 1.1g 168m S  0.3  0.1  65:05.57 hdbpreprocessor




1-336176231 - IBM AMM Infrastructure - SEV1 - Siebel - not validated - Summary: Zabbix_agent_on_fmsprdrtem004.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_fmsprdrtem004.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1378867] Date: Mar 29,2018 6:37 CUT Severity: Critical ResourceId: fmsprdrtem004 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: fmsprdrtem004.imzcloud.ibmammsap.local NodeAlias: 169.55.192.102 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3580056:amm

[root@fmsprdrtem004 ibmrmalik]# uptime
 02:09:57 up 13 days, 18:35,  1 user,  load average: 0.87, 0.58, 0.53
[root@fmsprdrtem004 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  2191) is running...
[root@fmsprdrtem004 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          3          4          0          0          1
-/+ buffers/cache:          0          6
Swap:            1          0          1


1-336177451 - IBM AMM Infrastructure - SEV1 - Siebel - not validated - Summary: Zabbix_agent_on_fmsprdeifp004.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_fmsprdeifp004.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1378882] Date: Mar 29,2018 6:37 CUT Severity: Critical ResourceId: fmsprdeifp004 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: fmsprdeifp004.imzcloud.ibmammsap.local NodeAlias: 169.55.192.120 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3580060:amm


[root@fmsprdeifp004 ibmrmalik]# uptime
 02:23:51 up 83 days, 37 min,  1 user,  load average: 0.00, 0.00, 0.00
[root@fmsprdeifp004 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  1999) is running...
[root@fmsprdeifp004 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             1          1          0          0          0          0
-/+ buffers/cache:          0          1
Swap:            1          0          1



-----------------------------------------------------------------------------------------------------------------------------------------------

30 March


1-336206651	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1383467] Date: Mar 29,2018 23:29 CUT Severity: Minor ResourceId: ci3s4hanaqaa TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 19.95 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CI3S4HANAQAA.imzcloud.ibmammsap.local NodeAlias: 10.210.1.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3582466:ci3

[root@CI3S4HANAQAA ibmrmalik]# df -k /tmp
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                       2502448 1918984    453016  81% /tmp


[root@CI3S4HANAQAA tmp]# du -mch --max-depth=1 .
394M    ./sapinst_exe.69613.1522357365
1.5G    ./sapinst_instdir
1.9G    .
1.9G    total



1-335084441
Summary: FS_is_read_only_on_Pepsapgbsdi01.imzcloud.ibmammsap.local[PROBLEM:1088380] Date: Mar 1,2018 7:18 CUT Severity: Minor ResourceId: pepsapgbsdi01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /home/gbsadm/.gvfs filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: Pepsapgbsdi01.imzcloud.ibmammsap.local NodeAlias: 100.126.32.44 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492260:pep

Pepsapgbsdi01:~ # sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /home/gbsadm/.gvfs filesystems are read-only

Pepsapgbsdi01:~ # cat /etc/fstab |grep gbsadm
/dev/gbsappvg/gbsadm_lv /home/gbsadm    ext3    _netdev,defaults        1       2

d?????????  ? ?      ?          ?            ? .gvfs

with gbsadm
Pepsapgbsdi01 /home/gbsadm% ll -ld /home/gbsadm/.gvfs
drwx------ 2 gbsadm sapsys 4096 Mar  1 01:16 /home/gbsadm/.gvfs

Pepsapgbsdi01:~ # df -k /home/gbsadm/
Filesystem                     1K-blocks  Used Available Use% Mounted on
/dev/mapper/gbsappvg-gbsadm_lv    999320  2484    944408   1% /home/gbsadm


Pepsapgbsdi01:~ # cat /etc/SuSE-release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 2
# This file is deprecated and will be removed in a future service pack or release.
# Please check /etc/os-release for details about this release.





1-336205651
Summary: Zabbix_agent_on_PEPSAPGPDDI01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1383242] Date: Mar 29,2018 22:36 CUT Severity: Critical ResourceId: pepsapgpddi01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PEPSAPGPDDI01.imzcloud.ibmammsap.local NodeAlias: 100.126.32.57 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3582345:pep



1-336208671	sev1
Summary: Zabbix_agent_on_0f.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1384324] Date: Mar 30,2018 4:12 CUT Severity: Critical ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: 0f.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3582921:cia

[root@dal09ammsol01 ibmrmalik]# uptime
 23:45:52 up 199 days, 13:17,  1 user,  load average: 15.55, 16.80, 21.41
[root@dal09ammsol01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4279) is running...
[root@dal09ammsol01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          5          2         17
-/+ buffers/cache:         10         20
Swap:           11          4          7




1-336177211	sev1
Summary: Zabbix_agent_on_CROSFLAVS01_is_unavailable[PROBLEM:1378080] Date: Mar 29,2018 6:34 CUT Severity: Major ResourceId: crosflavs01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cng InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Agent_availability Node: CROSFLAVS01 NodeAlias: 10.68.210.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3579942:cng




1-336210311	sev1
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1384124] Date: Mar 30,2018 3:8 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3582803:amm




1-336214561  IBM MSD Infras - Cloud Shared   sev1
Summary: 146.89.170.31(146.89.170.31) is unreachable. The host has failed to respond to the ping request. Date: Mar 30,2018 5:43 CUT Severity: Critical ResourceId: ri3ua020v1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ics InstanceId: 146.89.170.31 InstanceValue: unreachable InstanceSituation: Node Status ComponentType: ComputerSystem Component: NodeAvail SubComponent: Ping Node: 146.89.170.31 NodeAlias: 146.89.170.31 Manager: Ping Probe Agent: Ping probe on ri3pa010 AlertKey: ncopingprobe AlertGroup: PingStatus EventKey: USRD0P0MSDP:3583107:ics




1-336205341	sev2
*** Details of Generic Service Request - DO NOT CHANGE ***

yanbalbodev	10.28.25.13 	10.4.7.13
yanbalboprd	10.28.25.15 	10.4.7.15
yanbalboqas	10.28.25.14	10.4.7.14



----------------------------------------------------------------------------------------------------------------

1 April

LBDMP1PRDDB1   10.8.8.72

[root@LBDMP1PRDDB1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         12         19          7          0         10
-/+ buffers/cache:          1         29
Swap:            7          0          7


top - 02:40:32 up  2:30,  2 users,  load average: 3.72, 5.46, 14.07
Tasks: 347 total,   1 running, 346 sleeping,   0 stopped,   0 zombie
Cpu(s): 22.6%us, 12.9%sy,  0.0%ni, 53.6%id, 10.0%wa,  0.0%hi,  0.8%si,  0.0%st
Mem:    31.349G total,   12.175G used,   19.175G free,  277.055M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   10.342G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 8155 sybmp1    20   0 24.2g 7.6g 7.6g S 419.1 24.2 439:54.30 dataserver
 4533 daaadm    20   0 5125m 258m  17m S 23.3  0.8  17:25.62 jstart
 2305 root      20   0  505m 5700 4664 S 16.6  0.0   2:30.71 ManagementAgent
 2693 root      20   0 18412  824  480 S  3.7  0.0   0:25.00 irqbalance
19060 daaadm    20   0 4070m 240m  17m S  1.3  0.7   0:43.43 jstart


[root@LBDMP1PRDDB1 ibmrmalik]# uptime
 02:40:49 up  2:31,  2 users,  load average: 3.85, 5.41, 13.91


Total DISK READ: 957.42 K/s | Total DISK WRITE: 2.67 M/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO>    COMMAND
 8185 be/4 sybmp1      0.00 B/s    0.00 B/s  0.00 % 81.82 % dataserve~15_0 -sMP1
  752 be/3 root        0.00 B/s    3.91 K/s  0.00 %  6.46 % [jbd2/dm-0-8]
 8169 be/4 sybmp1    128.96 K/s  890.99 K/s  0.00 %  0.05 % dataserve~15_0 -sMP1
 8166 be/4 sybmp1    140.68 K/s   15.63 K/s  0.00 %  0.00 % dataserve~15_0 -sMP1
 8167 be/4 sybmp1      0.00 B/s  375.15 K/s  0.00 %  0.00 % dataserve~15_0 -sMP1
 8168 be/4 sybmp1    547.10 K/s   31.26 K/s  0.00 %  0.00 % dataserve~15_0 -sMP1
 8170 be/4 sybmp1    140.68 K/s  672.15 K/s  0.00 %  0.00 % dataserve~15_0 -sMP1
 8171 be/4 sybmp1      0.00 B/s  672.15 K/s  0.00 %  0.00 % dataserve~15_0 -sMP1
    1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init
    2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]


----------------------------------------------------------------------------------------------------------------------------------------------

2 April

1-336276421		sev1
Summary: Zabbix_agent_on_DASDBDEV.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1400823] Date: Apr 2,2018 7:52 CUT Severity: Critical ResourceId: dasdbdev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dst InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DASDBDEV.imzcloud.ibmammsap.local NodeAlias: 10.14.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3590472:dst

DASDBDEV:/etc/init.d # cat /etc/os-release
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"



1-336214561	sev1
Summary: 146.89.170.31(146.89.170.31) is unreachable. The host has failed to respond to the ping request. Date: Mar 30,2018 5:43 CUT Severity: Critical ResourceId: ri3ua020v1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ics InstanceId: 146.89.170.31 InstanceValue: unreachable InstanceSituation: Node Status ComponentType: ComputerSystem Component: NodeAvail SubComponent: Ping Node: 146.89.170.31 NodeAlias: 146.89.170.31 Manager: Ping Probe Agent: Ping probe on ri3pa010 AlertKey: ncopingprobe AlertGroup: PingStatus EventKey: USRD0P0MSDP:3583107:ics







** Details of Generic Service Request - DO NOT CHANGE ***

It is required to validate if port 22 is open in BO equipment. 
yanbalbodev	10.28.25.13 	10.4.7.13

[root@yanbalbodev ibmrmalik]# netstat -antplu | grep -i  ":22"
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      4153/sshd
tcp        0    496 10.4.7.13:22                146.89.140.60:60969         ESTABLISHED 45577/sshd
tcp        0      0 :::22                       :::*                        LISTEN      4153/sshd


yanbalboprd	10.28.25.15 	10.4.7.15

[root@yanbalboprd ibmrmalik]# netstat -antplu | grep -i  ":22"
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      3346/sshd
tcp        0    312 10.4.7.15:22                146.89.140.60:61534         ESTABLISHED 6575/sshd
tcp        0      0 :::22                       :::*                        LISTEN      3346/sshd


yanbalboqas	10.28.25.14	10.4.7.14

[root@yanbalboqas ibmrmalik]# netstat -antplu | grep -i  ":22"
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      4134/sshd
tcp        0    200 10.4.7.14:22                146.89.140.60:61581         ESTABLISHED 10047/sshd
tcp        0      0 :::22                       :::*                        LISTEN      4134/sshd




1-336253491	sev1
Summary: Zabbix_agent_on_LBDMP1PRDDB1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1394941] Date: Apr 1,2018 4:13 CUT Severity: Critical ResourceId: lbdmp1prddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDMP1PRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.72 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3587619:lbd





1-335855291 sev3	hana9.xsportal.local	10.110.214.241		root/PEJCv4ss	Ticket 57991593		57991605	
Summary: Drive_with_Media_Errors_on_host_clderpdtbp1dr.imzcloud.ibmammsap.local[PROBLEM:1327555] Date: Mar 22,2018 13:3 CUT Severity: Minor ResourceId: clderpdtbp1dr TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Check_vmtools_config_file Node: clderpdtbp1dr.imzcloud.ibmammsap.local NodeAlias: 10.204.0.141 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3555137:sm5





1-335665037 sev3
SC8SANS4D22:/home/ibmrmalik # cat /etc/os-release
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"




1-336282839	sev2
BI1ERPDBQAS01   10.135.4.18  , IMZ login to this server not working. Please check	
[root@BI1ERPDBQAS01 ~]# /etc/init.d/sssd status
sssd (pid  3127) is running...



1-336282661	sev3
Summary: NTP_time_is_driffted_on_LBDTP1PRDApp1.imzcloud.ibmammsap.local[PROBLEM:1402338] Date: Apr 2,2018 14:8 CUT Severity: Warning ResourceId: lbdtp1prdapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 88.49 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDTP1PRDApp1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.80 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3591300:lbd




1-336290761      sev3
Summary: NTP_time_is_driffted_on_LBDFP1PRDDB1.imzcloud.ibmammsap.local[PROBLEM:1402406] Date: Apr 2,2018 14:28 CUT Severity: Warning ResourceId: lbdfp1prddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 99.83 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDFP1PRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.66 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3591342:lbd

[root@LBDFP1PRDDB1 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 hkg02ammadc001. 146.89.141.11    7 u  102   64    0    0.000    0.000   0.000
 hkg02ammadc002. 146.89.141.10    7 u    1   64    1    1.033   -2.246   0.000
[root@LBDFP1PRDDB1 ibmrmalik]# ntpstat
unsynchronised
   polling server every 64 s
	



snapshot vide 1-336273596   for change no 1-336272950
Please take a VM snap shot of OP1 - CLDPROAPPP1  & CLDPRODTBP1 as a part of CSr # - CSR # 1-336272950
OP1 - CLDPROAPPP1	A0CTSG014XVM037  
 	CLDPRODTBP1 	A0CTSG014XVM036


------------------------------------------------------------------------------------------------------------------------------------------------

3 April


1-336304561	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/db/db2inst2/db2data[PROBLEM:1406335] Date: Apr 3,2018 7:7 CUT Severity: Major ResourceId: crosfliem01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data InstanceValue: 9.58 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: crosfliem01.imzcloud.ibmammsap.local NodeAlias: 10.68.210.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3593458:cng

[root@crosfliem01 ibmrmalik]# df -k /db/db2inst2/db2data
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/vg_db2inst2-lv_db_db2inst2_db2data
                      10190136 3306844   6359004  35% /db/db2inst2/db2data





1-336309831	sev3
I am not able to access below server on IMZCLOUD domain. 
Kindly check if my IDs are pushed on all servers thanks

Access issue on below Server.
Ip = 10.15.0.11
hostname = AINALOPRDDBAS
Customer name = Alorica Inc. (AIN)

-----------------------------------------------------
Login Details:
Jump server : 169.53.60.88:33891 , 169.53.60.88:33892
Domain: IBMAMMSAP , IMZCLOUD 
Username  = IMZCloud\ibmGRamachandra
E-mail: gurramac@in.ibm.com 
Lotus notes id : Guruprasad G Ramachandra/India/IBM@IBMIN



1-336202511	sev2	
Summary: Free_disk_space_is_less_than_10%_on_volume_/[PROBLEM:1382845] Date: Mar 29,2018 20:53 CUT Severity: Major ResourceId: lbdfq1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Free_disk_space_on_/_(percentage) InstanceValue: 8.98 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_disk_space_on_/_(percentage Node: LBDFQ1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.39 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_disk_space_on_/_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3582131:lbd

[root@LBDFQ1App00 ibmrmalik]# df -k /
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      10190136 8797372    868476  92% /

[root@LBDFQ1App00 sapmnt]# ls -ltrS
total 1926260
drwxr-xr-x 7 fq1adm sapsys       4096 Apr  3 20:34 FQ1
-rw------- 1 root   root   1972480000 Mar 30 04:12 FQ1.tar




1-336307291

10.199.1.10

ibmICeausu

pam_tally2 --user=ibmICeausu --reset



1-336313571	sev3
Summary: FS_is_read_only_on_IA1OTASPRDAPP.imzcloud.ibmammsap.local[PROBLEM:1407769] Date: Apr 3,2018 12:47 CUT Severity: Minor ResourceId: ia1otasprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /Archive/media filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: IA1OTASPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.17.147 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3594132:ia1

66.248.245.34:/media /Archive/media         nfs4   rw,soft,timeo=30,rsize=8192,wsize=8192 0

[root@IA1OTASPRDAPP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /Archive/media filesystems are read-only



1-336265421	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/log[PROBLEM:1398694] Date: Apr 1,2018 21:21 CUT Severity: Minor ResourceId: bi1erpdbdev01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 19.99 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3589317:bi1

[root@BI1ERPDBDEV01 ibmrmalik]# df -k /hana/log
Filesystem     1K-blocks      Used Available Use% Mounted on
/dev/sdd1      136244224 111462084  24782140  82% /hana/log


./mnt00001/hdb00003/logsegment_000_00000000.dat
./mnt00001/hdb00003/logsegment_000_00000001.dat
./mnt00001/hdb00003/logsegment_000_00000002.dat
./backup/back11MAR/COMPLETE_DATA_BACKUP_databackup_3_1




1-336289761	sev3
Summary: SAP: HANA script Hana_Status returned no Instance value. Date: 04/02/2018 Severity: Minor ResourceId: tqaerpqah TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: tqa InstanceId: 10 InstanceValue: Hana_Status InstanceSituation: No Instance resturned by the script ComponentType: ComputerSystem Component: ITM6Agent SubComponent: HANAScript ApplId: SAP Node: TQAERPQAH NodeAlias: TQAERPQAH Manager: TQAERPQAH Agent: EIF Probe on ri3pa010 AlertKey: msd_hanascrp_g5hm_stdv1 AlertGroup: ITM_K5H_PERFORMANCE_OBJECT_STATUS EventKey: USRD0P0MSDP:3591326:tqa



1-336301001	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/trans[PROBLEM:1404911] Date: Apr 3,2018 0:24 CUT Severity: Minor ResourceId: tqasolman TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans InstanceValue: 19.65 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQASOLMAN.imzcloud.ibmammsap.local NodeAlias: 10.7.1.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3592802:tqa

[root@TQASOLMAN ibmrmalik]# df -k /usr/sap/trans
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/tsmappvg-usrtrans_lv
                      41284928 36210748   2977028  93% /usr/sap/trans

./SW/Solman72SP06/ABAP/K-75101INSAPUI.SAR
./SW/Solman72SP06/ABAP/K-751BHINSAPUI.SAR
./SW/Solman72SP06/ABAP/K-750BHINSAPUI.SAR
./SW/Solman72SP06/JAVA/ADSSAP15_0-20009985.SCA
./EPS/in/I710020751258_0108417.PAT
./EPS/in/I720020751259_0105790.PAT
./EPS/in/CSR0120031469_0096979.PAT
./SUM/abap/data/R-751BRINSAPUI.SAP
./SUM/abap/data/R-75101INSAPUI.SAP
./SUM/abap/data/R-750BRINSAPUI.SAP






1-336290911	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap[PROBLEM:1402539] Date: Apr 2,2018 15:6 CUT Severity: Minor ResourceId: tqaerpdevh TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap InstanceValue: 10.68 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQAERPDEVH.imzcloud.ibmammsap.local NodeAlias: 10.7.1.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3591417:tqa

[root@TQAERPDEVH log]# df -k /usr/sap
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/vghanadata-lv_usr_sap
                      52399104 3829740  48569364   8% /usr/sap




1-336318201
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/trans[PROBLEM:1408228] Date: Apr 3,2018 14:55 CUT Severity: Critical ResourceId: tqasolman TicketGroup: ApsSAPTechnical CustomerCode: tqa InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans InstanceValue: 4.7 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: TQASOLMAN.imzcloud.ibmammsap.local NodeAlias: 10.7.1.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3594367:tqa

[root@TQASOLMAN ibmrmalik]# df -k /usr/sap/trans
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/tsmappvg-usrtrans_lv
                      61927420 39070612  19711336  67% /usr/sap/trans
	

----------------------------------------------------------------------------------------------------------------------------------------

4 April


1-336250971	sev3	
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1392680] Date: Mar 31,2018 17:46 CUT Severity: Minor ResourceId: smtmquaqt3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 9.73 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: smtmquaqt3.imzcloud.ibmammsap.local NodeAlias: 10.78.24.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3586655:cma

[root@smtmquaqt3 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 1969676   2801488  42% /var



1-336250161	sev3
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var[PROBLEM:1392681] Date: Mar 31,2018 17:46 CUT Severity: Major ResourceId: smtmquaqt3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 9.73 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: smtmquaqt3.imzcloud.ibmammsap.local NodeAlias: 10.78.24.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3586656:cma

[root@smtmquaqt3 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 1970144   2801020  42% /var




1-336252191	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1393740] Date: Mar 31,2018 22:39 CUT Severity: Minor ResourceId: ci3s4hanaprda TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 16.44 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CI3S4HANAPRDA.imzcloud.ibmammsap.local NodeAlias: 10.210.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3587073:ci3

[root@CI3S4HANAPRDA ibmrmalik]# df -k /tmp
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                       1998672 1623020    270796  86% /tmp

-rw-r-----  1 root         sapinst       8965 Apr  1 22:12 HDB_SL_Logfile.log
-rw-r-----  1 root         sapinst      32768 Mar 29 22:31 sap_jvm_monitoringboard_0_7027
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_7013
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_63151
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_63060
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_63046
-rw-------  1 root         sapinst      45108 Apr  1 14:46 +~JF7879546277844099209.tmp
-rw-------  1 root         sapinst      53248 Mar 29 22:31 sap_jvm_0_7027
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_7013
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_63151
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_63060
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_63046




1-336252211	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/tmp[PROBLEM:1393753] Date: Mar 31,2018 22:43 CUT Severity: Major ResourceId: ci3s4hanaprda TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 9.79 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CI3S4HANAPRDA.imzcloud.ibmammsap.local NodeAlias: 10.210.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3587078:ci3

[root@CI3S4HANAPRDA ibmrmalik]# df -k /tmp
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                       1998672 1623020    270796  86% /tmp

-rw-r-----  1 root         sapinst       8965 Apr  1 22:12 HDB_SL_Logfile.log
-rw-r-----  1 root         sapinst      32768 Mar 29 22:31 sap_jvm_monitoringboard_0_7027
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_7013
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_63151
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_63060
-rw-r-----  1 root         sapinst      32768 Apr  4 11:51 sap_jvm_monitoringboard_0_63046
-rw-------  1 root         sapinst      45108 Apr  1 14:46 +~JF7879546277844099209.tmp
-rw-------  1 root         sapinst      53248 Mar 29 22:31 sap_jvm_0_7027
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_7013
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_63151
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_63060
-rw-------  1 root         sapinst      53248 Apr  4 11:50 sap_jvm_0_63046




APSSAP TECHNICAL	
area CMS-TR-SAP-CLIENT
subarea CMS-SQ-SAP-TRIO-10
status Closed




1-336342511	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap[PROBLEM:1413447] Date: Apr 4,2018 8:59 CUT Severity: Major ResourceId: rrtnas TicketGroup: ApsSAPTechnical CustomerCode: cma InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap InstanceValue: 9.27 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: rrtnas.imzcloud.ibmammsap.local NodeAlias: 10.78.24.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3596371:cma

[root@rrtnas ibmrmalik]# df -k /usr/sap
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/app_vg-usrsap_lv
                      28252316 25208764   1601920  95% /usr/sap

[root@rrtnas sap]# find . -xdev -type f -size +1000000
./saprouter/dev_rout		21591320661
./saprouter/dev_rout.old

Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/app_vg-usrsap_lv
                      28252316 21130800   5679884  79% /usr/sap

\


1-336048461	sev3		10.140.48.156	root/NZsH36Le	Ticket 58079507		
Summary: Drive_with_Errors_on_monhana-1024-4.xsportal.local[PROBLEM:1356470] Date: Mar 26,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_monhana-1024-4.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_monhana-1024-4.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_monhana-1024-4.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3570061:amm



1-336212681	sev3 		10.140.48.171	root/EEbTQ8pm	Ticket 58080705	
Summary: Drive_with_Errors_on_monhana-1024-12.xsportal.local[PROBLEM:1384914] Date: Mar 30,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_monhana-1024-12.xsportal.local InstanceValue: 12:7 30 UBad - 558.406 GB SAS HDD N N 512B ST600MP0005 U - ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_monhana-1024-12. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_monhana-1024-12.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3583262:amm



1-336335581	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_F:[PROBLEM:1411762] Date: Apr 4,2018 2:5 CUT Severity: Minor ResourceId: pipprod01 TicketGroup: ApsSAPTechnical CustomerCode: raa InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: InstanceValue: 18 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: PIPPROD01 NodeAlias: 10.4.12.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_F: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3595552:raa



1-336354811	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1414358] Date: Apr 4,2018 13:27 CUT Severity: Minor ResourceId: smtmdevdt3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 17.88 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: smtmdevdt3.imzcloud.ibmammsap.local NodeAlias: 10.78.22.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3596882:cma

[root@smtmdevdt3 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 2442136   2329028  52% /var





1-336344141	sev3
SummSummary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1413446] Date: Apr 4,2018 8:59 CUT Severity: Minor ResourceId: ia1s4hprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 12.77 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: IA1S4HPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3596370:ia1

[root@IA1S4HPRDAPP ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 3366044   1405120  71% /var


------------------------------------------------------------------------------------------------------------------------------

5 April

1-336355651	sev1
Summary: Zabbix_agent_on_fra02ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1415050] Date: Apr 4,2018 16:46 CUT Severity: Critical ResourceId: fra02ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: fra02ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.220 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3597194:amm

[root@fra02ammsol01 ibmrmalik]# uptime
 11:58:15 up 209 days,  1:55,  3 users,  load average: 2.86, 8.22, 11.79
[root@fra02ammsol01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  19276) is running...
[root@fra02ammsol01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK




1-336347461	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1414124] Date: Apr 4,2018 12:19 CUT Severity: Major ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3596751:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      53273100 13482972  37078088  27% /


1-336349921	SEV2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var[PROBLEM:1413943] Date: Apr 4,2018 11:19 CUT Severity: Major ResourceId: smtmdevdt3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 5.12 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: smtmdevdt3.imzcloud.ibmammsap.local NodeAlias: 10.78.22.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3596645:cma

[root@smtmdevdt3 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 2446632   2324532  52% /var



1-336362301	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1415995] Date: Apr 4,2018 20:31 CUT Severity: Minor ResourceId: smtmquaqt4 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 18.44 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: smtmquaqt4.imzcloud.ibmammsap.local NodeAlias: 10.78.24.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3597715:cma

[root@smtmquaqt4 ibmrmalik]# df -k /var
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       5033512 3581812   1189352  76% /var



1-336376231	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1419491] Date: Apr 5,2018 8:22 CUT Severity: Minor ResourceId: ci3s4hanaprda TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 14.17 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CI3S4HANAPRDA.imzcloud.ibmammsap.local NodeAlias: 10.210.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3599900:ci3

[root@CI3S4HANAPRDA ibmrmalik]# df -k /tmp
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                       1998672 1685240    208576  89% /tmp
#lvextend -L +5G  /dev/mapper/VolGroup-lv_tmp 
# resize2fs /dev/mapper/VolGroup-lv_tmp 


-rw-r-----  1 root         sapinst      32768 Mar 29 22:31 sap_jvm_monitoringboard_0_7027
-rw-r-----  1 root         sapinst      32768 Apr  5 11:36 sap_jvm_monitoringboard_0_7013
-rw-r-----  1 root         sapinst      32768 Apr  5 11:36 sap_jvm_monitoringboard_0_122026
-rw-r-----  1 root         sapinst      32768 Apr  5 11:36 sap_jvm_monitoringboard_0_121939
-rw-r-----  1 root         sapinst      32768 Apr  5 11:36 sap_jvm_monitoringboard_0_121925
-rw-------  1 root         sapinst      45108 Apr  5 10:21 +~JF7932406834432444205.tmp
-rw-------  1 root         sapinst      53248 Mar 29 22:31 sap_jvm_0_7027
-rw-------  1 root         sapinst      53248 Apr  5 11:36 sap_jvm_0_7013
-rw-------  1 root         sapinst      53248 Apr  5 11:36 sap_jvm_0_122026
-rw-------  1 root         sapinst      53248 Apr  5 11:36 sap_jvm_0_121939
-rw-------  1 root         sapinst      53248 Apr  5 11:36 sap_jvm_0_121925







1-336374871	sev2
Hi Team, As part of customer's critical project, we need to transfer a file from one location to another between 2 VM's. The path and file name are specified below. Please do the needful:
Source: CI3S4HANAQA	10.210.1.13	10.201.0.13		 CI3S4HANAQAA.local.TMG.dom (10.201.0.14): 10.210.1.14
[root@CI3S4HANAQAA sources]# ls -ltr |grep Export01042018_QAS
drwxrwxrwx  3 root      root               4096 Mar 31 13:51 Export01042018_QAS


Patch: /oracle/sources/sources/Export01042018_QAS
Destination: CI3S4HANADEVA	10.210.1.16




1-336301571	sev3
Summary: FS_is_read_only_on_hhhdhdb.imzcloud.ibmammsap.local[PROBLEM:1405313] Date: Apr 3,2018 2:19 CUT Severity: Minor ResourceId: hhhdhdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: hhh InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /run/user/1001 filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: hhhdhdb.imzcloud.ibmammsap.local NodeAlias: 10.7.14.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3593002:hhh

hhhdhdb:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
OK




1-336292471
P2:[MAXIMO] Create new keystore in OP1 CLDP [00165722/2018]
Customer: SMRT Corporation Ltd
Reported by: Uma Maheshwar Dev Bontala
Phone:+65 (6554) 8535
E-Mail:umamaheshwar@smrt.com.sg
Priority:2: High
SAP Incident Number:0165722/2018


Description:

Reconstruction
04/02/2018   22:24:27   S0016320183

Please provide step-by-step instructions on how to reproduce your issue:
Step 1: SFTP key step up
 
Step 2:
Step 3:
____________________
Business Consequences
04/02/2018   22:24:26   S0016320183

project delays
____________________
Description
04/02/2018   22:24:25   S0016320183

Hi Team,
 
 
Please assist to create new keystore in OP1 with the keys attached.
 
sFTP account name : _maximosapsftpp
Password:  <password sent via email>
 
Keystore = SFTP_ maximosapsftpp
Keystore Entry = sftp_keystore_maximo
 
 
Thanks & regards,
Uma Maheshwar Dev

(OP1)CLDPROAPPP1- 10.198.0.75

sftp _maximosapsftpp@10.198.0.75

IdentityFile ~/.ssh/_maximosapsftpp1-priv.ppk




 

1-336295571 
1-336295551 
1-336290351 


--------------------------------------------------------------------------------------------------------------

6 April


1-336403631	sev3
Apleona    FRA02	 import the certificate from Kohlhammer into the gnupg
170.225.68.22	
APLHRHP1




1-336222416	sev2	par01ammsol04   146.89.142.142 , IMZ login to this server is not working. Please check.  sev2
/dev/mapper/VolGroup-lv_tmp
                      3.9G  3.9G     0 100% /tmp

/dev/mapper/pm1logvg-pm1db2logdirlv
                      26704124 25205504    135472 100% /db2/PM1/log_dir
/dev/mapper/pm1archvg-pm1db2arch_lv
                      92760056 87970268     71708 100% /db2/PM1/log_archive



1-336271668	sev2
IMZ Login not working




1-336222911	sev3
Summary: Processor_load_is_too_high_on_LON02AMMADC001[PROBLEM:1385890] Date: Mar 30,2018 11:28 CUT Severity: Minor ResourceId: ri3lr061 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ict InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 7.9 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: LON02AMMADC001 NodeAlias: 146.89.140.76 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3583759:ict




1-336406421	sev3
A/c sapdl0db locked
SAPibm#1






1-336295571 sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_C:[PROBLEM:1404222] Date: Apr 2,2018 21:38 CUT Severity: Minor ResourceId: ri3pa046 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 19.99 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: AMMDAL09VCS001 NodeAlias: 146.89.140.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3592495:ibs



1-335614871	sev1
Summary: Sybase SQL Status: Unknown Date: 03/15/2018 Severity: Critical ResourceId: tqaboprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: tqa InstanceId: BOP:SQL:Unknown InstanceSituation: Sybase Server Status ComponentType: Database Component: Sybase SubComponent: Status ApplId: SYBASE MsgId: SYBASETSA001E Node: tqaboprd NodeAlias: 10.7.1.20 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_svrstat_goyf_sapsyb_prod AlertGroup: ITM_Sybase_Server_Summary EventKey: USRD0P0MSDP:3533081:tqa



1-336272651	sev3
Summary: Processor_load_is_too_high_on_AQAERPDBPRD[PROBLEM:1400373] Date: Apr 2,2018 5:55 CUT Severity: Minor ResourceId: aqaerpdbprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: aqa InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 10.466667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: AQAERPDBPRD NodeAlias: 10.135.26.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3590212:aqa




1-336275531	sev3
Summary: Processor_load_is_too_high_on_SNG01AMMADC001[PROBLEM:1401190] Date: Apr 2,2018 9:15 CUT Severity: Minor ResourceId: sng01ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 17.433333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SNG01AMMADC001 NodeAlias: 146.89.140.140 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3590706:amm




1-336276141	10.121.75.5	root/Cnsas6h9	Ticket 58145035 
Summary: Drive_with_Errors_on_dalhana-1024-2.xsportal.local[PROBLEM:1400681] Date: Apr 2,2018 7:19 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local InstanceValue: Media Error Count = 1 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_dalhana-1024-2.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_dalhana-1024-2.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3590383:amm



1-336263321	sev3
Summary: Processor_load_is_too_high_on_TOR01AMMADC001[PROBLEM:1397847] Date: Apr 1,2018 17:37 CUT Severity: Minor ResourceId: tor01ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 7.9 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: TOR01AMMADC001 NodeAlias: 146.89.141.76 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3588922:amm




1-336309831	sev2	
I am not able to access below server on IMZCLOUD domain. 
Kindly check if my IDs are pushed on all servers thanks

Access issue on below Server.
Ip = 10.15.0.11
hostname = AINALOPRDDBAS
Customer name = Alorica Inc. (AIN)

-----------------------------------------------------
Login Details:
Jump server : 169.53.60.88:33891 , 169.53.60.88:33892
Domain: IBMAMMSAP , IMZCLOUD 
Username  = IMZCloud\ibmGRamachandra
E-mail: gurramac@in.ibm.com 
Lotus notes id : Guruprasad G Ramachandra/India/IBM@IBMIN





1-336295551 
1-336290351 


-----------------------------------------------------------------------------------------------------------------

9 April



server is still in build stage. AMM dont have access or any info. Informed in 3.x slack to assign appropriately

1-336370141
1-336370081
1-336370071
1-336370061
1-336368141



1-336331161	sev3
Summary: Zabbix_poller_processes_more_than_75%_busy



1-336360621	sev2
Summary: Lack_of_free_swap_space_on_SK3CARAPPRD02.imzcloud.ibmammsap.local[PROBLEM:1415986] Date: Apr 4,2018 20:29 CUT Severity: Major ResourceId: sk3carapprd02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.97 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SK3CARAPPRD02.imzcloud.ibmammsap.local NodeAlias: 10.5.241.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3597712:sk3

[root@SK3CARAPPRD02 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            63         46         16         19          0         24
-/+ buffers/cache:         21         42
Swap:           57         36         21

top - 12:02:18 up 507 days, 20:10,  1 user,  load average: 0.14, 0.08, 0.02
Tasks: 381 total,   2 running, 379 sleeping,   0 stopped,   0 zombie
Cpu(s):  9.7%us,  0.4%sy,  0.0%ni, 89.8%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    63.350G total,   46.595G used,   16.754G free,  451.996M buffers
Swap:   58.000G total,   36.726G used,   21.274G free,   24.906G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
51987 sepadm    20   0 58.9g  10g  10g S  0.0 16.5 577:38.73 835m SEP_00_DIA_W31
33040 sepadm    20   0 61.4g  17g  14g S  0.0 27.1 638:24.06 779m SEP_00_DIA_W45
58507 sepadm    20   0 58.8g  10g  10g S  0.0 17.3 321:12.77 778m SEP_00_DIA_W33
 7824 sepadm    20   0 58.9g  11g  11g S  2.0 18.9 779:55.29 656m SEP_00_DIA_W42
20625 sepadm    20   0 58.7g 9.7g 9.5g S  0.0 15.3   1016:04 613m SEP_00_DIA_W23
55988 sepadm    20   0 58.6g  10g  10g S  0.0 17.1 513:53.90 538m SEP_00_DIA_W36
62105 sepadm    20   0 58.4g  10g  10g S  0.0 17.0   1105:18 296m SEP_00_DIA_W35
15031 sepadm    20   0 58.3g 9.9g 9.8g S  0.0 15.6 803:50.57 289m SEP_00_DIA_W24
64933 sepadm    20   0 58.2g 6.7g 6.6g S  0.0 10.5 161:02.38 220m SEP_00_DIA_W15
32709 sepadm    20   0 58.2g 9.2g 9.1g S  0.0 14.5 818:19.62 198m SEP_00_DIA_W22
20603 sepadm    20   0 58.2g 3.2g 3.1g S  0.0  5.0 114:50.64 198m SEP_00_DIA_W1
20618 sepadm    20   0 58.2g 8.7g 8.5g S  0.0 13.7 556:52.70 181m SEP_00_DIA_W16
20614 sepadm    20   0 58.2g 6.7g 6.6g S  0.0 10.6 274:02.33 149m SEP_00_DIA_W12
20616 sepadm    20   0 58.2g 7.0g 6.9g S  0.0 11.0 431:37.95 146m SEP_00_DIA_W14
20607 sepadm    20   0 58.2g 3.8g 3.7g S  0.0  5.9 141:15.09 143m SEP_00_DIA_W5
25070 sepadm    20   0 58.2g  10g  10g S  0.0 16.4 126:54.82 139m SEP_00_DIA_W29
20606 sepadm    20   0 58.1g 4.4g 4.3g S  0.0  7.0 376:09.75 131m SEP_00_DIA_W4




1-336391391	sev3
Summary: Chef_Client_is_not_running_on_CHE01AMMCHEF01.imzcloud.ibmammsap.local[PROBLEM:1421947] Date: Apr 5,2018 17:41 CUT Severity: Minor ResourceId: ri3lr074 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: iap InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Chef_status ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Chef_status Node: CHE01AMMCHEF01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.87 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Chef_status AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3601313:iap


[root@CHE01AMMCHEF01 init.d]# which knife
/usr/bin/knife
[root@CHE01AMMCHEF01 init.d]# which chef-client
/usr/bin/chef-client
[root@CHE01AMMCHEF01 init.d]# date
Mon Apr  9 05:23:06 CDT 2018
Chef Client finished, 93/411 resources updated in 06 minutes 48 seconds
You have mail in /var/spool/mail/root




1-336405721	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/log[PROBLEM:1424829] Date: Apr 6,2018 3:20 CUT Severity: Minor ResourceId: bi1bwhdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 19.99 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1BWHDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3603106:bi1

[root@BI1BWHDBQAS01 ibmrmalik]# df -h /hana/log
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdd1       130G  111G   19G  86% /hana/log


[root@BI1BWHDBQAS01 log]# find . -xdev -type f -size +1000000
./mnt00001/hdb00002.00003/logsegment_000_00000000.dat
./mnt00001/hdb00002.00003/logsegment_000_00000001.dat
./mnt00001/hdb00002.00003/logsegment_000_00000002.dat
./mnt00001/hdb00002.00003/logsegment_000_00000003.dat
./mnt00001/hdb00002.00003/logsegment_000_00000004.dat
./mnt00001/hdb00002.00003/logsegment_000_00000005.dat
./mnt00001/hdb00002.00003/logsegment_000_00000006.dat
./mnt00001/hdb00002.00003/logsegment_000_00000007.dat
./mnt00001/hdb00002.00003/logsegment_000_00000008.dat
./mnt00001/hdb00002.00003/logsegment_000_00000009.dat
./mnt00001/hdb00002.00003/logsegment_000_00000010.dat
./mnt00001/hdb00002.00003/logsegment_000_00000011.dat
./mnt00001/hdb00002.00003/logsegment_000_00000012.dat
./mnt00001/hdb00002.00003/logsegment_000_00000013.dat
./mnt00001/hdb00002.00003/logsegment_000_00000014.dat
./mnt00001/hdb00002.00003/logsegment_000_00000015.dat
./mnt00001/hdb00002.00003/logsegment_000_00000016.dat
./mnt00001/hdb00002.00003/logsegment_000_00000017.dat
./mnt00001/hdb00002.00003/logsegment_000_00000018.dat
./mnt00001/hdb00002.00003/logsegment_000_00000019.dat
./backuplog/HBQ_DB/DB_HBQ/log_backup_2_0_6877788992_6894566208.1522915137639
./backuplog/HBQ_DB/DB_HBQ/log_backup_2_0_6894566208_6904425600.1522915148463




1-336421171	sev3
Summary: Processor_load_is_too_high_on_SNG01AMMADC001	




1-336421541	sev3
Summary: Zabbix_data_sender_processes_more_than_75%_busy[PROBLEM:1428435] Date: Apr 6,2018 17:45 CU




1-336423651	sev3
Summary: Zabbix_poller_processes_more_than_75%_busy




1-336426261	sev2
Summary: Lack_of_free_swap_space_on_SC7NP3DBCI.imzcloud.ibmammsap.local[PROBLEM:1429543] Date: Apr 6,2018 22:31 CUT Severity: Major ResourceId: sc7np3dbci TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sc7 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 36.32 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SC7NP3DBCI.imzcloud.ibmammsap.local NodeAlias: 10.7.20.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3605576:sc7

[root@SC7NP3DBCI ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          1          0         11
-/+ buffers/cache:          3         12
Swap:            7          5          2


top - 12:42:28 up 17 days, 22:06,  1 user,  load average: 0.02, 0.04, 0.00
Tasks: 397 total,   2 running, 395 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.6%us,  0.2%sy,  0.0%ni, 99.1%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.154G used,  418.301M free,  588.684M buffers
Swap: 8191.996M total, 5758.137M used, 2433.859M free,   11.022G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 90898 db2np3    20   0 10.7g 1.6g 1.4g S  0.3 10.4   2892:08 382m db2sysc
 27244 np3adm    20   0 1821m 4376 1436 S  0.0  0.0   0:04.34 102m icman
104057 np3adm    20   0 7350m 369m 368m S  0.0  2.3   4:04.65  78m NP3_00_DIA_W3
104062 np3adm    20   0 7348m 324m 321m S  0.0  2.0   2:43.44  71m NP3_00_DIA_W8
 38974 np3adm    20   0 7350m 334m 328m S  0.0  2.1   3:26.27  69m NP3_00_DIA_W1
104060 np3adm    20   0 7346m 233m 230m S  0.0  1.5   0:46.52  66m NP3_00_DIA_W6
104064 np3adm    20   0 7344m 211m 209m S  0.0  1.3   1:04.98  65m NP3_00_DIA_W9
104059 np3adm    20   0 7343m 319m 316m S  0.0  2.0   3:13.47  65m NP3_00_DIA_W5
104075 np3adm    20   0 7328m  91m  85m S  0.0  0.6   1:17.05  48m NP3_00_DIA_W1
104058 np3adm    20   0 7321m 5780 5408 S  0.0  0.0   0:00.87  47m NP3_00_DIA_W4
104056 np3adm    20   0 7321m 5896 5440 S  0.0  0.0   0:00.88  47m NP3_00_DIA_W2
104054 np3adm    20   0 7321m 5916 5372 S  0.0  0.0   0:00.87  46m NP3_00_DIA_W0
 90896 root      20   0 1245m 4392 3948 S  0.0  0.0   0:00.13  45m db2syscr
104082 np3adm    20   0 7327m  27m  21m S  0.0  0.2   0:03.57  45m NP3_00_BTC_W2




1-336429791	sev2
Summary: Lack_of_free_swap_space_on_smgwquaqq1.imzcloud.ibmammsap.local[PROBLEM:1429889] Date: Apr 7,2018 0:1 CUT Severity: Major ResourceId: smgwquaqq1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.93 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: smgwquaqq1.imzcloud.ibmammsap.local NodeAlias: 10.78.24.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3605736:cma

[root@smgwquaqq1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          8          0         16
-/+ buffers/cache:         13         18
Swap:            7          4          3


top - 10:47:16 up 208 days, 42 min,  1 user,  load average: 0.30, 0.23, 0.09
Tasks: 466 total,   1 running, 465 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.6%us,  0.3%sy,  0.0%ni, 98.9%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   30.834G used,  520.055M free,  915.348M buffers
Swap: 8191.996M total, 4547.922M used, 3644.074M free,   16.912G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 40502 qq1adm    20   0 6568m 4.8g 1544 S  0.0 15.4 273:10.46 1.4g SAPup_real
 12755 tivmon    20   0 1922m  32m  15m S  0.0  0.1  49:08.68   9m kuddb2
  1723 root      20   0  284m  46m 1712 S  0.0  0.1 122:21.30 6960 vmtoolsd
 55091 root      20   0 2127m  51m 4208 S  0.0  0.2  13:18.10 6144 ksaagent
 79077 db2qq1    20   0 15.0g 5.8g 5.0g S  0.4 18.4   1043:46 4088 db2sysc
 41483 qq1adm    20   0  260m  85m 1680 S  0.0  0.3   0:44.12 3240 SAPup_real
  1778 root      20   0 51008 1036 1032 S  0.0  0.0   0:00.02 2884 VGAuthService
 79075 root      20   0 1245m  58m  15m S  0.0  0.2   0:00.12 2044 db2syscr
 79084 root      20   0 1248m  48m 4660 S  0.0  0.2   0:32.15 2044 db2syscr
 79085 root      20   0 1248m  48m 4640 S  0.0  0.2   0:32.13 2044 db2syscr
 79086 root      20   0 1248m  48m 4640 S  0.0  0.2   0:32.17 2044 db2syscr
  2928 root      20   0  231m 2548 2264 S  0.0  0.0   0:01.77  908 smbd
  2961 root      20   0  246m  15m  808 S  0.0  0.0   0:16.75  868 smbd
  2855 root      20   0 83040 1328 1232 S  0.0  0.0   1:31.70  824 master
  2982 root      20   0  253m  55m 1868 S  0.0  0.2   0:21.09  788 chef-client
  2868 postfix   20   0 93456 1664 1352 S  0.0  0.0   0:31.62  712 qmgr
  2744 root      20   0 66260  512  412 S  0.0  0.0   0:06.16  632 sshd



1-336434011	sev2
Summary: Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:1431044] Date: Apr 7,2018 5:36 CUT Severity: Major ResourceId: ia1ftsprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 0.93 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1FTSPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3606282:ia1

[root@IA1FTSPRDAPP ibmrmalik]# uptime
 12:53:31 up 3 days, 20:44,  1 user,  load average: 0.01, 0.04, 0.02
[root@IA1FTSPRDAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          5          1          0          0          1
-/+ buffers/cache:          4          3
Swap:           31          0         31



1-336434131	sev3
Summary: Processor_load_is_too_high_on_SNCHCIIDA11[PROBLEM:1431233] Date: Apr 7,2018 6:33 CUT Severity: Minor ResourceId: snchciida11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 7.266667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SNCHCIIDA11 NodeAlias: 10.73.11.113 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3606384:snc	



1-336434211 	sev3		10.127.155.66	Invalid record ID specified, no records found that match your criteria.     SL  58242961 raised for the missing info about the esxi	
Summary: Drive_with_Errors_on_parhana-1024-11.xsportal.local[PROBLEM:1431341] Date: Apr 7,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_parhana-1024-11.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_parhana-1024-11. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_parhana-1024-11.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3606445:amm	




1-336434341	sev3
Summary: Processor_load_is_too_high_on_SNCHCIITA11[PROBLEM:1431541] Date: Apr 7,2018 7:45 CUT Severity: Minor ResourceId: snchciita11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 11.6 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: SNCHCIITA11 NodeAlias: 10.73.11.51 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3606525:snc




1-336434761		sev3
Summary: Processor_load_is_too_high_on_HKG02AMMADC001[PROBLEM:1431003] Date: Apr 7,2018 5:25 CUT Severity: Minor ResourceId: hkg02ammadc001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 0.475 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: HKG02AMMADC001 NodeAlias: 146.89.141.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3606260:amm	




1-336441411	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1433966] Date: Apr 7,2018 20:37 CUT Severity: Minor ResourceId: dlthspspi TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 18.97 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLTHSPSPI.imzcloud.ibmammsap.local NodeAlias: 10.4.5.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3607728:dal

[root@DLTHSPSPI ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   20G  4.8G  80% /


[root@DLTHSPSPI /]# find . -xdev -type f -size +1000000
./var/spool/abrt/ccpp-2017-11-27-09:03:08-23159/coredump
./usr/local/patchagent/update/log/detect.log
./opt/tivoli/tsm/client/ba/bin/dsmsched.log
./opt/controlm/ctmagent/CTM_Agent.tar


[root@DLTHSPSPI ccpp-2017-11-27-09:03:08-23159]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   19G  5.4G  78% /



1-336441951	sev 2
Summary: Lack_of_free_swap_space_on_HHHDPO.imzcloud.ibmammsap.local[PROBLEM:1434338] Date: Apr 7,2018 22:39 CUT Severity: Major ResourceId: hhhdpo TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: hhh InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.92 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: HHHDPO.imzcloud.ibmammsap.local NodeAlias: 10.7.14.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3607936:hhh

[root@HHHDPO ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          7          0          1          0          1
-/+ buffers/cache:          4          2
Swap:            7          4          3


top - 09:04:59 up 23 days, 22:12,  1 user,  load average: 0.06, 0.06, 0.00
Tasks: 305 total,   1 running, 304 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.3%us,  0.3%sy,  0.0%ni, 98.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7856.773M total, 7442.633M used,  414.141M free,  710.984M buffers
Swap: 8191.996M total, 4278.438M used, 3913.559M free, 1719.172M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 34242 hdpadm    20   0 2959m  54m 1456 S  0.0  0.7  17:14.97 907m java
 49770 hdpadm    20   0 6304m 2.6g  20m S  0.0 34.2  57:25.13 115m jstart
 46551 hdpadm    20   0 1429m 201m 1700 S  0.0  2.6   0:31.71  83m en.sapHDP_SCS
  2148 root      20   0 1056m  52m 5016 S  0.0  0.7  19:30.40  36m ds_agent
  3079 root      20   0  250m  19m 1780 S  0.0  0.3   0:02.31  29m chef-client
 49707 hdpadm    20   0 1688m 105m 7048 S  0.0  1.3   0:22.81  22m icman
 91770 root      20   0  275m 1908 1316 S  0.0  0.0   0:31.39  18m gnome-screens
 48854 hdpadm    20   0  265m  11m 7584 S  0.0  0.2   0:01.54  17m jc.sapHDP_J60
 32705 sapadm    20   0 1096m  22m 3292 S  0.0  0.3  18:50.85  16m sapstartsrv
 48858 hdpadm    20   0  877m  14m 1548 S  0.0  0.2   0:59.84  16m igspw_mt
 26462 root      20   0 1709m 7412 2824 S  0.0  0.1   0:24.79  15m kuma620
 48859 hdpadm    20   0  877m  15m 1548 S  0.0  0.2   0:59.41  14m igspw_mt
 26178 root      20   0 1441m 7644 2404 S  0.0  0.1   0:19.62  12m koyagent
 16726 root      20   0  160m  776  676 S  0.0  0.0   0:00.73  12m Xvnc
 46262 hdpadm    20   0 1005m  17m 3708 S  0.0  0.2   1:39.92  11m sapstartsrv





1-336444601	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1435238] Date: Apr 8,2018 2:47 CUT Severity: Major ResourceId: mgggbjqgtsx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 8.38 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJQGTSX03.imzcloud.ibmammsap.local NodeAlias: 10.133.18.193 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3608428:mgg

[root@MGGGBJQGTSX03 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  8.5G  822M  92% /

[root@MGGGBJQGTSX03 /]# find . -xdev -type f -size +1000000
./Staging/tmp/sapinst_instdir/NW750/HDB/INSTALL/STD/sapjvm/sapjvm_8/jre/lib/amd64/server/libjvm.so
./Staging/JGQ_export_HANA_03082017/JAVA/JDMP/EXPDMP_5_J2EE_CONFIGENTRY.001
./Staging/JGQ_export_HANA_03082017/JAVA/JDMP/EXPDMP_5_J2EE_CONFIGENTRY.002
./Staging/SAPJVM8_12-80000202.SAR
./Staging/SWPM/SWPM10SP18_6-20009701.SAR



1-336445981	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1435368] Date: Apr 8,2018 3:20 CUT Severity: Major ResourceId: mgggbjpeccx05 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 8.38 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJPECCX05.imzcloud.ibmammsap.local NodeAlias: 10.133.18.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3608489:mgg

[root@MGGGBJPECCX05 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  8.7G  616M  94% /

./root/.vnc/core.64208
find: `./F': Host is down
find: `./F': Host is down
find: `./D': Host is down
find: `./D': Host is down
./sapmnt/exe_749/exe.tar


[root@MGGGBJPECCX05 sapmnt]# ls -ltrS
total 12
drwxr-xr-x 7 npjadm sapsys 4096 Oct 30 04:13 NPJ
drwxr-xr-x 8 nepadm sapsys 4096 Nov  6 00:15 NEP
drwxrwxrwx 2 root   root   4096 Oct 30 04:13 exe_749
[root@MGGGBJPECCX05 sapmnt]# cd exe_749/
[root@MGGGBJPECCX05 exe_749]# ls -ltrS
total 3307296
-rwxrwxrwx 1 ibmpdas domain users 3386664960 Oct 30 03:07 exe.tar
[root@MGGGBJPECCX05 exe_749]# pwd
/sapmnt/exe_749
-rwxrwxrwx 1 ibmpdas domain users 3.2G Oct 30 03:07 exe.tar


[root@MGGGBJPECCX05 .vnc]# pwd
/root/.vnc
-rw-------  1 root root 513908736 Apr  7 20:18 core.64208





1-336455051	sev2
Summary: Cleared and Re-fired: ITM Agent Offline: BRPCAMLVSA06D:UA Date: 04/08/2018 Severity: Major ResourceId: brpcamlvsa06d TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: br3 InstanceId: REMOTE_fmsprdrtem001 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: brpcamlvsa06d NodeAlias: 10.138.10.16 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3610096:br3



1-336455061	sev2
Summary: ITM Agent Offline: BRPCAMLVSA01D:5H Date: 04/08/2018 Severity: Major ResourceId: brpcamlvsa01d TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: br3 InstanceId: REMOTE_fmsprdrtem002 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: brpcamlvsa01d NodeAlias: 10.138.10.11 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3610187:br3



1-336455071	sev2
Summary: ITM Agent Offline: BRPCAMLVSA04D:UA Date: 04/08/2018 


1-336455151	sev2
Summary: ITM Agent Offline: DSA:BRPCAMLVSA05D:SYB Date: 





1-336455171	sev2
Summary: Lack_of_free_swap_space_on_ms3wdcladb41.imzcloud.ibmammsap.local[PROBLEM:1439157] Date: Apr 8,2018 21:19 CUT Severity: Major ResourceId: ms3wdcladb41 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.86 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: ms3wdcladb41.imzcloud.ibmammsap.local NodeAlias: 10.12.6.66 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3610258:ms3

[root@ms3wdcadbsd1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          7          0          8
-/+ buffers/cache:          6          8
Swap:            7          4          3


top - 14:46:49 up 29 days, 18:29,  1 user,  load average: 0.18, 0.09, 0.04
Tasks: 288 total,   2 running, 286 sleeping,   0 stopped,   0 zombie
Cpu(s): 22.8%us,  2.0%sy,  0.0%ni, 74.6%id,  0.6%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.569G total,   10.159G used, 5539.758M free,  475.559M buffers
Swap: 8191.996M total, 3837.492M used, 4354.504M free, 8323.730M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 2016 sybsdj    20   0 55304 5692 1764 S  0.0  0.0   0:00.22 2272 xpserver
 1975 sybsdj    20   0 1777m  13m 2404 S  0.0  0.1   0:12.57 1352 jsagent
21661 sybsd1    20   0 98436 7676  960 S  0.0  0.0   0:29.77  672 backupserver
10384 root      20   0  215m  28m 1760 S  0.0  0.2  15:33.69  588 koy15col
 1958 sybsdj    20   0 7652m 2.4g 2.4g S  0.3 15.2 403:46.34  516 dataserver



1-336459121	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/boot[PROBLEM:1440355] Date: Apr 9,2018 4:8 CUT Severity: Minor ResourceId: twysapdd1app1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: twy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/boot InstanceValue: 11.44 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: TWYSAPDD1APP1.imzcloud.ibmammsap.local NodeAlias: 10.137.10.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/boot AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3610821:twy

Apr  9 11:43:19 TWYSAPDD1APP1 [sssd[krb5_child[130441]]]: Server not found in Kerberos database

[root@TWYSAPDD1APP1 ~]# df -h /boot
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  8.2G  1.1G  89% /

----------------------------------------------------------------------------------------------------------------------------------------------------------------

10 April

1-336421351	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1428357] Date: Apr 6,2018 17:22 CUT Severity: Minor ResourceId: cldsmabap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDSMABAP01.imzcloud.ibmammsap.local NodeAlias: 10.198.0.76 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3604939:sm5

[root@CLDSMABAP01 sssd]# df -h /tmp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                      2.9G  2.6G  195M  94% /tmp


sssd is stopped

Apr 10 05:13:58 CLDSMABAP01 sssd[be[imzcloud.ibmammsap.local]]: Failed to read k  eytab [default]: No such file or directory

(Tue Apr 10 15:31:19 2018) [sssd[nss]] [sss_dp_init] (0x0010): Failed to connect to monitor services.
(Tue Apr 10 15:31:19 2018) [sssd[nss]] [sss_process_init] (0x0010): fatal error setting up backend connector
(Tue Apr 10 15:31:19 2018) [sssd[nss]] [nss_process_init] (0x0010): sss_process_init() failed

/dev/mapper/smaarchvg-smalogarch_lv
                       50G   47G     0 100% /sybase/SMA/log_archive
/dev/mapper/smalogvg-smasyblog1_lv
                       22G   21G  377M  99% /sybase/SMA/saplog1
/dev/mapper/smadatavg-smasapdata1_lv
                       23G   22G     0 100% /sybase/SMA/sapdata1
/dev/mapper/smadatavg-smasapdata2_lv
                       23G   22G     0 100% /sybase/SMA/sapdata2
/dev/mapper/smadatavg-smasapdata3_lv
                       23G   22G     0 100% /sybase/SMA/sapdata3
/dev/mapper/smadatavg-smasapdata4_lv
                       23G   22G     0 100% /sybase/SMA/sapdata4
/dev/mapper/smadatavg-smasaptemp_lv





1-336524501 2-Urgent    SMRT Corp - SAP HEC-AMM 
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1461943] Date: Apr 10,2018 9:38 CUT Severity: Major ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3616498:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   14G   36G  28% /




1-336396411	sev2
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1422637] Date: Apr 5,2018 19:57 CUT Severity: Minor ResourceId: cldbobiadwt1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 19.98 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDBOBIADWT1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.218 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3601747:sm5

[root@CLDBOBIADWT1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   19G  5.1G  80% /




1-336524671    1-Critical    Limited Brands, Inc. - SAP HEC-AMM
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1425825] Date: Apr 6,2018 7:35 CUT Severity: Minor ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 19.5 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3603580:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   14G   36G  28% /





1-336524671	sev1
Zabbix_agent_on_LBDBQ1App01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1462189] Date: Apr 10,2018 10:19 CUT Severity: Critical ResourceId: lbdbq1app01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDBQ1App01.imzcloud.ibmammsap.local NodeAlias: 10.8.8.48 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3616587:lbd

[root@LBDBQ1App01 ibmrmalik]# uptime
 19:07:14 up 288 days, 13:14,  1 user,  load average: 0.01, 0.06, 0.39
[root@LBDBQ1App01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  2896) is running...
[root@LBDBQ1App01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK



1-336534251    1-Critical    IBM AMM Infrastructure        Summary: Zabbix_agent_on_HKG02AMMSOL04.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_HKG02AMMSOL04.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1462594] Date: Apr 10,2018 11:21 CUT Severity: Critical ResourceId: hkg02ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: HKG02AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.141.36 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3616770:amm




1-336534691    1-Critical    Limited Brands, Inc. - SAP HEC-AMM
Summary: Zabbix_agent_on_LBDFP1App00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1463119] Date: Apr 10,2018 12:15 CUT Severity: Critical ResourceId: lbdfp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDFP1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.67 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3616880:lbd




1-336543931	sev2
Summary: Zabbix_agent_on_SAHOTDMS_is_unavailable[PROBLEM:1463974] Date: Apr 10,2018 14:7 CUT Severity: Major ResourceId: sahotdms TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ch5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Agent_availability Node: SAHOTDMS NodeAlias: 10.7.12.54 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3617164:ch5

System Boot Time:          4/10/2018, 5:12:09 PM



1-336481621	sev2
Summary: Lack_of_free_swap_space_on_DAL09AMMCHEF01.imzcloud.ibmammsap.local[PROBLEM:1449730] Date: Apr 9,2018 17:58 CUT Severity: Major ResourceId: ri3lr022 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.95 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: DAL09AMMCHEF01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3613536:mic

[root@DAL09AMMCHEF01 ~]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          6          1          0          0          1
-/+ buffers/cache:          4          2
Swap:            3          0          3


top - 10:06:28 up 210 days, 21:12,  2 users,  load average: 0.17, 0.20, 0.25
Tasks: 422 total,   2 running, 362 sleeping,   0 stopped,  58 zombie
Cpu(s):  9.2%us,  1.3%sy,  0.0%ni, 89.4%id,  0.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:  7993.590M total, 6816.547M used, 1177.043M free,  664.609M buffers
Swap: 4095.996M total,  860.090M used, 3235.906M free, 1118.711M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
45238 root      20   0  379m  752  748 S  0.0  0.0   0:02.67 221m get_imz_data.rb
21763 root      20   0  379m  88m  748 S  0.0  1.1   0:02.67 133m get_imz_data.rb
57857 opscode   20   0  269m 2612 2608 S  0.0  0.0   0:04.54 124m bundle
59479 opscode   20   0  269m 1384 1188 S  0.0  0.0   0:00.00 124m bundle
58048 opscode   20   0 4554m 1.1g 6284 S  0.0 14.0 399:47.32  37m java
57935 opscode   20   0  547m 100m 3380 S  7.9  1.3   5602:20  36m beam.smp
57797 opscode   20   0  457m  49m 2900 S  1.0  0.6   2104:13  23m beam.smp
43964 root      35  15 1082m  45m 1040 S  0.0  0.6  53:56.37  22m java
57648 opscode   20   0  446m  58m 2872 S  0.3  0.7  36:18.61  16m beam.smp
57945 opscode   20   0 2655m 522m 3316 S 22.2  6.5   2702:10  15m beam.smp
59763 opscode   20   0  116m 2740 2736 S  0.0  0.0   0:00.22  15m ruby
59761 opscode   20   0  116m 2740 2736 S  0.0  0.0   0:00.22  15m ruby
59765 opscode   20   0  116m 2740 2736 S  0.0  0.0   0:00.21  15m ruby
 4235 root      20   0  245m 1944  636 S  0.0  0.0   1:06.46  13m smbd
57985 opscode   20   0  132m  17m 2684 S  0.0  0.2   1:27.20 9696 bundle
58639 root      35  15 1065m  12m  644 S  0.0  0.2  27:22.53 4636 java
45204 root      20   0  106m 1936 1932 S  0.0  0.0   0:00.19 3272 sshd
59695 opscode   20   0  344m 169m 2112 S  0.3  2.1 279:16.55 2256 bundle
59692 opscode   20   0  303m 128m 2112 S  0.0  1.6 293:34.40 2252 bundle
59760 opscode-  20   0 2114m  60m  57m S  0.0  0.8  35:36.91 2248 postgres
59756 opscode-  20   0 2115m  57m  54m S  0.0  0.7  30:13.77 2196 postgres
59347 opscode-  20   0 2115m  31m  29m S  0.0  0.4 105:12.20 2172 postgres
59753 opscode-  20   0 2116m  62m  59m S  0.0  0.8  35:44.93 2108 postgres
59759 opscode-  20   0 2116m  62m  59m S  0.0  0.8  40:26.48 2016 postgres
21749 root      20   0  106m 3636 2148 S  0.0  0.0   0:00.18 1952 sshd
59757 opscode-  20   0 2116m  60m  57m S  0.0  0.8  48:09.67 1840 postgres




1-336467941	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/hana/data[PROBLEM:1442483] Date: Apr 9,2018 7:57 CUT Severity: Major ResourceId: bi1crmdbprd01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 8.81 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1CRMDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3611404:bi1

[root@BI1CRMDBPRD01 ibmrmalik]# df -h /hana/data
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_data  1.5T  996G  540G  65% /hana/data

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

11 April

1-336563521	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1471483] Date: Apr 11,2018 8:23 CUT Severity: Minor ResourceId: dcghanasolapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 19.41 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: dcghanasolapp.imzcloud.ibmammsap.local NodeAlias: 10.197.5.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3619509:cpw

[root@dcghanasolapp ibmrmalik]# df -h /tmp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                      2.0G  1.2G  680M  64% /tmp


1-336563431	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1471420] Date: Apr 11,2018 8:14 CUT Severity: Critical ResourceId: mgggbjqgtsx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJQGTSX03.imzcloud.ibmammsap.local NodeAlias: 10.133.18.193 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3619481:mgg

[root@MGGGBJQGTSX03 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  3.8G  5.5G  42% /





1-336552491	sev1
Summary: Zabbix_agent_on_Pepsapg3sdi01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1467657] Date: Apr 10,2018 22:14 CUT Severity: Critical ResourceId: pepsapg3sdi01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: Pepsapg3sdi01.imzcloud.ibmammsap.local NodeAlias: 100.126.32.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3618317:pep

Pepsapg3sdi01:/etc/init.d # cat /etc/os-release
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"




1-336536428	sev3

Add space to the following filesystems on the following servers:

BD1 - mtsbodsdev01 - 10.74.6.46

Need to have 10 GB add to /sybase/BD1
[root@mtsbodsdev01 ibmrmalik]# df -h /sybase/BD1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bd1datavg-bd1sybase_lv
                      7.9G  5.4G  2.2G  72% /sybase/BD1

[root@mtsbodsdev01 ibmrmalik]# vgs bd1datavg
  VG        #PV #LV #SN Attr   VSize   VFree
  bd1datavg   2   7   0 wz--n- 727.99g 360.99g

lvextend -L +10G  /dev/mapper/bd1datavg-bd1sybase_lv
resize2fs /dev/mapper/bd1datavg-bd1sybase_lv

[root@mtsbodsdev01 ibmrmalik]# df -h /sybase/BD1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bd1datavg-bd1sybase_lv
                       18G  5.4G   12G  32% /sybase/BD1


BQ1 - mtsbodsqas01 - 10.74.6.47

Need to have 10 GB add to /sybase/BQ1

[root@mtsbodsqas01 ibmrmalik]# df -h /sybase/BQ1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bq1datavg-bq1sybase_lv
                       11G  6.2G  4.2G  60% /sybase/BQ1

[root@mtsbodsqas01 ibmrmalik]# vgs bq1datavg
  VG        #PV #LV #SN Attr   VSize   VFree
  bq1datavg   2   7   0 wz--n- 727.99g 357.99g

lvextend -L +10G  /dev/mapper/bq1datavg-bq1sybase_lv
resize2fs /dev/mapper/bq1datavg-bq1sybase_lv

[root@mtsbodsqas01 ibmrmalik]# df -h /sybase/BQ1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bq1datavg-bq1sybase_lv
                       21G  6.2G   14G  32% /sybase/BQ1




DEP - r3devep - 10.74.6.45	added a 16GB disk

Need to add 3 GB to /sybase/DEP/sybtemp

[root@r3devep ibmrmalik]# df -h /sybase/DEP/sybtemp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/depdatavg-depsybtemp_lv
                      5.0G  1.2G  3.6G  25% /sybase/DEP/sybtemp

[root@r3devep ibmrmalik]# vgs depdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  depdatavg   2   7   0 wz--n- 143.99g 1.99g

[root@r3devep ibmrmalik]# df -h /sybase/DEP/sybtemp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/depdatavg-depsybtemp_lv
                      7.9G  1.2G  6.4G  16% /sybase/DEP/sybtemp


vgextend depdatavg /dev/sdj

lvextend -L +3G  /dev/mapper/depdatavg-depsybtemp_lv
resize2fs /dev/mapper/depdatavg-depsybtemp_lv




PEP - prdepdb1 - 10.74.5.14

Need to add 2 GB to /sybase/PEP/sapdiag

[root@prdepdb1 ibmrmalik]# df -h /sybase/PEP/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/peplogvg-pepsybdiag_lv
                      5.0G  2.2G  2.6G  46% /sybase/PEP/sapdiag

[root@prdepdb1 ibmrmalik]# vgs peplogvg
  VG       #PV #LV #SN Attr   VSize   VFree
  peplogvg   2   4   0 wz--n- 127.99g 1016.00m

[root@prdepdb1 ibmrmalik]# df -h /sybase/PEP/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/peplogvg-pepsybdiag_lv
                      6.9G  2.2G  4.5G  33% /sybase/PEP/sapdiag


vgextend peplogvg /dev/sdk

lvextend -L +2G  /dev/mapper/peplogvg-pepsybdiag_lv
resize2fs /dev/mapper/peplogvg-pepsybdiag_lv



sdk                                  8:160  0    8G  0 disk
sdl                                  8:176  0    8G  0 disk



Need to add 3 GB to /sybase/PEP/sybtemp

[root@prdepdb1 ibmrmalik]# df -h /sybase/PEP/sybtemp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pepdatavg-pepsybtemp_lv
                      5.0G  1.2G  3.6G  25% /sybase/PEP/sybtemp

[root@prdepdb1 ibmrmalik]# vgs pepdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  pepdatavg   3   7   0 wz--n- 362.99g 1012.00m

[root@prdepdb1 ibmrmalik]# df -h /sybase/PEP/sybtemp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pepdatavg-pepsybtemp_lv
                      7.9G  1.2G  6.4G  16% /sybase/PEP/sybtemp

vgextend pepdatavg /dev/sdl

lvextend -L +1G  /dev/mapper/pepdatavg-pepsybtemp_lv
resize2fs /dev/mapper/pepdatavg-pepsybtemp_lv




1-336570251	sev3
Summary: Chef_Client_is_not_running_on_TQASOLMAN.imzcloud.ibmammsap.local[PROBLEM:1473073] Date: Apr 11,2018 12:20 CUT Severity: Minor ResourceId: tqasolman TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: tqa InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Chef_status ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Chef_status Node: TQASOLMAN.imzcloud.ibmammsap.local NodeAlias: 10.7.1.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Chef_status AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3619940:tqa

[root@TQASOLMAN ibmrmalik]# which knife
/usr/bin/knife
[root@TQASOLMAN ibmrmalik]# which chef-client
/usr/bin/chef-client
[root@TQASOLMAN ibmrmalik]# /etc/init.d/chef-client status
chef-client (pid  6091) is running...



1-336574731	sev2
Summary: Lack_of_free_swap_space_on_PBBffdapdb00.imzcloud.ibmammsap.local[PROBLEM:1473533] Date: Apr 11,2018 13:20 CUT Severity: Major ResourceId: pbbffdapdb00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pbb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: PBBffdapdb00.imzcloud.ibmammsap.local NodeAlias: 10.6.7.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3620101:pbb

[root@PBBffdapdb00 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         10          4          4          0          5
-/+ buffers/cache:          4         10
Swap:           32          0         32




1-336534591
1-336534721
1-336534981
1-336560081



1-336567211	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1472402] Date: Apr 11,2018 10:52 CUT Severity: Minor ResourceId: mgggbjpeccx07 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 19.04 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJPECCX07.imzcloud.ibmammsap.local NodeAlias: 10.133.18.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3619767:mgg

[root@MGGGBJPECCX07 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  7.5G  1.8G  81% /

./root/.vnc/core.8274
-rw-------  1 root root    319360 Oct 14 16:16 MGGGBJPECCX07:7.log
-rw-------  1 root root 423711527 Apr 11 17:26 MGGGBJPECCX07:12.log
-rw-------  1 root root 423718601 Apr 11 17:26 MGGGBJPECCX07:11.log
-rw-------  1 root root 601505792 Apr 11 11:52 core.8274

./sapmnt/kernel_749/exe.tar


CMS-TR-SAP-CLIENT

CMS-SQ-SAP-TRIO-10

--------------------------------------------------------------------------------------------------------------------------------------------

11 April


1-336567291	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/home/ncdcs[PROBLEM:1472546] Date: Apr 11,2018 11:9 CUT Severity: Minor ResourceId: mgggbjdcntx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home/ncdcs InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJDCNTX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.199 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home/ncdcs AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3619801:mgg


[root@MGGGBJDCNTX02 ibmrmalik]# df -h /home/ncdcs
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ncdsapappvg-ncdcs
                      2.0G  1.5G  369M  81% /home/ncdcs

[root@MGGGBJDCNTX02 ncdcs]# find . -xdev -type f -size +500000
./HTTP/logs/access_log
./HTTP/logs/error_log



1-335091421	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1090347] Date: Mar 1,2018 11:0 CUT Severity: Minor ResourceId: daltfsdsd0001 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: toy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DALTFSDSD0001.imzcloud.ibmammsap.local NodeAlias: 10.4.1.183 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492759:toy

[root@DALTFSDSD0001 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   21G  3.8G  85% /
[root@DALTFSDSD0001 log]# df -h .
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   21G  3.8G  85% /
[root@DALTFSDSD0001 log]# pwd
/usr/local/patchagent/update/log

-rw-r--r--. 1 root root     119736 Mar  1 21:03 err.log
-rw-r--r--. 1 root root     123410 Apr 11 04:45 localprofile.txt.OLD
-rw-r--r--. 1 root root     123410 Apr 11 04:45 localprofile.txt
-rw-r--r--. 1 root root     149542 Apr 11 05:17 action.log
-rw-r--r--. 1 root root     604505 Apr 11 05:17 JDDA.log.1
-rw-r--r--. 1 root root    1000006 Apr 11 05:02 JDDA.log.4
-rw-r--r--. 1 root root    1000013 Apr 11 05:12 JDDA.log.0
-rw-r--r--. 1 root root    1000020 Apr 11 04:53 JDDA.log.3
-rw-r--r--. 1 root root    1000031 Apr 10 04:42 JDDA.log.2
-rw-r--r--. 1 root root   40081550 Apr 12 02:47 Policy.log
-rw-r--r--. 1 root root  159601087 Apr 12 02:47 updateagent.log
-rw-r--r--. 1 root root 5050930561 Apr 11 05:17 detect.log


1-336584951	sev3
Summary: Processor_load_is_too_high_on_PHSBWDEV01[PROBLEM:1476415] Date: Apr 11,2018 18:14 CUT Severity: Minor ResourceId: phsbwdev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: phs InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 9.391667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: PHSBWDEV01 NodeAlias: 10.5.6.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3621114:phs



1-336586631	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/home[PROBLEM:1480792] Date: Apr 12,2018 0:47 CUT Severity: Minor ResourceId: cldsmabap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home InstanceValue: 16.53 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDSMABAP01.imzcloud.ibmammsap.local NodeAlias: 10.198.0.76 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/home AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3623313:sm5

[root@CLDSMABAP01 ibmrmalik]# df -h /home
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_home
                      2.0G  1.3G  532M  72% /home



1-336595311	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1482062] Date: Apr 12,2018 3:35 CUT Severity: Minor ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 13.81 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3623804:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   14G   36G  28% /


1-336526261	sev3
Summary: NTP_time_is_driffted_on_PBBbwhdap00.imzcloud.ibmammsap.local[PROBLEM:1460708] Date: Apr 10,2018 6:30 CUT Severity: Warning ResourceId: pbbbwhdap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pbb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.11 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: PBBbwhdap00.imzcloud.ibmammsap.local NodeAlias: 10.6.7.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3616169:pbb


1-336551961	sev2	mail sent to cust to cleanup the temp
Summary: Free_disk_space_is_less_than_10%_on_volume_C:[PROBLEM:1466987] Date: Apr 10,2018 20:47 CUT Severity: Major ResourceId: snchbibta13 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 9.9 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: SNCHBIBTA13 NodeAlias: 10.73.11.32 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3618129:snc


	
1-336558081	sev 3
Summary: NTP_time_is_driffted_on_dlthqehap3.imzcloud.ibmammsap.local[PROBLEM:1469813] Date: Apr 11,2018 4:6 CUT Severity: Warning ResourceId: dlthqehap3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.14 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: dlthqehap3.imzcloud.ibmammsap.local NodeAlias: 10.4.5.38 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3618925:dal




1-336421351
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1428357] Date: Apr 6,2018 17:22 CUT Severity: Minor ResourceId: cldsmabap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDSMABAP01.imzcloud.ibmammsap.local NodeAlias: 10.198.0.76 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3604939:sm5




1-336434211 	sev3		10.127.155.66	root/LVYsv529		IPMI root/CPggfjj47F		hot swap error SL ticket 58490205
Summary: Drive_with_Errors_on_parhana-1024-11.xsportal.local[PROBLEM:1431341] Date: Apr 7,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_parhana-1024-11.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_parhana-1024-11. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_parhana-1024-11.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3606445:amm



so	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/hana/data[PROBLEM:1486113] Date: Apr 12,2018 13:18 CUT Severity: Major ResourceId: bi1crmdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 6.48 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1CRMDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3624930:bi1

[root@BI1CRMDBQAS01 ibmrmalik]# df -h /hana/data
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_data  772G  731G   41G  95% /hana/data

./51051151/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/BIN.TGZ
./51051151/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/DATLANGUAGES.TGZ
./51051151/DATA_UNITS/XSAC_DI_CORE_10/XSACDEVXDI12_0.ZIP
./51051151/DATA_UNITS/XSA_RT_10_LINUX_X86_64/packages/INITIAL_CONTENT.TGZ
./new/COMPLETE_DATA_BACKUP_databackup_3_1
./mnt00001/hdb00003/datavolume_0000.dat
./WholeBackup/COMPLETE_DATA_BACKUP05APR_databackup_3_1
./WholeBackup/COMPLETE_DATA_BACKUP12APR_databackup_3_1
./WholeBackup/COMPLETE_DATA_BACKUP_databackup_3_1
./WholeBackup/COMPLETE_DATA_BACKUP29MAR_databackup_3_1



1-336610191	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/data[PROBLEM:1486101] Date: Apr 12,2018 13:15 CUT Severity: Minor ResourceId: bi1erpdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 19.69 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3624919:bi1

[root@BI1ERPDBQAS01 ibmrmalik]# df -h /hana/data
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_data  768G  670G   99G  88% /hana/data

[root@BI1ERPDBQAS01 data]# find . -xdev -type f -size +1000000
./51051151HANADB/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/BIN.TGZ
./51051151HANADB/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/DATLANGUAGES.TGZ
./51051151HANADB/DATA_UNITS/XSAC_DI_CORE_10/XSACDEVXDI12_0.ZIP
./51051151HANADB/DATA_UNITS/XSA_RT_10_LINUX_X86_64/packages/INITIAL_CONTENT.TGZ
./mnt00001/hdb00001/datavolume_0000.dat
./mnt00001/hdb00003/datavolume_0000.dat
./SWPM18/SWPM10SP18_6-20009701.SAR
./back0509/COMPLETE_DATA_BACKUP_databackup_3_1
./Schedule_Backup/COMPLETE_DATA_BACKUP_databackup_3_1
./Schedule_Backup/COMPLETE_DATA_BACKUP29MAR_databackup_3_1
./Schedule_Backup/COMPLETE_DATA_BACKUP12APR_databackup_3_1
./backup15MAR/COMPLETE_DATA_BACKUP15MAR_databackup_3_1



1-336612221 sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/data


1-336610141	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/data[PROBLEM:1486077] Date: Apr 12,2018 13:11 CUT Severity: Minor ResourceId: bi1erpdbdev01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 19.73 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3624911:bi1

[root@BI1ERPDBDEV01 ibmrmalik]# df -h /hana/log
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdd1       130G   43G   88G  33% /hana/log



1-336613701	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/tmp[PROBLEM:1486492] Date: Apr 12,2018 14:25 CUT Severity: Minor ResourceId: twysapxc1app1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: twy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 2.18 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: TWYSAPXC1APP1.imzcloud.ibmammsap.local NodeAlias: 10.137.10.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625056:twy


-------------------------------------------------------------------------------------------------------------------------------------------------

13 April

1-336614181	sev2
Summary: Processor_load_is_too_high_on_sng01ammsol01.imzcloud.ibmammsap.local[PROBLEM:1486809] Date: Apr 12,2018 15:25 CUT Severity: Major ResourceId: sng01ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.4475 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: sng01ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.157 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625150:amm

[root@sng01ammsol01 ibmrmalik]# uptime
 20:10:34 up 213 days,  7:34,  1 user,  load average: 1.35, 1.05, 0.97



1-336610211	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/data[PROBLEM:1486105] Date: Apr 12,2018 13:16 CUT Severity: Minor ResourceId: bi1crmdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 17.56 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1CRMDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3624922:bi1


1-336610781	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/hana/data[PROBLEM:1486095] Date: Apr 12,2018 13:14 CUT Severity: Critical ResourceId: bi1erpdbdev01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 3.02 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3624917:bi1

[root@BI1ERPDBDEV01 ibmrmalik]# df -h /hana/data
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_data
                      384G  373G   12G  97% /hana/data

[root@BI1ERPDBDEV01 ibmrmalik]# cd /hana/data
[root@BI1ERPDBDEV01 data]# find . -xdev -type f -size +1000000
./dump/51051151HANADB/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/BIN.TGZ
./dump/51051151HANADB/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/DATLANGUAGES.TGZ
./dump/51051151HANADB/DATA_UNITS/XSAC_DI_CORE_10/XSACDEVXDI12_0.ZIP
./dump/51051151HANADB/DATA_UNITS/XSA_RT_10_LINUX_X86_64/packages/INITIAL_CONTENT.TGZ
./mnt00001/hdb00003/datavolume_0000.dat
./instlogs/SWPM18/SWPM10SP18_6-20009701.SAR
./backup08032017/log_backup_3_0_2250194368_2265566016.1487179127574
./backup08032017/log_backup_3_0_2265566016_2281684992.1487180027683
./backup08032017/log_backup_3_0_2294466304_2302859456.1487182727942
./backup08032017/log_backup_3_0_2302859456_2319635904.1487183435834
./backup08032017/log_backup_3_0_2319635904_2336406336.1487184054928
./backup08032017/log_backup_3_0_2336406336_2353182144.1487184893960
./backup08032017/log_backup_3_0_2353182144_2369958528.1487185624005
./backup08032017/log_backup_3_0_2369958528_2386733312.1487186225288
./backup08032017/log_backup_3_0_2386733312_2401628928.1487187125291
./backup08032017/log_backup_3_0_2409584128_2426359744.1487188791797
./backup08032017/log_backup_3_0_2426359744_2443134272.1487189538148
./backup08032017/log_backup_3_0_2443134272_2459902656.1487190164830
./backup08032017/log_backup_3_0_2459902656_2476679680.1487190819060
./backup08032017/log_backup_3_0_2476679680_2493452416.1487191503998
./backup08032017/log_backup_3_0_2493452416_2510229504.1487192196149
./backup08032017/log_backup_3_0_2510229504_2527002240.1487193019673
./backup08032017/log_backup_3_0_2527002240_2543772928.1487193722357
./backup08032017/log_backup_3_0_2543772928_2560548480.1487194404551
./backup08032017/log_backup_3_0_2560548480_2577320960.1487195053771
./backup08032017/log_backup_3_0_2577320960_2591788480.1487195953771
./backup08032017/log_backup_3_0_2591788480_2600811392.1487196853842
./WholeBackup/COMPLETE_DATA_BACKUP29MAR_databackup_3_1
./WholeBackup/COMPLETE_DATA_BACKUP_databackup_3_1
./WholeBackup/COMPLETE_DATA_BACKUP12APR_databackup_3_1



1-336613711	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/tmp[PROBLEM:1486494] Date: Apr 12,2018 14:25 CUT Severity: Critical ResourceId: twysapxc1app1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: twy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 2.18 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: TWYSAPXC1APP1.imzcloud.ibmammsap.local NodeAlias: 10.137.10.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625058:twy

[root@TWYSAPXC1APP1 ibmrmalik]# df -h /tmp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                      2.0G  1.6G  262M  86% /tmp




1-336604421    Business Innovation    APSSAP TECHNICAL    2-Urgent
BI1CRMDBPRD01   10.135.3.16 , Hana backup of this server is failing with error. Seems there is a hung job. Please check and clear that.

[root@BI1CRMDBPRD01 ibmrpradyumnan]# /opt/tivoli/tsm/tdp_hana/runsap
* 447: backup could not be completed: [110122] A data backup cannot be created because another data backup is running or a storage snapshot has been prepared. SQLSTATE: HY000

[root@BI1CRMDBPRD01 ibmrpradyumnan]# date
Thu Apr 12 18:01:25 AST 2018
[root@BI1CRMDBPRD01 ibmrpradyumnan]#

Summary: TSM: fra02ammtsm001 ANR2578W Schedule @428 in domain FRA_P_HANA for node BI1_BI1CRMDBPRD01_HANA has missed its scheduled start up window.~ Date: 04/12/18 05:45 CDT Severity: Minor ResourceId: bi1crmdbprd01 TicketGroup: AMM-BUR CustomerCode: bi1 InstanceId: 2578 InstanceValue: ANR2578W Schedule @428 in domain FRA_P_HANA for node BI1_BI1CRMD ComponentType: ManagementInfrastructure Component: TSM Node: BI1CRMDBPRD01 NodeAlias: 146.89.140.242 Manager: fra02ammtsm001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: TSM:TSM_SERVER:FRA02AMMTSM001 AlertGroup: TSM_SERVER_EVENT EventKey: USRD0P0MSDP:3624605:bi1


1-336622171    Business Innovation    APSSAP TECHNICAL    2-Urgent
Summary: Free_disk_space_is_less_than_10%_on_volume_/hana/log[PROBLEM:1489065] Date: Apr 12,2018 19:30 CUT Severity: Major ResourceId: bi1erpdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 10 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625689:bi1

[root@BI1ERPDBQAS01 ibmrmalik]# df -h /hana/log
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdd1       258G  235G   24G  91% /hana/log

[root@BI1ERPDBQAS01 log]# find . -xdev -type f -size +1000000
./mnt00001/hdb00003/logsegment_000_00000015.dat
./mnt00001/hdb00003/logsegment_000_00000016.dat
./mnt00001/hdb00003/logsegment_000_00000014.dat
./mnt00001/hdb00003/logsegment_000_00000003.dat
./mnt00001/hdb00003/logsegment_000_00000000.dat
./mnt00001/hdb00003/logsegment_000_00000006.dat
./backup22MAR/COMPLETE_DATA_BACKUP22MAR_databackup_3_1
./backuplog/log_backup_3_0_46676893440_46693665280.1522673544555
./backuplog/log_backup_3_0_46693665280_46710437888.1522673544556
./backuplog/log_backup_3_0_46710437888_46727215104.1522673544557
./backuplog/log_backup_3_0_46727215104_46743992320.1522673544558
./backuplog/log_backup_3_0_46743992320_46758393472.1522673581999
./backuplog/log_backup_3_0_46829928384_46840552832.1522922936623
./backuplog/log_backup_3_0_46923980224_46933041984.1523256876157
./backuplog/log_backup_3_0_46936517440_46944956096.1523264077263
./backuplog/log_backup_3_0_46949343808_46958210816.1523273078981





1-336611201    Business Innovation    APSSAP TECHNICAL    2-Urgent
BI1CRMDBPRD01   10.135.3.16 , Hana backup of this server is failing. Please check

[root@BI1CRMDBPRD01 ibmrpradyumnan]# /opt/tivoli/tsm/tdp_hana/runsap
* 447: backup could not be completed: [110122] A data backup cannot be created because another data backup is running or a storage snapshot has been prepared. SQLSTATE: HY000
[root@BI1CRMDBPRD01 ibmrpradyumnan]# date
Thu Apr 12 18:01:25 AST 2018
[root@BI1CRMDBPRD01 ibmrpradyumnan]#
Summary: TSM: fra02ammtsm001 ANR2579E Schedule @434 in domain FRA_P_HANA for node BI1_BI1CRMDBPRD01_HANA failed (return code 191).~ Date: 04/12/18 09:58 CDT Severity: Minor ResourceId: bi1crmdbprd01 TicketGroup: AMM-BUR CustomerCode: bi1 InstanceId: 2579 InstanceValue: ANR2579E Schedule @434 in domain FRA_P_HANA for node BI1_BI1CRMD ComponentType: ManagementInfrastructure Component: TSM Node: BI1CRMDBPRD01 NodeAlias: 146.89.140.242 Manager: fra02ammtsm001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: TSM:TSM_SERVER:FRA02AMMTSM001 AlertGroup: TSM_SERVER_EVENT EventKey: USRD0P0MSDP:3625112:bi1

/dev/mapper/tsmbackup_vg-tsmpool_lv   1008G  901G   57G  95% /TSMSTG/METAPOOL
/dev/mapper/tsmdbalog_vg-tsmalog_lv    296G  251G   31G  90% /TSMLOGS/ALOG




1-336611121  -  P1  -  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC) 
Summary: Zabbix_agent_on_C1ECCP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1486595] Date: Apr 12,2018 14:36 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625071:pnc




1-335091421	sev3
Free_disk_space_on_OS_filesystem Node: DALTFSDSD0001.imzcloud.ibmammsap.local NodeAlias: 10.4.1.183 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492759:toy

-rwxrwxrwx.   1 root   root     1941200 Jun 15  2017 DALTFSDSD0001_JSAGENT.log
-rwxrwxrwx.   1 root   root    38906936 Jun 15  2017 DALTFSDSD0001.log
-rwxrwxrwx.   1 root   root    47090593 Jun 15  2017 DALTFSDSD0001_XP.log
-rwxrwxrwx.   1 root   root   186234368 Jun 15  2017 DALTFSDSD0001_BS.log





1-336628501 / IBM MSD Infras - Cloud Shared / SEV1 / Siebel / not validated / Summary: 10.245.120.36(10.245.120.36) is unreachable
Summary: 10.245.120.36(10.245.120.36) is unreachable. The host has failed to respond to the ping request. Date: Apr 13,2018 2:59 CUT Severity: Critical ResourceId: ri3vw030 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ics InstanceId: 10.245.120.36 InstanceValue: unreachable InstanceSituation: Node Status ComponentType: ComputerSystem Component: NodeAvail SubComponent: Ping Node: 10.245.120.36 NodeAlias: 10.245.120.36 Manager: Ping Probe Agent: Ping probe on ri3pa010 AlertKey: ncopingprobe AlertGroup: PingStatus EventKey: USRD0P0MSDP:3626676:ics




1-336633801  - P1 - AMM - Siebel - Not validated - Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1492367] Date: Apr 13,2018 3:10 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3626691:amm

[root@wdc04ammsol01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4544) is running...
[root@wdc04ammsol01 ibmrmalik]# uptime
 22:33:56 up 156 days, 15:42,  3 users,  load average: 8.54, 12.45, 18.68




1-336587021    IBM AMM Infrastructure    AMM-DELIVERY-TECH    2-Urgent
MGGGBJSECCX02   10.133.18.164  ,  There is a read error on '/var/opt/ds_agent/am/lpt$vpn.181' in this server. Please check.

The file is skipped.~~ Date: 04/11/18 15:30 CDT Severity: Minor ResourceId: lon02ammtsm001 TicketGroup: AMM-BUR CustomerCode: amm InstanceId: 4047MGG_MGGGBJSECCX02_FIL>LON02AMMTSM001:DLY_INC_2230 InstanceValue: ANE4047E There is a read error on '/var/opt/ds_agent/am/lpt$vpn. ComponentType: ManagementInfrastructure Component: TSM Node: lon02ammtsm001 NodeAlias: 10.133.18.164 Manager: lon02ammtsm001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: TSM:ADSM_BACKUP_ARCHIVE_CLIENT:MGG_MGGGBJSECCX02_FIL>LON02AMMTSM001 AlertGroup: TSM_CLIENT_EVENT EventKey: USRD0P0MSDP:3622795:amm

[root@MGGGBJSECCX02 patterns]# ls -ltr
total 129756
-rw-r--r-- 1 root root 38756279 Apr 12 21:13 icrc$oth.185
-rw-r--r-- 1 root root    43803 Apr 12 21:13 tmblack.239
-rw-r--r-- 1 root root  1760381 Apr 12 21:13 tmwhite.495
-rw-r--r-- 1 root root  8673080 Apr 12 21:13 ssaptn.939
-rw-r--r-- 1 root root 83624069 Apr 12 21:13 lpt$vpn.185
-rw-r--r-- 1 root root      915 Apr 12 21:13 components.xml
[root@MGGGBJSECCX02 patterns]# cat lpt$vpn.185
cat: lpt.185: No such file or directory
[root@MGGGBJSECCX02 patterns]# pwd
/var/opt/ds_agent/patterns




1-336611421	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1487158] Date: Apr 12,2018 16:26 CUT Severity: Minor ResourceId: iplsas4ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ipl InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 18.33 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: iplsas4ap01.imzcloud.ibmammsap.local NodeAlias: 10.138.1.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625232:ipl

[root@iplsas4ap01 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.8G  1.9G  61% /var




1-336534981	sev3
Summary: NTP_time_is_driffted_on_LBDBOQQASApp3.imzcloud.ibmammsap.local[PROBLEM:1462924] Date: Apr 10,2018 11:57 CUT Severity: Warning ResourceId: lbdboqqasapp3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 112.33 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDBOQQASApp3.imzcloud.ibmammsap.local NodeAlias: 10.8.8.59 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3616849:lbd




1-336621301    Manitoba Telecom Services - SAP HEC-AMM    CMS-SQ-SAP-TRIO-9    2-Urgent
Summary: Processor_load_is_too_high_on_prdepapp1.imzcloud.ibmammsap.local[PROBLEM:1488892] Date: Apr 12,2018 19:10 CUT Severity: Major ResourceId: prdepapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 3.2125 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: prdepapp1.imzcloud.ibmammsap.local NodeAlias: 10.74.5.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625630:mtb

[root@prdepapp1 ~]# uptime
 00:47:55 up 496 days, 15:03,  0 users,  load average: 0.32, 0.29, 0.16



1-336621381    Manitoba Telecom Services - SAP HEC-AMM    CMS-SQ-SAP-TRIO-9    2-Urgent
Summary: Processor_load_is_too_high_on_prdbods01.imzcloud.ibmammsap.local[PROBLEM:1488926] Date: Apr 12,2018 19:11 CUT Severity: Major ResourceId: prdbods01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.2925 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: prdbods01.imzcloud.ibmammsap.local NodeAlias: 10.74.5.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625639:mts


[root@prdbods01 ~]# uptime
 00:58:34 up 346 days, 10:00,  1 user,  load average: 0.00, 0.00, 0.00



1-336618657 is the  change   1-336634867  
snapshot
VM snapshot of 10.6.2.12 (JQ1) - svjq1srv0	A0EASG014XVM004 




1-336639893	sev 3
Team,

Could you please check the Password status of SAPFSM User on fra02ammsol01(146.89.140.220)? since we are getting Password expire error while trying to connect to the DB2 Database.
If so please reset the password.






1-336134541	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1371753] Date: Mar 28,2018 11:36 CUT Severity: Minor ResourceId: ercnwd01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: egr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 19.68 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: ercnwd01.imzcloud.ibmammsap.local NodeAlias: 10.5.1.104 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3577393:egr

[root@ercnwd01 ibmrmalik]# df -k /
Filesystem           1K-blocks     Used Available Use% Mounted on
/dev/mapper/vg00-lv_root
                      26437900 22036364   3591760  86% /



./var/cache/yum/x86_64/6Server/rhel-6-server-rpms/2fdb7b6222da7583b7cbd370dd55a54095f1c754-primary.xml.gz.sqlite
./var/tsm/dsmsched_syb.log
./home/ibmvbotas/ASE Sybase_16_SP02_PL07/ASEBS16002_7-10013280.SAR
./usr/local/patchagent/update/log/detect.log
./usr/local/patchagent/mcescan/var/cache/yum/rhel-x86_64-server-6/primary.xml.gz.sqlite

[root@ercnwd01 bin]# pwd
/opt/tivoli/tsm/client/ba/bin
./opt/tivoli/tsm/client/ba/bin/dsmsched.log
-rw-r--r--. 1 root root    1918502 Apr 13 00:04 dsminstr.log
-r--r--r--. 1 root bin     2846516 Mar 28  2017 dsm.jar
-r-x------. 1 root bin    11526520 Mar 28  2017 dsmenc
-rwxrwxrwx. 1 root root   12414928 Apr 13 10:04 dsmwebcl.log
-r-sr-xr-x. 1 root bin    13590402 Mar 28  2017 dsmtca
-r-xr-xr-x. 1 root bin    13654988 Mar 28  2017 dsmadmc
-r-xr-xr-x. 1 root bin    13783392 Mar 28  2017 dsmcad
-r-xr-xr-x. 1 root bin    14402963 Mar 28  2017 dsmc
-r-xr-xr-x. 1 root bin    15607902 Mar 28  2017 dsmagent
-r-xr-xr-x. 1 root bin    93122022 Mar 28  2017 libTsmViSdk.so
-rwxrwxrwx. 1 root root 1038984432 Apr 13 10:04 dsmsched.log






1-336435501	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1431632] Date: Apr 7,2018 8:9 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 1.03 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3606579:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   14G   36G  28% /

---------------------------------------------------------------------------------------------------------------------------------------------------

16 April



1-336693501	sev2
Disk full Solman server


1-335091421	sev3
AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DALTFSDSD0001.imzcloud.ibmammsap.local NodeAlias: 10.4.1.183 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492759:toy

[root@DALTFSDSD0001 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   21G  3.7G  85% /

[root@DALTFSDSD0001 /]# find . -xdev -type f -size +1000000
./usr/local/patchagent/update/log/detect.log

[root@DALTFSDSD0001 /]# find . -xdev -type f -size +500000
./var/cache/yum/x86_64/6Server/rhel-6-server-rpms/97aca6360dd72007b0f5561d93cce5ab0a4a98e9-primary.xml.gz.sqlite
./usr/local/patchagent/update/log/detect.log
./usr/local/patchagent/mcescan/var/cache/yum/rhel-x86_64-server-6/primary.xml.gz.sqlite
./opt/nimsoft/robot/q2.rdb




1-336695061    2-Urgent    SMRT Corp - SAP HEC-AMM        Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1523087] Date: Apr 16,2018 1:50 CUT Severity: Major ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 6.22 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3634087:sm5





1-336595661	sev2
Summary: Lack_of_free_swap_space_on_bw-prd.imzcloud.ibmammsap.local[PROBLEM:1482533] Date: Apr 12,2018 4:44 CUT Severity: Major ResourceId: bw-prd TicketGroup: AMM-DELIVERY-TECH CustomerCode: tqa InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 49.26 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: bw-prd.imzcloud.ibmammsap.local NodeAlias: 10.7.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3623913:tqa

[root@bw-prd ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0         23          0         24
-/+ buffers/cache:          6         25
Swap:           13          8          5


top - 05:45:13 up 46 days, 10:36,  1 user,  load average: 2.00, 0.70, 0.51
Tasks: 371 total,   5 running, 366 sleeping,   0 stopped,   0 zombie
Cpu(s): 28.5%us,  1.9%sy,  0.0%ni, 69.0%id,  0.2%wa,  0.0%hi,  0.5%si,  0.0%st
Mem:    31.352G total,   30.831G used,  533.496M free,  129.840M buffers
Swap:   13.766G total, 8446.117M used, 5649.879M free,   24.206G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
16255 tbpadm    20   0 1430m  52m 1616 S  0.7  0.2  32:57.83 741m en.sapTBP_ASCS
 4266 root      20   0  257m  38m 1056 S  0.0  0.1   0:04.84  16m chef-client
 3806 sapadm    20   0  649m  16m 1804 S  0.0  0.1   3:06.73  11m sapstartsrv
 4080 tbpadm    20   0  719m  33m  14m S  0.0  0.1   9:33.71  10m sapstartsrv
 3886 tbpadm    20   0  849m  21m 2576 S  0.0  0.1   6:41.00  10m sapstartsrv
 3702 root      20   0  106m  912  660 S  0.0  0.0   0:37.58 6352 saphostexec
16254 tbpadm    20   0 71424 3600 1200 S  0.0  0.0   0:38.74 5040 ms.sapTBP_ASCS





1-336622421	sev3
Read error on '/var/opt/ds_agent/am/icrc$oth.183'.	
lrwxrwxrwx. 1 root root       23 Apr 15 20:28 tmwhite.495 -> ../patterns/tmwhite.495
lrwxrwxrwx. 1 root root       23 Apr 15 20:28 tmblack.239 -> ../patterns/tmblack.239
lrwxrwxrwx. 1 root root       22 Apr 15 20:28 ssaptn.939 -> ../patterns/ssaptn.939
lrwxrwxrwx. 1 root root       23 Apr 15 20:28 lpt$vpn.191 -> ../patterns/lpt$vpn.191
lrwxrwxrwx. 1 root root       24 Apr 15 20:28 icrc$oth.191 -> ../patterns/icrc$oth.191

no file with .183. We have one with 191.




1-336639261	sev3	10.140.48.156	root/NZsH36Le	IPMI root/UZDEuyc2pp	58612185	ssh or IPMI not accessible raised with SL 58606845
Summary: Drive_with_Errors_on_monhana-1024-4.xsportal.local[PROBLEM:1493889] Date: Apr 13,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_monhana-1024-4.xsportal.local InstanceValue: Media Error Count = 15 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_monhana-1024-4.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_monhana-1024-4.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3627102:amm	




1-336641701	sev2
Summary: Processor_load_is_too_high_on_SK3BWQAS01.imzcloud.ibmammsap.local[PROBLEM:1494513] Date: Apr 13,2018 8:21 CUT Severity: Major ResourceId: sk3bwqas01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.47 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SK3BWQAS01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3627223:sk3

[root@SK3BWQAS01 ibmrmalik]# uptime
 08:00:44 up 626 days, 14:51,  1 user,  load average: 11.64, 11.05, 10.69

 09:47:38 up 626 days, 16:38,  2 users,  load average: 2.22, 2.16, 2.38

[root@SK3BWQAS01 ibmrmalik]# uptime
 09:48:18 up 626 days, 16:39,  2 users,  load average: 1.42, 1.97, 2.30


[root@SK3BWQAS01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         31          0          4          1         24
-/+ buffers/cache:          5         26
Swap:           23          0         23




1-336644561	sev3
Please provide Used Storage for the systems in attachment





1-336662771	sev3
Summary: Zabbix_data_sender_processes_more_than_75%_busy




1-336673601	sev2
Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:1504547] Date: Apr 14,2018 4:52 CUT Severity: Major ResourceId: sng01ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.5075 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SNG01AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.164 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3630219:amm

 03:54:13 up 55 days, 10:33,  1 user,  load average: 0.76, 0.77, 0.69



1-336318041 - icmbnd File missing in DU3

IP 10.78.22.35
hostname  smedidevdu3
HANA SID:  DU3
Instance 60
IP 10.78.22.34


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

17 April

1-336639261	sev3	10.140.48.156	root/NZsH36Le	Ticket 58639827
Summary: Drive_with_Errors_on_monhana-1024-4.xsportal.local[PROBLEM:1493889] Date: Apr 13,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_monhana-1024-4.xsportal.local InstanceValue: Media Error Count = 15 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_monhana-1024-4.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_monhana-1024-4.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3627102:amm	





1-336693221    Incident    1    MNG    4/15/2018    LONMAGSLM0010    Summary:  
Zabbix_agent_on_LONMAGSLM0010.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_LONMAGSLM0010.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1521254] Date: Apr 15,2018 21:31 CUT Severity: Critical ResourceId: lonmagslm0010 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LONMAGSLM0010.imzcloud.ibmammsap.local NodeAlias: 10.69.0.77 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3633572:mng



Sev1 > 1-336722501
3.x - SCO - 1-336722501 - SL-Toronto-01 - Central American Retail Sourcing (C - SAP09 - SAP HEC-AMM - Initial - PP6 Is Not Able To Process Messages - Instance Is Not RespondingTime Line :
9.00 PM ET - Alvin Thew / Oncall DPE HEC Update : As per client,  PP6 is not able to process messages. Instance is not responding.
- Client is requesting to reboot (JAVA + DB)
- Provide approval as DPE9.09 PM ET - Bharath Kumar Reddy : IC Update : Provide Action Plan
1-> stopping PP6 app vsappp6-ci (10.9.4.221) (J2EE SCS/CI) - In progress
2-> stopping PP6 DB  vsappp6-db (10.9.4.208)
3-> starting  PP6 DB vsappp6-db (10.9.4.208)
4-> starting PP6 app vsappp6-ci (10.9.4.221) (J2EE SCS/CI)


vsappp6-ci (10.9.4.221)	vcenter name A0E3CA014XVM021
Toronto

A0E3CA016BCA224
Normal
Unknown
3.91 TB
1.15 TB
4/17/2018 7:17:10 AM
Enabled
Disabled






1-336720681    Egyptian Refining Company    AMM-DELIVERY-TECH    2-Urgent    NetCool
Summary: Processor_load_is_too_high_on_ercerpd1.imzcloud.ibmammsap.local[PROBLEM:1533412] Date: Apr 16,2018 22:23 CUT Severity: Major ResourceId: ercerpd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: egr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.345 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: ercerpd1.imzcloud.ibmammsap.local NodeAlias: 10.5.1.101 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3636625:egr

[root@ercerpd1 ibmrmalik]# w
 05:46:19 up 45 days, 19:19,  1 user,  load average: 1.21, 1.24, 1.30

ttop - 05:48:52 up 45 days, 19:21,  1 user,  load average: 1.09, 1.16, 1.26
Tasks: 253 total,   2 running, 251 sleeping,   0 stopped,   0 zombie
Cpu(s): 54.9%us,  1.8%sy,  0.0%ni, 43.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.572G total,   15.005G used,  580.566M free,  446.152M buffers
Swap:   13.766G total, 3551.586M used,   10.297G free, 7613.176M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
13129 erdadm    20   0 14.6g 150m  56m R 98.4  0.9  64611:08 dw.sapERD_DVEBMGS10 pf=/usr/sap/ERD/SYS/profile/ERD_DVEBMGS10_ercerpd1




1-336722841	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1532387] Date: Apr 16,2018 20:3 CUT Severity: Minor ResourceId: twysapdd1db1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: twy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 19.88 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: TWYSAPDD1DB1.imzcloud.ibmammsap.local NodeAlias: 10.137.10.27 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3636312:twy	


./Staging/Sybase_Update/ebf27577/archives/ase_mm/ase.iam.zip
./Staging/Syb_1600205_RDBMS/SYBASE_LINUX_X86_64/archives/ase_mm/ase.iam.zip

-rw-r--r--  1 sybdd1 sapsys   1638400 Apr  9 13:52 ASEUP_SUPPORT_20180409_135230.tar
-rw-r--r--  1 sybdd1 sapsys   1699840 Apr  9 14:05 ASEUP_SUPPORT_20180409_135922.tar

-r-xr-xr-x 1 nobody nobody 72658640 Jan 20  2017 saphostagent.sar
[root@TWYSAPDD1DB1 archives]# pwd
/Staging/Syb_1600205_RDBMS/SYBASE_LINUX_X86_64/archives




1-336719761	sev3
Summary: Processor_load_is_too_high_on_PHSBWDEV01[PROBLEM:1531396] Date: Apr 16,2018 18:11 CUT Severity: Minor ResourceId: phsbwdev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: phs InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 11.7 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: PHSBWDEV01 NodeAlias: 10.5.6.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3636036:phs




1-336716261	sev2
Summary: Processor_load_is_too_high_on_snchecaqa15.imzcloud.ibmammsap.local[PROBLEM:1531750] Date: Apr 16,2018 18:43 CUT Severity: Major ResourceId: snchecaqa15 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.329444 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: snchecaqa15.imzcloud.ibmammsap.local NodeAlias: 10.73.12.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3636087:snc

[root@snchecaqa15 ibmrmalik]# w
 00:53:06 up 230 days, 12:57,  1 user,  load average: 54.37, 54.32, 54.21

[root@snchecaqa15 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         35         27          5          1         23
-/+ buffers/cache:         10         52
Swap:            7          0          7

ps aux

top - 01:08:52 up 230 days, 13:13,  1 user,  load average: 58.40, 57.40, 56.03
Tasks: 694 total,   1 running, 693 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.7%us,  4.0%sy,  0.0%ni, 94.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.901G total,   35.680G used,   27.221G free, 1822.023M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   23.547G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 88053 root      20   0 44916 8736 2768 S 100.0  0.0 437:31.82 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile


statfs("/usr/sap/QR1", {f_type="EXT2_SUPER_MAGIC", f_bsize=4096, f_blocks=5160607, f_bfree=3538564, f_bavail=3276420, f_files=1310720, f_ffree=1272929, f_fsid={-1738194383, 207401707}, f_namelen=255, f_frsize=4096}) = 0
statfs("/usr/sap/DAA", {f_type="EXT2_SUPER_MAGIC", f_bsize=4096, f_blocks=774084, f_bfree=357508, f_bavail=318190, f_files=196608, f_ffree=193956, f_fsid={-2072058733, 1365831516}, f_namelen=255, f_frsize=4096}) = 0
statfs("/usr/sap/ccms", {f_type="EXT2_SUPER_MAGIC", f_bsize=4096, f_blocks=516052, f_bfree=498879, f_bavail=472665, f_files=131072, f_ffree=131056, f_fsid={263157320, -459834775}, f_namelen=255, f_frsize=4096}) = 0
statfs("/sapmnt/QR1",


[root@snchecaqa15 /]# cat /etc/fstab |grep /sapmnt/QR1
#/dev/qr1appvg/qr1sapmnt_lv     /sapmnt/QR1     ext3    _netdev,defaults        1       2
snchecaqa11:/sapmnt/QR1           /sapmnt/QR1 nfs   defaults  1  2




1-336713671	sev2
Summary: Processor_load_is_too_high_on_snchecaqa14.imzcloud.ibmammsap.local[PROBLEM:1531088] Date: Apr 16,2018 17:49 CUT Severity: Major ResourceId: snchecaqa14 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.054444 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: snchecaqa14.imzcloud.ibmammsap.local NodeAlias: 10.73.12.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3635942:snc

[root@snchecaqa14 ibmrmalik]# w
 01:38:57 up 230 days, 16:28,  1 user,  load average: 68.54, 67.47, 65.26

top - 01:39:27 up 230 days, 16:29,  1 user,  load average: 68.64, 67.58, 65.36
Tasks: 692 total,   2 running, 690 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.6%us,  4.1%sy,  0.0%ni, 94.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.901G total,   35.211G used,   27.690G free, 1766.551M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   21.998G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  6989 root      20   0 44872 8716 2740 R 100.0  0.0 368:06.01 saposcol

statfs("/usr/sap/ccms", {f_type="EXT2_SUPER_MAGIC", f_bsize=4096, f_blocks=516052, f_bfree=498879, f_bavail=472665, f_files=131072, f_ffree=131056, f_fsid={1632642513, 374291064}, f_namelen=255, f_frsize=4096}) = 0
statfs("/sapmnt/QR1",

[root@snchecaqa14 ibmrmalik]# cat /etc/fstab |grep /sapmnt
#/dev/qr1appvg/qr1sapmnt_lv     /sapmnt/QR1     ext3    _netdev,defaults        1       2
snchecaqa11:/sapmnt/QR1           /sapmnt/QR1 nfs   defaults  1  2




10.72.1.99    snchecada11	10.73.11.99(IMZ ip)




1-336713631	sev1
ummary: Zabbix_agent_on_snchecaqa15.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1531079] Date: Apr 16,2018 17:47 CUT Severity: Critical ResourceId: snchecaqa15 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: snchecaqa15.imzcloud.ibmammsap.local NodeAlias: 10.73.12.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3635937:snc

[root@snchecaqa15 ibmrmalik]# uptime
 03:24:04 up 230 days, 15:28,  2 users,  load average: 83.74, 82.98, 81.85
[root@snchecaqa15 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  39982) is running...



1-336712861	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1529667] Date: Apr 16,2018 15:34 CUT Severity: Minor ResourceId: c1bwp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 16.6 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: C1BWP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3635554:pnc

[root@C1BWP ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   20G  4.0G  84% /

./var/spool/abrt/ccpp-2018-04-16-15:32:53-34696/coredump

--------------------------------------------------------------------------------------------------------------------------------------------------------

18 April

1-336751231	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1541869] Date: Apr 17,2018 16:8 CUT Severity: Minor ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0.25 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3639208:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   14G   36G  28% /


1-336766713
svjq1srv0	snapshot	AGEAS
vm snapshot for csr 1-336727368

host: svjq1srv0	A0EASG014XVM004		10.6.2.12


1-335091421	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1090347] Date: Mar 1,2018 11:0 CUT Severity: Minor ResourceId: daltfsdsd0001 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: toy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DALTFSDSD0001.imzcloud.ibmammsap.local NodeAlias: 10.4.1.183 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3492759:toy

[root@DALTFSDSD0001 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   20G  4.1G  84% /

[root@DALTFSDSD0001 ibmrmalik]# vgs vg00
  VG   #PV #LV #SN Attr   VSize  VFree
  vg00   2   3   0 wz--n- 59.50g 15.00g

#lvextend -L +5G  /dev/mapper/vg00-lv_root 
# resize2fs /dev/mapper/vg00-lv_root 


[root@DALTFSDSD0001 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       31G   20G  8.8G  70% /




1-336620711	sev 3
Summary: NTP_time_is_driffted_on_MG2ERPPRDDB.imzcloud.ibmammsap.local[PROBLEM:1487533] Date: Apr 12,2018 17:8 CUT Severity: Warning ResourceId: mg2erpprddb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mg2 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 5.78 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: MG2ERPPRDDB.imzcloud.ibmammsap.local NodeAlias: 10.198.3.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3625326:mg2

[root@MG2ERPPRDDB ibmrmalik]# ntpstat
unsynchronised
   polling server every 1024 s
[root@MG2ERPPRDDB ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 sng01ammadc001. 146.89.140.139   7 u  809 1024  377   25.659  148577. 1438.65
 sng01ammadc002. 146.89.140.138   7 u   72 1024  377    0.730  148806. 1418.06




1-336768241 2-Urgent    Summary: Processor_load_is_too_high_on_DLTHPEHP2.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_DLTHPEHP2.imzcloud.ibmammsap.local[PROBLEM:1547179] Date: Apr 18,2018 3:13 CUT Severity: Major ResourceId: dlthpehp2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.2375 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: DLTHPEHP2.imzcloud.ibmammsap.local NodeAlias: 10.4.5.54 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641069:dal

[root@DLTHPEHP2 ibmrmalik]# uptime
 23:48:45 up 200 days,  1:47,  1 user,  load average: 0.41, 0.93, 4.61
[root@DLTHPEHP2 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         56          6         21          0         29
-/+ buffers/cache:         26         36
Swap:           20          3         17

asks: 434 total,   1 running, 433 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.8%us,  0.2%sy,  0.0%ni, 97.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.914G total,   56.453G used, 6616.258M free,  319.809M buffers
Swap:   20.762G total, 3145.477M used,   17.690G free,   29.589G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
48721 hpeadm    20   0 59.5g 2.4g 681m S 33.9  3.7  43:39.57 HPE_02_BTC_W54
56644 root      20   0  540m  28m 9236 S  1.8  0.0  51:39.52 BESClient
 1485 root      20   0     0    0    0 S  0.4  0.0  65:28.40 flush-253:0





1-336766021	sev2
Summary: Processor_load_is_too_high_on_DLTHPEHP3.imzcloud.ibmammsap.local[PROBLEM:1547178] Date: Apr 18,2018 3:13 CUT Severity: Major ResourceId: dlthpehp3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.115 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: DLTHPEHP3.imzcloud.ibmammsap.local NodeAlias: 10.4.5.55 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641068:dal

23:45:14 up 200 days,  1:44,  1 user,  load average: 0.25, 1.03, 5.39

[root@DLTHPEHP3 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         56          6         24          0         34
-/+ buffers/cache:         22         40
Swap:           20          6         13

top - 23:46:07 up 200 days,  1:45,  1 user,  load average: 0.15, 0.88, 5.11
Tasks: 433 total,   3 running, 429 sleeping,   0 stopped,   1 zombie
Cpu(s): 10.8%us,  0.4%sy,  0.0%ni, 88.7%id,  0.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    62.914G total,   56.580G used, 6486.344M free,  358.363M buffers
Swap:   20.762G total, 6976.359M used,   13.949G free,   34.217G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
20698 hpeadm    20   0 58.1g  16g  15g R 30.2 25.6 632:40.72 HPE_03_DIA_W29
30109 hpeadm    20   0 58.0g 3.7g 3.6g S 27.9  5.9   6:36.32 HPE_03_DIA_W10
27091 hpeadm    20   0 58.0g 8.6g 8.5g R 26.5 13.7  55:16.81 HPE_03_DIA_W3
21111 hpeadm    20   0 58.0g  10g  10g S 20.9 17.3  43:39.46 HPE_03_DIA_W21
 4304 daaadm    20   0 7276m 562m 9460 S 11.6  0.9   3072:29 jstart
 2506 hpeadm    20   0 58.1g  13g  13g S  7.6 21.1 141:38.16 HPE_03_DIA_W31
16015 hpeadm    20   0 58.0g  15g  14g S  4.0 24.1 372:26.19 HPE_03_DIA_W18





1-336768531   IBM AMM Infrastructure   P1 
Summary: Zabbix_agent_on_jeremynew.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1547571] Date: Apr 18,2018 4:14 CUT Severity: Critical ResourceId: jeremynew TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: jeremynew.imzcloud.ibmammsap.local NodeAlias: 146.89.142.243 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641171:amm




1-336766171  -P1 - SM5 - SAP HEC-AMM - Siebel - Not Validated
Summary: Zabbix_agent_on_cldbpcdtbp1dr.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1547620] Date: Apr 18,2018 4:16 CUT Severity: Critical ResourceId: cldbpcdtbp1dr TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: cldbpcdtbp1dr.imzcloud.ibmammsap.local NodeAlias: 10.204.0.142 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641200:sm5

[root@cldbpcdtbp1dr ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  39269) is running...
[root@cldbpcdtbp1dr ~]# uptime
 05:50:37 up 515 days, 18:57,  2 users,  load average: 0.27, 0.46, 0.67




1-336780641 - Sev1 - BI1 - AMM-SAP - Siebel - Not Validated - Summary: Zabbix_agent_on_BI1ERPAPDEV01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_BI1ERPAPDEV01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548010] Date: Apr 18,2018 5:6 CUT Severity: Critical ResourceId: bi1erpapdev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: bi1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: BI1ERPAPDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641801:bi1

[root@BI1ERPAPDEV01 ~]# /etc/init.d/zabbix-agent  status
zabbix_agentd (pid  4067) is running...
[root@BI1ERPAPDEV01 ~]# uptime
 08:28:28 up 299 days,  6:53,  1 user,  load average: 0.00, 0.01, 0.00




1-335014541	Dallas`	sev3
Scan for AV1 has 23 deviations review posted file at http://9.58.92.198/reports/3xHCD/2018_Q1_AV1_health_check_results.zip


/etc/init.d/zabbix-agent status




1-336785731    I.S. Sklavenitis S.A    AMM-DELIVERY-TECH    1-Critical
Summary: Zabbix_agent_on_SK3PODEV01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548364] Date: Apr 18,2018 5:32 CUT Severity: Critical ResourceId: sk3podev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: SK3PODEV01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642033:sk3

[root@SK3PODEV01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  20607) is running...
[root@SK3PODEV01 ibmrmalik]# uptime
 09:31:11 up 516 days, 17:36,  2 users,  load average: 0.15, 0.25, 0.18




1-336768551    St Jude Medical  Dallas - SAP HEC    AMM-DELIVERY-TECH    1-Critical
Summary: Zabbix_agent_on_judhdmart03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1547575] Date: Apr 18,2018 4:15 CUT Severity: Critical ResourceId: judhdmart03 TicketGroup: AMM-DELIVERY-TECH CustomerCode: jud InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: judhdmart03.imzcloud.ibmammsap.local NodeAlias: 10.196.4.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641175:jud

[root@judhdmart03 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  10609) is running...
[root@judhdmart03 ibmrmalik]# uptime
 06:35:54 up 24 days, 13:44,  2 users,  load average: 2.32, 9.43, 6.00



1-336785751    Promociones Habitat S.A.    AMM-DELIVERY-TECH    1-Critical
Summary: Zabbix_agent_on_PHSBWPRD01_is_unavailable[PROBLEM:1548363] Date: Apr 18,2018 5:32 CUT Severity: Critical ResourceId: phsbwprd01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: phs InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: PHSBWPRD01 NodeAlias: 10.5.6.6 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642031:phs

System Boot Time:          4/1/2018, 5:14:26 PM
Zabbix service is up and fine




1-336786311    Promociones Habitat S.A.    AMM-DELIVERY-TECH    1-Critical
Summary: Zabbix_agent_on_PHSSAPPRD01_is_unavailable[PROBLEM:1548501] Date: Apr 18,2018 5:36 CUT Severity: Critical ResourceId: phssapprd01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: phs InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: PHSSAPPRD01 NodeAlias: 10.5.6.7 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642153:phs

System Boot Time:          4/1/2018, 5:19:43 PM
Zabbix agent running



1-336784511    West African Cotton Company    CMS-SQ-SAP-TRIO-11    1-Critical
Summary: Zabbix_agent_on_AFRFIORIDEV.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548329] Date: Apr 18,2018 5:31 CUT Severity: Critical ResourceId: afrfioridev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRFIORIDEV.imzcloud.ibmammsap.local NodeAlias: 10.197.1.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641996:afr

[root@AFRFIORIDEV ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9412) is running...
[root@AFRFIORIDEV ibmrmalik]# uptime
 08:59:16 up 135 days, 11:24,  1 user,  load average: 0.03, 0.14, 0.36




1-336681681	sev3	Frankfurt	10.134.17.82	root/ZJGEpn7P	Ticket 58693047 
Summary: Drive_with_Errors_on_fraha-1024-10.xsportal.local[PROBLEM:1515200] Date: Apr 15,2018 7:7 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_fraha-1024-10.xsportal.local InstanceValue: Media Error Count = 2 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_fraha-1024-10.xs Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_fraha-1024-10.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3632252:amm






1-336785191    1-Critical    West African Cotton Company    AFR
Summary: Zabbix_agent_on_AFRSH4PRD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548383] Date: Apr 18,2018 5:33 CUT Severity: Critical ResourceId: afrsh4prd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRSH4PRD.imzcloud.ibmammsap.local NodeAlias: 10.197.0.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642052:afr

[root@AFRSH4PRD ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9471) is running...
[root@AFRSH4PRD ibmrmalik]# uptime
 09:46:01 up 134 days, 12:15,  1 user,  load average: 0.00, 0.02, 0.04



1-336788051    1-Critical    West African Cotton Company    AFR
Summary: Zabbix_agent_on_AFRFIORIPRD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548641] Date: Apr 18,2018 5:44 CUT Severity: Critical ResourceId: afrfioriprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRFIORIPRD.imzcloud.ibmammsap.local NodeAlias: 10.197.0.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642208:afr



1-336787611    1-Critical    West African Cotton Company    AFR
Summary: Zabbix_agent_on_AFRS4HQADB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548306] Date: Apr 18,2018 5:30 CUT Severity: Critical ResourceId: afrs4hqadb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRS4HQADB.imzcloud.ibmammsap.local NodeAlias: 10.197.1.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641973:afr

[root@AFRS4HQADB ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  35571) is running...
[root@AFRS4HQADB ibmrmalik]# uptime
 09:53:33 up 246 days, 17:31,  1 user,  load average: 0.18, 0.26, 0.35




1-336787621    1-Critical    West African Cotton Company    AFR
Summary: Zabbix_agent_on_AFRS4HDEV.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548321] Date: Apr 18,2018 5:30 CUT Severity: Critical ResourceId: afrs4hdev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRS4HDEV.imzcloud.ibmammsap.local NodeAlias: 10.197.1.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641988:afr

[root@AFRS4HDEV ibmrmalik]# uptime
 09:56:48 up 135 days, 12:45,  2 users,  load average: 0.01, 0.03, 0.08
[root@AFRS4HDEV ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  108620) is running...




1-336786121    1-Critical    West African Cotton Company    AFR
Summary: Zabbix_agent_on_AFRS4HDEVDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548463] Date: Apr 18,2018 5:34 CUT Severity: Critical ResourceId: afrs4hdevdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRS4HDEVDB.imzcloud.ibmammsap.local NodeAlias: 10.197.1.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642115:afr



1-336785361 sev1
Summary: Zabbix_agent_on_AFRFIORIQA.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548409] Date: Apr 18,2018 5:33 CUT Severity: Critical ResourceId: afrfioriqa TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRFIORIQA.imzcloud.ibmammsap.local NodeAlias: 10.197.1.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642065:afr

[root@AFRFIORIQA ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9345) is running...
[root@AFRFIORIQA ibmrmalik]# uptime
 10:06:43 up 134 days, 12:34,  1 user,  load average: 0.31, 0.13, 0.04





1-336785791
Summary: Zabbix_agent_on_AFRS4HQA.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548369] Date: Apr 18,2018 5:32 CUT Severity: Critical ResourceId: afrs4hqa TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRS4HQA.imzcloud.ibmammsap.local NodeAlias: 10.197.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642039:afr

[root@AFRS4HQA ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9177) is running...
[root@AFRS4HQA ibmrmalik]# uptime
 10:10:14 up 135 days, 12:39,  2 users,  load average: 0.11, 0.07, 0.07

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

19 April


TRIO 11    1-336838071     Incident    3    MNG
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1567252] Date: Apr 19,2018 0:11 CUT Severity: Minor ResourceId: framagbwh0006 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 17.32 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: FRAMAGBWH0006.imzcloud.ibmammsap.local NodeAlias: 10.69.0.151 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647011:mng

[root@FRAMAGBWH0006 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   20G  4.2G  83% /

./var/crash/127.0.0.1-2016-03-07-18:33:52/vmcore
./var/spool/abrt/ccpp-2018-04-18-13:03:32-31095/coredump
./home/bd1adm/messages.2
./usr/local/patchagent/update/log/detect.log



TRIO 11    1-336838031    Incident    2    MNG
Summary: Processor_load_is_too_high_on_LONMAGSBD0003.imzcloud.ibmammsap.local[PROBLEM:1567230] Date: Apr 19,2018 0:7 CUT Severity: Major ResourceId: lonmagsbd0003 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.213125 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LONMAGSBD0003.imzcloud.ibmammsap.local NodeAlias: 10.69.0.49 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647003:mng

[root@LONMAGSBD0003 ibmrmalik]# uptime
 01:38:11 up 13 days, 16:12,  1 user,  load average: 19.79, 19.76, 19.73
[root@LONMAGSBD0003 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         23         39          3          0         10
-/+ buffers/cache:         12         50
Swap:          127          0        127

top - 01:40:10 up 13 days, 16:14,  1 user,  load average: 19.74, 19.78, 19.73
Tasks: 480 total,   2 running, 478 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.5%us,  4.4%sy,  0.0%ni, 93.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.913G total,   23.605G used,   39.308G free,  975.312M buffers
Swap:  127.762G total,    0.000k used,  127.762G free,   10.579G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 5313 root      20   0 44260 7996 2664 R 100.0  0.0 279:16.94 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile
15045 zabbix    20   0 92324 2796 1856 S  2.3  0.0   0:02.13 /usr/sbin/zabbix_agentd: listener #3 [waiting for connection]
27269 root      20   0  534m  20m 9196 S  2.3  0.0  79:34.52 /opt/BESClient/bin/BESClient
30887 jq1adm    20   0 14.4g 2.9g  30m S  1.3  4.6 392:45.64 /usr/sap/JQ1/J00/exe/jstart -appTrc -debugMode=yes -nodeId=3 pf=/usr/sap/JQ1/SYS/profile/JQ1_J00_LONMAGSBD0003 -DSAPINFO=JQ1_00_server1





TRIO 11     1-336836331     Incident    2    MNG
Summary: Processor_load_is_too_high_on_LONMAGSPO0002.imzcloud.ibmammsap.local[PROBLEM:1567284] Date: Apr 19,2018 0:13 CUT Severity: Major ResourceId: lonmagspo0002 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 5.005 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LONMAGSPO0002.imzcloud.ibmammsap.local NodeAlias: 10.69.0.36 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647022:mng

[root@LONMAGSPO0002 ibmrmalik]# w
 02:49:42 up 13 days, 17:24,  1 user,  load average: 20.11, 20.02, 19.78
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/1    146.89.140.60    02:49    1.00s  0.10s  0.20s sshd: ibmrmalik
[root@LONMAGSPO0002 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0         10          0         13
-/+ buffers/cache:         16         14
Swap:           62          0         62

top - 02:51:24 up 13 days, 17:25,  1 user,  load average: 19.83, 19.92, 19.76
Tasks: 286 total,   1 running, 285 sleeping,   0 stopped,   0 zombie
Cpu(s): 17.3%us,  9.2%sy,  0.0%ni, 73.4%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.352G total,   30.773G used,  592.598M free,  921.047M buffers
Swap:   62.527G total,    0.000k used,   62.527G free,   13.231G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 5021 root      20   0 43292 7016 2672 S 98.7  0.0 290:33.33 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile
14636 root      20   0  534m  19m 9184 S  2.0  0.1  81:02.53 /opt/BESClient/bin/BESClient
34242 iq1adm    20   0 12.5g 5.7g  42m S  1.3 18.3 419:23.66 /usr/sap/IQ1/J00/exe/jstart -appTrc -nodeId=3 pf=/usr/sap/IQ1/SYS/profile/IQ1_J00_LONMAGSPO0002 -DSAPINFO=IQ1_00_server1 -hostvm -nodeNa




TRIO 11     1-336837871    Incident    2    MNG
Summary: Processor_load_is_too_high_on_LONMAGSLM0006.imzcloud.ibmammsap.local[PROBLEM:1567155] Date: Apr 19,2018 0:0 CUT Severity: Major ResourceId: lonmagslm0006 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 8.51 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LONMAGSLM0006.imzcloud.ibmammsap.local NodeAlias: 10.69.0.73 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3646963:mng

[root@LONMAGSLM0006 ibmrmalik]# w
 02:54:30 up 261 days, 22:17,  2 users,  load average: 17.44, 17.11, 17.02
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/0    146.89.140.60    02:54    0.00s  0.00s  0.01s sshd: ibmrmalik
root     pts/2    :1.0             31Aug17 225days  0.08s  0.04s -csh
[root@LONMAGSLM0006 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         14          0          0          1          3
-/+ buffers/cache:         10          5
Swap:            7          0          7

top - 02:55:16 up 261 days, 22:18,  2 users,  load average: 17.50, 17.16, 17.04
Tasks: 317 total,   2 running, 315 sleeping,   0 stopped,   0 zombie
Cpu(s): 15.6%us, 36.3%sy,  0.0%ni, 47.9%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   14.862G used,  717.305M free, 1493.941M buffers
Swap: 8191.996M total,  153.324M used, 8038.672M free, 3255.449M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 25656 root      20   0 43308 7052 2724 R 96.9  0.0   2069:59 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile
 66593 spjadm    20   0 7622m 5.4g 143m S  2.7 34.9   4328:13 /usr/sap/SPJ/J01/exe/jstart -appTrc -nodeId=2 pf=/usr/sap/SPJ/SYS/profile/SPJ_J01_LONMAGSLM0006 -DSAPINFO=SPJ_01_server0 -hostvm -nodeN
127847 root      20   0  534m  22m 9224 S  2.0  0.1  79:40.84 /opt/BESClient/bin/BESClient




TRIO 11    1-336838091     Incident    2    MNG
Summary: Processor_load_is_too_high_on_LONMAGSLM0010.imzcloud.ibmammsap.local[PROBLEM:1567256] Date: Apr 19,2018 0:12 CUT Severity: Major ResourceId: lonmagslm0010 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 14.36 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LONMAGSLM0010.imzcloud.ibmammsap.local NodeAlias: 10.69.0.77 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647014:mng

[root@LONMAGSLM0010 ibmrmalik]# w
 02:58:17 up 252 days, 16:50,  1 user,  load average: 13.89, 13.69, 13.66
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/0    146.89.140.60    02:58    0.00s  0.00s  0.01s sshd: ibmrmalik
[root@LONMAGSLM0010 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          7          0          0          0          3
-/+ buffers/cache:          3          4
Swap:            7          0          7

top - 02:58:49 up 252 days, 16:51,  1 user,  load average: 14.29, 13.80, 13.70
Tasks: 238 total,   2 running, 236 sleeping,   0 stopped,   0 zombie
Cpu(s): 38.5%us, 61.5%sy,  0.0%ni,  0.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7856.773M total, 7370.473M used,  486.301M free,  742.371M buffers
Swap: 8191.996M total,  788.637M used, 7403.359M free, 3236.402M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 42817 root      20   0 37028 3628 2144 R 96.3  0.0   2974:06 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile
 43213 root      20   0  535m  21m 9188 S  2.0  0.3  81:11.65 /opt/BESClient/bin/BESClient
 19728 sp2adm    20   0 3198m 1.3g 7288 S  0.3 16.5 808:44.62 ./jre/bin/java -Xms1024m -Xmx1024m -Djava.awt.headless=true -Dmail.mime.charset=UTF-8 -Dorg.owasp.esapi.resources=./config/esapi -XX:+U



1-336838671	sev2
Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local[PROBLEM:1570193] Date: Apr 19,2018 2:14 CUT Severity: Major ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.86875 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: 0f.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647297:cia

[root@dal09ammsol01 ibmrmalik]# w
 22:09:58 up 219 days, 11:41,  1 user,  load average: 23.32, 12.39, 9.65
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/0    146.89.140.60    22:09    0.00s  0.01s  0.01s sshd: ibmrmalik
[root@dal09ammsol01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          6          1         16
-/+ buffers/cache:         12         18
Swap:           11          4          7

top - 22:10:33 up 219 days, 11:41,  1 user,  load average: 24.39, 13.92, 10.27
Tasks: 533 total,   4 running, 529 sleeping,   0 stopped,   0 zombie
Cpu(s): 28.7%us,  2.8%sy,  0.0%ni, 33.5%id, 34.9%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    31.316G total,   30.654G used,  677.512M free, 2029.617M buffers
Swap:   12.000G total, 4319.156M used, 7968.840M free,   16.253G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
15455 dsmadm    20   0 6901m 188m 179m R 100.0  0.6 140694:54 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
27562 dsmadm    20   0 6899m 107m  98m R 99.8  0.3 140713:29 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
24490 db2dsm    20   0 13.1g 3.0g 2.7g S  6.7  9.7  20201:53 db2sysc 0
15826 dsmadm    20   0 5602m 759m 4832 S  4.6  2.4   3845:11 ./jre/bin/java -Xms512m -Xmx1024m -Djava.awt.headless=true -XX:MaxPermSize=256m -Dmail.mime.charset=UTF-8 -Dorg.owasp.esapi.resources=./
15087 dsmadm    20   0 6913m 1.0g 965m S  3.1  3.1   3:25.34 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
10249 dsmadm    20   0 6913m 863m 827m S  2.6  2.7   2:08.76 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01




1-336836121	sev2
Summary: Processor_load_is_too_high_on_SK3BWQAS01.imzcloud.ibmammsap.local[PROBLEM:1566739] Date: Apr 18,2018 23:21 CUT Severity: Major ResourceId: sk3bwqas01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.395 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SK3BWQAS01.imzcloud.ibmammsap.local NodeAlias: 10.5.241.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3646889:sk3

[root@SK3BWQAS01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         31          0          4          1         24
-/+ buffers/cache:          5         26
Swap:           23          0         23
[root@SK3BWQAS01 ibmrmalik]# w
 06:20:24 up 629 days, 13:11,  1 user,  load average: 5.01, 5.14, 4.69
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/0    dal09ammvpn01.ib 06:19    0.00s  0.00s  0.01s sshd: ibmrmalik

top - 06:24:55 up 629 days, 13:15,  1 user,  load average: 5.61, 5.37, 4.89
Tasks: 292 total,   2 running, 290 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.8%us,  8.2%sy,  0.0%ni, 51.8%id, 34.2%wa,  0.0%hi,  3.1%si,  0.0%st
Mem:    31.626G total,   31.401G used,  230.016M free, 1587.625M buffers
Swap:   24.000G total,  443.113M used,   23.567G free,   24.346G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
10632 root      20   0     0    0    0 S  4.3  0.0   1180:31 [nfsd]
10633 root      20   0     0    0    0 D  4.0  0.0   1175:48 [nfsd]
10635 root      20   0     0    0    0 S  4.0  0.0   1181:12 [nfsd]
10637 root      20   0     0    0    0 D  4.0  0.0   1175:53 [nfsd]
10638 root      20   0     0    0    0 S  4.0  0.0   1180:10 [nfsd]
10639 root      20   0     0    0    0 S  4.0  0.0   1177:59 [nfsd]
10636 root      20   0     0    0    0 D  3.7  0.0   1179:36 [nfsd]
10634 root      20   0     0    0    0 S  3.3  0.0   1179:53 [nfsd]
16367 root      20   0     0    0    0 D  2.7  0.0 261:30.97 [jbd2/dm-16-8]



1-336823171	sev3
Please add diskspace as below:

Hostname:   HHHQPO   & HHHDPO
IFN IP:        10.7.14.32   & 10.7.14.33
Space Required: 32 GB added to /backup directory 
Reason: Having Space Issue

[root@HHHQPO ibmrmalik]# df -h /backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hqpappvg-backup_lv
                       50G  381M   47G   1% /backup

[root@HHHDPO ibmrmalik]# df -h /backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hdpappvg-backup_lv
                       50G  307M   47G   1% /backup




1-336816111	sev2
Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:1552439] Date: Apr 18,2018 12:50 CUT Severity: Major ResourceId: sng01ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.08 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SNG01AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.164 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3643676:amm

[root@SNG01AMMSOL04 ibmrmalik]# w
 23:42:08 up 58 days,  6:21,  1 user,  load average: 0.33, 0.67, 0.93
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/0    146.89.140.60    23:42    0.00s  0.03s  0.03s sshd: ibmrmalik
[root@SNG01AMMSOL04 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          6          0          8
-/+ buffers/cache:         22          9
Swap:            7          7          0

top - 23:42:44 up 58 days,  6:22,  1 user,  load average: 0.35, 0.64, 0.90
Tasks: 371 total,   2 running, 369 sleeping,   0 stopped,   0 zombie
Cpu(s):  3.4%us,  0.5%sy,  0.0%ni, 95.2%id,  0.9%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.349G total,   30.695G used,  670.199M free,  194.691M buffers
Swap: 8191.996M total, 8191.996M used,    0.000k free, 8420.723M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
42306 daaadm    20   0 3663m 1.3g 3288 S  5.6  4.0   2226:50 ./jre/bin/java -Xms
 4588 sm1adm    20   0 7029m 909m 822m S  3.3  2.8  13:39.18 dw.sapSM1_DVEBMGS00
24176 db2sm1    20   0 13.8g 3.9g 3.5g S  2.7 12.5  15671:48 db2sysc 0
32663 root      20   0 2662m 199m 3360 S  2.0  0.6 232:44.44 /opt/ds_agent ds_am
62957 root      20   0  535m  18m 6552 R  1.7  0.1  79:53.52 /opt/BESClient/b


1-336812681	sev2
Summary: NTP_time_is_driffted_on_ECCQAS00.imzcloud.ibmammsap.local[PROBLEM:1553467] Date: Apr 18,2018 14:54 CUT Severity: Major ResourceId: eccqas00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: eto InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -5.08 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: ECCQAS00.imzcloud.ibmammsap.local NodeAlias: 10.5.2.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3644076:eto



1-336812301	sev3
Summary: Processor_load_is_too_high_on_LON02AMMADC001[PROBLEM:1552307] Date: Apr 18,2018 12:31 CUT Severity: Minor ResourceId: ri3lr061 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ict InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 6.891667 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: LON02AMMADC001 NodeAlias: 146.89.140.76 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3643641:ict



1-336809341	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_C:[PROBLEM:1550939] Date: Apr 18,2018 9:55 CUT Severity: Major ResourceId: svfd1srv0 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 7.82 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: SVFD1SRV0 NodeAlias: 10.6.1.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3643279:age

C:\SEPTEMP	ITM_6.2.3_FIXPACK_1_AGENT_MP_ENG      0.97 Gb





1-336771111    2-Urgent    MSC Industrial Supply Co.     
Summary: Processor_load_is_too_high_on_ms3wdcladb46.imzcloud.ibmammsap.local[PROBLEM:1547745] Date: Apr 18,2018 4:30 CUT Severity: Major ResourceId: 336774541TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.535 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: ms3wdcladb46.imzcloud.ibmammsap.local NodeAlias: 10.12.6.62 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641439:ms3


   
1-336774541    2-Urgent    Apleona GmbH (Grounding) (AP5)    
Summary: Processor_load_is_too_high_on_APLBREDP1.imzcloud.ibmammsap.local[PROBLEM:1547870] Date: Apr 18,2018 4:49 CUT Severity: Major ResourceId: aplbredp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ap5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.375 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: APLBREDP1.imzcloud.ibmammsap.local NodeAlias: 170.225.68.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641746:ap5



1-336775761    2-Urgent    Apleona GmbH (Grounding) (AP5)
Summary: Processor_load_is_too_high_on_APLHRHE1.imzcloud.ibmammsap.local[PROBLEM:1547864] Date: Apr 18,2018 4:48 CUT Severity: Major ResourceId: aplhrhe1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ap5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 3.445 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: APLHRHE1.imzcloud.ibmammsap.local NodeAlias: 170.225.68.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641743:ap5



1-336775671    2-Urgent    Apleona GmbH (Grounding) (AP5
Summary: Processor_load_is_too_high_on_APLERPPD6.imzcloud.ibmammsap.local[PROBLEM:1547849] Date: Apr 18,2018 4:48 CUT Severity: Major ResourceId: aplerppd6 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ap5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.613333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: APLERPPD6.imzcloud.ibmammsap.local NodeAlias: 170.225.68.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3641742:ap5





monhana-1024-12
10.140.48.171	root/EEbTQ8pm






on VMSS is on A0E3CA016BCA224 
vsappp6-ci (10.9.4.221)	vcenter name A0E3CA014XVM021
Toronto  vmss copy started at 12.18 pm 




1-336837951	sev1	A0D8DE014XVM008   correct one is A0D8DE012XVM008
Summary: Free_disk_space_is_less_than_5%_on_DB_volume_/sybase/backup[PROBLEM:1567176] Date: Apr 19,2018 0:1 CUT Severity: Critical ResourceId: framaggrc0002 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/backup InstanceValue: 0.17 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: FRAMAGGRC0002.imzcloud.ibmammsap.local NodeAlias: 10.69.0.160 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/backup AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3646972:mng

[root@FRAMAGGRC0002 ibmrmalik]# df -h /sybase/backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/gd1appvg-gd1appvg_sybase_backup
                       15G   11G  3.7G  74% /sybase/backup

Add 35 GB to sybase backup
sdl of 40GB aded


vgextend gd1appvg /dev/sdl

lvextend -L +35G /dev/mapper/gd1appvg-gd1appvg_sybase_backup
resize2fs /dev/mapper/gd1appvg-gd1appvg_sybase_backup




1-336849081    1-Critical    CMA CGM (CMA)    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var
Clearing Event Received
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var[PROBLEM:1574085] Date: Apr 19,2018 7:19 CUT Severity: Critical ResourceId: smtmdevdt3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 4.66 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: smtmdevdt3.imzcloud.ibmammsap.local NodeAlias: 10.78.22.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647979:cma

[root@smtmdevdt3 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.1G  2.6G  45% /var





1-336838121    Manchester City Airport Group - SAP HEC-AMM    CMS-SQ-SAP-TRIO-11    2-Urgent
Summary: Lack_of_free_swap_space_on_FRAMAGSPO0003.imzcloud.ibmammsap.local[PROBLEM:1567303] Date: Apr 19,2018 0:14 CUT Severity: Major ResourceId: framagspo0003 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.09 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: FRAMAGSPO0003.imzcloud.ibmammsap.local NodeAlias: 10.69.0.155 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647025:mng

[root@FRAMAGSPO0003 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          4          0          5
-/+ buffers/cache:         25          6
Swap:           13          7          6


top - 07:52:44 up 20 days, 23:08,  1 user,  load average: 0.00, 0.05, 0.11
Tasks: 273 total,   1 running, 272 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.8%us,  1.4%sy,  0.0%ni, 96.1%id,  0.6%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    31.352G total,   30.776G used,  589.520M free,  598.051M buffers
Swap:   13.766G total, 7238.996M used, 6857.000M free, 5305.965M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 5339 root      20   0 5867m 2.8g 2620 S  0.0  9.0  70:06.34 1.1g python
20876 id1adm    20   0 8737m 4.9g  34m S  0.9 15.5 391:41.06 194m jstart
20877 id1adm    20   0 8570m 4.3g  34m S  0.9 13.6 372:22.08 190m jstart
20874 id1adm    20   0 8513m 4.4g  34m S  1.8 13.9 366:22.05 166m jstart
20875 id1adm    20   0 8552m 4.2g  34m S  1.4 13.4 361:24.40 128m jstart
 5319 da1adm    20   0 3159m 245m 7684 S  0.0  0.8 111:31.13 110m jstart
 5241 daaadm    20   0 3003m 379m 6728 S  0.9  1.2 450:35.97  33m jstart
 5480 root      20   0  250m  19m 1800 S  0.0  0.1   0:02.38  31m chef-client
12554 sybid1    20   0 31.6g 4.1g 4.1g S  3.7 13.2 875:42.62  25m dataserver




top - 07:52:27 up 20 days, 23:08,  1 user,  load average: 0.00, 0.06, 0.11
Tasks: 273 total,   1 running, 272 sleeping,   0 stopped,   0 zombie
Cpu(s): 17.0%us, 10.9%sy,  0.0%ni, 70.0%id,  2.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    31.352G total,   30.776G used,  589.793M free,  597.973M buffers
Swap:   13.766G total, 7239.020M used, 6856.977M free, 5305.934M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 5339 root      20   0 5867m 2.8g 2620 S  0.0  9.0  70:06.31 1.1g python /usr/bin/goferd
20876 id1adm    20   0 8737m 4.9g  34m S  0.3 15.5 391:40.89 194m /usr/sap/ID1/J00/exe/jstart -appTrc -nodeId=3 pf=/usr/sap/ID1/SYS/profile/ID1_J00_FRAMAGSPO0003 -DSAPINFO=ID1_00_server1 -hostvm -n
20877 id1adm    20   0 8570m 4.3g  34m S  1.0 13.6 372:21.92 190m /usr/sap/ID1/J00/exe/jstart -appTrc -nodeId=2 pf=/usr/sap/ID1/SYS/profile/ID1_J00_FRAMAGSPO0003 -DSAPINFO=ID1_00_server0 -hostvm -n
20874 id1adm    20   0 8513m 4.4g  34m S  0.7 13.9 366:21.89 166m /usr/sap/ID1/J00/exe/jstart -appTrc -nodeId=5 pf=/usr/sap/ID1/SYS/profile/ID1_J00_FRAMAGSPO0003 -DSAPINFO=ID1_00_server3 -hostvm -n
20875 id1adm    20   0 8552m 4.2g  34m S  0.7 13.4 361:24.26 128m /usr/sap/ID1/J00/exe/jstart -appTrc -nodeId=4 pf=/usr/sap/ID1/SYS/profile/ID1_J00_FRAMAGSPO0003 -DSAPINFO=ID1_00_server2 -hostvm -n
 5319 da1adm    20   0 3159m 245m 7684 S  0.3  0.8 111:31.09 110m /usr/sap/DA1/SMDA96/exe/jstart -appTrc -nodeId=0 pf=/usr/sap/DA1/SYS/profile/DA1_SMDA96_FRAMAGSPO0003 -hostvm -nodeName=smdagent -f
 5241 daaadm    20   0 3003m 379m 6728 S 10.4  1.2 450:35.75  33m /usr/sap/DAA/SMDA98/exe/jstart -appTrc -nodeId=0 pf=/usr/sap/DAA/SYS/profile/DAA_SMDA98_FRAMAGSPO0003 -hostvm -nodeName=smdagent -f
 5480 root      20   0  250m  19m 1800 S  0.0  0.1   0:02.38  31m /opt/chef/embedded/bin/ruby --disable-gems /usr/bin/chef-client -d -c /etc/chef/client.rb -P /var/run/chef/client.pid -i 1800 -s 30
12554 sybid1    20   0 31.6g 4.1g 4.1g S 79.3 13.2 875:42.40  25m /sybase/ID1/ASE-16_0/bin/dataserver -d/sybase/ID1/sybsystem/master.dat -e/sybase/ID1/ASE-16_0/install/ID1.log -c/sybase/ID1/ASE-16_
 3832 sapadm    20   0 1550m  32m 5172 S  0.0  0.1  39:27.48  23m /usr/sap/hostctrl/exe/sapstartsrv pf=/usr/sap/hostctrl/exe/host_profile -D
 5318 dabadm    20   0 2930m 341m 7528 S  5.5  1.1 142:44.03  22m /usr/sap/DAB/SMDA97/exe/jstart -appTrc -nodeId=0 pf=/usr/sap/DAB/SYS/profile/DAB_SMDA97_FRAMAGSPO0003 -hostvm -nodeName=smdagent -f
 5238 da1adm    20   0  185m 3580 1372 S  0.0  0.0   0:01.22  18m jc.sapDA1_SMDA96 pf=/usr/sap/DA1/SYS/profile/DA1_SMDA96_FRAMAGSPO0003




1-336837931    Manchester City Airport Group - SAP HEC-AMM    CMS-SQ-SAP-TRIO-11    2-Urgent
Summary: Free_disk_space_is_less_than_10%_on_DB_volume_/sybase/backup[PROBLEM:1567175] Date: Apr 19,2018 0:1 CUT Severity: Major ResourceId: framaggrc0002 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/backup InstanceValue: 0.17 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: FRAMAGGRC0002.imzcloud.ibmammsap.local NodeAlias: 10.69.0.160 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/backup AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3646971:mng

[root@FRAMAGGRC0002 ibmrmalik]# df -h /sybase/backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/gd1appvg-gd1appvg_sybase_backup
                       49G   11G   37G  22% /sybase/backup



1-336848991    3-Standard    CONTROLADORA DE NEGOCIOS    CNG   Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/db/db2inst2/db2data
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/db/db2inst2/db2data[PROBLEM:1573993] Date: Apr 19,2018 7:8 CUT Severity: Minor ResourceId: crosfliem01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data InstanceValue: 12.55 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: crosfliem01.imzcloud.ibmammsap.local NodeAlias: 10.68.210.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647950:cng

[root@crosfliem01 ibmrmalik]# df -h /db/db2inst2/db2data
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_db2inst2-lv_db_db2inst2_db2data
                      9.8G  3.2G  6.1G  35% /db/db2inst2/db2data

--------------------------------------------------------------------------------------------------------------------

20 April

1-336873491  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)   P2
Summary: FS_is_read_only_on_C1ECCQ.imzcloud.ibmammsap.local[PROBLEM:1589600] Date: Apr 20,2018 0:35 CUT Severity: Major ResourceId: c1eccq TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCQ.imzcloud.ibmammsap.local NodeAlias: 10.199.2.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3651335:pnc

[root@C1ECCQ ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /mnt/sapexchangeIT filesystems are read-only

[root@C1ECCQ ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK


 cat /etc/fstab |grep /mnt/sapexchangeIT
//10.3.1.1/SAPEXCHANGE  /mnt/sapexchangeIT/ cifs credentials=/root/.cifs,uid=908,gid=5003

//10.3.1.1/SAPEXCHANGE  /mnt/sapexchangeIT/ -t cifs -o credentials=/root/.cifs,uid=908,gid=5003

//10.7.1.171/sapexchange /mnt/sapexchangePT  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003



1-336785001	sev1
Summary: Zabbix_agent_on_MGGGBJDGTSX03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548361] Date: Apr 18,2018 5:32 CUT Severity: Critical ResourceId: mgggbjdgtsx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJDGTSX03.imzcloud.ibmammsap.local NodeAlias: 10.133.18.191 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642032:mgg

[root@MGGGBJDGTSX03 ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  67849) is running...
[root@MGGGBJDGTSX03 ~]# uptime
 03:02:59 up 359 days, 16:09,  5 users,  load average: 1.06, 1.17, 1.17



1-336869251	sev3
Summary: Free_disk_space_is_less_than_20%_on_DB_volume_/sybase/DEV/log_archive[PROBLEM:1584510] Date: Apr 19,2018 18:10 CUT Severity: Minor ResourceId: dg1erpdevdg TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dg1 InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/DEV/log_archive InstanceValue: 9.29 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: DG1erpdevdg.imzcloud.ibmammsap.local NodeAlias: 10.143.31.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/DEV/log_archive AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3649828:dg1

-rwxr-x--- 1 sybdev sapsys           0 Apr 19 21:32 testfile
drwxr-x--- 2 sybdev sapsys       16384 Apr 17 17:55 lost+found
-rw-r----- 1 sybdev sapsys 58089920512 Apr 19 13:10 backup_DEV_19_04_2018.dmp
[root@DG1erpdevdg log_archive]# pwd
/sybase/DEV/log_archive




1-336869101	sev3
Summary: FS_is_read_only_on_XF1SABS4HQ.imzcloud.ibmammsap.local[PROBLEM:1584261] Date: Apr 19,2018 17:46 CUT Severity: Minor ResourceId: xf1sabs4hq TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sbh InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: sudo: /usr/libexec/sudoers.so must be only be writable by owner ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: XF1SABS4HQ.imzcloud.ibmammsap.local NodeAlias: 10.7.6.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3649756:sbh

[ibmrmalik@XF1SABS4HQ ~]$ sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / / /boot /opt /opt/monitor/IBM /var /tmp /home /usr/sap /sapmnt/SEQ /usr/sap/trans /home/seqadm /home/daaadm /home/sapadm /usr/sap/finger_print /backup/dbbackup /backup/logbackup filesystems are read-only



1-336868841	sev2
Summary: Processor_load_is_too_high_on_fra02ammsol01.imzcloud.ibmammsap.local[PROBLEM:1583547] Date: Apr 19,2018 16:58 CUT Severity: Major ResourceId: fra02ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.74125 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: fra02ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.220 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3649583:amm

[root@fra02ammsol01 ibmrmalik]# w
 21:49:36 up 224 days, 11:47,  3 users,  load average: 0.70, 0.95, 1.30




1-336868091 sev2
Summary: Free_disk_space_is_less_than_10%_on_DB_volume_/sybase/DEV/log_archive[PROBLEM:1584511] Date: Apr 19,2018 18:10 CUT Severity: Major ResourceId: dg1erpdevdg TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dg1 InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/DEV/log_archive InstanceValue: 9.29 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: DG1erpdevdg.imzcloud.ibmammsap.local NodeAlias: 10.143.31.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/DEV/log_archive AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3649829:dg1

[root@DG1erpdevdg ibmrmalik]# df -h /sybase/DEV/log_archive
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/devarchvg-devlogarch_lv
                       63G   55G  5.3G  92% /sybase/DEV/log_archive
[root@DG1erpdevdg ibmrmalik]# cd /sybase/DEV/log_archive
[root@DG1erpdevdg log_archive]# ls -ltrS
total 56783916
-rwxr-x--- 1 sybdev sapsys           0 Apr 19 22:00 testfile
drwxr-x--- 2 sybdev sapsys       16384 Apr 17 17:55 lost+found
-rw-r----- 1 sybdev sapsys 58089920512 Apr 19 13:10 backup_DEV_19_04_2018.dmp






1-336854367	sev3
Please add diskspace as below:

Hostname:   HHHDSOL
IFN IP:        10.7.14.41
Space Required: 32 GB added to /backup directory 
Reason: Having Space Issue




1-336853281	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1578618] Date: Apr 19,2018 10:30 CUT Severity: Minor ResourceId: ri3lr074 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: iap InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 19.9 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CHE01AMMCHEF01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.87 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3648450:iap

root@CHE01AMMCHEF01 ~]# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                       35G   28G  6.1G  82% /
tmpfs                 3.9G   12K  3.9G   1% /dev/shm
/dev/sda1             477M   83M  369M  19% /boot
//146.89.140.21/cms_sap_syb_db
                       15G  4.3G   11G  29% /root/cms_sap_syb_db




1-336876991   IBM AMM Infrastructure   P1
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1591144] Date: Apr 20,2018 3:10 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3651634:amm





1-336875514	sev3
Please extend 100 GB on FS - /usr/sap/ - CLDERPAPPP1 - 10.198.0.71	A0CTSG014XVM029
Please add disk if neccessary

Currently the fill levels are:

/usr/sap is occupied 71%
/usr/interfaces has taken 78gb of space out of 218gb

[root@CLDERPAPPP1 ibmrmalik]# df -h /usr/sap/
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                      218G  148G   59G  72% /usr/sap

new disk sdf

vgextend vg_app /dev/sdf

lvextend -L +100G /dev/mapper/vg_app-lv_usrsap
resize2fs /dev/mapper/vg_app-lv_usrsap

[root@CLDERPAPPP1 ibmrmalik]# df -h /usr/sap/
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                      316G  148G  153G  50% /usr/sap




1-336877231  IBM MSD Infras - Cloud APPS  2
Summary: Processor_load_is_too_high_on_dal09ammsol02.imzcloud.ibmammsap.local[PROBLEM:1591773] Date: Apr 20,2018 4:6 CUT Severity: Major ResourceId: ri3pa034 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.315 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsol02.imzcloud.ibmammsap.local NodeAlias: 146.89.140.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3651740:cia

[root@dal09ammsol02 ibmrmalik]# uptime
 01:31:22 up 377 days,  3:45,  1 user,  load average: 1.34, 1.45, 1.35



1-336876951  BM AMM Infrastructure  2 
Summary: Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local[PROBLEM:1591089] Date: Apr 20,2018 3:3 CUT Severity: Major ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 5.66875 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3651621:amm

[root@wdc04ammsol01 ibmrmalik]# uptime
 01:36:02 up 163 days, 18:44,  1 user,  load average: 0.05, 0.14, 0.22




1-336835311    IBM AMM Infrastructure    AMM-DELIVERY-TECH    2-Urgent
Summary: Lack_of_available_memory_on_server_ammpar01custesx001.imzcloud.ibmammsap.local[PROBLEM:1564785] Date: Apr 18,2018 22:17 CUT Severity: Major ResourceId: ammpar01custesx001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-Template_Virt_VMware_Hypervisor:Used_memory InstanceValue: 439.15 GB ComponentType: ZABBIX Component: Template_Virt_VMware_Hypervisor SubComponent: Used_memory Node: ammpar01custesx001.imzcloud.ibmammsap.local NodeAlias: 146.89.142.147 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_Virt_VMware_Hypervisor:Used_memory AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3646433:amm




1-336834961    IBM AMM Infrastructure    AMM-DELIVERY-TECH    2-Urgent


1-336880401   SMRT Corp - SAP HEC-AMM   P1  
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1593365] Date: Apr 20,2018 6:19 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3652040:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   14G   36G  28% /



1-336884061  CONTROLADORA DE NEGOCIOS   P1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/db/db2inst2/db2data[PROBLEM:1593907] Date: Apr 20,2018 7:9 CUT Severity: Critical ResourceId: crosfliem01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data InstanceValue: 2.73 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: crosfliem01.imzcloud.ibmammsap.local NodeAlias: 10.68.210.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/db/db2inst2/db2data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3652185:cng

[root@crosfliem01 ibmrmalik]# df -h /db/db2inst2/db2data
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_db2inst2-lv_db_db2inst2_db2data
                      9.8G  3.2G  6.1G  35% /db/db2inst2/db2data


----------------------------------------------------------------------------------------------------------------------------------------------------------

23 April


1-336928471	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1618560] Date: Apr 21,2018 20:56 CUT Severity: Critical ResourceId: ia1otasprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: IA1OTASPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.17.147 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3656596:ia1

[root@IA1OTASPRDAPP /]# df -h .
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  9.8G     0 100% /
[root@IA1OTASPRDAPP /]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   2   7   0 wz--n- 71.50g 4.46g


lvextend -L +2G /dev/mapper/VolGroup-lv_root 
resize2fs /dev/mapper/VolGroup-lv_root


 /etc/lvm/archive/.lvm_IA1OTASPRDAPP_61745_2014141401: fclose failed: No space left on device
  /etc/lvm/cache/.cache.tmp: write error failed: No space left on device




1-335289321	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1154453] Date: Mar 6,2018 17:43 CUT Severity: Critical ResourceId: sncheuadd11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0.56 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: sncheuadd11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.137 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3508009:snc

[root@sncheuadd11 ibmrmalik]# df -k /
Filesystem           1K-blocks    Used Available Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      10190136 5349080   4316768  56% /




1-336888751   sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1594117] Date: Apr 20,2018 7:32 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 3.51 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3652465:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   14G   36G  28% /



1-336895971	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap[PROBLEM:1596899] Date: Apr 20,2018 11:46 CUT Severity: Minor ResourceId: vsappp6-ci TicketGroup: ApsSAPTechnical CustomerCode: ca3 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap InstanceValue: 12.79 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: vsappp6-ci.imzcloud.ibmammsap.local NodeAlias: 10.9.4.221 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3653089:ca3

Request DPE approval to add 10GB to /usr/sap mount:
/dev/mapper/vg_app-lv_usersap
                       40G   32G  5.7G  85% /usr/sap

[root@vsappp6-ci ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usersap
                       50G   40G  6.9G  86% /usr/sap
[root@vsappp6-ci ibmrmalik]# vgs vg_app
  VG     #PV #LV #SN Attr   VSize   VFree
  vg_app   1   2   0 wz--n- 128.00g 68.00g



lvextend -L +10G /dev/mapper/vg_app-lv_usersap 
resize2fs /dev/mapper/vg_app-lv_usersap

[root@vsappp6-ci ibmrmalik]# df -h  /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usersap
                       60G   40G   17G  72% /usr/sap




1-336014951	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1348580] Date: Mar 24,2018 20:0 CUT Severity: Minor ResourceId: dlbdwdap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 19.09 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLBDWDAP00.imzcloud.ibmammsap.local NodeAlias: 10.13.2.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3566147:dlb




1-336939331	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1630597] Date: Apr 22,2018 11:34 CUT Severity: Minor ResourceId: lonmagerp0002 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 19.36 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: LONMAGERP0002.imzcloud.ibmammsap.local NodeAlias: 10.69.0.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3658196:mng

[root@LONMAGERP0002 tmp]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   16G  8.7G  64% /




1-336947881    1-Critical    Dilip Buildcon Limited (DLB)    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var[PROBLEM:1641236] Date: Apr 23,2018 3:41 CUT Severity: Critical ResourceId: dlbpecap02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLBPECAP02.imzcloud.ibmammsap.local NodeAlias: 10.13.1.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3659683:dlb

[root@DLBPECAP02 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  1.8G  2.8G  40% /var




1-336947971	sev2
Summary: Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:1641473] Date: Apr 23,2018 4:5 CUT Severity: Major ResourceId: dal09ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 6.5275 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: DAL09AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.36 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3659731:amm

[root@DAL09AMMSOL04 ibmrmalik]# uptime
 00:33:22 up 204 days, 20:00,  1 user,  load average: 1.05, 0.94, 2.59

[root@DAL09AMMSOL04 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          6          0         21
-/+ buffers/cache:          9         21
Swap:            7          7          0


top - 00:37:06 up 204 days, 20:03,  1 user,  load average: 3.53, 2.26, 2.76
Tasks: 369 total,   1 running, 368 sleeping,   0 stopped,   0 zombie
Cpu(s): 45.5%us,  2.8%sy,  0.0%ni, 28.0%id, 23.0%wa,  0.0%hi,  0.8%si,  0.0%st
Mem:    31.349G total,   30.953G used,  405.922M free,   43.332M buffers
Swap: 8191.996M total, 8191.996M used,    0.000k free,   21.307G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 6232 db2dm1    20   0 11.9g 4.1g 3.7g S 181.0 13.1  38487:45 db2sysc 0
45711 dm1adm    20   0 7509m 1.0g 924m S  7.0  3.1   7:30.22 dw.sapDM1_DVEBMGS00 pf=/usr/sap/DM1/SYS/profile/DM1_DVEBMGS00_DAL09





1-336902991    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM
Summary: Lack_of_free_swap_space_on_DLTHPEHP4.imzcloud.ibmammsap.local[PROBLEM:1600630] Date: Apr 20,2018 16:15 CUT Severity: Major ResourceId: dlthpehp4 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 30.11 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: DLTHPEHP4.imzcloud.ibmammsap.local NodeAlias: e
 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3653656:dal

[root@DLTHPEHP4 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         48         14         28          0         31
-/+ buffers/cache:         17         45
Swap:           20         20          0





1-336948251    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_DLTHPEHP4.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_DLTHPEHP4.imzcloud.ibmammsap.local[PROBLEM:1642122] Date: Apr 23,2018 5:1 CUT Severity: Major ResourceId: dlthpehp4 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.175833 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: DLTHPEHP4.imzcloud.ibmammsap.local NodeAlias: 10.4.5.56 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3659808:dal

[root@DLTHPEHP4 ibmrmalik]# uptime
 01:51:20 up 74 days,  1:22,  3 users,  load average: 0.13, 0.09, 



1-336948271    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_DLTHPEHP3.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_DLTHPEHP3.imzcloud.ibmammsap.local[PROBLEM:1642127] Date: Apr 23,2018 5:3 CUT Severity: Major ResourceId: dlthpehp3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.16 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: DLTHPEHP3.imzcloud.ibmammsap.local NodeAlias: 10.4.5.55 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3659810:dal

[root@DLTHPEHP3 ibmrmalik]# uptime
 01:54:08 up 205 days,  3:53,  1 user,  load average: 0.00, 0.04, 1.29




1-336893901	sev2
Summary: Processor_load_is_too_high_on_ercerpd1.imzcloud.ibmammsap.local[PROBLEM:1596402] Date: Apr 20,2018 11:2 CUT Severity: Major ResourceId: ercerpd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: egr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.315 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: ercerpd1.imzcloud.ibmammsap.local NodeAlias: 10.5.1.101 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3652983:egr

[root@ercerpd1 ibmrmalik]# uptime
 11:59:05 up 52 days,  1:32,  2 users,  load average: 1.57, 1.38, 1.69



1-336948401	sev3
Summary: Drive_with_Media_Errors_on_host_snchcraqd11.imzcloud.ibmammsap.local[PROBLEM:1642479] Date: Apr 23,2018 5:29 CUT Severity: Minor ResourceId: snchcraqd11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Check_vmtools_config_file Node: snchcraqd11.imzcloud.ibmammsap.local NodeAlias: 10.73.12.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Check_vmtools_config_file AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3659860:snc

--------------------------------------------------------------------------------------------------------------------------------------------------------

24 April

1-336971891    Performance in Lighting S.p.A. (PL2)    CMS-SQ-SAP-TRIO-11    1-Critical
Summary: Zabbix_agent_on_PL2SAPDEV.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1651415] Date: Apr 23,2018 17:5 CUT Severity: Critical ResourceId: pl2sapdev TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pl2 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PL2SAPDEV.imzcloud.ibmammsap.local NodeAlias: 10.7.33.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3661374:pl2

[root@PL2SAPDEV ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9525) is running...
[root@PL2SAPDEV ibmrmalik]# uptime
 03:31:45 up 62 days,  7:36,  1 user,  load average: 0.15, 0.09, 0.02





1-336845921	sev3
Summary: Processor_load_is_too_high_on_PHSBWDEV01[PROBLEM:1572796] Date: Apr 19,2018 5:14 CUT Severity: Minor ResourceId: phsbwdev01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: phs InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 1.5 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: PHSBWDEV01 NodeAlias: 10.5.6.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3647706:phs






1-336982261	sev2
Summary: Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local[PROBLEM:1660358] Date: Apr 24,2018 3:4 CUT Severity: Major ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 5.4225 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3662858:amm

[root@wdc04ammsol01 ibmrmalik]# uptime
 22:30:10 up 167 days, 15:38,  1 user,  load average: 12.61, 18.01, 24.31

[root@wdc04ammsol01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0         10          1         12
-/+ buffers/cache:         16         15
Swap:            0          0          0


top - 22:35:42 up 167 days, 15:44,  1 user,  load average: 6.48, 12.47, 20.12
Tasks: 505 total,   3 running, 502 sleeping,   0 stopped,   0 zombie
Cpu(s): 13.6%us,  1.7%sy,  0.0%ni, 60.2%id, 23.8%wa,  0.0%hi,  0.6%si,  0.0%st
Mem:    31.316G total,   30.422G used,  916.199M free, 1543.512M buffers
Swap: 1023.996M total, 1023.988M used,    8.000k free,   12.901G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
27514 db2wsm    20   0 17.4g 7.8g 7.4g S 31.9 24.9  11248:57 db2sysc 0
 1484 wsmadm    20   0 6991m 1.0g 942m R 18.6  3.3   4:28.68 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
 3088 wsmadm    20   0 7045m 998m 889m S 15.6  3.1   5:12.08 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
 3076 wsmadm    20   0 7054m 988m 891m S 14.6  3.1   4:23.26 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
12349 wsmadm    20   0 7003m 984m 888m S  7.0  3.1   3:16.95 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
14874 wsmadm    20   0 9594m 4.6g  16m S  4.0 14.7 948:57.39 /usr/sap/WSM/DVEBMGS50/exe/jlaunch pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01 -DSAPINFO=WSM_50_server -nodeId=1 -file=/usr/
 9790 wsmadm    20   0 7019m 941m 846m S  3.6  2.9   4:06.36 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
25311 wsmadm    20   0 6935m 286m 241m S  3.6  0.9   0:05.30 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
 1173 wsmadm    20   0 6905m 133m  94m S  3.0  0.4   0:02.55 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
15690 wsmadm    20   0 6908m 194m 154m S  3.0  0.6   0:19.35 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
 4193 wsmadm    20   0 7037m 1.1g 979m S  2.3  3.4   3:35.03 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
 4160 wsmadm    20   0 7022m 964m 864m S  2.0  3.0   2:49.91 dw.sapWSM_DVEBMGS50 pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01
13395 wsmadm    20   0  837m  88m  27m S  1.7  0.3 177:25.59 gwrd -dp pf=/usr/sap/WSM/SYS/profile/WSM_DVEBMGS50_wdc04ammsol01





1-336941331
Script to be run on EP1 hr_payslip.sh /h
(EP1)CLDERPAPPP1-10.198.0.71

Customer: SMRT Corporation Ltd
Reported by: Uma Maheshwar Dev Bontala
Phone: +65 (6554) 8535
E-Mail: umamaheshwar@smrt.com.sg
Priority: 2: High
SAP Incident Number: 203946 / 2018


Description:
Reconstruction
04/23/2018   02:01:48   S0016320183

Please provide step-by-step instructions on how to reproduce your issue:
Step 1:run script
Step 2:
Step 3:
____________________
Business Consequences
04/23/2018   02:01:47   S0016320183

Business delays
____________________
Description
04/23/2018   02:01:46   S0016320183

Hi Team ,
 
Please run the below script on EP1.
/home/postman/ HR hr_payslip.sh
Also do capture the logs and share with us.
 
 
Thanks & Regards,
Uma Maheshwar Dev





1-336983391 / MGG / SEV1 / Siebel / not validated / Summary: Free_disk_space_is_less_than_5%_on_OS_volume_
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1662320] Date: Apr 24,2018 5:53 CUT Severity: Critical ResourceId: mgggbjpeccx05 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 5 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJPECCX05.imzcloud.ibmammsap.local NodeAlias: 10.133.18.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3663192:mgg

[root@MGGGBJPECCX05 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  8.8G  472M  96% /

[root@MGGGBJPECCX05 /]# find . -xdev -type f -size +500000
./root/.vnc/core.64208
./sapmnt/exe_749/exe.tar

-rw-------  1 root root 513908736 Apr  7 20:18 core.64208
[root@MGGGBJPECCX05 .vnc]# pwd
/root/.vnc
-rw-------    1 root   root   40574647 Feb 26 23:30 aa


Cleaned by PDL
[root@MGGGBJPECCX05 sapmnt]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  5.7G  3.7G  61% /





1-336983601 - P2 - FBT- SAP HEC-AMM - Siebel - Not Validated - Free_disk_space_is_less_than_10%_on_OS_volume_/var
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var[PROBLEM:1663075] Date: Apr 24,2018 6:51 CUT Severity: Major ResourceId: fbtprdhanapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 6.9 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: fbtprdhanapp1.imzcloud.ibmammsap.local NodeAlias: 10.4.27.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3663319:fbt

[root@fbtprdhanapp1 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.2G  2.4G  49% /var




1-336964854    CI3 Certified IT Consultants for TMG (CICTMG)    AMM-DELIVERY-TECH
On May 04, 2018 take full backup for CI3S4HANAPRDA host (OS+APP+DB)
Need full back taken for CI3S4HANAPRDA host (OS+APP+DB). Before taking backup we need confirmation if downtime is required for Application or DB.



-----------------------------------------------------------------------------------------------------------------------------------------------------

25 April


10.73.12.37
snchbibqd11


1-337028521    IBM MSD Infras - Cloud APPS    AMM-DELIVERY-TECH    2-Urgent	no access
1-337028621    IBM MSD Infras - Cloud APPS    AMM-DELIVERY-TECH    2-Urgent 	no access
1-337031181    IBM MSD Infras - Cloud APPS    AMM-DELIVERY-TECH    2-Urgent	no access
1-337027271    IBM MSD Infras - Cloud APPS    OSLINUX    2-Urgent		no access
1-337027421    IBM MSD Infras - Cloud APPS    AMM-DELIVERY-TECH    2-Urgent	no access





1-335248332
P2: [RIMS] Create keystores in OD1 and OQ1
Customer: SMRT Corporation Ltd
Reported by: Uma Maheshwar Dev Bontala
Phone: +65 (6554) 8535
E-Mail: umamaheshwar@smrt.com.sg
Priority: 2: High
SAP Incident Number: 000115365/2018


Description:

Reconstruction
03/05/2018   22:05:43   S0016320183

Please provide step-by-step instructions on how to reproduce your issue:
Step 1: Key Store creation
Step 2:
Step 3:
____________________
Business Consequences
03/05/2018   22:05:42   S0016320183

project delays
____________________
Description
03/05/2018   22:05:41   S0016320183

Hi Team,
 
Please assist to install and create the keystores in OD1
(CLDPROAPDD1)  and OQ1 (CLDPROAPDT1)

OD1 / CLDPROAPDD1 / 10.198.0.201
OQ1 / CLDPROAPDT1 / 10.198.0.217

 
Keys attached.
 
SFTP server                        : HQDSFTPAPPP1 [172.19.1.76]
Username                           : _rimssapsftpd
Password                            : @r1m5s@psftpd
 
Keystore = SFTP_rimssapsftpd
Keystore Entry = sftp_keystore_rims
 
Thanks & Regards,
Uma Maheshwar Devl


[postman@cldproapdd1 ~]$ sftp _rimssapsftpd@172.19.1.76
Connecting to 172.19.1.76...
Connection closed by 172.19.1.76
Couldn't read packet: Connection reset by peer

CLDPROAPDT1:oq1adm 51> sftp _rimssapsftpd@172.19.1.76
Connecting to 172.19.1.76...
Connection closed by 172.19.1.76
Couldn't read packet: Connection reset by peer


[postman@cldproapdd1 ~]$ sftp _rimssapsftpd@172.31.10.20
Connecting to 172.31.10.20...
ssh_exchange_identification: Connection closed by remote host
Couldn't read packet: Connection reset by peer


CLDPROAPDT1:oq1adm 51> sftp _rimssapsftpd@172.31.10.20
Connecting to 172.31.10.20...
Received disconnect from 172.31.10.20: 7: Exceeded failed login limit
Couldn't read packet: Connection reset by peer



1-337039751    IBM AMM Infrastructure    AMM-DELIVERY-TECH    2-Urgent
Summary: Lack_of_free_swap_space_on_fra02ammsol01.imzcloud.ibmammsap.local[PROBLEM:1678693] Date: Apr 25,2018 5:16 CUT Severity: Major ResourceId: fra02ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: fra02ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.220 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3667191:amm

[root@fra02ammsol01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         27          3          7          1         15
-/+ buffers/cache:         10         20
Swap:           11          4          7


top - 01:36:32 up 229 days, 15:34,  3 users,  load average: 1.78, 2.18, 2.69
Tasks: 643 total,   2 running, 641 sleeping,   0 stopped,   0 zombie
Cpu(s): 15.2%us,  0.2%sy,  0.0%ni, 80.4%id,  4.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.316G total,   27.420G used, 3989.984M free, 1048.879M buffers
Swap:   12.000G total, 4702.254M used, 7585.742M free,   15.694G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
14210 fsmadm    20   0 8903m 3.0g  13m S  0.3  9.6   1264:41 795m jlaunch
31049 db2fsm    20   0 19.3g 2.6g 2.3g S  1.0  8.5  13903:52 374m db2sysc
31072 db2fsm    20   0 2754m  85m 6648 S  0.0  0.3 282:18.21 299m db2fmp
13036 fsmadm    20   0 3710m 136m 4244 S  0.0  0.4 735:33.84 242m jlaunch
10197 db2fsm    20   0 1344m  23m 5152 S  0.0  0.1   9:52.28 176m db2fmp
 7622 fsmadm    20   0 1278m 158m 1676 S  0.0  0.5  34:47.15 164m igspw_mt
 7621 fsmadm    20   0 1278m 205m 1680 S  0.0  0.6  36:09.55 150m igspw_mt



1-337026941    IBM AMM Infrastructure    AMM-DELIVERY-TECH    2-Urgent
Summary: Processor_load_is_too_high_on_LON02AMMZAB001.imzcloud.ibmammsap.local[PROBLEM:1676291] Date: Apr 25,2018 1:27 CUT Severity: Major ResourceId: lon02ammzab001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.07 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LON02AMMZAB001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.84 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3666470:amm


---------------------------------------------------------------------------------------------------------------------------------------------------------------

26 April

1-337045911    Suncor Energy Inc. (SNC)    CMS-SQ-SAP-TRIO-12    1-Critical
Summary: Zabbix_agent_on_snchdsbtd11.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1680957] Date: Apr 25,2018 8:30 CUT Severity: Critical ResourceId: snchdsbtd11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: snchdsbtd11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3667580:snc

[root@snchdsbtd11 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4524) is running...
[root@snchdsbtd11 ibmrmalik]# uptime
 19:19:28 up 16:53,  1 user,  load average: 0.00, 0.00, 0.00


1-337041591    Suncor Energy Inc. (SNC)    APSSAP TECHNICAL    1-Critical
Summary: Free_disk_space_is_less_than_5%_on_volume_/sybase/T1D[PROBLEM:1680992] Date: Apr 25,2018 8:34 CUT Severity: Critical ResourceId: snchdsbtd11 TicketGroup: ApsSAPTechnical CustomerCode: snc InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sybase/T1D InstanceValue: 4.81 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: snchdsbtd11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sybase/T1D AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3667598:snc

/dev/mapper/t1ddatavg-t1dsybase_lv
                      7.9G  7.2G  369M  96% /sybase/T1D

./ASE-16_0/install/core.jsa_20180425_022501.19413
./ASE-16_0/bin/diagserver
./data/IBM_DBHEALTH_data.dat




1-336755511    Suncor Energy Inc. (SNC)    CMS-SQ-SAP-TRIO-12    1-Critical
Summary: Zabbix_agent_on_snchltaqa14.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1542886] Date: Apr 17,2018 18:9 CUT Severity: Critical ResourceId: snchltaqa14 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: snchltaqa14.imzcloud.ibmammsap.local NodeAlias: 10.73.12.64 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3639605:snc

[root@snchltaqa14 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  68947) is running...
[root@snchltaqa14 ibmrmalik]# uptime
 19:32:03 up 238 days,  9:23,  1 user,  load average: 0.05, 0.04, 0.05




1-337077611    1-Critical    Dixons Carphone (CPW)
Summary: Zabbix_agent_on_cpwHANAsolApp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1693902] Date: Apr 26,2018 0:32 CUT Severity: Critical ResourceId: cpwhanasolapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: cpwHANAsolApp.imzcloud.ibmammsap.local NodeAlias: 10.197.6.27 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3670141:cpw

[root@cpwHANAsolApp ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  108564) is running...
[root@cpwHANAsolApp ibmrmalik]# uptime
 02:00:48 up 331 days, 18:05,  1 user,  load average: 6.25, 6.45, 6.52




1-337079281    IBM MSD Infras - Cloud APPS    AMM-DELIVERY-TECH    2-Urgent
Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local[PROBLEM:1695318] Date: Apr 26,2018 2:19 CUT Severity: Major ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.6175 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3670357:cia

[root@dal09ammsol01 ibmrmalik]# w
 22:12:49 up 226 days, 11:44,  2 users,  load average: 2.27, 2.84, 4.77

top - 22:14:21 up 226 days, 11:45,  2 users,  load average: 2.18, 2.65, 4.52
Tasks: 538 total,   4 running, 534 sleeping,   0 stopped,   0 zombie
Cpu(s): 27.3%us,  0.4%sy,  0.0%ni, 72.1%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.316G total,   30.576G used,  757.195M free, 2051.441M buffers
Swap:   12.000G total, 4243.898M used, 8044.098M free,   13.655G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
27562 dsmadm    20   0 6899m 106m  97m R 100.0  0.3 150808:38 DSM_50_BTC_W24
15455 dsmadm    20   0 6901m 184m 176m R 100.0  0.6 150790:06 DSM_50_BTC_W23




1-337078821    Central American Retail Sourcing Inc. aka Dollarcity SAP HEC-AMM    CMS-SQ-SAP-TRIO-9    2-Urgent
Summary: Lack_of_free_swap_space_on_vsapqe6-ciapp.imzcloud.ibmammsap.local[PROBLEM:1693873] Date: Apr 26,2018 0:31 CUT Severity: Major ResourceId: vsapqe6-ciapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ca3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.99 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: vsapqe6-ciapp.imzcloud.ibmammsap.local NodeAlias: 10.9.5.207 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3670136:ca3

[root@vsapqe6-ciapp ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         31          0          7          0         21
-/+ buffers/cache:          9         22
Swap:           13          6          6

top - 21:42:38 up 559 days, 12:11,  1 user,  load average: 1.45, 0.86, 0.69
Tasks: 333 total,   3 running, 330 sleeping,   0 stopped,   0 zombie
Cpu(s): 24.4%us,  1.1%sy,  0.0%ni, 74.1%id,  0.1%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    31.572G total,   31.077G used,  506.055M free,  440.469M buffers
Swap:   13.766G total, 7065.492M used, 7030.504M free,   21.482G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
35697 qe6adm    20   0 28.5g 6.8g 6.2g S  6.9 21.6   2837:09 1.2g QE6_05_DIA_W13
34116 qe6adm    20   0 1562m  45m  24m S  0.0  0.1 103:27.61 773m en.sapQE6_ASCS
35692 qe6adm    20   0 28.4g 8.0g 6.8g S  0.0 25.5   2892:30 507m QE6_05_DIA_W8
 4281 qe6adm    20   0 27.4g 7.0g 6.6g S  2.3 22.0   2404:01 352m QE6_05_DIA_W11
63585 qe6adm    20   0 27.2g 6.4g 6.1g S  4.0 20.2   2747:11 298m QE6_05_DIA_W14
57135 root      20   0  371m  15m 1364 S  0.3  0.0 552:52.83 123m vmtoolsd
35683 qe6adm    20   0 1748m  29m  22m S  0.0  0.1   9:04.76 119m icman
 3229 root      20   0 6843m 103m 5180 S  0.0  0.3 402:27.23 106m java





1-337079621    1-Critical    SMRT Corp - SAP HEC-AMM        Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/[PROBLEM:1696148] Date: Apr 26,2018 3:19 CUT Severity: Critical ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0.25 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3670492:sm5

[root@CLDERPAPPP1 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       51G   30G   19G  62% /



1-337058631    CMA CGM (CMA)    AMM-DELIVERY-TECH    2-Urgent
Summary: Lack_of_free_swap_space_on_smtmuatut3.imzcloud.ibmammsap.local[PROBLEM:1686358] Date: Apr 25,2018 14:37 CUT Severity: Major ResourceId: smtmuatut3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.97 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: smtmuatut3.imzcloud.ibmammsap.local NodeAlias: 10.78.26.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3668626:cma

[root@smtmuatut3 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         26          4         19          0         20
-/+ buffers/cache:          5         25
Swap:            7          4          3

top - 04:18:15 up 273 days, 20:12,  1 user,  load average: 0.16, 0.17, 0.15
Tasks: 407 total,   1 running, 406 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.3%us,  0.1%sy,  0.0%ni, 99.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   26.716G used, 4736.859M free,  341.863M buffers
Swap: 8191.996M total, 4189.750M used, 4002.246M free,   20.691G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 25246 ut3adm    20   0 1507m  66m  33m S  0.0  0.2 178:13.40 785m en.sapUT3_ASCS0
 26717 ut3adm    20   0 4101m 1.0g  32m S  0.0  3.2  31:31.76 299m icman
130537 ut3adm    20   0 24.8g 908m 769m S  0.0  2.8   5:17.11  49m UT3_10_BTC_W32
  1724 root      20   0  299m  28m 1328 S  0.0  0.1 155:15.67  39m vmtoolsd
 21109 root      20   0 2063m  63m 3384 S  0.0  0.2  36:17.81  30m ksaagent
 26699 ut3adm    20   0 1191m 4468 1256 S  0.0  0.0  10:48.30  24m igsmux_mt
 26701 ut3adm    20   0  823m 5308 1000 S  0.0  0.0   6:27.69  22m igspw_mt
 26700 ut3adm    20   0  823m 5308 1000 S  0.3  0.0   6:33.11  22m igspw_mt




1-337082711    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM        Summary: Processor_load_is_too_high_on_DLTHPEHP4.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_DLTHPEHP4.imzcloud.ibmammsap.local[PROBLEM:1696318] Date: Apr 26,2018 3:34 CUT Severity: Major ResourceId: dlthpehp4 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.088333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: DLTHPEHP4.imzcloud.ibmammsap.local NodeAlias: 10.4.5.56 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3670522:dal

[root@DLTHPEHP4 ibmrmalik]# w
 01:25:37 up 77 days, 56 min,  1 user,  load average: 1.29, 1.29, 1.27


top - 01:26:14 up 77 days, 57 min,  1 user,  load average: 1.27, 1.29, 1.27
Tasks: 431 total,   3 running, 428 sleeping,   0 stopped,   0 zombie
Cpu(s): 11.7%us,  0.2%sy,  0.0%ni, 88.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.914G total,   59.167G used, 3836.879M free,   33.320M buffers
Swap:   20.762G total,   10.971G used,    9.791G free,   38.473G cached




1-337083241






1-337053061    CMA CGM (CMA)    AMM-DELIVERY-TECH    2-Urgent
@rmalik  project customer

Summary: Processor_load_is_too_high_on_smtmuatut3.imzcloud.ibmammsap.local[PROBLEM:1683031] Date: Apr 25,2018 10:54 CUT Severity: Major ResourceId: smtmuatut3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.12 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: smtmuatut3.imzcloud.ibmammsap.local NodeAlias: 10.78.26.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3667968:cma

[root@smtmuatut3 ibmrmalik]# w
 06:08:21 up 273 days, 22:02,  1 user,  load average: 0.34, 0.31, 0.21

top - 06:08:35 up 273 days, 22:02,  1 user,  load average: 0.33, 0.31, 0.21
Tasks: 407 total,   1 running, 406 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.7%us,  0.3%sy,  0.0%ni, 97.9%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   26.717G used, 4736.059M free,  367.770M buffers
Swap: 8191.996M total, 4188.691M used, 4003.305M free,   20.708G cached



1-337018061    SMRT Corp - SAP HEC-AMM    CMS-SQ-SAP-TRIO-10    2-Urgent
@rmalik clearing event received
Summary: Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local[PROBLEM:1671863] Date: Apr 24,2018 18:48 CUT Severity: Major ResourceId: clderpappd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.98 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: CLDERPAPPD1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.208 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3665607:sm5

[root@CLDERPAPPD1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         13          1          6          0          7
-/+ buffers/cache:          6          9
Swap:           13          6          6

top - 14:12:45 up 65 days, 16:28,  1 user,  load average: 0.06, 0.04, 0.00
Tasks: 413 total,   1 running, 412 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.7%us,  0.3%sy,  0.0%ni, 98.8%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.572G total,   13.982G used, 1628.301M free,  399.023M buffers
Swap:   13.766G total, 6963.582M used, 7132.414M free, 7644.879M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
39014 ed1adm    20   0 1428m  13m 2008 S  0.0  0.1  12:35.23 785m en.sapED1_ASCS
41376 ed1adm    20   0 22.6g 4.9g 4.8g S  0.0 31.8  75:00.61 111m ED1_00_DIA_W12
 4458 daaadm    20   0 2626m  55m 2460 S  0.0  0.4 124:22.29 109m jstart
42582 ed1adm    20   0 22.4g 5.0g 4.9g S  0.0 32.4  37:15.42  85m ED1_00_DIA_W5
58382 ed1adm    20   0 3161m  57m  12m S  0.0  0.4   0:50.81  83m icman
41366 ed1adm    20   0 22.5g 5.0g 4.9g S  0.0 32.4  48:42.95  81m ED1_00_DIA_W2
51188 ed1adm    20   0 22.5g 4.8g 4.7g S  0.0 30.8  31:32.48  80m ED1_00_DIA_W0
 8499 ed1adm    20   0 22.5g 4.5g 4.4g S  0.0 29.1  21:14.05  75m ED1_00_DIA_W3
41370 ed1adm    20   0 22.5g 4.9g 4.7g S  0.0 31.4  42:53.79  73m ED1_00_DIA_W6
60377 ed1adm    20   0 22.4g 3.9g 3.7g S  0.0 24.8  12:03.23  67m ED1_00_DIA_W4
49747 ed1adm    20   0 22.4g 5.4g 5.2g S  0.0 34.4  38:15.34  64m ED1_00_DIA_W17
41372 ed1adm    20   0 22.5g 4.0g 3.8g S  0.0 25.8  45:24.24  62m ED1_00_DIA_W8




1-337005871    Limited Brands, Inc. - SAP HEC-AMM    CMS-SQ-SAP-TRIO-10    2-Urgent
Summary: ITM Agent Offline: FQ1-vhlbifq1d:lbdfq1app00:mySAP Date: 04/24/2018 Severity: Major ResourceId: lbdfq1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: REMOTE_fmsprdrtem002 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: lbdfq1app00 NodeAlias: 10.8.8.39 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3664218:lbd

[root@LBDFQ1App00 ibmrmalik]# /opt/monitor/IBM/ITM/bin/cinfo -r

*********** Thu Apr 26 14:34:08 HKT 2018 ******************
User: root Groups: root sapinst
Host name : LBDFQ1App00  Installer Lvl:06.23.03.00
CandleHome: /opt/monitor/IBM/ITM
***********************************************************
Host         Prod  PID    Owner  Start  ID   ..Status
LBDFQ1App00  sa    61000                FQ1  ...process not running


[root@LBDFQ1App00 bin]# ./itmcmd agent -o FQ1 start sa
Processing. Please wait...
Starting IBM Tivoli Composite Application Manager Agent for SAP Applications ...
IBM Tivoli Composite Application Manager Agent for SAP Applications started


	

1-337087941    1-Critical    Central American Retail Sourcing Inc. aka Dollarcity SAP HEC-AMM
Summary: Zabbix_agent_on_ca3TOR01web01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1699178] Date: Apr 26,2018 6:54 CUT Severity: Critical ResourceId: ca3tor01web01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ca3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ca3TOR01web01.imzcloud.ibmammsap.local NodeAlias: 10.9.4.100 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3671107:ca3

[ibmrmalik@ca3TOR01web01 ~]$ sudo su
[root@ca3TOR01web01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  13820) is running...
[root@ca3TOR01web01 ibmrmalik]# w
 03:36:19 up 670 days, 15:42,  1 user,  load average: 0.04, 0.03, 0.01


---------------------------------------------------------------------------------------------------------------------------------------------------

27 April

City Football group London
1-337112521 sev1	on lon02ammhana003.xsportal.local	10.112.13.138	root/BRPbwpg9	A0D9UK014XVM026		IPMI Qw28xSbJCb	Ticket # 59098045
Summary: Zabbix_agent_on_loncfgchp0004.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1714875] Date: Apr 26,2018 23:12 CUT Severity: Critical ResourceId: loncfgchp0004 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cf9 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: loncfgchp0004.imzcloud.ibmammsap.local NodeAlias: 10.69.2.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3674558:cf9

 
1-337113001	sev1	A0D9UK014XVM025	lon02ammhana003.xsportal.local		10.112.13.138	root/BRPbwpg9	IPMI Qw28xSbJCb	Ticket # 59098045
Summary: Zabbix_agent_on_loncfgchp0003.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1714860] Date: Apr 26,2018 23:11 CUT Severity: Critical ResourceId: loncfgchp0003 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cf9 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: loncfgchp0003.imzcloud.ibmammsap.local NodeAlias: 10.69.2.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3674554:cf9

https://mbpsjazz.austin.ibm.com:9443/jazz/web/projects/CMS%20NG#action=com.ibm.team.workitem.viewWorkItem&id=223008


1-337119201    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    CMS-SQ-SAP-TRIO-9
Summary: FS_is_read_only_on_C1ECCQ.imzcloud.ibmammsap.local[PROBLEM:1717833] Date: Apr 27,2018 2:19 CUT Severity: Major ResourceId: c1eccq TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCQ.imzcloud.ibmammsap.local NodeAlias: 10.199.2.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3675075:pnc

[root@C1ECCQ ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /mnt/sapexchangePT filesystems are read-only

[root@C1ECCQ ibmrmalik]# cat /etc/fstab |grep /mnt/sapexchangePT
//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  credentials=/etc/sapexchangePT_credential,uid=908,gid=5003

mount //10.7.1.171/sapexchange /mnt/sapexchangePT -t cifs -o credentials=/etc/sapexchangePT_credential,uid=908,gid=5003




1-337119161    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    CMS-SQ-SAP-TRIO-9
Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local[PROBLEM:1717827] Date: Apr 27,2018 2:19 CUT Severity: Major ResourceId: c1bwd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT /mnt/sapexchangePT filesystems are ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWD.imzcloud.ibmammsap.local NodeAlias: 10.199.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3675074:pnc

[root@C1BWD ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /mnt/sapexchangePT /mnt/sapexchangePT filesystems are read-only

# 1-326361567
//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  credentials=/etc/sapexchangePT_credential,uid=908,gid=5003



1-337122181    IBM AMM Infrastructure    2-Urgent    AMM-DELIVERY-TECH	sev2
Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:1720187] Date: Apr 27,2018 5:3 CUT Severity: Major ResourceId: sng01ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.84 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SNG01AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.164 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3675491:amm

[root@SNG01AMMSOL04 ibmrmalik]# w
 03:19:32 up 66 days,  9:59,  1 user,  load average: 0.49, 1.37, 1.43

top - 03:19:49 up 66 days,  9:59,  1 user,  load average: 1.03, 1.45, 1.45
Tasks: 370 total,   1 running, 369 sleeping,   0 stopped,   0 zombie
Cpu(s): 13.2%us,  1.7%sy,  0.0%ni, 76.6%id,  8.1%wa,  0.0%hi,  0.3%si,  0.0%st
Mem:    31.349G total,   31.131G used,  223.645M free,  537.059M buffers
Swap: 8191.996M total, 6054.953M used, 2137.043M free,   19.036G cached




1-337123821    IBM AMM Infrastructure    2-Urgent    AMM-DELIVERY-TEC
Summary: Processor_load_is_too_high_on_dal09ammsrtr2.imzcloud.ibmammsap.local[PROBLEM:1721000] Date: Apr 27,2018 6:3 CUT Severity: Major ResourceId: dal09ammsrtr2 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.02 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsrtr2.imzcloud.ibmammsap.local NodeAlias: 146.89.140.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3675615:amm


[root@dal09ammsrtr2 ibmrmalik]# w

 03:40:45 up 384 days,  4:50,  1 user,  load average: 1.98, 1.90, 1.79
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/0    146.89.140.60    03:40    0.00s  0.04s  0.19s sshd: ibmrmalik
[root@dal09ammsrtr2 ibmrmalik]# top -M
top - 03:40:49 up 384 days,  4:50,  1 user,  load average: 1.82, 1.87, 1.78
Tasks: 151 total,   1 running, 150 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.8%us,  4.2%sy,  0.0%ni, 65.9%id, 29.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7865.609M total, 5841.797M used, 2023.812M free,  368.625M buffers
Swap:   13.766G total, 2538.348M used,   11.287G free, 1131.715M cached



1-337124151  P1  Egyptian Refining Company
Summary: Dataserver_process_is_not_running[PROBLEM:1722078] Date: Apr 27,2018 7:20 CUT Severity: Critical ResourceId: ercerpd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: egr InstanceId: Zabbix-*UNKNOWN*:Sybase_Dataserver ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: Sybase_Dataserver Node: ercerpd1.imzcloud.ibmammsap.local NodeAlias: 10.5.1.101 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:Sybase_Dataserver AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3675825:egr

[root@ercerpd1 ibmrmalik]# w
 10:02:20 up 55 days, 23:35,  2 users,  load average: 0.09, 0.09, 0.12
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/0    146.89.140.60    10:02    0.00s  0.12s  0.19s sshd: ibmrmalik
ibmzlapk pts/2    146.89.140.60    09:14   26:41   0.17s  0.20s sshd: ibmzlapko
[root@ercerpd1 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  3617) is running...
[root@ercerpd1 ibmrmalik]#


-----------------------------------------------------------------------------------------------------------------------------------

30 April

1-337077611	sev1
Summary: Zabbix_agent_on_cpwHANAsolApp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1693902] Date: Apr 26,2018 0:32 CUT Severity: Critical ResourceId: cpwhanasolapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: cpwHANAsolApp.imzcloud.ibmammsap.local NodeAlias: 10.197.6.27 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3670141:cpw
[root@cpwHANAsolApp ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  71910) is running...
[root@cpwHANAsolApp ibmrmalik]# w
 09:20:29 up 336 days,  1:24,  2 users,  load average: 0.15, 0.17, 0.26



1-336534541	sev2
Summary: ITM Agent Offline: HM1-hkg02am:hkg02ammsol04:mySAP Date: 04/10/2018 Severity: Major ResourceId: hkg02ammsol04 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: amm InstanceId: REMOTE_fmsprdrtem002 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: hkg02ammsol04 NodeAlias: 146.89.141.36 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3616784:amm




1-336675341	sev3	10.127.155.74	root/QqLzTGu9	Ticket 59207510 
Summary: Drive_with_Errors_on_parhana-1024-4.xsportal.local[PROBLEM:1505355] Date: Apr 14,2018 7:8 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_parhana-1024-4.xsportal.local InstanceValue: Media Error Count = 4 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_parhana-1024-4.x Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_parhana-1024-4.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3630403:amm

Media Error Count = 37
Media Error Count = 54



1-336852781	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/log[PROBLEM:1575311] Date: Apr 19,2018 9:6 CUT Severity: Minor ResourceId: bi1bwhdbqas01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1BWHDBQAS01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3648286:bi1

[root@BI1BWHDBQAS01 ibmrmalik]# df -h /hana/log
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdd1       130G  117G   14G  90% /hana/log

/hana/log/mnt00001

./mnt00001/hdb00002.00003/logsegment_000_00000000.dat
./mnt00001/hdb00002.00003/logsegment_000_00000001.dat
./mnt00001/hdb00002.00003/logsegment_000_00000002.dat
./mnt00001/hdb00002.00003/logsegment_000_00000003.dat
./mnt00001/hdb00002.00003/logsegment_000_00000004.dat
./mnt00001/hdb00002.00003/logsegment_000_00000005.dat
./mnt00001/hdb00002.00003/logsegment_000_00000006.dat
./mnt00001/hdb00002.00003/logsegment_000_00000007.dat
./mnt00001/hdb00002.00003/logsegment_000_00000008.dat
./mnt00001/hdb00002.00003/logsegment_000_00000009.dat
./mnt00001/hdb00002.00003/logsegment_000_00000010.dat
./mnt00001/hdb00002.00003/logsegment_000_00000011.dat
./mnt00001/hdb00002.00003/logsegment_000_00000012.dat
./mnt00001/hdb00002.00003/logsegment_000_00000013.dat
./mnt00001/hdb00002.00003/logsegment_000_00000014.dat
./mnt00001/hdb00002.00003/logsegment_000_00000015.dat
./mnt00001/hdb00002.00003/logsegment_000_00000016.dat
./mnt00001/hdb00002.00003/logsegment_000_00000017.dat
./mnt00001/hdb00002.00003/logsegment_000_00000018.dat
./mnt00001/hdb00002.00003/logsegment_000_00000019.dat
./backuplog/HBQ_DB/DB_HBQ/log_backup_2_0_6877788992_6894566208.1522915137639
./backuplog/HBQ_DB/DB_HBQ/log_backup_2_0_6894566208_6904425600.1522915148463



1-336880351	Summary: Lack_of_available_memory_on_server_ammpar01custesx003.imzcloud.ibmammsap.loca	sev2



1-336884021	sev3	10.134.53.162	root/AHcWe59j	Ticket # 59208340
Summary: Drive_with_Errors_on_frahana-1024-9.xsportal.local





1-336889311   sev2
Summary: Lack_of_free_swap_space_on_SAHODMS.imzcloud.ibmammsap.local[PROBLEM:1595242] Date: Apr 20,2018 9:14 CUT Severity: Major ResourceId: sahodms TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ch5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: SAHODMS.imzcloud.ibmammsap.local NodeAlias: 10.7.12.49 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3652749:ch5



1-336917541	sev3	10.134.53.165	root/NkF4Akll	Ticket 59206944 
Summary: Drive_with_Errors_on_frahana-1024-5.xsportal.local	
media error 7




1-336936991	sev3	10.127.155.79	root/S8w9EY9z	Ticket 59211058 
Summary: Drive_with_Errors_on_parhana-1024-3.xsportal.loca
media error count 10





1-336950481	sev3

Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/trans[PROBLEM:1644610] Date: Apr 23,2018 9:17 CUT Severity: Minor ResourceId: xf1sabs4hd TicketGroup: ApsSAPTechnical CustomerCode: sbh InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans InstanceValue: 6.6 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: XF1SABS4HD.imzcloud.ibmammsap.local NodeAlias: 10.7.6.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/trans AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3660285:sbh

[root@XF1SABS4HD ibmrmalik]# df -h /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/sap_vg-usrsaptrans_lv
                       12G  9.2G  2.0G  83% /usr/sap/trans


-rw-rw-r-- 1 sedadm sapsys   10284 Apr 30 10:33 SEDE901583.SED
-rw-rw-r-- 1 sedadm sapsys   11898 Apr 24 15:18 SEDE901553.SED
-rw-rw-r-- 1 sedadm sapsys   12929 Apr 24 16:55 SEDE901557.SED
-rw-rw-r-- 1 sedadm sapsys   14936 Apr 23 15:36 SEDE901537.SED
-rw-rw-r-- 1 sedadm sapsys   15169 Apr 26 00:01 SEDE901565.SED
-rw-rw-r-- 1 sedadm sapsys   19415 Apr 30 10:34 ULOG18_2
-rw-rw-r-- 1 sedadm sapsys   20210 Apr 23 15:59 SEDE901539.SED
-rw-rw-r-- 1 sedadm sapsys   20270 Apr 26 16:11 SEDE901567.SED
-rw-rw-r-- 1 sedadm sapsys   37876 Apr 29 17:19 SEDE901579.SED
-rw-rw-r-- 1 sedadm sapsys   47974 Apr 24 15:11 SEDE901551.SED
-rw-rw-r-- 1 sedadm sapsys   51803 Apr 23 14:43 SEDE901509.SED
-rw-rw-r-- 1 sedadm sapsys   87361 Apr 29 21:46 SEDE901581.SED
-rw-rw-r-- 1 sedadm sapsys 2545170 Apr 30 16:38 SLOG1817.SED
-rw-rw-r-- 1 sedadm sapsys 3321938 Apr 30 16:38 SLOG1805.SED
-rw-rw-r-- 1 sedadm sapsys 3326026 Apr 30 16:38 SLOG1751.SED
-rw-rw-r-- 1 sedadm sapsys 3326464 Apr 30 16:38 SLOG1809.SED
-rw-rw-r-- 1 sedadm sapsys 3326464 Apr 30 16:38 SLOG1808.SED
-rw-rw-r-- 1 sedadm sapsys 3326756 Apr 30 16:38 SLOG1810.SED
-rw-rw-r-- 1 sedadm sapsys 3348660 Apr 30 16:38 SLOG1807.SED
-rw-rw-r-- 1 sedadm sapsys 6657162 Apr 30 16:38 SLOG1801.SED






1-336955191 sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/log	

 [root@BI1ERPDBQAS01 ibmrmalik]# df -h /hana/log
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdd1       258G  201G   58G  78% /hana/log



1-336971951	sev2
Summary: Lack_of_available_memory_on_server_ammmon01custesx14.imzcloud.ibmammsap.local[PROBLEM:1651529] Date: Apr 23,2018 17:9 CUT Severity: Major ResourceId: ammmon01custesx14 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-Template_Virt_VMware_Hypervisor:Used_memory InstanceValue: 423.86 GB ComponentType: ZABBIX Component: Template_Virt_VMware_Hypervisor SubComponent: Used_memory Node: ammmon01custesx14.imzcloud.ibmammsap.local NodeAlias: 146.89.141.160 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_Virt_VMware_Hypervisor:Used_memory AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3661479:amm





1-337065891	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var	

[root@IA1S4HQASAPP ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  1.8G  2.8G  39% /var




1-337070281	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/log[PROBLEM:1688937] Date: Apr 25,2018 18:14 CUT Severity: Minor ResourceId: bi1bwhdbprd01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1BWHDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3669236:bi1

/hana/log/backuplog/DB_HBP




1-337074441	sev3
Summary: Processor_load_is_too_high_on_WINT331[PROBLEM:1691030] Date: Apr 25,2018 20:50 CUT Severity: Minor ResourceId: wint331 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 14.233333 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT331 NodeAlias: 10.136.0.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3669633:mt5


----------------------------------------------------------------------------------------------------------------------

2 May


1-337191211	sev3
YHIBWDS01	YWD	10.6.4.202
YHIBIDS01	YRD	10.6.4.203
YHIBIPS01	YRP	10.6.4.208




1-336999881  IAG GBS Limited (IA1)  P2
Summary: ITM Agent Offline: IA1WEBDSLBDRHTTPdp:UAGENT00 Date: 04/24/2018 Severity: Major ResourceId: ia1webdslbdr TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: IA1WEBDSLBDR:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: ia1webdslbdr NodeAlias: 10.133.15.31 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3664133:ia1




1-336917541	sev3	10.134.53.165	root/NkF4Akll	Ticket 59206944




1-336675341	sev3	10.127.155.74	root/QqLzTGu9	Ticket 59207510 




1-336975571  sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:1655936] Date: Apr 23,2018 20:50 CUT Severity: Minor ResourceId: dlbpepda00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 18 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLBPEPDA00.imzcloud.ibmammsap.local NodeAlias: 10.13.1.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3662058:dlb

[root@DLBPEPDA00 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.1G  2.5G  46% /var



1-337139281	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1731063] Date: Apr 27,2018 16:19 CUT Severity: Major ResourceId: clderpappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 2.06 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: CLDERPAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3677126:sm5




1-337144641	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PROBLEM:1737430] Date: Apr 27,2018 23:53 CUT Severity: Minor ResourceId: mgggbjpeccx06 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJPECCX06.imzcloud.ibmammsap.local NodeAlias: 10.133.18.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3678222:mgg

[root@MGGGBJPECCX06 ibmrmalik]# df -h /
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda3        49G   38G  8.5G  82% /

[root@MGGGBJPECCX06 hanadb]# ls -ltrS
total 3170072
-rw-r--r--. 1 root root        186 Sep  2  2017 filelist.dat
-rw-r--r--. 1 root root        719 Sep  2  2017 hana_install.conf
-rw-r--r--  1 root root      25199 Sep  2  2017 hana_install.sh
-rwxr-xr-x. 1 root root    3222072 Sep  2  2017 SAPCAR
-rw-r--r--. 1 root root  306716276 Sep  2  2017 IMDB_CLIENT100_95_0-10009663.SAR
-rw-r--r--. 1 root root  602926843 Sep  2  2017 IMC_STUDIO2_95_0-80000321.SAR
-rw-r--r--. 1 root root 2333236191 Sep  2  2017 IMDB_SERVER100_95_0-10009569.SAR
[root@MGGGBJPECCX06 hanadb]# df -h .
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda3        49G   38G  8.5G  82% /
[root@MGGGBJPECCX06 hanadb]# pwd
/swdeploy/hanadb




1-337232331 - CI3
Need 2 ID's unlocked at OS Level for the VM's: CI3WDDEV   10.210.1.23 & CI3WDPRD     	10.210.1.22.
The ID's are:
1) m.fergany
2) tsamir
This issue occurred after fixing a network request under 
Reference Ticket: 1-335857450




1-337265301	sev3
Summary: NTP_time_is_driffted_on_CONSPTEWS4HAPD.imzcloud.ibmammsap.local[PROBLEM:1830461] Date: May 2,2018 11:54 CUT Severity: Warning ResourceId: consptews4hapd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: con InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.08 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CONSPTEWS4HAPD.imzcloud.ibmammsap.local NodeAlias: 10.16.1.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3692045:con




1-337264251	sev2
Summary: NTP_time_is_driffted_on_LBDWD1App80.imzcloud.ibmammsap.local[PROBLEM:1830359] Date: May 2,2018 11:44 CUT Severity: Major ResourceId: lbdwd1app80 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -5.03 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDWD1App80.imzcloud.ibmammsap.local NodeAlias: 10.8.8.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3692026:lbd



1-337258791	sev3
Summary: NTP_time_is_driffted_on_CONSPECCAPD.imzcloud.ibmammsap.local[PROBLEM:1829683] Date: May 2,2018 10:46 CUT Severity: Warning ResourceId: conspeccapd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: con InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.03 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CONSPECCAPD.imzcloud.ibmammsap.local NodeAlias: 10.16.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3691891:con




1-337257421	sev3
Summary: NTP_time_is_driffted_on_sveq1srv0.imzcloud.ibmammsap.local[PROBLEM:1829028] Date: May 2,2018 9:56 CUT Severity: Warning ResourceId: sveq1srv0 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.42 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sveq1srv0.imzcloud.ibmammsap.local NodeAlias: 10.6.2.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3691781:age




1-337269681	sev1
Summary: Zabbix_agent_on_HC1HOECCHAAPD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1831981] Date: May 2,2018 13:43 CUT Severity: Critical ResourceId: hc1hoecchaapd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: hc1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: HC1HOECCHAAPD.imzcloud.ibmammsap.local NodeAlias: 10.211.80.76 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3692391:hc1


HC1HOECCHAAPD:/etc/init.d # uptime
 11:31am  up   1:06,  4 users,  load average: 0.00, 0.00, 0.01

SCORE WIP

HC1HOECCHAAPD:/etc/init.d # rczabbix-agentd status
Ã¢ zabbix-agentd.service - Zabbix Monitor Agent
   Loaded: loaded (/usr/lib/systemd/system/zabbix-agentd.service; enabled; vendor preset: disabled)
   Active: active (running) since Wed 2018-05-02 11:00:47 -03; 31min ago
 Main PID: 22859 (zabbix-agentd)
    Tasks: 6 (limit: 512)
   CGroup: /system.slice/zabbix-agentd.service
           Ã¢Ã¢22859 /usr/sbin/zabbix-agentd -f
           Ã¢Ã¢22861 /usr/sbin/zabbix-agentd: collector [idle 1 sec
           Ã¢Ã¢22862 /usr/sbin/zabbix-agentd: listener #1 [waiting for connection
           Ã¢Ã¢22863 /usr/sbin/zabbix-agentd: listener #2 [waiting for connection
           Ã¢Ã¢22864 /usr/sbin/zabbix-agentd: listener #3 [waiting for connection
           Ã¢Ã¢22865 /usr/sbin/zabbix-agentd: active checks #1 [idle 1 sec

May 02 11:21:25 HC1HOECCHAAPD sudo[24196]: gkr-pam: couldn't get the password from user: Authentication failure
May 02 11:21:25 HC1HOECCHAAPD sudo[24196]: pam_unix(sudo:auth): conversation failed
May 02 11:21:25 HC1HOECCHAAPD sudo[24196]: pam_unix(sudo:auth): auth could not identify password for [zabbix]
May 02 11:22:23 HC1HOECCHAAPD sudo[24196]: pam_sss(sudo:auth): authentication failure; logname= uid=481 euid=0 tty= ruser=zabbix rhost= user=zabbix
May 02 11:22:23 HC1HOECCHAAPD sudo[24196]: pam_sss(sudo:auth): received for user zabbix: 10 (User not known to the underlying authentication module)
May 02 11:22:23 HC1HOECCHAAPD sudo[24196]:   zabbix : PAM authentication error: User not known to the underlying authentication module ; TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/var/lib/zabbix/bad_drives.sh
May 02 11:22:23 HC1HOECCHAAPD sudo[24196]:   zabbix : command not allowed ; TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/var/lib/zabbix/bad_drives.sh
May 02 11:24:34 HC1HOECCHAAPD sudo[24199]:   zabbix : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/var/lib/zabbix/check_rw_mounts.sh
May 02 11:24:34 HC1HOECCHAAPD sudo[24199]: pam_tally2(sudo:setcred): unknown option: per_user
May 02 11:25:34 HC1HOECCHAAPD sudo[24199]: pam_unix(sudo:session): session opened for user root by (uid=0)







1-337269761    Hortus Comercio de Alimentos SA (St. Marche) (HC1)    1-Critical @rmalik
Summary: Zabbix_agent_on_HC1HOECCHAAPQ.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1832084] Date: May 2,2018 13:48 CUT Severity: Critical ResourceId: hc1hoecchaapq TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: hc1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: HC1HOECCHAAPQ.imzcloud.ibmammsap.local NodeAlias: 10.211.80.83 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3692415:hc1

HC1HOECCHAAPQ:/home/ibmrmalik # rczabbix-agentd status
Ã¢ zabbix-agentd.service - Zabbix Monitor Agent
   Loaded: loaded (/usr/lib/systemd/system/zabbix-agentd.service; enabled; vendor preset: disabled)
   Active: active (running) since Wed 2018-05-02 10:37:55 -03; 1h 5min ago
 Main PID: 19785 (zabbix-agentd)
    Tasks: 6 (limit: 512)
   CGroup: /system.slice/zabbix-agentd.service
           Ã¢Ã¢19785 /usr/sbin/zabbix-agentd -f
           Ã¢Ã¢19870 /usr/sbin/zabbix-agentd: collector [idle 1 sec
           Ã¢Ã¢19871 /usr/sbin/zabbix-agentd: listener #1 [waiting for connection
           Ã¢Ã¢19872 /usr/sbin/zabbix-agentd: listener #2 [waiting for connection
           Ã¢Ã¢19873 /usr/sbin/zabbix-agentd: listener #3 [waiting for connection
           Ã¢Ã¢19874 /usr/sbin/zabbix-agentd: active checks #1 [idle 1 sec

May 02 11:30:03 HC1HOECCHAAPQ sudo[23229]: pam_unix(sudo:auth): auth could not identify password for [zabbix]
May 02 11:30:42 HC1HOECCHAAPQ sudo[23229]: pam_sss(sudo:auth): authentication failure; logname= uid=481 euid=0 tty= ruser=zabbix rhost= user=zabbix
May 02 11:30:42 HC1HOECCHAAPQ sudo[23229]: pam_sss(sudo:auth): received for user zabbix: 10 (User not known to the underlying authentication module)
May 02 11:30:42 HC1HOECCHAAPQ sudo[23229]:   zabbix : PAM authentication error: User not known to the underlying authentication module ; TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/var/lib/zabbix/media_errors.sh
May 02 11:42:22 HC1HOECCHAAPQ sudo[23425]: pam_tally2(sudo:auth): unknown option: per_user
May 02 11:42:22 HC1HOECCHAAPQ sudo[23425]: gkr-pam: couldn't get the password from user: Authentication failure
May 02 11:42:22 HC1HOECCHAAPQ sudo[23425]: pam_unix(sudo:auth): conversation failed
May 02 11:42:22 HC1HOECCHAAPQ sudo[23425]: pam_unix(sudo:auth): auth could not identify password for [zabbix]
May 02 11:42:22 HC1HOECCHAAPQ sudo[23425]: pam_sss(sudo:auth): authentication failure; logname= uid=481 euid=0 tty= ruser=zabbix rhost= user=zabbix
May 02 11:42:22 HC1HOECCHAAPQ sudo[23425]: pam_sss(sudo:auth): received for user zabbix: 10 (User not known to the underlying authentication module)

HC1HOECCHAAPQ:/home/ibmrmalik # uptime
 11:43am  up   1:16,  3 users,  load average: 0.00, 0.00, 0.00




1-337194771	CI3S4HANAPRDA: RAM and Processor Core Upgrade sev2
Please increase RAM and Process Core as mentioned below for the VM: CI3S4HANAPRDA.
1) Additional 100 GB RAM to be 200 GB
2) Add 7 more processor cores to be 23

--------------------------------------------------------------------------------------------------------------------------------------------

3 May



1-337131351	Need Add RAM and disk+swap space	sev3

S4D App - 10.6.7.12
[root@PBBs4hdap00 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          2          5          0          0          1
-/+ buffers/cache:          0          6
Swap:           34          0         34


/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0

[root@PBBs4hdap00 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   2   7   0 wz--n- 64.50g 504.00m

sdf                                8:80   0   25G  0 disk
Ã¢Ã¢VolGroup-lv_swap (dm-1)        253:1    0   35G  0 lvm  [SWAP]

32 GB disk added sdg

vgextend VolGroup /dev/sdg


[root@PBBs4hdap00 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   3   7   0 wz--n- 96.50g 32.49g




VM_Name	Server Purpose			OS		RAM  (OLD)	RAM (NEW)	SWAP
(NEW)	SID
PBBs4hdap00	02 DEV S4HANA ERP - APPS (ASCS)	RHEL 6.8	8G	32G	64G	S4D		DONE



PBBs4hqap00	04 QAS S4HANA ERP - APPS (ASCS)	RHEL 6.8	16G	32G	64G	S4Q		DONE
[root@PBBs4hqap00 ibmrmalik]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0

[root@PBBs4hqap00 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   1   7   0 wz--n- 39.51g 2.50g

[root@PBBs4hqap00 ibmrmalik]# lsblk |grep -i swap
  Ã¢Ã¢VolGroup-lv_swap (dm-1)      253:1    0    8G  0 lvm  [SWAP]

sdf 56 gb added

vgextend VolGroup /dev/sdf




PBBbwhdap00	08 DEV BW on HANA - APPS (ASCS)	RHEL 6.8	8G	32G	64G	B4D

[root@PBBbwhdap00 ibmrmalik]# cat /etc/fstab |grep -i swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0


[root@PBBbwhdap00 ibmrmalik]# lsblk |grep -i swap
  Ã¢Ã¢VolGroup-lv_swap (dm-1)      253:1    0   33G  0 lvm  [SWAP]
Ã¢Ã¢VolGroup-lv_swap (dm-1)        253:1    0   33G  0 lvm  [SWAP]


[root@PBBbwhdap00 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   2   7   0 wz--n- 71.50g 9.49g

sde                                8:64   0   28G  0 disk

vgextend VolGroup /dev/sde










PBBffdapdb00	11 Non-Prod Fiori Front-End Server (DB + Apps)	RHEL 6.8	16G	32G	64G	F4D	DONE

/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0

[root@PBBffdapdb00 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   2   7   0 wz--n- 64.50g 2.49g


[root@PBBffdapdb00 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31          3         27          0          0          1
-/+ buffers/cache:          1         29
Swap:           32          0         32


31GB extension
Ã¢Ã¢VolGroup-lv_swap (dm-1)          253:1    0   33G  0 lvm  [SWAP]

sdj new disk

vgextend VolGroup /dev/sdj

[root@PBBffdapdb00 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31          4         27          0          0          1
-/+ buffers/cache:          2         29
Swap:           63          0         63


1-337308971    City Football Group - SAP HEC-AMM    Summary: Zabbix_agent_on_a0b4uk013cfgvyatta002_is_unavailable
Summary: Zabbix_agent_on_a0b4uk013cfgvyatta002_is_unavailable[PROBLEM:1847098] Date: May 3,2018 8:36 CUT Severity: Critical ResourceId: a0b4uk013cfgvyatta002 TicketGroup: AMM-DELIVERY-TECH CustomerCode: cf9 InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: a0b4uk013cfgvyatta002 NodeAlias: 159.8.184.149 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3695670:cf9




1-337314411  -  P3  -  TAQA Arabia
Add Root Switch Privilege (sudo rootsh) to User ID â€œtaqaadminâ€ to those servers
TQAERPPRD1 (10.200.0.17)	10.7.1.17
TQAERPDEV (10.200.0.15)		10.7.1.15
TQABWAPP (10.200.0.19)		10.7.1.19
TQABWPRDH (10.200.0.40)		10.7.1.40






TQAERPDEVH (10.200.0.33)	10.7.1.33
[root@TQAERPDEVH ibmrmalik]# rpm -qa |grep -i sap-c++
compat-sap-c++-4.8.2-16.el6.x86_64


TQAERPQAH (10.200.0.35)		10.7.1.35
TQAERPPRDH (10.200.0.37)	10.7.1.37	

---> Package compat-sap-c++.x86_64 0:4.8.2-16.el6 will be updated
---> Package compat-sap-c++.x86_64 0:4.8.2-19.el6 will be an update


Package compat-sap-c++-4.8.2-19.el6.x86_64 already installed and latest version
Nothing to do


scp /root/compat-sap-c++-4.8.2-16.el6.x86_64.rpm x.x.x.x:/root

   rpm -Uvh compat-sap-c++-4.8.2-16.el6.x86_64.rpm

   ln -s -f /opt/rh/SAP/lib64/compat-sap-c++.so /usr/lib64/libstdc++.so.6





1-337314421  -  P3  -  TAQA Arabia  -  @rmalik
Install the OS Package â€œpackage compat-sap-c++-6â€ over Servers
TQAERPDEVH (10.200.0.33)	10.7.1.33
TQAERPQAH (10.200.0.35)		10.7.1.35
TQAERPPRDH (10.200.0.37)	10.7.1.37	
TQABWPRDH (10.200.0.40)		10.7.1.40	

 yum install compat-sap-c++

---------------------------------------------------------------------------------------------------------------------------------------

4 May

1-337352971    2-Urgent    AGEAS - SAP HEC-AMM        Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/ 
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:1865172] Date: May 4,2018 7:24 CUT Severity: Major ResourceId: svcs1srv0 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: SVCS1SRV0.imzcloud.ibmammsap.local NodeAlias: 10.6.1.142 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3699424:age

[root@SVCS1SRV0 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  6.8G  2.6G  73% /





1-337103561	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/log[PROBLEM:1708716] Date: Apr 26,2018 18:33 CUT Severity: Minor ResourceId: bi1erpdbprd01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBPRD01.imzcloud.ibmammsap.local NodeAlias: 10.135.3.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/log AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3673660:bi1

[root@BI1ERPDBPRD01 ibmrmalik]# df -h /hana/log
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdd1       1.5T  1.3T  176G  89% /hana/log

./backuplog/log_backup_3_0_53994495296_54011272512.1524826895376
./backuplog/log_backup_3_0_54164805568_54181582784.1524842118791
./backuplog/log_backup_3_0_54181582784_54198359936.1524842318507
./backuplog/log_backup_3_0_54039099008_54055614016.1524837697737




1-337124091	sev3	10.116.145.26	root/KVJP7cm3	59378204
Summary: Drive_with_Errors_on_snghana-1024-10.xsportal.local[PROBLEM:1721991] Date: Apr 27,2018 7:10 CUT Severity: Minor ResourceId: dal09ammmonit001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-*UNKNOWN*:ESXi_Monitoring_snghana-1024-10.xsportal.local InstanceValue: Media Error Count = 3 ComponentType: ZABBIX Component: *UNKNOWN* SubComponent: ESXi_Monitoring_snghana-1024-10. Node: dal09ammmonit001 NodeAlias: 146.89.140.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: *UNKNOWN*:ESXi_Monitoring_snghana-1024-10.xsportal.local AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3675797:amm

Media error 3





1-337135131	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/hana/data[PROBLEM:1729025] Date: Apr 27,2018 13:33 CUT Severity: Minor ResourceId: bi1erpdbdev01 TicketGroup: ApsSAPTechnical CustomerCode: bi1 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data InstanceValue: 17.21 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: BI1ERPDBDEV01.imzcloud.ibmammsap.local NodeAlias: 10.135.4.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/hana/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3676711:bi1

[root@BI1ERPDBDEV01 ibmrmalik]# df -h /hana/data
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_data
                      384G  323G   62G  84% /hana/data

[root@BI1ERPDBDEV01 data]# find . -xdev -type f -size +1000000
./dump/51051151HANADB/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/BIN.TGZ
./dump/51051151HANADB/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server/DATLANGUAGES.TGZ
./dump/51051151HANADB/DATA_UNITS/XSAC_DI_CORE_10/XSACDEVXDI12_0.ZIP
./dump/51051151HANADB/DATA_UNITS/XSA_RT_10_LINUX_X86_64/packages/INITIAL_CONTENT.TGZ
./mnt00001/hdb00003/datavolume_0000.dat
./instlogs/SWPM18/SWPM10SP18_6-20009701.SAR
./WholeBackup/COMPLETE_DATA_BACKUP19APR_databackup_3_1
./WholeBackup/COMPLETE_DATA_BACKUP03MAY_databackup_3_1
./WholeBackup/COMPLETE_DATA_BACKUP27APR_databackup_3_1





1-337357421 Meggitt Plc (MGG) sev1
Summary: Zabbix_agent_on_MGGGBJPECCX05.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1866584] Date: May 4,2018 9:8 CUT Severity: Critical ResourceId: mgggbjpeccx05 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPECCX05.imzcloud.ibmammsap.local NodeAlias: 10.133.18.22 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3699750:mgg

[root@MGGGBJPECCX05 ibmrmalik]# uptime
 05:13:50 up 255 days, 15:49,  1 user,  load average: 2.24, 1.70, 1.34
[root@MGGGBJPECCX05 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  10731) is running...




1-337339811		sev3
10.6.4.201	

[ibmrmalik@YHIEDS01 ~]$ df -h /usr/sap/DAA		add 5GB
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/yedappvg-usrsapdaa_lv
                      9.3G  6.5G  2.4G  74% /usr/sap/DAA

[root@YHIEDS01 ibmrmalik]# vgs yedappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  yedappvg   1  14   0 wz--n- 128.00g 11.61g

lvextend -L +5G  /dev/mapper/yedappvg-usrsapdaa_lv
resize2fs /dev/mapper/yedappvg-usrsapdaa_lv

[root@YHIEDS01 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/yedappvg-usrsapdaa_lv
                       15G  6.5G  7.1G  48% /usr/sap/DAA


[root@YHIEDS01 ibmrmalik]# df -h /sybase/YED/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/yedlogvg-yedsybdiag_lv
                       31G   18G   12G  60% /sybase/YED/sapdiag

[root@YHIEDS01 ibmrmalik]# vgs yedlogvg
  VG       #PV #LV #SN Attr   VSize   VFree
  yedlogvg   2   4   0 wz--n- 331.99g 252.99g


lvextend -L +5G  /dev/mapper/yedlogvg-yedsybdiag_lv
resize2fs /dev/mapper/yedlogvg-yedsybdiag_lv



10.6.4.207

[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywplogvg-ywpsybdiag_lv
                       26G   21G  4.2G  83% /sybase/YWP/sapdiag

[root@YHIBWPS01 ibmrmalik]# vgs ywplogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  ywplogvg   7   4   0 wz--n- 92.48g 7.48g

lvextend -L +6G  /dev/mapper/ywplogvg-ywpsybdiag_lv
resize2fs /dev/mapper/ywplogvg-ywpsybdiag_lv

root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywplogvg-ywpsybdiag_lv
                       32G   21G  9.8G  68% /sybase/YWP/sapdiag


/sybase/YWP/sapdata1							add 90GB

[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdata1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpdatavg-ywpsapdata1_lv
                      261G  226G   23G  92% /sybase/YWP/sapdata1

[root@YHIBWPS01 ibmrmalik]# vgs ywpdatavg
  VG        #PV #LV #SN Attr   VSize VFree
  ywpdatavg  10   7   0 wz--n- 1.10t 10.97g

[root@YHIBWPS01 ibmrmalik]# vgs ywpdatavg
  VG        #PV #LV #SN Attr   VSize VFree
  ywpdatavg  11   7   0 wz--n- 1.49t 410.96g

sdw                                   65:96   0  400G  0 disk
vgextend ywpdatavg /dev/sdw

lvextend -L +90G  /dev/mapper/ywpdatavg-ywpsapdata1_lv
resize2fs /dev/mapper/ywpdatavg-ywpsapdata1_lv

[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdata1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpdatavg-ywpsapdata1_lv
                      350G  226G  107G  68% /sybase/YWP/sapdata1




[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdata2			add 90GB
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpdatavg-ywpsapdata2_lv
                      261G  226G   23G  91% /sybase/YWP/sapdata2

lvextend -L +90G  /dev/mapper/ywpdatavg-ywpsapdata2_lv
resize2fs /dev/mapper/ywpdatavg-ywpsapdata2_lv

[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdata2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpdatavg-ywpsapdata2_lv
                      350G  226G  107G  68% /sybase/YWP/sapdata2




[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdata3			add 90GB
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpdatavg-ywpsapdata3_lv
                      261G  226G   23G  92% /sybase/YWP/sapdata3

lvextend -L +90G  /dev/mapper/ywpdatavg-ywpsapdata3_lv
resize2fs /dev/mapper/ywpdatavg-ywpsapdata3_lv



[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdata4			add 90GB
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpdatavg-ywpsapdata4_lv
                      261G  226G   23G  92% /sybase/YWP/sapdata4

lvextend -L +90G  /dev/mapper/ywpdatavg-ywpsapdata4_lv
resize2fs /dev/mapper/ywpdatavg-ywpsapdata4_lv

[root@YHIBWPS01 ibmrmalik]# df -h /sybase/YWP/sapdata4
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpdatavg-ywpsapdata4_lv
                      350G  226G  107G  68% /sybase/YWP/sapdata4



1-337314433	frankfurt
Add OS User â€œtaqaadminâ€ with Root Switch Privilege (sudo rootsh) to those servers 
TQASOLMAN (10.200.0.14)		10.7.1.14
[root@TQASOLMAN ~]#  cat /etc/sudoers |grep taqaadmin
taqaadmin tqa*=(root) NOPASSWD:SUROOT # Service Request 1-336357051 Expires 2018-12-30

	
TQAADS (10.200.0.18)		10.7.1.18
[root@TQAADS ~]#  cat /etc/sudoers |grep taqaadmin
taqaadmin tqa*=(root) NOPASSWD:SUROOT # Service Request 1-336357051 Expires 2018-12-30






1-337159791
-----------------------------------------------------------------------------------------------------------------------------------------------------------------

7 May

http://pokgsa.ibm.com/gsa/projects/o/openclient-images/rhel74/





1-337412171	lon2    sev2
Long Description: *** Details of Generic Service Request - DO NOT CHANGE ***

dears,

I , kindly check and revert!

10.201.0.17	10.5.242.17	CI2SOL	
[root@CI2SOL ibmrmalik]# w
 11:40:40 up 185 days,  5:52,  1 user,  load average: 0.08, 0.18, 0.15
 
10.201.0.16	10.5.242.16	CI2DEVAPP
[root@CI2DEVAPP ibmrmalik]# w
 11:41:39 up 291 days, 22:49,  2 users,  load average: 0.04, 0.09, 0.08







[root@hkg02ammtsm001 ibmrmalik]# free -g
              total        used        free      shared  buff/cache   available
Mem:            251          19           1         174         230          56
Swap:             1           1           0

[root@hkg02ammtsm001 ibmrmalik]# top -M
top: unknown option 'M'
Usage:
  top -hv | -bcHiOSs -d secs -n max -u|U user -p pid(s) -o field -w [cols]
[root@hkg02ammtsm001 ibmrmalik]# cat /etc/os-release
NAME="Red Hat Enterprise Linux Server"
VERSION="7.5 (Maipo)"
ID="rhel"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="7.5"
PRETTY_NAME="Red Hat"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:redhat:enterprise_linux:7.5:GA:server"
HOME_URL="https://www.redhat.com/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"

REDHAT_BUGZILLA_PRODUCT="Red Hat Enterprise Linux 7"
REDHAT_BUGZILLA_PRODUCT_VERSION=7.5
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="7.5"





1-337438221 - OS Linux - Kindly run the following telnet on mentioned servers	sev3

Kindly run the following telnet on mentioned servers : 

telnet 10.78.22.11 1500
telnet 10.5.22.11 1500

MMGRAS >> 10.78.22.12
SMARCDEVD41 >> 10.78.22.27
SMDBDEVD41 >> 10.78.22.26
ADADPAS3 >> 10.78.24.46
ADADPAS1 >> 10.78.24.11
ADADPAS2 >> 10.78.24.12






1-337442101 IBM AMM Infrastructure  SEV1
Summary: Zabbix_agent_on_lon02ammtsm001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1930779] Date: May 7,2018 10:2 CUT Severity: Critical ResourceId: lon02ammtsm001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: lon02ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.114 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3710349:amm

[root@lon02ammtsm001 ibmrmalik]# w
 12:23:56 up 3 days, 19:04,  3 users,  load average: 7.04, 8.37, 11.45


[root@lon02ammtsm001 init.d]# systemctl status zabbix-agent
Ã¢ zabbix-agent.service - Zabbix Agent
   Loaded: loaded (/usr/lib/systemd/system/zabbix-agent.service; enabled; vendor preset: disabled)
   Active: active (running) since Thu 2018-05-03 17:19:41 CEST; 3 days ago




1-337430611 IBM AMM Infrastructure  SEV1
Summary: Zabbix_agent_on_DAL09AMMZAB001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1928339] Date: May 7,2018 6:52 CUT Severity: Critical ResourceId: dal09ammzab001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DAL09AMMZAB001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709839:amm

[root@DAL09AMMZAB001 ~]# w
 07:34:16 up  3:44,  1 user,  load average: 0.08, 0.03, 0.05

[root@DAL09AMMZAB001 ~]# systemctl status zabbix-agent
Ã¢ zabbix-agent.service - Zabbix Agent
   Loaded: loaded (/usr/lib/systemd/system/zabbix-agent.service; enabled; vendor preset: disabled)
   Active: active (running) since Mon 2018-05-07 07:47:04 EDT; 4s ago







1-337430951 IBM MSD Infras - Cloud MONITORING  SEV1 @rmalik -- can u plz chk this sev1's
Summary: Zabbix_agent_on_DAL09AMMYUM01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1928628] Date: May 7,2018 7:18 CUT Severity: Critical ResourceId: ri3lr023 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DAL09AMMYUM01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709930:mic


[root@DAL09AMMYUM01 ~]# uptime
 06:00:25 up  2:38,  1 user,  load average: 0.00, 0.00, 0.00
[root@DAL09AMMYUM01 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.9 (Santiago)
[root@DAL09AMMYUM01 ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  2520) is running...




1-337314433	sev3
Add OS User â€œtaqaadminâ€ with Root Switch Privilege (sudo rootsh) to those servers 
TQASOLMAN (10.200.0.14)		10.7.1.14
[root@TQASOLMAN ~]#  cat /etc/sudoers |grep taqaadmin
taqaadmin tqa*=(root) NOPASSWD:SUROOT # Service Request 1-336357051 Expires 2018-12-30

[root@TQASOLMAN ibmrmalik]# pam_tally2 --user=taqaadmin
pam_tally2: pam_get_uid; no such user taqaadmin
pam_tally2: Unknown user

	
TQAADS (10.200.0.18)		10.7.1.18
[root@TQAADS ~]#  cat /etc/sudoers |grep taqaadmin
taqaadmin tqa*=(root) NOPASSWD:SUROOT # Service Request 1-336357051 Expires 2018-12-30

[root@TQAADS ibmrmalik]# pam_tally2 --user=taqaadmin
pam_tally2: pam_get_uid; no such user taqaadmin
pam_tally2: Unknown user




Fgw70odns






1-337439731 St Jude Medical Singapore - SAP HEC  1
Summary: Zabbix_agent_on_sjmqepdb01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1931121] Date: May 7,2018 10:35 CUT Severity: Critical ResourceId: sjmqepdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: sjmqepdb01.imzcloud.ibmammsap.local NodeAlias: 10.198.12.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3710429:ju1

[root@sjmqepdb01 ibmrmalik]# uptime
 11:00:47 up 295 days, 23:54,  1 user,  load average: 1.35, 0.85, 0.70
[root@sjmqepdb01 ibmrmalik]# /etc/init.d/zabbix-agent
Usage: /etc/init.d/zabbix-agent {start|stop|status|restart|try-restart|force-reload}
[root@sjmqepdb01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  32538) is running...






1-336878834	sev3

Security Alert Remediation- IBM AOD security alert and recommended remediation on RH Linux OS Ver  5.x/6.x

Recommended Alert Below :
Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x

Please deploy above Q218-patches manually to the following servers.

<Server List>

DLTHSPSPI	10.4.5.26	A0DBUS014XVM010

Thanks and regards,
Sai Sandeep.

TRIO-CEM-AMM 3.x-Q218: Apply latest Q218 bundle  patches on RH Linux 	


[root@DLTHSPSPI ibmrmalik]# uname -a
Linux DLTHSPSPI 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux

kernel-headers.x86_64 0:2.6.32-696.23.1.el6

Linux DLTHSPSPI 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux






1-337410981	sev3
Hi Team, with referene to the attached singed PCR form could you please add 9 more vCPUs to the VM CI3S4HANAPRDA	10.210.1.12	Paris





1-337425441    Summary: Zabbix_agent_on_dcgdfedb00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926218] Date:
Summary: Zabbix_agent_on_dcgdfedb00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926218] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: dcgdfedb00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dcgdfedb00.imzcloud.ibmammsap.local NodeAlias: 10.197.6.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709414:cpw




1-337425551    Summary: Zabbix_agent_on_dcgqfeapp30.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926229] Date:
Summary: Zabbix_agent_on_dcgqfeapp30.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926229] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: dcgqfeapp30 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dcgqfeapp30.imzcloud.ibmammsap.local NodeAlias: 10.197.6.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709429:cpw




1-337425661    Summary: Zabbix_agent_on_DCGHANAPRDDB1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926342] Dat
Summary: Zabbix_agent_on_DCGHANAPRDDB1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926342] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: dcghanaprddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DCGHANAPRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.197.5.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709450:cpw




1-337426271    Summary: Zabbix_agent_on_cpwHANAsolApp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926367] Dat
Summary: Zabbix_agent_on_cpwHANAsolApp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926367] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: cpwhanasolapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: cpwHANAsolApp.imzcloud.ibmammsap.local NodeAlias: 10.197.6.27 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709457:cpw




1-337425731    Summary: Zabbix_agent_on_dcghanaqasapp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926365] Dat
Summary: Zabbix_agent_on_dcghanaqasapp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926365] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: dcghanaqasapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dcghanaqasapp.imzcloud.ibmammsap.local NodeAlias: 10.197.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709461:cpw




1-337426441    Summary: Zabbix_agent_on_DCGPFEAPP10.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926404] Date:
Summary: Zabbix_agent_on_DCGPFEAPP10.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926404] Date: May 7,2018 6:30 CUT Severity: Critical ResourceId: dcgpfeapp10 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DCGPFEAPP10.imzcloud.ibmammsap.local NodeAlias: 10.197.5.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709482:cpw




1-336786351    Summary: Zabbix_agent_on_dcgrfeapp20.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548497] Date:
Summary: Zabbix_agent_on_dcgrfeapp20.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1548497] Date: Apr 18,2018 5:36 CUT Severity: Critical ResourceId: dcgrfeapp20 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dcgrfeapp20.imzcloud.ibmammsap.local NodeAlias: 10.197.5.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3642152:cpw

[root@dcgrfeapp20 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  3716) is running...
[root@dcgrfeapp20 ibmrmalik]# uptime
 17:12:37 up 58 days, 20:34,  1 user,  load average: 0.04, 0.11, 0.05



1-337053541    Summary: Zabbix_agent_on_cpwHANAsolmDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1683851] Dat
Summary: Zabbix_agent_on_cpwHANAsolmDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1683851] Date: Apr 25,2018 12:9 CUT Severity: Critical ResourceId: cpwhanasolmdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: cpwHANAsolmDB.imzcloud.ibmammsap.local NodeAlias: 10.197.6.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3668131:cpw

[root@cpwHANAsolmDB ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  5079) is running...
[root@cpwHANAsolmDB ibmrmalik]# uptime
 16:07:57 up 12 days,  2:49,  1 user,  load average: 0.14, 0.27, 0.26



1-337053621    Summary: Zabbix_agent_on_dcghanasoldb1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1684034] Dat
Summary: Zabbix_agent_on_dcghanasoldb1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1684034] Date: Apr 25,2018 12:23 CUT Severity: Critical ResourceId: dcghanasoldb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dcghanasoldb1.imzcloud.ibmammsap.local NodeAlias: 10.197.5.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3668156:cpw

[root@dcghanasoldb1 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4964) is running...
[root@dcghanasoldb1 ibmrmalik]# uptime
 16:03:05 up 33 days,  4:21,  1 user,  load average: 0.34, 0.36, 0.31



1-337056241    Summary: Zabbix_agent_on_dcghanasolapp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1685261] Dat
Summary: Zabbix_agent_on_dcghanasolapp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1685261] Date: Apr 25,2018 13:1 CUT Severity: Critical ResourceId: dcghanasolapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dcghanasolapp.imzcloud.ibmammsap.local NodeAlias: 10.197.5.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3668283:cpw

[root@dcghanasolapp ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  61939) is running...
[root@dcghanasolapp ibmrmalik]# uptime
 15:59:03 up 69 days, 18:42,  2 users,  load average: 1.67, 1.53, 1.44


----------------------------------------------------------------------------------------------------------------------------------------------------

8 May


1-337516281    2-Urgent    Fitbit, Inc. - SAP HEC-AMM        Summary: Lack_of_free_swap_space_on_fbqhanaapp.imzcloud.ibmammsap.local

Summary: Lack_of_free_swap_space_on_fbqhanaapp.imzcloud.ibmammsap.local[PROBLEM:1957518] Date: May 8,2018 8:25 CUT Severity: Major ResourceId: fbqhanaapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.86 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: fbqhanaapp.imzcloud.ibmammsap.local NodeAlias: 10.4.26.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3716854:fbt

[root@fbqhanaapp ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         62          0          8          0          8
-/+ buffers/cache:         53          9
Swap:           63         32         31

top - 01:44:09 up 40 days, 17:41,  1 user,  load average: 0.07, 0.06, 0.07
Tasks: 401 total,   1 running, 400 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.7%us,  0.2%sy,  0.0%ni, 99.0%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.914G total,   62.483G used,  441.273M free,  115.586M buffers
Swap:   64.000G total,   32.090G used,   31.910G free, 8892.379M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
14435 s4qadm    20   0  124g  44g  13m S  0.0 71.0  15:12.81  25g icman





ADADPAS3 >> 10.78.24.46




1-337510181	Time need to be change in IC4SAP to IST time	sev3
 change system time as India "IST" time in all adani based server 


10.182.201.18	ADNAELDEVDB	10.198.201.18
10.182.201.11	ADNAELDEVAPP	10.198.201.11
10.182.202.12	ADNAELQADB	10.198.202.12
10.182.200.20	ADNAELDB	10.198.200.20
10.182.200.12	ADNAELAPP1	10.198.200.12	
10.182.200.11	ADNAELAPP2	10.198.200.11
10.182.201.19	ADNBIDEVDB	10.198.201.19
10.182.201.13	ADNBIDEVAPP	10.198.201.13
10.182.200.21	ADNABPDB	10.198.200.21
10.182.200.13	ADNABPAPP1	10.198.200.13
10.182.200.14	ADNABPAPP2	10.198.200.14
10.182.201.20	ADNMP1DEVDB	10.198.201.20
10.182.201.16	ADNMP1DEVAPP	10.198.201.16
10.182.202.11	ADNMP1QADB	10.198.202.11
10.182.200.22	ADNMP1DB	10.198.200.22
10.182.200.17	ADNMP1APP1	10.198.200.17
10.182.200.18	ADNMP1APP2	10.198.200.18
10.182.201.15	ADNPODEV	10.198.201.15
10.182.200.16	ADNPOPROD	10.198.200.16
10.182.201.14	ADNDMSDEV	10.198.201.14
10.182.200.15	ADNDMSPROD	10.198.200.15
10.182.200.23	ADNSFTPPD	10.198.200.23		
10.182.200.19	ADNWEBDISP	10.198.200.19	



cd /etc
1.cp localtime /tmp/localtime.old
2.rm localtime 
3. ln -s /usr/share/zoneinfo/Asia/Calcutta localtime 
4. date 


to get timezone list
ls /usr/share/zoneinfo


ln -s /usr/share/zoneinfo/Asia/Calcutta localtime
/usr/share/zoneinfo/Asia/Calcutta



1-337505748	sev3
HANA 1 Installation Source File over those Servers:
o             TQAERPPRDH (10.200.0.37)          <Priority>

o             TQAERPDEVH (10.200.0.33)

o             TQAERPQAH (10.200.0.35)

o             TQABWPRDH (10.200.0.40)




1-337447751	sev3
Enable the FTP services on ADNAELDEVDB 10.182.201.18 (CFN IP)	10.198.201.18 (IFN IP)





1-337518921    1-Critical    IBM AMM Infrastructure    Summary: Zabbix_agent_on_dal09ammtsm001.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_dal09ammtsm001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1958772] Date: May 8,2018 10:17 CUT Severity: Critical ResourceId: dal09ammtsm001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dal09ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.50 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3717081:amm

[root@dal09ammtsm001 ~]# uptime
 05:29:38 up 18:38,  3 users,  load average: 1.18, 0.95, 1.62

 Active: active (running) since Mon 2018-05-07 10:51:58 CDT; 18h ago
  Process: 2013 ExecStart=/usr/sbin/zabbix_agentd -c $CONFFILE (code=exited, status=0/SUCCESS)




1-337523211  -  P1  -  IBM AMM Infrastructure
ummary: Zabbix_agent_on_lon02ammtsm001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1959178] Date: May 8,2018 10:44 CUT Severity: Critical ResourceId: lon02ammtsm001
Summary: Zabbix_agent_on_lon02ammtsm001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1959178] Date: May 8,2018 10:44 CUT Severity: Critical ResourceId: lon02ammtsm001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: lon02ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.114 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3717172:amm

Active: active (running) since Thu 2018-05-03 17:19:41 CEST; 4 days ago
  Process: 2301 ExecStart=/usr/sbin/zabbix_agentd -c $CONFFILE (code=exited, status=0/SUCCESS)
[root@lon02ammtsm001 ibmrmalik]# uptime
 14:22:16 up 4 days, 21:03,  2 users,  load average: 16.98, 10.25, 7.83




1-337498771    Limited Brands, Inc. - SAP HEC-AMM    Assigned/In Progress    3-Standard    LBD    AMM-DELIVERY-TECH
Please allocate space to each sapdata, as seems like there is no space in the VG 
Please allocate space as bellow

"/dev/mapper/VolGroup-lv_root
                      9.8G  6.6G  2.7G  72% /"  --> 3 GB

IP and hostname
LBDWP1APP80	10.8.8.65

lvextend -L +3G  /dev/mapper/VolGroup-lv_root
resize2fs /dev/mapper/VolGroup-lv_root

[root@LBDWP1App80 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                       13G  6.6G  5.5G  55% /



1-337498791    Limited Brands, Inc. - SAP HEC-AMM    Assigned/In Progress    3-Standard    LBD    AMM-DELIVERY-TECH
"/dev/mapper/bipappvg-usrtrans_lv
                       40G   29G  9.4G  75% /usr/sap/trans" -->  11GB
[root@LBDBIPPRDApp3 ibmrmalik]# df -h /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipappvg-usrtrans_lv
                       40G   29G  9.4G  75% /usr/sap/trans

[root@LBDBIPPRDApp3 ibmrmalik]# df -h /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipappvg-usrtrans_lv
                       51G   29G   20G  59% /usr/sap/trans

lvextend -L +11G  /dev/mapper/bipappvg-usrtrans_lv
resize2fs /dev/mapper/bipappvg-usrtrans_lv


IP and hostname
LBDBIPPRDApp3	10.8.8.185




1-337498811    Limited Brands, Inc. - SAP HEC-AMM    Assigned/In Progress    3-Standard    LBD    AMM-DELIVERY-TECH	duplicate of 1-337498771
"/dev/mapper/VolGroup-lv_root
                      9.8G  6.6G  2.7G  72% /"  3GB


IP and hostname
LBDWP1APP80	10.8.8.65

[root@LBDWP1App80 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                       13G  6.6G  5.5G  55% /



1-337498831    Limited Brands, Inc. - SAP HEC-AMM    Assigned/In Progress    3-Standard    LBD    AMM-DELIVERY-TECH
Please allocate space as bellow

"/dev/mapper/bipdatavg-bipsapdata1_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata1  -->7GB
[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata1


Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata1_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata1
[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata2

Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata2_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata2
[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata3

Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata3_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata3
[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata4
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata4_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata4
sdh added
vgextend bipdatavg /dev/sdh


lvextend -L +7G  /dev/mapper/bipdatavg-bipsapdata1_lv
resize2fs /dev/mapper/bipdatavg-bipsapdata1_lv

[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata1_lv
                       40G   22G   16G  59% /sybase/BIP/sapdata1
[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata2_lv
                       40G   22G   16G  59% /sybase/BIP/sapdata2
[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata3
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata3_lv
                       40G   22G   16G  59% /sybase/BIP/sapdata3
[root@LBDBIPPRDDB1 ibmrmalik]# df -h /sybase/BIP/sapdata4
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bipdatavg-bipsapdata4_lv
                       40G   22G   16G  59% /sybase/BIP/sapdata4



/dev/mapper/bipdatavg-bipsapdata2_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata2  -->7GB

/dev/mapper/bipdatavg-bipsapdata3_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata3  -->7GB


/dev/mapper/bipdatavg-bipsapdata4_lv
                       33G   22G  9.2G  71% /sybase/BIP/sapdata4"  -->7GB

IP and hostname
LBDBIPPRDDB1	10.8.8.182




1-337498851    Limited Brands, Inc. - SAP HEC-AMM    Assigned/In Progress    3-Standard    LBD    AMM-DELIVERY-TECH
/dev/mapper/bd1appvg-usrsap_lv
                     1008M  747M  211M  79% /usr/sap  --> 1 GB

[root@LBDBD1App00 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bd1appvg-usrsap_lv
                     1008M  747M  210M  79% /usr/sap

lvextend -L +1G  /dev/mapper/bd1appvg-usrsap_lv
resize2fs /dev/mapper/bd1appvg-usrsap_lv

IP and hostname
LBDBD1APP00	10.8.8.22

[root@LBDBD1App00 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bd1appvg-usrsap_lv
                      2.0G  747M  1.2G  40% /usr/sap



1-337498881    Limited Brands, Inc. - SAP HEC-AMM    Assigned/In Progress    3-Standard    LBD    AMM-DELIVERY-TECH
"/dev/mapper/cd1appvg-sapstage_lv
                      5.0G  3.7G  1.1G  78% /sapstage  --> 2 GB

/dev/mapper/cd1appvg-backup_lv
                      5.0G  3.8G  978M  80% /backup"  --> 2GB

IP and hostname
LBDCD1APP00	10.8.8.18

[root@LBDCD1App00 ibmrmalik]# df -h /sapstage
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/cd1appvg-sapstage_lv
                      5.0G  3.7G  1.1G  78% /sapstage

lvextend -L +2G  /dev/mapper/cd1appvg-sapstage_lv
resize2fs /dev/mapper/cd1appvg-sapstage_lv


[root@LBDCD1App00 ibmrmalik]# df -h /backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/cd1appvg-backup_lv
                      5.0G  3.8G  978M  80% /backup

lvextend -L +2G  /dev/mapper/cd1appvg-backup_lv
resize2fs /dev/mapper/cd1appvg-backup_lv

[root@LBDCD1App00 ibmrmalik]# df -h /backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/cd1appvg-backup_lv
                      6.9G  3.8G  2.9G  57% /backup
[root@LBDCD1App00 ibmrmalik]# df -h /sapstage
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/cd1appvg-sapstage_lv
                      6.9G  3.7G  3.0G  56% /sapstage




1-337526581    2-Urgent    Tecnologia De Materiales S.A.    Summary: Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.local
Summary: Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.local[PROBLEM:1961912] Date: May 8,2018 14:1 CUT Severity: Major ResourceId: tdmprdecc TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: tdm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.52 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: TDMprdecc.imzcloud.ibmammsap.local NodeAlias: 10.4.20.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3717632:tdm

[root@TDMprdecc ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          5          0          5
-/+ buffers/cache:          5          5
Swap:           13          6          7

top - 09:54:34 up 592 days,  3:09,  3 users,  load average: 0.15, 0.21, 0.19
Tasks: 306 total,   1 running, 305 sleeping,   0 stopped,   0 zombie
Cpu(s):  3.9%us,  0.2%sy,  0.1%ni, 95.7%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    11.682G total,   11.546G used,  138.895M free, 9576.000k buffers
Swap:   13.766G total, 6914.664M used, 7181.332M free, 5796.293M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
57009 hp1adm    20   0 1504m 6920 1316 S  0.0  0.1  40:45.55 792m en.sapHP1_ASCS
 5272 root      20   0 2294m  10m 1584 S  0.3  0.1  36:14.88 415m python
59049 hp1adm    20   0 2484m  16m 9868 S  0.0  0.1  43:35.70 106m icman
11231 root      20   0  323m 2032 1252 S  0.0  0.0 300:54.17  88m vmtoolsd




1-337526791	sev1
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1962421] Date: May 8,2018 14:44 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3717798:amm

-------------------------------------------------------------------------------------------------------------------------------------------------------------------

9 May


1-337541981	sev3
Please Enable the FTP Servies for all the below servers.

CFN IP	Host Name
10.182.201.18	ADNAELDEVDB	10.198.201.18
10.182.201.11	ADNAELDEVAPP	10.198.201.11
10.182.202.12	ADNAELQADB	10.198.202.12
10.182.200.20	ADNAELDB	10.198.200.20
10.182.200.12	ADNAELAPP1	10.198.200.12
10.182.200.11	ADNAELAPP2	10.198.200.11
10.182.201.19	ADNBIDEVDB	10.198.201.19
10.182.201.13	ADNBIDEVAPP	10.198.201.13
10.182.200.21	ADNABPDB	10.198.200.21
10.182.200.13	ADNABPAPP1	10.198.200.13
10.182.200.14	ADNABPAPP2	10.198.200.14
10.182.201.20	ADNMP1DEVDB	10.198.201.20
10.182.201.16	ADNMP1DEVAPP	10.198.201.16
10.182.202.11	ADNMP1QADB	10.198.202.11
10.182.200.22	ADNMP1DB	10.198.200.22
10.182.200.17	ADNMP1APP1	10.198.200.17
10.182.200.18	ADNMP1APP2	10.198.200.18
10.182.201.15	ADNPODEV	10.198.201.15
10.182.200.16	ADNPOPROD	10.198.200.16
10.182.201.14	ADNDMSDEV	10.198.201.14
10.182.200.15	ADNDMSPROD	10.198.200.15
10.182.200.23	ADNSFTPPD	10.198.200.23
10.182.200.19	ADNWEBDISP	10.198.200.19



1-337576293  -  P3  -  Nederlandse Aardolie Maatschappij BV Shell (NAM)
10.7.7.22	Win 2k12 Frankfurt
Hi Team, 

Please change the regular Access to Admin Access for 
Kite.Zack@beca.com
on
EEPDEV02



1-337425061	Sev1
Summary: Zabbix_agent_on_MGGGBJSECCX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926128] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjseccx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJSECCX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.164 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709221:mgg


1-337425071	sev1
Summary: Zabbix_agent_on_MGGGBJSGTSX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926105] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjsgtsx01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJSGTSX01.imzcloud.ibmammsap.local NodeAlias: 10.133.18.183 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709220:mgg


1-337424661	sev1
Summary: Zabbix_agent_on_MGGGBJDGTSX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926129] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjdgtsx01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJDGTSX01.imzcloud.ibmammsap.local NodeAlias: 10.133.18.185 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709222:mgg


1-337425091	sev1
Summary: Zabbix_agent_on_MGGGBJPGTSX03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926113] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjpgtsx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPGTSX03.imzcloud.ibmammsap.local NodeAlias: 10.133.18.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709227:mgg



1-337424641	sev1
Summary: Zabbix_agent_on_MGGGBJPCNTX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926112] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjpcntx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPCNTX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709223:mgg


1-337424851	sev1
Summary: Zabbix_agent_on_MGGGBJPECCX03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926185] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: mgggbjpeccx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPECCX03.imzcloud.ibmammsap.local NodeAlias: 10.133.18.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709345:mgg


1-337424941 	sev1	
Summary: Zabbix_agent_on_MGGGBJPECCX06.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926225] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: mgggbjpeccx06 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPECCX06.imzcloud.ibmammsap.local NodeAlias: 10.133.18.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709412:mgg



1-337425241	sev1
Summary: Zabbix_agent_on_MGGGBJVECCX04.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926172] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjveccx04 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJVECCX04.imzcloud.ibmammsap.local NodeAlias: 10.133.18.174 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709272:mgg



1-337425221 	sev1
Summary: Zabbix_agent_on_MGGGBJVECCX07.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926171] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjveccx07 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJVECCX07.imzcloud.ibmammsap.local NodeAlias: 10.133.18.177 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709242:mgg



1-337425611	sev1
Summary: Zabbix_agent_on_MGGGBJDSOLX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926310] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: mgggbjdsolx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJDSOLX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.196 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709439:mgg




1-337424771	sev1
Summary: Zabbix_agent_on_MGGGBJDSOLX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926170] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: mgggbjdsolx01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJDSOLX01.imzcloud.ibmammsap.local NodeAlias: 10.133.18.195 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709239:mgg



1-337426861	sev1
Summary: Zabbix_agent_on_MGGGBJPECCX10.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926491] Date: May 7,2018 6:31 CUT Severity: Critical ResourceId: mgggbjpeccx10 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPECCX10.imzcloud.ibmammsap.local NodeAlias: 10.133.18.37 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709539:mgg



1-337424461	sev1
Summary: Zabbix_agent_on_AFRS4HQADB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926072] Date: May 7,2018 6:26 CUT Severity: Critical ResourceId: afrs4hqadb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRS4HQADB.imzcloud.ibmammsap.local NodeAlias: 10.197.1.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709198:afr



1-337425801 	sev1
Summary: Zabbix_agent_on_AFRS4HQA.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926399] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: afrs4hqa TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRS4HQA.imzcloud.ibmammsap.local NodeAlias: 10.197.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709471:afr


1-337425901	sev1
Summary: Zabbix_agent_on_AFRSH4PRD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926430] Date: May 7,2018 6:30 CUT Severity: Critical ResourceId: afrsh4prd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: 	.imzcloud.ibmammsap.local NodeAlias: 10.197.0.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709490:afr



1-337425111	sev1
Summary: Zabbix_agent_on_IA1HCIPRDAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926133] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: ia1hciprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1HCIPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709230:ia1



1-337425181	sev1
Summary: Zabbix_agent_on_IA1FOIDEVAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926163] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: ia1foidevapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1FOIDEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709237:ia1



1-337425031    sev1
Summary: Zabbix_agent_on_IA1WEBDSLB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926104] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: ia1webdslb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1WEBDSLB.imzcloud.ibmammsap.local NodeAlias: 10.133.15.32 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709215:ia1



1-337425141	sev1
Summary: Zabbix_agent_on_IA2PODEVDBAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926134] Date: May 7,2018 6:27 CUT Severity: Critical ResourceId: ia2podevdbapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA2PODEVDBAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.45 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709232:ia1




1-337426211	sev1
Summary: Zabbix_agent_on_IA1OTASPRDDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926341] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: ia1otasprddb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1OTASPRDDB.imzcloud.ibmammsap.local NodeAlias: 10.133.17.146 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709446:ia1



1-337425651	sev1
Summary: Zabbix_agent_on_IA2S4HDEVDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926318] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: ia2s4hdevdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA2S4HDEVDB.imzcloud.ibmammsap.local NodeAlias: 10.133.16.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709451:ia1



1-337426311	sev1
Summary: Zabbix_agent_on_IA1ADSDEVAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926366] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: ia1adsdevapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1ADSDEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709456:ia1



1-337426181	sev1
Summary: Zabbix_agent_on_IA1PISBXDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926340] Date: May 7,2018 6:29 CUT Severity: Critical ResourceId: ia1pisbxdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1PISBXDB.imzcloud.ibmammsap.local NodeAlias: 10.133.16.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709445:ia1



1-337585721	sev1
Summary: Zabbix_agent_on_PBBs4hpap00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1986079] Date: May 9,2018 13:43 CUT Severity: Critical ResourceId: pbbs4hpap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pbb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PBBs4hpap00.imzcloud.ibmammsap.local NodeAlias: 10.6.7.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3725056:pbb




1-337586781	sev1
Summary: Zabbix_agent_on_PBBs4hdap00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1986084] Date: May 9,2018 13:43 CUT Severity: Critical ResourceId: pbbs4hdap00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pbb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PBBs4hdap00.imzcloud.ibmammsap.local NodeAlias: 10.6.7.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3725058:pbb




1-337586831	
Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:1986186] Date: May 9,2018 13:55 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /usr/sap/TecnoFerrari filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3725092:pnc

[root@C1ECCP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /usr/sap/TecnoFerrari filesystems are read-only


//10.24.100.80/TecnoFerrari
                      466G   39G  428G   9% /usr/sap/TecnoFerrari

[root@C1ECCP ibmrmalik]# cat /etc/fstab |grep //10.24.100.80/TecnoFerrari
mount //10.24.100.80/TecnoFerrari /usr/sap/TecnoFerrari -t cifs -o credentials=/etc/TecnoFerrari_credential,uid=908,gid=5003


[root@C1ECCP sap]# sh /var/lib/zabbix/check_rw_mounts.sh
OK





1-336811861 NTP_time_is_driffted_on_IA1BPCPRDDBHA.imzcloud.ibmammsap.local	sev3
Summary: NTP_time_is_driffted_on_IA1BPCPRDDBHA.imzcloud.ibmammsap.local[PROBLEM:1551103] Date: Apr 18,2018 10:22 CUT Severity: Warning ResourceId: ia1bpcprddbha TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.62 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: IA1BPCPRDDBHA.imzcloud.ibmammsap.local NodeAlias: 10.133.15.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3643345:ia1



1-337425461	sev1
Summary: Zabbix_agent_on_IA1ADSPRDAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926265] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: ia1adsprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1ADSPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709428:ia1



1-337424881	sev1
Summary: Zabbix_agent_on_IA2WEDDSPDEV1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926187] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: ia2weddspdev1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA2WEDDSPDEV1.imzcloud.ibmammsap.local NodeAlias: 10.133.16.44 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709353:ia1


1-337424901
Summary: Zabbix_agent_on_IA2SOLMANDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926152] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: ia2solmandb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA2SOLMANDB.imzcloud.ibmammsap.local NodeAlias: 10.133.15.71 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709407:ia1



1-337424981	sev1
Summary: Zabbix_agent_on_IA1POPRDAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1926216] Date: May 7,2018 6:28 CUT Severity: Critical ResourceId: ia1poprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1POPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3709411:ia1



1-337455741	sev2
Summary: Processor_load_is_too_high_on_smhccdevdcc.imzcloud.ibmammsap.local[PROBLEM:1935298] Date: May 7,2018 15:42 CUT Severity: Major ResourceId: smhccdevdcc TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 0.995 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: smhccdevdcc.imzcloud.ibmammsap.local NodeAlias: 10.78.22.51 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3711348:cma


1-337455901
Summary: Processor_load_is_too_high_on_smslddevdl0.imzcloud.ibmammsap.local[PROBLEM:1935410] Date: May 7,2018 15:48 CUT Severity: Major ResourceId: smslddevdl0 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.31 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: smslddevdl0.imzcloud.ibmammsap.local NodeAlias: 10.78.22.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3711384:cma

[root@smslddevdl0 ~]# uptime
 16:18:23 up 120 days,  8:38,  5 users,  load average: 0.06, 0.06, 0.07

top - 16:18:43 up 120 days,  8:39,  5 users,  load average: 0.04, 0.05, 0.06
Tasks: 495 total,   2 running, 493 sleeping,   0 stopped,   0 zombie
Cpu(s): 20.2%us,  3.8%sy,  0.0%ni, 75.7%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.139G used,  433.203M free, 1048.250M buffers
Swap: 8191.996M total,  428.332M used, 7763.664M free, 6457.574M cached




1-337457411
Summary: Processor_load_is_too_high_on_smedidevdu1.imzcloud.ibmammsap.local[PROBLEM:1935720] Date: May 7,2018 16:7 CUT Severity: Major ResourceId: smedidevdu1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.01 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: smedidevdu1.imzcloud.ibmammsap.local NodeAlias: 10.78.22.55 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3711463:cma

top - 16:25:19 up 79 days,  3:42,  1 user,  load average: 0.00, 0.00, 0.00
Tasks: 350 total,   1 running, 349 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.1%us,  0.5%sy,  0.0%ni, 98.4%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.563G total,   14.727G used,  855.281M free,  950.164M buffers
Swap: 8191.996M total,  233.000M used, 7958.996M free, 6690.629M cached


[root@smedidevdu1 ~]# w
 16:25:36 up 79 days,  3:42,  1 user,  load average: 0.00, 0.00, 0.00



1-337456531
Summary: Processor_load_is_too_high_on_rrtnas.imzcloud.ibmammsap.local[PROBLEM:1935726] Date: May 7,2018 16:9 CUT Severity: Major ResourceId: rrtnas TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cma InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.01 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: rrtnas.imzcloud.ibmammsap.local NodeAlias: 10.78.24.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3711466:cma

[root@rrtnas ~]# w
 18:29:40 up 309 days,  5:21,  1 user,  load average: 0.02, 0.01, 0.00

top - 18:29:58 up 309 days,  5:21,  1 user,  load average: 0.01, 0.01, 0.00
Tasks: 169 total,   1 running, 168 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.0%us,  0.3%sy,  0.1%ni, 98.6%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7856.793M total, 7339.973M used,  516.820M free,  665.688M buffers
Swap: 8191.996M total,   31.043M used, 8160.953M free, 3015.332M cached
-----------------------------------------------------------------------------------------------------------------------------------------------------------


10 May

1-337245031	sev3
Summary: NTP_time_is_driffted_on_CA3DWD.imzcloud.ibmammsap.local[PROBLEM:1819838] Date: May 1,2018 22:26 CUT Severity: Warning ResourceId: ca3dwd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ca3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.3 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: CA3DWD.imzcloud.ibmammsap.local NodeAlias: 10.9.5.215 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3690175:ca3


1-337590923	sev3		A0E3CA014XVM004
Add disk space to the following Dollar City systems and mount points:
10.9.5.203 - add 10GB to /usr/sap

[root@DB6 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                       73G   55G   15G  79% /usr/sap
sdf
vgextend vg_app /dev/sdf
lvextend -L +10G  /dev/mapper/vg_app-lv_usrsap
resize2fs /dev/mapper/vg_app-lv_usrsap



10.9.5.203 - add 10GB to/sybase
[root@DB6 ibmrmalik]# df -h /sybase
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_data-lv_db
                      197G  153G   35G  82% /sybase
sdg
vgextend vg_data /dev/sdg
lvextend -L +10G  /dev/mapper/vg_data-lv_db
resize2fs /dev/mapper/vg_data-lv_db


[root@DB6 ibmrmalik]# vgs vg_app
  VG     #PV #LV #SN Attr   VSize  VFree
  vg_app   2   2   0 wz--n- 90.99g 7.49g

[root@DB6 ibmrmalik]# vgs vg_data
  VG      #PV #LV #SN Attr   VSize   VFree
  vg_data   1   1   0 wz--n- 201.00g 1020.00m




1-337506961	sev3
Summary: Processor_load_is_too_high_on_WINT331[PROBLEM:1953386] Date: May 8,2018 3:1 CUT Severity: Minor ResourceId: wint331 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mt5 InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 38.4 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: WINT331 NodeAlias: 10.136.0.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3715997:mt5




1-337392391	sev3
Summary: NTP_time_is_driffted_on_LBDBOQQASDB1.imzcloud.ibmammsap.local[PROBLEM:1890078] Date: May 5,2018 10:37 CUT Severity: Warning ResourceId: lbdboqqasdb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 146.24 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDBOQQASDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.56 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3703115:lbd





10.201.0.17	10.5.242.17	CI2SOL	
[root@CI2SOL ibmrmalik]# w
 11:40:40 up 185 days,  5:52,  1 user,  load average: 0.08, 0.18, 0.15
 
10.201.0.16	10.5.242.16	CI2DEVAPP
[root@CI2DEVAPP ibmrmalik]# w
 11:41:39 up 291 days, 22:49,  2 users,  load average: 0.04, 0.09, 0.08



1-337654251    1-Critical    Limited Brands, Inc. - SAP HEC-AMM    LBD
Summary: Zabbix_agent_on_LBDBODDEVApp3.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2024386] Date: May 10,2018 11:25 CUT Severity: Critical ResourceId: lbdboddevapp3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDBODDEVApp3.imzcloud.ibmammsap.local NodeAlias: 10.8.8.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3736304:lbd



1-337654221    1-Critical    Limited Brands, Inc. - SAP HEC-AMM    LBD
Summary: Zabbix_agent_on_LBDFP1PRDDB1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2024375] Date: May 10,2018 11:23 CUT Severity: Critical ResourceId: lbdfp1prddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDFP1PRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.66 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3736301:lbd



1-337656101 Limited Brands, Inc. - SAP HEC-AMM 1-Critical 
LBDPP1App00 - 10.8.8.83





10.8.8.11	LBDSD1App00 on esx a0b4hk013esx021.imzcloud.ibmammsap.local   in disconnected state

Public IP: 119.81.190.92 (Hong Kong 2)

Private IP: 10.110.230.77

root/Vgumc8Wt

Ticket 59288929  for esxi disconnected state

vim-cmd vmsvc/getallvms |grep LBDSD1App00

[LBDHKG02BCA220] LBDSD1App00/LBDSD1App00



Query 4 :- Precautions needs to be taken at the time when taking console.

Solution -- IMPORTANT Before suspended to VM must create resource utilization file..

First ssh to ESXi host where the hung VM is located. Get root password from Softlayer portal
once you logged run this command from tmp folder
/tmp # esxtop â€“b â€“d 5 -n 100 > output-perf-statistics-file.csv
This csv file will have resource utilization on the ESX host at that time.

NOTE -- Doc reviewer, Kindly add more valid points, if need to follow.


-----------------------------------------------------------------------------------------------------------------------------------------------------------

11 May

1-337687951- P1 - Limited Brands, Inc. 
Summary: Zabbix_agent_on_LBDSP1App00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2051844] Date: May 11,2018 8:21 CUT Severity: Critical ResourceId: lbdsp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDSP1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.63 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3742079:lbd

top - 17:06:07 up 319 days, 16:06,  2 users,  load average: 43.04, 42.76, 43.38
Tasks: 455 total,   1 running, 454 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.1%us,  0.4%sy,  0.0%ni, 94.7%id,  2.8%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.350G total,   31.082G used,  273.848M free,  409.141M buffers
Swap: 8191.996M total, 5087.551M used, 3104.445M free,   21.796G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
58800 sp1adm    20   0 29.6g 5.5g 5.3g D  0.0 17.5  21:10.02  16m SP1_00_DIA_W24
32323 sp1adm    20   0 29.6g 5.3g 5.2g S  0.7 17.0  31:16.91  16m SP1_00_DIA_W19
 4798 sp1adm    20   0 29.6g 4.3g 4.1g D  0.0 13.7  20:59.60  16m SP1_00_DIA_W3
64266 sp1adm    20   0 29.6g 4.7g 4.6g S  1.0 15.1  30:14.09  16m SP1_00_DIA_W0
42662 sp1adm    20   0 29.6g 3.9g 3.7g S  0.7 12.4  21:21.92  16m SP1_00_DIA_W5
63751 sp1adm    20   0 29.6g 4.4g 4.2g S  1.0 14.0  42:02.40  16m SP1_00_DIA_W16
59428 sp1adm    20   0 29.6g 3.9g 3.7g D  0.0 12.3   7:45.33  16m SP1_00_DIA_W20
48752 sp1adm    20   0 29.6g 3.4g 3.3g S  0.0 11.0  14:38.57  16m SP1_00_DIA_W4
62198 sp1adm    20   0 29.6g 4.8g 4.7g D  0.0 15.4  57:43.47  16m SP1_00_DIA_W18
 6353 sp1adm    20   0 29.6g 4.4g 4.3g S  0.3 14.1  18:46.67  16m SP1_00_DIA_W9
17476 sp1adm    20   0 29.6g 4.8g 4.7g S  1.0 15.4  14:51.53  16m SP1_00_DIA_W1
21699 sp1adm    20   0 29.6g 2.9g 2.8g S  0.0  9.4  28:08.94  16m SP1_00_DIA_W14
61793 sp1adm    20   0 29.5g 3.4g 3.3g S  0.0 10.8  10:45.44  16m SP1_00_DIA_W21
61872 sp1adm    20   0 29.5g 3.4g 3.3g S  0.0 10.9  11:29.62  16m SP1_00_DIA_W17
44093 sp1adm    20   0 29.5g 3.9g 3.7g S  0.0 12.3  11:43.85  16m SP1_00_DIA_W22
26450 sp1adm    20   0 29.5g 3.1g 3.0g S  0.0  9.9   5:33.17  16m SP1_00_DIA_W15
52977 sp1adm    20   0 29.5g 3.8g 3.7g S  1.3 12.1  12:24.50  16m SP1_00_DIA_W23

[root@LBDSP1App00 ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  23409) is running...
[root@LBDSP1App00 ~]# uptime
 17:06:58 up 319 days, 16:06,  2 users,  load average: 42.42, 42.65, 43.31





1-337362171	sev3
Summary: NTP_time_is_driffted_on_LBDFP1PRDDB1.imzcloud.ibmammsap.local[PROBLEM:1867487] Date: May 4,2018 10:27 CUT Severity: Warning ResourceId: lbdfp1prddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 96.28 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDFP1PRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.66 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3699989:lbd





1-337653401 ---> To add additional disk for the VM		sev2	Paris
We are in process to extend swap size on CI3 Linux application servers, BOP  is pending because there is no any free disk available to extend swap on CI3BOPRD server, so need to add 64 GB LUN.
VM in scope: CI3BOPRD	10.210.1.25

[root@CI3BOPRD ibmrmalik]# cat /etc/fstab |grep -i swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0

0
[root@CI3BOPRD ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   1   7   0 wz--n- 39.51g 2.50g

 --- Logical volume ---
  LV Path                /dev/VolGroup/lv_swap
  LV Name                lv_swap
  VG Name                VolGroup
  LV UUID                cZlo9J-1WfI-yMi3-zHn1-9mRY-YOC6-4TMYgR
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2016-03-17 13:30:30 +0200
  LV Status              available
  # open                 1
  LV Size                8.00 GiB
  Current LE             2048
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           253:1

sdg                                  8:96   0   56G  0 disk

vgextend VolGroup /dev/sdg





1-337579961	sev3
Summary: NTP_time_is_driffted_on_LBDPP1App00.imzcloud.ibmammsap.local[PROBLEM:1984371] Date: May 9,2018 11:8 CUT Severity: Warning ResourceId: lbdpp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: 78.7 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: LBDPP1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.83 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3724506:lbd





1-337265541	sev3
Summary: NTP_time_is_driffted_on_DLBPECAP01.imzcloud.ibmammsap.local[PROBLEM:1830744] Date: May 2,2018 12:19 CUT Severity: Warning ResourceId: dlbpecap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.01 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: DLBPECAP01.imzcloud.ibmammsap.local NodeAlias: 10.13.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3692102:dlb




1-337695371  IBM AMM Infrastructure






1-337495705    sev3
11 May 2018,  05	:30 AM to 09:30 AM PDT - 4 Hrs
6pm to 10pm
Restart IAAS Non-Prod server for windows security patching activity.

1- Customer will stop application  on  all servers and  will  update us through mail.
2- OS performer  can restart  all  vms  to  auto update the  DS agent version to 10.0.0.2649
3-  After  windows  OS back  online,verify the DS agent version
4- Inform the customer  after  all VM reboot activity complete.



1-337660301	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/DAA[PROBLEM:2029558] Date: May 10,2018 14:22 CUT Severity: Critical ResourceId: lbdtw1app00 TicketGroup: ApsSAPTechnical CustomerCode: lbd InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/DAA InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: LBDTW1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/DAA AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3737025:lbd

[root@LBDTW1App00 ~]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/tw1appvg-usrsapdaa_lv
                      4.0G  4.0G     0 100% /usr/sap/DAA

[root@LBDTW1App00 DAA]# find . -xdev -type f -size +500000
./SYS/exe/jvm/linuxx86_64/sapjvm_6.1.079/sapjvm_6/jre/lib/amd64/server/libjvm.so
./SMDA98/SMDAgent_vhlbitw1ci/core.56971
./SMDA98/SMDAgent_vhlbitw1ci/core.54046
./SMDA98/SMDAgent_vhlbitw1ci/core.51821
./SMDA98/SMDAgent_vhlbitw1ci/core.35497
./SMDA98/work/jvm_smdagent_vhlbitw1ci.out
./SMDA98/exe/sapjvm_6/jre/lib/amd64/server/libjvm.so




1-337656751	sev1
Summary: Zabbix_agent_on_LBDPP1App01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2028754] Date: May 10,2018 13:35 CUT Severity: Critical ResourceId: lbdpp1app01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDPP1App01.imzcloud.ibmammsap.local NodeAlias: 10.8.8.84 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3736835:lbd





1-337656641
Summary: Sybase Status: Date: 05/10/2018 Severity: Critical ResourceId: lbdboqqasdb1 TicketGroup: ApsSAPTechnical CustomerCode: lbd InstanceId: BOQ:: InstanceSituation: Sybase Server Status ComponentType: Database Component: Sybase SubComponent: Status ApplId: SYBASE MsgId: SYBASETSA001E Node: lbdboqqasdb1 NodeAlias: 10.8.8.56 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: hec_svrstat_goyf_sapsyb_nprd AlertGroup: ITM_Sybase_Server_Summary EventKey: USRD0P0MSDP:3736808:lbd




1-337656101	sev1
Summary: Zabbix_agent_on_LBDTW1App00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2028169] Date: May 10,2018 12:53 CUT Severity: Critical ResourceId: lbdtw1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDTW1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3736609:lbd




1-337704431	sev1
Summary: Zabbix_agent_on_LBDFP1PRDDB1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2058717] Date: May 11,2018 13:57 CUT Severity: Critical ResourceId: lbdfp1prddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDFP1PRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.66 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3742876:lbd


[root@LBDFP1PRDDB1 ~]# uptime
 10:26:29 up 48 days,  3:09,  1 user,  load average: 6.67, 11.22, 12.23

[root@LBDFP1PRDDB1 ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9591) is running...


top - 10:27:09 up 48 days,  3:09,  1 user,  load average: 5.56, 10.37, 11.89
Tasks: 327 total,   1 running, 326 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.4%us,  0.2%sy,  0.0%ni, 64.2%id, 34.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.909G total,   33.590G used,   29.319G free, 2391.605M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   19.812G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
34217 sybfp1    20   0 59.5g  14g  14g S  7.6 22.9   3524:17 dataserver
55891 root      20   0  640m  78m 9356 S  2.7  0.1 225:42.95 BESClient
   89 root      20   0     0    0    0 S  0.7  0.0  29:17.61 kblockd/7
14087 nobody    20   0 80096 7020 5108 S  0.3  0.0   0:00.27 BESClient
14088 root      20   0 15160 1436  948 R  0.3  0.0   0:00.05 top
62377 daaadm    20   0 5159m 444m  18m S  0.3  0.7  89:51.94 jstart




1-336676271	sev1
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1506361] Date: Apr 14,2018 9:44 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3630595:jud


----------------------------------------------------------------------------------------------------------------------------------------

14 May


1-337764011: 
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2109632] Date: May 14,2018 2:31 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3752385:jud



1-337654131	sev2
Summary: NTP_time_is_driffted_on_LBDFQ1App01.imzcloud.ibmammsap.local[PROBLEM:2024259] Date: May 10



1-337674371	sev2
Summary: NTP_time_is_driffted_on_LBDCD1App00.imzcloud.ibmammsap.local[PROBLEM:2041027] Date: May 10
Summary: NTP_time_is_driffted_on_LBDCD1App00.imzcloud.ibmammsap.local[PROBLEM:2041027] Date: May 10,2018 21:14 CUT Severity: Major ResourceId: lbdcd1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: -13.97 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: LBDCD1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.18 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3739482:lbd




1-337710791 	sev2	
Summary: Free_disk_space_is_less_than_10%_on_volume_/tmp[PROBLEM:2062539] Date: May 11,2018 16:56 CUT Severity: Major ResourceId: lbdsd1app00 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_OS_Linux:Free_disk_space_on_/tmp_(percentage) InstanceValue: 9.99 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_disk_space_on_/tmp_(percent Node: LBDSD1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_disk_space_on_/tmp_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3743686:lbd




1-337452221	sev2
DF is getting hung ( some times intermittent ) on following servers. Please check.
smslddevdl0     10.78.22.21
smgwuatuq3      10.78.26.11 
smgwquaqq1      10.78.24.14
smgwdevdq1      10.78.22.13
smdsquaqo1q71   10.78.24.27




1-337760711    2-Urgent    IBM AMM Infrastructure    Summary: Low_space_available_on_datastore_PL2FRA02BCB57
1-337760721    2-Urgent    IBM AMM Infrastructure    Summary: Low_space_available_on_datastore_PL2FRA02BCB57




59291145

CASE 02097964
Blue dump on the console and server inaccessible
Red Hat Enterprise Linux 6.7
Filed on May 14 2018 01:02:46 AM -07:00 by Andy Wu
Assigned to New Case Queue


10.8.8.11	LBDSD1App00 on esx a0b4hk013esx021.imzcloud.ibmammsap.local   in disconnected state

Public IP: 119.81.190.92 (Hong Kong 2)

Private IP: 10.110.230.77

root/Vgumc8Wt

Ticket 59288929  for esxi disconnected state

vim-cmd vmsvc/getallvms |grep LBDSD1App00

IPMI root/Savdwpjxr2

[LBDHKG02BCA220] LBDSD1App00/LBDSD1App00




1-337660711	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var[PROBLEM:2030229] Date: May 10,2018 15:6 CUT Severity: Major ResourceId: fbtprdhanapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 7.81 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: fbtprdhanapp1.imzcloud.ibmammsap.local NodeAlias: 10.4.27.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3737217:fbt



1-337750901	sev2
Summary: Processor_load_is_too_high_on_CI3S4HANAPRDA.imzcloud.ibmammsap.local[PROBLEM:2097575] Date: May 13,2018 8:24 CUT Severity: Major ResourceId: ci3s4hanaprda TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ci3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.638437 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: CI3S4HANAPRDA.imzcloud.ibmammsap.local NodeAlias: 10.210.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3749565:ci3

---------------------------------------------------------------------------------------------------------------------------------------------------

15 May

10.8.8.15

Master ticket for LBD Master sr# 1-337793251
1-337794141	limited brands master ticket	sev1
Summary: Zabbix_agent_on_LBDSD1App01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2130641] Date: May 14,2018 21:26 CUT Severity: Critical ResourceId: lbdsd1app01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: lbd InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: LBDSD1App01.imzcloud.ibmammsap.local NodeAlias: 10.8.8.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3756164:lbd




1-337775371 sev2	
Summary: Processor_load_is_too_high_on_IA1S4HPRDAPP.imzcloud.ibmammsap.local[PROBLEM:2114783] Date: May 14,2018 10:26 CUT Severity: Major ResourceId: ia1s4hprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.9175 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1S4HPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3753619:ia1




1-337776321    Suncor Energy Inc. (SNC)    2-Urgent 
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/tmp[PROBLEM:2116516] Date: May 14,2018 12:31 CUT Severity: Major ResourceId: snchdijpa12 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 7.89 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: snchdijpa12.imzcloud.ibmammsap.local NodeAlias: 10.73.10.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3754163:snc





1-337774128    Manchester City Airport Group - SAP HEC-AMM    2-Urgent
Customer: MANCHESTER AIRPORT PLC
Reported by: SUPPORT BASIS
Phone:+44 (8703660742)
E-Mail:shonali.kellogg@capgemini.com
Priority:2: High
SAP Incident Number:242099/2018


Description:
Reconstruction
05/14/2018   04:01:08   S0014339176

Because of this BW prod system PC's are failing.
____________________
Business Consequences
05/14/2018   04:01:07   S0014339176

Because of this BW prod system PC's are failing.
____________________
Description
05/14/2018   04:01:06   S0014339176

Hi Team,
 
Currently we are getting BP1 to X39 RFC connection failed issue. Could
you please check and  let us, if Pod SAPRouter (which is existing in
WP1 server )is worki





1-337785181    IBM AMM Infrastructure    2-Urgent
Summary: Processor_load_is_too_high_on_hkg02ammsol01.imzcloud.ibmammsap.local[PROBLEM:2120711] Date: May 14,2018 15:15 CUT Severity: Major ResourceId: hkg02ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 3.11125 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: hkg02ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.141.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3754833:amm



1-337782671    IBM AMM Infrastructure    2-Urgent
Summary: Processor_load_is_too_high_on_sng01ammsol01.imzcloud.ibmammsap.local[PROBLEM:2121020] Date: May 14,2018 15:34 CUT Severity: Major ResourceId: sng01ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 0.865 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: sng01ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.157 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3755070:amm





1-337779421    DEGASA S.A. de C.V. (DG1)    2-Urgent
Summary: Lack_of_free_swap_space_on_DG1erpslmdg.imzcloud.ibmammsap.local[PROBLEM:2119292] Date: May 14,2018 13:26 CUT Severity: Major ResourceId: dg1erpslmdg TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dg1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 47.95 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: DG1erpslmdg.imzcloud.ibmammsap.local NodeAlias: 10.143.30.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3754324:dg1

[root@DG1erpslmdg ~]# free -g
             total       used       free     shared    buffers     cached
Mem:            23         20          2         11          0         11
-/+ buffers/cache:          8         14
Swap:            7          5          2


top - 22:38:35 up 3 days, 16:24,  1 user,  load average: 0.00, 0.02, 0.00
Tasks: 439 total,   1 running, 437 sleeping,   0 stopped,   1 zombie
Cpu(s):  0.3%us,  0.4%sy,  0.0%ni, 99.2%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    23.451G total,   20.671G used, 2846.730M free,  246.801M buffers
Swap: 8191.996M total, 5778.156M used, 2413.840M free,   11.538G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 85686 smaadm    20   0  878m  28m 1596 S  0.0  0.1   0:30.68 4504 igspw_mt
  9050 sapadm    20   0  708m  36m 3500 S  0.0  0.2   4:11.51 3228 sapstartsrv
 85687 smaadm    20   0  878m  31m 1592 S  0.0  0.1   0:30.77 2052 igspw_mt





1-337708881    COTY Inc (CTU)    1-Critical
Summary: Zabbix_agent_on_CTUBWQB1AP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2061845] Date: May 11,2018 16:8 CUT Severity: Critical ResourceId: ctubwqb1ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBWQB1AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3743422:ctu


1-337669171    COTY Inc (CTU)    1-Critical
Summary: Zabbix_agent_on_CTUBWPB0AP01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2038599] Date: May 10,2018 17:48 CUT Severity: Critical ResourceId: ctubwpb0ap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBWPB0AP01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3738487:ctu



1-337608531    COTY Inc (CTU)    1-Critical   transferred to SAP



1-337794121 	SEV3
Summary: Free_disk_space_is_less_than_20%_on_volume_C:[PROBLEM:2130636] Date: May 14,2018 21:25 CUT Severity: Minor ResourceId: dlthsbbsi02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: InstanceValue: 19.92 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Free_disk_space_on_OS_filesystem Node: DLTHSBBSI02 NodeAlias: 10.4.5.27 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Free_disk_space_on_OS_filesystem_C: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3756158:dal



1-337631361	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/DR1[PROBLEM:2004229] Date: May 10,2018 2:49 CUT Severity: Minor ResourceId: juddtrans01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: jud InstanceId: Zabbix-Template_OS_Linux:Free_disk_space_on_/usr/sap/DR1_(percentage) InstanceValue: 20 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_disk_space_on_/usr/sap/DR1_ Node: juddtrans01.imzcloud.ibmammsap.local NodeAlias: 10.196.4.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_disk_space_on_/usr/sap/DR1_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3734385:jud

[root@juddtrans01 ibmrmalik]# df -h /usr/sap/DR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/dr1appvg-dr1usrDR1_lv
                       25G   19G  4.6G  81% /usr/sap/DR1

[root@juddtrans01 DR1]# find . -xdev -type f -size +1000000
./SUM/abap/data/R-75004INSAPUI.SAP
./SUM/abap/log/SAPI-102AGINPOASBC.DR1
./SUM/abap/log/SAPI-75004INSAPUI.DR1
./SUM/abap/log/SAPI-V11AGINGRCFNDA.DR1




1-337480471    Shiseido Co. Ltd    1-Critical
Summary: Zabbix_agent_on_IC99SAZJ3.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1941427] Date: May 4,2018 21:53 CUT Severity: Critical ResourceId: ic99sazj3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ssd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IC99SAZJ3.imzcloud.ibmammsap.local NodeAlias: 66.248.237.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3701575:ssd




1-337792661	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:2130631] Date: May 14,2018 21:24 CUT Severity: Minor ResourceId: snchtrida11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 19.85 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: snchtrida11.imzcloud.ibmammsap.local NodeAlias: 10.73.11.136 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3756156:snc



1-337644521	sev3
Summary: FS_is_read_only_on_CLDPROAPPP1.imzcloud.ibmammsap.local[PROBLEM:2007016] Date: May 10,2018 7:6 CUT Severity: Minor ResourceId: cldproappp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /usr/interfaces/SAP_to_ARIBA filesystems are read-onl ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: CLDPROAPPP1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.75 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3735426:sm5

[root@CLDPROAPPP1 ibmrmalik]# cat /etc/fstab |grep /usr/interfaces/SAP_to_ARIBA
CLDERPAPPP1:/usr/interfaces/SAP_to_ARIBA        /usr/interfaces/SAP_to_ARIBA   nfs       defaults        0 0
10.168.1.71:/usr/interfaces/SAP_to_ARIBA        /usr/interfaces/SAP_to_ARIBA   nfs       defaults        0 0





1-337802331 / DLB / SEV2 / Siebel / Not validated / Summary: Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local[PROBLEM:2136747] Date: May 15,2018 4:29 CUT Severity: Major ResourceId: dlbpecap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.3475 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: DLBPECAP01.imzcloud.ibmammsap.local NodeAlias: 10.13.1.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3757371:dlb

top - 11:18:10 up 332 days, 22:11,  2 users,  load average: 2.09, 1.87, 1.88
Tasks: 396 total,   6 running, 390 sleeping,   0 stopped,   0 zombie
Cpu(s): 77.3%us,  1.1%sy,  0.0%ni, 21.4%id,  0.0%wa,  0.0%hi,  0.3%si,  0.0%st
Mem:    62.901G total,   57.746G used, 5278.660M free, 2092.738M buffers
Swap: 8191.996M total,  155.266M used, 8036.730M free,   38.711G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 40486 pecadm    20   0 49.9g  17g  17g R 98.4 27.8 161:42.56 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
103521 pecadm    20   0 49.9g 7.1g 7.0g R 91.8 11.4   3:57.70 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
  1645 pecadm    20   0 50.7g 2.2g 1.2g R 53.7  3.5   2996:34 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
 12227 pecadm    20   0 50.5g 2.0g 1.1g R 42.1  3.1 303:42.30 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01





1-337800661    IBM AMM Infrastructure    2-Urgent    AMM-DELIVERY-TECH
Summary: Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local[PROBLEM:2135996] Date: May 15,2018 3:24 CUT Severity: Major ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.93875 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3757144:amm




1-337797611    IBM AoD Business Systems    2-Urgent    AMM-DELIVERY-TECH
Summary: Free_disk_space_is_less_than_10%_on_volume_S:[PROBLEM:2133660] Date: May 14,2018 23:43 CUT Severity: Major ResourceId: ri3pa046 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_S: InstanceValue: 10 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_WIN SubComponent: Free_disk_space_on_SAP_filesyste Node: AMMDAL09VCS001 NodeAlias: 146.89.140.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_WIN:Free_disk_space_on_SAP_filesystem_S: AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3756567:ibs





1-337804031
LONMAGSLM0003	10.69.0.70 London
sybase/SPA/sapdiag	
[root@LONMAGSLM0003 ibmrmalik]# df -h /sybase/SPA/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/spalogvg-spasybdiag_lv
                      5.0G  4.3G  466M  91% /sybase/SPA/sapdiag

[root@LONMAGSLM0003 ibmrmalik]# vgs spalogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  spalogvg   1   4   0 wz--n- 32.00g 1020.00m

sdf

vgextend spalogvg /dev/sdf

lvextend -L +11G /dev/mapper/spalogvg-spasybdiag_lv
resize2fs /dev/mapper/spalogvg-spasybdiag_lv

[root@LONMAGSLM0003 ibmrmalik]# df -h /sybase/SPA/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/spalogvg-spasybdiag_lv
                       16G  4.3G   11G  29% /sybase/SPA/sapdiag

-------------------------------------------------------------------------------------------------------------------------------------------------------------------

16 April


1-337830841    IBM AMM Infrastructure    1-Critical    AMM-DELIVERY-TECH
Summary: Zabbix_agent_on_sng01ammtsm001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2151896] Date: May 15,2018 23:9 CUT Severity: Critical ResourceId: sng01ammtsm001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: sng01ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.140.178 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3760534:amm



1-337377481    COTY Inc (CTU)    1-Critical
Summary: Zabbix_agent_on_CTUBOPR0AP02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1874851] Date: May 4,2018 20:38 CUT Severity: Critical ResourceId: ctubopr0ap02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOPR0AP02.imzcloud.ibmammsap.local NodeAlias: 10.12.10.34 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3701308:ctu




1-336909011    PEPSICO INC (PEP)    1-Critical  
Summary: Zabbix_agent_on_PEPSAPGGDDI01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1602888] Date: Apr 20,2018 19:39 CUT Severity: Critical ResourceId: pepsapggddi01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PEPSAPGGDDI01.imzcloud.ibmammsap.local NodeAlias: 100.126.32.65 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3654215:pep



1-336896611    PEPSICO INC (PEP)    1-Critical
Summary: Zabbix_agent_on_PEPSAPGGDDI00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:1599545] Date: Apr 20,2018 15:8 CUT Severity: Critical ResourceId: pepsapggddi00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PEPSAPGGDDI00.imzcloud.ibmammsap.local NodeAlias: 100.126.32.64 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3653496:pep



1-337831841    Misr ltalia    2-Urgent    AMM-DELIVERY-TECH
Summary: Lack_of_free_swap_space_on_S4WD-PRD.imzcloud.ibmammsap.local[PROBLEM:2151836] Date: May 15,2018 23:1 CUT Severity: Major ResourceId: s4wd-prd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mi4 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.73 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: S4WD-PRD.imzcloud.ibmammsap.local NodeAlias: 10.71.6.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3760523:mi4

[root@S4WD-PRD ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:             7          7          0          1          0          1
-/+ buffers/cache:          5          2
Swap:           13          7          6

top - 04:36:37 up 60 days,  7:04,  1 user,  load average: 0.01, 0.25, 0.28
Tasks: 194 total,   1 running, 193 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.7%us,  1.8%sy,  0.0%ni, 95.3%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7865.590M total, 7421.340M used,  444.250M free,   26.363M buffers
Swap:   13.766G total, 7352.422M used, 6743.574M free, 1806.039M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
53722 gwpadm    20   0 1427m  12m 1452 S  0.0  0.2   8:46.46 782m en.sapGWP_ASCS0
16331 root      20   0 4459m 2.4g 3552 S  0.0 31.7  55:23.79 352m python
55268 gwpadm    20   0 1665m  12m 6264 S  0.0  0.2   1:27.83 117m icman




1-337830391    IAG GBS Limited (IA1)    2-Urgent    AMM-DELIVERY-TECH
Summary: Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:2150981] Date: May 15,2018 21:28 CUT Severity: Major ResourceId: ia1nfsprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.06 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1NFSPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.25 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3760281:ia1



1-337830191    I.S. Sklavenitis S.A    2-Urgent    AMM-DELIVERY-TECH
Summary: Processor_load_is_too_high_on_SK3CARAPPRD02.imzcloud.ibmammsap.local[PROBLEM:2150147] Date: May 15,2018 20:21 CUT Severity: Major ResourceId: sk3carapprd02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sk3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.63125 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SK3CARAPPRD02.imzcloud.ibmammsap.local NodeAlias: 10.5.241.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3759967:sk3




1-337654631	sev2
Summary: Processor_load_is_too_high_on_YHIEQS01.imzcloud.ibmammsap.local[PROBLEM:2026087] Date: May 10,2018 11:54 CUT Severity: Major ResourceId: yhieqs01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: yhi InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 4.31 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: YHIEQS01.imzcloud.ibmammsap.local NodeAlias: 10.6.4.205 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3736402:yhi






1-337750731	sev2
Summary: Lack_of_free_swap_space_on_YHIBWDS01.imzcloud.ibmammsap.local[PROBLEM:2096994] Date: May 13,2018 7:27 CUT Severity: Major ResourceId: yhibwds01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: yhi InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 50 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: YHIBWDS01.imzcloud.ibmammsap.local NodeAlias: 10.6.4.202 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3749475:yhi


[root@YHIBWDS01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          6          0          8
-/+ buffers/cache:          6          9
Swap:            8          4          4


top - 11:30:39 up 85 days, 17:20,  1 user,  load average: 0.05, 0.08, 0.03
Tasks: 307 total,   1 running, 306 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.9%us,  0.4%sy,  0.0%ni, 98.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.577G total,   15.136G used,  451.395M free,  676.270M buffers
Swap: 9215.996M total, 4685.141M used, 4530.855M free, 8627.152M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
23076 ywdadm    20   0 1428m  11m 2700 S  0.0  0.1   7:54.27 784m en.sapYWD_ASCS0
24724 ywdadm    20   0 1665m  31m 9592 S  0.0  0.2   2:44.80 101m icman




1-337826851	sev2
Summary: Processor_load_is_too_high_on_snchecapa11.imzcloud.ibmammsap.local[PROBLEM:2149698] Date: May 15,2018 19:57 CUT Severity: Major ResourceId: snchecapa11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.125556 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: snchecapa11.imzcloud.ibmammsap.local NodeAlias: 10.73.10.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3759892:snc


1-337826851	sev2
top - 21:47:50 up 197 days, 11:23,  6 users,  load average: 89.86, 131.94, 178.
Tasks: 1289 total,  16 running, 1273 sleeping,   0 stopped,   0 zombie
Cpu(s): 43.8%us,  2.8%sy,  0.0%ni, 44.2%id,  8.1%wa,  0.0%hi,  1.1%si,  0.0%st
Mem:    62.901G total,   62.556G used,  353.773M free,  130.293M buffers
Swap: 8191.996M total,  197.617M used, 7994.379M free,   31.700G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 96274 pr1adm    20   0  162m  39m 7228 R 37.6  0.1   1:45.52 R3load
  5555 root      20   0     0    0    0 S 20.5  0.0  14:48.09 flush-253:20
 36748 pr1adm    20   0  162m  39m 7228 S 19.8  0.1   1:44.77 R3load
 28786 pr1adm    20   0  171m  50m 7196 S 11.9  0.1   0:08.64 R3load
 29656 pr1adm    20   0  171m  48m 7196 R 11.6  0.1   0:05.00 R3load
 28090 pr1adm    20   0  171m  50m 7204 S  9.9  0.1   0:19.28 R3load






1-337821931	sev2
Summary: SAP: MIS-SSGSA0119_MIS_00:Ins:MIS: an alert of class:System occured. Lost connection to mySAP system Date: 05/15/2018 Severity: Major ResourceId: ssgsa0119 TicketGroup: ApsSAPTechnical CustomerCode: mmd InstanceId: MIS-SSGSA0119_MIS_00:Ins:Lost connection to mySAP system InstanceValue: 9900:System InstanceSituation: CCMS Alerts, System down ComponentType: Application Component: SAP SubComponent: Alert ApplId: SAP MsgId: MYSAPTSA003E Node: ssgsa0119 NodeAlias: 100.126.0.13 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_aldown_gsa2_msa_nprd AlertGroup: ITM_R3_Alerts EventKey: USRD0P0MSDP:3759388:mmd
100.126.0.13




1-335887868	sev3
Due ot lack of Swap space, it needs to be increased on SSGSA0121. Refer to PEM alert 1-335423581. Also refer to other servers at end of ticket

As per Hosoya san, Installation Guide: AS ABAP of NW 7.3 to 7.5 on UNIX: SAP ASE mentions the below:

Hardware Requirements
https://help.sap.com/viewer/e345db692e3c43928199d701df58c0d8/CURRENT_VERSION/en-US/526e0e40a177492198d44419db83c817.html


1597355 - Swap-space recommendation for Linux


2 x RAM (16GB) = 32GB

Please secure at least 32 GB swap space.
It is a general size in the SAP environment.


Please refer to this recommendation when making adjustments. If extra disk space is needed, let us know. I understand that no downtime is needed. Please inform janakip@au1.ibm.com on the next step. 

Once all tasks are  completed, please send email 
TO: janakip@au1.ibm.com, YUUTA@jp.ibm.com, 
CC: MATSUZAK@jp.ibm.com, TASHIRO@jp.ibm.com,

From Janaki on 16th May, 2018.

Other systems for which SWAP SPACE is required and new disk needs to be added to server.

1. SSGSA0121 ( Linux) - 24 gb Swap space to added ( > DISK ADDED - 36 gb avail.now)
2. SSGSA0119 ( Linux)- 24 gb  Swap space to be added.	sdh
vgextend VolGroup /dev/sdh


3. SSGSA0120 (Windows) -  gb Swap space to be added
4. SSGSA0122 ( Linux) - 24 gb Swap space to be added
sdh



1-337841791  -  P1  -  Limited Brands, Inc. - SAP HEC-AMM  -  @rmalik
Summary: Zabbix_agent_on_LBDBP1App00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2156385] Date: May 16,2018 6:41 CUT Severity: Critical ResourceId: lbdbp1app00
Summary: Zabbix_agent_on_LBDBP1App00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2156385] Date: May 16,2018 6:41 CUT Severity: Critical ResourceId: lbdbp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDBP1App00.imzcloud.ibmammsap.local NodeAlias: 10.8.8.77 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3761536:lbd

------------------------------------------------------------------------------------------------------------------------------------

17 May



1-337657913    OS side check on the call   sev3
P3:Allow access to IPL servers




1-337850064    AGEAS - SAP HEC-AMM    2-Urgent
Customer:  Ageas B.V.
Reported by: Abhishek Mohapatra
Phone:  +31 302525304
E-Mail: abhisek.mohapatra@msg-global.com
Priority: 2: High
SAP Incident Number: 0247709/2018


Description:

Reconstruction
05/16/2018   04:30:47   S0019242479

Server restart
____________________
Business Consequences
05/16/2018   04:30:46   S0019242479

High
____________________
Description
05/16/2018   04:30:45   S0019242479

Hi Team, Kindly restart the JQ1 FS-QUO server as we are getting
runtime exception while RFC calls to FSPM.   Environment to restart -
JQ1 FS-QUO Time to restart: 05162018 5:30pm PHT   IPW Link: 
https://svwd1srv0.eastwestageaslife.com:11043/sap/bc/ui5_ui5/ui2/ushell/
shells/abap/FioriLaunchpad.html  

Regards, 
Abhisek




1-337844781    PEPSICO INC (PEP)    2-Urgent
Summary: ITM Agent Offline: pepsapgwqdi00:INTERNET00 Date: 05/16/2018 Severity: Major ResourceId: pepsapgwqdi00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: pepsapgwqdi00:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: pepsapgwqdi00 NodeAlias: 100.126.32.115 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3761883:pep

1-337844721    PEPSICO INC (PEP)    2-Urgent
Summary: ITM Agent Offline: pepsapgwqdi00:UA Date: 05/16/2018 Severity: Major ResourceId: pepsapgwqdi00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pep InstanceId: REMOTE_fmsprdrtem001 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: pepsapgwqdi00 NodeAlias: 100.126.32.115 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3761849:pep



1-337847181	sev3
Please unlock OS user ID below 
user: aldadm
Hostname:ADNAELDEVDB	10.198.201.18 SIngapore
IP:10.182.201.18




1-337856141   SSGSA0122 	100.126.0.16 SIngapore add 5 GB to fs 
/dev/mapper/mnplogvg-mnpsyblog1_lv
                       22G   21G  377M  99% /sybase/MNP/saplog1


[root@SSGSA0122 ~]# df -h /sybase/MNP/saplog1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/mnplogvg-mnpsyblog1_lv
                       27G   21G  5.1G  81% /sybase/MNP/saplog1

add 5GB

vgextend mnplogvg /dev/sdi

lvextend -L +5G /dev/mapper/mnplogvg-mnpsyblog1_lv
resize2fs /dev/mapper/mnplogvg-mnpsyblog1_lv


Summary: MSD:URL: URL Status: URI authority not found Date: 05/16/2018 Severity: Major ResourceId: ssgsa0122 TicketGroup: ApsSAPTechnical CustomerCode: mmd InstanceId: URI authority not found[http://ssgsa0122:51000/sld] InstanceValue: http://ssgsa0122:51000/sld InstanceSituation: URL Status - Generic URL ComponentType: Application Component: URL SubComponent: URL ApplId: URL Node: SSGSA0122 NodeAlias: SSGSA0122 Manager: SSGSA0122 Agent: EIF Probe on ri3pa010 AlertKey: msd_urldown_gumc_msa_nprd AlertGroup: ITM_INTERNETMANAGED_URL00 EventKey: USRD0P0MSDP:3762522:mmd




1-337873331 - Sev1 - IBM AMM Infrastructure - Siebel- Not Validated - Summary: Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2181506] Date: May 17,2018 3:49 CUT Severity: Critical ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3765767:amm




1-337764011	sev1
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2109632] Date: May 14,2018 2:31 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3752385:jud




1-337873841 - Sev1 - CTU - SAP HEC-AMM - Siebel - Not Validated - Summary: Zabbix_agent_on_CTUBOPR0APL2.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_CTUBOPR0APL2.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2182427] Date: May 17,2018 5:24 CUT Severity: Critical ResourceId: ctubopr0apl2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CTUBOPR0APL2.imzcloud.ibmammsap.local NodeAlias: 10.12.10.38 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3766153:ctu



---------------------------------------------------------------------------------------------------------------------------

20 May

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/RedHat%20Satellite%20infra%20%26%20Chef%20recipe



1-337985501    1-Critical    St Jude Medical  Dallas - SAP HEC    Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2239755] Date: May 20,2018 0:55 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3781836:jud


1-337986971    1-Critical    Fitbit, Inc. - SAP HEC-AMM    Summary: Zabbix_agent_on_fbtprdbwapp2.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_fbtprdbwapp2.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2240465] Date: May 20,2018 2:11 CUT Severity: Critical ResourceId: fbtprdbwapp2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: fbtprdbwapp2.imzcloud.ibmammsap.local NodeAlias: 10.4.27.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3782141:fbt


1-337987681    1-Critical    MSC Industrial Supply Co.    Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2240672] Date: May 20,2018 2:33 CUT Severity: Critical ResourceId: ms3wdclapp01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3782251:ms3





1-336516229	sev3
AGEAS server patching change

Singapore DC

SPSVPPAOAPP01	10.6.3.24	A0EASG014XVM041	snapshot
[root@spsvppaoapp01 tmp]# date
Sun May 20 11:48:04 SGT 2018
[root@spsvppaoapp01 tmp]# uname -a
Linux spsvppaoapp01 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvppaoapp01 ~]# date;uname -a
Sun May 20 13:06:36 +08 2018
Linux spsvppaoapp01 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

----------------------------------------------------------------------------------------
SPSVSPASAPP01	10.6.3.33	A0EASG014XVM030	snapshot
[root@spsvspasapp01 tmp]# date;uname -a
Sun May 20 12:18:26 SGT 2018
Linux spsvspasapp01.eastwestageaslife.com 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvspasapp01 ibmrmalik]# date;uname -a
Sun May 20 13:05:59 +08 2018
Linux spsvspasapp01.eastwestageaslife.com 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone showing as +08
-----------------------------------------------------------------------------------
SPSVSPDSASE01	10.6.3.32	A0EASG014XVM035	snapshot
[root@spsvspdsase01 tmp]# date
Sun May 20 12:16:28 SGT 2018
[root@spsvspdsase01 tmp]# uname -a
Linux spsvspdsase01.eastwestageaslife.com 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvspdsase01 ibmrmalik]# date;uname -a
Sun May 20 13:04:24 +08 2018
Linux spsvspdsase01.eastwestageaslife.com 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone is +08
----------------------------------------------------------------------------------------------------------------
SPSVWPAWAPP12	10.6.3.31	A0EASG014XVM038	snapshot
[root@spsvwpawapp12 tmp]# date;uname -a
Sun May 20 12:20:38 SGT 2018
Linux spsvwpawapp12 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvwpawapp12 ibmrmalik]# date; uname -a
Sun May 20 13:22:30 +08 2018
Linux spsvwpawapp12 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone is +08
----------------------------------------------------------------------------------------------------------
SPSVWPAWAPP11	10.6.3.30	A0EASG014XVM037	snapshot
[root@spsvwpawapp11 tmp]# date;uname -a
Sun May 20 12:22:49 SGT 2018
Linux spsvwpawapp11.eastwestageaslife.com 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvwpawapp11 ibmrmalik]# date;uname -a
Sun May 20 13:35:10 +08 2018
Linux spsvwpawapp11.eastwestageaslife.com 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone +08
-------------------------------------------------------------------------------------------------------
SPSVEPAPAPP01	10.6.3.28	A0EASG014XVM028	snapshot
[root@spsvepapapp01 tmp]# date;uname -a
Sun May 20 12:24:45 SGT 2018
Linux spsvepapapp01 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvepapapp01 ibmrmalik]# date;uname -a
Sun May 20 13:38:41 +08 2018
Linux spsvepapapp01 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone is +08
------------------------------------------------------------------------------------------	
SPSVEPDPASE01	10.6.3.27	A0EASG014XVM034	snapshot
[root@spsvepdpase01 tmp]# date;uname -a
Sun May 20 12:26:25 SGT 2018
Linux spsvepdpase01 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvepdpase01 ibmrmalik]# date;uname -a
Sun May 20 14:00:50 +08 2018
Linux spsvepdpase01 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone +08
--------------------------------------------------------------------------------------------
SPSVPPDOASE01	10.6.3.23	A0EASG014XVM033	snapshot
[root@spsvppdoase01 tmp]# date;uname -a
Sun May 20 12:27:47 SGT 2018
Linux spsvppdoase01 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvppdoase01 ibmrmalik]# date; uname -a
Sun May 20 14:02:07 +08 2018
Linux spsvppdoase01 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated
------------------------------------------------------------------------------------------------------
SPSVBPAAAPP01	10.6.3.20	A0EASG014XVM042	snapshot
[root@spsvbpaaapp01 tmp]# sh script.sh
Warning: RPMDB altered outside of yum.
[root@spsvbpaaapp01 tmp]# date;uname -a
Sun May 20 12:29:15 +08 2018
Linux spsvbpaaapp01 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvbpaaapp01 ibmrmalik]# date;uname -a
Sun May 20 14:05:36 +08 2018
Linux spsvbpaaapp01 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone is same b4 and after patching

----------------------------------------------------------------------------
SPSVBPDAASE01	10.6.3.19	A0EASG014XVM027	snapshot
[root@spsvbpdaase01 tmp]# sh script.sh
Warning: RPMDB altered outside of yum.
[root@spsvbpdaase01 tmp]# date;uname -a
Sun May 20 12:31:04 +08 2018
Linux spsvbpdaase01 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvbpdaase01 ibmrmalik]# date;uname -a
Sun May 20 14:06:59 +08 2018
Linux spsvbpdaase01 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated timezone is same b4 and after patching
--------------------------------	
SPSVMPLMAPP01	10.6.3.46	A0EASG014XVM045	snapshot		root/BffCl1dg	Iaas 
[root@spsvmplmapp01 tmp]# date;uname -a
Sun May 20 12:31:50 SGT 2018
Linux spsvmplmapp01.eastwestageaslife.com 2.6.32-642.15.1.el6.x86_64 #1 SMP Mon Feb 20 02:26:38 EST 2017 x86_64 x86_64 x86_64 GNU/Linux

Replaced:
  jpackage-utils.noarch 0:1.7.5-3.16.el6

Complete!

[root@spsvmplmapp01 ibmrmalik]# date;uname -a
Sun May 20 14:13:20 +08 2018
Linux spsvmplmapp01.eastwestageaslife.com 2.6.32-696.23.1.el6.x86_64 #1 SMP Sat Feb 10 11:10:31 EST 2018 x86_64 x86_64 x86_64 GNU/Linux

VMtools updated but timezone is not changing
------------------------------------



1-337981651	2-Urgent	St Jude Medical  Dallas - SAP HEC	Summary: Lack_of_free_swap_space_on_juddtrans02.imzcloud.ibmammsap.local
Summary: Lack_of_free_swap_space_on_juddtrans02.imzcloud.ibmammsap.local[PROBLEM:2238966] Date: May 19,2018 23:44 CUT Severity: Major ResourceId: juddtrans02 TicketGroup: AMM-DELIVERY-TECH CustomerCode: jud InstanceId: Zabbix-Template_OS_Linux:Free_swap_space_in_% InstanceValue: 49.92 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_swap_space_in_% Node: juddtrans02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3781544:jud

[root@juddtrans02 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         30          0          7          0         16
-/+ buffers/cache:         13         17
Swap:            7          4          3

top - 05:42:07 up 162 days, 12:26,  1 user,  load average: 18.00, 17.68, 17.50
Tasks: 495 total,   1 running, 494 sleeping,   0 stopped,   0 zombie
Cpu(s): 12.4%us,  1.0%sy,  0.0%ni, 86.2%id,  0.1%wa,  0.0%hi,  0.3%si,  0.0%st
Mem:    31.349G total,   30.956G used,  403.055M free,  883.684M buffers
Swap: 8191.996M total, 4104.270M used, 4087.727M free,   16.103G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
24602 qr1adm    20   0 6016m 4.8g 1620 S  0.0 15.4 136:49.37 1.0g SAPup_real
10862 root      20   0 3819m 1.2g 7912 S  0.0  3.8 113:18.64 729m python
22831 qr1adm    20   0 1428m 470m 2436 S  7.6  1.5   4169:52 328m en.sapQR1_ASCS0
53366 qr1adm    20   0 4107m 331m 2040 S  0.3  1.0  84:45.42 106m java




1-337987191	2-Urgent	Manchester City Airport Group - SAP HEC-AMM		Summary: Free_disk_space_is_less_than_10%_on_DB_volume_/sybase/SPA/log_archive
Summary: Free_disk_space_is_less_than_10%_on_DB_volume_/sybase/SPA/log_archive[PROBLEM:2240346] Date: May 20,2018 2:0 CUT Severity: Major ResourceId: lonmagslm0003 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/SPA/log_archive InstanceValue: 9.89 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: LONMAGSLM0003.imzcloud.ibmammsap.local NodeAlias: 10.69.0.70 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/SPA/log_archive AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3782082:mng

[root@LONMAGSLM0003 ibmrmalik]# df -h /sybase/SPA/log_archive
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/spaarchvg-spalogarch_lv
                       50G   41G  5.9G  88% /sybase/SPA/log_archive

[root@LONMAGSLM0003 log_archive]# find . -xdev -type f -size +1000000
./SPA/SPA_TRAN_BK_20180518_1000
./SPA/SPA_TRAN_BK_20180519_1100
./SPA/SPA_TRAN_BK_20180518_0100
./SPA/SPA_TRAN_BK_20180517_0600
./SPA/SPA_TRAN_BK_20180519_0400
./SPA/SPA_TRAN_BK_20180517_1400
./SPA/SPA_TRAN_BK_20180518_1900
./SPA/SPA_TRAN_BK_20180519_1900
./SPA/SPA_TRAN_BK_20180518_1500
./SPA/SPA_TRAN_BK_20180519_1500
./SPA/SPA_TRAN_BK_20180519_1700
./SPA/SPA_TRAN_BK_20180517_1700
./SPA/SPA_TRAN_BK_20180517_0500
./SPA/SPA_TRAN_BK_20180519_1800
./SPA/SPA_TRAN_BK_20180520_0200
./SPA/SPA_TRAN_BK_20180518_0900
./SPA/SPA_TRAN_BK_20180520_0100
./SPA/SPA_TRAN_BK_20180520_0000





1-337870509    3-Standard    SMRT Corp - SAP HEC-AMM        P2:Crontab to be disabled on EP1 CLDERPAPPP
P2:Crontab to be disabled on EP1 CLDERPAPPP [0000248797/2018]
Customer: SMRT Corporation Ltd
Reported by: Uma Maheshwar Dev Bontala
Phone:+65 (6554) 8535
E-Mail:umamaheshwar@smrt.com.sg
Priority:2: High
SAP Incident Number:0000248797/2018


Description:

Information for SAP
05/17/2018   01:12:07   S0016320183

Please note the timings are in SGT.
____________________
Reconstruction
05/17/2018   01:09:03   S0016320183

Please provide step-by-step instructions on how to reproduce your issue:
Step 1: Crontab to be disabled 
Step 2:
Step 3:
____________________
Business Consequences
05/17/2018   01:09:02   S0016320183

scheduled Go-Live
____________________
Description
05/17/2018   01:09:01   S0016320183

Hi Team
 
Please help to disable the crontab entries as in the below schedule.
Crontab Job Entry
Last Run Date/Time
To disable at date/time
0 7,8,9,11, 13 ,15,17,19,22 * * * /home/postman/HR/ftphrclock_cas.sh
>> /home/postman/HR/ftphrclock_cas.log 2>&1
 
18.05.2018, 13:00 hrs
18.05.2018, 13:30 hrs
0 6 * * * /home/postman/HR/ housekeeping-ftphrclock_cas.sh >/dev/null
2>&1
19.05.2018, 06:00 hrs
19.05.2018, 08:00 hrs
00 04 * * * /home/postman/HR/ hrmaximo_out.sh 2>&1
18.05.2018, 04:00 hrs
18.05.2018, 13:30 hrs
 
 
Thanks & Regards,
Uma Maheshwar Dev

(EP1)CLDERPAPPP1-10.198.0.71

[postman@CLDERPAPPP1 ~]$ crontab -l|grep -i ftphrclock_cas.log
0 7,8,9,11,13,15,17,19,22 * * * /home/postman/HR/ftphrclock_cas.sh >> /home/postman/HR/ftphrclock_cas.log 2>&1

[postman@CLDERPAPPP1 ~]$ crontab -l|grep -i housekeeping-ftphrclock_cas.sh
0 6 * * * /home/postman/HR/housekeeping-ftphrclock_cas.sh >/dev/null 2>&1

[postman@CLDERPAPPP1 ~]$ crontab -l|grep -i hrmaximo_out.sh
00 04 * * * /home/postman/HR/hrmaximo_out.sh 2>&1





1-337992501    1-Critical    MSC Industrial Supply Co.    Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2244339] Date: May 20,2018 7:1 CUT Severity: Critical ResourceId: ms3wdclapp01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3783015:ms3



1-337992021 St Jude Medical  Dallas - SAP HEC 1-Critical
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2242469] Date: May 20,2018 5:25 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3782799:jud




1-337992851    1-Critical    MSC Industrial Supply Co.    Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2245209] Date: May 20,2018 8:39 CUT Severity: Critical ResourceId: ms3wdclapp01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3783252:ms3


--------------------------------------------------------------------------------------------------------------------------

21 May


1-337989991    1-Critical    St Jude Medical  Dallas - SAP HEC    Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2244232] Date: May 20,2018 6:45 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3782993:jud




1-337991191	sev3
User ibmjchudasama root access is not working on any of the servers
Hi Team ,
ibmjchudasama root access is not working on all the IC4SAP Servers.

print screen error message provided in attachment file.
10.198.200.21	

[root@ADNABPDB ibmrmalik]# su - ibmjchudasama
[ibmjchudasama@ADNABPDB ~]$ id
uid=99696(ibmjchudasama) gid=1513(domain users) groups=1513(domain users)

[root@ADNABPDB ibmrmalik]# cat /etc/sudoers |grep ibmjchudasama
[root@ADNABPDB ibmrmalik]#




1-337839941	sev3
Summary: Processor_load_is_too_high_on_IPLSAUTLD01[PROBLEM:2156401] Date: May 16,2018 6:42 CUT Severity: Minor ResourceId: iplsautld01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ipl InstanceId: Zabbix-AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) InstanceValue: 9.45 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_WIN SubComponent: Processor_load_(1_min_average) Node: IPLSAUTLD01 NodeAlias: 10.138.2.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_WIN:Processor_load_(1_min_average) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3761539:ipl





1-337943711	sev2
Summary: Processor_load_is_too_high_on_CLDBOBIADWD1.imzcloud.ibmammsap.local[PROBLEM:2216209] Date: May 18,2018 19:58 CUT Severity: Major ResourceId: cldbobiadwd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.22 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: CLDBOBIADWD1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.209 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3776701:sm5




1-337949361	sev2
Summary: Processor_load_is_too_high_on_MGGGBJPCNTX01.imzcloud.ibmammsap.local[PROBLEM:2216907] Date: May 18,2018 21:4 CUT Severity: Major ResourceId: mgggbjpcntx01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 3.2225 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: MGGGBJPCNTX01.imzcloud.ibmammsap.local NodeAlias: 10.133.18.32 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3776944:mgg




1-337901241	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var[PROBLEM:2199697] Date: May 17,2018 20:50 CUT Severity: Major ResourceId: dlbqecap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 8.82 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DLBQECAP01.imzcloud.ibmammsap.local NodeAlias: 10.13.2.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3770519:dlb

[root@DLBQECAP01 ~]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  4.0G  579M  88% /var

[root@DLBQECAP01 log]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.0G  2.6G  44% /var




1-338006151 1-Critical    IBM AMM Infrastructure    Summary: Zabbix_agent_on_FRA02AMMSOL04.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_FRA02AMMSOL04.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2256418] Date: May 21,2018 3:45 CUT Severity: Critical ResourceId: fra02ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: FRA02AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.228 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3786114:amm
A0CXDE014XVM001

[root@FRA02AMMSOL04 ~]# uptime
 08:14:37 up 3 min,  2 users,  load average: 0.72, 0.51, 0.21
[root@FRA02AMMSOL04 ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  9139) is running...
You have mail in /var/spool/mail/root




1-337890181    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_free_swap_space_on_FRA02AMMSOL04.imzcloud.ibmammsap.local
Summary: Lack_of_free_swap_space_on_FRA02AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:2192296] Date: May 17,2018 13:47 CUT Severity: Major ResourceId: fra02ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.96 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: FRA02AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.228 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3768276:amm

[root@FRA02AMMSOL04 ~]# free -g
             total       used       free     shared    buffers     cached
Mem:            15          3         12          0          0          1
-/+ buffers/cache:          1         14
Swap:           13          0         13
You have mail in /var/spool/mail/root

top - 08:27:22 up 16 min,  1 user,  load average: 0.02, 0.10, 0.12
Tasks: 253 total,   1 running, 252 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.5%us,  0.2%sy,  0.0%ni, 99.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.579G total, 3327.047M used,   12.330G free,  128.000M buffers
Swap:   13.766G total,    0.000k used,   13.766G free, 1969.543M cached

nilesh 8793285283






1-337905957	sev3 
TO BE DONE DURING THE BELOW TIMES:	Singapore
21 May 2018 (Mon) IST 2:30 PM - 5:00 PM 
21 May 2018 (Mon) PDT 2:00 AM - 4:30 AM 
21 May 2018 (Mon) JST 6:00 PM - 8:30 PM
Fiori       (ssgsa0119) add 24 GB (Total 32GB)	100.126.0.13		Th67#4hg
WebDisp     (ssgsa0120)  - add 8GB (Total 16GB) 100.126.0.14	Windows
SolMan ABAP (ssgsa0121) - add 24GB (Total 32GB) 100.126.0.15
SolMan Java (ssgsa0122) -add 24GB (Total 32GB)   100.126.0.16
Build Plans:
a) Fiori       (ssgsa0119)	
1. Take Snapshot of Server SSGSA0119 - OS 
2. Bring Apps and Sybase DB down for SSGSA0119 - SAP
3. Increase space on SWAP file system by adding 24 gb, so the final total is 32 GB - OS
4. Do a Linux reboot to release memory, as Memory usage levels are high - OS
5. Validate OS &pProvide screenshot of Swap Space after increase - OS
6. Bring up Sybase DB and apps for SSGSA0119 - SAP

/dev/mapper/VolGroup-lv_swap 	swap                    swap    defaults        0 0


---------------------------------------------------------------------
b) WebDisp     (ssgsa0120) 	
1. Take Snapshot of Server SSGSA0120 - AMM-BUR - TSM4VEsnapshot 
2. Bring Apps down for SSGSA0120 - SAP
3. Increase space on paging file by adding 8 gb, so the final total is 16 GB - OS
4. Windows reboot  & prvde screenshot of Swap space after increase - OS
5. Bring apps up for SSGSA0120
----------------------------------------------------------------------
c) SolMan ABAP (ssgsa0121)	
1. Take Snapshot of Server ssgsa0121 - OS
2. Bring down Apps and Sybase DB for SSGSA0120 - SAP
3. Increase space on SWAP file system by adding 24 gb, so the final total is 32 GB - OS
4. Validate OS and provide screenshot of Swap space after increase - OS
5. Bring up Sybase DB and app for SSGSA0121

[root@SSGSA0121 ~]# cat /etc/fstab |grep -i swap
/dev/mapper/VolGroup-lv_swap 			swap                    swap    defaults        0 0


----------------------------------------------------------------------
d) SolMan Java (ssgsa0122)		
1. Take Snapshot of Server ssgsa0122 - OS
2. Bring down Apps and Sybase DB for ssgsa0122 - SAP
3. Increase space on SWAP file system by adding 24 gb, so the final total is 32 GB - OS
4. Validate OS and provide screenshot of Swap space after increase - OS
5. Bring up Sybase DB and apps for SSGSA0122


/dev/mapper/VolGroup-lv_swap


-------------------------------------------------------------------------------------------------------------------------------------------

22 May

1-338037131    Limited Brands, Inc. - SAP HEC-AMM    1-Critical
Summary: Free_disk_space_is_less_than_5%_on_DB_volume_/backup[PROBLEM:2266327] Date: May 21,2018 19:30 CUT Severity: Critical ResourceId: lbdmp1prddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup InstanceValue: 3.44 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: LBDMP1PRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.72 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3788952:lbd





1-338042701 - Sev1 - PNC - AMM-SAP - Siebel - Not Validated - Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local 
Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local[PROBLEM:2270323] Date: May 22,2018 2:15 CUT Severity: Critical ResourceId: c1bwp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3790024:pnc



1-338042401    IBM AMM Infrastructure    2-Urgent
Summary: Lack_of_available_memory_on_server_ammpar01custesx003.imzcloud.ibmammsap.local[PROBLEM:2269611] Date: May 22,2018 0:51 CUT Severity: Major ResourceId: ammpar01custesx003 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-Template_Virt_VMware_Hypervisor:Used_memory InstanceValue: 412.45 GB ComponentType: ZABBIX Component: Template_Virt_VMware_Hypervisor SubComponent: Used_memory Node: ammpar01custesx003.imzcloud.ibmammsap.local NodeAlias: 146.89.142.147 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_Virt_VMware_Hypervisor:Used_memory AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3789851:amm



1-338037291    Limited Brands, Inc. - SAP HEC-AMM    2-Urgent
Summary: Processor_load_is_too_high_on_LBDMP1PRDDB1.imzcloud.ibmammsap.local[PROBLEM:2266724] Date: May 21,2018 20:8 CUT Severity: Major ResourceId: lbdmp1prddb1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.19125 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LBDMP1PRDDB1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.72 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3789088:lbd




1-338033051 2-Urgent    IAG GBS Limited (IA1)
Summary: Processor_load_is_too_high_on_IA1S4HPRDAPP.imzcloud.ibmammsap.local[PROBLEM:2263478] Date: May 21,2018 15:21 CUT Severity: Major ResourceId: ia1s4hprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.9525 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1S4HPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3788174:ia1



1-338030931 - Sev2 - FBT - SAP HEC-AMM - Siebel - Not Validated - Summary: Processor_load_is_too_high_on_fbqfirapp.imzcloud.ibmammsap.local  
Summary: Processor_load_is_too_high_on_fbqfirapp.imzcloud.ibmammsap.local[PROBLEM:2263771] Date: May 21,2018 15:56 CUT Severity: Major ResourceId: fbqfirapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: fbt InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.4425 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: fbqfirapp.imzcloud.ibmammsap.local NodeAlias: 10.4.26.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3788274:fbt



1-338042641 2-Urgent  Manchester City Airport Group - SAP HEC-AMM
Summary: Free_disk_space_is_less_than_10%_on_DB_volume_/sybase/SPA/log_archive[PROBLEM:2270209] Date: May 22,2018 2:0 CUT Severity: Major ResourceId: lonmagslm0003 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/SPA/log_archive InstanceValue: 9.72 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: LONMAGSLM0003.imzcloud.ibmammsap.local NodeAlias: 10.69.0.70 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/SPA/log_archive AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3789993:mng

Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/spaarchvg-spalogarch_lv
                       50G   42G  5.7G  88% /sybase/SPA/log_archive
./SPA_TRAN_BK_20180520_1100
./SPA_TRAN_BK_20180519_1100
./SPA_TRAN_BK_20180521_0600
./SPA_TRAN_BK_20180519_0400
./SPA_TRAN_BK_20180521_2100
./SPA_TRAN_BK_20180520_2100
./SPA_TRAN_BK_20180520_2200
./SPA_TRAN_BK_20180521_1600
./SPA_TRAN_BK_20180519_1900
./SPA_TRAN_BK_20180519_1500
./SPA_TRAN_BK_20180519_1700
./SPA_TRAN_BK_20180519_1800
./SPA_TRAN_BK_20180520_0200
./SPA_TRAN_BK_20180520_0100
./SPA_TRAN_BK_20180521_1000



1-338009228
10.198.0.71

Cronjob 2, please disable on 22nd of May 2018 at 10:00AM, SGT.

(2) 0 6 * * * /home/postman/HR/housekeeping-ftphrclock_cas.sh
>/dev/null 2>&1 - disable (22.05.2018)


(1) 0 7,8,9,11,13,15,17,19,22 * * * /home/postman/HR/ftphrclock_cas.sh
>> /home/postman/HR/ftphrclock_cas.log 2>&1    - disable (21.05.2018,
15:30 hrs)

(3) 00 04 * * * /home/postman/HR/hrmaximo_out.sh 2>&1 - disable
(21.05.2018, 15:30 hrs)


[postman@CLDERPAPPP1 ~]$ crontab -l|grep -i postman/HR/ftphrclock_cas.sh
0 7,8,9,11,13,15,17,19,22 * * * /home/postman/HR/ftphrclock_cas.sh >> /home/postman/HR/ftphrclock_cas.log 2>&1
[postman@CLDERPAPPP1 ~]$ crontab -l|grep -i postman/HR/hrmaximo_out.sh
00 04 * * * /home/postman/HR/hrmaximo_out.sh 2>&1


[postman@CLDERPAPPP1 ~]$ crontab -l|grep -i postman/HR/ftphrclock_cas.sh
#0 7,8,9,11,13,15,17,19,22 * * * /home/postman/HR/ftphrclock_cas.sh >> /home/postman/HR/ftphrclock_cas.log 2>&1
[postman@CLDERPAPPP1 ~]$  crontab -l|grep -i postman/HR/hrmaximo_out.sh
#00 04 * * * /home/postman/HR/hrmaximo_out.sh 2>&1
[postman@CLDERPAPPP1 ~]$  crontab -l|grep -i /home/postman/HR/housekeeping-ftphrclock_cas.sh
#0 6 * * * /home/postman/HR/housekeeping-ftphrclock_cas.sh >/dev/null 2>&1



1-338046411  IBM AMM Infrastructure  P2
Summary: Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local[PROBLEM:2270902] Date: May 22,2018 3:7 CUT Severity: Major ResourceId: wdc04ammsol01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 6.7525 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: wdc04ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.142.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3790133:amm

[root@wdc04ammsol01 ibmrmalik]# uptime
 22:42:59 up 13 days, 13:05,  1 user,  load average: 0.13, 4.61, 12.63


top - 22:44:15 up 13 days, 13:06,  1 user,  load average: 0.07, 3.59, 11.65
Tasks: 501 total,   1 running, 500 sleeping,   0 stopped,   0 zombie
Cpu(s):  3.0%us,  3.7%sy,  0.0%ni, 93.3%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.316G total,   30.623G used,  709.492M free, 1900.172M buffers
Swap: 1023.996M total, 1023.996M used,    0.000k free,   16.279G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
16313 wsmadm    20   0 6896m  78m  32m S 44.5  0.2   0:02.02 WSM_50_DIA_W6
11943 root      20   0 5585m 769m 5028 S  2.0  2.4 145:51.69 java
13096 root      20   0  683m  72m 7832 S  2.0  0.2 392:58.79 BESClient
 2646 root      20   0  338m  28m 8776 S  1.0  0.1  20:28.07 sssd_be
12159 root      20   0 44980 7916 2616 S  1.0  0.0  12:56.13 saposcol
 5361 db2wsm    20   0 16.6g 7.8g 7.3g S  0.7 25.0 984:58.42 db2sysc



1-338012701	sev2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:2259327] Date: May 21,2018 9:17 CUT Severity: Major ResourceId: mgggbjpeccx06 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ InstanceValue: 9.9 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: MGGGBJPECCX06.imzcloud.ibmammsap.local NodeAlias: 10.133.18.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3786930:mgg

/swdeploy/hanadb
./IMDB_SERVER100_95_0-10009569.SAR
./IMC_STUDIO2_95_0-80000321.SAR
./IMDB_CLIENT100_95_0-10009663.SAR


Filesystem      Size  Used Avail Use% Mounted on
/dev/sda3        49G   42G  4.6G  91% /




1-337943911	sev2
Summary: Processor_load_is_too_high_on_LBDWD3App80.imzcloud.ibmammsap.local[PROBLEM:2216423] Date: May 18,2018 20:17 CUT Severity: Major ResourceId: lbdwd3app80 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.465 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LBDWD3App80.imzcloud.ibmammsap.local NodeAlias: 10.8.8.32 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3776774:lbd




1-337949641	sev2
Summary: Processor_load_is_too_high_on_LBDBOQQASApp3.imzcloud.ibmammsap.local[PROBLEM:2217208] Date: May 18,2018 21:37 CUT Severity: Major ResourceId: lbdboqqasapp3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.385 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LBDBOQQASApp3.imzcloud.ibmammsap.local NodeAlias: 10.8.8.59 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3777036:lbd





1-337963241	sev2
Summary: ITM Agent Offline: FP1-vhlbiFP1CI_FP1_00:Ins Date: 05/19/2018 Severity: Major ResourceId: lbdfp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: FP1-vhlbifp1d:lbdfp1app00:mySAP InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: lbdfp1app00 NodeAlias: 10.8.8.67 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3778998:lbd




1-337964061     sev2
Summary: Clea	red and Re-fired: ITM Agent Offline: FP1-vhlbifp1d:lbdfp1app00:mySAP Date: 05/19/2018 Severity: Major ResourceId: lbdfp1app00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: REMOTE_fmsprdrtem004 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: lbdfp1app00 NodeAlias: 10.8.8.67 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3778962:lbd




1-337902771	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:2200423] Date: May 17,2018 21:55 CUT Severity: Minor ResourceId: pngda00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dlb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var InstanceValue: 11.63 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: PNGDA00.imzcloud.ibmammsap.local NodeAlias: 10.13.1.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/var AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3770872:dlb





1-338049271    IBM AMM Infrastructure    2-Urgent
Summary: Lack_of_available_memory_on_server_ammpar01custesx001.imzcloud.ibmammsap.local[PROBLEM:2271556] Date: May 22,2018 4:37 CUT Severity: Major ResourceId: ammpar01custesx001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-Template_Virt_VMware_Hypervisor:Used_memory InstanceValue: 414.94 GB ComponentType: ZABBIX Component: Template_Virt_VMware_Hypervisor SubComponent: Used_memory Node: ammpar01custesx001.imzcloud.ibmammsap.local NodeAlias: 146.89.142.147 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_Virt_VMware_Hypervisor:Used_memory AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3790355:amm




1-337409361	sev3
Summary: Free_disk_space_is_less_than_20%_on_DB_volume_/backup[PROBLEM:1908365] Date: May 6,2018 12:3 CUT Severity: Minor ResourceId: snchdijpd11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup InstanceValue: 14.41 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: snchdijpd11.imzcloud.ibmammsap.local NodeAlias: 10.73.10.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/backup AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3706026:snc

[root@snchdijpd11 ibmrmalik]# df -h /backup
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/di6archvg-backup_lv
                       50G   41G  6.4G  87% /backup
/backup/NWDI


[root@snchdijpd11 backup]# find . -xdev -type f -size +1000000
./NWDI/SWPM/SWPM10SP21_7-20009701.SAR
./NWDI/SWPM/SWPM10SP21_6-20009703.SAR
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_42_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_29_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_41_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_3_BC_SLD_CHANGELOG.002
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_43_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_40_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_33_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_36_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_13_DAV_CONTENTSTORE.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_37_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_3_BC_SLD_CHANGELOG.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_38_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_43_CBS_BINARY.002
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_30_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_35_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_34_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_39_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_32_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_31_CBS_BINARY.001
./NWDI/DI6DBexport29Dec2017/JAVA/JDMP/EXPDMP_3_BC_SLD_CHANGELOG.003
./NWDI/Software/51050819/DATA_UNITS/JAVA_EXPORT_JDMP_BPM/EXPDUMP.001
./NWDI/Software/51050819/DATA_UNITS/JAVA_EXPORT_JDMP/EXPDUMP.001
./NWDI/Software/51050819/DATA_UNITS/JAVA_IDE/distros/com.sap.netweaver.developerstudio.distribution.complete.extsoa/8.31.130000.140828071619/nwds-extsoa-7.3-EHP1-SP13-PAT0000-win32.zip
./NWDI/Software/old_soft/ASE_SW/51052668_1.ZIP
./NWDI/Software/ASE/51052162_1.ZIP





1-338034081    IBM AMM Infrastructure    2-Urgent   transferred to Houcine
Summary: Lack_of_available_memory_on_server_ammfra02custesx21.imzcloud.ibmammsap.local[PROBLEM:2264110] Date: May 21,2018 16:20 CUT Severity: Major ResourceId: ammfra02custesx21 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-Template_Virt_VMware_Hypervisor:Used_memory InstanceValue: 438.31 GB ComponentType: ZABBIX Component: Template_Virt_VMware_Hypervisor SubComponent: Used_memory Node: ammfra02custesx21.imzcloud.ibmammsap.local NodeAlias: 146.89.140.222 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_Virt_VMware_Hypervisor:Used_memory AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3788340:amm




1-338034011 LV extended by 20GB			10.10.0.10 	

[root@tstmon01han01 ibmrmalik]# df -h /sapmnt/shared
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_shared
                      512G  469G   44G  92% /sapmnt/shared

[root@tstmon01han01 ibmrmalik]# vgs vghanadata
  VG         #PV #LV #SN Attr   VSize VFree
  vghanadata   1   3   0 wz--n- 2.18t 130.00g

#lvextend -L +20G  /dev/mapper/vghanadata-lv_hana_shared 
# resize2fs /dev/mapper/vghanadata-lv_hana_shared 



1-337922136
Description
05/18/2018   02:43:34   S0015810016

Description
05/18/2018 11:55:45 DUAMA / D-
 
Hi Team,
 
Please create a D drive with 100 GB space on the server 10.92.99.147 to
download all the software's. This drive should be mounted on all the
below windows and Linux/RHL servers.
 
This software's which will be residing on the new shared drive will be
used to install/upgrade other SAP applications on the TROO SBX
servvers.
 
Hostname CFN
sves1srv0 10.92.99.139
SVJS1SRV0 10.92.99.140
SVCS1SRV0 10.92.99.142
SVCS1SRV0 10.92.99.142
SVFS1SRV0 10.92.99.145
SVNS1SRV0 10.92.99.146
SVMS1SRV0 10.92.99.147	10.6.1.147
svls1srv0 10.6.1.144
SVWS1SRV0 10.6.1.152
 
Any clarifications, please feel free to email us
 
Satish.Kumar.Narayanasetti@msg-global.com
Karen.Samantha.Robles@msg-global.com
surjit.singh@sap.com
____________________
Business Consequences
05/18/2018   02:43:24   S0015810016

A productive system is completely down? No
 
An imminent go-live or upgrade is jeopardized? No Go-live/Upgrade date
 
The core business processes are seriously affected? No
 
Estimated financial loss within next 24 hours:
 
Number of users affected:
 
Is a workaround available? No
 
Description of business processes with business impact (english)
Description
05/18/2018 11:55:45 DUAMA / D-
 
Hi Team,
 
Please create a D drive with 100 GB space on the server 10.92.99.147 to
download all the software's. This drive should be mounted on all the
below windows and Linux/RHL servers.
 
This software's which will be residing on the new shared drive will be
used to install/upgrade other SAP applications on the TROO SBX
servvers.
 
Hostname CFN
sves1srv0 10.92.99.139	10.6.1.139
SVJS1SRV0 10.92.99.140	10.6.1.140
SVCS1SRV0 10.92.99.142	10.6.1.142
SVCS1SRV0 10.92.99.142
SVFS1SRV0 10.92.99.145
SVNS1SRV0 10.92.99.146
SVMS1SRV0 10.92.99.147
svls1srv0 10.6.1.144
SVWS1SRV0 10.6.1.152
 
Any clarifications, please feel free to email us
 
Satish.Kumar.Narayanasetti@msg-global.com
Karen.Samantha.Robles@msg-global.com
surjit.singh@sap.com
____________________
Information for SAP
05/17/2018   22:55:44   S0015810016

SY-SYSID ............... RPP
SY-MANDT ............... 100
 
Installation number .... 0020921481
 
System type ............ Production System
 
SAP version
Release ................ 740
Support Package Level .. 0012
 
Database ...............
 
Database Server
Vendor .................
Name ...................
IP address .............
Type ...................
CPU type ...............
Operating system .......
 
Message Server
Vendor ................. VMware, Inc.
Name ................... spsvepaeapp01
IP address ............. 10.6.3.12
Type ...................
CPU type ............... Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz
Operating system ....... LINUX_X86_64 RHEL6
 
Software Component/Release/Support Package Level
FSPM 530 0001
MDG_FND 747 0010
MSGPMCON 200
OTDP 0562_701
OTEXBAS 1050_700 0001
PI_BASIS 740 0012
SAP_ABA 740 0012
SAP_BASIS 740 0012
SAP_BS_FND 747 0010
SAP_BW 740 0012
SAP_GWFND 740 0013
SAP_UI 740 0014
ST-A/PI 01S_731
ST-PI 740 0002
WEBCUIF 747 0010


------------------------------------------------------------------------------------------------------------------------------------------

23 May

1-338082461    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    1-Critical
Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:2291218] Date: May 23,2018 0:29 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3795258:pnc


1-338081941    St Jude Medical  Dallas - SAP HEC    1-Critical
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2291474] Date: May 23,2018 0:54 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3795309:jud




1-338077961    Manitoba Telecom Services - SAP HEC-AMM    1-Critical
Summary: Zabbix_agent_on_tor01mtsdrvyatta001_is_unavailable[PROBLEM:2286046] Date: May 22,2018 21:20 CUT Severity: Critical ResourceId: tor01mtsdrvyatta001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: mtb InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: tor01mtsdrvyatta001 NodeAlias: 158.85.97.189 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3794366:mtb




1-338080851    Sancor Cooperativa de Seguros Ltda (SC8)    2-Urgent    AMM-DELIVERY-TECH
Summary: ITM Agent Offline: FD0-SC8SANFID20_FD0_00:Ins Date: 05/22/2018 Severity: Major ResourceId: sc8sanfid20 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sc8 InstanceId: FD0-sc8sanfid:sc8sanfid20:mySAP InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: sc8sanfid20 NodeAlias: 10.15.31.13 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3794907:sc8







1-338086131 - Sev1 - PNC - AMM-SAP - Siebel - Not Validated - Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local  
Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:2292066] Date: May 23,2018 2:14 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3795487:pnc





1-337875931	sev3
FS reorganization on IP1
LONMAGSPO0001 	10.69.0.35
Worked on troubleshooting and fixing the ownership and permission issues





1-338086451  IBM AMM Infrastructure P2
Summary: Processor_load_is_too_high_on_dal09ammsrtr2.imzcloud.ibmammsap.local[PROBLEM:2292775] Date: May 23,2018 3:48 CUT Severity: Major ResourceId: dal09ammsrtr2 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.07 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsrtr2.imzcloud.ibmammsap.local NodeAlias: 146.89.140.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3795682:amm





1-338086481  ETRO SPA (ETO)  P1
Summary: Zabbix_agent_on_eccpdb00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2292837] Date: May 23,2018 3:58 CUT Severity: Critical ResourceId: eccpdb00 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: eto InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: eccpdb00.imzcloud.ibmammsap.local NodeAlias: 10.5.2.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3795702:eto





1-338088471  - Sev1 - CTU - SAP HEC-AMM - Siebel - Not Validated - Summary: Zabbix_agent_on_ctubwpb0db01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_ctubwpb0db01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2293979] Date: May 23,2018 6:7 CUT Severity: Critical ResourceId: ctubwpb0db01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ctu InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ctubwpb0db01.imzcloud.ibmammsap.local NodeAlias: 10.12.10.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3796016:ctu



1-338088801  St Jude Medical  Dallas - SAP HEC  P1
Summary: Zabbix_agent_on_judhdmart02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2294600] Date: May 23,2018 7:21 CUT Severity: Critical ResourceId: judhdmart02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: jud InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: judhdmart02.imzcloud.ibmammsap.local NodeAlias: 10.196.4.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3796247:jud




1-337701491	sev3
Need ID's created for the newly migrated VM:CI3S4HANAQA2



1-338086811  Toyota Financial Services - SAP HEC-AMM  P2
Summary: Backupserver_process_is_not_running[PROBLEM:2293627] Date: May 23,2018 5:32 CUT Severity: Major ResourceId: daltfsdsd0001 TicketGroup: ApsSAPTechnical CustomerCode: toy InstanceId: Zabbix-AMM_Sybase_Linux:Sybase_BackupServer ComponentType: ZABBIX Component: AMM_Sybase_Linux SubComponent: Sybase_BackupServer Node: DALTFSDSD0001.imzcloud.ibmammsap.local NodeAlias: 10.4.1.183 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_Sybase_Linux:Sybase_BackupServer AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3795936:toy





1-338091391	sev3
Hi Team,
Please adjust the time zone on CI3S4HANAQA2 to be the same as on CI3S4HANAQAA â€œCESTâ€!"


CI3S4HANAQA2	10.210.1.31

[root@ci3s4hanaqa2 ~]# date
Wed May 23 11:10:07 UTC 2018


same as CI3S4HANAQAA	10.210.1.14
[root@CI3S4HANAQAA ~]# date
Wed May 23 11:10:19 CEST 2018


----------------------------------------------------------------------------------------------------------------------------------------------------------------


24 May

1-338123081   - Sev1 - MS3 - AMM-SAP - Siebel - Not Validated - Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2328357] Date: May 24,2018 1:34 CUT Severity: Critical ResourceId: ms3wdclapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3800195:ms3




1-338118031    IAG GBS Limited (IA1)    2-Urgent    CMS-SQ-SAP-TRIO-9 
Summary: Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:2312287] Date: May 23,2018 20:41 CUT Severity: Major ResourceId: ia1nfsprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.15 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1NFSPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.25 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3799331:ia1




1-338126441  - P1  -  St Jude Medical  Dallas - SAP HEC 
Summary: Zabbix_agent_on_juddtrans03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2328836] Date: May 24,2018 2:24 CUT Severity: Critical ResourceId: juddtrans03 TicketGroup: AMM-DELIVERY-TECH CustomerCode: jud InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: juddtrans03.imzcloud.ibmammsap.local NodeAlias: 10.196.4.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3800326:jud





1-338125531  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)  P1
Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:2328769] Date: May 24,2018 2:14 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3800296:pnc




1-338117421  Limited Brands, Inc. - SAP HEC-AMM  P2
Summary: Processor_load_is_too_high_on_LBDBOQQASApp3.imzcloud.ibmammsap.local[PROBLEM:2307984] Date: May 23,2018 19:47 CUT Severity: Major ResourceId: lbdboqqasapp3 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 0.66 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LBDBOQQASApp3.imzcloud.ibmammsap.local NodeAlias: 10.8.8.59 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3799169:lbd




1-337510881	sev3
Security Alert Remediation- IBM AOD security alert and recommended remediation on RH Linux OS Ver  5.x/6.x

Recommended Alert Below :
Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x

Please deploy above Q218-patches manually to the following servers.

<Server List>

LONMAGSPO0002
LONMAGSBD0003
LONMAGSBD0004

Thanks and regards,
Sai Sandeep.



SFTP config
(OD1)10.198.0.201 
(OQ1) 10.198.0.217 
first test on OD1 

account: _rimstest
Password:<password sent to Edward separately>
SFTP Server : 172.31.10.20

/home/postman/.ssh




1-338115261    MSC Industrial Supply Co.    2-Urgent
Summary: Processor_load_is_too_high_on_ms3wdclapp01.imzcloud.ibmammsap.local[PROBLEM:2306877] Date: May 23,2018 18:28 CUT Severity: Major ResourceId: ms3wdclapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 5.4 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3798738:ms3

[root@ms3wdclapp01 ibmrmalik]# uptime
 06:09:07 up 121 days,  6:03,  1 user,  load average: 24.27, 24.24, 24.25

top - 06:43:49 up 121 days,  6:38,  1 user,  load average: 24.48, 24.29, 24.26
Tasks: 398 total,   1 running, 397 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.6%us,  0.2%sy,  0.0%ni, 99.2%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.350G total,   28.886G used, 2523.168M free, 1278.598M buffers
Swap: 8191.996M total,  196.953M used, 7995.043M free,   10.808G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 5394 root      20   0 6774m 4.8g 5284 S  0.3 15.3 157:18.70 python
41117 ed1adm    20   0 30.1g 1.8g 1.6g S  0.0  5.7   1:35.52 ED1_01_DIA_W12
48274 ed1adm    20   0 30.1g 1.5g 1.4g S  0.0  4.9   0:31.69 ED1_01_DIA_W2
62876 ed1adm    20   0 30.1g 1.5g 1.3g S  0.0  4.7   0:31.32 ED1_01_DIA_W4
47491 ed1adm    20   0 30.1g 1.2g 1.0g S  0.0  3.7   0:21.02 ED1_01_DIA_W1
49062 ed1adm    20   0 30.1g 1.0g 905m S  0.0  3.1   1:03.55 ED1_01_DIA_W11
 2307 ed1adm    20   0 30.1g 877m 789m S  0.0  2.7   0:25.20 ED1_01_DIA_W10
21572 ed1adm    20   0 30.1g 873m 785m S  0.0  2.7   0:19.10 ED1_01_DIA_W8
 3094 ed1adm    20   0 30.1g 862m 777m S  0.0  2.7   0:28.10 ED1_01_DIA_W14
48265 ed1adm    20   0 30.1g 860m 765m S  0.0  2.7   0:42.82 ED1_01_DIA_W13
25563 ed1adm    20   0 1429m 845m  49m S  0.0  2.6  27:54.33 en.sapED1_ASCS0
17549 ed1adm    20   0 30.1g 844m 754m S  0.0  2.6   0:14.86 ED1_01_DIA_W6
 5292 ed1adm    20   0 30.1g 820m 736m S  0.0  2.6   0:15.19 ED1_01_DIA_W9
33190 ed1adm    20   0 30.1g 811m 728m S  0.0  2.5   0:16.51 ED1_01_DIA_W7
42497 ed1adm    20   0 30.1g 730m 650m S  0.0  2.3   0:12.59 ED1_01_DIA_W5
40204 ed1adm    20   0 30.1g 670m 598m S  0.0  2.1   0:08.02 ED1_01_DIA_W0
16831 ed1adm    20   0 30.1g 596m 459m S  0.0  1.9   1:29.29 ED1_01_BTC_W32





1-338135521 / MS3 / SEV1 / Siebel / Not validated
Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2331684] Date: May 24,2018 6:54 CUT Severity: Critical ResourceId: ms3wdclapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3801139:ms3



1-338132061  1-Critical MSC Industrial Supply Co. 
Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2332200] Date: May 24,2018 7:39 CUT Severity: Critical ResourceId: ms3wdclapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3801290:ms3


---------------------------------------------------------------------------------------------------------------------------------------------------------------

25 May

1-338171201 1-Critical    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC) Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local 
Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local[PROBLEM:2346031] Date: May 25,2018 2:15 CUT Severity: Critical ResourceId: c1bwp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3805113:pnc





1-338174131  1-Critical    MSC Industrial Supply Co.    Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailabl
Summary: Zabbix_agent_on_ms3wdclapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2346689] Date: May 25,2018 3:29 CUT Severity: Critical ResourceId: ms3wdclapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: ms3wdclapp01.imzcloud.ibmammsap.local NodeAlias: 10.12.6.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3805323:ms3


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------


28 May


1-338243489    2-Urgent    Dilip Buildcon Limited (DLB) 
Customer wants to check connection test with Bank Via SFTP port from their Development Web Dispatcher. Can OS team do this test>

OS login ID in Development Web dispatcher

Hostname	         IFN IP                   	CFN IP
DLBDWDAP00	10.13.2.24	                172.16.22.24

Please find the IP address for SFTP from Bank Side : Public:
   103.105.72.55 (Linux SFTP).

IP for CBI bank 169.38.92.21
User ID: DBL_CBI

[root@DLBDWDAP00 /]# sftp DBL_CBI@103.105.72.55
Connecting to 103.105.72.55...
^C[root@DLBDWDAP00 /]# sftp DBL_CBI@169.38.92.21
Connecting to 169.38.92.21...

[root@DLBDWDAP00 /]# ping 103.105.72.55
PING 103.105.72.55 (103.105.72.55) 56(84) bytes of data.
^C
--- 103.105.72.55 ping statistics ---
17 packets transmitted, 0 received, 100% packet loss, time 16528ms

[root@DLBDWDAP00 /]# ping 169.38.92.21
PING 169.38.92.21 (169.38.92.21) 56(84) bytes of data.
64 bytes from 169.38.92.21: icmp_seq=1 ttl=64 time=0.197 ms
64 bytes from 169.38.92.21: icmp_seq=2 ttl=64 time=0.127 ms
64 bytes from 169.38.92.21: icmp_seq=3 ttl=64 time=0.122 ms
64 bytes from 169.38.92.21: icmp_seq=4 ttl=64 time=0.121 ms
64 bytes from 169.38.92.21: icmp_seq=5 ttl=64 time=0.131 ms
64 bytes from 169.38.92.21: icmp_seq=6 ttl=64 time=0.188 ms
^C
--- 169.38.92.21 ping statistics ---
6 packets transmitted, 6 received, 0% packet loss, time 5680ms
rtt min/avg/max/mdev = 0.121/0.147/0.197/0.034 ms


[root@DLBDWDAP00 /]# telnet 169.38.92.21 22
Trying 169.38.92.21...
^C
[root@DLBDWDAP00 /]# telnet 103.105.72.55 22
Trying 103.105.72.55...
telnet: connect to address 103.105.72.55: Connection timed out




   
1-338251241    2-Urgent    AGEAS - SAP HEC-AMM 
Summary: Processor_load_is_too_high_on_svsq1srv0.imzcloud.ibmammsap.local[PROBLEM:2389109] Date: May 28,2018 7:41 CUT Severity: Major ResourceId: svsq1srv0 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.095 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: svsq1srv0.imzcloud.ibmammsap.local NodeAlias: 10.6.2.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3815962:age

top - 17:20:22 up 11 days, 16:18,  1 user,  load average: 7.52, 7.54, 7.46
Tasks: 373 total,   1 running, 372 sleeping,   0 stopped,   0 zombie
Cpu(s): 87.8%us,  0.5%sy,  0.0%ni, 11.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.352G total,   30.337G used, 1039.008M free, 2454.395M buffers
Swap:   13.766G total,   28.000k used,   13.766G free,   13.285G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
19632 sybsq1    20   0 4459m 2.8g 2.8g S 597.7  9.0  13869:39 dataserver
22897 root      20   0 2413m  67m  14m S 99.4  0.2   4182:34 ksaagent
21926 root      20   0  614m  67m 8772 S  2.7  0.2 343:35.51 BESClient
11016 nobody    20   0 80096 7060 5144 S  0.7  0.0   3:52.71 BESClient
50508 sq1adm    20   0 7937m 2.2g  24m S  0.7  7.0  70:41.56 jlaunch
 2862 root      20   0 2536m 212m 5592 S  0.3  0.7  74:31.18 ds_am





1-338253101 Egyptian Refining Company 2-Urgent
Summary: Lack_of_free_swap_space_on_ercsolprd1.imzcloud.ibmammsap.local[PROBLEM:2389832] Date: May 28,2018 9:5 CUT Severity: Major ResourceId: ercsolprd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: egr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.97 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: ercsolprd1.imzcloud.ibmammsap.local NodeAlias: 10.5.1.106 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3816221:egr

[root@ercsolprd1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            39         38          0         12          0         14
-/+ buffers/cache:         23         16
Swap:           13          6        

top - 11:15:55 up 80 days, 41 min,  1 user,  load average: 55.08, 55.12, 55.09
Tasks: 413 total,   1 running, 412 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.0%us,  0.4%sy,  0.0%ni, 98.6%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    39.461G total,   38.479G used, 1006.250M free,  715.676M buffers
Swap:   13.766G total, 7052.242M used, 7043.754M free,   14.344G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
58633 esjadm    20   0 8818m 2.7g  16m S  0.8  6.8  61:32.70 148m jstart
51321 esmadm    20   0 1200m  19m 2732 S  0.0  0.0   1:37.62  14m igsmux_mt





1-338255261	sev1
Summary: Zabbix_agent_on_DLTHPPSPI.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2390476] Date: May 28,2018 10:20 CUT Severity: Critical ResourceId: dlthppspi TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DLTHPPSPI.imzcloud.ibmammsap.local NodeAlias: 10.4.5.59 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3816478:dal
A0DBUS014XVM024

Migrate virtual machine
A0DBUS014XVM024
The VM 
failed to 
resume on 
the 
destination 
during early 
power on. 
View details...
System
AMMDAL09VCS001.imzcloud.ibmammsap.local
5/28/2018 3:42:36 PM
5/28/2018 3:42:36 PM
5/28/2018 3:49:44 PM


https://kb.vmware.com/s/article/2046325
https://kb.vmware.com/s/article/2141355

Web UI: https://mbpsjazz.austin.ibm.com:9443/jazz/resource/itemName/com.ibm.team.workitem.WorkItem/235165




1-338252900	sev1
Customer: Delta Air Lines, Inc.
Reported by: Venkatesh Kusuma
Phone:+1 4047152600
E-Mail:venkatesh.kusuma@delta.com
Priority:1: Very High
SAP Incident Number:0000272370/2018


Description:

Reconstruction
05/28/2018   07:21:55   S0018868491

Please provide step-by-step instructions on how to reproduce your issue:
Step 1:Access system Via SAPGUI
Step 2:Access link
Step 3:
____________________
Business Consequences
05/28/2018   07:21:54   S0018868491

Production portal is not responding, users will be impacted
____________________
Description
05/28/2018   07:21:53   S0018868491

Hello Team,   We are unable to access the system HPP via SAP GUI and
Java link is also not responsive.   SID : HSP LINK : 
http://10.250.17.59:50000/dir/start/index.jsp   Please look into the
issue at the earliest.   Regards, Delta Basis Team






1-337922697 SMRT Corp - SAP HEC-AMM 	Hana DB Upgrade + sap kernel + OS upgrade 
10.198.0.211

CLDERPAPPQ1:eq1adm 51> echo $LD_LIBRARY_PATH
/usr/sap/EQ1/SYS/exe/run:/usr/sap/EQ1/SYS/exe/uc/linuxx86_64:/usr/sap/EQ1/hdbclient/:/oracle/client/10x_64/instantclient


LD_LIBRARY_PATH=/usr/sap/EQ1/SYS/exe/run:/usr/sap/EQ1/SYS/exe/uc/linuxx86_64:/usr/sap/EQ1/hdbclient/ 


export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/sap/EQ1/SYS/exe/run:/usr/sap/EQ1/SYS/exe/uc/linuxx86_64:/usr/sap/EQ1/hdbclient/







1-338251921	sev2
Summary: Lack_of_free_swap_space_on_ADNMP1DEVAPP.imzcloud.ibmammsap.local[PROBLEM:2390060] Date: May 28,2018 9:33 CUT Severity: Major ResourceId: adnmp1devapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: adn InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 48.85 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: ADNMP1DEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.198.201.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3816346:adn

[root@ADNMP1DEVAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         22          8          2          0          8
-/+ buffers/cache:         13         17
Swap:            7          4          3


top - 18:09:24 up 88 days, 19:20,  4 users,  load average: 0.10, 0.10, 0.09
Tasks: 369 total,   1 running, 368 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.2%us,  0.7%sy,  0.0%ni, 97.0%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   22.787G used, 8759.902M free,  164.910M buffers
Swap: 8191.996M total, 5062.406M used, 3129.590M free, 9101.051M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
  2779 root      20   0 10.3g 7.7g 2280 S  0.0 24.5 174:57.36 1.3g python /usr/bin/goferd





1-336485841	sev2
Summary: ITM Agent Offline: MPP-adnmp1db:adnmp1app1:mySAP Date: 04/09/2018 Severity: Major ResourceId: adnmp1app1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: adn InstanceId: REMOTE_fmsprdrtem002 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: adnmp1app1 NodeAlias: 10.198.200.17 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3613248:adn




	
1-337242381	sev3
Summary: NTP_time_is_driffted_on_ADNMP1DEVDB.imzcloud.ibmammsap.local[PROBLEM:1819650] Date: May 1,2018 22:13 CUT Severity: Warning ResourceId: adnmp1devdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: adn InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.22 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: ADNMP1DEVDB.imzcloud.ibmammsap.local NodeAlias: 10.198.201.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3690137:adn





1-338177131
VM SNAP SHOT for the change

Database 	CLDPRODTBP1	10.198.0.145	A0CTSG014XVM036
Application 	CLDPROAPPP1	10.198.0.75	A0CTSG014XVM037   

----------------------------------------------------------------------------------------------------------------------------------------------------


29 May


1-338262186
CLDPROAPPP1	10.198.0.75

[root@SNG01AMMCHEF01 ~]# locate compat-sap
/root/compat-sap-c++-4.8.2-16.el6.x86_64.rpm




1-338275061  Delta Airlines, Inc. - SAP HEC-AMM  P1 
Summary: Zabbix_agent_on_DLTHSGGAT.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2404165] Date: May 29,2018 8:41 CUT Severity: Critical ResourceId: dlthsggat TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: DLTHSGGAT.imzcloud.ibmammsap.local NodeAlias: 10.4.5.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3820189:dal

[root@DLTHSGGAT ibmrmalik]# uptime
 05:07:57 up 21 days, 20:18,  1 user,  load average: 10.00, 9.49, 9.32
[root@DLTHSGGAT ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  20327) is running...

top - 05:08:47 up 21 days, 20:19,  1 user,  load average: 11.60, 10.00, 9.50
Tasks: 315 total,   1 running, 314 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.7%us,  0.2%sy,  0.0%ni, 99.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.352G total,   29.739G used, 1651.148M free,  850.980M buffers
Swap:   23.762G total, 4508.000k used,   23.757G free,   20.023G cached



1-338265831	sev2
Summary: Processor_load_is_too_high_on_IA1WEBDSPPRD2.imzcloud.ibmammsap.local[PROBLEM:2397092] Date: May 28,2018 21:20 CUT Severity: Major ResourceId: ia1webdspprd2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 33.5 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1WEBDSPPRD2.imzcloud.ibmammsap.local NodeAlias: 10.133.15.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3818142:ia1




1-338275691  -  P2  -  IBM AMM Infrastructure
Summary: Processor_load_is_too_high_on_dal09ammsrtr2.imzcloud.ibmammsap.local[PROBLEM:2404237] Date: May 29,2018 8:47 CUT Severity: Major ResourceId: dal09ammsrtr2 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsrtr2.imzcloud.ibmammsap.local NodeAlias: 146.89.140.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3820209:amm




1-338268341	sev2
Summary: Processor_load_is_too_high_on_IA1OTASDEVAPP.imzcloud.ibmammsap.local[PROBLEM:2397029] Date: May 28,2018 21:13 CUT Severity: Major ResourceId: ia1otasdevapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 12.7025 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1OTASDEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.34 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3818128:ia1




1-338260871	sev2
Summary: Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:2395566] Date: May 28,2018 18:55 CUT Severity: Major ResourceId: ia1ftsprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 0.92 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1FTSPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3817755:ia1






1-338251331	sev2
Summary: Free_disk_space_is_less_than_10%_on_DB_volume_/sybase/P1B/log_archive[PROBLEM:2389288] Date: May 28,2018 8:1 CUT Severity: Major ResourceId: snchbibpd11 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: snc InstanceId: Zabbix-AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/P1B/log_archive InstanceValue: 9.41 % ComponentType: ZABBIX Component: AMM_DSADB2_LINUX SubComponent: Free_disk_space_on_DB_filesystem Node: snchbibpd11.imzcloud.ibmammsap.local NodeAlias: 10.73.10.46 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DSADB2_LINUX:Free_disk_space_on_DB_filesystem_/sybase/P1B/log_archive AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3816008:snc

[root@snchbibpd11 ibmrmalik]# df -h /sybase/P1B/log_archive
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/p1barchvg-p1blogarch_lv
                      119G  112G  123M 100% /sybase/P1B/log_archive



1-338279951  -  Amcor Rigid Plastics USA, Inc.  -  P1
Summary: Zabbix_agent_on_hrsybs05a.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2405781] Date: May 29,2018 10:48 CUT Severity: Critical ResourceId: hrsybs05a1-338279971  -   Amcor Rigid
Summary: Zabbix_agent_on_hrsybs05a.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2405781] Date: May 29,2018 10:48 CUT Severity: Critical ResourceId: hrsybs05a TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: app InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: hrsybs05a.imzcloud.ibmammsap.local NodeAlias: 10.138.11.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3820815:app




1-338279971  -   Amcor Rigid Plastics USA, Inc-  P1
Summary: Zabbix_agent_on_hroras05b.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2405838] Date: May 29,2018 10:51 CUT Severity: Critical ResourceId: hroras05b
Summary: Zabbix_agent_on_hroras05b.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2405838] Date: May 29,2018 10:51 CUT Severity: Critical ResourceId: hroras05b TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: app InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: hroras05b.imzcloud.ibmammsap.local NodeAlias: 10.138.11.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3820837:app





1-338280071  -  P1  -  Adani Enterprises Ltd. (ADN)
Summary: Free_disk_space_is_less_than_5%_on_volume_/sapmnt/data[PROBLEM:2405997] Date: May 29,2018 11:8 CUT Severity: Critical ResourceId: adnmp1qadb TicketGroup: ApsSAPTechnical CustomerCode: adn InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX
Summary: Free_disk_space_is_less_than_5%_on_volume_/sapmnt/data[PROBLEM:2405997] Date: May 29,2018 11:8 CUT Severity: Critical ResourceId: adnmp1qadb TicketGroup: ApsSAPTechnical CustomerCode: adn InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/data InstanceValue: 4.95 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: ADNMP1QADB.imzcloud.ibmammsap.local NodeAlias: 10.198.202.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3820866:adn




1-338280081  -  P2  -  Adani Enterprises Ltd. (ADN)
Summary: Free_disk_space_is_less_than_10%_on_volume_/sapmnt/data[PROBLEM:2405963] Date: May 29,2018 11:3 CUT Severity: Major ResourceId: adnmp1qadb TicketGroup: ApsSAPTechnical CustomerCode: adn InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/data InstanceValue: 9.35 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: ADNMP1QADB.imzcloud.ibmammsap.local NodeAlias: 10.198.202.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/data AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3820857:adn





1-338177131
VM SNAP SHOT for the change-revert snapshot

Database 	CLDPRODTBP1	10.198.0.145	A0CTSG014XVM036
Application 	CLDPROAPPP1	10.198.0.75	A0CTSG014XVM037 



---------------------------------------------------------------------------------------------------------------------------------------------------

30 May


1-338311291  -  P2  -  IBM MSD Infras - Cloud APPS
Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local[PROBLEM:2424376] Date: May 30,2018 7:2 CUT Severity: Major ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.5275 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: 0f.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3826038:cia



1-338169763 sev3
Take snapshot of a VM pre changes
A0EASG014XVM003 	svjd1srv0


----------------------------------------------------------------------------------------------------------------------------------------------------------

31 May


Tribe Manager/CRB 	Adnan Khan 	Leader 	Adnan Khan/Fairfax/IBM 	adnank 	USA 	Software Architect 	Joseph Sande 	db
Tribe Technical Lead/CRB 	SAI BOPPANA 	Leader 	Sai Boppana/New York/IBM 	sboppana 	USA 	Manager - SAP Build and Projects DB2 and SQL Server Database 	Stacie Herman 	db
Squad Manager(RAVI VENKATARAMANI)   Squad Technical Leader(Blessen Babuji) 
SQUAD(SAP Trio 9 AP,SAP Trio 10 AP,SAP Trio 11 AP) 
 LN Dist list (SAP Client Tribe Leadership): ;Adnan Khan/Fairfax/IBM;Sai Boppana/New York/IBM;Luis Alonso Salas/Costa Rica/IBM;Gerard C Aloysius/India/IBM





1-338346151 1-Critical Adani Enterprises Ltd. (ADN)
Summary: Free_disk_space_is_less_than_5%_on_volume_/sapmnt/shared[PROBLEM:2465419] Date: May 31,2018 6:53 CUT Severity: Critical ResourceId: adnbidevdb TicketGroup: ApsSAPTechnical CustomerCode: adn InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/shared InstanceValue: 4.44 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: ADNBIDEVDB.imzcloud.ibmammsap.local NodeAlias: 10.198.201.19 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/shared AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3830762:adn

[root@ADNBIDEVDB ibmrmalik]# df -h /sapmnt/shared
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_shared
                      128G  123G  5.6G  96% /sapmnt/shared

FIles over 2GB in size individually
[root@ADNBIDEVDB shared]# find . -xdev -type f -size +2000000
./BID/HDB00/backup/data/COMPLETE_DATA_BACKUP_databackup_3_1
./BID/HDB00/backup/data/Initial.20180308103521_databackup_3_1
./BID/HDB00/backup/data/COMPLETE_DATA_BACKUP_P1_databackup_3_1
./export/exportabr/ABAP/DATA/_BIC_B0000576000.001
./DA/DA_kernal/51051055_2.ZIP


Files over 1.5 GB
./BID/exe/linuxx86_64/HDB_1.00.120.00.1462275491_2901232/libhdbcs.so
./BID/exe/linuxx86_64/HDB_1.00.122.13.1507793622_4101635/libhdbcs.so
./BID/HDB00/backup/data/COMPLETE_DATA_BACKUP_databackup_3_1
./BID/HDB00/backup/data/Initial.20180308103521_databackup_3_1
./BID/HDB00/backup/data/COMPLETE_DATA_BACKUP_P1_databackup_3_1
./export/exportabr/ABAP/DATA/REPOSRC-2.001
./export/exportabr/ABAP/DATA/_BIC_B0000576000.001
./DA/DA_kernal/51051055_2.ZIP
./DA/DA_kernal/SWPM/SWPM10SP18_6-20009698.SAR





1-338346911	sev3

*** Details of Generic Service Request - DO NOT CHANGE ***

Hello,
 
Could you take these 4 files in DIR_TRANS of SAP SYSTEM DT3  SMTMDEVDT3 (10.78.22.16)
in directory :
 
/usr/sap/trans/cofiles/
K900044.TV1
K900751.TV1
 
/usr/sap/trans/data/
R900044.TV1
R900751.TV1
 
[root@smtmdevdt3 cofiles]# ls -ltr |grep K900044.TV1
-rwxrwxr-x 1 dt3adm sapsys    2694 Dec  5 14:15 K900044.TV1
[root@smtmdevdt3 cofiles]# ls -ltr |grep K900751.TV1
-rwxrwxr-x 1 dt3adm sapsys    2531 Dec  5 14:15 K900751.TV1


[root@smtmdevdt3 data]# ls -ltr |grep R900044.TV1
-rwxrwxr-x 1 dt3adm sapsys       81675 Oct  6  2017 R900044.TV1
[root@smtmdevdt3 data]# ls -ltr |grep R900751.TV1
-rwxrwxr-x 1 dt3adm sapsys       33775 Oct  6  2017 R900751.TV1

Copy this 4 files in DIR_TRANS of DU3	SMEDIDEVDU3 (10.78.22.35)
in directory 
 
/usr/sap/trans/cofiles/
K900044.TV1
K900751.TV1
 
/usr/sap/trans/data/
R900044.TV1
R900751.TV1
 
When these files will be copied please inform us by email




1-338013701   snapshots for the change
SJMDEPAA01   10.198.11.10            DEP (apps)	A0FGSG014XVM001
SJMDCPAA01   10.198.11.13           DRP (apps)	A0FGSG014XVM003
SJMDWDWD01   10.198.13.10           DWD (Webdisp)	A0FGSG014XVM013
SJMDPQJA01   10.198.11.19            DPQ (apps)	A0FGSG014XVM011
SAPDPQDB01   10.198.11.20           DPQ (db) 	A0FGSG014XVM012





1-338343625	sev3
SIDADM password reset in Sanbox systems

ES1 : sves1srv0 (ES1adm/rs1adm)
ESM : sves1hdbsrv01 (esmadm)
CS1 : svcs1srv0 (cs1adm/xs1adm)

10.6.1.142





1-338346931
SMTMQUAQT3 >> 10.78.24.17
from 32GB to 64GB
[root@smtmquaqt3 ibmrmalik]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0

0
[root@smtmquaqt3 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   2   7   0 wz--n- 54.50g 5.49g

  lv_swap       VolGroup -wi-ao---- 20.00g 

swap to 48 GB

sde                                8:64   0   32G  0 disk


[root@smtmquaqt3 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   3   7   0 wz--n- 86.50g 37.49g

[root@smtmquaqt3 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            63          5         58          0          0          2
-/+ buffers/cache:          2         60
Swap:           47          0         47





1-338358281 Inter Pipeline Ltd 1-Critical 
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/RPA[PROBLEM:2472391] Date: May 31,2018 12:21 CUT Severity: Critical ResourceId: iplsas4ap01 TicketGroup: ApsSAPTechnical CustomerCode: ipl InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/RPA InstanceValue: 4.95 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: iplsas4ap01.imzcloud.ibmammsap.local NodeAlias: 10.138.1.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/RPA AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3832594:ipl

[root@iplsas4ap01 ibmrmalik]# df -h /usr/sap/RPA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/rpaappvg-rpausrRPA_lv
                       24G  9.4G   14G  42% /usr/sap/RPA





1-338325101 - Copy transport files from DT3 to DM3 & DM1	sev3

could you get these 4 files in DIR_TRANS of SAP SYSTEM SMTMDEVDT3 (10.78.22.16)
in directory 
/usr/sap/trans/cofiles/
K900044.TV1
K900751.TV1

[root@smtmdevdt3 cofiles]# ls -ltr |grep K900044.TV1
-rwxrwxr-x 1 dt3adm sapsys    2694 Dec  5 14:15 K900044.TV1
[root@smtmdevdt3 cofiles]# ls -ltr |grep K900751.TV1
-rwxrwxr-x 1 dt3adm sapsys    2531 Dec  5 14:15 K900751.TV1

/usr/sap/trans/data/
R900044.TV1
R900751.TV1

[root@smtmdevdt3 data]# ls -ltr |grep R900044.TV1
-rwxrwxr-x 1 dt3adm sapsys       81675 Oct  6  2017 R900044.TV1
[root@smtmdevdt3 data]# ls -ltr |grep R900751.TV1
-rwxrwxr-x 1 dt3adm sapsys       33775 Oct  6  2017 R900751.TV1


Copy this 4 files in DIR_TRANS of SMEMDEVDM3 (10.78.22.29) & SMEMDEVDM1 (10.78.22.39) in directory 
/usr/sap/trans/cofiles/
K900044.TV1
K900751.TV1


[root@smemdevdm3 cofiles]# ls -ltr |grep K900751.TV1
-rw-rw-r-- 1 dm3adm sapsys 2531 May 31 14:05 K900751.TV1
[root@smemdevdm3 cofiles]# ls -ltr |grep K900044.TV1
-rw-rw-r-- 1 dm3adm sapsys 2694 May 31 14:05 K900044.TV1

dm1adm:sapsys


/usr/sap/trans/data/
R900044.TV1
R900751.TV1 

[root@smemdevdm3 data]# ls -ltr |grep R900751.TV1
-rw-rw-r-- 1 dm3adm sapsys    33775 May 31 14:05 R900751.TV1
[root@smemdevdm3 data]# ls -ltr |grep R900044.TV1
-rw-rw-r-- 1 dm3adm sapsys    81675 May 31 14:05 R900044.TV1


[root@smemdevdm1 data]# ls -ltr |grep R900044.TV1
-rw-rw-r-- 1 nobody nobody    81675 May 31 14:11 R900044.TV1
[root@smemdevdm1 data]# ls -ltr |grep R900751.TV1
-rw-rw-r-- 1 nobody nobody    33775 May 31 14:11 R900751.TV1




SMRT

Singapore site
CLDERPDTBP1	A0CTSG014XVM028
CLDERPAPPP1	A0CTSG014XVM029

and

HOng Kong site
CLDERPDTBP1dr 	hkhana-1024-2.xsportal.local
CLDERPAPPP1	A0CTSG014XVM029



-------------------------------------------------------------------------------------------------

1 June

1-338403281    1-Critical    IBM MSD Infras - Cloud MONITORING    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/tmp 
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/tmp[PROBLEM:2492407] Date: Jun 1,2018 8:21 CUT Severity: Critical ResourceId: ri3lr022 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mic InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 4.83 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: DAL09AMMCHEF01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3837933:mic

[root@DAL09AMMCHEF01 ~]# df -h /tmp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-tmp  2.9G  2.4G  429M  85% /tmp




1-338403731 - QT3 and DT1 Performance issue
SMTMDEVDT1 >> 10.78.22.41
[root@smtmdevdt1 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            63         57          6         36          0         39
-/+ buffers/cache:         17         46
Swap:           49          0         49

top - 11:14:34 up 109 days,  2:39,  1 user,  load average: 6.24, 6.68, 6.75
Tasks: 465 total,   7 running, 458 sleeping,   0 stopped,   0 zombie
Cpu(s): 78.9%us,  0.3%sy,  0.0%ni, 20.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    63.342G total,   57.213G used, 6276.000M free,  518.719M buffers
Swap:   50.000G total,  169.059M used,   49.835G free,   39.398G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 81602 dt1adm    20   0 49.1g 169m  79m R 100.0  0.3   4824:42 DT1_10_BTC_W89
 16062 dt1adm    20   0 49.1g 154m  96m R 99.9  0.2  83:17.62 DT1_10_BTC_W95
 35750 dt1adm    20   0 49.1g 242m 152m R 99.9  0.4   3018:57 DT1_10_BTC_W105
 78796 dt1adm    20   0 49.2g 295m 121m R 99.9  0.5   4814:13 DT1_10_BTC_W88
 28600 dt1adm    20   0 49.1g 206m 133m R 99.3  0.3   3567:45 DT1_10_BTC_W107
 80042 dt1adm    20   0 49.2g 300m 120m R 98.9  0.5   4804:11 DT1_10_BTC_W93
 46638 dt1adm    20   0 49.1g 1.2g 1.1g S 18.3  1.8   0:34.25 DT1_10_DIA_W11
 31322 dt1adm    20   0 49.2g 3.1g 3.0g S  8.0  4.9   0:17.84 DT1_10_DIA_W46




SMTMQUAQT3 >> 10.78.24.17
[root@smtmquaqt3 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         35         27         18          0         21
-/+ buffers/cache:         13         49
Swap:           47          0         47


top - 11:16:22 up 22:01,  1 user,  load average: 10.58, 10.92, 11.79
Tasks: 376 total,  12 running, 364 sleeping,   0 stopped,   0 zombie
Cpu(s): 96.3%us,  1.0%sy,  0.0%ni,  2.2%id,  0.0%wa,  0.0%hi,  0.5%si,  0.0%st
Mem:    62.902G total,   35.230G used,   27.672G free,  454.281M buffers
Swap:   48.000G total,    0.000k used,   48.000G free,   21.717G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 48586 qt3adm    20   0 53.3g 6.4g 6.2g R 80.1 10.2 126:45.32 QT3_10_DIA_W25
 48577 qt3adm    20   0 53.3g 3.8g 3.6g R 67.1  6.0  25:07.94 QT3_10_DIA_W16
 48595 qt3adm    20   0 53.3g 8.7g 8.4g S 65.8 13.8  63:59.60 QT3_10_DIA_W33
 48594 qt3adm    20   0 53.3g 8.5g 8.3g S 64.5 13.5  97:31.48 QT3_10_DIA_W32
 48597 qt3adm    20   0 53.3g 7.8g 7.6g R 63.5 12.5  60:46.95 QT3_10_DIA_W35
 48591 qt3adm    20   0 53.3g 7.7g 7.5g R 62.5 12.2  64:25.10 QT3_10_DIA_W29
 48574 qt3adm    20   0 53.3g 6.5g 6.3g R 61.8 10.3  50:52.74 QT3_10_DIA_W13
 48585 qt3adm    20   0 53.3g 7.8g 7.6g S 58.8 12.4  77:05.69 QT3_10_DIA_W24
 59363 qt3adm    20   0 53.4g  12g  12g R 56.1 20.2  68:19.53 QT3_10_DIA_W39
 48583 qt3adm    20   0 53.3g 9.5g 9.3g S 54.5 15.1 120:39.29 QT3_10_DIA_W22
 48575 qt3adm    20   0 53.3g 3.0g 2.8g R 52.2  4.7  17:07.15 QT3_10_DIA_W14
 48596 qt3adm    20   0 53.3g  11g  11g R 52.2 18.6  85:42.69 QT3_10_DIA_W34
 48569 qt3adm    20   0 53.3g 4.2g 4.0g R 20.9  6.7   5:15.86 QT3_10_DIA_W8
 48582 qt3adm    20   0 53.3g 5.5g 5.3g R 10.6  8.7  81:43.60 QT3_10_DIA_W21





1-338407871 Limited Brands, Inc. - SAP HEC-AMM 1-Critical 
Summary: Zabbix_agent_on_LBDTP1PRDApp1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2499568] Date: Jun 1,2018 12:7 CUT Severity: Critical ResourceId: lbdtp1prdapp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: lbd InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: LBDTP1PRDApp1.imzcloud.ibmammsap.local NodeAlias: 10.8.8.80 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3838905:lbd





-------------------------------------------------------------------------------------------------------------------------

2 June

1-338444451	sev1
Summary: Zabbix_agent_on_lonmaghan0010.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2521912] Date: Jun 2,2018 12:8 CUT Severity: Critical ResourceId: lonmaghan0010 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: lonmaghan0010.imzcloud.ibmammsap.local NodeAlias: 10.69.0.57 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3843919:mng





1-337922495 - EP1 - OS+HDB+Kernel upgrade

Singapore Site
EP1 - CLDERPAPPP1 / 10.198.0.71- apps - RHEL to UPGRADE to 6.9 
EP1 - CLDERPDTBP1 / 10.168.1.141 - DB - RHEL to UPGRADE to 6.7	10.168.1.141 10.198.0.141 10.116.35.185
EP1 - CLDERPDTBP2 / 10.198.0.146 - stanbynode to UPGRADE to 6.7 


Hong Kong Site - DR servers
EP1 - CLDERPAPPP1/ 10.198.0.71 - APP - RHEL to UPGRADE to 6.9 
CLDERPDTBP1dr/ / 10.168.1.141 - DB RHEL to UPGRADE to 6.7 


mount 146.89.140.30:/storage/library /storage/library -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003       //10.7.1.171/sapexchange /mnt/sapexchangePT  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003


mount -o

 mount 10.198.0.141:/usr/sap/EP1/HDB00/backup/data /EP1_BACKUP

---------------------------------------------------------------------------------------------------------------------------------------------------------------

5 June


1-338546437 - File Size of EQ2 & EQ3

EQ2
CLDERPDTBQ2 / 10.168.1.220	10.198.0.220
CLDERPAPPQ2 / 10.168.1.221	10.198.0.221

EQ3
CLDERPDTBQ3 / 10.168.1.140	10.198.0.140
CLDERPAPPQ3 / 10.168.1.72	10.198.0.72




1-338589161 - MSC Industrial Supply Co. - Sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/sapmnt/EP1[PROBLEM:2591479] Date: Jun 5,2018 8:16 CUT Severity: Major ResourceId: ms3wdclapp29 TicketGroup: ApsSAPTechnical CustomerCode: ms3 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/EP1 InstanceValue: 9.9 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: ms3wdclapp29.imzcloud.ibmammsap.local NodeAlias: 10.12.7.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/EP1 AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3861578:ms3

[root@ms3wdclapp29 ibmrmalik]# df -h /sapmnt/EP1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ep1appvg-ep1sapmnt_lv
                       20G   18G  1.4G  93% /sapmnt/EP1


[root@ms3wdclapp29 EP1]# find . -xdev -type f -size +300000
./global/100JOBLG/0001X07000100X39562
./global/100JOBLG/0001X07000100X42555
./global/100JOBLG/0001X07000000X71434
./global/100JOBLG/0001X07000100X61348
./global/100JOBLG/0001X07000000X48245
./global/100JOBLG/0001X07000000X14418
./global/100JOBLG/0001X07000000X86395
./global/100JOBLG/0001X07000100X42429
./global/100JOBLG/0001X07000000X44151
./global/100JOBLG/0001X07000100X47136
./global/100JOBLG/0001X07000100X82928
./global/100JOBLG/0001X07000000X03949
./global/100JOBLG/0001X07000100X80027
./global/100JOBLG/0001X07000100X43839




1-338589601 - Promociones Habitat S.A.
Summary: Zabbix_agent_on_PHSSAPPRD01_is_unavailable[PROBLEM:2594355] Date: Jun 5,2018 9:4 CUT Severity: Critical ResourceId: phssapprd01 TicketGroup: AMM-DELIVERY-TECH CustomerCode: phs InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: PHSSAPPRD01 NodeAlias: 10.5.6.7 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3861944:phs
server not accessible



1-338589631 - West African Cotton Company
Summary: Zabbix_agent_on_AFRS4HQADB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2594361] Date: Jun 5,2018 9:4 CUT Severity: Critical ResourceId: afrs4hqadb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: afr InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: AFRS4HQADB.imzcloud.ibmammsap.local NodeAlias: 10.197.1.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3861946:afr



1-338589701 - Computer Systems Integration 
Summary: Zabbix_agent_on_PSDEVASJAVA.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2594410] Date: Jun 5,2018 9:5 CUT Severity: Critical ResourceId: psdevasjava TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: csy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PSDEVASJAVA.imzcloud.ibmammsap.local NodeAlias: 10.197.2.43 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3861960:csy



1-338607801    1-Critical    MSC Industrial Supply Co
Summary: Free_disk_space_is_less_than_5%_on_volume_/sapmnt/EP1[PROBLEM:2597583] Date: Jun 5,2018 10:19 CUT Severity: Critical ResourceId: ms3wdclapp29 TicketGroup: ApsSAPTechnical CustomerCode: ms3 InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/EP1 InstanceValue: 4.97 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: ms3wdclapp29.imzcloud.ibmammsap.local NodeAlias: 10.12.7.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/EP1 AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863521:ms3

[root@ms3wdclapp29 ibmrmalik]# df -h /sapmnt/EP1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ep1appvg-ep1sapmnt_lv
                       20G   18G  840M  96% /sapmnt/EP1


1-338605851    2-Urgent    Space Tours S.A. de C.V. (SP9)    Summary: Processor_load_is_too_high_on_sp9spacesap30.imzcloud.ibmammsap.local[
Summary: Processor_load_is_too_high_on_sp9spacesap30.imzcloud.ibmammsap.local[PROBLEM:2597282] Date: Jun 5,2018 10:7 CUT Severity: Major ResourceId: sp9spacesap30 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sp9 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.135 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: sp9spacesap30.imzcloud.ibmammsap.local NodeAlias: 10.15.11.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863469:sp9



1-338606081	sev2
Summary: Processor_load_is_too_high_on_sp9spacesap32.imzcloud.ibmammsap.local[PROBLEM:2597090] Date: Jun 5,2018 9:58 CUT Severity: Major ResourceId: sp9spacesap32 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sp9 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.2375 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: sp9spacesap32.imzcloud.ibmammsap.local NodeAlias: 10.15.11.21 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863382:sp9


1-338588091	sev1
Summary: Zabbix_agent_on_a0b4uk013etrovyatta001_is_unavailable[PROBLEM:2595478] Date: Jun 5,2018 9:21 CUT Severity: Critical ResourceId: a0b4uk013etrovyatta001 TicketGroup: AMM-DELIVERY-TECH CustomerCode: eto InstanceId: Zabbix-Template_App_Zabbix_Agent:Agent_availability ComponentType: ZABBIX Component: Template_App_Zabbix_Agent SubComponent: Agent_availability Node: a0b4uk013etrovyatta001 NodeAlias: 159.122.210.133 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_App_Zabbix_Agent:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3862100:eto




1-338607891	sev2
Summary: Processor_load_is_too_high_on_HC1HOSMAPTREXP.imzcloud.ibmammsap.local[PROBLEM:2597710] Date: Jun 5,2018 10:24 CUT Severity: Major ResourceId: hc1hosmaptrexp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: hc1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.1 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: HC1HOSMAPTREXP.imzcloud.ibmammsap.local NodeAlias: 10.211.80.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863537:hc1



1-338611501
Summary: Zabbix_agent_on_IA1S4HQASAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599813] Date: Jun 5,2018 11:25 CUT Severity: Critical ResourceId: ia1s4hqasapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1S4HQASAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.17.140 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863901:ia1


1-338611511
Summary: Zabbix_agent_on_IA1BPCDEVDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599812] Date: Jun 5,2018 11:25 CUT Severity: Critical ResourceId: ia1bpcdevdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1BPCDEVDB.imzcloud.ibmammsap.local NodeAlias: 10.133.16.35 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863900:ia1



1-338611541
Summary: Zabbix_agent_on_IA1FIOPRDAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599816] Date: Jun 5,2018 11:25 CUT Severity: Critical ResourceId: ia1fioprdapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1FIOPRDAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.15.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863904:ia1



1-338611591
Summary: Zabbix_agent_on_IA1BPCQASAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599814] Date: Jun 5,2018 11:25 CUT Severity: Critical ResourceId: ia1bpcqasapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1BPCQASAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.17.149 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863902:ia1



1-338611571
Summary: Zabbix_agent_on_MGGGBJPGTSX04.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599817] Date: Jun 5,2018 11:25 CUT Severity: Critical ResourceId: mgggbjpgtsx04 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPGTSX04.imzcloud.ibmammsap.local NodeAlias: 10.133.18.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863905:mgg



1-338608831	sev1
Summary: Zabbix_agent_on_dcghanapreap1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599884] Date: Jun 5,2018 11:25 CUT Severity: Critical ResourceId: dcghanapreap1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cpw InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: dcghanapreap1.imzcloud.ibmammsap.local NodeAlias: 10.197.5.23 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863923:cpw



1-338608991
Summary: Zabbix_agent_on_IA1WEBDSLB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599941] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: ia1webdslb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1WEBDSLB.imzcloud.ibmammsap.local NodeAlias: 10.133.15.32 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863942:ia1



1-338611891
Summary: Zabbix_agent_on_IA1FIODEVDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599959] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: ia1fiodevdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1FIODEVDB.imzcloud.ibmammsap.local NodeAlias: 10.133.16.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863939:ia1



1-338612041- P1 - IAG GBS Limited (IA1)-portal-not validated- "Summary: Zabbix_agent_on_IA1WEBDSPQAS1.imzcloud.ibmammsap.local_is_unavailable "- Warm transfer and SRE priority validation - Acknowledgment Required.
Summary: Zabbix_agent_on_IA1WEBDSPQAS1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599961] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: ia1webdspqas1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1WEBDSPQAS1.imzcloud.ibmammsap.local NodeAlias: 10.133.17.143 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863953:ia1




1-338613101  /Sev1-MGG/Siebel-Monitoring not validated//Summary: Zabbix_agent_on_MGGGBJPCNTX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599963/SRE Warm transfer/Acknowledgement required
Summary: Zabbix_agent_on_MGGGBJPCNTX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599963] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: mgggbjpcntx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJPCNTX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.33 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863967:mgg




1-338612051 / CSY / SEV1 / Siebel / Not validated / Summary: Zabbix_agent_on_PSQASDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599914] / SRE Warm transfer - Acknowledgement Required
Summary: Zabbix_agent_on_PSQASDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599914] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: psqasdb TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: csy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PSQASDB.imzcloud.ibmammsap.local NodeAlias: 10.197.2.20 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863950:csy




1-338613131- P1 - IAG GBS Limited (IA1)-portal-not validated- "Summary: Zabbix_agent_on_IA1S4HSBXAPP.imzcloud.ibmammsap.local_is_unavailable"- Warm transfer and SRE priority validation - Acknowledgment Required.
Summary: Zabbix_agent_on_IA1S4HSBXAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600002] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: ia1s4hsbxapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1S4HSBXAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863937:ia1




1-338613111 / CSY / SEV1 / Siebel / Not validated / Summary: Zabbix_agent_on_PSWEB2.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600001] / SRE Warm transfer - Acknowledgement Required
Summary: Zabbix_agent_on_PSWEB2.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600001] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: psweb2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: csy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: PSWEB2.imzcloud.ibmammsap.local NodeAlias: 10.197.2.44 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863933:csy




1-338612071 / MGG / SEV1 / Siebel / Not validated / Summary: Zabbix_agent_on_MGGGBJDGTSX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600011] / SRE Warm transfer - Acknowledgement Required
Summary: Zabbix_agent_on_MGGGBJDGTSX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600011] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: mgggbjdgtsx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJDGTSX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.186 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863964:mgg



1-338611991- P1 - IAG GBS Limited (IA1)-portal-not validated- "Summary: Zabbix_agent_on_IA1SOLMANSCE.imzcloud.ibmammsap.local_is_unavailable"- Warm transfer and SRE priority validation - Acknowledgment Required.
Summary: Zabbix_agent_on_IA1SOLMANSCE.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600007] Date: Jun 5,2018 11:26 CUT Severity: Critical ResourceId: ia1solmansce TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IA1SOLMANSCE.imzcloud.ibmammsap.local NodeAlias: 10.133.16.26 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3863955:ia1





1-338612021 / MGG / SEV1 / Siebel / Not validated / Summary: Zabbix_agent_on_MGGGBJDSOLX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600008] / SRE Warm transfer - Acknowledgement Required
1-338612031- P1 - Meggitt Plc (MGG)-portal-not validated- "Summary: Zabbix_agent_on_MGGGBJSGTSX03.imzcloud.ibmammsap.local_is_unavailable"- Warm transfer and SRE priority validation - Acknowledgment Required.
1-338612031- P1 - Meggitt Plc (MGG)-portal-not validated- "Summary: Zabbix_agent_on_MGGGBJSECCX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599962] Dat"- Warm transfer and SRE priority validation - Acknowledgment Required.
1-338611971  -  Sev1-  Siebel - Meggitt Plc (MGG) - IC4SAP-SL - not validated- "Zabbix_agent_on_MGGGBJSECCX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600009] "- Warm transfer and SRE priority validation - Acknowledgment Required.
1-338611931 / IA1 / SEV1 / Siebel / Not validated / Summary: Zabbix_agent_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599886] / SRE Warm transfer - Acknowledgement Required
1-338609071  -  Sev1-  Siebel - Meggitt Plc (MGG) - IC4SAP-SL - not validated- "Zabbix_agent_on_MGGGBJDGTSX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600010] "- Warm transfer and SRE priority validation - Acknowledgment Required.
1-338611931 / IA1 / SEV1 / Siebel / Not validated / Summary: Zabbix_agent_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599886] / SRE Warm transfer - Acknowledgement Required
1-338609071  -  Sev1-  Siebel - Meggitt Plc (MGG) - IC4SAP-SL - not validated- "Zabbix_agent_on_MGGGBJDGTSX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600010] "- Warm transfer and SRE priority validation - Acknowledgment Required.
1-338609041  -  Sev1-  Siebel - Meggitt Plc (MGG) - IC4SAP-SL - not validated- "Zabbix_agent_on_MGGGBJSGTSX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2599915] "- Warm transfer and SRE priority validation - Acknowledgment Required.
1-338612091- P1 - Computer Systems Integration LLC-portal-not validated- "Summary: Zabbix_agent_on_PSPRDAP1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2600004] Date: Jun "- Warm transfer and SRE priority validation - Acknowledgment Required.




CS10313565	Delta Air Lines -- DAL	P1 - Severe	dal#dlthpehdb4#Resource Pacemaker Active Nodes CRITICAL: /usr/local/ncpa/var/log/KzbhQSZr	DLTHPEHDB4	
CS10313657	Delta Air Lines -- DAL	P1 - Severe	dal#dlthpehdb4s#Resource Pacemaker vIP Error signing on to the CIB service: Transport endpoint is not connected	DLTHPEHDB4S	
CS10313654	Delta Air Lines -- DAL	P1 - Severe	dal#dlthpehdb4s#Resource Pacemaker Colocation ERROR: status: crm_mon (rc=107): Connection to cluster failed: Transport endpoint is not connected	DLTHPEHDB4S	
CS10313658	Delta Air Lines -- DAL	P1 - Severe	dal#dlthpehdb4s#Resource Pacemaker Active Nodes CRITICAL: /usr/local/ncpa/var/log/GGuGWVmD	DLTHPEHDB4S

implemented sudo and FS is fine


1-338588814
copy files and folders from Source 10.6.1.24 to Target: 10.6.1.145 








sng01ammsol01.ibmammsap.local
10.116.35.179
-----------------------------------------------------------------------------------------------------------------------------------------------------------


6 June

1-338366061





1-338648098	sev3
Question on reducing free space on Solution Manager ( Java) - MNP - 
SSGSA0122	100.126.0.16



1-338304121	sev3
Summary: NTP_time_is_driffted_on_PSPRDAP2.imzcloud.ibmammsap.local[PROBLEM:2420234] Date: May 30,2018 0:8 CUT Severity: Warning ResourceId: psprdap2 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: csy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.21 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: PSPRDAP2.imzcloud.ibmammsap.local NodeAlias: 10.197.2.40 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3824996:csy




1-338663311
MMGRAS 	10.78.22.12
Paris DC

login with one service id didnt work





1-338663471- P1 - Egyptian Media Company (EMC)
Summary: Zabbix_agent_on_EMCBOPRD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2644599] Date: Jun 6,2018 10:26 CUT Severity: Critical ResourceId: emcboprd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: emc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: EMCBOPRD.imzcloud.ibmammsap.local NodeAlias: 10.14.5.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3872935:emc



1-338567745-AGEAS
Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x

---------------------------------------------------------------------------------------------------------------------------------------

7 Jun


1-338622491    SAP09    Assigned/In Progress    SAP09    2-Urgent    NetCool    Cloud    IAG GBS Limited (IA1)    CMS-TR-SAP-CLIENT    CMS-SQ-SAP-TRIO-9    6/5/2018 4:42    Summary: Processor_load_is_too_high_on_IA1WEBDSPSBX1.imzcloud.ibmammsap.local[PROBLEM:2601496] Date
Summary: Processor_load_is_too_high_on_IA1WEBDSPSBX1.imzcloud.ibmammsap.local[PROBLEM:2601496] Date: Jun 5,2018 11:42 CUT Severity: Major ResourceId: ia1webdspsbx1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.355 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA1WEBDSPSBX1.imzcloud.ibmammsap.local NodeAlias: 10.133.16.15 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_




1-338623701    SAP09    Assigned/In Progress    SAP09    2-Urgent    NetCool    Cloud    IAG GBS Limited (IA1)    CMS-TR-SAP-CLIENT    CMS-SQ-SAP-TRIO-9    6/5/2018 4:45    Summary: Processor_load_is_too_high_on_IA2SCCDEVAGE.imzcloud.ibmammsap.local[PROBLEM:2602110] Date:
Summary: Processor_load_is_too_high_on_IA2SCCDEVAGE.imzcloud.ibmammsap.local[PROBLEM:2602110] Date: Jun 5,2018 11:45 CUT Severity: Major ResourceId: ia2sccdevage TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.44 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA2SCCDEVAGE.imzcloud.ibmammsap.local NodeAlias: 10.133.16.51 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3864641:ia1


1-338625791    SAP09    Assigned/In Progress    SAP09    2-Urgent    NetCool    Cloud    IAG GBS Limited (IA1)    CMS-TR-SAP-CLIENT    CMS-SQ-SAP-TRIO-9    6/5/2018 4:50    Summary: Processor_load_is_too_high_on_IA2BPCDEVAPP.imzcloud.ibmammsap.local[PROBLEM:2602649] 
Summary: Processor_load_is_too_high_on_IA2BPCDEVAPP.imzcloud.ibmammsap.local[PROBLEM:2602649] Date: Jun 5,2018 11:50 CUT Severity: Major ResourceId: ia2bpcdevapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ia1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.59 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: IA2BPCDEVAPP.imzcloud.ibmammsap.local NodeAlias: 10.133.16.48 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3864815:ia1




1-338534171 (Sev1) - Need *LIN* OS performer to check
Customer: SMRT Corporation Ltd
Reported by: Uma Maheshwar Dev Bontala
Phone:+65 (6554) 8535
E-Mail:umamaheshwar@smrt.com.sg
Priority:1: Very High
SAP Incident Number:0000277248/2018

Please provide step-by-step instructions on how to reproduce your issue:
 
The files are not getting encrypted on EP1 CLDERPAPPP1	10.198.0.71
Script is :  (/usr/IDEALConnect/ idea_new.sh )





1-338700361 / IBM MSD Infras / SEV2  - @Ravi Malik
Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local[PROBLEM:2685006]
Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local[PROBLEM:2685006] Date: Jun 7,2018 9:34 CUT Severity: Major ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.26875 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3878926:cia





1-338546437	sev3
Please provide the file size of these two servers. 




1-338185661	sev3
Summary: NTP_time_is_driffted_on_dlthdpspi.imzcloud.ibmammsap.local[PROBLEM:2352600] Date: May 25,2018 12:3 CUT Severity: Warning ResourceId: dlthdpspi TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.05 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: dlthdpspi.imzcloud.ibmammsap.local NodeAlias: 10.4.5.16 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3806910:dal



1-338704751	sev3
Host Name	CFN IP	IFN IP
EEPTST01	10.10.10.140	10.7.7.140




1-338356611	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/RPA[PROBLEM:2472368] Date: May 31,2018 12:20 CUT Severity: Minor ResourceId: iplsas4ap01 TicketGroup: ApsSAPTechnical CustomerCode: ipl InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/RPA InstanceValue: 13.89 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: iplsas4ap01.imzcloud.ibmammsap.local NodeAlias: 10.138.1.13 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/RPA AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3832591:ipl





1-338356931	sev2
Summary: ITM Agent Offline: MGGGBJPGTSX03HTTPdp:UAGENT00 Date: 05/31/2018 Severity: Major ResourceId: mgggbjpgtsx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: MGGGBJPGTSX03:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: mgggbjpgtsx03 NodeAlias: 10.5.255.28 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832365:mgg




1-338704751	sev2
Summary: ITM Agent Offline: ES1-ms3wdcwapp08_ES1_00:Ins Date: 05/31/2018 Severity: Major ResourceId: ms3wdcwapp08 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: ES1-ms3wdclv:ms3wdcwapp08:mySAP InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: ms3wdcwapp08 NodeAlias: 10.12.6.22 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832359:ms3




1-338359401	sev2
Summary: ITM Agent Offline: SPP-spsvspdsase01:Sys Date: 05/31/2018 Severity: Major ResourceId: spsvspasapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: SPP-spsvspd:spsvspasapp01:mySAP InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: spsvspasapp01 NodeAlias: 10.6.3.33 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832446:age



1-338359801
Summary: ITM Agent Offline: MGGGBJSECCX01HTTPdp:UAGENT00 Date: 05/31/2018 Severity: Major ResourceId: mgggbjseccx01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: MGGGBJSECCX01:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: mgggbjseccx01 NodeAlias: 10.133.18.163 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832142:mgg




1-338360041	10.133.18.198
Summary: ITM Agent Offline: MGGGBJQCNTX01:INTERNET00 Date: 05/31/2018 Severity: Major ResourceId: mgggbjqcntx01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: MGGGBJQCNTX01:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: mgggbjqcntx01 NodeAlias: 10.5.255.198 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832134:mgg



1-338360071	sev2
Summary: ITM Agent Offline: MGGGBJPGTSX03:UA Date: 05/31/2018 Severity: Major ResourceId: mgggbjpgtsx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: REMOTE_fmsprdrtem002 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: mgggbjpgtsx03 NodeAlias: 10.133.18.28 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832367:mgg



1-338360201	sev2
Summary: ITM Agent Offline: GD1-FRAMAGGRC0002_GD1_00:Ins Date: 05/31/2018 Severity: Major ResourceId: framaggrc0002 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mng InstanceId: GD1-framagg:framaggrc0002:mySAP InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: framaggrc0002 NodeAlias: 10.69.0.160 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832393:mng




1-338360271	sev2
Summary: ITM Agent Offline: MGGGBJSGTSX03:INTERNET00 Date: 05/31/2018 Severity: Major ResourceId: mgggbjsgtsx03 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: MGGGBJSGTSX03:UA InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: mgggbjsgtsx03 NodeAlias: 10.5.255.189 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832338:mgg


	
1-338360321	sev2
Summary: ITM Agent Offline: HP1-tdmprdhana:tdmprdecc:mySAP Date: 05/31/2018 Severity: Major ResourceId: tdmprdecc TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: tdm InstanceId: REMOTE_fmsprdrtem001 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: tdmprdecc NodeAlias: 10.4.20.31 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832505:tdm




1-338360371	sev2
Summary: ITM Agent Offline: RPP-spsvepaeapp01_RPP_05:Ins Date: 05/31/2018 Severity: Major ResourceId: spsvepaeapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: RPP-spsvepd:spsvepaeapp01:mySAP InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: spsvepaeapp01 NodeAlias: 10.6.3.12 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832398:age




1-338360381	sev2
Summary: ITM Agent Offline: EPP-spsvepdehdb01:Sys Date: 05/31/2018 Severity: Major ResourceId: spsvepaeapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: EPP-spsvepd:spsvepaeapp01:mySAP InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: spsvepaeapp01 NodeAlias: 10.6.3.12 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832394:age


-----------------------------------------------------------------------------------------------------------------------


8 June

1-338372491	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap[PROBLEM:2475665] Date: May 31,2018 15:10 CUT Severity: Minor ResourceId: lonmagspo0001 TicketGroup: ApsSAPTechnical CustomerCode: mng InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap InstanceValue: 20 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: LONMAGSPO0001.imzcloud.ibmammsap.local NodeAlias: 10.69.0.35 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3833553:mng



1-338546437	sev3
File Size of EQ2 & EQ3



1-338092123	completed the change




1-338736621 Manitoba Telecom Services - SAP HEC-AMM 1-Critical
Summary: Zabbix_agent_on_bodsqas01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2713148] Date: Jun 8,2018 8:40 CUT Severity: Critical ResourceId: bodsqas01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: bodsqas01.imzcloud.ibmammsap.local NodeAlias: 10.74.6.47 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: 




1-338736811	se1
Summary: SAP SolMan Sys=DM1_DAL09AMMSOL04,MO=A1ASHP01,Alert=Database Unavailable,Desc=The availability checks for database A1ASHP01 have failed. This means that the database could not be connected from Solution Manager via the DBACOCKPIT DB connection. You should Date: 06/08/2018 Severity: Critical TicketGroup: ApsSAPTechnical CustomerCode: a1a InstanceId: DM1_DAL09AMMSOL04:A1ASHP01:Database Unavailable InstanceValue: Database Unavailable:A1ASHP01 InstanceSituation: SAP Solman MAI Alert occurred ComponentType: Application Component: SAP SubComponent: Alert ApplId: MYSAP Node: a1a_DAL09AMMSOL04_a1a NodeAlias: DAL09AMMSOL04 Manager: DAL09AMMSOL04 Agent: EIF Probe on ri3pa010 AlertKey: msd_solminbx_gsa1_msa_prod AlertGroup: ITM_SAP_MAI_ALERTS EventKey: USRD0P0MSDP:3883839:a1a

dalhana-512-9.xsportal.local	Dallas 9
CentOS
Private IP: 10.121.75.188
root/Ycs4zMcb



1-338737971 Manitoba Telecom Services - SAP HEC-AMM 1-Critical
Summary: Zabbix_agent_on_mtsbodsqas01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2714081] Date: Jun 8,2018 10:2 CUT Severity: Critical ResourceId: mtsbodsqas01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: mtsbodsqas01.imzcloud.ibmammsap.local NodeAlias: 10.74.6.47 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3884012:mtb




1-338740231 Manitoba Telecom Services - SAP HEC-AMM 1-Critical-
Summary: Zabbix_agent_on_R3QATapp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2714142] Date: Jun 8,2018 10:8 CUT Severity: Critical ResourceId: r3qatapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: R3QATapp.imzcloud.ibmammsap.local NodeAlias: 10.74.6.43 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3884022:mtb


  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  4822 root      20   0 38652 5560 2444 R 99.3  0.0 237:31.04 saposcol

5:32:44 up 28 days, 13:36,  1 user,  load average: 32.24, 31.72, 31.40
Tasks: 362 total,   3 running, 359 sleeping,   0 stopped,   0 zombie
Cpu(s): 30.9%us, 20.1%sy,  0.0%ni, 48.8%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.903G total,   34.020G used,   28.883G free, 1456.977M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   13.618G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  4822 root      20   0 38656 5564 2444 R 99.4  0.0 239:04.26 saposcol





1-338738051 -- Manitoba Telecom Services - SAP HEC-AMM  SEV1-
Summary: Zabbix_agent_on_prdbodsapp01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2714217] Date: Jun 8,2018 10:16 CUT Severity: Critical ResourceId: prdbodsapp01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: prdbodsapp01.imzcloud.ibmammsap.local NodeAlias: 10.74.5.17 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3884044:mtb

nning, 272 sleeping,   0 stopped,   0 zombie
Cpu(s): 12.9%us, 16.9%sy,  0.0%ni, 70.2%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.341G total, 9384.453M used,   22.176G free,  754.910M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free, 3182.949M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  9409 root      20   0 37400 4808 2200 R 98.9  0.0 185:24.56 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile





1-338740361
Summary: Zabbix_agent_on_r3devapp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2714527] Date: Jun 8,2018 10:29 CUT Severity: Critical ResourceId: r3devapp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: r3devapp.imzcloud.ibmammsap.local NodeAlias: 10.74.6.41 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3884197:mtb

                                                                                                        26(sapsys_ww)
[root@r3devapp ~]# uptime
 07:09:09 up 49 days, 14:03,  1 user,  load average: 13.54, 13.30, 13.28
[root@r3devapp ~]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  4293) is running...
[root@r3devapp ~]# top -M
top - 07:10:04 up 49 days, 14:04,  1 user,  load average: 13.45, 13.30, 13.28
Tasks: 358 total,   2 running, 356 sleeping,   0 stopped,   0 zombie
Cpu(s):  7.7%us, 18.2%sy,  0.0%ni, 74.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.342G total,   29.351G used, 2039.164M free,  970.074M buffers
Swap:   20.000G total,    0.000k used,   20.000G free,   11.738G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  5372 root      20   0 43616 7348 2708 R 99.5  0.0 362:59.45 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile





1-338741011 Manitoba Telecom Services - SAP- 1-Critical
Summary: Zabbix_agent_on_prdsap1app.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2716094] Date: Jun 8,2018 11:40 CUT Severity: Critical ResourceId: prdsap1app TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: prdsap1app.imzcloud.ibmammsap.local NodeAlias: 10.74.5.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3884791:mtb



1-338737441    SAP09    2-Urgent    Manitoba Telecom Services - SAP HEC-AMM
Summary: Processor_load_is_too_high_on_mtsbodsqas01.imzcloud.ibmammsap.local[PROBLEM:2713258] Date: Jun 8,2018 8:51 CUT Severity: Major ResourceId: mtsbodsqas01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mtb InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.015 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: mtsbodsqas01.imzcloud.ibmammsap.local NodeAlias: 10.74.6.47 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3883810:mtb




1-338733391    SAP09    2-Urgent    Manitoba Telecom Services - SAP HEC-AMM
mtsbodsqas01    10.74.6.47 , DF is getting hung on this server. Please check NFS mounts. Backups are affected.

Summary: TSM: mon01ammtsm001.ibmammsap.local ANR2578W Schedule SYBLOG_LIN_0045 in domain DFL_N_SYBLOG for node MTB_MTSBODSQAS01_SYBLOG has missed its scheduled start up window.~ Date: 06/08/18 00:45 CDT Severity: Minor ResourceId: mtsbodsqas01 TicketGroup: AMM-BUR CustomerCode: mtb InstanceId: 2578 InstanceValue: ANR2578W Schedule SYBLOG_LIN_0045 in domain DFL_N_SYBLOG for nod ComponentType: ManagementInfrastructure Component: TSM Node: MTSBODSQAS01 NodeAlias: 146.89.141.178 Manager: mon01ammtsm001.ibmammsap.local Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: TSM:TSM_SERVER:MON01AMMTSM001 AlertGroup: TSM_SERVER_EVENT EventKey: USRD0P0MSDP:3883264:mtb



------------------------------------------------------------------------------------------------------------------------

11 June


10.134.2.14
mounted the FS for AGEAS server


1-338811441 - IBM AMM Infrastructure - Sev2
Summary: Processor_load_is_too_high_on_HKG02AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:2795038] Date: Jun 11,2018 10:6 CUT Severity: Major ResourceId: hkg02ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 8.315 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: HKG02AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.141.36 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3896825:amm




AGEAS cloning

amit dayal for the specs

anthony pedano
10.92.99.133	10.6.1.34	A0EASG012XVM011		svmd1srv0


svmd1srv0-CLONE to be renamed as svmh1srv0 10.6.1.164

svmh1srv0 to go down  SVMH1SRV0 	10.6.1.164	10.92.99.164 	







1-338372881	sev 3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sybase/BD1[PROBLEM:2476861] Date: May 31,2018 16:39 CUT Severity: Minor ResourceId: ms3wdcladb13 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_OS_Linux:Free_disk_space_on_/sybase/BD1_(percentage) InstanceValue: 15.96 % ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Free_disk_space_on_/sybase/BD1_( Node: ms3wdcladb13.imzcloud.ibmammsap.local NodeAlias: 10.12.6.29 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Free_disk_space_on_/sybase/BD1_(percentage) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3833884:ms3

[root@ms3wdcladb13 ibmrmalik]# df -h /sybase/BD1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/bd1datavg-bd1sybase_lv
                       13G   11G  1.6G  88% /sybase/BD1

[root@ms3wdcladb13 BD1]# find . -xdev -type f -size +1000000
./ASE-16_0/bin/diagserver
./data/sybmgmtdb.dat
./data/IBM_DBHEALTH_data.dat
./data/sysprocs.dat




1-338451621	sev3
Summary: NTP_time_is_driffted_on_wdctfshnadr01.imzcloud.ibmammsap.local[PROBLEM:2529078] Date: Jun 2,2018 20:12 CUT Severity: Warning ResourceId: wdctfshnadr01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: toy InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.22 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: wdctfshnadr01.imzcloud.ibmammsap.local NodeAlias: 10.12.0.187 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3845031:toy	



1-338451791	sev3
Summary: NTP_time_is_driffted_on_sjmdmpdb01.imzcloud.ibmammsap.local[PROBLEM:2529161] Date: Jun 2,2018 20:24 CUT Severity: Warning ResourceId: sjmdmpdb01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ju1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Time-offset InstanceValue: -5.28 sec/day ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Time-offset Node: sjmdmpdb01.imzcloud.ibmammsap.local NodeAlias: 10.198.11.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3845070:ju1

---------------------------------------------------------------------------------------------------------------------------------

12 June



1-338842321 SMRT Corp - SAP HEC-AMM 1-Critical
Summary: Zabbix_agent_on_CLDERPAPPD1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2828915] Date: Jun 12,2018 10:55 CUT Severity: Critical ResourceId: clderpappd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: sm5 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: CLDERPAPPD1.imzcloud.ibmammsap.local NodeAlias: 10.198.0.208 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3902590:sm5




1-338362361	sev2
Summary: ITM Agent Offline: SD1-ms3wdcap:ms3wdcappsd1:mySAP Date: 05/31/2018 Severity: Major ResourceId: ms3wdcappsd1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ms3 InstanceId: REMOTE_fmsprdrtem003 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: ms3wdcappsd1 NodeAlias: 10.12.6.65 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832257:ms3



1-338830518
AGEAS
10.6.1.24

            Total    Copied   Skipped  Mismatch    FAILED    Extras
 Dirs :    132312    132312         0         0         0         0
Files :     67611     67611         0         0         0         0
Bytes :   2.843 g   2.843 g         0         0         0         0
Times :   0:31:44   0:06:06                       0:00:00   0:25:38


Speed :             8332180 Bytes/sec.
Speed :             476.771 MegaBytes/min.
Ended : Tuesday, June 12, 2018 11:39:20 PM








1-338066933
HK
LBDBOPPRDAPP4 	10.8.8.90	10.65.2.90
-------------------------------------------------------------------------------------------------------------------------------------

13 Jun

1-338550121 - DT1 - Some AL11 dir authoritzation issue 
SMTMDEVDT1	10.78.22.41    Paris






1-338873891 - IBM AMM Infrastructure - Sev2
Summary: Processor_load_is_too_high_on_dal09ammsrtr2.imzcloud.ibmammsap.local[PROBLEM:2845637] Date: Jun 13,2018 8:31 CUT Severity: Major ResourceId: dal09ammsrtr2 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.005 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsrtr2.imzcloud.ibmammsap.local NodeAlias: 146.89.140.28 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3906807:amm





1-338870071 - IBM AMM Infrastructure - Sev2
Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local[PROBLEM:2844591] Date: Jun 13,2018 7:3 CUT Severity: Major ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.05375 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3906520:cia





1-338877831 - Meggitt Plc (MGG) - Sev1 
Summary: Zabbix_agent_on_MGGGBJSGTSX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2847410] Date: Jun 13,2018 10:39 CUT Severity: Critical ResourceId: mgggbjsgtsx02 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: mgg InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: MGGGBJSGTSX02.imzcloud.ibmammsap.local NodeAlias: 10.133.18.184 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3907161:mgg






10.92.99.133	10.6.1.34	A0EASG012XVM011		svmd1srv0


1-338899549
cloned VM is svmd1srv0-CLONE
rename and change back details for 
svms1srv0	10.92.99.147	10.6.1.147






1-338876791 - MSC Industrial Supply Co. - Sev2
Summary: NTP_time_is_driffted_on_ms3wdcladb14.imzcloud.ibmammsap.local[PROBLEM:2847240] Date: Jun 13,2018 10:35 CUT Severity: Major ResourceId: ms3wdcladb14 TicketGroup: AMM-DELIVERY-TECH CustomerCode: ms3 InstanceId: Zabbix-Template_OS_Linux:Time-offset InstanceValue: 5.02 sec/day ComponentType: ZABBIX Component: Template_OS_Linux SubComponent: Time-offset Node: ms3wdcladb14.imzcloud.ibmammsap.local NodeAlias: 10.12.6.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: Template_OS_Linux:Time-offset AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3907141:ms3

------------------------------------------------------------------------------------------------------------------------------------------

16 June


1-338899549	sev3
cloned VM is svmd1srv0-CLONE
rename and change back details for 
svms1srv0	10.92.99.147	10.6.1.147



1-338972131	sev1
Summary: CI:EEM: Logon Error on DAL_dlthqehap (SID=HQE SN=00), System not available Details: The script could not be executed successfully.Details can be found in the <a href="http://dal09ammsol04.imzcloud.ibmammsap.local:8000/sap/bc/webdynpro/sap/diag_app_start Date: 06/15/2018 Severity: Critical ResourceId: dlthqehap TicketGroup: ApsSAPTechnical CustomerCode: dal InstanceId: DM1_DAL09AMMSOL04:CI_DALHQE_00_dlthqehap_GUI:UX Script Availability Alert InstanceValue: UX Script Availability Alert:CI_DALHQE_00_dlthqehap_GUI InstanceSituation: SAP Solman MAI Alert occurred ComponentType: Application Component: SAP SubComponent: Alert ApplId: MYSAP Node: dlthqehap NodeAlias: DAL09AMMSOL04 Manager: DAL09AMMSOL04 Agent: EIF Probe on ri3pa010 AlertKey: msd_solminbx_gsa2_msa_prod AlertGroup: ITM_SAP_MAI_ALERTS EventKey: USRD0P0MSDP:3923588:dal




1-338972511  -  P1  - PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)
Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:2919092] Date: Jun 16,2018 0:28 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3923727:pnc

[root@C1ECCP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK

[root@C1ECCP ibmrmalik]# df -h /mnt/sapexchangeIT
Filesystem            Size  Used Avail Use% Mounted on
//10.3.1.1/SAPEXCHANGE/
                      3.3T  2.5T  892G  74% /mnt/sapexchangeIT

[root@C1ECCP sapexchangeIT]# vi testrm.txt
[root@C1ECCP sapexchangeIT]# ls -ltr |grep testrm.txt
-rwxr-xr-x. 0 ecpadm sapsys 11 Jun 16 00:56 testrm.txt




OS Windows 1-338943231 IAAS Server - Unable to login





1-338972481  -  P2  -  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)
Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local[PROBLEM:2919094] Date: Jun 16,2018 0:28 CUT Severity: Major ResourceId: c1bwd TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1BWD.imzcloud.ibmammsap.local NodeAlias: 10.199.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3923728:pnc 

//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

[root@C1BWD sapexchangePT]# cd  /mnt/sapexchangePT
[root@C1BWD sapexchangePT]# vi testrm.txt
[root@C1BWD sapexchangePT]# sh /var/lib/zabbix/check_rw_mounts.sh
OK
[root@C1BWD sapexchangePT]# rm testrm.txt
rm: remove regular file `testrm.txt'? y




1-338973451  -  P1  -  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)
Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:2920426] Date: Jun 16,2018 2:13 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangePT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3923978:pnc

[root@C1ECCP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK
[root@C1ECCP ibmrmalik]# cd /mnt/sapexchangePT
[root@C1ECCP sapexchangePT]# vi ravitest.txt
[root@C1ECCP sapexchangePT]# rm ravitest.txt
rm: remove regular file `ravitest.txt'? y





1-338973551  -  P2  -  IBM MSD Infras - Cloud APPS
Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local[PROBLEM:2920718] Date: Jun 16,2018 2:37 CUT Severity: Major ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 2.66125 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: 0f.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3924040:cia





1-338362961	sev2
Summary: ITM Agent Offline: PQ2-ahecq2hdb:ahecq2sap01:mySAP Date: 05/31/2018 Severity: Major ResourceId: ahecq2sap01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: a1a InstanceId: REMOTE_fmsprdrtem001 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: ahecq2sap01 NodeAlias: 10.4.10.51 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:3832511:a1a	





1-338974461
1GB space to FS /usr/sap  on smpsd1srv0	10.6.1.51
[root@smpsd1srv0 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/md1appvg-usrsap_lv
                     1008M  957M     0 100% /usr/sap
[root@smpsd1srv0 ibmrmalik]# vgs md1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  md1appvg   1  13   0 wz--n- 128.00g 38.00g

lvextend -L +1G  /dev/mapper/md1appvg-usrsap_lv
resize2fs /dev/mapper/md1appvg-usrsap_lv




1-338974431  -  P2  -  AGEAS - SAP HEC-AMM
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/tmp[PROBLEM:2921386] Date: Jun 16,2018 3:41 CUT Severity: Major ResourceId: smpsd1srv0 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: age InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp InstanceValue: 7.47 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_disk_space_on_OS_filesystem Node: smpsd1srv0.imzcloud.ibmammsap.local NodeAlias: 10.6.1.51 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_disk_space_on_OS_filesystem_/tmp AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3924182:age




1-338975041  -  P2  -  IBM AMM Infrastructure
ummary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:2922210] Date: Jun 16,2018 5:13 CUT Severity: Major ResourceId: sng01ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 0.975 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SNG01AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.164 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3924383:amm




1-338954661  -  P1 -  IBM AoD Business Systems
Summary: Free_disk_space_is_less_than_5%_on_volume_/TSMLOGS/TLOG[PROBLEM:2906900] Date: Jun 15,2018 15:9 CUT Severity: Critical ResourceId: ri3vw035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ibs InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/TSMLOGS/TLOG InstanceValue: 4.94 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: hkg02ammtsm001.imzcloud.ibmammsap.local NodeAlias: 146.89.141.50 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/TSMLOGS/TLOG AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3919127:ibs

[root@hkg02ammtsm001 ibmrmalik]# df -h /TSMLOGS/TLOG
Filesystem                         Size  Used Avail Use% Mounted on
/dev/mapper/tsmtlog_vg-tsmtlog_lv  1.1T  1.1T  594M 100% /TSMLOGS/TLOG




1-338965311	se1
Summary: Free_disk_space_is_less_than_5%_on_volume_/sapmnt/SMJ[PROBLEM:2911916] Date: Jun 15,2018 18:55 CUT Severity: Critical ResourceId: agdb2r06a TicketGroup: ApsSAPTechnical CustomerCode: app InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/SMJ InstanceValue: 0 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: agdb2r06a.imzcloud.ibmammsap.local NodeAlias: 10.138.11.24 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/sapmnt/SMJ AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3921665:app

[root@agdb2r06a ibmrmalik]# df -h /sapmnt/SMJ
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/smjappvg-smjsapmnt_lv
                       16G   16G     0 100% /sapmnt/SMJ


--------------------------------------------------------------------------------------------------------------------------------------

17 June


1-338995721    1-Critical    Inter Pipeline Ltd        Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2935110] Date: Jun 16,2018 23:57 CUT Severity: Critical ResourceId: iplsas4ax01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ipl InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IPLsas4ax01.imzcloud.ibmammsap.local NodeAlias: 10.138.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927324:ipl




1-338994861	sev2
Summary: Lack_of_free_swap_space_on_LON02AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:2935336] Date: Jun 17,2018 0:15 CUT Severity: Major ResourceId: lon02ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.93 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: LON02AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.100 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927366:amm




1-338999241    1-Critical    IBM AMM Infrastructure        Summary: Zabbix_agent_on_LON02AMMSOL04.imzcloud.ibmammsap.local_is_unavailable
A0CXUK014XVM001




1-338999521    1-Critical    Inter Pipeline Ltd        Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2936575] Date: Jun 17,2018 2:28 CUT Severity: Critical ResourceId: iplsas4ax01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ipl InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IPLsas4ax01.imzcloud.ibmammsap.local NodeAlias: 10.138.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927683:ipl




1-338998281    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_LON02AMMSOL04.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_LON02AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:2936155] Date: Jun 17,2018 1:41 CUT Severity: Major ResourceId: lon02ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 9.1525 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: LON02AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.100 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927564:amm



1-338999401 2-Urgent    IBM MSD Infras - Cloud APPS  Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local[PROBLEM:2936451] Date: Jun 17,2018 2:15 CUT Severity: Major ResourceId: ri3pa035 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: cia InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.81375 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: dal09ammsol01.imzcloud.ibmammsap.local NodeAlias: 146.89.140.30 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927638:cia

2:11:06 up 40 days, 11:57,  1 user,  load average: 5.88, 7.23, 11.80
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
ibmrmali pts/1    146.89.140.60    22:11    0.00s  0.01s  0.03s sshd: ibmrmalik
[root@dal09ammsol01 ibmrmalik]# top -M
top - 22:11:44 up 40 days, 11:57,  1 user,  load average: 10.40, 8.11, 11.92
Tasks: 1034 total,   3 running, 1031 sleeping,   0 stopped,   0 zombie
Cpu(s): 21.8%us,  1.3%sy,  0.0%ni, 32.4%id, 44.3%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    31.315G total,   30.838G used,  488.840M free, 1826.770M buffers
Swap:   12.000G total, 3151.137M used, 9136.859M free,   15.337G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
14833 dsmadm    20   0 6961m 305m 184m R 82.6  1.0   9:57.56 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
17642 db2dsm    20   0 11.9g 3.2g 2.7g S 29.4 10.1   1579:19 db2sysc 0
24369 dsmadm    20   0 6913m 865m 816m R 14.9  2.7   1:47.20 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
 7646 dsmadm    20   0 6911m 787m 742m S 10.6  2.5   0:55.14 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
17960 dsmadm    20   0 6902m 433m 397m S  8.6  1.4   0:12.56 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01




1-338995801    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM        Summary: Lack_of_free_swap_space_on_DLTHPEHP1.imzcloud.ibmammsap.local
Summary: Lack_of_free_swap_space_on_DLTHPEHP1.imzcloud.ibmammsap.local[PROBLEM:2935407] Date: Jun 17,2018 0:22 CUT Severity: Major ResourceId: dlthpehp1 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: dal InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.94 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: DLTHPEHP1.imzcloud.ibmammsap.local NodeAlias: 10.4.5.53 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927391:dal



1-338994161    2-Urgent    Apple Leisure Group - SAP HEC-AMM        Summary: Lack_of_free_swap_space_on_USSAPASP.imzcloud.ibmammsap.local
Summary: Lack_of_free_swap_space_on_USSAPASP.imzcloud.ibmammsap.local[PROBLEM:2933497] Date: Jun 16,2018 21:14 CUT Severity: Major ResourceId: ussapasp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: av1 InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% InstanceValue: 49.93 % ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Free_swap_space_in_% Node: USSAPASP.imzcloud.ibmammsap.local NodeAlias: 10.68.213.14 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Free_swap_space_in_% AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3926989:av1

[root@USSAPASP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            15         15          0          2          0          3
-/+ buffers/cache:         11          4
Swap:           13          6          6




1-339000061    1-Critical     Inter Pipeline Ltd Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2941475] Date: Jun 17,2018 4:21 CUT Severity: Critical ResourceId: iplsas4ax01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ipl InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IPLsas4ax01.imzcloud.ibmammsap.local NodeAlias: 10.138.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927931:ipl

top - 22:32:19 up 8 days, 14:22,  1 user,  load average: 96.28, 96.14, 96.20
Tasks: 482 total,   1 running, 481 sleeping,   0 stopped,   0 zombie
Cpu(s):  4.7%us,  8.2%sy,  0.0%ni, 87.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.900G total,   24.999G used,   37.902G free, 1069.035M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   16.787G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  9586 root      20   0 38188 5668 2212 S 100.0  0.0 361:18.28 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile



1-338998861    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local
Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local[PROBLEM:2941428] Date: Jun 17,2018 4:15 CUT Severity: Major ResourceId: sng01ammsol04 TicketGroup: AMM-DELIVERY-TECH CustomerCode: amm InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) InstanceValue: 1.705 ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Processor_load_(1_min_average_pe Node: SNG01AMMSOL04.imzcloud.ibmammsap.local NodeAlias: 146.89.140.164 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Processor_load_(1_min_average_per_core) AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927907:amm



1-338760650-Meghna Group Of Industries (MG2)-16-Jun-2018 11:00:00 PM(Pacific Time)	Please increase SWAP
Hello Team.
Please increase SWAP space for   DEV server(s) :

MG2ERPDEVCAPP 
10.198.4.12

/dev/mapper/VolGroup-lv_swap 	swap                    swap    defaults        0 0

[root@MG2ERPDEVCAPP ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   1   7   0 wz--n- 39.51g 2.50g

[root@MG2ERPDEVCAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          4          0          4
-/+ buffers/cache:          6          4
Swap:            7          7          0

sdg

vgextend VolGroup /dev/sdg


[root@MG2ERPDEVCAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11          4          7          0          0          0
-/+ buffers/cache:          3          8
Swap:           27          0         27


[root@MG2ERPDEVCAPP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            11          4          7          0          0          0
-/+ buffers/cache:          3          8
Swap:           49          0         49

swap extended by 20GB
add additional 22GB

  484  2018-06-17 12:20:15 vgs VolGroup
  485  2018-06-17 12:20:34 lsblk
  486  2018-06-17 12:26:02 lsblk
  487  2018-06-17 12:29:48 vgextend VolGroup /dev/sdg
  488  2018-06-17 12:29:55 vgs VolGroup
  489  2018-06-17 12:30:31 swapoff -v /dev/mapper/VolGroup-lv_swap
  490  2018-06-17 12:39:44 free -g
  491  2018-06-17 12:40:38 lvextend /dev/mapper/VolGroup-lv_swap -L +20G
  492  2018-06-17 12:40:58 mkswap /dev/mapper/VolGroup-lv_swap
  493  2018-06-17 12:41:07 swapon -va
  494  2018-06-17 12:41:13 free -g
  495  2018-06-17 12:46:00 exit
  496  2018-06-17 12:46:15 hostname -f
  497  2018-06-17 12:46:29 vi /etc/hosts
  498  2018-06-17 12:47:43 exit
  499  2018-06-17 12:48:55 free -g







1-338998711
RHEL
SNG
10.6.2.11
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap[PROBLEM:2940626] Date: Jun 17,2018 3:7 CUT Severity: Critical ResourceId: sveq1srv0 TicketGroup: ApsSAPTechnical CustomerCode: age InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap InstanceValue: 5 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: sveq1srv0.imzcloud.ibmammsap.local NodeAlias: 10.6.2.11 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927766:age

[root@sveq1srv0 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/rq1appvg-rq1usrsap_lv
                      3.0G  2.7G  144M  96% /usr/sap

[root@sveq1srv0 ibmrmalik]# vgs rq1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  rq1appvg   1  10   0 wz--n- 128.00g 47.00g



lvextend -L +1G  /dev/mapper/rq1appvg-rq1usrsap_lv
resize2fs /dev/mapper/rq1appvg-rq1usrsap_lv






1-339000211    1-Critical     Inter Pipeline Ltd     Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable
Summary: Zabbix_agent_on_IPLsas4ax01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:2941764] Date: Jun 17,2018 4:49 CUT Severity: Critical ResourceId: iplsas4ax01 TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: ipl InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Agent_availability ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Agent_availability Node: IPLsas4ax01.imzcloud.ibmammsap.local NodeAlias: 10.138.2.31 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Agent_availability AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3927976:ipl

top - 22:59:24 up 8 days, 14:49,  1 user,  load average: 96.25, 96.19, 96.18
Tasks: 482 total,   2 running, 480 sleeping,   0 stopped,   0 zombie
Cpu(s):  4.9%us,  8.1%sy,  0.0%ni, 87.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.900G total,   25.069G used,   37.831G free, 1070.633M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   16.788G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  9586 root      20   0 38188 5668 2212 R 100.0  0.0 365:22.26 /usr/sap/hostctrl/exe/saposcol -l -w60 pf=/usr/sap/hostctrl/exe/host_profile





1-338969940
10.6.2.61
add 1 GB to /usr/sap

SVCC1SRV0:/home/ibmrmalik # df -k /usr/sap
Filesystem                     1K-blocks    Used Available Use% Mounted on
/dev/mapper/sccappvg-usrsap_lv   3063568 2927300         0 100% /usr/sap





1-338988693
LBDSP1App00	10.8.8.63     HK
Description:

311150 / 2018 Permission issue on /extdata MPA folder
System: SP1 - LBDSP1App00
Installation: 0020965273 - HANA ENTERPRISE CLOUD
Component: HEC operated by IBM - Incident (XX-HST-IBM-INC)
Customer: 1650698 - Mast Technology Services, Inc.
Access Data Missing
Connection Opened\

Br,
Mirela Chilat
Delivery Project Executive
-------------------------------------------------------------------------------------------------------------------------------------------

18 June


1-338457921 sev3
Summary: FS_is_read_only_on_PSDEVDB.imzcloud.ibmammsap.local



1-338466421	sev3	Summary: FS_is_read_only_on_MG2ERPQASDB.imzcloud.ibmammsap.local
10.198.5.11


1-338467451	sev3	Summary: FS_is_read_only_on_LONCFGCHD0003.imzcloud.ibmammsap.local


1-338472281	sev3	Summary: FS_is_read_only_on_ECCDAS00.imzcloud.ibmammsap.local



1-338486241	sev2	Summary: Free_disk_space_is_less_than_10%_on_volume_/sybase/SPA	


1-339013681    2-Urgent    IBM MSD Infras - Cloud APPS
top - 22:06:22 up 41 days, 11:52,  3 users,  load average: 26.36, 18.35, 11.34
Tasks: 1078 total,   2 running, 1076 sleeping,   0 stopped,   0 zombie
Cpu(s):  2.2%us,  0.3%sy,  0.0%ni, 24.8%id, 72.6%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.315G total,   30.877G used,  448.711M free, 2076.066M buffers
Swap:   12.000G total, 3345.484M used, 8942.512M free,   14.625G cached


  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
12857 dsmadm    20   0 6963m 236m 116m S 43.6  0.7  11:03.32 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
18480 dsmadm    20   0 6996m 282m 133m R 28.7  0.9   0:09.20 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
17642 db2dsm    20   0 11.9g 3.2g 2.7g S 13.9 10.1   1652:12 db2sysc 0



1-339013911 sev1
ZAbbix alert 



1-339014351`sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sapdb/PCS/sapdata2
[root@DLBPCSDA00 ibmrmalik]# df -h /sapdb/PCS/sapdata2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pcssapdbvg-pcssapdata2_lv
                       20G   17G  2.6G  87% /sapdb/PCS/sapdata2

[root@DLBPCSDA00 sapdata2]# find . -xdev -type f -size +1000000
./DISKD0002
./DISKD0008





1-339014291	sev3	Summary: Free_disk_space_is_less_than_20%_on_volume_/sapdb/PCS/sapdata1
[root@DLBPCSDA00 sapdata2]# df -h /sapdb/PCS/sapdata1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pcssapdbvg-pcssapdata1_lv
                       20G   16G  2.6G  87% /sapdb/PCS/sapdata1

[root@DLBPCSDA00 sapdata1]# find . -xdev -type f -size +1000000
./DISKD0001
./DISKD0007




1-339014221	sev3	
Summary: Free_disk_space_is_less_than_20%_on_volume_/sapdb/PCS/sapdata4




1-339013821	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sapdb/PCS/sapdata2
[root@DLBPCSDA00 sapdata1]# df -h /sapdb/PCS/sapdata2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pcssapdbvg-pcssapdata2_lv
                       20G   17G  2.6G  87% /sapdb/PCS/sapdata2

[root@DLBPCSDA00 sapdata2]# find . -xdev -type f -size +1000000
./DISKD0002
./DISKD0008





1-339013801	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sapdb/PCS/sapdata1

[root@DLBPCSDA00 sapdata2]# df -h /sapdb/PCS/sapdata1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pcssapdbvg-pcssapdata1_lv
                       20G   16G  2.6G  87% /sapdb/PCS/sapdata1

[root@DLBPCSDA00 sapdata1]# find . -xdev -type f -size +1000000
./DISKD0001
./DISKD0007





1-339012991	sev2
Summary: Processor_load_is_too_high_on_MGGGBJPCNTX01.imzcloud.ibmammsap.local	





1-339011571	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/SP1
[root@LBDSP1App00 ibmrmalik]# df -h /usr/sap/SP1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/sp1appvg-sp1usrSP1_lv
                       30G   23G  5.2G  82% /usr/sap/SP1

[root@LBDSP1App00 SP1]# find . -xdev -type f -size +1000000
./DVEBMGS00/data/stat77
./DVEBMGS00/data/stat106
./DVEBMGS00/data/stat105
./DVEBMGS00/data/stat79
./DVEBMGS00/data/stat101
./DVEBMGS00/data/stat78
./DVEBMGS00/data/stat81
./DVEBMGS00/data/stat82
./testfile




1-339013021    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Free_disk_space_is_less_than_10%_on_volume_D: 




1-338482001	Summary: FS_is_read_only_on_CLDPROAPDT1.imzcloud.ibmammsap.local	sev3
10.198.0.217
statfs("/opt/monitor/IBM", {f_type="EXT2_SUPER_MAGIC", f_bsize=4096, f_blocks=1255328, f_bfree=1161870, f_bavail=1096437, f_files=327680, f_ffree=322844, f_fsid={534915413, 742775588}, f_namelen=255, f_frsize=4096}) = 0
statfs("/proc/sys/fs/binfmt_misc", {f_type=0x42494e4d, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid={0, 0}, f_namelen=255, f_frsize=4096}) = 0
statfs("/var/lib/nfs/rpc_pipefs", {f_type=0x67596969, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid={0, 0}, f_namelen=255, f_frsize=4096}) = 0
statfs("/usr/interfaces", {f_type="NFS_SUPER_MAGIC", f_bsize=1048576, f_blocks=56057, f_bfree=30496, f_bavail=27644, f_files=3653632, f_ffree=3486323, f_fsid={0, 0}, f_namelen=255, f_frsize=1048576}) = 0
statfs("/SOFTWARE",

started nfs service on NFS server



1-339011131	sev3	Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
 10.4.27.13



	
1-339014981    1-Critical    IBM MSD Infras - Cloud Shared    Summary: High space used (100%) for /home/sklmdb2
146.89.141.11	





1-338943231   1-Critical   AGEAS - SAP HEC-AMM
Customer: Ageas B.V.
Reported by: A. A. Thombare
Phone:+31 302525304
E-Mail:amit.anil.thombare@sap.com
Priority:2: High
SAP Incident Number:0000309679/2018


Description:
Reconstruction
06/15/2018   04:22:53   S0017935590

IAAS Server - Unable to login
____________________
Business Consequences
06/15/2018   04:22:52   S0017935590

IAAS Server - Unable to login
____________________
Description
06/15/2018   04:22:51   S0017935590

Hi Siva / Alvin
We are facing issue while login in IAAS Windows server. Suddenly


------------------------------------------------------------------------------------------------------------------------------------------

19 June


1-339046901 - Sev1 - PNC - AMM-SAP - Siebel - Not Validated - FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local 
Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:2995745] Date: Jun 19,2018 0:28 CUT Severity: Critical ResourceId: c1eccp TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: pnc InstanceId: Zabbix-AMM_DELIVERY_TECH_LINUX:Read_Only_FS InstanceValue: CRITICAL | /mnt/sapexchangeIT filesystems are read-only ComponentType: ZABBIX Component: AMM_DELIVERY_TECH_LINUX SubComponent: Read_Only_FS Node: C1ECCP.imzcloud.ibmammsap.local NodeAlias: 10.199.1.10 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_DELIVERY_TECH_LINUX:Read_Only_FS AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:3936183:pnc

[root@C1ECCP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK
[root@C1ECCP ibmrmalik]# cd /mnt/sapexchangeIT
[root@C1ECCP sapexchangeIT]# vi testrm.txt
[root@C1ECCP sapexchangeIT]# ls -ltr |grep testrm
-rwxr-xr-x. 0 ecpadm sapsys 7 Jun 19 00:40 testrm.txt
[root@C1ECCP sapexchangeIT]# cat testrm.txt
testrm
[root@C1ECCP sapexchangeIT]# rm testrm.txt
rm: remove regular file `testrm.txt'? y




Precheck of change 1-336600305
SVMD1SRV010.6.1.34	A0EASG012XVM011		svmd1srv0
security database on the server does not have the 




1-339014981	sev1	146.89.141.11	A0CXHK012XVM002	HK
Summary: High space used (100%) for /home/sklmdb2





1-339047381    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
/mnt/sapexchangeIT



1-339046801  1     ms3wdcappsp1     Summary: SAP: SP1-ms3wdclapp49_SP1_01:Ins:SP1: an alert of class:System occured	




1-339048281    2-Urgent    IBM MSD Infras - Cloud APPS        Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local
146.89.140.30	

top - 22:16:34 up 42 days, 12:02,  2 users,  load average: 3.98, 4.44, 8.54
Tasks: 1062 total,   1 running, 1061 sleeping,   0 stopped,   0 zombie
Cpu(s): 10.8%us,  1.1%sy,  0.0%ni, 38.3%id, 49.7%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    31.315G total,   30.490G used,  845.496M free, 2171.738M buffers
Swap:   12.000G total, 3164.934M used, 9123.062M free,   14.584G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  996 dsmadm    20   0 6963m 259m 139m S 53.8  0.8  13:04.29 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
17642 db2dsm    20   0 11.9g 3.2g 2.8g S 18.2 10.2   1742:54 db2sysc 0





1-339043891	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.78.22.13

[root@smgwdevdq1 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  3.5G  1.1G  77% /var




1-339043711   sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var



1-339042871   sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_C:
10.6.1.37    windows 




1-339050831    1-Critical    IBM MSD Infras - Cloud APPS        Summary: Zabbix_agent_on_0f.imzcloud.ibmammsap.local_is_unavailable




1-339042421	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/tempbackup	
10.12.6.22





1-339036781	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap
10.68.210.12




1-339033681  sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/interfaces/HDE
10.4.5.12




1-339033291	sev2
Summary: Processor_load_is_too_high_on_LBDMP1PRDDB1.imzcloud.ibmammsap.local
10.8.8.72




1-339032681	3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/SP1
10.133.15.13




1-339032151	3
Summary: FS_is_read_only_on_sved1srv0.imzcloud.ibmammsap.local
10.6.1.11



Create cron job to clear cache.
SP1 / SPJ DB	ms3wdcladb48	     10.12.7.37
SP1 / SPJ app ms3wdclapp49    10.12.7.38  




1-339026321	sev3
Summary: NTP_time_is_driffted_on_ageSNG01web01.imzcloud.ibmammsap.local
 10.6.3.100



1-339051081    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Processor_load_is_too_high_on_PECAP01.imzcloud.ibmammsap.local[PROBLEM:2999223] Date: Jun
 10.13.1.12


1-339051041    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local[PROBLEM:2999211] Date: J
 10.13.1.12




1-338806621
/usr/sap/saprouter

# ./saprouter -r  >> start command 

SSGSA0119 	100.126.0.13	10.24.143.205
https://sites.google.com/site/peterphdomantay/home/sap-netweaver-for-basis/creating-sap-router-as-a-service





1-339055134
SVMD1SRV0 - Server restart

Customer: 	Ageas B.V.
Reported by: 	A. A. Thombare
Phone: 	+31 302525304
E-Mail: 	amit.anil.thombare@sap.com
Priority: 	3: Medium
SAP Incident Number: 	0000314338 	2018


Description:
"Hi Team,
Could you please restart server - SVMD1SRV0
We are facing issue in DB backup on this server.
Alvin updated there was issue on this server with domain, that might
cause issue.
 
Server  - svmd1srv0
 
IP Address - 10.92.99.133
 
Server type - Windows
 
Time - As early as we can"


10.92.99.133	10.6.1.34	A0EASG012XVM011		svmd1srv0




1-339052951	sev2
IFN IP is 10.6.4.206
*** Details of Generic Service Request - DO NOT CHANGE ***

Hi Support

Please set yhisftp to no expiry password, and unable login for yhisftp.

Regards
Wilson

--------------------------------------------------------------------------------------------------------------------------------------------

20 Jun

1-339083821	sev2
Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
10.199.2.31
CRITICAL | /mnt/sapexchangeIT




1-339081901	sev3
Summary: NTP_time_is_driffted_on_ageSNG01web01.imzcloud.ibmammsap.local	
 10.6.3.100




1-339079491	sev2
Summary: Processor_load_is_too_high_on_PECAP01.imzcloud.ibmammsap.local
10.13.1.12



1-339079461	sev2
Summary: Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local
10.13.1.12



1-339076851	sev2
Summary: Processor_load_is_too_high_on_SSMCI000.imzcloud.ibmammsap.local
10.5.2.10



1-339074361     sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap[PROBLEM:301	




1-339072021	sev3
Summary: NTP_time_is_driffted_on_SVWS1SRV0.imzcloud.ibmammsap.local
 10.6.1.152




1-339085241	sev3
Summary: NTP_time_is_driffted_on_fbqhanaapp.imzcloud.ibmammsap.local
 10.4.26.31



1-339085141	sev2
Summary: Processor_load_is_too_high_on_MGGGBJPCNTX01.imzcloud.ibmammsap.local
10.133.18.32



1-339080971	sev3
Summary: NTP_time_is_driffted_on_fbtprdbwapp1.imzcloud.ibmammsap.local
10.4.27.19




1-339075781	sev3
close ticket yesterday's issue pw non expiry Siva


1-339071891
Summary: Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.local
10.4.20.31



1-339070751	sev2
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var/opt/BESWebReportsServer
10.68.210.29



1-339070121	sev2
Summary: Lack_of_free_swap_space_on_USSAPAEPAP01.imzcloud.ibmammsap.local
10.68.213.11



1-339068891	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap
10.68.210.12


1-339085981  IBM AMM Infrastructure  P2  --
Summary: Lack_of_available_memory_on_server_ammdal13custesx002.imzcloud.ibmammsap.loca
146.89.142.201




1-339088671/P2/CCP/IBM MSD Infras - Cloud APPS/Monitoring (internal) not validated/Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local 
Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local
146.89.140.30




1-338915301  Dilip Buildcon Limited (DLB)  P3 
*** Details of Generic Service Request - DO NOT CHANGE ***

Hostname	IFN IP		CFN IP
DLBDWDAP00	10.13.2.24	172.16.22.24

Linux operating system, H2H will run on java installed at your end.
Minimum JDK versions need at your end are,
 
â€¢	7u131 
â€¢	8u131
Please upgrade to minimum version if you are using older version.
 
Once done, please download H2H Headless client 4.2.25 from below link and keep on this server.
https://drive.google.com/open?id=10aMJLgJWyUia9bIMKjhFJzvv6l4TTS5M
 
Please update once done with screenshot of below command,
java -version

For any query or concern please reach out to
Bhushan Desai
CMP Support Team â€“ UNIKEN
State Bank Global IT Centre, Om Sagar Bhavan, Nerul MIDC, Navi Mumbai â€“ 400706
C :  +91 7767001239
e-Mail id : support.uniken@sbi.co.in , support@uniken.com





1-339084426
Space reduction Janaki's request

--------------------------------------------------------------------------------------------------------------------------------------

21 June

1-338646891
chnge will start on 21st june 11:30 AM IST
CEM-AMM 3.x-Q218: Apply latest Q218 bundle  patches on RH Linux OS 



1-339108551    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent
Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
10.199.2.31	/mnt/sapexchangeIT




1-339073829	sev3
cloning
1)create clone of DEV svnd1srv0 10.92.99.132  10.6.1.33		WIn2k12R2	A0EASG012XVM010
clone everything 
2) once clone is created, look for the hotfix server svnh1srv0	10.6.1.163	10.92.99.163 2CPU 16GB
3) copy the profile and identity of svnh1srv0 which is the current original hotfix server (there is nothing inside and not used) 
4) transfer to the clone and rename it as svnh1srv0 
5) shutdown the old svnh1srv0 
 
6:47:09 AM: thewayy@my.ibm.com - Alvin YY Thew/Malaysia/IBM: so basically the same thing except on a different source this time





YHIEPS01  server with   yhisftp login id 	10.6.4.206




1-339108061	sev3
Summary: NTP_time_is_driffted_on_sjmdwdwd01.imzcloud.ibmammsap.local
 10.198.13.10





1-339105251    IBM AMM Infrastructure    2-Urgent    AMM
Summary: Lack_of_available_memory_on_server_ammdal13custesx003.imzcloud.ibmammsap.local
Node: ammdal13custesx003.imzcloud.ibmammsap.local NodeAlias: 146.89.142.201



1-339101181    IBM AMM Infrastructure    2-Urgent    AMM
Summary: Lack_of_available_memory_on_server_ammsng01custesx010.imzcloud.ibmammsap.local
Node: ammsng01custesx010.imzcloud.ibmammsap.local NodeAlias: 146.89.140.160




1-339111259    AGEAS - SAP HEC-AMM    2-Urgent    AGE



PHSBWPRD01 	PHSBWPRD01 	APP + DB 	Windows 2012R2 	10.5.6.6 


----------------------------------------------------------------------------------------------------------------------------------
22 June


[root@SNG01AMMCHEF01 ~]# knife environment list
_default
sm5_production
sm5_production_dr

CLDERPAPPD1

[root@SNG01AMMCHEF01 ~]# knife node list|grep -i CLDERPAPPD1
CLDERPAPPD1.imzcloud.ibmammsap.local


./bootstrap_v12.sh -o sm5 -n CLDERPAPPD1.imzcloud.ibmammsap.local -l -d imzcloud.ibmammsap.local -t osonly -e sm5_production





1-339124691  / Manchester City Airport Group - SAP HEC-AMM/ SEV1 
Manchester Airport Group (MNG)
LONMAGSPO0002 - IP 10.69.0.36	172.22.0.36	A0D8UK014XVM019
A0D8UK014XVM019_restore_06202018   restored one
lv extension with 10GB on /sybase/IQ1
[root@LONMAGSPO0002 SWPM]# df -h /sybase/IQ1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/iq1datavg-sybase_iq1
                       16G   14G  856M  95% /sybase/IQ1

lvextend -L +10G  /dev/mapper/iq1datavg-sybase_iq1
resize2fs /dev/mapper/iq1datavg-sybase_iq1
172.22.0.146	10.69.0.146
path 1 = /sybase/IQ1/sapdata_1/
path 2= /sybase/IQ1/saplog_1/




1-339115511    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_tor01ammsol01.imzcloud.ibmammsap.local 
146.89.141.91 	




1-339142511 2-Urgent    IBM MSD Infras - Cloud APPS
Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local
146.89.140.30

Tasks: 1058 total,   3 running, 1055 sleeping,   0 stopped,   0 zombie
Cpu(s): 15.1%us,  1.3%sy,  0.0%ni, 25.8%id, 57.6%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    31.315G total,   31.091G used,  230.344M free, 2124.793M buffers
Swap:   12.000G total, 3845.504M used, 8442.492M free,   15.260G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
16958 dsmadm    20   0 6956m 301m 191m R 66.7  0.9   6:41.69 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
17642 db2dsm    20   0 12.2g 3.1g 2.7g S  9.6  9.8   1987:14 db2sysc 0
 1468 dsmadm    20   0 6908m 593m 560m S  5.9  1.8   0:12.94 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
29381 dsmadm    20   0 8539m 2.5g  18m S  5.6  8.1 324:10.29 /usr/sap/DSM/DVEBMGS50/exe/jlaunch pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01 -DSAPINFO=DSM_50_server -nodeId=1 -file=/usr/
 2980 root      20   0 1007m 158m 4984 S  4.0  0.5   0:05.44 chef-client worker: ppid=5770;start=21:40:47;





1-339144241    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM        Summary: Lack_of_free_swap_space_on_DLTHPEHP1.imzcloud.ibmammsap.local
10.4.5.53




1-339144621    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM        Summary: Lack_of_free_swap_space_on_DLTHPGGAT.imzcloud.ibmammsap.local
10.4.5.57
[root@DLTHPGGAT ibmrmalik]# free -h
             total       used       free     shared    buffers     cached
Mem:           62G        62G       599M        21G        77M        23G
-/+ buffers/cache:        38G        23G
Swap:          20G        10G        10G




1-339144171    CI3 Certified IT Consultants for TMG (CICTMG)    3-Standard 
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.210.1.12




1-339127811    Concessionaria Aeroporto Rio de Janeiro S.A. (CON)    2-Urgent    SAPPJ
Summary: Processor_load_is_too_high_on_conspsmjavap.imzcloud.ibmammsap.local
10.16.1.88


1-339126701    Concessionaria Aeroporto Rio de Janeiro S.A. (CON)    2-Urgent    SAPPJ
Summary: Processor_load_is_too_high_on_consppoapd.imzcloud.ibmammsap.local
 10.16.1.21

----------------------------------------------------------------------------------------------------------------------------------------------------


25 June

1-339203161    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_sng01ammsol01.imzcloud.ibmammsap.local
146.89.140.157


top - 20:21:29 up 19 days, 11:53,  1 user,  load average: 1.18, 0.85, 0.78
Tasks: 492 total,   1 running, 491 sleeping,   0 stopped,   0 zombie
Cpu(s): 10.1%us,  0.3%sy,  0.0%ni, 82.2%id,  7.4%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.316G total,   31.005G used,  318.465M free,  844.957M buffers
Swap:   12.000G total, 9911.797M used, 2376.199M free,   11.054G cached




1-339205311    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local
146.89.140.164

[root@SNG01AMMSOL04 ibmrmalik]# uptime
 21:26:49 up 53 days,  9:36,  1 user,  load average: 1.89, 1.29, 1.11
[root@SNG01AMMSOL04 ibmrmalik]# top -M
top - 21:28:17 up 53 days,  9:38,  1 user,  load average: 2.17, 1.54, 1.21
Tasks: 351 total,   8 running, 343 sleeping,   0 stopped,   0 zombie
Cpu(s): 52.7%us,  7.4%sy,  0.0%ni, 10.6%id, 27.9%wa,  0.0%hi,  1.4%si,  0.0%st
Mem:    31.349G total,   30.759G used,  603.902M free,  427.879M buffers
Swap: 8191.996M total, 8191.973M used,   24.000k free,   19.737G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
33612 db2sm1    20   0 10.9g 4.1g 3.6g S 91.8 13.0  16532:10 db2sysc 0
62989 sm1adm    20   0 7008m 754m 693m R 17.9  2.4   2:06.16 dw.sapSM1_DVEBMGS00 pf=/usr/sap/SM1/SYS/profile/SM1_DVEBMGS00_SNG01AMMSOL04
34315 sm1adm    20   0 7022m 887m 813m R 14.6  2.8   7:13.36 dw.sapSM1_DVEBMGS00 pf=/usr/sap/SM1/SYS/profile/SM1_DVEBMGS00_SNG01AMMSOL04
16462 sm1adm    20   0 6903m 149m 107m S 10.3  0.5   0:07.43 dw.sapSM1_DVEBMGS00 pf=/usr/sap/SM1/SYS/profile/SM1_DVEBMGS00_SNG01AMMSOL04
58365 sm1adm    20   0 7032m 934m 847m R 10.3  2.9   9:42.86 dw.sapSM1_DVEBMGS00 pf=/usr/sap/SM1/SYS/profile/SM1_DVEBMGS00_SNG01AMMSOL04
25873 sm1adm    20   0 7016m 923m 849m R  9.9  2.9   5:58.78 dw.sapSM1_DVEBMGS00 pf=/usr/sap/SM1/SYS/profile/SM1_DVEBMGS00_SNG01AMMSOL04



1-339207471    Meggitt Plc (MGG)    2-Urgent
 10.133.18.202	/usr/sap/PGQ
[root@mgggbjqgtsy02 ibmrmalik]# df -h /usr/sap/PGQ
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pgqappvg-pgqusrPGQ_lv
                       24G   23G   60M 100% /usr/sap/PGQ
[root@mgggbjqgtsy02 ibmrmalik]# vgs gqappvg
  Volume group "gqappvg" not found
  Cannot process volume group gqappvg
[root@mgggbjqgtsy02 ibmrmalik]# vgs pgqappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  pgqappvg   1  13   0 wz--n- 128.00g 24.00g

lvextend -L +6G  /dev/mapper/pgqappvg-pgqusrPGQ_lv
resize2fs /dev/mapper/pgqappvg-pgqusrPGQ_lv




1-339211661	Summary: Processor_load_is_too_high_on_GRC01	sev3
10.68.210.15




1-339208691
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var	sev3
10.198.201.16



1-339208671   sev3
10.13.1.17
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var





1-339207961	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/[PR
10.4.1.173





1-339111259 
Server - svmd1srv0
IP Address - 10.92.99.133	10.6.1.34
06/20/2018
sql logs





1-339207691	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.78.22.20




1-339214501    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Processor_load_is_too_high_on_PECAP02.imzcloud.ibmammsap.local[PROBLEM:3128959] Date: Jun
Summary: Processor_load_is_too_high_on_PECAP02.imzcloud.ibmammsap.local
 10.13.1.13





1-339213751    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Processor_load_is_too_high_on_DLBPECAP02.imzcloud.ibmammsap.local[PROBLEM:3128957] Date: J
Summary: Processor_load_is_too_high_on_DLBPECAP02.imzcloud.ibmammsap.local
 10.13.1.13






1-339204585
P2- Folders missing
Please check why the /tmp and the sub folders are missing in ED1
CLDERPAPPD1 10.198.0.208	& EQ1  CLDERPAPPQ1 10.198.0.211



1-339204700
Server - svnd1srv0
IP address - 10.92.99.132	
IMZ: 10.6.1.33
VMWare hostname : A0EASG012XVM010
Server Type - Windows

security database does not have a computer account



--------------------------------------------------------------------------------------------------------------------------------

26  June


snapshot of SVFS1SRV0





1-339228271    Limited Brands, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_LBDBIPPRDApp1.imzcloud.ibmammsap.local
10.8.8.183



1-339242881    3-Standard    PT Blue Bird TBK (PBB)        Summary: NTP_time_is_driffted_on_PBBs4hqap00.imzcloud.ibmammsap.local
10.6.7.14



1-339244541    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_DLTHPEHP1.imzcloud.ibmammsap.local 
10.4.5.53 
  
top - 23:28:54 up 30 days, 22:49,  1 user,  load average: 11.70, 14.43, 14.15
Tasks: 529 total,  10 running, 519 sleeping,   0 stopped,   0 zombie
Cpu(s): 70.2%us,  0.5%sy,  0.0%ni, 29.2%id,  0.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    62.913G total,   62.017G used,  917.613M free,  190.203M buffers
Swap:   20.762G total,   16.152G used, 4720.090M free,   34.472G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
39616 hpeadm    20   0 59.7g  18g  16g R 100.0 28.8 751:22.99 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
31041 hpeadm    20   0 59.4g 1.9g 379m R 98.0  3.1 366:10.59 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
61297 hpeadm    20   0 58.2g 791m 457m R 93.1  1.2  37:40.78 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
53561 hpeadm    20   0 58.2g 1.3g 1.0g R 92.7  2.1  34:50.84 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
21680 hpeadm    20   0 58.2g 806m 437m R 92.4  1.3  35:34.38 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
13906 hpeadm    20   0 58.2g 891m 512m R 92.1  1.4  42:34.47 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
53488 hpeadm    20   0 58.2g 547m 206m R 92.1  0.8  34:52.61 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
55735 hpeadm    20   0 58.0g 548m 397m R 91.7  0.9  35:35.05 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1
26575 hpeadm    20   0 58.3g 892m 491m R 88.4  1.4  88:49.48 dw.sapHPE_DVEBMGS00 pf=/usr/sap/HPE/SYS/profile/HPE_DVEBMGS00_DLTHPEHP1




1-339245241    1-Critical    IBM MSD Infras - Cloud APPS        Summary: Zabbix_agent_on_dal09ammsol01.imzcloud.ibmammsap.local_is_unavailable 
146.89.140.30





1-339242311
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.13.1.17





1-339241311
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.13.1.17




1-339237931	sev3
Create folders in ES5 system (10.168.1.2)[0319102/2018]




1-339236041
Summary: NTP_time_is_driffted_on_CLDBOBIADWT1.imzcloud.ibmammsap.local
10.198.0.218






1-339245821  IBM AMM Infrastructure  P2  -- 
Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local
 146.89.140.164




1-339228121
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/trans[
10.12.6.63





1-339225911
Summary: NTP_time_is_driffted_on_YHIEQS01.imzcloud.ibmammsap.local
10.6.4.205




1-339224041
Summary: Processor_load_is_too_high_on_GRC01
10.68.210.15	Windows




1-339220501
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/ECP
 10.13.3.13




1-339207461
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/PGQ
10.133.18.202




1-339205161
Summary: NTP_time_is_driffted_on_LBDBIPPRDDB1.imzcloud.ibmammsap.local
 10.8.8.182 




1-339204041
Summary: NTP_time_is_driffted_on_sm5webdisp01.imzcloud.ibmammsap.local
 10.198.0.238



1-339243574   High Sev2
--------------------------------------------------------------------------------------------------------------------------------------


27 June


1-339243693  Egyptian Cement (ECT)  P3
ECTFIODEV
ECTFIOPRD

CFN IP	IFN IP
10.40.10.12	10.5.10.12
[root@ectfiodev ~]# df -h --total
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  2.2G  7.1G  24% /
tmpfs                 4.9G  8.0K  4.9G   1% /dev/shm
/dev/sda1             477M   79M  374M  18% /boot
/dev/mapper/VolGroup-lv_opt
                      4.9G  371M  4.2G   8% /opt
/dev/mapper/VolGroup-lv_mon
                      4.9G   11M  4.6G   1% /opt/monitor/IBM
/dev/mapper/VolGroup-lv_var
                      4.9G  2.0G  2.7G  43% /var
/dev/mapper/VolGroup-lv_tmp
                      2.0G   70M  1.8G   4% /tmp
/dev/mapper/VolGroup-lv_home
                      2.0G  3.9M  1.9G   1% /home
/dev/mapper/sources-sources_lv
                       63G   27G   32G  46% /sources
total                  96G   32G   60G  35%




10.40.10.11	10.5.10.11




1-339261031    Adama Agan Ltd. (Makhteshim) (MKM)    2-Urgent    Summary: Zabbix_agent_on_ECCDEMO_is_unavailable
10.7.9.11





1-339261561    Saudi International Petrochemical Co. (Sipchem) (SPH)    1-Critical    Summary: Zabbix_agent_on_sph-sq-dms.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:3180226] Date:    SAPPJ




1-339261051    Hadi Hamad Al-Hammam Contracting Co (HHH)    1-Critical    Summary: Zabbix_agent_on_HHHPAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:3180248] Date: Jun    SAPPJ
10.7.14.35
[root@HHHPAPP ibmrmalik]# uptime
 06:00:51 up 102 days, 13:06,  1 user,  load average: 0.01, 0.06, 0.03
[root@HHHPAPP ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  3249) is running...



1-339260541    Hadi Hamad Al-Hammam Contracting Co (HHH)    1-Critical    Summary: Zabbix_agent_on_HHHQAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:3180193] Date: Jun    SAPPJ
 10.7.14.39


1-339260391    Hadi Hamad Al-Hammam Contracting Co (HHH)    1-Critical    Summary: Zabbix_agent_on_HHHDAPP.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:3180159] Date: Jun    SAPPJ
10.7.14.37


1-339258071    Hadi Hamad Al-Hammam Contracting Co (HHH)    1-Critical    Summary: Zabbix_agent_on_hhhdhdb.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:3180133] Date: Jun    SAPPJ
10.7.14.22



1-338851391
Summary: NTP_time_is_driffted_on_ADNAELDEVDB.imzcloud.ibmammsap.local




1-338855231
Summary: NTP_time_is_driffted_on_ADNBIDEVDB.imzcloud.ibmammsap.local



1-338856431
Summary: NTP_time_is_driffted_on_smdbsbxse1.imzcloud.ibmammsap.local



1-338881441
Summary: NTP_time_is_driffted_on_ADNAELDB.imzcloud.ibmammsap.loca





1-339290831/Sev1/Concessionaria Aeroporto Rio de Janeiro S.A. (CON)/Siebel-Monitoring not validated/Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/
./Staging/SUM/abap/data/R-751BRINSAPUI.SAP
./Staging/SUM/abap/data/R-75101INSAPUI.SAP

[root@conspbw4hapq data]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  8.1G  1.2G  88% /





1-339290811  Concessionaria Aeroporto Rio de Janeiro S.A. (CON)   P2
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/
10.16.1.28



1-339288631  Concessionaria Aeroporto Rio de Janeiro S.A. (CON)  P3




1-339290101 /Sev2 / IBM AoD Business Systems /Siebel / Summary: Lack_of_available_memory_on_server_ammdal09custesx033.imzcloud.ibmammsap.local





SPSVHPIGSQL01	10.6.3.38
SPSVCPICAPP11	10.6.3.41	
SPSVWPLWAPP11	10.6.3.39
SPSVWPLWAPP12	10.6.3.40	
SPSVCPICAPP12	10.6.3.42
svnd1srv0 10.92.99.132  10.6.1.33
10.92.99.133	10.6.1.34	A0EASG012XVM011		svmd1srv0

--------------------------------------------------------------------------------------------------------------------------------------------

28 Jun


spsvcpicapp11	10.6.3.41	WIndows
spsvcpicapp12	10.6.3.42	WIndows




1-339317961    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Lack_of_free_swap_space_on_DLTHQEHAP.imzcloud.ibmammsap.local[PROBLEM:3209435] Date: Jun 2
[root@DLTHQEHAP ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         56          6         35          0         35
-/+ buffers/cache:         20         42
Swap:           20         12          7

top - 21:45:27 up 33 days, 21:40,  1 user,  load average: 0.36, 0.24, 0.14
Tasks: 389 total,   1 running, 387 sleeping,   0 stopped,   1 zombie
Cpu(s):  3.3%us,  0.5%sy,  0.0%ni, 96.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.913G total,   56.154G used, 6921.715M free,  123.973M buffers
Swap:   20.113G total,   12.612G used, 7681.359M free,   35.893G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
21709 root      20   0 4971m 2.9g 2420 S  0.0  4.6  86:11.49 196m python /usr/bin/goferd
18317 hqeadm    20   0 1507m 687m  12m S  0.0  1.1 211:50.30 125m en.sapHQE_ASCS01 pf=/usr/sap/HQE/SYS/profile/HQE_ASCS01_DLTHQEHAP
55854 hqeadm    20   0 57.9g  10g  10g S  0.0 16.6  19:06.54 115m dw.sapHQE_DVEBMGS00 pf=/usr/sap/HQE/SYS/profile/HQE_DVEBMGS00_DLTHQEHAP
20186 hqeadm    20   0 58.1g  14g  14g S  0.0 23.7 104:06.53 106m dw.sapHQE_DVEBMGS00 pf=/usr/sap/HQE/SYS/profile/HQE_DVEBMGS00_DLTHQEHAP
19784 root      20   0 19.3g 331m 4368 S  0.0  0.5  21:12.76  87m java -Dupdateagent -Djava.endorsed.dirs=. -Dsun.net.inetaddr.ttl=60 -Dsun.net.inetaddr.negative.ttl=60 gravitixagent
21609 daaadm    20   0 4978m 371m 7056 S  0.0  0.6 247:41.10  63m /usr/sap/DAA/SMDA98/exe/jstart -appTrc -nodeId=0 pf=/usr/sap/DAA/SYS/profile/DAA_SMDA98_DLTHQEHAP -hostvm -nodeName=smdagent -file=
20163 hqeadm    20   0 57.8g 9.7g 9.6g S  0.0 15.4  55:48.89  44m dw.sapHQE_DVEBMGS00 pf=/usr/sap/HQE/SYS/profile/HQE_DVEBMGS00_DLTHQEHAP
53030 hqeadm    20   0 57.9g  10g  10g S  0.0 16.5  15:05.43  44m dw.sapHQE_DVEBMGS00 pf=/usr/sap/HQE/SYS/profile/HQE_DVEBMGS00_DLTHQEHAP
20179 hqeadm    20   0 57.9g  12g  11g S  0.0 19.3  67:07.33  40m dw.sapHQE_DVEBMGS00 pf=/usr/sap/HQE/SYS/profile/HQE_DVEBMGS00_DLTHQEHAP



1-339317551    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Lack_of_free_swap_space_on_DLTHPEHP2.imzcloud.ibmammsap.local[PROBLEM:3208485] Date: Jun 2
free [root@DLTHPEHP2 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            62         40         22         21          0         23
-/+ buffers/cache:         16         46
Swap:           20         20          0

top - 21:58:53 up 32 days, 21:18,  1 user,  load average: 0.05, 0.13, 0.15
Tasks: 431 total,   2 running, 429 sleeping,   0 stopped,   0 zombie
Cpu(s): 10.3%us,  0.7%sy,  0.0%ni, 88.9%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.913G total,   40.311G used,   22.602G free,  100.996M buffers
Swap:   20.762G total,   20.713G used,   49.551M free,   23.383G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 9083 root      20   0 19.4g 103m 4676 S  0.0  0.2  21:34.06 299m java -Dupdateagent -Djava.endorsed.dirs=. -Dsun.net.inetaddr.ttl=60 -Dsun.net.inetaddr.negative.ttl=60 gravitixagent
36051 hpeadm    20   0 8135m 255m  79m S  0.0  0.4  15:45.88 150m icman -attach pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
10029 root      20   0 1963m  31m 1008 S  0.0  0.0  65:42.16  96m python /usr/bin/goferd
36061 hpeadm    20   0 58.1g 5.2g 5.1g S  0.0  8.2 144:56.44  86m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36059 hpeadm    20   0 58.1g 5.3g 5.1g S  0.0  8.4 151:57.84  84m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36098 hpeadm    20   0 58.0g 428m 380m S  0.0  0.7   1:18.03  83m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36097 hpeadm    20   0 57.9g 383m 354m S  0.0  0.6   1:00.40  78m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36075 hpeadm    20   0 58.1g 5.7g 5.5g S  0.0  9.0 191:40.12  78m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
10043 daaadm    20   0 6525m 353m 7044 S  0.7  0.5 344:07.28  71m /usr/sap/DAA/SMDA98/exe/jstart -appTrc -nodeId=0 pf=/usr/sap/DAA/SYS/profile/DAA_SMDA98_DLTHPEHP2 -hostvm -nodeName=smdagent -file=
36057 hpeadm    20   0 58.1g 5.0g 4.8g S  0.0  7.9 146:36.96  70m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36074 hpeadm    20   0 58.0g 6.4g 6.3g S  0.0 10.2 170:30.55  67m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
46453 hpeadm    20   0 58.1g 6.4g 6.2g S  8.9 10.1 185:01.99  66m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36063 hpeadm    20   0 58.0g 5.3g 5.2g S  0.0  8.4 156:34.86  66m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36067 hpeadm    20   0 58.0g 5.6g 5.5g S  0.0  8.9 168:12.43  66m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2
36055 hpeadm    20   0 58.0g 5.1g 5.0g S  0.0  8.1 155:02.73  65m dw.sapHPE_D02 pf=/usr/sap/HPE/SYS/profile/HPE_D02_DLTHPEHP2




1-339307621    IAG GBS Limited (IA1)    2-Urgent    Summary: Processor_load_is_too_high_on_IA1S4HQASAPP.imzcloud.ibmammsap.local[PROBLEM:3204413] Date:

1-339294301    IAG GBS Limited (IA1)    2-Urgent    Summary: Processor_load_is_too_high_on_IA1S4HSBXAPP.imzcloud.ibmammsap.local[PROBLEM:3199338] Date:




ECTFIODEV	10.5.10.12
ECTFIOPRD	10.5.10.11




1-339322921  IBM MSD Infras - Cloud APPS  P1
146.89.140.30




1-339323051 - P1- MS3	Ticket # 61265711
EP1 - Production system Down
Team - Please check asap.

SID -EP1	Washington DC
Hostname - 
ms3wdclapp29	10.12.7.12	
ms3wdclapp30	10.12.7.13
MDCSERVERP1	10.12.7.41	msc-phana-1024-5.imzcloud.ibmammsap.local
Private IP: 10.148.59.176	root/C2yYj5pZ
ipmi pw TGxleZ4jSg






1-339248525 restart nonprod ND1 (tomatosx) today 

10.6.1.33	SVND1SRV0   windows	A0EASG012XVM010

imzcloud.ibmammsap.local




Certified IT Consultants - TMG(CI3) 	CI3S4HANAPRDA 	10.210.1.12	10.201.0.12 	Production 	Deployed 	PRD	PRD

----------------------------------------------------------------------------------------------------------------------------------------------

2July

1-339438411    2-Urgent    Manchester City Airport Group - SAP HEC-AMM      Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/ 
10.69.0.36





1-339439681	{Meggitt Plc (MGG) --> 10.133.18.33/NCP}	London
Summary: Free_disk_space_is_less_than_5%_on_volume_/sapdb_backups/NCP
 10.133.18.33
[root@MGGGBJPCNTX02 ibmrmalik]# df -h /sapdb_backups/NCP
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/NCPsapdbbkupvg-NCP_sapdbbkup_lv
                      180G  170G   17M 100% /sapdb_backups/NCP

sdf 48 GB
vgextend NCPsapdbbkupvg /dev/sdf

lvextend -L +50G /dev/mapper/NCPsapdbbkupvg-NCP_sapdbbkup_lv
resize2fs /dev/mapper/NCPsapdbbkupvg-NCP_sapdbbkup_lv



1-339289381





1-339440821    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local 
146.89.140.36




1-339220781	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap/DT1
10.78.22.41





1-339225841	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/DB3
 10.78.22.14




1-339227651	sev2
NFS issue
SMSLTQUAQK1     10.78.24.39
SMGRCQUAQG1     10.78.24.43 , Backup of these servers are failing due to NFS issue, DF is hung. Please check



1-339331701	sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/DT1
10.78.22.41




1-339443271    3-Standard    St Jude Medical Singapore - SAP HEC        CEM-AMM 3.x- Apply latest Q218 Patches on  Servers




1-339331861	sev1
Summary: Zabbix_agent_on_SMDIDEVDD1.imzcloud.ibmammsap.local_is_unavailable
10.78.22.49




1-339332131	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/interface/dev
10.78.22.12



1-339340271
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/DO1
10.78.22.30



1-339389111	sev2
Summary: Lack_of_free_swap_space_on_smediuatuu3.imzcloud.ibmammsap.local
10.78.26.25

top - 06:12:29 up 340 days, 21:42,  1 user,  load average: 0.05, 0.08, 0.08
Tasks: 327 total,   1 running, 326 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.1%us,  0.2%sy,  0.0%ni, 99.8%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   13.988G used, 1611.871M free,  535.707M buffers
Swap: 8191.996M total, 4523.520M used, 3668.477M free, 9737.219M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 89296 uu3adm    20   0 2323m 386m 6080 S  0.0  2.4   6:28.51 960m icman -attach pf=/usr/sap/UU3/SYS/profile/UU3_D10_smedi-uat-uu3
 87306 uu3adm    20   0 1429m 3624 2236 S  0.0  0.0  12:22.70 792m en.sapUU3_ASCS00 pf=/usr/sap/UU3/SYS/profile/UU3_ASCS00_smedi-uat-uu3





1-339411521	sev2
Summary: Free_disk_space_is_less_than_10%_on_DB_volume_/db2/QX8/log_archive
10.78.24.22
[root@SMPOQUAQX8 ibmrmalik]# df -h /db2/QX8/log_archive
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/qx8archvg-qx8db2arch_lv
                       50G   43G  4.0G  92% /db2/QX8/log_archive





1-339416851	sev2
Summary: Lack_of_free_swap_space_on_smeccuatue3.imzcloud.ibmammsap.local
10.78.26.16

top - 08:06:21 up 341 days, 46 min,  1 user,  load average: 0.39, 0.54, 0.29
Tasks: 448 total,   3 running, 445 sleeping,   0 stopped,   0 zombie
Cpu(s): 11.7%us,  1.7%sy,  0.0%ni, 81.3%id,  5.2%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    31.342G total,   30.190G used, 1179.301M free,  221.523M buffers
Swap: 8191.996M total, 4216.094M used, 3975.902M free,   21.987G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 28983 ue3adm    20   0 1429m  36m  13m S  0.3  0.1  92:52.79 770m en.sapUE3_ASCS00 pf=/usr/sap/UE3/SYS/profile/UE3_ASCS00_smecc-uat-ue3
 30461 ue3adm    20   0 4822m 2.4g  32m S  0.3  7.7  31:08.89 674m icman -attach pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3
106377 ue3adm    20   0 23.8g  55m  33m S  0.0  0.2   0:02.00  18m dw.sapUE3_D10 pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3
 41665 ue3adm    20   0 23.8g  60m  36m S  0.0  0.2   0:02.00  18m dw.sapUE3_D10 pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3
 58227 ue3adm    20   0 23.8g  60m  36m S  0.0  0.2   0:02.00  18m dw.sapUE3_D10 pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3
 92203 ue3adm    20   0 23.8g  60m  36m S  0.0  0.2   0:01.99  18m dw.sapUE3_D10 pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3
 95104 ue3adm    20   0 23.8g  59m  35m S  0.0  0.2   0:01.99  18m dw.sapUE3_D10 pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3
 97243 ue3adm    20   0 23.8g  59m  35m S  0.0  0.2   0:01.99  18m dw.sapUE3_D10 pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3
 97645 ue3adm    20   0 23.8g  59m  35m S  0.0  0.2   0:02.00  18m dw.sapUE3_D10 pf=/usr/sap/UE3/SYS/profile/UE3_D10_smecc-uat-ue3




1-339430301	SEV2
Summary: Processor_load_is_too_high_on_smeccsbxse1.imzcloud.ibmammsap.local
10.78.20.15


-------------------------------------------------------------------------------------------------------------------------------

2 July

1-339261561 sev1
Summary: Zabbix_agent_on_sph-sq-dms.imzcloud.ibmammsap.local_is_unavailable
10.7.13.18



1-339458171    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Lack_of_free_memory_on_server_DAL09AMMTS001
Node: DAL09AMMTS001 NodeAlias: 146.89.140.20



1-339461701    2-Urgent    IBM MSD Infras - Cloud Shared        Summary: MSD:Low server memory. Memory available is 4% (695MB)
Summary: MSD:Low server memory. Memory available is 4% (695MB)
Node: ri3vw006 NodeAlias: 146.89.3.81



1-339472541    CMA CGM (CMA)    2-Urgent    SAPPJ    Summary: Processor_load_is_too_high_on_smtmdevdt1.imzcloud.ibmammsap.local[PROBLEM:3325110] Date: J 




10.6.3.42	spsvcpicapp12




1-339470621 - P2- AGE - SAP HEC-AMM - Siebel - Not Validated - SAP Incident Number:00040049/2018	





1-339482223
To Create new file sytem
hi Team, 

Good Day

Need the following Paths to be created and mounted on DEV an PRD Fiori Servers to be able to start installation:

/Sybase     	200 GB
/usr            100 GB

Note: /usr is already exists but with available space almost 7 GB
 
ECTFIODEV	10.5.10.12	
ECTFIOPRD	10.5.10.11


vg_data-lv_db

vg_data-lv_usr

[root@ectfiodev usr]# df -h /usr
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  2.2G  7.1G  24% /


vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab



vgextend mmpdatavg /dev/sdb

lvextend -L +50G /dev/mapper/mmpdatavg-mmpsapdata1_lv
resize2fs /dev/mapper/mmpdatavg-mmpsapdata1_lv




1-339416531
10.6.1.12   add 1GB to /usr/sap


Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                       45G   38G  4.2G  90% /usr/sap

lvextend -L +1000M /dev/mapper/vg_app-lv_usrsap
resize2fs /dev/mapper/vg_app-lv_usrsap


mount -t ext4 /dev/vg_data/lv_db /sybase 

/dev/vg_data/lv_usr
/dev/vg_data/lv_db
--------------------------------------------------------------------------------------------------------------------------

4 July


1-339494611    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Lack_of_free_memory_on_server_DAL09AMMTS002
146.89.140.21	Win


1-339498731    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_fra02ammsol01.imzcloud.ibmammsap.local
146.89.140.220 Linux


[root@fra02ammsol01 ibmrmalik]# uptime
 21:44:38 up 64 days, 14:00,  1 user,  load average: 0.16, 0.37, 0.48
[root@fra02ammsol01 ibmrmalik]# top -M
top - 21:44:45 up 64 days, 14:00,  1 user,  load average: 0.15, 0.36, 0.48
Tasks: 526 total,   1 running, 525 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.4%us,  0.1%sy,  0.0%ni, 99.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.316G total,   29.415G used, 1946.895M free, 1806.508M buffers
Swap:   12.000G total, 2564.637M used, 9723.359M free,   17.603G cached




1-339510481 1-Critical    Meggitt Plc (MGG)
[root@MGGGBJPCNTX02 ibmrmalik]# df -h /sapdb_backups/NCP
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/NCPsapdbbkupvg-NCP_sapdbbkup_lv
                      289G  274G   17M 100% /sapdb_backups/NCP
[root@MGGGBJPCNTX02 ibmrmalik]# vgs NCPsapdbbkupvg
  VG             #PV #LV #SN Attr   VSize   VFree
  NCPsapdbbkupvg   5   1   0 wz--n- 293.98g 1012.00m




1-339509701	Summary: Processor_load_is_too_high_on_DLTHPEHP4.imzcloud.ibmammsap.local	sev2
 10.4.5.56




1-339509831 1-Critical    Dilip Buildcon Limited (DLB)    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/home
10.13.1.12


1-339510811    1-Critical    Dilip Buildcon Limited (DLB)    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/home
10.13.1.12





1-339513361    2-Urgent    IBM AMM Infrastructure        Summary: Lack_of_available_memory_on_server_a0b4ca013esx015.imzcloud.ibmammsap.local 
Node: a0b4ca013esx015.imzcloud.ibmammsap.local NodeAlias: 146.89.141.97


-------------------------------------------------------------------------------------------------------------------------------

5 July


1-339533021 - Sev1 - PNC - AMM-SAP - Siebel - Not Validated - Summary: Zabbix_agent_on_C1ECCP.imzcloud.ibmammsap.local_is_unavailable
10.199.1.10


1-339527841
server storage details



1-339511341
local account pw reset




1-339537321 - Sev2 - IBM MSD Infras - Cloud APPS - Sibel Not Validated - Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local
146.89.140.30



1-339535131 St Jude Medical Singapore - SAP HEC P2
Summary: Lack_of_free_swap_space_on_sjmpcpaa02.imzcloud.ibmammsap.local
10.198.10.14 


1-339534771	sev1	RED :EP1~ABAP:ABAP System not available
Ticket # 61265711 old   monitoring ticket 61599225	Ticket # 61605505 new ticket on 5th July
MDCSERVERP1	10.12.7.41	msc-phana-1024-5.imzcloud.ibmammsap.local
Private IP: 10.148.59.176	root/C2yYj5pZ
ipmi pw TGxleZ4jSg 


IBM SWAT Bridge
Toll Free:    1-888-426-6840
Toll:         1-215-861-6239
Passcode: 16533155

Thank you for taking my call today. After some troubleshooting we are still seeing dropped packets when 'eth0' is brought up. I believe the issue is that the switch configuration is set for a LACP bonded connection; but you are not using this on the server side. I believe that this is causing the flapping with 'eth0'. I would like to change the configuration from 'LACP' to 'Basic' bonding in an attempt to get this connection issue corrected. The steps we will take will be to:
1. null the network
2. change the configuration from 'LACP' to 'Basic'
3. bring up the network

Once you get confirmation from your customer on when this can be done we will get this scheduled.

Thank you,

Joe M.
Advanced Customer Support
IBM Cloud 


-------------------------------------------------------------------------------------------------------------------------

7 July


1-339612481    Dilip Buildcon Limited (DLB)    2-Urgent    DLB
10.13.1.12
Summary: Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local

top - 14:34:52 up 386 days,  1:28,  1 user,  load average: 2.41, 2.51, 3.05
Tasks: 388 total,   6 running, 382 sleeping,   0 stopped,   0 zombie
Cpu(s): 88.4%us,  1.2%sy,  0.0%ni,  9.9%id,  0.0%wa,  0.0%hi,  0.6%si,  0.0%st
Mem:    62.901G total,   61.799G used, 1128.652M free, 1278.121M buffers
Swap: 8191.996M total,  433.301M used, 7758.695M free,   44.735G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 75133 pecadm    20   0 50.6g 2.3g 1.3g R 94.2  3.6 451:54.99 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
 83505 pecadm    20   0 50.4g  28g  28g R 93.5 45.6 671:27.29 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
 89481 pecadm    20   0 50.2g  25g  25g R 51.1 40.9 402:48.39 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
 75375 pecadm    20   0 50.2g  28g  28g S 50.4 46.1 732:50.91 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
 37095 pecadm    20   0 50.6g 2.1g 1.1g R 34.8  3.3   1258:53 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
 84251 pecadm    20   0 50.4g  23g  23g S  9.3 37.9 512:50.79 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01
 88157 pecadm    20   0 50.1g  20g  19g S  8.3 32.3 112:07.37 dw.sapPEC_D00 pf=/usr/sap/PEC/SYS/profile/PEC_D00_DLBPECAP01




1-339612501    Dilip Buildcon Limited (DLB)    2-Urgent    DLB
10.13.1.12	DLBPECAP01




1-339614361 AGEAS - SAP HEC-AMM 2-Urgent
10.6.1.21
Summary: Lack_of_free_swap_space_on_svod1srv0.imzcloud.ibmammsap.local



1-339613761	sev2
Summary: Processor_load_is_too_high_on_PECAP01.imzcloud.ibmammsap.local


1-339603871	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/sapdb_backups
10.133.18.32



1-339596681	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/
10.4.20.31





1-339593151	10.196.4.15	sev2
Summary: Lack_of_free_swap_space_on_juddtrans03.imzcloud.ibmammsap.local




1-339589150	sev2
IMZ Login not working	





1-339588051	sev2
Summary: Lack_of_free_memory_on_server_ECCPROD02



1-339587651	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap/DR1
10.196.4.11



	
1-339579331 sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/db2/DI2/db2dump




1-339559231	sev2	
Summary: Lack_of_free_swap_space_on_C1BJD.imzcloud.ibmammsap.local
10.199.2.33




1-339559191	sev3	Win	 10.5.6.21
Summary: Processor_load_is_too_high_on_PHSSAPDEV01



1-339558561	sev2	
Summary: Processor_load_is_too_high_on_C1BWD.imzcloud.ibmammsap.local
10.199.2.31



1-339555991	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap	




1-339555061 sev2
Summary: Lack_of_free_swap_space_on_S4HANA-




1-339554981	sev2	10.4.20.31
Summary: Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.local




1-339554791	sev2
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap
10.68.210.12




1-339552941	sev2
Summary: Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local
10.198.0.208




1-339616561  -  Sev1 -  Siebel - Limited Brands, Inc. - SAP HEC-AMM-  not validated- "Zabbix_agent_on_LBDSP1App01.imzcloud.ibmammsap.local_is_unavailable
 10.8.8.64



1-339616791    SAP11    2-Urgent    SORAA - SAP HEC-AMM
Summary: Free_disk_space_is_less_than_10%_on_volume_F:
10.4.13.10



-------------------------------------------------------------------------------------------------------------------------------------

8 Jul



1-339620291	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.197.0.12




1-339616761	sev3	10.4.13.10	
Summary: Free_disk_space_is_less_than_20%_on_volume_F:




1-339551711   sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap
10.68.210.13



1-339599771
SNCHTNAPD11 	10.73.10.108
Toronto
[root@snchtnapd11 ibmrmalik]# df -h /sybase/PN1/saplog1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pn1logvg-pn1syblog1_lv
                       22G   21G  377M  99% /sybase/PN1/saplog1
add 10GB
vgextend pn1logvg /dev/sdr

lvextend -L +10G /dev/mapper/pn1logvg-pn1syblog1_lv
resize2fs /dev/mapper/pn1logvg-pn1syblog1_lv



1-339541141	sev2
Summary: Lack_of_free_swap_space_on_BWDEVApp1.imzcloud.ibmammsap.local
10.70.1.72
top - 19:02:09 up 78 days, 21:10,  1 user,  load average: 0.03, 0.04, 0.01
Tasks: 270 total,   1 running, 269 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.7%us,  0.3%sy,  0.0%ni, 99.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.571G total,   15.124G used,  457.773M free,  727.273M buffers
Swap:   13.766G total, 7206.711M used, 6889.285M free, 4588.348M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
15348 bjdadm    20   0 1428m  14m 1736 S  0.0  0.1  11:37.93 784m en.sapBJD_ASCS01 pf=/usr/sap/BJD/SYS/profile/BJD_ASCS01_BWDEVApp1
17160 bjdadm    20   0 1665m  12m 6828 S  0.0  0.1   2:43.98 117m icman -attach pf=/usr/sap/BJD/SYS/profile/BJD_DVEBMGS00_BWDEVApp1
 1958 root      20   0 1548m 529m 6316 S  0.0  3.3 169:54.63  52m /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
17177 bjdadm    20   0 15.2g 795m 665m S  0.0  5.0  27:46.77  32m dw.sapBJD_DVEBMGS00 pf=/usr/sap/BJD/SYS/profile/BJD_DVEBMGS00_BWDEVApp1
17142 bjdadm    20   0  835m 3564 1260 S  0.0  0.0  15:15.35  27m /usr/sap/BJD/DVEBMGS00/exe/igspw_mt -mode=profile -no=1 -restartcount=0 -wdpid=17136 pf=/usr/sap/BJD/SYS/profile/BJD_DVEBMGS00_BWDE
17190 bjdadm    20   0 15.1g  46m  25m S  0.0  0.3   0:18.39  27m dw.sapBJD_DVEBMGS00 pf=/usr/sap/BJD/SYS/profile/BJD_DVEBMGS00_BWDEVApp1
17191 bjdadm    20   0 15.1g  46m  25m S  0.0  0.3   0:18.40  27m dw.sapBJD_DVEBMGS00 pf=/usr/sap/BJD/SYS/profile/BJD_DVEBMGS00_BWDEVApp1
17166 bjdadm    20   0 15.2g 2.0g 1.9g S  0.0 13.1  15:03.70  27m dw.sapBJD_DVEBMGS00 pf=/usr/sap/BJD/SYS/profile/BJD_DVEBMGS00_BWDEVApp1




1-339623400	sev3
Reset hdvadm password




1-339634361 St Jude Medical  Dallas - SAP HEC 2-Urgent
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap/DR1
10.196.4.11





1-339532361	sev2
Summary: Lack_of_free_swap_space_on_APLBREDP1.imzcloud.ibmammsap.local
170.225.68.11





1-339529521	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap/RPA
 10.138.1.13




1-339529291	 10.69.0.70	sev3
Summary: Free_disk_space_is_less_than_20%_on_DB_volume_/sybase/SPA/log_archive




1-339525411	 10.133.17.140	sev2
Summary: Processor_load_is_too_high_on_IA1S4HQASAPP.imzcloud.ibmammsap.local




1-339519534		sev3
Disable cron job in EP1
Description:
"Hi Team,
 
Please disable the below cronjob in EP1 CLDERPAPPP1
A0CTSG014XVM029 			CLDERPAPPP1 	10.168.1.71 	10.198.0.71
 
15 7,8,9,11,13,15,17,19,22 * * * /home/postman/HR/hrcas_in_new.sh > /home/postman/HR/hrcas_in_new.log 2>&1






1-339519101	sev2
Summary: Processor_load_is_too_high_on_EMCBOPRD.imzcloud.ibmammsap.local
10.14.5.15





1-339490024	Linux Swap configuration check -JD1	sev3
JD1 	172.22.0.145 		swap is 14GB

10.71.0.145

(Lon migration

10.69.0.145)




1-339490864	sev3	Linux Swap configuration check -JP1

JP1 	172.22.0.47 	10.69.0.47	LONMAGSBD0001	64 GB swap and 32 GB RAM
JP1 	172.22.0.48 	10.69.0.48	LONMAGSBD0002	32 GB swap and 16 GB RAM





1-339489944	sev3	Linux Swap configuration check -JQ1
JQ1 	172.22.0.49 	10.69.0.49	LONMAGSBD0003	128 GB swap and 64 GB RAM





1-339486841	sev2	10.198.201.16
Summary: ITM Agent Offline: MPQ-adnmp1qadb





1-339486021	sev2	10.13.2.12
Summary: Lack_of_free_swap_space_on_DLBQECAP01.imzcloud.ibmammsap.local





1-339485801	sev2	10.198.201.16 
Summary: ITM Agent Offline: MPQ-adnmp1qa:adnmp1devapp:mySAP

-----------------------------------------------------------------------------------------------------------------------------------------

10 Jul



1-339648371    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_DLTHQEHAP2.imzcloud.ibmammsap.local
10.4.5.37

1-339648411    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_dlthqehap4.imzcloud.ibmammsap.local
10.4.5.39


1-339656651    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_DLTHQEHAP2.imzcloud.ibmammsap.local
10.4.5.37


1-339689001    2-Urgent    Wellnext (WNX)    Summary: Lack_of_free_swap_space_on_WNXECCAPPQ01.imzcloud.ibmammsap.local 
10.143.21.17



1-339688161    2-Urgent    IBM MSD Infras - Cloud APPS            Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local
146.89.140.30


1-339690281    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Lack_of_free_memory_on_server_DAL09AMMTS002
 146.89.140.21



1-339690481    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Free_disk_space_is_less_than_10%_on_volume_E:
146.89.140.20



1-335296151
Mount Point need to be remove : /backup
System : DEV/QAS/PRD
Hostname	Server IP	IMZ IP address
SU6SUNECD00	10.10.10.139	10.13.3.11
SU6SUNECQ00	10.10.10.140	10.13.3.12
SU6SUNECP00	10.10.10.141	10.13.3.13


-----------------------------------------------------------------------------------------------------------------------------------------------------

11 July


1-339729251    MSC Industrial Supply Co.    2-Urgent    Summary: Lack_of_free_swap_space_on_ms3wdcladb44.imzcloud.ibmammsap.local
10.12.7.31




1-339729491  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)  P2
Summary: FS_is_read_only_on_C1ECCD.imzcloud.ibmammsap.loca /mnt/sapexchangePT
10.199.2.12





1-339729641 - Sev2 - IBM -  - Siebel - Not Validated - Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local[



1-339725388  COTY Inc (CTU)   P3  -- @Ravi Malik
Coty- PB0 - All app server Fileshare se
Request:
Create a new NFS mountpoint "/usr/sap/PB0/interfaces of 20GB from the
Fileshare. Mount this NFS "FROM" the fileshare to all PB0 App servers
Pls share the server list of all PB0 App servers where this mount is to be mapped 



1-339725609  COTY Inc (CTU)   P3 -- @Ravi Malik
Coty - QB1 - All app servers (edited)



1-339730491	sev2
Summary: Lack_of_free_swap_space_on_IC99SAZJ2.imzcloud.ibmammsap.loca





1-339725795	sev1	Customer reported System Slow & multiple dumps with DBSQL_SQL_ERROR
CLDERPDTBP1    HANA	10.168.1.141	10.198.0.141	10.168.1.141 10.198.0.141 10.116.35.185
CLDERPAPPP1    App	10.168.1.71	10.198.0.71




---------------------------------------------------------------------------------------------------------------------------------


12 July


1-339734118    IAG GBS Limited (IA1)    2-Urgent    Reboot IaaS+ servers after OS patching
Please reboot the impacted IaaS+ servers impacted by OS patching	
tomorrow (12-July) at 6:30 AM CET.	10.30 AM IST
 HCIPRD	IA1HCIPRDAPP 	10.133.15.23	Linux	
FTSPRD  IA1FTSPRDAPP	10.133.15.24	Linux
NFS     IA1NFSPRDAPP	10.133.15.25	Linux
OTAPP	IA1OTASPRDAPP	10.133.17.147	linux
OTDB	IA1OTASPRDDB	10.133.17.146	Linux
OT	IA1HCIDEVAPP	10.133.17.150	Linux





1-339694069
P2 : [RIMS] Create new keystore in OP1
OP1 ( CLDPROAPPP1 )
(OP1)CLDPROAPPP1- 10.198.0.75 

SFTP server                        : CLDSFTPSVRP1 [172.31.10.20]
Username                           : _rimssapsftpp
Password                            : <email sent separately>
 
Keystore = SFTP_rimssapsftpp
Keystore Entry = sftp_keystore_rims
 




1-339693956
snapshot request
SVFH1SRV0	






1-339756491    Dilip Buildcon Limited (DLB)    2-Urgent
Summary: Processor_load_is_too_high_on_DLBPNGDA00.imzcloud.ibmammsap.local
10.13.1.17


1-339756461    Dilip Buildcon Limited (DLB)    2-Urgent
Summary: Processor_load_is_too_high_on_PNGDA00.imzcloud.ibmammsap.local
10.13.1.17
 




1-339749911	sev2
Summary: Processor_load_is_too_high_on_fra02ammsol01.imzcloud.ibmammsap.local
146.89.140.220



1-339523761	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_E:
146.89.140.20



1-339547741
Summary: Processor_load_is_too_high_on_lon02ammtsm001.imzcloud.ibmammsap.local
146.89.140.114





1-339620281	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var



1-339619751
Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var
10.15.11.14





1-339636911
Summary: Drive_with_Errors_on_dalhana-1024-2.xsportal.local
146.89.140.41





1-339696621	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_E:
146.89.140.21

-----------------------------------------------------------------------------------------------------------------------------

13 July


1-339801251    1-Critical    Delta Airlines, Inc. - SAP HEC-AMM    
Summary: Free_disk_space_is_less_than_5%_on_volume_/EPI-USE/SAP 
10.4.5.53	DLTHPEHP1	10.250.17.53
sdl 16 GB
[root@DLTHPEHP1 ibmrmalik]# df -h /EPI-USE/SAP
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-vg_ep1
                       30G   28G  903M  97% /EPI-USE/SAP
vgextend vg_app /dev/sdl

lvextend -L +7G /dev/mapper/vg_app-vg_ep1
resize2fs /dev/mapper/vg_app-vg_ep1




1-339740211		FS extend from excel



1-339800911	sev1	done
pw reset
Db connection failed due to 
Password validation for user sapfsm failed
146.89.140.220



1-339701841    2-Urgent    IBM MSD Infras - Cloud MONITORING
Summary: Lack_of_free_memory_on_server_DAL09AMMTS001
146.89.140.20


1-339739161    2-Urgent    IBM MSD Infras - Cloud MONITORING
Summary: Lack_of_free_memory_on_server_DAL09AMMTS002
146.89.140.21




1-339646251	{Meggitt Plc (MGG) --> 10.133.18.26}    3-Standard
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/EGP

[root@MGGGBJPGTSX01 ibmrmalik]# df -h /usr/sap/EGP
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/egpappvg-egpusrEGP_lv
                       24G   19G  3.5G  85% /usr/sap/EGP
[root@MGGGBJPGTSX01 ibmrmalik]# vgs egpappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  egpappvg   1  13   0 wz--n- 128.00g 24.00g

lvextend -L +3G /dev/mapper/egpappvg-egpusrEGP_lv
resize2fs /dev/mapper/egpappvg-egpusrEGP_lv



1-339776031	sev2
VM backup issue
Worked with Robin and Siva on VM backup failure issues
a0ctsg014xvm036
a0diml014xvm007
a0easg012xvm064
adnabpapp1
pbbs4hpap00
ssgsa0119
svjs1srv0




1-339801851 2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Free_disk_space_is_less_than_10%_on_volume_E: 
146.89.140.21

---------------------------------------------------------------------------------------------

16 July

1-339885881 3-Standard    SORAA - SAP HEC-AMM        Summary: Free_disk_space_is_less_than_20%_on_volume_F: 
10.4.12.12


1-339887231    1-Critical    Home Control Singapore Summary: Zabbix_agent_on_eccci0prd.imzcloud.ibmammsap.local_is_unavailable   @Ravi Malik pls chk
10.198.2.140	eccci0prd	SNG




1-339740211		FS extend from excel


1-339820861	Summary: NTP_time_is_driffted_on_ageSNG01web01.imzcloud.ibmammsap.local	sev3
 10.6.3.100



1-339839981	Summary: NTP_time_is_driffted_on_svjh1srv0.imzcloud.ibmammsap.loca	sev3
10.6.1.156

-----------------------------------------------------------------------------------------------

17 July

1-339895151    2-Urgent    SORAA - SAP HEC-AMM        Summary: Lack_of_free_memory_on_server_ECCPROD02
10.6.0.11     10.4.12.11


1-339912441    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_dlthdehap.imzcloud.ibmammsap.local



1-339920881 2-Urgent    Lindt and Sprungli North America Inc (LNA)    Summary: Processor_load_is_too_high_on_lnasv234.imzcloud.ibmammsap.local



1-339921061 2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local



1-339911231    2-Urgent    American Airlines SAP HEC-AMM

dalhana-512-9.xsportal.local	Private IP: 10.121.75.188	Ticket # 62114769	root/Ycs4zMcb	10.4.9.20




1-339928561    2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local
top - 02:56:46 up 70 days, 16:42,  2 users,  load average: 9.72, 10.63, 9.63
Tasks: 1050 total,   1 running, 1049 sleeping,   0 stopped,   0 zombie
Cpu(s):  5.3%us,  0.6%sy,  0.0%ni, 55.9%id, 38.1%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    31.315G total,   30.604G used,  728.344M free, 1974.168M buffers
Swap:   12.000G total, 5418.812M used, 6869.184M free,   16.744G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
17642 db2dsm    20   0 12.7g 3.1g 2.7g S 11.2 10.0   4097:49 db2sysc 0
30193 dsmadm    20   0 6919m 1.1g 1.1g S  9.3  3.6   0:46.30 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
29381 dsmadm    20   0 8505m 2.6g  17m S  8.3  8.3 692:32.06 /usr/sap/DSM/DVEBMGS50/exe/jlaunch pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01 -DSAPINFO=
 8186 dsmadm    20   0 6873m  75m  60m S  5.6  0.2   0:02.26 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
25415 dsmadm    20   0 5658m 797m 5088 S  4.3  2.5 871:22.64 ./jre/bin/java -Xms512m -Xmx1024m -Djava.awt.headless=true -XX:MaxPermSize=256m -Dmail.mime.charset=U
11711 dsmadm    20   0 6922m 1.2g 1.2g S  2.0  3.8   2:34.05 dw.sapDSM_DVEBMGS50 pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01
25128 root      20   0  685m  78m 7804 S  2.0  0.2   2074:08 /opt/BESClient/bin/BESClient
26421 dsmadm    20   0  800m  43m  19m S  1.3  0.1 141:04.19 gwrd -dp pf=/usr/sap/DSM/SYS/profile/DSM_DVEBMGS50_dal09ammsol01



1-339928071    2-Urgent    Lindt and Sprungli North America Inc (LNA)    
Summary: Processor_load_is_too_high_on_lnasv234.imzcloud.ibmammsap.local


1-339928891    2-Urgent    Lindt and Sprungli North America Inc (LNA)        
Summary: Processor_load_is_too_high_on_lnasv240.imzcloud.ibmammsap.local




1-339933301    2-Urgent    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)        Summary: Lack_of_free_swap_space_on_C1BWP.imzcloud.ibmammsap.local




10.133.18.36 access issue on LOndon server sssd is not starting
Meggit
10.5.255.20	10.133.18.20 	
10.5.255.40	10.133.18.40



1-339935451 MSC Industrial Supply Co. 2-Urgent


----------------------------------------------------------------------------------------------------------------

18 July


1-339959261
JS1	SVJS1SRV0	10.6.1.140
RS1	SVES1SRV0	10.6.1.139
CS1	SVCS1SRV0	10.6.1.142
XS1	SVCS1SRV0	10.6.1.142 


JS1	SVJS1SRV0	10.6.1.140  - js1adm
RS1	SVES1SRV0	10.6.1.139  - rs1adm
CS1	SVCS1SRV0	10.6.1.142  - cs1adm
XS1	SVCS1SRV0	10.6.1.142  - xs1adm

FS1 we already reset and shared with users 

pls reset for JS1, RS1, CS1 & XS1 with "Ageas@18" 




1-339951141    YHI CORPORATION (SINGAPORE) PTE LTD    2-Urgent    Summary: Processor_load_is_too_high_on_YHIEQS01.imzcloud.ibmammsap.local
10.6.4.205



1-339961211  Delta Airlines, Inc. - SAP HEC-AMM  P2




1-338897121
Summary: NTP_time_is_driffted_on_TNGDEVERPDB.imzcloud.ibmammsap.local	sev3


1-339126101	sev2
DF Hung / NFS issue



1-339134521	sev3
Summary: Free_disk_space_is_less_than_20%_on_DB_volume_/db2/QX8/log_archive




1-339151401	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/usr/sap
[root@LONMAGSPO0001 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ip1appvg-usr_sap
                      976M  743M  183M  81% /usr/sap

-rw-------.  1 ip1adm sapsys 2072047 Jun  8  2014 ariba_JobBean.ear
-rw-------.  1 ip1adm sapsys 3253579 Jun 10  2016 aribanwfiletransfer_PI7.3.zip




1-339965631  Bombardier Aerospace P1
Summary: Zabbix_agent_on_bmtmon1lapp03.imzcloud.ibmammsap.local_is_unavailable
10.206.0.43




1-339966421 ETRO SPA (ETO)  P1 -- @Ravi Malik
Summary: Zabbix_agent_on_ECCQAS00.imzcloud.ibmammsap.local_is_unavailable



1-339966391  ETRO SPA (ETO)  P1 -- @Ravi Malik
Summary: Zabbix_agent_on_ECCPAS00.imzcloud.ibmammsap.local_is_unavailable
10.5.2.21



--------------------------------------------------------------------------------------------------------

19 July

1-339985921 Sev 2 Suncor..		Ticket # 62196245
TR1 DB down
10.73.11.74

10.166.156.212	torhana-8192-1.xsportal.local	

146.89.140.30:/storage/library/
                      3.6T  2.7T  718G  80% /Staging/sapsft
146.89.140.30:/storage/library
                      3.6T  2.7T  718G  80% /storage/library

HDD10 Serial: bthv550604jg1p2pgn is now HDD10 Serial: BTHV533301SC1P2PGN
HDD15 Serial: bthv550604je1p2pgn is now HDD15 Serial: BTHV6372035F1P2PGN



[root@snchecatd11 ibmrmalik]# blkid
/dev/sda1: LABEL="BOOT" UUID="9f4596ad-d184-4ba0-a430-378b4f94e374" TYPE="ext4"
/dev/sda2: LABEL="SWAP" UUID="e49dcdbd-2d54-447f-ab93-3a707c96626d" TYPE="swap"
/dev/sda3: LABEL="OS" UUID="9bcc6a6d-517b-46a6-a2d1-c68263100e65" TYPE="ext4"
/dev/sdb1: UUID="zROqIY-F2Q4-nROr-kUyB-SBRw-vGCz-kZ0Kdn" TYPE="LVM2_member"
/dev/mapper/hanadata-lv_hana_data: LABEL="/sapmnt/data" UUID="360fc0d2-7631-4dac-8762-e4a3ed070e42" TYPE="xfs"


LALABEL=/sapmnt/shar      /sapmnt/shared            xfs   defaults,inode64                            0 0
LABEL=/usr/sap          /usr/sap                xfs   defaults,inode64                            0 0
LABEL=/sapmnt/log         /sapmnt/log               xfs   defaults,swalloc,nobarrier,inode64          0 0






1-339950271	Summary: NTP_time_is_driffted_on_svud1srv0.imzcloud.ibmammsap.local	sev3
10.6.1.137



1-339951051	sev3
Summary: NTP_time_is_driffted_on_svcd1srv0.imzcloud.ibmammsap.local



1-339482223
To Create new file sytem
hi Team, 

Good Day

Need the following Paths to be created and mounted on DEV an PRD Fiori Servers to be able to start installation:

/Sybase     	200 GB
/usr            100 GB

Note: /usr is already exists but with available space almost 7 GB
 
ECTFIODEV	10.5.10.12	
ECTFIOPRD	10.5.10.11


vg_data-lv_db

vg_data-lv_usr

[root@ectfiodev usr]# df -h /usr
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  2.2G  7.1G  24% /


vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 100G -n lv_usr vg_data
mkfs.ext4 /dev/mapper/vg_data-lv_usr
mkdir /usr
mount     mount -t ext4 /dev/vg_data/lv_usr /usr
vi /etc/fstab


lvcreate -L 100G -n lv_usr vg_data
mkfs.ext4 /dev/mapper/vg_data-lv_usr




vgextend mmpdatavg /dev/sdb

lvextend -L +50G /dev/mapper/mmpdatavg-mmpsapdata1_lv
resize2fs /dev/mapper/mmpdatavg-mmpsapdata1_lv






1-339973091    Concessionaria Aeroporto Rio de Janeiro S.A. (CON)    1-Critical    Summary: Zabbix_agent_on_consppoapp.imzcloud.ibmammsap.local_is_unavailable[
10.16.1.103



1-337718371	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/



1-339989111  sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.78.20.31	




1-340006331
Summary: Free_disk_space_is_less_than_10%_on_volume_C:

--------------------------------------------------------------------------------------------------------------

20 July


1-340042971    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
/mnt/sapexchangeIT
10.199.2.31


SUncor	WIn2012 Toronto
SNCHDSBQA11 	10.73.12.46	fixed but needs a reboot



1-339337091	sev2
Summary: Lack_of_free_swap_space_on_ADNAELDEVAPP.imzcloud.ibmammsap.loca




1-339368591	sev3	 CRITICAL | /usr/sap/trans /usr/sap/trans
Summary: FS_is_read_only_on_FRAMAGGRC0002.imzcloud.ibmammsap.local







1-340045361    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1ECCQ.imzcloud.ibmammsap.local[PROBLEM:3726756] Date: Jul 20,2018 2:10
 CRITICAL | /mnt/sapexchangePT
10.199.2.11






1-340045341    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1ECCD.imzcloud.ibmammsap.local[PROBLEM:3726744] Date: Jul 20,2018 2:8
CRITICAL | /mnt/sapexchangePT		10.199.2.12



1-339552381	10.198.0.141	Summary: Drive_with_Media_Errors_on_host_clderpdtbp1.imzcloud.ibmammsap.local	sev3
clderpdtbp1.smrtnet.ads	SNG
10.116.103.235
root/S8bnB7bm
 /opt/lsi/storcli/storcli
/opt/MegaRAID/storcli




1-340045601    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local  




1-339579331	sev3
Summary: Free_disk_space_is_less_than_20%_on_volume_/db2/DI2/db2dump




1-339639881   sev3
Summary: Processor_load_is_too_high_on_PHSBWDEV01




1-339641631	sev3
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/
10.133.18.23

----------------------------------------------------------------------------------------------------------
23 July


1-340005251	sev1
Summary: Zabbix_agent_on_smediquaqu3.imzcloud.ibmammsap.local_is_unavailable
10.78.24.32



1-340005301	sev1
Summary: Zabbix_agent_on_smediuatuu3.imzcloud.ibmammsap.local_is_unavailable
10.78.26.25



1-340130051  - Sev1 - MS3 - AMM-SAP - Siebel - Not Validated -  Zabbix_agent_on_ms3wdclapp35.imzcloud.ibmammsap.local_is_unavailable


1-340131281 - P1- MS3 - AMM-SAP - Siebel - Not Validated - Summary: Zabbix_agent_on_ms3wdclapp35.imzcloud.ibmammsap.local_is_unavailable
10.12.7.20



1-340131491    1-Critical    MSC Industrial Supply Co.    Summary: Zabbix_agent_on_ms3wdclapp35.imzcloud.ibmammsap.local_is_unavailable 
10.12.7.20



1-335013481





1-339837641





1-340113811    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_dlthpehdb.imzcloud.ibmammsap.local
10.4.5.52


1-340116171    2-Urgent    MSC Industrial Supply Co.    Summary: Processor_load_is_too_high_on_ms3wdclapp35.imzcloud.ibmammsap.local
10.12.7.20



1-340132971    1-Critical    PEPSICO INC (PEP)    Summary: Zabbix_agent_on_saps07db00.imzcloud.ibmammsap.local_is_unavailable 



1-340120081    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_LBDFD1DEVDB1.imzcloud.ibmammsap.local
10.8.8.14



1-340120621    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_LBDBOQQASApp3.imzcloud.ibmammsap.local
10.8.8.59



1-340122491    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_LBDTP1PRDApp1.imzcloud.ibmammsap.local
10.8.8.80



1-340123941    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_LBDFQ1QASDB1.imzcloud.ibmammsap.local
 10.8.8.38




/sybase/PE1/log_archive/PE1/




1-340137061    1-Critical    MSC Industrial Supply Co.    Summary: Zabbix_agent_on_ms3wdclapp35.imzcloud.ibmammsap.local_is_unavailable
10.12.7.20




Helpeed with permission and access for Suncor Server
/dev/mapper/pe1archvg-pe1logarch_lv
/dev/mapper/pe1archvg-backup_lv	/backup




1-340102629	swap increase






1-340140061    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_a0b4ca013esx018.imzcloud.ibmammsap.local


1-340140181    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_sng01ammtsm001.imzcloud.ibmammsap.local    


1-340141171 2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_ammlon02custesx04.imzcloud.ibmammsap.local

---------------------------------------------------------------------------------------------------------------------------------

24 July



1-340157661    IAG GBS Limited (IA1)    1-Critical -- 
Summary: Zabbix_agent_on_IA1BPCPRDDB.imzcloud.ibmammsap.local_is_unavailable




1-340157631    IAG GBS Limited (IA1)    1-Critical  --
Summary: Zabbix_agent_on_IA1S4HPRDDBHA.imzcloud.ibmammsap.local_is_unavailable




1-340138361	pw reset for win server	sev3
Reset Administrator Password for ADNWEBDISP


1-340157751 - SL-London-02 - IAG GBS Limited (IA1) - SAP09 - SAP HEC-AMM - Ongoing - SAP System SP1 / BP1 Is Down



1-340144581    2-Urgent    SMRT Corp - SAP HEC-AMM        Summary: Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local
10.198.0.208



1-340144741    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_LBDSP1App01.imzcloud.ibmammsap.local
10.8.8.64


1-340172841    1-Critical    IBM AMM Infrastructure    Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable
146.89.142.30



1-340134107    swap increase on 3 servers
Suncore
Add SWAP - snchecapa17, snchecapa20 (?)  Tor

snchecapa17	10.73.10.21		add 88 GB   TOATAL 96
/dev/mapper/VolGroup-lv_swap

[root@snchecapa17 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize   VFree
  VolGroup   3   7   0 wz--n- 113.50g 66.49g
sdg 40 GB
vgextend VolGroup /dev/sdg



		
snchecapa20	10.73.10.24
/dev/mapper/VolGroup-lv_swap
[root@snchecapa20 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize   VFree
  VolGroup   3   7   0 wz--n- 113.50g 66.49
sdf -  40Gb


snchecapa15	10.73.10.19	
/dev/mapper/VolGroup-lv_swap

vgextend VolGroup /dev/sde
[root@snchecapa15 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize   VFree
  VolGroup   3   7   0 wz--n- 113.50g 66.49g



sde 32





#1 stop SAP
	-  snchecapa11, snchecapa13, snchecapa16, , (Akshay)
	- nchecapa12, snchecapa14, snchecapa15, snchecapa17, (Shaik)
    - snchecapa18 snchecapa19, snchecapa20  (Brooke)

#2 PAS snchecapa11 
	- Add SWAP (Josue)
	 - Bring SAP UP (Akshay)

#2  snchecapa13, snchecapa16, snchecapa18, snchecapa19
	- Reboot (Josue)
	- Start SAP (Akshay)

#3 snchecapa12, snchecapa14, snchecapa15, snchecapa17, snchecapa20
	- Add SWAP - snchecapa12, snchecapa14, snchecapa15 (Josue)
	- Add SWAP - snchecapa17, snchecapa20 (Ravi)
	- Bring SAP up 
		- snchecapa12, snchecapa14, snchecapa15 (Shaik)
		 - snchecapa17, snchecapa20 (Akshay)

Total Downtime approved 2,5 hours








1-340159801	10.73.10.54 - sapdata1, sapdata2 and saplog1 needs to be increased to 100 GB 	/sev2

/dev/mapper/p1dlogvg-p1dsyblog1_lv
                       55G   47G  5.2G  91% /sybase/P1D/saplog1

sdk 64G
vgextend p1dlogvg /dev/sdk


/dev/mapper/p1ddatavg-p1dsapdata1_lv
                       23G   22G     0 100% /sybase/P1D/sapdata1
/dev/mapper/p1ddatavg-p1dsapdata2_lv
                       23G   21G  1.1G  96% /sybase/P1D/sapdata2




lvextend -L +45G  /dev/mapper/p1dlogvg-p1dsyblog1_lv
resize2fs /dev/mapper/p1dlogvg-p1dsyblog1_lv


-----------------------------------------------------------------------------------------------------------------

25 July


1-340211491    Limited Brands, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_LBDSP1App00.imzcloud.ibmammsap.local[PROBLEM:3831171] Date:


1-340210111    Limited Brands, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_LBDSP1App01.imzcloud.ibmammsap.local[PROBLEM:3831191] Date:


1-340174011 ( CPU and Memory Utilization from April 2018 to July 2018) Chennai
10.13.1.12	DLBPECAP01		not installed   SNG working latest vmtools version 10.1.10.63510 (build-6082533) on 
10.13.1.13	DLBPECAP02
10.13.1.11	DLBPECDB00		Already latest and running	
10.13.1.21	DLBPEPDA00		installed but service not starting
10.13.1.15	DLBPBWAP01		updated the tools
10.13.1.14	DLBPBWDB00		HANA
10.13.1.17	DLBPNGDA00		updated the tools
10.13.1.18	DLBPCSDA00		updated the tools
10.13.1.20	DLBPWDAP00		updated the tools
10.13.1.16	DLBPBIDA00		updated the tools
10.13.1.19	DLBPSMDA00		updated the tools

VMwareTools-10.1.10-6082533.tar.gz



1-340156534




1-340218281    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_DLTHPEHP4.imzcloud.ibmammsap.loca





1-340217941  -  P2  -  IBM AMM Infrastructure
Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local
146.89.140.164



----------------------------------------------------------------------------------------------------------------------

28 July


1-339751543





SNG MCO
888-426-6840---- PC:  13296508



1.888.426.6840,
pc: 20931499        
Host Code:85795121

svhh1srv0	10.6.1.159




spsvbpaaapp01    10.6.3.20	A0EASG014XVM042
MRT - PP1    SAP NW Portal 7.4    Database Server    RedHat Linux    CLDENPDTBP1    10.168.1.144    10.198.0.144  SERVER STILL DOWN
spsvbpaaapp01
YHIBIPS01
YHIBWPS01
YHIEPS01
CLDENPDTBP1




/dev/mapper/



10.70.2.72 
10.70.2.14



1-340158926
DCGDFEAPP01    - DFE     - 10.197.6.25
DCGDFEDB00     - DFE     - 10.197.6.24
DCGHANAPREAP1  - RSF PAS - 10.197.5.23  - NOT COMPLETED (ISSUES) 

CHange
DCGHANAPREAP1	10.197.5.23	 London
[root@dcghanapreap1 tmp]# date
Sat Jul 28 03:40:41 BST 2018
[root@dcghanapreap1 tmp]# uname -a
Linux dcghanapreap1 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
[root@dcghanapreap1 tmp]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.9 (Santiago)


[root@dcghanapreap1 ~]# uname -a
Linux dcghanapreap1 2.6.32-754.2.1.el6.x86_64 #1 SMP Tue Jul 3 16:37:52 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
[root@dcghanapreap1 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.10 (Santiago)
[root@dcghanapreap1 ~]# date
Sat Jul 28 04:26:45 BST 2018





CEREBOS 
BJD	BWDEVApp1	10.70.1.72	DEV - NOT accessible
CRD	CRDEVApp1	10.70.1.79	DEV - NOT accessible 
HMD	HMDEVApp1	10.70.1.80	DEV - NOT accessible
BJD	BOBJDEVApp1	10.70.1.71	DEV - UP
CRQ	CRQAApp1	10.70.1.81	QAS - started UP and Running
HMQ	HMQAApp1	10.70.1.82	QAS - started UP and Running
BJP	BWPRDApp1	10.70.2.72	PRD - NOT Running  OS credntials not working
CRP	CRPRDApp1	10.70.2.76	PRD - UP
HMP	HMPRDApp1	10.70.2.77	PRD - UP
BJP	BOBJPRDApp1	10.70.2.71	PRD - UP   

8:36:14 AM: BJD	BWDEVApp1	10.70.1.72	DEV - NOT accessible
CRD	CRDEVApp1	10.70.1.79	DEV - NOT accessible 
HMD	HMDEVApp1	10.70.1.80	DEV - NOT accessible 		OK
BJP	BWPRDApp1	10.70.2.72	PRD - NOT Running  OS credntials not working





[root@dcghanapreap1 sssd]# rpm -qa|grep -i chef
chef-12.19.33-1.el6.x86_64

[root@SNG01AMMCHEF01 ~]# knife environment list
_default
cb4_production

./bootstrap_v12.sh -o cb4 -n dcghanapreap1 -l -d imzcloud.ibmammsap.local -t osonly -e cb4_production
export CHEF_ORG=cpw; 

/bootstrap_v12.sh -o cpw -n dcghanapreap1 -l -d imzcloud.ibmammsap.local -t osonly -e cpw_production




A0DIML014XVM001 eCPRDWeb1   IaaS        PRDA0DIML014XVM041 eCPRDWeb2   IaaS        PRDA0DIML014XVM042 eCPRDApp1   IaaS        PRDA0DIML014XVM043 eCPRDApp2   IaaS        PRDA0DIML014XVM044 eCPRDApp3   IaaS        PRDA0DIML014XVM045 eCPRDApp4   IaaS        PRDA0DIML014XVM046 eCPRDSolr1  IaaS        PRDA0DIML014XVM047 eCPRDDHApp1 IaaS        PRDeCPRDLog1   eCPRDLog1   IaaS        PRD





BJP	BWPRDApp1	10.70.2.72

cb4
[root@SNG01AMMCHEF01 ~]# export CHEF_ORG=cb4
[root@SNG01AMMCHEF01 ~]# knife environment list
_default
cb4_production

./bootstrap_v12.sh -o cb4 -n BWPRDApp1 -l -d imzcloud.ibmammsap.local -t osonly -e cb4_production





VM Name     Host Name   Server Type Landscape TierA0DIML014XVM001 eCPRDWeb1   IaaS        PRDA0DIML014XVM041 eCPRDWeb2   IaaS        PRDA0DIML014XVM042 eCPRDApp1   IaaS        PRDA0DIML014XVM043 eCPRDApp2   IaaS        PRDA0DIML014XVM044 eCPRDApp3   IaaS        PRDA0DIML014XVM045 eCPRDApp4   IaaS        PRDA0DIML014XVM046 eCPRDSolr1  IaaS        PRDA0DIML014XVM047 eCPRDDHApp1 IaaS        PRDeCPRDLog1   eCPRDLog1   IaaS        PRD
those



BJD    BWDEVApp1    10.70.1.72    DEV - NOT accessible
CRD    CRDEVApp1    10.70.1.77    DEV - NOT accessible
HMD    HMDEVApp1    10.70.1.78    DEV - NOT accessible



DCGHANAPREAP2    - RSF     - 10.197.5.24




10.70.2.72





10.6.1.168
10.6.1.167
10.6.1.166
10.6.1.165
10.6.1.164   
10.6.1.163
10.6.1.151
10.6.1.150
10.6.1.149
10.6.1.148
10.6.1.14   



10.198.12.16



10.197.3.16:/usr/sap/trans      /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    0       0
10.197.2.23:/sapmnt/RSF        /sapmnt/RSF              nfs      rw,hard,intr,rsize=32768,wsize=32768    0       0


10.197.3.16:/usr/sap/trans
                       94G   62G   28G  70% /usr/sap/trans



10.197.5.24	sssd service issue

mount //10.197.2.23:/sapmnt/RSF /sapmnt/RSF -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003       //10.7.1.171/sapexchange /mnt/sapexchangePT  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003  



Harsha
172.25.1.21:/usr/sap/trans     /usr/sap/trans          nfs     _netdev,defaults        1       2

172.25.1.21


sjmdepaa01	10.198.11.10	A0FGSG014XVM001	done
sjmdpqja01	10.198.11.19	A0FGSG014XVM011	
sjmdbjdb01	10.198.11.16 	A0FGSG014XVM008		df -hTP
sjmqgpdb01	10.198.12.15	A0FGSG014XVM019
sjmqpqja01	10.198.12.16	A0FGSG014XVM020

A0FGSG014XVM019	SJMQGPDB01
A0FGSG014XVM020	SJMQPQJA01
A0FGSG014XVM011	SJMDPQJA01



e2fsck -f -y /dev/mapper/vg00_root



1-340347241   sev1
SFTP Server - spsvmplmapp01 (10.70.111.46	A0EASG014XVM045	 	10.6.3.46	


1-340357191
Zabbix agent 


----------------------------------------------------------------------------------------------------------------------------

29 July


1-340342901    1-Critical    IBM MSD Infras - Cloud APPS    Summary: Zabbix_agent_on_0f.imzcloud.ibmammsap.local_is_unavailable
146.89.140.30



1-340365911    1-Critical    Suncor Energy Inc. (SNC)    Summary: Free_disk_space_is_less_than_5%_on_volume_C
10.73.10.52	SNCHBIBPA16



1-340328751    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_ammlon02custesx02.imzcloud.ibmammsap.local

1-340335091    2-Urgent    IBM AMM Infrastructure    Summary: SNG01AMMSOL04.imzcloud.ibmammsap.local_has_just_been_restarted


1-340352441    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_ammdal13custesx004.imzcloud.ibmammsap.local

1-340352811    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_free_swap_space_on_fra02ammsol01.imzcloud.ibmammsap.local

1-340356361    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_a0b4ca013esx019.imzcloud.ibmammsap.local

1-340366021    2-Urgent    IBM AMM Infrastructure    Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var


1-340266671    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_free_memory_on_server_DAL09AMMTS001

1-340296071    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_free_memory_on_server_DAL09AMMTS002

1-340296171    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_a0b4ca013esx016.imzcloud.ibmammsap.local

1-340307761    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_ammsng01custesx012.imzcloud.ibmammsap.local

1-340317751    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_dal09ammtsm001.imzcloud.ibmammsap.local

1-340320761    2-Urgent    IBM AMM Infrastructure    Summary: ITM Agent Offline: SM1-SNG01AMMSOL04:Sys
[root@SNG01AMMSOL04 ibmrmalik]# /opt/monitor/IBM/ITM/bin/cinfo -r

*********** Sun Jul 29 01:06:47 EDT 2018 ******************
User: root Groups: root sapinst
Host name : SNG01AMMSOL04        Installer Lvl:06.23.03.00
CandleHome: /opt/monitor/IBM/ITM
***********************************************************
Host           Prod  PID   Owner  Start  ID   ..Status
SNG01AMMSOL04  sa    6358  root   Jul27  SM1  ...running



1-340371321    2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local
146.89.140.30
top - 00:17:34 up 82 days, 14:03,  4 users,  load average: 9.65, 8.79, 7.58
Tasks: 1055 total,   1 running, 1054 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.9%us,  0.3%sy,  0.0%ni, 68.8%id, 28.9%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    31.315G total,   29.051G used, 2318.453M free, 1792.336M buffers
Swap:   12.000G total, 5831.293M used, 6456.703M free,   14.998G cached



1-340368701    2-Urgent    Raycap GmbH (RYC)  Summary: Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local
10.7.64.14   transfer to SAP
top - 07:22:06 up 108 days, 16:21,  5 users,  load average: 5.76, 5.65, 5.78
Tasks: 370 total,   2 running, 368 sleeping,   0 stopped,   0 zombie
Cpu(s): 96.8%us,  2.8%sy,  0.0%ni,  0.2%id,  0.0%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    19.507G total,   18.278G used, 1258.582M free,  308.430M buffers
Swap:   47.996G total, 5103.465M used,   43.012G free,   12.811G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
104633 db2rp4    20   0 6634m 3.6g 3.2g S 169.8 18.2 732:10.97 db2sysc 0
 41487 rp4adm    20   0  314m  28m  11m R 23.1  0.1   9:15.14 /usr/sap/RP4/SYS/exe/uc/linuxx86_64/R3load -i COEP.cmd -



1-340367391    2-Urgent    St Jude Medical Singapore - SAP HEC    Summary: Processor_load_is_too_high_on_sjmqbdba01.imzcloud.ibmammsap.local
top - 05:27:33 up 1 day,  2:57,  2 users,  load average: 0.00, 0.02, 0.02
Tasks: 381 total,   1 running, 380 sleeping,   0 stopped,   0 zombie
Cpu(s): 11.8%us,  3.5%sy,  0.0%ni, 84.6%id,  0.0%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:    31.349G total,   14.274G used,   17.075G free, 1074.301M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free, 5484.070M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
53401 qbjadm    20   0 4648m 300m  33m S 61.0  0.9 405:01.05 /usr/sap/QBJ/sap_bobj/enterprise_xi40/linux_x64//boe_cmsd -loggingPath /usr/sap/QBJ/sap_bobj/logging/
53753 qbjadm    20   0 7313m 1.4g  18m S 52.4  4.3 801:06.60 /usr/sap/QBJ/sap_bobj/enterprise_xi40/linux_x64/sapjvm/bin/java -Dcom.wily.introscope.agent.agentName




1-340368491    2-Urgent    IAG GBS Limited (IA1)        Summary: Processor_load_is_too_high_on_IA1WEBDSLBDR.imzcloud.ibmammsap.local
top - 05:31:32 up 6 days, 19:58,  1 user,  load average: 0.88, 0.37, 0.13
Tasks: 188 total,   1 running, 186 sleeping,   0 stopped,   1 zombie
Cpu(s):  2.0%us,  0.7%sy,  0.0%ni, 97.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7855.695M total, 5426.754M used, 2428.941M free,  692.688M buffers
Swap:   16.000G total,    0.000k used,   16.000G free, 2309.258M cached



1-340368511    2-Urgent    CONTROLADORA DE NEGOCIOS    Summary: Free_disk_space_is_less_than_10%_on_volume_C:
10.68.210.14
Cleaned up old log files. C drive is at 25% free now



1-340369921    2-Urgent    American Airlines SAP HEC-AMM    Summary: Processor_load_is_too_high_on_a1aerped1ap01.imzcloud.ibmammsap.local
[root@a1aerped1ap01 ~]# uptime
 23:53:24 up 2 days,  9:51,  1 user,  load average: 0.00, 0.00, 0.00



1-340370621    2-Urgent    Manitoba Telecom Services - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_prdbodsapp01.imzcloud.ibmammsap.local
[root@prdbodsapp01 ~]# uptime
 01:56:04 up 56 days,  5:50,  1 user,  load average: 0.03, 0.02, 0.00


1-340370591    2-Urgent    Manitoba Telecom Services - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_solnmgrdev.imzcloud.ibmammsap.local
[root@solnmgrdev ~]# uptime
 02:57:47 up 2 days, 14:45,  1 user,  load average: 0.02, 0.05, 0.06


1-340371231    2-Urgent    Bombardier Recreational Products Inc. (BR3)    Summary: Processor_load_is_too_high_on_BRPCAMLVSA04D.imzcloud.ibmammsap.local
[root@BRPCAMLVSA04D ibmrmalik]# uptime
 03:43:38 up 338 days, 16:33,  2 users,  load average: 0.19, 0.05, 0.01



1-340317183 sev1 for APP from Cust
same issue as above
spsvbpaaapp01  10.6.3.20
A0EASG014XVM042



spsvfpafsql01  
10.6.3.29

-------------------------------------------------------------------------------------------------------------------------------

30 July


1-340167051	


10.198.10.7	sjmpfpaa01	10.198.10.7	A0FGSG014XVM032
./bootstrap_v12.sh -o jud -n sjmpfpaa01 -l -d imzcloud.ibmammsap.local -t osonly -e jud_production 

[root@SNG01AMMCHEF01 ~]# knife environment list
_default
jud_production
jud_production_hkg02
jud_usproduction

User:root	
Password:@dm1nsjm  


A0FGSG014XVM018	SJMQFPAA01 10.198.12.14


DEV	sjmdfpaa01	10.198.11.17	10.195.2.17




1-340402891    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
10.73.10.45


1-340402931    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local


1-340405711    2-Urgent    SMRT Corp - SAP HEC-AMM    Summary: Ruuning_out_of_available_memory_on_server_cldbpcdtbp1.imzcloud.ibmammsap.local

1-340405821    2-Urgent    SMRT Corp - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_cldbpcdtbp1.imzcloud.ibmammsap.local


1-340408241    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local 


1-340404405	server reboot CS1 OS restart sev3

SVCS1SRV0	10.6.1.142




1-340409191 - Sev1 - ETO - AMM-SAP - Siebel - Not Validated - Zabbix_agent_on_ECCPAS00.imzcloud.ibmammsap.local_is_unavailable
10.6.1.144


1-340408301  Sancor Cooperativa de Seguros Ltda (SC8)  P3 -- @Ravi Malik
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var



1-340409691	sev3
CS1 OS restart
SVCS1SRV0	10.6.1.142

-------------------------------------------------------------------------------------------------
31 July


1-340438426 -Sev1 -  AGE - SAP HEC-AMM - Siebel - Not Validated - Ageas: SPP system


svjd1srv0 - 10.6.1.12
A0EASG014XVM003 	svjd1srv0



1-340427371    1-Critical    IBM AMM Infrastructure    Summary: Zabbix_agent_on_hkg02ammsol01.imzcloud.ibmammsap.local_is_unavailable



1-340428519  Please reset password for user es5adm	sev3


1-340317183
10.6.3.20 (APP - Applciation)
10.6.3.19 (APP -DB)  
officially the MCO for ageas is   

8:41:35 AM: Issue Start Date/Time        : SAT 7/28/2018 4:11AM SGT 
                                              : Resolved Date/Time        : SAT 7/28/2018 9.30PM SGT  




1-340429231    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_hkg02ammsol01.imzcloud.ibmammsap.local

1-340429971    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_fra02ammsol01.imzcloud.ibmammsap.local

1-340440971    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_lon02ammsol01.imzcloud.ibmammsap.local

1-340445751    2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local

1-340446901    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local 


1-340297767		Th67#4hg
A0DIML014XVM002		DONE
eCDEVWebApp1
IaaS
App
Singapore
DEV
10.60.1.142

A0DIML014XVM003		DONE
eCDEVDHApp1
IaaS
App
Singapore
DEV
10.60.1.141

A0DIML014XVM023		DONE
eCQAWeb1
IaaS
App
Singapore
QAS
10.60.1.143

A0DIML014XVM024		DONE
eCQAApp1
IaaS
App
Singapore
QAS
10.60.1.144

A0DIML014XVM025		DONE
eCQADHApp1
IaaS
App
Singapore
QAS
10.60.1.145 




1-340434656	SUNCOR : PR! addition of disk space to /usr/sap/DAA for teh Addiotnal app servers	sev3
snchecapa12	10.73.10.16
[root@snchecapa12 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.2G  44% /usr/sap/DAA

snchecapa13	10.73.10.17
[root@snchecapa13 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.2G  44% /usr/sap/DAA

snchecapa14	10.73.10.18
[root@snchecapa14 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.2G  44% /usr/sap/DAA

snchecapa15	10.73.10.19
[root@snchecapa15 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.1G  46% /usr/sap/DAA

snchecapa16	10.73.10.20
[root@snchecapa16 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.1G  46% /usr/sap/DAA

snchecapa19	10.73.10.23
[root@snchecapa19 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.1G  46% /usr/sap/DAA

snchecapa18	10.73.10.22
[root@snchecapa18 ibmrmalik]# df -h //usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.1G  46% /usr/sap/DAA

snchecapa17	10.73.10.21
[root@snchecapa17 ibmrmalik]# df -h /usr/sap/DAA                                
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-usrsapdaa_lv
                      4.0G  1.7G  2.1G  46% /usr/sap/DAA



1-340421071    2-Urgent    American Airlines SAP HEC-AMM    Summary: Processor_load_is_too_high_on_a1aerped1ap01.imzcloud.ibmammsap.local

1-340426121    2-Urgent    IAG GBS Limited (IA1)    Summary: Processor_load_is_too_high_on_IA1S4HQASAPP.imzcloud.ibmammsap.local

1-340366101    2-Urgent    Apleona GmbH (Grounding) (AP5)    Summary: Lack_of_free_swap_space_on_APLHRHK1.imzcloud.ibmammsap.local


1-340438837  AGEAS - SAP HEC-AMM  P3 
Enable IPS on SPSVEPDEHDB01
Request to enable IPS on SPSVEPDEHDB01 (EPP/RPP) 					
10.70.111.11 (10.6.3.11)

as part of security requirement under SAP HEC-AMM contract,


13x250=3250
2X400=800
7X550=3850
7900

-----------------------------------------------------------------------------------------------------------------------------
1 August


Sev1 for Suncor
user enablement for ssh


1-340486341  AGEAS - SAP HEC-AMM  P1 -- 
Zabbix_agent_on_svjq1srv0.imzcloud.ibmammsap.local_is_unavailable
10.6.2.12


1-340511551  IBM AMM Infrastructure  P2  Lack_of_available_memory_on_server_ammlon02custesx08.imzcloud.ibmammsap.local gm



1-340507121    IBM AMM Infrastructure    2-Urgent    Summary: Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.local



1-340513431 - Sev1 - AGE - SAP HEC-AMM - Siebel - Not Validated - Summary: Zabbix_agent_on_svjq1srv0.imzcloud.ibmammsap.local_is_unavailable



1-340317183	RCA  236419
10.6.3.20 (APP - Applciation)	10.6.3.20	A0EASG014XVM042
10.6.3.19 (APP -DB)  
officially the MCO for ageas is   

8:41:35 AM: Issue Start Date/Time        : SAT 7/28/2018 4:11AM SGT 
                                              : Resolved Date/Time        : SAT 7/28/2018 9.30PM SGT 




1-340515451  -  P1  -  AGEAS - SAP HEC-AMM  -  
Summary: Zabbix_agent_on_svjq1srv0.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:4025629] Date: Aug 1,2018 4:8 CUT Severity: Critical ResourceId: svjq1srv0


1-340510611, Need to add storage for /usr/sap/PR1. Currently it is at 90% utilization, this can be increased by 10 GB 

10:37:32 AM: 10.73.10.22 

[root@snchecapa18 ibmrmalik]# df -h  /usr/sap/PR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-pr1usrPR1_lv
                       20G   17G  2.1G  90% /usr/sap/PR1
[root@snchecapa18 ibmrmalik]# vgs pr1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  pr1appvg   2  14   0 wz--n- 159.99g 8.99g

lvextend -L +5G  /dev/mapper/pr1appvg-pr1usrPR1_lv
resize2fs /dev/mapper/pr1appvg-pr1usrPR1_lv



1-340516691  IBM AMM Infrastructure  P2  -- 
Summary: Free_disk_space_is_less_than_10%_on_volume_C:




1-337258991	sev 3    10.137.10.31
Summary: NTP_time_is_driffted_on_TWYSAPXF1APP1.imzcloud.ibmammsap.loca


--------------------------------------------------------------------------------------------------------------

2 Aug

1-340549431    Incident    2    SNC    8/1/2018     snchecapa18    Extend file system on PR1 host snchecapa18	sev3
Please extend FS /usr/sap/PR1 to 75 GB on PR1 host snchecapa18	10.73.10.22.Toronto

Current value :25 GB
After extension : 75GB

[root@snchecapa18 ibmrmalik]# df -h /usr/sap/PR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-pr1usrPR1_lv
                       25G   17G  7.3G  69% /usr/sap/PR1


[root@snchecapa18 ibmrmalik]# df -h /usr/sap/PR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pr1appvg-pr1usrPR1_lv
                      75G   17G   55G  23% /usr/sap/PR1



1-339482223
To Create new file sytem
hi Team, 

Good Day

Need the following Paths to be created and mounted on DEV an PRD Fiori Servers to be able to start installation:

/Sybase     	200 GB
/usr            100 GB

Note: /usr is already exists but with available space almost 7 GB
 
ECTFIODEV	10.5.10.12	
[root@ectfiodev ibmrmalik]# df -h /usr
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  4.9G  4.4G  53% /

[root@ectfiodev ibmrmalik]# df -h /usr
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      109G  4.9G   98G   5% /



ECTFIOPRD	10.5.10.11
[root@ectfioprd ibmrmalik]# df -h /usr
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  2.2G  7.2G  23% /

[root@ectfioprd ibmrmalik]# df -h /usr
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      109G  2.2G  101G   3% /


vg_data-lv_db

vg_data-lv_usr

[root@ectfiodev usr]# df -h /usr
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  2.2G  7.1G  24% /


vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab



vgextend mmpdatavg /dev/sdb

lvextend -L +50G /dev/mapper/mmpdatavg-mmpsapdata1_lv
resize2fs /dev/mapper/mmpdatavg-mmpsapdata1_lv




1-340540501    Meggitt Plc (MGG)    2-Urgent    Summary: Processor_load_is_too_high_on_MGGGBJPECCX05.imzcloud.ibmammsap.local


1-340534861    Meggitt Plc (MGG)    2-Urgent    Summary: Processor_load_is_too_high_on_MGGGBJPECCX07.imzcloud.ibmammsap.local[PROBLEM:4036166] Date

1-340529671    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_C1ECCD.imzcloud.ibmammsap.local


1-340554571  IBM AMM Infrastructure  P2



1-340552891	sev3
S for DR1 - 10.73.11.99 . /usr/sap/DR1 is at 100% 

 
1-340522561- P2 - Limited Brands, Inc. - SAP HEC-AMM-portal-not validated- "Summary: Lack_of_free_swap_space_on_LBDBQ1App01.imzcloud.ibmammsap.local 




1-340557551    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_DLTHPEHP1.imzcloud.ibmammsap.local




1-340558391  IBM AMM Infrastructure  P2  Processor_load_is_too_high_on_tor01ammsol01.imzcloud.ibmammsap.local 




1-340435870	build plan   ref 1-337905957 - SSGSA0120

-----------------------------------------------------------------------------------------------------------------------

3 Aug


1-340586731  Saudi Business Machines LTD (SBM)  P1




1-340546021    1-Critical    IBM MSD Infras - Cloud MONITORING    Summary: Zabbix_agent_on_frdal09prxy01.imzcloud.ibmammsap.local_is_unavailable




1-340317183	RCA  236419

10.6.3.20 (APP - Applciation)	10.6.3.20	A0EASG014XVM042
10.6.3.19 (APP -DB)  
officially the MCO for ageas is   

8:41:35 AM: Issue Start Date/Time        : SAT 7/28/2018 4:11AM SGT 
                                              : Resolved Date/Time        : SAT 7/28/2018 9.30PM SGT
https://mbpsjazz.austin.ibm.com:9443/jazz/web/projects/CMS%20NG#action=com.ibm.team.workitem.viewWorkItem&id=236419
RedHat case: CASE 02155442


1-340585461    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_lon02ammsol01.imzcloud.ibmammsap.local


1-340592201    2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local


1-340569971    2-Urgent    IBM AMM Infrastructure    Summary: ITM Agent Offline: db2dbh:sapha1db:UD 
server insccessible
Summary: ITM Agent Offline: db2dbh:sapha1db:UD Date: 08/02/2018 Severity: Major ResourceId: sapha1db TicketGroup: MSD_U_OPS_AUTO_ALERTS CustomerCode: amm InstanceId: REMOTE_fmsprdrtem003 InstanceValue: Offline InstanceSituation: MS Status ComponentType: ManagementInfrastructure Component: ITM6Agent ApplId: ITM MsgId: TIVTSA084E Node: sapha1db NodeAlias: 10.137.1.22 Manager: EIF Probe on ri3pa010 Agent: EIF Probe on ri3pa010 AlertKey: msd_msoffl_gmsc_agent AlertGroup: ITM_ManagedSystem EventKey: USRD0P0MSDP:4131838:amm



1-340590921    1-Critical    IBM AMM Infrastructure    Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable 


1-340590881    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_DLTHPEHP1.imzcloud.ibmammsap.local  



1-340591359	Add space to FS    sev3

Account: PT Blue Bird TBK (PBB)
FS:/usr/sap/trans
Hostname:PBBbwhdap00
IP:10.6.7.18
Space to add: 20GB




1-340570209


----------------------------------------------------------------------------------------------------------

6 Aug


14713

1-340670391    2-Urgent    IBM AMM Infrastructure        Summary: Lack_of_available_memory_on_server_ammlon02custesx12.imzcloud.ibmammsap.local
146.89.140.104

MGGGBJPECCX03

MGGGBJPECCX07



1-339368591	sev3	
Summary: FS_is_read_only_on_FRAMAGGRC0002.imzcloud.ibmammsap.local	10.69.0.160

[root@FRAMAGGRC0002 ibmrmalik]# /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /usr/sap/trans /usr/sap/trans filesystems are read-only


172.22.0.39:/usr/sap/trans				LONMAGGRC0001	Linux	10.69.0.39	172.22.0.39
                       40G  5.9G   32G  16% /usr/sap/trans

/usr/sap/trans 172.22.0.39(rw,sync,no_root_squash)


[root@FRAMAGGRC0002 trans]# cat /etc/fstab |grep /usr/sap/trans
#/dev/vg_saptrans/lv_saptrans           /usr/sap/trans  ext4    defaults       0 0
/dev/gd1appvg/gd1appvg_usr_sap_trans      /usr/sap/trans     ext4    defaults  1  2
#172.22.0.39:/usr/sap/trans /usr/sap/trans nfs rsize=8192,wsize=8192,timeo=14,intr
172.22.0.39:/usr/sap/trans /usr/sap/trans nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0

//10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

mount -t nfs 1172.22.0.39:/usr/sap/trans /usr/sap/trans 

 gd1appvg_usr_sap                 gd1appvg    -wi-ao----   1.00g 


1-340672221    2-Urgent    DEGASA S.A. de C.V. (DG1)    Summary: dg1erpprodg.imzcloud.ibmammsap.local_has_just_been_restarted 


1-340672561    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_DLTHPEHP1.imzcloud.ibmammsap.local

1-340672601    2-Urgent    MSC Industrial Supply Co.    Summary: Lack_of_free_swap_space_on_ms3wdclapp19.imzcloud.ibmammsap.local
 10.12.6.37



1-340674181 IBM AMM Infrastructure  P2  
Processor_load_is_too_high_on_tor01ammsol01.imzcloud.ibmammsap.local


1-339946361    restart DR DB server as per request from PDL

--------------------------------------------------------------------------------------------------------------------


7 Aug

1-340701361    Apleona GmbH (Grounding) (AP5)    2-Urgent    Summary: Lack_of_free_swap_space_on_APLHRHE1.imzcloud.ibmammsap.local 
 170.225.68.21



1-340699151    Apleona GmbH (Grounding) (AP5)    2-Urgent    Summary: Lack_of_free_swap_space_on_APLERPPD6.imzcloud.ibmammsap.local
 170.225.68.20




1-340680821	sev2
RS1 directory needs additional space
15GB to /usr/sap/RS1
[root@SVES1SRV0 ibmrmalik]# df -h /usr/sap/RS1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/rs1appvg-rs1usrRS1_lv
                       24G   23G  312K 100% /usr/sap/RS1

[root@SVES1SRV0 ibmrmalik]# df -h /usr/sap/RS1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/rs1appvg-rs1usrRS1_lv
                       39G   23G   15G  62% /usr/sap/RS1

[root@SVES1SRV0 ibmrmalik]#
[root@SVES1SRV0 ibmrmalik]# vgs rs1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  rs1appvg   1   5   0 wz--n- 250.00g 207.00g


AGEAS RAM upgrade pre checks
10.6.3.12	A0EASG014XVM024	spsvepaeapp01	32->512GB hotswappable
10.6.3.46	A0EASG014XVM045	spsvmplmapp01	16->256 GB hotswappable


9986973524



1-340696251    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_available_memory_on_server_ammche01custesx02  
      
1-340698491    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_lon02ammsol01.imzcloud.ibmammsap.local



1-340696651    2-Urgent    MSC Industrial Supply Co.    Summary: Lack_of_free_swap_space_on_ms3wdcladb43.imzcloud.ibmammsap.local


1-340697001    2-Urgent    Dilip Buildcon Limited (DLB)    Summary: Processor_load_is_too_high_on_DLBPSMDA00.imzcloud.ibmammsap.local


1-340698221    2-Urgent    Dilip Buildcon Limited (DLB)    Summary: Lack_of_free_swap_space_on_DLBPSMDA00.imzcloud.ibmammsap.local



1-340702701    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Lack_of_free_swap_space_on_snchtripa11.imzcloud.ibmammsap.local


1-340703151    1-Critical    COTY Inc (CTU)    Summary: Zabbix_agent_on_ctubwqb0ap02.imzcloud.ibmammsap.local_is_unavailable




1-340703111 / P2 / IBM MSD Infras - Cloud APPS  Summary: Processor_load_is_too_high_on_dal09ammsol02.imzcloud.ibmammsap.local


1-340703131 / P2 / IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local




1-340710971    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_dlthdehap.imzcloud.ibmammsap.local

-------------------------------------------------------------------------------------------------------------------------------------------

8 Aug


1-340736151    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1ECCQ.imzcloud.ibmammsap.local
10.199.2.11	CRITICAL | /mnt/sapexchangeIT




1-340738381    Meggitt Plc (MGG)    3-Standard    Summary: FS_is_read_only_on_MGGGBJPECCX05.imzcloud.ibmammsap.local




1-340713046		sev3
spsvopltapp01	10.6.3.35	10.70.111.35	A0EASG012XVM042



1-340713031 sev3
0396447
spsvtplnapp01 10.6.3.44		10.70.111.44	A0EASG012XVM057
and sphvtplnapp02 (DR) 
tomatosx
CR22  

9:32:51 AM: 300GB  
Additional space of 300 GB to be added to E Drive in Tomatosx Server.
Existing size of this E:\ drive is 69 GB.



1-340739251  IBM MSD Infras - Cloud APPS  P1  -- 

1-340738521  IBM AMM Infrastructure P2 -- 
a0b4ca013esx016


10.197.6.25
10.78.22.45
10.197.5.24
10.197.5.23	no access
10.197.5.22
id is ibmsalagwadi

-------------------------------------------------------------------------------------------------
9 Aug


1-340773661- P1- A1A - SAP HEC-AMM - Siebel - Not Validated - Free_disk_space_is_less_than_5%_on_volume_/usr/sap/PD2
/usr/sap/PD2	 10.4.10.58
[root@a1aerppd2ap01 ibmrmalik]# df -h /usr/sap/PD2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pd2appvg-pd2usrPD2_lv
                       34G   33G     0 100% /usr/sap/PD2
[root@a1aerppd2ap01 ibmrmalik]# vgs pd2appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  pd2appvg   1  13   0 wz--n- 128.00g 9.00g

[root@a1aerppd2ap01 ibmrmalik]# df -h /usr/sap/PD2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pd2appvg-pd2usrPD2_lv
                       40G   33G  5.3G  86% /usr/sap/PD2



1-340774041    Concessionaria Aeroporto Rio de Janeiro S.A. (CON)    3-Standard    Summary: NTP_time_is_driffted_on_conspbobdapp.imzcloud.ibmammsap.local



1-340737089 	SUNCOR : OS issue related to rootsh access	sev3	github issue for chef:Infra #930
Desc			SID	Hostname	IFN IP

DevÂ CRM -App		DC1	snchcrada11	10.73.11.102
[ibmrmalik@snchcrada11 ~]$ sudo su
sudo: unable to mkdir /var/log/sudo-io/00/01: Input/output error
sudo: error initializing I/O plugin sudoers_io


DevÂ CRM -App		DC1	snchcrada11	10.73.11.102
Biller Direct (App)	DV6	snchbdjda11	10.73.11.116
BOBJ DB			D1B	snchbibdd11	10.73.11.106
BO DS Database		D1D	snchdsbdd11	10.73.11.111
NWGW Application Server	DE1	sncheuada11	10.73.11.138



1-340774791    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local




SAP HEC AMM Sev1 1-340774151 - AGEAS (AGE) - SL-SINGAPORE-SNG01 - XQ1  URL is inaccessible 
svcq1srv0 	A0EASG014XVM017		10.6.2.16 
svhq1srv0	10.6.2.17
10.6.2.15




1-340776531    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_DLTHPEHP3.imzcloud.ibmammsap.local[PROBLEM:4217487] Date: Au



1-340776481    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_DLTHPEHP2.imzcloud.ibmammsap.local[PROBLEM:4217433] Date: Au




1-340775351    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_DLTHPEHP1.imzcloud.ibmammsap.local[PROBLEM:4217428] Date: Au

1-340174011 ( CPU and Memory Utilization from April 2018 to July 2018) Chennai
10.13.1.12	DLBPECAP01		not installed   SNG working latest vmtools version 10.1.10.63510 (build-6082533) on 
10.13.1.13	DLBPECAP02
10.13.1.11	DLBPECDB00		Already latest and running	
10.13.1.21	DLBPEPDA00		installed but service not starting
10.13.1.15	DLBPBWAP01		updated the tools
10.13.1.14	DLBPBWDB00		HANA
10.13.1.17	DLBPNGDA00		updated the tools
10.13.1.18	DLBPCSDA00		updated the tools
10.13.1.20	DLBPWDAP00		updated the tools
10.13.1.16	DLBPBIDA00		updated the tools
10.13.1.19	DLBPSMDA00		updated the tools

C:\Users\IBM_ADMIN\Documents\DLBPECAP01-performance.xls



1-340775881    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Processor_load_is_too_high_on_PECAP01.imzcloud.ibmammsap.local


1-340778471    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local


Sev-1 (1-340778691 ) that SHP DB is unavailable
a1ahecsmpdb01    10.4.9.20	pHana:dalhana-512-9.xsportal.local
a1ahecsmpap01    10.4.9.18
a1ahecsjpap02    10.4.9.19


1-340783421 IBM AMM Infrastructure  P2  Lack_of_available_memory_on_server_a0b4ca013esx016.imzcloud.ibmammsap.local
a0b4ca013esx016	

-------------------------------------------------------------------------------------------------------------------------

10 Aug



1-340805511  - Sev1 - CB4 - SAP HEC-AMM - Siebel - Not Validated - Zabbix_agent_on_CRDEVApp1.imzcloud.ibmammsap.local_is_unavailable
10.70.1.79



1-339693956  snapshot request




1-340803861    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
 10.199.2.31	
CRITICAL | /mnt/sapexchangeIT

[root@C1BWD ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /mnt/sapexchangePT /mnt/sapexchangePT /mnt/sapexchangePT filesystems are read-only





1-340805881    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1ECCQ.imzcloud.ibmammsap.local



1-340223227	Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x	sev3	London
ERCSOLPRD1	10.5.1.106	
ERCNWQ01	10.5.1.105	
ERCERPP1	10.5.1.103




1-340807601  - P1- CB4 - SAP HEC-AMM -Siebel - Not Validated - : Zabbix_agent_on_CRDEVApp1.imzcloud.ibmammsap.local_is_unavailable 
10.70.1.79
[root@CRDEVApp1 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  36999) is running...
[root@CRDEVApp1 ibmrmalik]# uptime
 11:18:57 up 13 days,  1:29,  1 user,  load average: 0.12, 0.07, 0.04




Ageas: Storage and memory Change Request 1-340713046	replication validation
a0easg012xvm042 spsvopltapp01
a0easg012xvm057 spsvtlplnapp01	A0B4HK012VCS002	10.6.3.44




1-340795861  IBM AMM Infrastructure  P1
146.89.140.220



1-340809771    CMA CGM (CMA)    3-Standard    Summary: NTP_time_is_driffted_on_smedisbxsu1.imzcloud.ibmammsap.local[PROBLEM:4242052] Date: Aug 10


1-340809621    CMA CGM (CMA)    3-Standard    Summary: NTP_time_is_driffted_on_smboquaqb3.imzcloud.ibmammsap.local[PROBLEM:4241682] Date: Aug 10,


1-340809561    CMA CGM (CMA)    3-Standard    Summary: NTP_time_is_driffted_on_smecctrnte1.imzcloud.ibmammsap.local[PROBLEM:4241636] Date: Aug 10


1-340809531    CMA CGM (CMA)    3-Standard    Summary: NTP_time_is_driffted_on_spspnas.imzcloud.ibmammsap.local[PROBLEM:4241605] Date: Aug 10,201


-----------------------------------------------------------------------------------------------------------------------------------


13 AUg

1-340783421
Summary: Lack_of_available_memory_on_server_a0b4ca013esx016.imzcloud.ibmammsap.local



1-340874361  - Sev1 - PBB - IC4SAP-SL - Siebel - Not Validated - Zabbix_agent_on_PBBs4hpap00.imzcloud.ibmammsap.local_is_unavailable



1-340844122
Hi Team,
We need to increase space in Open Text Database server for "F Drive"
and "G" drive.
 
For F:\ Drive - 75 GB space to be extended For G drive - 25 GB space
to be extended
 
Please increase the space as per below details.
 
OS - Windows
 
host - spsvopitsql01
 
Server: 10.70.111.34	10.6.3.34	A0EASG012XVM041
 
Drive: "F Drive " and "G" Drive
 
Space to be increased: For F:\ Drive - 75 GB space to be extended and
For G drive - 25 GB space to be extended
 
Attached is screenshot of drive where space to be extended.



1-340352971	sev1
Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var
10.13.1.12 



1-340754691
reset the unlockcount and change  bluemix server OS user

----------------------------------------------------------------------------------------------------------------------

14 Aug

1-340911591    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
CRITICAL | /mnt/sapexchangeIT



1-340911511    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1ECCD.imzcloud.ibmammsap.local
CRITICAL | /mnt/sapexchangeIT

mount /10.7.1.171/sapexchange /mnt/sapexchangePT -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

/10.7.1.171/sapexchange /mnt/sapexchangePT  cifs  credentials=/etc/sapexchangePT_credential,uid=908,gid=5003

//10.7.1.171/sapexchange /mnt/sapexchangePT  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003



1-340908411    Egyptian Refining Company    3-Standard    EGR - Request the OS performance and utilization details for all VMs
EGR - Request the OS performance and utilization details for all VMs for the last 1 month (14 July - 13 Aug 2018)

List of VMs

Host Name	CFN IP	IFN IP
ERCERPD1	10.10.0.101	10.5.1.101	A0DDUK014XVM001	C:\Users\IBM_ADMIN\Documents\A0DDUK014XVM001-performance.xls
ERCERPP1	10.10.0.106	10.5.1.103	A0DDUK014XVM003 C:\Users\IBM_ADMIN\Documents\A0DDUK014XVM003-performance.xls
ERCERPQ1	10.10.0.102	10.5.1.102	A0DDUK014XVM002	C:\Users\IBM_ADMIN\Documents\A0DDUK014XVM002-performance.xls
ERCNWD01	10.10.0.103	10.5.1.104	A0DDUK014XVM004	C:\Users\IBM_ADMIN\Documents\A0DDUK014XVM004-performance.xls
ERCNWQ01	10.10.0.104	10.5.1.105	A0DDUK014XVM005	C:\Users\IBM_ADMIN\Documents\A0DDUK014XVM005-performance.xls
ERCSOLPRD1	10.10.0.105	10.5.1.106	A0DDUK014XVM006	C:\Users\IBM_ADMIN\Documents\A0DDUK014XVM006-performance.xls

Datacentre - SL-LONDON-LON01

Due to ADS Services was down on 12 August 2018 (1-340863921) that have impacted & disrupting the client's business that heavily relies on printing invoices and reports

Reason : To identify which of the VMs that facing an issues during the business hours and what time it was happened.

Please email to Rizal (Rizal Rosli/Malaysia/IBM), Victor (Victor A. Botas/Romania/IBM) and Bogdan Boagiu/Romania/IBM






1-340904091    Suncor Energy Inc. (SNC)    1-Critical    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/
-rw-------    1 root   root   34359738368 Aug 13 14:43 swapfile
[root@snchsmada11 /]# hostname -i
10.73.11.53


1-340903011    Suncor Energy Inc. (SNC)    1-Critical    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/
10.73.11.54 
-rw-------    1 root   root   34359738368 Aug 13 14:47 swapfile
[root@snchsmjda11 /]# hostname -i
10.72.1.54




1-340820201
SVMS1SRV0 10.92.99.147	10.6.1.147
Directory : E:\downloads\msg.PM
 
Once done with the install, please get them to reboot the server and update us.
 
SNO	Component 	Current Version	Target Version
4	Microsoft MSXML	3.0 6.0 	MSXML from version 4.0 Service Pack 3
6	Microsoft .NET Framework	4.0.30319.36399	4.6.1
8	Microsoft Visual C++ 2015 (Update 3) Redistributable Package MFC	 	14.0.24212



1-340910381  IBM AMM Infrastructure  P2
Summary: Free_disk_space_is_less_than_10%_on_volume_F: 





1-340916371 IBM MSD Infras - Cloud APPS  P2 Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local --


Toronto	
snchbdjda11 // 10.73.11.116	10.73.11.116	10.72.1.116
[root@TOR01AMMCHEF01 ~]# knife environment list
_default
snc_production
snc_production_68

snchbdjda11.imzcloud.ibmammsap.local


./bootstrap_v12.sh -o snc -n snchbdjda11 -l -d imzcloud.ibmammsap.local -t osonly -e snc_production 




1-340914611  IBM MSD Infras - Cloud Shared  P2 Summary: MSD:Low server memory. Memory available is 5% (808MB).

---------------------------------------------------------------------------------------------------------------------------------

16 Aug


1-340984511    AGEAS - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_agesvedmhsrv0.imzcloud.ibmammsap.local
 10.6.1.176

agesvedmhsrv0:/home/ibmrmalik # uptime
 01:44am  up 43 days  4:35,  2 users,  load average: 1.19, 0.97, 1.73
top - 01:44:34 up 43 days,  4:35,  2 users,  load average: 0.86, 0.91, 1.69
Tasks: 395 total,   1 running, 394 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.4 us,  0.2 sy,  0.0 ni, 99.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  25176908+total, 15180182+used, 99967272 free,    10000 buffers
KiB Swap:  2097148 total,        0 used,  2097148 free. 45487096 cached Mem


1-340973271
10.13.1.18, the file system /sapdb/backups 150 GB



1-340985791    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchltaqa13.imzcloud.ibmammsap.local[PROBLEM:4384513] Date: Aug

1-340985731    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchpijqa11.imzcloud.ibmammsap.local[PROBLEM:4384434] Date: Aug

1-340985521    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchzraqa12.imzcloud.ibmammsap.local[PROBLEM:4384073] Date: Aug

1-340985501    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchzraqa11.imzcloud.ibmammsap.local[PROBLEM:4384038] Date: Aug

1-340985371    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchecaqa20.imzcloud.ibmammsap.local[PROBLEM:4383837] Date: Aug

1-340985351    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchecaqa19.imzcloud.ibmammsap.local[PROBLEM:4383810] Date: Aug

1-340985231    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchecaqa15.imzcloud.ibmammsap.local[PROBLEM:4383484] Date: Aug

1-340984791    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchltaqa12.imzcloud.ibmammsap.local[PROBLEM:4384502] Date: Aug

1-340984741    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Lack_of_free_swap_space_on_snchpijqa12.imzcloud.ibmammsap.local[PROBLEM:4384445] Date: Aug


1-340988491 - Sev1 - IBM AMM Infrastructure - Siebel - Not Validated - No_Data_available_for_datastore_WDC04POOL4DS198


1-340989451 - Sev1 - IBM AMM Infrastructure - Siebel - Not Validated - No_Data_available_for_datastore_WDC04POOL1DS222



1-340994531 - Sev1 - PBB - IC4SAP-SL - Siebel - Not Validated - Summary: Zabbix_agent_on_PBBs4hpap00.imzcloud.ibmammsap.local_is_unavailable


1-340994571 / PBB / SEV1 / Siebel / Not validated / Summary: Zabbix_agent_on_PBBs4hdap00.imzcloud.ibmammsap.local_is_unavailable


1-340994591- P1 - PT Blue Bird TBK (PBB)-portal-not validated- "Summary: Zabbix_agent_on_PBBs4hqap00.imzcloud.ibmammsap.local_is_unavailable



1-340994031    MSC Industrial Supply Co.    2-Urgent    Summary: Processor_load_is_too_high_on_ms3wdcladb24.imzcloud.ibmammsap.local


1-340995851    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Processor_load_is_too_high_on_DLBPSMDA00.imzcloud.ibmammsap.loca




1-340998231    
/upgrade  will be new FS  	10.210.1.21	

with 50GB space  
sde                                8:64   0  100G  0 disk
sdd                                8:48   0   32G  0 disk

 upgrade_lv    bdaappvg -wi-a----- 50.00g

/dev/mapper/bdaappvg-upgrade_lv

vgextend mmpdatavg /dev/sdb


[root@CI3BWHANADEVA ibmrmalik]#

vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount <full lv path>  dir_path
vi /etc/fstab

/dev/mapper/bdaappvg-upgrade_lv		/upgrade 	ext3    _netdev,defaults        1       2




spsvbpaaapp01	10.6.3.20



1-340988561    IBM AMM Infrastructure    1-Critical    Summary: No_Data_available_for_datastore_A0F3US026BCA101



1-340993151    IBM AMM Infrastructure    2-Urgent    Summary: Lack_of_free_swap_space_on_WDC04AMMSOL04.imzcloud.ibmammsap.local


1-341000271    AGEAS - SAP HEC-AMM    1-Critical    Summary: Zabbix_agent_on_spsvepdehdb01.imzcloud.ibmammsap.local_is_unavailable


1-341003621 - DW3 is down
SMBWDEVDW3 >> 10.78.22.46
add 40 GB swap

0
[root@smbwdevdw3 ibmrmalik]# free -hg
             total       used       free     shared    buffers     cached
Mem:           31G       8.0G        23G        39M       722M       5.6G
-/+ buffers/cache:       1.7G        29G
Swap:         8.0G         0B       8.0G

/dev/mapper/VolGroup-lv_swap 	swap                    swap    defaults        0 0

[root@smbwdevdw3 ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   1   7   0 wz--n- 39.51g 2.50g


sdc                                8:32   0   64G  0 disk
sdd                                8:48   0   32G  0 disk
sde                                8:64   0  100G  0 disk

--------------------------------------------------------------------------------------------------------------

18 Aug


1-340992041	sev2
Password Reset request for CI3S4HANADEVA --> devadm




1-341090691	Free_disk_space_is_less_than_5%_on_volume_/TSMLOGS/TLOG	sev1



1-341091411	Free_disk_space_is_less_than_5%_on_volume_/db2/LM2/db2dump sev1



1-341092741	sev3
Summary: FS_is_read_only_on_fra02ammtsm001.imzcloud.ibmammsap.local
/run/user/0
146.89.140.242



1-341090441 IBM AMM Infrastructure 2-Urgent
Free_disk_space_is_less_than_10%_on_volume_/TSMLOGS/TLOG



1-341097381	sev3 	146.89.140.204
Processor_load_is_too_high_on_FRA02AMMADC001



1-340867271 ref change
1-340904091    Suncor Energy Inc. (SNC)    1-Critical    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/
-rw-------    1 root   root   34359738368 Aug 13 14:43 swapfile
[root@snchsmada11 /]# hostname -i
10.73.11.53


1-340903011    Suncor Energy Inc. (SNC)    1-Critical    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/
10.73.11.54 
-rw-------    1 root   root   34359738368 Aug 13 14:47 swapfile

[root@snchsmada11 /]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap


[root@snchsmjda11 ibmrmalik]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap





1-340223765  18 Aug 6:30 PM IST
TRIO-CEM-AMM 3.x-Q318: Apply latest Q318 bundle  patches on RH Linux OS Ver 5.x/6.x



1-340743881	clear cache for 2 AGEAS servers spsvepajapp01	

----------------------------------------------------------------------------------------------------------------------

19 Aug


1-341116261	sev2
Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local


1-341117171	sev2
Summary: nfsserver.imzcloud.ibmammsap.local_has_just_been_restarted



1-339891597	sev3
CEM-AMM 3.x-Q318: Apply latest Q318 bundle  patches on RH Linux OS Ver 5.x/6.x




1-341117621	sev2
DALTFSFDBP001.imzcloud.ibmammsap.local_has_just_been_restarted



1-341117591	sev2
DALTFSFAPP001.imzcloud.ibmammsap.local_has_just_been_restarted


1-341117561	sev2
DALTFSWDPP001.imzcloud.ibmammsap.local_has_just_been_restarted



1-339891597	Change
3.30PM 8/19/2018	Dallas09	DONE
Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x



1-340211031	Change
Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x



1-341120121

--------------------------------------------------------------------------------------------------------


21 Aug


1-341174141    2-Urgent    Manitoba Telecom Services - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_R3QATapp.imzcloud.ibmammsap.local



1-340517402	sev3	2.30 PM IST
CEM-AMM 3.x-Q318: Apply latest Q318 bundle patches on RH Linux OS Ver 5.x/6.x
ECCDAS00
ECCDDB00
uname -a;date;cat /etc/redhat-release




1-341145768	CMA CGM - Kindly increase VolGroup FS to 10GB space sev3
 smemdevdm1	10.78.22.39	10 GB	VolGroup	done
 smemdevdm3	10.78.22.29	10 GB	VolGroup	done
 smedidevdu1	10.78.22.55	10 GB	VolGroup	done
 smedidevdu3	10.78.22.35	10 GB	VolGroup	done
 smbwdevdw3	10.78.22.46	10 GB	VolGroup	done
 smgrcdevdg1	10.78.22.48	10 GB	VolGroup	done
 smdsdevdo1	10.78.22.30	10 GB	VolGroup	done
 smtmdevdt1	10.78.22.41	10 GB	VolGroup	done
 smemquaqm3	10.78.24.26	10 GB	VolGroup	done
 smediquaqu3	10.78.24.32	10 GB	VolGroup	done
 smbwquaqw3	10.78.24.41	10 GB	VolGroup	done
 smgrcquaqg1	10.78.24.43	10 GB	VolGroup	done	
 smemuatum3	10.78.26.21	10 GB	VolGroup	done
 smediuatuu3	10.78.26.25	10 GB	VolGroup	done
 smbwuatuw3	10.78.26.28	10 GB	VolGroup	done



1-341184381 - Kindly check memory and swap size then increase swap size
SMTMSBXST1, ST1 >> 10.78.20.13

/dev/mapper/VolGroup-lv_swap

SPSPNAS >> 10.78.22.11 
/dev/VolGroup/lv_swap
at 8 GB currently
+56G




SPSVOPITSQL01 	10.6.3.34	10.70.111.34	A0EASG012XVM041




 

1-341157131  add 128GB disk to server name - sncheuadd11  before it becomes a sev1? 
SNCHEUADD11 	10.73.11.137	

*/dev/mapper/de1datavg-de1sapdata1_lv
                    23G   21G  1.4G  94% /sybase/DE1/sapdata1
/dev/mapper/de1datavg-de1sapdata2_lv
                    23G   21G  1.4G  94% /sybase/DE1/sapdata2
/dev/mapper/de1datavg-de1sapdata3_lv
                    23G   21G  1.4G  94% /sybase/DE1/sapdata3
/dev/mapper/de1datavg-de1sapdata4_lv
                    23G   21G  1.4G  94% /sybase/DE1/sapdata4

---------------------------------------------------------------------------------------------------------------------------

22 Aug


1-341186271	sev2

Source - msg.PM TROO DEV server details - 10.92.99.133 	10.6.1.34 svmd1srv0	A0EASG012XVM011
Target - msg.PM Sandbox server details -       10.92.99.147 10.6.1.147 svms1srv0




SMPOSBXSX8 	10.78.20.20
SMPODEVDX8 	10.78.22.22
SMPOQUAQX8 	10.78.24.22

telnet proxysg.cma-cgm.com 8080


swap was incorrectly configured that was taking space from / as a swapfile, removed it and extended the swap lv


1-340907281	sev2
[root@snchbwada11 /]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap



1-340907291	Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/	sev2



1-340907351	Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/	sev3	
[root@snchgrada11 /]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0
 /swapfile   swap    swap    defaults  0   0



1-340906601	Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/	sev2

1-340906711	Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/	sev3
[root@snchepjda11 /]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0
 /swapfile   swap    swap    defaults  0   0



1-340907401	Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/	sev2

1-340906781	Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/	sev2
[root@snchecada11 /]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0
 /swapfile   swap    swap    defaults  0   0


-----------------------------------------------------------------------------------------------------------------

23 Aug


1-341248371  -  P2  -  IBM AMM Infrastructure 
 Summary: Lack_of_free_memory_on_server_DAL09AMMTS002	sev2




1-341004341 	FS /idocs missing on all ECC sap system in Blx side	sev3
mmgras01.blx.cma-cgm.com (MMGRAS, 10.78.22.12)		CFN 10.5.22.12
smecc-dev-de1.cma-cgm.com, (smeccdevde1, 10.78.22.18)
smecc-qua-qe1.cma-cgm.com (SMECCQUAQE1, 10.78.24.19)	10.5.24.19
smecc-uat-ue3.cma-cgm.com (SMECCUATUE3, 10.78.26.16)	10.5.26.16
smecc-trn-te1.cma-cgm.com (SMECCTRNTE1, 10.78.28.17)	10.5.28.17

4 servers and 1 source server 

NAS FS : /idocs on each ECC system on BLX( dev, qua, trn, uat).. Size : 10G Owner : adm Group : sapsys

mount -t nfs 10.5.22.12:/idocs/trn /idocs
10.5.22.12:/idocs/trn /idocs nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0




1-340556558	8/23/2018 3:30 PM IST
CEM-AMM 3.x-Q318: Apply latest Q318 bundle patches on RH Linux OS Ver 5.x/6.x




1-341256321 - IAG GBS Limited (IA1)- SAP09 - Sev3 (User: Cognizsh need SUDO permission/acce)




1-341227101	sev1
Summary: 66.248.241.253(66.248.241.253) is unreachable



SNCHSMADA11	10.73.11.53	ok
SNCHSMJDA11	10.73.11.54	ok
	snchtnada11	10.73.11.11
SNCHCRADA11	10.73.11.102	ok
	SNCHZRADA11	10.73.11.103
SNCHPIJDA11	10.73.11.114	ok
snchbwada11	10.73.11.100	ok
snchgrada11	10.73.11.105	ok
snchepjda11	10.73.11.112	ok
snchecada11	10.73.11.99	ok
snchmdada11	10.73.11.104	ok
snchltada11	10.73.11.115	ok
snchcuada11	10.73.11.117	ok
snchapada11	10.73.11.101	ok
snchbdjda11	10.73.11.116		7GB swap
snchbwjda11	10.73.11.135	ok
snchtrida11	10.73.11.136	ok
sncheuada11	10.73.11.138



----------------------------------------------------------------------------------------------------------------------------

24 Aug

1-341364541- P1 - Sancor Cooperativa de Seguros Ltda (SC8)Summary: Zabbix_agent_on_sc8sansfiqa14.imzcloud.ibmammsap.local_is_unavailable




1-340844122 sev2
G drive extension for AGEAS server





1-341376051 DyStar Singapore Pte Ltd (DYS)- 3-Standard
FS_is_read_only_on_dyssmdasmd40.imzcloud.ibmammsap.local
10.6.12.21
dyssmdasmd40:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
rm: cannot remove '/run/user/95872/gvfs/testfile': Permission denied
CRITICAL |  /run/user/95872/gvfs filesystems are read-only


dyssmdasmd40:/run/user/95872 # ls -ltr
ls: cannot access 'gvfs': Permission denied
total 0
d????????? ? ?         ?              ?            ? gvfs




1-341380011 Delta Airlines, Inc. - SAP HEC-AMM 2-Urgent
Processor_load_is_too_high_on_dlthpehdb.imzcloud.ibmammsap.local



1-341380711	sev2
Free_disk_space_is_less_than_10%_on_OS_volume_/tmp




1-340348201	 ITM Agent Offline: QAS-tngqaser:tngqaseapp20:mySAP   sev2
Host          Prod  PID    Owner  Start  ID   ..Status
TNGQASEAPP20  sa    43265                QAS  ...process not running
./itmcmd agent -o QAS start sa




1-341387271 	ETD - /interface Permission Issue sev3
ms3wdclpap200
10.12.6.87

user etdadm ftpetd  ftpetd_po
group mscftp

Summary:
1. create user etdadm
2. create user ftpadm
3. create user ftpadm_po
4. create group mscftp
5. add all users above to this group
6. create new subfolders under /interfaces as ETD and MFT
7. under /interface/ETD create the following folder and chown etdadm:mscftp:
8. /interface/ETD/AssettAccounting
9. /interface/ETD/GeneralLedger
10. /interface/ETD/AccountsReceivable
11. /interface/ETD/AccountsPayable
and under MFT create the following:
12. /interface/MFT/GeneralLedger
13. /interface/MFT/AccountsReceivable
14. /interface/MFT/Reconciliation
15. /interface/MFT/SalesCommissions
16. /interface/MFT/AssetAccounting
17. /interface/MFT/BankingTreasury
18. /interface/MFT/AccountsPayable




1-341361431    sev2
Processor_load_is_too_high_on_IA1S4HQASAPP.imzcloud.ibmammsap.local




1-341362331	sev2
Processor_load_is_too_high_on_IA1S4HPRDAPP.imzcloud.ibmammsap.local




1-341363551     sev2
Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local




1-340346521	sev2
Summary: ITM Agent Offline: DEV-tngdever:tngdeveapp40:mySAP




1-340347101	sev2
ITM Agent Offline: QAS-TNGQASEAPP20_QAS_





1-341386353  sev3
Please add 60GB on sncheuapd12 in below FS
[root@sncheuapd12 ibmrmalik]# df -h /sybase/PE1/saplog1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pe1logvg-pe1syblog1_lv
                       22G   18G  3.4G  84% /sybase/PE1/saplog1
[root@sncheuapd12 ibmrmalik]# vgs pe1logvg
  VG       #PV #LV #SN Attr   VSize  VFree
  pe1logvg   1   4   0 wz--n- 32.00g 1020.00m






1-341381920 sev3
Reuqest for VM snap shot - on OP1 - CI 09 ARIBA upgrade
cldproappp1 - 10.198.0.75	A0CTSG014XVM037
CLDPRODTBP1 - 10.198.0.145	A0CTSG014XVM036


------------------------------------------------------------------------------------------------------------------


27 Aug


1-341432231	sev2
ITM Agent Offline: ECQ:SU6SUNECQ00



1-341444021	sev2
ITM Agent Offline: ECP-su6sunecp:su6sunecp00



1-341455711	sev2
 ITM Agent Offline: ECQ-su6sunecq:su6sunecq00



1-341468291	sev2
ITM Agent Offline: MPD-amerpdv_MRD_00:



1-341426531
[root@CLDGRCDTBP1 ibmrmalik]# /opt/monitor/IBM/ITM/bin/cinfo -r

*********** Mon Aug 27 19:03:00 +08 2018 ******************
User: root Groups: root sapinst
Host name : CLDGRCDTBP1  Installer Lvl:06.23.03.00
CandleHome: /opt/monitor/IBM/ITM
***********************************************************
Host         Prod  PID    Owner  Start  ID   ..Status
CLDGRCDTBP1  oy    6234                 GP1  ...process not running
CLDGRCDTBP1  oy    4449                 GP1  ...process not running
CLDGRCDTBP1  oy    20499                GP1  ...process not running
CLDGRCDTBP1  oy    4493   root   Jul28  GP1  ...running


1-341363591	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var



1-341394031	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var



1-341418721	sev3
NTP_time_is_driffted_on_AHPOQ2SAP01.imzcloud.ibmammsap.local




1-341404781	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/opt

[root@MGGGBJPECCX01 nmon_logs]# df -h /opt
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_opt
                      5.8G  4.0G  1.6G  73% /opt





1-339681278	sev3
Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x	
DLTHSGGAT	10.4.5.24		
DLTHSPSPI	10.4.5.26	




1-340770031	sev3
Update Linux kernel and OS packages using YUM for Redhat  5.x/6.x
FBDHANAAPP
FBDBWAPP
FBDFIRAPP
FBDFIRWD


uname -a;date;cat /etc/redhat-release



--------------------------------------------------------------------------------------------------------------------------

28 Aug


1-341517311 MSC Industrial Supply Co. 2-Urgent
Lack_of_free_swap_space_on_ms3wdcappsd1.imzcloud.ibmammsap.local





10.6.3.102 

SR #1-341502101 Unable to Login to 3.x server for AGEAS   ( SVCC2SRV1   10.6.3.102 ) 

SVCC2SRV1	10.6.3.102



1-341518271	sev3
Unable to access OS - Restart host



1-341516531	sev3
NTP_time_is_driffted_on_ageSNG01web01.imzcloud.ibmammsap.local




1-340723791	sev1
Zabbix_agent_on_snchecapd11.imzcloud.ibmammsap.local_is_unavailable



1-340890561
Free_disk_space_is_less_than_5%_on_OS_volume_/var




1-340907111	sev1
Zabbix_agent_on_sncheuaqa12.imzcloud.ibmammsap.local_is_unavailable


-------------------------------------------------------------------------------------------------------

29 Aug


1-341548751 - Cerebos Pacific Limited - SAP HEC-AMM - Sev1
Zabbix_agent_on_ecqahanadb1.imzcloud.ibmammsap.local_is_unavailable




1-341547331    SAP07    2-Urgent    Raycap GmbH (RYC)    RYC 
Processor_load_is_too_high_on_deeh11ryc1009.imzcloud.ibmammsap.loca



1-341556131 - West African Cotton Company - Sev2 
Processor_load_is_too_high_on_AFRS4HDEV.imzcloud.ibmammsap.local




admin/SAPibm#1 on jenkins page

--------------------------------------------------------------------------------------------------------------

30 Aug


1-341588601 / IBM / SEV2 / Siebel / Not validated / Summary: Processor_load_is_too_high_on_0f.imzcloud.ibmammsap.local 
146.89.140.30	



1-341540331   restart ntp  estart NTP service on MG2ERPQASDB anytime between 7pm to 9pm Bangladesh time 
NTP_time_is_driffted_on_MG2ERPQASDB.imzcloud.ibmammsap.local



1-341539247
VM snapshots
svaq1srv0	A0EASG014XVM021		10.6.2.18	10.70.110.18


http://w3-01.ibm.com/download/standardsoftware/PC/lang_en/issiCatalogPC.html



1-341394351	sev2
Lack_of_free_swap_space_on_ms3wdclapp01.imzcloud.ibmammsap.local





1-341566771  sev2
Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local[

./bootstrap_v12.sh -o sm5 -n CLDERPAPPD1 -l -d imzcloud.ibmammsap.local -t osonly -e sm5_production




1-341597871    SAP07    2-Urgent    Raycap GmbH (RYC)    RYC
Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local



1-340903191   sev2
Free_disk_space_is_less_than_10%_on_OS_volume_/[



1-340906781	sev2
Free_disk_space_is_less_than_10%_on_OS_volume_/[

[root@snchecada11 ibmrmalik]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                       44G  5.9G   36G  15% /





1-341600981 -  IBM AMM Infrastructure - Sev1
Zabbix_agent_on_tor01ammsol01.imzcloud.ibmammsap.local_is_unavailable




10.12.10.84 
reboot   system boot  4.4.21-69-defaul Fri Jun 29 00:49 - 05:04  (04:15)
ibmlyu   pts/0        Aug 29 22:32 (146.89.140.21)


CTUBWQB2DB01:/tmp # who -b
         system boot  Aug 27 19:51

reboot   system boot  4.4.121-92.80-de Fri Jun 29 14:53 - 12:54 (3+22:00)
reboot   system boot  4.4.114-92.64-de Fri Jun 29 10:21 - 14:38  (04:17)
reboot   system boot  4.4.114-92.64-de Fri Jun 29 07:02 - 10:06  (03:04)
reboot   system boot  4.4.21-69-defaul Fri Jun 29 05:18 - 06:48  (01:30)
reboot   system boot  4.4.21-69-defaul Fri Jun 29 00:49 - 05:04  (04:15)

shutdown system down  4.4.121-92.80-de Mon Aug 27 16:16 - 19:51  (03:34)

CTUBWQB2DB01:/etc # who -b -u
         system boot  Aug 27 19:51
(unknown) :0           Aug 27 19:51   ?          8999 (:0)
ibmlyu   pts/0        Aug 29 22:32 18:03        2781 (146.89.140.21)
ibmhmuppalla pts/3        Aug 30 15:26 00:36      125086 (146.89.140.21)
ibmrmalik pts/5        Aug 30 15:48   .        132711 (146.89.140.20)

--------------------------------------------------------------------------------------------------------------------

31 Aug


1-341632681    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_free_swap_space_on_lon02ammtsm001.imzcloud.ibmammsap.local 




1-341600981	sev1
Zabbix_agent_on_tor01ammsol01.imzcloud.ibmammsap.local_is_unavailable





1-341624671	sev2
Processor_load_is_too_high_on_lnasv218.imzcloud.ibmammsap.local




1-341634381 sev1
Free_disk_space_is_less_than_5%_on_OS_volume_/tmp




1-341505061 Limited Brands, Inc. - SAP HEC-AMM 3-Standard-
NTP_time_is_driffted_on_LBDBIPPRDDB1.imzcloud.ibmammsap.local




1-341635151 Aceros Chilca - MEPSA 2-Urgent
Lack_of_free_swap_space_on_acerosqasecc.imzcloud.ibmammsap.local





1-341638231 SMRT Corp - SAP HEC-AMM 2-Urgent
Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.local



1-341639991	sev1
Zabbix_agent_on_snchmdapa11.imzcloud.ibmammsap.local_is_unavailable




1-341640021	sev1
Zabbix_agent_on_snchecapa14.imzcloud.ibmammsap.local_is_unavailable



 1-341642683 SNC APP server No Login   sev2



1-341644591	sev1


1-341641341    SAP12    Suncor Energy Inc. (SNC)    1-Critical
Zabbix_agent_on_snchpijpa12.imzcloud.ibmammsap.local_is_unavaila

-----------------------------------------------------------------------------------------------------------


3 Sept

1-341673141    2-Urgent    Raycap GmbH (RYC)    Summary: Free_disk_space_is_less_than_10%_on_volume_/db2/RQ2/log_dir





1-341677251    2-Urgent    IBM AoD Business Systems    Summary: Lack_of_free_swap_space_on_hkg02ammtsm001.imzcloud.ibmammsap.local




1-341684501    2-Urgent    DFJ Trung Group Corporation (TNG)    Summary: Processor_load_is_too_high_on_tngprodeapp00.imzcloud.ibmammsap.local




1-341686591    2-Urgent    DFJ Trung Group Corporation (TNG)    Summary: Processor_load_is_too_high_on_TNGPRODEAPP01.imzcloud.ibmammsap.local


--------------------------------------------------------------------------------------------------------------------------------------


4 Sept


1-341713191 Summary:Free_disk_space_is_less_than_5%_on_OS_volume_/var IBM AMM Infrastructure    1-Critical



1-341718311    Limited Brands, Inc. - SAP HEC-AMM    1-Critical    LBD
Zabbix_agent_on_LBDPQ1App01.imzcloud.ibmammsap.local_is_unavailable



1-341716821    2-Urgent    American Airlines SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_AHBSISBX01.imzcloud.ibmammsap.local




1-339810622 4 Sept 1130 AM
C1BJD	10.199.2.33	A0DSDE014XVM012
		
		
C1BWD	10.199.2.31	A0DSDE014XVM008
		
		
C1ECCD	10.199.2.12	AODSDE014XVM003

Notify IBM:
DPE "MaheshNaik <mahenaik@in.ibm.com>" 
PDL Andrei Fofirca-Iacob (andrei.fofirca@ro.ibm.com)
Customer:
Matteo Lancellotti (matteo.lancellotti@panariagroup.it)

Inform to mschedul@in.ibm.com (CEM team) if this change Failed/On-hold.


10.199.2.12    /usr/sap/ECD/DVEBMGS40/exe/sapstartsrv: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.15' not found
[root@C1ECCD ibmrmalik]# strings /usr/lib64/libstdc++.so.6 | grep GLIBC


ln -s /opt/rh/SAP/lib64/compat-sap-c++.so /usr/sap/lib/libstdc++.so.6 
chown -R ecdadm:sapsys /usr/sap/lib   




1-341643131	sev3
1. rename consptdfapq (10.16.1.30)
/usr/sap/trans to /usr/sap/trans_old

[root@consptdfapq ibmrmalik]# df -h /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/tdqappvg-usrtrans_lv
                       40G   29G  9.4G  76% /usr/sap/trans

[root@consptdfapq ibmrmalik]# cat /etc/fstab |grep /usr/sap/trans
/dev/tdqappvg/usrtrans_lv       /usr/sap/trans  ext3    _netdev,defaults       12





2. rename conspdfdbapp (10.16.1.104)
/usr/sap/trans to /usr/sap/trans_old


3. mount CONSPTDFAPD:/usr/sap/trans (10.16.1.19)  to both servers:

consptdfapq:/usr/sap/trans (10.16.1.30)

conspdfdbapp:/usr/sap/trans (10.16.1.104)


----------------------------------------------------------------------------------------------------------

5 Sept


1-341501036   patching change




1-341754231 - SL-Chennai-01 - Multiple - IC4SAP-SL - Host (ammche01custesx02) disconnected

DLBPSMDA00	08:18:41 up  7:45,
DLBSECAP01	08:20:17 up 475 days,
DLBPECAP01	08:20:44 up  4:30,
DLBDNGDA00	08:21:14 up 11:25
DLBDBWAP01	08:21:33 up 11:26
DLBPNGDA00	08:21:57 up  7:49
DLBPWDAP00	08:22:16 up 11:28
DLBPBIDA00	08:22:51 up 11:26
DLBDBIDA00	08:23:49 up 11:25
DLBPBWAP01	08:24:08 up 31 min
SU6SUNECP00	08:24:28 up  3:13


SU6SUNECD00	08:51:44 up  8:08
DLBQBWAP01	08:52:07 up  8:10
DLBPECAP01	08:52:28 up  5:02
DLBPSMDA00	08:52:47 up  8:19
DLBPNGDA00	08:53:10 up  8:20


DLBDBWDB00	09:08:09 up 482 days
DLBDCSDA00	09:08:34 up 574 days,
DLBDECAP01	09:09:50 up 12:11
DLBDECDB00	09:10:48 up 217 days
DLBDEPDA00	09:11:10 up 488 days
DLBDWDAP00	09:12:05 up 12:18
DLBPBWDB00	09:12:29 up 440 days
DLBPCSDA00	09:12:48 up 445 days
DLBPECAP02	09:13:12 up 445 days
DLBPECDB00	 09:13:40 up 440 days
DLBPEPDA00	09:14:03 up 326 days
DLBQBWAP01	09:14:21 up  8:32,
DLBQBWDB00	09:14:41 up 440 days
DLBQECAP01	09:15:03 up 384 days
DLBQECDB00	09:15:58 up 389 days
DLBQEPDA00	09:16:49 up 12:18
DLBSECDB00	09:17:38 up 578 days
SU6SUNECD00	09:18:08 up  8:34,
SU6SUNECQ00	09:18:25 up 12:19

/etc/init.d/zabbix-agent status;uptime;date


-----------------------------------------------------------------------------------------


7 Sept



1-341826281	10.68.213.13  Helped Geovanni with the login issue on 2 servers
1-341826271	10.68.214.13


1-341713191 Summary:Free_disk_space_is_less_than_5%_on_OS_volume_/var IBM AMM Infrastructure    1-Critical




1-341828351- P1 -PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)-portal-not validated- "Summary: Zabbix_agent_on_C1ECCP.imzcloud.ibmammsap.local_is_unavailable




1-341734391    2-Urgent    IBM AMM Infrastructure        Summary: Processor_load_is_too_high_on_sng01ammsol01.imzcloud.ibmammsap.local
146.89.140.157


1-341765671    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/tmp/opscode_log


1-341772321    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/tmp/opscode


1-341790101    2-Urgent    Arnoldo Mondadori Editore SpA  (ARM)    Summary: Processor_load_is_too_high_on_armfksap207.imzcloud.ibmammsap.local



1-341830271    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local


1-341828531    2-Urgent    IBM AoD Business Systems    Summary: Lack_of_free_swap_space_on_hkg02ammtsm001.imzcloud.ibmammsap.local



1-341806081  time diff on QA and prod servers 
QAS : 10.134.1.12 (working fine)
PRD : 10.134.1.11 (we are seeing error on apps) 

11:09:35 AM: both are one customer Vietnam UTC +7 

-----------------------------------------------------------------------------------------------------------

10 Sept



1-341883541  IBM AMM Infrastructure  P1 AMM-DELIVERY-TECH



1-341784951
clear cache on OS 

svjd1srv0	10.6.1.12
svjq1srv0	10.6.2.12



1-341886991    2-Urgent    Dilip Buildcon Limited (DLB)    Summary: ITM Agent Offline: PBI:DLBPBIDA00:SYB



1-341887051    2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local  


1-341567411	sev3
NTP_time_is_driffted_on_eccdb0qas.imzcloud.ibmammsap.local




1-341662791	sev3
NTP_time_is_driffted_on_eccddb00.imzcloud.ibmammsap.local


1-341663141	sev3
NTP_time_is_driffted_on_loncfgchp0003.imzcloud.ibmammsap.local[



1-341872001	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var

[root@APLBCSDI3 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  3.6G  1.1G  78% /var




1-341566541
NTP_time_is_driffted_on_tngproderpdb.imzcloud.ibmammsap.local
10.134.1.11




1-341695891	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/home
[root@tngprodeapp00 ~]# df -h /home
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_home
                      2.0G   29M  1.8G   2% /home



1-341695941	sev2
Free_disk_space_is_less_than_10%_on_OS_volume_/home
10.134.2.11
[root@tngprodeapp00 ibmrmalik]# df -h /home
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_home
                      2.0G   29M  1.8G   2% /home



1-341897621    IBM AMM Infrastructure    2-Urgent    AMM



1-341898501    IBM AMM Infrastructure    2-Urgent    AMM



1-341891121	sev1
150 GB..../sybase/YWP/sapdata5


[root@YHIBWPS01 ibmrmalik]# vgs ywpdatavg
  VG        #PV #LV #SN Attr   VSize VFree
  ywpdatavg  11   7   0 wz--n- 1.49t 50.96g


/dev/mapper/ywpdatavg-ywpsapdata4_lv
                      350G  256G   77G  77% /sybase/YWP/sapdata4

sdg                                    8:96   0  400G  0 disk

lvcreate -L 150G -n ywpsapdata5_lv ywpdatavg

mkfs.ext2/3/4 path of lvdisplay

mkfs.ext3 /dev/mapper/ywpdatavg-ywpsapdata5_lv

mount -t ext3 /dev/mapper/ywpdatavg-ywpsapdata5_lv /sybase/YWP/sapdata5

mount -t ext4 block_device /mount/point 

/dev/mapper/VolGroup-usrsapdaa_lv /usr/sap/DAA ext4 defaults 1 2



---------------------------------------------------------------------------------------------------------------


11 Sept




1-341837351	sev3
Processor_load_is_too_high_on_PHSSAPDEV01



1-341842651
Free_disk_space_is_less_than_20%_on_volume_D:



1-341852431	sev3
Processor_load_is_too_high_on_PHSBWDEV01



1-341662801	sev3
NTP_time_is_driffted_on_YHIBWPS01.imzcloud.ibmammsap.local
[root@YHIBWPS01 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
*sng01ammadc001. 146.89.140.139   5 u  717 1024  377    0.465  -266.31 263.763
+sng01ammadc002. 146.89.140.138   5 u  350 1024  377    0.543  -299.81 257.205
[root@YHIBWPS01 ibmrmalik]# ntpstat
synchronised to NTP server (146.89.140.140) at stratum 6
   time correct to within 822 ms
   polling server every 1024 s




1-341715791	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var
[root@YHIBWPS01 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.0G  2.6G  44% /var


1-341851851	sev3
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/YWP
[root@YHIBWPS01 ibmrmalik]# df -h /usr/sap/YWP
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ywpappvg-ywpusrYWP_lv
                       20G  8.1G   11G  43% /usr/sap/YWP



1-341871801	sev3 
NTP_time_is_driffted_on_YHISMDS01.imzcloud.ibmammsap.local
[root@YHISMDS01 ibmrmalik]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
+sng01ammadc001. 146.89.140.139   5 u  391 1024  377    0.519  -246.18 189.358
*sng01ammadc002. 146.89.140.138   5 u  210 1024  377    0.528  -330.43 238.835
[root@YHISMDS01 ibmrmalik]# ntpstat
synchronised to NTP server (146.89.140.141) at stratum 6
   time correct to within 1041 ms
   polling server every 1024 s





1-341743851	sev2
ITM Agent Offline: RZ:ECQ-ECQ-SU6SUNECQ00:RDB



1-341917461    1-Critical    IBM AoD Business Systems
A0ETUS016BCA086	146.89.140.53





1-341847141	sev2	10.69.0.70
/sybase/SPA
added 5 GB




1-341916901    2-Urgent    IAG GBS Limited (IA1)    Summary: Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local


1-341749291	sev2
ITM Agent Offline: RZ:ECD-ECD-SU6SUNECD00:RDB
[root@SU6SUNECD00 ibmrmalik]# /opt/monitor/IBM/ITM/bin/cinfo -r

*********** Tue Sep 11 11:58:21 IST 2018 ******************
User: root Groups: root sapinst
Host name : SU6SUNECD00  Installer Lvl:06.23.03.00
CandleHome: /opt/monitor/IBM/ITM
***********************************************************
Host         Prod  PID   Owner  Start  ID   ..Status
SU6SUNECD00  rz    5748  root   Sep05  ECD  ...running
SU6SUNECD00  sa    6184  root   Sep05  ECD  ...running




1-341749281	sev2
ITM Agent Offline: ECD-SU6SUNECD00






1-341747361	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var

[root@iplsaboat01 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.0G  2.7G  43% /var

----------------------------------------------------------------------------------------------------------------

12 Sept

1-341934634
Source: 10.6.1.24 E:  we have FS-PRO folder copy this to target
Target: 10.6.1.161 , E drive  

target has FS-PRO already, rename to FS-PRO_Old 
FD1 tp FH1 Binary copy (FSPRO)
SID: FD1 , FH1
Hostnames: svfd1srv0, svfh1srv0

SAP_LocalAdmin(SVFH1SRV)\SAP_LocalAdmin)
FH1User(SVFH1SRV)\FH1User)

robocopy /e /b /purge E:\empty E:\FS-PRO_OLD



LBD HK
LBDBQ1APP01    10.8.8.48   
LBD    LBDBODDEVAPP2    10.8.8.29  rebooting
LBD    LBDBODDEVAPP3    10.8.8.30  rebooting
LBD    LBDBODDEVAPP4    10.8.8.31  rebooting	conn ref


LBD    LBDBODDEVDB1    10.8.8.27   rebooting
09:31:50 up 22 min,  1 user,  load average: 0.00, 0.00, 0.02



LBD    LBDWD1APP80    10.8.8.13    rebooting
 09:26:04 up 16 min,  1 user,  load average: 0.08, 0.04, 0.04

LBD    LBDWD2APP80    10.8.8.16    rebooting
 09:24:46 up 15 min,  1 user,  load average: 0.03, 0.03, 0.05



LBD    LBDWD3APP80    10.8.8.32    rebooting
 09:23:39 up 14 min,  1 user,  load average: 0.06, 0.09, 0.12



1-341979281    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Processor_load_is_too_high_on_sncheuaqa11.imzcloud.ibmammsap.local[



1-341974881    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
/mnt/sapexchangeIT		10.199.2.31


1-341974671    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    2-Urgent    Summary: FS_is_read_only_on_C1ECCD.imzcloud.ibmammsap.local
/mnt/sapexchangeIT	10.199.2.12





1-341977741	sev1
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/QE1




Helped Wasif with his Windows login error




1-341961801 Arnoldo Mondadori Editore SpA  (ARM)  P1
Zabbix_agent_on_armfksap207.imzcloud.ibmammsap.local_is_unavailable
10.7.102.41



 ~= RMALIK

57993213692

1-341984821	sev1	fs increase
Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/UB3[PROBLEM:5194485] Date: Sep 12,2018 7:13 CUT Severity: Critical ResourceId: smbouatub3 TicketGroup: ApsSAPTechnical CustomerCode: cma InstanceId: Zabbix-AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/UB3 InstanceValue: 3.08 % ComponentType: ZABBIX Component: AMM_APSSAP_Technical_LINUX SubComponent: Free_disk_space_on_SAP_filesyste Node: smbouatub3.imzcloud.ibmammsap.local NodeAlias: 10.78.26.12 Manager: Zabbix: fmsprdzab001 Agent: EIF Probe on fmsprdeifp003.fms.ibmcloud.com AlertKey: AMM_APSSAP_Technical_LINUX:Free_disk_space_on_SAP_filesyste_/usr/sap/UB3 AlertGroup: ZabbixEvent EventKey: USRD0P0MSDP:4343803:cma 
1-341984821



London DIxon
DCGHANAPREAP1 / 10.197.5.23 
[root@LON02AMMCHEF01 ibmrmalik]# export CHEF_ORG=cpw
[root@LON02AMMCHEF01 ibmrmalik]# knife environment list
_default
cpw_dr
cpw_production

[root@LON02AMMCHEF01 ibmrmalik]# knife node list|grep -i DCGHANAPREAP1
dcghanapreap1.imzcloud.ibmammsap.local

./bootstrap_v12.sh -o cpw -n DCGHANAPREAP1 -l -d imzcloud.ibmammsap.local -t osonly -e cpw_production


------------------------------------------------------------------------------------------------------------------------

13 Sept


1-342011211    Toyota Financial Services - SAP HEC-AMM    2-Urgent    Summary: Lack_of_free_swap_space_on_DALTFSECC0001.imzcloud.ibmammsap.local



1-342010121    IBM AMM Infrastructure    2-Urgent    Summary: Lack_of_available_memory_on_server_ammlon02custesx03.imzcloud.ibmammsap.local[
422980 MB used of 524176 MB little less than 20% mem free





1-341745131	sev3
 Free_disk_space_is_less_than_20%_on_OS_volume_/var




1-342013491    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local



1-341870101	sev3
NTP_time_is_driffted_on_DLBPCSDA00.imzcloud.ibmammsap.local



1-341966431	sev3
NTP_time_is_driffted_on_DLBQECAP01.imzcloud.ibmammsap.local



1-342009231    IBM AMM Infrastructure    2-Urgent    AMM	71% memory used and 29% is still free 


1-342007631    IBM AMM Infrastructure    2-Urgent    AMM  	less than 17% mem free


1-342002254    Delta Airlines, Inc. - SAP HEC-AMM    3-Standard    mount /interfaces/HME folder in app serv  -- RFS
mount /interfaces/HME folder in app serv
Please mount this /interfaces/HME folder in below App server HQP system.	10.250.17.33(DLTHQEHAP 	10.4.5.33	10.250.17.33)
 
 HQP : dlthqpspi.hrhec.delta.com	10.4.5.36	10.250.17.36 


1-342016649  Delta Airlines, Inc. - SAP HEC-AMM  Create /interfaces/HME folder and mount  -- RFS
Create /interfaces/HME folder and mount
Attached the /interface/HME subfolders to be created similar to
PROD(HPE) system.



	


1-341363921	sev3
Drive_with_Media_Errors_on_host_CLDERPDTBQ3.imzcloud.ibmammsap.local
snghana-1024-7.xsportal.local
10.116.35.165
root/LX8AS8fB




FBTPRDFIRAPP 	10.4.27.16
[root@fbtprdfirapp ibmrmalik]# vmware-toolbox-cmd -v
10.0.9.55972 (build-3917699)


------------------------------------------------------------------------------------------------------------------


15 Sept



1-340675068 15 Sept 430 AM-Mario is starting as he is primary

Patching change 

unqsapbpcqas


A0ERUS014XVM002





1-339715458 15 Sept 900 Hrs AM
A0DBUS014XVM017


A0DBUS014XVM018


A0DBUS014XVM019


A0DBUS014XVM020


DLTHPEHP5
vix error code = 21011



1-342081131 2-Urgent    IBM MSD Infras - Cloud APPS     Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local


1-342082841 2-Urgent    DEGASA S.A. de C.V. (DG1)     Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/bkptmp
[root@dg1erpprodg ibmrmalik]# df -h /bkptmp/
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/prodatavg-backuptmp_lv
                      296G  276G  5.0G  99% /bkptmp

[root@dg1erpprodg bkptmp]# du -a . |sort -n -r |head -n 15
288541936       .
191041784       ./backupfull
81162420        ./backupfull/prd.dmp
70554332        ./backupfull/BKPPREUPD_PRD_09092018.dmp
67202396        ./upgrade
45975908        ./upgrade/export
39325028        ./backupfull/PRD_TRAN_BK
21224664        ./upgrade/upd
16666012        ./MEDIOS_ECC60EHP7
8273508 ./upgrade/export/lang2
8273504 ./upgrade/export/lang2/51050610
8273256 ./upgrade/export/lang2/51050610/DATA_UNITS
8268180 ./upgrade/export/expupg2
8268176 ./upgrade/export/expupg2/51050610
8267928 ./upgrade/export/expupg2/51050610/DATA_UNITS

DEGASA S A de C V (DG1) 	DG1ERPPRODG 	10.143.30.11	10.10.30.11 	Production 	Predeployment 	SAP ERP	PRO	00	DG1		8003 		ERP 6 0 	App DB 	GeovanniCruz Morales 	JairoGonzalez Ramos 	Sybase ASE 	RHEL 6.9		Full Service 	IC4SAP SL 	DG1 	SL-DALLAS-DAL13



1-342087361	sev1
10.73.11.74
Free_disk_space_is_less_than_5%_on_volume_/sapmnt/log[


[root@snchecatd11 ibmrmalik]# df -h /sapmnt/log
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hanashared-log
                      532G  512G   21G  97% /sapmnt/log




1-342082901 	10.73.11.99	/usr/sap/DR1
[root@snchecada11 ibmrmalik]# df -h /usr/sap/DR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/dr1appvg-dr1usrDR1_lv
                      162G  146G  8.0G  95% /usr/sap/DR1
[root@snchecada11 ibmrmalik]# vgs dr1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  dr1appvg   5  13   0 wz--n- 258.98g 9.49g




1-342084261 Summary: Free_disk_space_is_less_than_10%_on_volume_/sapmnt/log
[root@snchecatd11 ibmrmalik]# df -h /sapmnt/log
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hanashared-log
                      662G  516G  147G  78% /sapmnt/log
taken care vide 1-342087361


1-342084581
Summary: Free_disk_space_is_less_than_10%_on_volume_/usr/sap/DB1
[root@snchbwada11 ibmrmalik]# df -h /usr/sap/DB1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/db1appvg-db1usrDB1_lv
                       24G   21G  1.6G  94% /usr/sap/DB1
[root@snchbwada11 ibmrmalik]# vgs db1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  db1appvg   1  13   0 wz--n- 128.00g 22.00g




1-342022621
cache clear on 10.6.3.13



1-342083503 - COTY Inc (CTU) - PB0/QB1/QB2 - ALL SCALEOUT - Crashing
Washington
PB0
===========================
CTUBWPB0AP01 10.12.10.30	no issue
CTUBWPB0AP02
CTUBWPB0AP03
CTUBWPB0AP04
CTUBWPB0AP05
CTUBWPB0DB01 (HANA DB)
CTUBWPB0DB02
=============================
QB1
===========================
CTUBWQB1AP01 (SAP App)
CTUBWQB1DB01 (HANA DB)
ctubwqb1ap02 (SAP App)
ctubwqb1ap03
=============================
QB2
============================
CTUBWQB2AP01 (SAP App)
CTUBWQB2AP02 (SAP App1)
CTUBWQB2AP03
CTUBWQB2AP04
CTUBWQB2DB01 (HANA DB)
CTUBWQB2DB02



CTUBWPB0DB01
CTUBWQB1DB01
CTUBWQB2DB01

----------------------------------------------------------------------------------------------------------


16 Sept


Meenal: 9049743595	arun mohan
Bad magic number in super-block while trying to open /dev/mapper/centos-root
Couldn't find valid filesystem superblock.



1-339810779 16 Sept 530 AM

C1BWP	10.199.1.30	A0DSDE014XVM007
		
		
C1BJP	10.199.1.32	A0DSDE014XVM011






1-339132922 16 Sept 7.30 AM IST

PRDBODS01	10.74.5.16	MON
	
	
PRDBODSAPP01	10.74.5.17	MON
	
	
PRDSAP1APP	10.74.5.11	MON
	
	
prdepdb1	10.74.5.14	MON
	
	
prdepapp1	10.74.5.15	MON





1-342037663	sev1
run telnet test for 3 host



1-342097851    2-Urgent    Arnoldo Mondadori Editore SpA  (ARM)    Summary: Processor_load_is_too_high_on_armfksap207.imzcloud.ibmammsap.local


1-342093271    2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local




1-342096491 - P1 - CTU - SAP HEC-AMM - Siebel - Validated by EUS Matrix - QB1 System Down again
WDC HANA servers

CTUBWQB1DB01	10.12.10.22	coty-wdc04-phana-4096-6.imzcloud.ibmammsap.local	10.65.162.134	root/VR7bsjy4
CTUBWQB1DB02	10.12.10.53



1-342104581    2-Urgent    Raycap GmbH (RYC)    Summary: Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local




1-342086081    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Lack_of_free_swap_space_on_snchtripa11.imzcloud.ibmammsap.local
/opt/BESClient/bin/BESClient -RPMHelper





1-339810708 16 Sept 1130 AM
C1ECCPAP	10.199.1.14
	
	
C1ECCP		10.199.1.10

Starting Startup Agent sapstartsrv
/usr/sap/ECP/ASCS01/exe/sapstartsrv: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.15' not found (required by /usr/sap/ECP/ASCS01/exe/sapstartsrv)

mkdir /usr/sap/lib 
ln -s /opt/rh/SAP/lib64/compat-sap-c++.so /usr/sap/lib/libstdc++.so.6 
chown -R ecqadm:sapsys /usr/sap/lib


"/mnt/sapexchangeIT" 

 /mnt/sapexchangeIT

.10	//10.3.1.1/sapexchange /mnt/sapexchangeIT cifs credentials=/etc/sapexchangeIT_credential,uid=908,gid=5003
.14 	//10.3.1.1/sapexchange /mnt/sapexchangeIT cifs credentials=/etc/sapexchangeIT_credential,uid=908,gid=5003

.14
username=YSRVSAP
password=SAPPAN2012


.10
username=YSRVSAPEC
password=EC_SAP00

mount //10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/   -t cifs -o username=YSRVSAP,password=SAPPAN2012,uid=908,gid=5003  on .14

mount //10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/   -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003  on -10



//10.126.71.10:/sapmnt/ECP /sapmnt/ECP -t nfs  rw,hard,intr,rsize=32768,wsize=32768 0 0




both servers




1-342105211	sev2
Summary: Processor_load_is_too_high_on_ms3wdcladb13.imzcloud.ibmappsap.local



1-342105671    2-Urgent    IBM MSD Infras - Cloud APPS    Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local  

146.89.140.30

top - 03:29:29 up 19 days, 17:46,  2 users,  load average: 6.36, 10.66, 11.98
Tasks: 1106 total,   1 running, 1104 sleeping,   0 stopped,   1 zombie
Cpu(s):  3.6%us,  0.6%sy,  0.0%ni, 68.4%id, 27.3%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.315G total,   31.022G used,  300.855M free, 1976.270M buffers
Swap:   12.000G total, 2094.918M used,    9.954G free,   18.112G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
20428 dsmadm    20   0 6917m 1.4g 1.4g S 20.8  4.6   4:44.79 DSM_50_DIA_W5
30684 dsmadm    20   0 6913m 1.2g 1.1g S  3.6  3.7   1:34.29 DSM_50_DIA_W2
18998 db2dsm    20   0 12.6g 3.3g 2.8g S  3.0 10.5   1629:37 db2sysc
26314 dsmadm    20   0  789m  30m  18m S  2.0  0.1  58:56.55 gwrd


-------------------------------------------------------------------------------------------------------------------------


18 Sept


1-342105761	sev2	
Summary: Processor_load_is_too_high_on_snchecatd11.imzcloud.ibmammsap.local



1-342073631     1-Critical     Summary: Zabbix_agent_on_sng01stjude21vmplsvyatta001_is_unavailable[PROBLEM:5260127]

1-342073661     1-Critical     Summary: Zabbix_agent_on_sng01stjude21vmplsvyatta002_is_unavailable[PROBLEM:5260148]
119.81.115.44


1-341784811 backup failed vware tool update
SU6SUNECP00 	10.13.3.13	10.10.10.141	chennai



1-342161581	sev3
Not able to login 10.7.103.20	ARMFKSAP103 Frankfurt
parent SR 1-342113131




1-341933164	sev2
telnet install on 10.6.1.161


1-342166371
CAche clear on svjq1srv0



1-342117677
Server Role	Hostname	IFN IP (IBM) / CFN IP (cust)
Application Server - Development (DEV)	TNGDEVEAPP40	10.134.2.14 / 172.24.2.14
Application Server - Qulity (QAS)	TNGQASEAPP20	10.134.2.13 / 172.24.2.13



1-342172531  -  P2  -  Suncor Energy Inc. (SNC)
 Free_disk_space_is_less_than_10%_on_volume_/sapmnt/log



1-342176251  -  P1  -  Meggitt Plc (MGG)
Summary: Zabbix_agent_on_MGGGBJPECCX05.imzcloud.ibmammsap.local_is_unavailable



1-342173081   Lack_of_free_swap_space_on_ms3wdcappsp1.imzcloud.ibmammsap.localsev2


--------------------------------------------------------------------------------------------------------------------------------------------------------

19 Sept

1-342203341- Sev1 -Province of Nova Scotia (PS1) - Siebel Monitoring- Not Validated - Summary:  Zabbix_agent_on_mon01pnsmplsvyatta002_is_unavailable




1-342203351  -  Sev1-  Siebel - IBM AMM Infrastructure-  not validated- "Zabbix_agent_on_TSTMON01SAP16.imzcloud.ibmammsap.local_is_unavailable --



1-342203201- P1 - Inter Pipeline Ltd-portal-not validated- "Summary: Zabbix_agent_on_mon01iplmplsv



1-342177501	sev2
Processor_load_is_too_high_on_PCSDA00.imzcloud.ibmammsap.local



1-342177631	sev2
Processor_load_is_too_high_on_DLBPCSDA00.imzcloud.ibmammsap.local



1-342206751	sev2
TM Agent Offline: BIQ-bmtmon1lapp02_BIQ_10
[root@bmtmon1lapp02 bin]# /opt/monitor/IBM/ITM/bin/cinfo -r

*********** Wed Sep 19 08:32:16 EDT 2018 ******************
User: root Groups: root sapinst
Host name : bmtmon1lapp02        Installer Lvl:06.23.03.00
CandleHome: /opt/monitor/IBM/ITM
***********************************************************
Host           Prod  PID    Owner  Start  ID   ..Status
bmtmon1lapp02  sa    53824  root   08:32  BIQ  ...running





handvh4ssrv01	10.15.192.21
 

login this server  
ftp 10.183.123.13 21





1-342211561    Summary: Free_disk_space_is_less_than_10%_on_volume_/sapmnt/shared[PROBLEM:5407784] Date: Sep 19,20    Hortus Comercio de Alimentos SA (St. Marche) (HC1)



1-342216261  -  P1  -  Meggitt Plc (MGG)
Summary: Zabbix_agent_on_MGGGBJPECCX10.imzcloud.ibmammsap.local_is_unavailable




 1-342025265
1 - open boarding2  xls sheet
2- Go to customer  tab ad select  1st server
3-Login to server  
4- First check to which nic imz ip is configured....according to use route-* file to append   route  
5- echo "169.60.136.192/26 via 10.199.1.1" >> /etc/sysconfig/network-scripts/route* ; echo "169.60.136.128/26 via 10.199.1.1" >> /etc/sysconfig/network-scripts/route*; ping -c 2 frdal13abap01  
replace route* = route-eth0 or 1 according to imz ip configuration

DEGASA

DG1	DG1ERPDEVDG	10.143.31.11	DEV-ECC-ABAP	eth0
DG1	DG1ERPQASDG	10.143.31.12	QAS-ECC-ABAP
DG1	DG1ERPPRODG	10.143.30.11	PRD-ECC-ABAP
DG1	DG1ERPSLMDG	10.143.30.12	PRD-SLM-ABAB/JAVA
DG1	DG1ERPFTPDG	10.143.30.13	INFRA - FTP
DG1	DG1ERPVEDDG	10.143.31.13	APP
DG1	DG1ERPVEPDG	10.143.30.14	APP-OTHER





ARMFKSAP103 	10.7.103.20	
[root@FRA02AMMCHEF01 ibmrmalik]# export CHEF_ORG=arm
[root@FRA02AMMCHEF01 ibmrmalik]# knife environment list
_default
arm_development
arm_production

[root@FRA02AMMCHEF01 ibmrmalik]# knife node list|grep -i ARMFKSAP103
armfksap103.imzcloud.ibmammsap.local

./bootstrap_v12.sh -o arm -n ARMFKSAP103 -l -d imzcloud.ibmammsap.local -t osonly -e arm_production

10.7.103.20


MCO in Mon01 Pod1 due to an unplanned IBM Cloud event
r3devep	10.74.6.45
[root@r3devep ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / /opt/monitor/IBM /var /tmp /sybase/DEP/saplog1 /usr/sap / filesystems are read-only

[root@r3devep ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  / /boot /opt/monitor/IBM /var /tmp /home /sybase/DEP/saplog1 /home/depadm /home/daaadm /home/sapadm /usr/sap /usr/sap/DAA /usr/sap/ccms /sapmnt/DEP /usr/sap/trans /3rdPartySoftware/DEP /interface/DEP /sapstage /backup / filesystems are read-only



mtsbodsdev01	10.74.6.46
dmartdev01	10.74.6.48
mtsbodsqas01	10.74.6.47
dmartqas01	10.74.6.49

prdbods01	10.74.5.16
prdbodsapp01	10.74.5.17
mtsdmartprdh01	10.74.5.18
mtsdmartprdh02	10.74.5.19
r3dev	10.74.6.40
r3devapp	10.74.6.41
solnmgrdev	10.74.6.44
r3qat	10.74.6.42
r3qatapp	10.74.6.43
 

8:05:57 PM: prdsap1	10.74.5.10
prdsap1app	10.74.5.11
prdsap1dr	10.73.0.20
solnmgr1	10.74.5.12
mtsiaasdev1	10.74.6.65
mtsiaasqa01	10.74.6.66
mtsiaasprd1	10.74.5.21
prdhec1	10.74.5.13
prdepdb1	10.74.5.14
prdepapp1	10.74.5.15



user :hsapftp  

password : Anrndghk!12   

ls -l  

or ls  

----------------------------------------------------------------------------------------------------------------

20 Sept


SSGSA0121	100.126.0.14	SSGSA0120	10.24.143.206	Win2k12

SSGSA0122	100.126.0.16	10.24.143.208	RHEL




1-342133951	sev3
CIFS Share needet on APLBREDE1
we need a permanent filesystem connection on SAP Application Server APLBREDE1  	170.225.68.12	(DE1) to the Server  DC000TEL008.comp.ds

Please create the directory /usr/transfer/eloinvoice an map following filesystem via CIFS permanetly.

\\dc000tel008.comp.ds\DocXtractorII-System\     (IP-Adress 10.92.157.26)
Username: DOMA1\svc.elo.sap
Password: s06H3OV6nyapFDq1fqmh

If you have a question about this topic you can send me an e-mail.


mount -t cifs -o user=DOMA1\svc.elo.sap,password=s06H3OV6nyapFDq1fqmh \\dc000tel008.comp.ds\DocXtractorII-System\   /usr/transfer/eloinvoice

mount.cifs -o user=svc.elo.sap,dom=DOMA1,password=s06H3OV6nyapFDq1fqmh //10.92.157.26/DocXtractorII-System /usr/transfer/eloinvoice

lsof | grep  /usr/transfer/eloinvoice/ 





1-342251241 - IBM MSD Infras - Cloud MONITORING - Sev2





1-342016649	sev3
Create and NFS mount /interfaces/HME in the following servers:
SID	Hostname	IMZ IP Address
HME	DLTHMEHAP	10.4.5.49
HME	DLTHMEHAP2	10.4.5.31
HME	DLTHMEHAP3	10.4.5.20
HME	DLTHMEHAP4	10.4.5.25
HME	DLTHMEHAP5	10.4.5.58
 
Please model this after /interfaces/HPE:
SID	Hostname	IMZ IP Address
HPE	dlthpehp1       10.4.5.53

HPE	dlthpehp3	10.4.5.55
HPE	dlthpehp4	10.4.5.56
HPE	dlthpehp5	10.4.5.44




1-339902511	sev3
C drive cleanup 



[root@snchtnapa11 SHARE]# cat /etc/fstab |grep SHARE
nasprdstj001v2:/ifs/cifs/file136/corp/East_Coast/SAP/SAPReports /SHARE/MNT/FILE136/SAPReports nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0
nasprdstj001v2:/ifs/cifs/file136/corp/Finance/Department/Terra\040Nova/VisionCraft /SHARE/MNT/FILE136/VisionCraft nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0


[root@snchtnapa12 SHARE]# cat /etc/fstab |grep SHARE
nasprdstj001v2:/ifs/cifs/file136/corp/East_Coast/SAP/SAPReports /SHARE/MNT/FILE136/SAPReports nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0
nasprdstj001v2:/ifs/cifs/file136/corp/Finance/Department/Terra\040Nova/VisionCraft /SHARE/MNT/FILE136/VisionCraft nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0

run umount /mnt/sapexchangeIT/ and then mount it using mount 
//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/   -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003       //10.7.1.171/sapexchange /mnt/sapexchangePT  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=





1-341779105	sev3
LV extend by 50GB done to match the source with destination as per teh request

--------------------------------------------------------------------------------------------------------------

21 Sept


1-341961031	sev2
Summary: ITM Agent Offline: SOL-armfksap2:armfksap207




1-342234691	sev2
ITM Agent Offline: POD:armfksap005




1-342288621    2-Urgent    Manitoba Telecom Services - SAP HEC-AMM        Summary: Processor_load_is_too_high_on_R3QATapp.imzcloud.ibmammsap.local




1-341615951	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var


1-342226521	sev2
Lack_of_free_swap_space_on_LONCFGCGD0001.imzcloud.ibmammsap.local


top - 13:04:19 up 75 days, 15:35,  1 user,  load average: 0.12, 0.12, 0.05
Tasks: 379 total,   1 running, 378 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.5%us,  0.2%sy,  0.0%ni, 99.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.352G total,   30.841G used,  523.551M free,  329.078M buffers
Swap:   13.766G total, 7288.102M used, 6807.895M free,   13.651G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
 7131 cwdadm    20   0 4490m 216m 5112 S  0.0  0.7  42:27.61  41m wd.sapCWD_W80
43412 cgdadm    20   0 17.5g 1.0g 488m S  0.0  3.2  11:05.97  36m CGD_00_BTC_W28
43388 cgdadm    20   0 17.1g 658m 489m S  0.0  2.0   1:03.26  28m CGD_00_DIA_W4
43390 cgdadm    20   0 17.1g 633m 494m S  0.0  2.0   0:51.45  22m CGD_00_DIA_W6
43392 cgdadm    20   0 17.1g 640m 489m S  0.0  2.0   1:02.51  18m CGD_00_DIA_W8
43393 cgdadm    20   0 17.1g 653m 491m S  0.0  2.0   1:04.96  11m CGD_00_DIA_W9
43391 cgdadm    20   0 17.1g 669m 495m S  0.0  2.1   1:08.12  11m CGD_00_DIA_W7
43387 cgdadm    20   0 17.1g 749m 551m S  0.0  2.3   1:30.57  10m CGD_00_DIA_W3



1-341809171 from linux admin, cloud access not working on 10.73.10.128
toronto chef    fixed login issue


1-342177851	sev2
Processor_load_is_too_high_on_IA1S4HQASAPP.imzcloud.ibmammsap.local
10.133.17.140

top - 15:16:38 up 74 days,  5:29,  1 user,  load average: 0.06, 0.07, 0.01
Tasks: 268 total,   1 running, 267 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.2%us,  0.3%sy,  0.0%ni, 99.3%id,  0.0%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    15.561G total,   15.267G used,  300.898M free,   59.008M buffers
Swap:   31.996G total, 9643.750M used,   22.578G free, 8282.172M cached


1-342073501	sev2	10.6.4.202
Lack_of_free_swap_space_on_YHIBWDS01.imzcloud.ibmammsap.local[
top - 21:18:44 up 41 days, 23:07,  1 user,  load average: 0.00, 0.01, 0.01
Tasks: 300 total,   1 running, 299 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.7%us,  0.2%sy,  0.0%ni, 99.0%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.577G total,   14.838G used,  756.746M free,  751.465M buffers
Swap: 9215.996M total, 4889.055M used, 4326.941M free, 7689.391M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
18206 ywdadm    20   0 1428m  12m 2288 S  0.0  0.1   4:26.32 783m en.sapYWD_ASCS0
20296 ywdadm    20   0 1665m  18m 7076 S  0.0  0.1   1:31.48 111m icman
20271 ywdadm    20   0 1234m 8708 1628 S  0.0  0.1  11:32.48  39m igsmux_mt
 9462 daaadm    20   0  467m 8724 1916 S  0.0  0.1   0:31.95  34m sapstartsrv
18205 ywdadm    20   0 89160 3964 1572 S  0.0  0.0   0:19.48  26m ms.sapYWD_ASCS0
20267 ywdadm    20   0 15.0g  37m  29m S  0.0  0.2   8:19.62  23m YWD_00_DP




1-342221771	sev2
Processor_load_is_too_high_on_DLBPCSDA00.imzcloud.ibmammsap.local
top - 21:37:40 up 462 days,  8:52,  1 user,  load average: 0.02, 0.02, 0.06
Tasks: 246 total,   1 running, 245 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.5%us,  0.2%sy,  0.0%ni, 98.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.128G used,  444.691M free,  419.031M buffers
Swap: 8191.996M total,  704.988M used, 7487.008M free, 8037.867M cached



1-342221841	sev2
Processor_load_is_too_high_on_PCSDA00.imzcloud.ibmammsap.local
top - 21:37:40 up 462 days,  8:52,  1 user,  load average: 0.02, 0.02, 0.06
Tasks: 246 total,   1 running, 245 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.5%us,  0.2%sy,  0.0%ni, 98.3%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.562G total,   15.128G used,  444.691M free,  419.031M buffers
Swap: 8191.996M total,  704.988M used, 7487.008M free, 8037.867M cached



-----------------------------------------------------------------------------------------------------------

22 Sept


1-342216019	sev3
TRIO-CEM-AMM 3.x-Q318: Apply latest Q318 bundle  patches on RH Linux 
start and end mail to 

prasanth.narayanan1@abbott.com
prasad.appaji@abbott.com
cory.rowell@abbott.com
wroblesa@cr.ibm.com
mmendez@cr.ibm.com

JUDDTRANS03	10.196.4.15	A0GKUS014XVM003


--------------------------------------------------------------------------------------------------------------------

24 Sept



1-342320161 - server is not accessable SAP team are looking into it in#cms-sco-sap12-snc


1-342410251 
IMZ IP  - 10.15.192.21 (handvh4ssrv01) not accessab	Dallas13
HANDVH4SSRV01 	10.15.192.21	10.23.192.21
on dal13-pod1-4tb-host02.imzcloud.ibmammsap.local vsphere 10.186.255.76 root/lb4ldQWiQf@



frhkgprxy02
server access worked with Sai



Please create all folders in HME /interfaces/HME similar to PROD
/interfaces/HPE and to NFS mount this /interfaces/HME folder in all
below new App servers.
  HME - CI App1 DLTHMEHAP.hrhec.delta.com HME - App2
dlthmehp2.hrhec.delta.com HME - App3 dlthmehp3.hrhec.delta.com HME -
App4 dlthmehp4.hrhec.delta.com HME - App5 dlthmehp5.hrhec.delta.com

Create and NFS mount /interfaces/HME in the following servers:
SID	Hostname	IMZ IP Address
HME	DLTHMEHAP	10.4.5.48	
HME	DLTHMEHAP2	10.4.5.31	DLTHMEHAP2 	10.4.5.31	10.250.17.31
HME	DLTHMEHAP3	10.4.5.20	DLTHMEHAP3 	10.4.5.20	10.250.17.19
HME	DLTHMEHAP4	10.4.5.25	DLTHMEHAP4 	10.4.5.25	10.250.17.23 	
HME	DLTHMEHAP5	10.4.5.58	DLTHMEHAP5 	10.4.5.58	10.250.17.13 	
 
Please model this after /interfaces/HPE:
SID	Hostname	IMZ IP Address
HPE	dlthpehp1       10.4.5.53
HPE	dlthpehp3	10.4.5.55
HPE	dlthpehp4	10.4.5.56
HPE	dlthpehp5	10.4.5.44

Filesystem            Size  Used Avail Use% Mounted on
10.250.17.53:/interfaces/HPE
                      445G  250G  173G  60% /interfaces/HPE


[root@DLTHMEHAP ibmrmalik]# df -h /interfaces/HME
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hmeappvg-hmeIntface_lv
                       21G  2.4G   18G  12% /interfaces/HME


1-342002254
mount /interfaces/HME folder in app serv
Please mount this /interfaces/HME folder in below App server HQP system.
 
 HQP : dlthqpspi.hrhec.delta.com

Source HME:
SID	Hostname	IMZ IP Address
HME	DLTHMEHAP	DLTHMEHAP 	10.4.5.49	10.250.17.49 	

HQP:
SID	Hostname	IMZ IP Address
HQP	dlthqpspi	10.4.5.36	DLTHQPSPI 	10.4.5.36	10.250.17.36

mount -t nfs 10.250.17.49:/interfaces/HME /interfaces/HME


DLTHMEHDB 	10.4.5.48	10.250.17.48




1-342442029 Hanon Systems (HAN) 2-Urgent
IMZ login issue
handvh4ssrv01   10.187.27.174 , IMZ login to this server is failing. Backup affected, Please check.
HANDVH4SSRV01 	10.15.192.21	10.23.192.21





1-342124635
DLTHSBBSI02 	10.4.5.27	10.250.17.27 	 Win 2k12 Dallas	a0dbus012xvm001





sbmimdevsol  10.199.199.17   Frankfurt SLES login issue for 
Roxana.Maria.Matei@ro.ibm.com - Roxana Maria Matei/Romania/IBM



IMZ login issue
sbmimdevsol     10.199.199.17 , IMZ login to this server is not working. Backup affected, Please check





1-342497381	sev3
LBDMP1App00 	RHEL 	10.8.8.73 	10.65.2.73	HK


---------------------------------------------------------------------------------------------------

25 Sept

1-342016649	sev3
[root@DLTHMEHAP ibmrmalik]# df -h /interfaces/HME
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/hmeappvg-hmeIntface_lv
                       21G  2.4G   18G  12% /interfaces/HME

mount -t nfs 10.250.17.49:/interfaces/HME /interfaces/HME
10.250.17.49:/interfaces/HME /interfaces/HME defaults 0 0

10.250.17.49:/interfaces/HME /interfaces/HME nfs defaults 0 0




1-342380661	Frankfurt	sev3
Not able to login POP system and IP - 10.7.102.44
ARMFKSAP205
10.244.102.17	10.7.102.44



restore server
00:50:56:a8:7b:c2	adaptor1
00:50:56:a8:6c:e4	adaptor2





1-342528541 Raycap GmbH (RYC) 2-Urgent
10.7.64.21  processor load




1-342527171 MSC Industrial Supply Co. 2-Urgent
swap space	



1-342534207	sev3
host snchdsbpd11
10.73.10.54
add 500GB to /sybase/P1D/log_archive

[root@snchdsbpd11 ibmrmalik]# df -h /sybase/P1D/log_archive
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/p1darchvg-p1dlogarch_lv
                      620G  568G   21G  97% /sybase/P1D/log_archive
[root@snchdsbpd11 ibmrmalik]# vgs p1darchvg
  VG        #PV #LV #SN Attr   VSize   VFree
  p1darchvg   4   2   0 wz--n- 973.98g    0


[root@snchdsbpd11 ibmrmalik]# df -h /sybase/P1D/log_archive
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/p1darchvg-p1dlogarch_lv
                      1.1T  568G  488G  54% /sybase/P1D/log_archive


--------------------------------------------------------------------------------------------------------

26 Sept



1-342551931    CI3 Certified IT Consultants for TMG (CICTMG)    2-Urgent    Summary: Processor_load_is_too_high_on_CI3BWHANAPRDA.imzcloud.ibmammsap.local
10.210.1.18




1-341964491 eccdb0qas restart NTP at 3.30 to 4.40 IST
10.198.2.71	172.28.28.71		RHEL		DONE


1-342554111- P1 - Delta Airlines, Inc. - SAP HEC-AMM-portal-not validated- "Summary: Zabbix_agent_on_dlthmehap5.imzclou
10.4.5.58


1-342567851
pw reset and account unlock for handvh4ssrv01 for user h4sadm


1-342548896	sev3
these are temporary addition of resources for specific update  
now the changes completed., WE WANT TO REMOVE THE RAM/CPU and SPACE  
2.30 to 3.30 ECD - eccci0dev  	10.198.2.10	172.28.28.10	A0EGSG014XVM001
3.30 to 4.30 ECQ - eccci0qas  + NTP service restart	10.198.2.70	172.28.28.70	A0EGSG014XVM003
4.30 to 5.30 ECP - eccci0prd  	10.198.2.140	172.28.28.140 		A0EGSG014XVM005
these are the hosts in SINGAPORE DC

eccci0dev 	10.198.2.10	172.28.28.10	A0EGSG014XVM001	16 GB RAM and 8 CPUs  already has 4CPU
eccdb0dev	10.198.2.11	172.28.28.11


ECD - app  - eccci0dev
ECD - db   - eccdb0dev

eccci0qas  + NTP service restart	10.198.2.70	172.28.28.70	A0EGSG014XVM003	remove resources: 48 GB RAM and 8 CPU
ECQ - db   - eccdb0qas	10.198.2.71	172.28.28.71 	A0EGSG014XVM004	

eccap1prd	10.198.2.141	172.28.28.141		A0EGSG014XVM006
eccci0prd  	10.198.2.140	172.28.28.140 		A0EGSG014XVM005	32 GB RAM and 8 CPU onlr from eccci0prd
ECCDB0PRD 	10.198.2.142	172.28.28.142		A0EGSG014XVM007

10.6.2.42	svmq1srv1	A0EASG014XVM044



1-341122681	closed 27-08
1-341847293 	closed 14-09
1-342034901  	closed 13-09


Frankfurt
Saudi Business Machines LTD (SBM) 	SBMIMDEVSOL 	10.199.199.17	10.99.99.25 	
login issue

------------------------------------------------------------------------------------------------------------------------------


27 Sept

1-342601361 
FRDAL13ABAP01 		169.60.136.223 	
FRDAL13ABAP02 		169.60.136.224
FRDAL13ASCS01 		169.60.136.228
FRDAL13ASCS02 		169.60.136.229

rootsh or su - sapadm ka issue





1-341956811	sev2 	Processor_load_is_too_high_on_LBDBODDEVDB1.imzcloud.ibmammsap.local
top - 21:34:37 up 15 days, 12:25,  1 user,  load average: 0.01, 0.02, 0.00
Tasks: 299 total,   2 running, 297 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.2%us,  0.3%sy,  0.0%ni, 98.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.349G total,   29.030G used, 2374.973M free, 1353.496M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free,   25.538G cached



1-341957921	sev2	Processor_load_is_too_high_on_LBDBODDEVApp2.imzcloud.ibmammsap.local
top - 21:48:40 up 15 days, 12:40,  1 user,  load average: 0.07, 0.04, 0.01
Tasks: 321 total,   2 running, 319 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.6%us,  0.2%sy,  0.0%ni, 99.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.349G total,   22.092G used, 9480.043M free, 1264.742M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free, 9958.086M cached





1-342611241 - COTY Inc (CTU) - Sev1
Summary: Free_disk_space_is_less_than_5%_on_volume_/var/log
ctubwqb0ap03:/home/ibmrmalik # df -h /var/log
Filesystem                 Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-vloglv  1.2G  870M  227M  80% /var/log



1-342599671 - COTY Inc (CTU) - Sev3 (P2-Connectivity test to inbound and outbounr[00484023/3018])
SB3

10.12.10.12

DB3

10.12.10.14

QB1

10.12.10.23

PB0

10.12.10.30
10.12.10.31
10.12.10.44
10.12.10.45
10.12.10.149


 
Please execute the below commands from all application servers of SB3,
DB3, QB1 and PB0. Please send us the screenshots of response to these
commands for documentation purpose.
 
telnet sftp.cotyinc.com 22
telnet sftp.1010data.com 22
telnet 172.28.121.225 21
 



1-342608541 = the mount is 100% full and I need someone to add disk and extend the mount by 10GB for '/sybase/SD1'
[root@ms3wdcadbsd1 ibmrmalik]# df -h /sybase/SD1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/sd1datavg-sd1sybase_lv
                       16G   15G   62M 100% /sybase/SD1
ms3wdcadbsd1




1-342216981	sev2	Processor_load_is_too_high_on_BRPCAMLVSA04D.imzcloud.ibmammsap.local
top - 09:58:36 up 7 days, 20:21,  1 user,  load average: 0.05, 0.03, 0.00
Tasks: 191 total,   1 running, 190 sleeping,   0 stopped,   0 zombie
Cpu(s):  3.0%us,  0.3%sy,  0.0%ni, 96.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  7856.773M total, 6523.328M used, 1333.445M free,  803.059M buffers
Swap: 8191.996M total,    0.000k used, 8191.996M free, 2639.379M cached


-----------------------------------------------------------------------------------------------------------------------

28 Sept

1-342652431    1-Critical    DFJ Trung Group Corporation (TNG)    Summary: Zabbix_agent_on_tngprodeapp01.imzcloud.ibmammsap.local_is_unavailable

[root@tngprodeapp01 ibmrmalik]# uptime
 16:09:01 up 97 days, 20:32,  2 users,  load average: 4.04, 3.85, 3.71
[root@tngprodeapp01 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  66042) is running...



1-342652611 Manchester City Airport Group - SAP HEC-AMM 1-Critical
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/IP1
10.69.0.35
LONMAGSPO0001 	10.69.0.35	172.22.0.35 	London	A0D8UK014XVM018




172.21.1.9








SR # 1-342550212 	sev3
Windows Server :  10.6.1.127
Linux: 10.6.1.139 {sves1srv0}
We need to mount Windows on Linux, same has already mounted on 10.6.1.11
we need same setup on 10.6.1.139

same need to mount on 10.6.1.139 

3:51:24 PM: windows credentials: 
User â€“ admes1
Password â€“ Welcome@123 

mount -t cifs -o username=admes1,password=Welcome@123,dir_mode=0777,file_mode=0777 //10.92.99.127/STRS_Spool /usr/sap/OpenText/STRS_Spool/

//10.92.99.127/STRS_Spool /usr/sap/OpenText/STRS_Spool/  -t cifs -o username=admes1,password=Welcome@123,uid=908,gid=5003

//10.92.157.26/DocXtractorII-System      /usr/transfer/eloinvoice       cifs  credentials=/etc/eloinvoice_credential,uid=XXX,gid=XXX


//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/   -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003  rw,hard,intr,rsize=32768,wsize=32768    0       0

//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/   -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003


//10.92.99.127/STRS_Spool  /usr/sap/OpenText/STRS_Spool  cifs   credentials=/root/usercred.txt,iocharset=utf8,file_mode=0777,dir_mode=0777 0    0




1-342657111- P1 - DFJ Trung Group Corporation (TNG)- portal-not validated- "Summary: Zabbix_agent_on_TNGPRODEAPP01.imzcloud.ibmammsap.local_is_unavailable





1-342658231 DFJ Trung Group Corporation (TNG) 1-Critical
Zabbix_agent_on_TNGPRODEAPP01.imzcloud.ibmammsap.local_is_unavailable




1-342659591 DFJ Trung Group Corporation (TNG) 1-Critical-
Zabbix_agent_on_TNGPRODEAPP01.imzcloud.ibmammsap.local_is_unavailable



1-342655981    SAP09    DFJ Trung Group Corporation (TNG)    TNG    2-Urgent
Processor_load_is_too_high_on_TNGPRODEAPP00.imzcloud.ibmammsap.local


-------------------------------------------------------------------------------------------------------------------

1 Oct

kernel version
Hostname
IFN IP (IBM)
juddtrans01	10.196.4.11
juddtrans02	10.196.4.13


1-342713461    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_HKG02AMMSOL04.imzcloud.ibmammsap.local



1-342714301    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_free_swap_space_on_dal09ammtsm001.imzcloud.ibmammsap.local
top - 21:36:43 up 34 days, 12:06,  2 users,  load average: 10.74, 11.07, 13.37
Tasks: 627 total,   1 running, 626 sleeping,   0 stopped,   0 zombie
%Cpu(s): 16.6 us,  1.9 sy,  0.0 ni, 78.8 id,  2.4 wa,  0.0 hi,  0.2 si,  0.0 st
KiB Mem : 26385724+total,  9679872 free, 22784836 used, 23139254+buff/cache
KiB Swap:  4194296 total,  2711256 free,  1483040 used. 58406000 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S %MEM     TIME+   SWAP   USED COMMAND                                                                     %CPU
 4402 tsminst1  20   0   28.1g  17.7g  29868 S  7.0   6164:21  57284  17.8g dsmserv                                                                    560.2
40341 tsminst1  20   0  213.3g 173.3g 172.7g S 68.9  10930:01  89672 173.4g db2sysc                                                                    334.2



1-342722351    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local
 146.89.140.36 

1-342719921    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_MON01AMMSOL04.imzcloud.ibmammsap.local


1-342723131    2-Urgent    Toyota Financial Services - SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_DALTFSFDD0001.imzcloud.ibmammsap.local







1-342723061    1-Critical    COTY Inc (CTU)	SLES
Summary: Free_disk_space_is_less_than_5%_on_volume_/var/log
10.12.10.151	Washington	ctubwqb1ap03		no login via putty, chef or vcenter console
ctubwqb1ap03:/var/log # df -h /var/log
Filesystem               Size  Used Avail Use% Mounted on
/dev/mapper/system-root   24G   11G   14G  43% /var/log

Server was inaccessible, as the credentials were not getting accepted. Took the ON call DPE approval and restarted the server after which the login started to worlk. Then did a logrotate activity to do the cleanup of unnecessary stuff.
ctubwqb1ap03:/home/ibmrmalik # df -h /var/log
Filesystem               Size  Used Avail Use% Mounted on
/dev/mapper/system-root   24G   11G   14G  43% /var/log





1-342723081    1-Critical    COTY Inc (CTU)
 Free_disk_space_is_less_than_5%_on_volume_/usr/local
ctubwqb1ap03	 10.12.10.151 no login via putty, chef or vcenter console

ctubwqb1ap03:/var/log # df -h /usr/local
Filesystem               Size  Used Avail Use% Mounted on
/dev/mapper/system-root   24G   11G   14G  43% /usr/local




 




1-342722701
SNCHECAPD61	RHEL 7	
MOntreal
10.72.3.10



OQ1 / CLDPROAPDT1 / 10.198.0.217	instead of postman use OQ1adm

test@odbdr


sftp odb_user@172.21.1.9

-----------------------------------------------------------------------------------------------------

2 Oct


1-342775894	sev3
Mount trans FS

1. rename conspeccapp (10.80.1.122)	10.16.1.105
/usr/sap/trans to /usr/sap/trans_old

/dev/ecpappvg/usrtrans_lv       /usr/sap/trans  ext3    _netdev,defaults        1       2

2. mount 10.80.1.12:/usr/sap/trans (10.80.1.12)	10.16.1.12 

[root@CONSPECCAPD ibmrmalik]# df -h /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ecdappvg-usrtrans_lv
                       47G   28G   17G  62% /usr/sap/trans

to  client:
conspeccapp :/usr/sap/trans(10.80.1.122)	10.16.1.105

CONSPECCAPP 	10.16.1.105	10.80.1.122 	
CONSPECCAPD 	10.16.1.12	10.80.1.12


	

1-342780881  -  P2  -  Suncor Energy Inc. (SNC)
Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
 10.73.10.45




1-342779181  -  P2  -  Suncor Energy Inc. (SNC)  
 Free_disk_space_is_less_than_10%_on_volume_/usr/sap/PC1




1-342783921  -  P2  -  IBM AMM Infrastructure
Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local
146.89.142.30




1-342550626	sev3	Request Current Firmware and OS patch level of MMD A
Fiori	Virtual	SSGSA0119	MIS	00	901	100.126.0.13	10.24.143.205	RHEL 6.9
Web Dispatcher	Virtual	SSGSA0120	MWS	00	901	100.126.0.14	10.24.143.206	Windows 2012 R2
Solution Manager ABAP	Virtual	SSGSA0121	MMP	00	800	100.126.0.15	10.24.143.207	RHEL 6.9
Solution Manager Java	Virtual	SSGSA0122	MNP	10	-	100.126.0.16	10.24.143.208	RHEL 6.9




1-342784421	upgrade EP prod DB to 32 GB (spsvepdpase01)	sev3
spsvepdpase01	10.6.3.27	10.70.111.27	A0EASG014XVM034



1-342722701  -  P2  -  Suncor Energy Inc. (SNC)
 Free_disk_space_is_less_than_10%_on_volume_/sapmnt/log
10.74.0.10




1-342785671  -  P2  -  PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC) 
 FS_is_read_only_on_C1BWD.imzcloud.ibmammsap.local
/mnt/sapexchangeIT
10.199.2.31






1-342782691	sev3
Create NFS mounting in PTPKOMODO

Please create NFS mounting in PTPKOMODO from PTPBROMO with below folder and access read write by user appadm.
/192.168.166.12:/apld /apld
/sfa 
/rochedg 
/vendor 
/wigo 

/sapmnt/APP     *(rw,sync,no_root_squash)
/apld 		*(rw,sync,no_root_squash)
/sfa 		*(rw,sync,no_root_squash)
/rochedg 	*(rw,sync,no_root_squash)
/vendor 	*(rw,sync,no_root_squash)
/wigo		*(rw,sync,no_root_squash)

mount -t nfs /192.168.166.12:/apld /apld


SNG

PTPBROMO 	10.70.31.16	192.168.166.12
PTPKOMODO 	10.70.31.13	192.168.166.30 	



1-342786541  -  P1  -  SMRT Corp - SAP HEC-AMM		1-342789231		CASE 02194226
Web UI: https://mbpsjazz.austin.ibm.com:9443/jazz/resource/itemName/com.ibm.team.workitem.WorkItem/237299

Zabbix_agent_on_CLDERPAPPX5.imzcloud.ibmammsap.local_is_unavailable
CLDERPAPPX5 	203.127.229.226	10.198.0.235 	10.168.1.235	A0CTSG014XVM043

Oct  2 16:55:01 clderpappx5 kernel: EXT4-fs (dm-2): warning: mounting fs with errors, running e2fsck is recommended
Oct  2 16:55:01 clderpappx5 kernel: EXT4-fs (dm-3): warning: mounting fs with errors, running e2fsck is recommended
Oct  2 17:09:48 clderpappx5 SAPES5_01[10128]: Unable to open trace file sapstartsrv.log. (Error 11 Resource temporarily unavailable) [/bas/749_REL/src/proj/ntserv/ntservsserver.cpp 4476]
Oct  2 17:09:59 clderpappx5 SAPES5_00[11638]: Unable to open trace file sapstartsrv.log. (Error 11 Resource temporarily unavailable) [/bas/749_REL/src/proj/ntserv/ntservsserver.cpp 4476]





1-342787591  -  P2  -  SMRT Corp - SAP HEC-AMM
Free_disk_space_is_less_than_10%_on_volume_/usr/sap
10.198.0.71
[root@CLDERPAPPP1 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                      319G  274G   29G  91% /usr/sap
[root@CLDERPAPPP1 ibmrmalik]# cd /usr/sap
[root@CLDERPAPPP1 sap]# du -a . |sort -n -r |head -n 15
319215964       .
241122860       ./auditlog
32344552        ./trans
22677556        ./EP1
20365472        ./EP1/DVEBMGS00
17703168        ./trans_bkp
14139768        ./trans/data
11168808        ./trans_bkp/EPS
11168796        ./trans_bkp/EPS/in
9328512 ./EP1/DVEBMGS00/work_old
7254024 ./trans/tmp
6714136 ./EP1/DVEBMGS00/data
6533232 ./trans_bkp/log
4053280 ./trans/EP1
4053276 ./trans/EP1/DVEBMGS00





1-342786151  -  P2  -  MSC Industrial Supply Co.
Processor_load_is_too_high_on_ms3wdcladb13.imzcloud.ibmammsap.loca
 10.12.6.29



1-342784801  Meghna Group Of Industries (MG2)  Please add 64GB RAM
Add 64 GB RAM in SAP Application Server MHP host: MG2ERPPRDAPP
 (MG2) 	MG2ERPPRDAPP 	10.198.3.12	192.168.78.12 	SNG



1-340365491 	sev1
LV extension
[root@SMPOQUAQX8 ibmrmalik]# df -h /db2/QX8/db2dump
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/qx8archvg-qx8db2dump_lv
                      2.0G  958M  957M  51% /db2/QX8/db2dump 

----------------------------------------------------------------------------------------------------------

3 Oct

1-342808421  -  P2  -   Suncor Energy Inc. (SNC) 
Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
10.73.10.45


PTPBROMO  & PTPKOMODO


1-342808901  -  P1 -  COTY Inc (CTU)
Summary: Zabbix_agent_on_CTUBWQB2DB01.imzcloud.ibmammsap.local_is_unavailable
10.12.10.84
CTUBWQB2DB01 	10.12.10.84	172.22.64.84	WDC on 
coty-wdc04-phana-4096-6.imzcloud.ibmammsap.local  10.65.162.134	root/VR7bsjy4

IPMI root/Np6b2jmd7h



1-342805971
clear cache 	svjq1srv0



1-342813421  -  P2  -  IBM AMM Infrastructure
Lack_of_free_swap_space_on_tor01ammsol01.imzcloud.ibmammsap.local
146.89.141.91


1-342624291   sev1
Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.13.1.17

------------------------------------------------------------------------------------------------------------------------------------

4 Oct

1-342784021
Trying to join both DYSDCR01 and 02 to our Dystar domain. Already set up the DNS servers under network properties, but when trying to join, kept encountering error.We are able to ping our DC from the servers, and vice versa. We are still able to join computers to our domain in our network.Checked on our Firewall, there was no attempt from the server to our DC (see attached)Is there any configuration such as port opening over your side?




1-342808901
ibmrmalik@CTUBWQB2DB01:~> uptime
 04:45am  up  12:45,  2 users,  load average: 0.73, 0.78, 0.87




ptpbromo	10.70.31.16	
ptpkomodo	10.70.31.13	


ptpbromo	10.70.31.16
ptpkomodo	10.70.31.13  



1-342519590	
OQ1 / CLDPROAPDT1 / 10.198.0.217	instead of postman use OQ1adm

test2@odbdr2


sftp odb_user@172.21.1.9
-----------------------------------------------------------------------------------

5 Oct

1-342519590 Sev2 P1-Create keystore in OQ1[506040/2018]



1-342870045		Change 
5th Oct 830 AM
Customer Raised ticket : 0494934/2018

The reason behind the issue is there are several/multiple TP Processes existed at O.S level without any active imports in the system. Also frequent lock files are getting generated which is not allowing STMS routes to perform their functionality in a proper manner.  

Now SAP is asking for SERVER O.S  reboot for HMD and HMQ system which can be considered as the solution for the problem.


Impacted servers:
SID	Hostname	Server Ip	IMZ  IP	Landscape
HMD	HMDEVApp1	10.60.1.90	10.70.1.80	DEV-apps	A0DIML014XVM033
HMQ	HMQAApp1	10.60.1.82	10.70.1.82	QAS-apps	A0DIML014XVM036	drwsrwsrwt. 2 hmdadm sapsys   4096 Oct  5 12:05 tmp




1-342885901    2-Urgent    Apple Leisure Group - SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_USSAPAEDAP01.imzcloud.ibmammsap.local


1-342887201    2-Urgent    Bombardier Aerospace    Summary: Ruuning_out_of_available_memory_on_server_bmtmon1vhha1.imzcloud.ibmammsap.local


1-342879821    2-Urgent    IBM MSD Infras - Cloud IIT    Summary: Lack_of_free_memory_on_server_DAL09AMMRBOT1
146.89.140.43




10.6.7.12 - source - DEV
10.6.7.14 - Dest1 - QA	drwxrwxrwx 2 nobody sapsys     4096 Oct  4 20:31 tmp
10.6.7.16 - Dest2 - PROD


Ageas	1-342894681
10.6.1.154	sveh1hdbsrv01
SVEH1HDBSRV01 	10.6.1.154	10.92.99.154
sveh1hdbsrv01 	ageas-phana-1024-3.imzcloud.ibmammsap.local  	10.6.1.154 	SLES 	10.92.99.154
root/R222wM4A
---------------------------
Oct  5 01:34:26 sveh1hdbsrv01 kernel: [11554007.896312] bond0: link status definitely down for interface eth0, disabling it
Oct  5 01:34:26 sveh1hdbsrv01 kernel: [11554007.896318] bond0: making interface eth2 the new active one
Oct  5 01:34:30 sveh1hdbsrv01 kernel: [11554012.299948] bond0: link status definitely up for interface eth0, 10000 Mbps full duplex
Oct  5 03:27:18 sveh1hdbsrv01 kernel: [11560779.332841] bond0: link status definitely down for interface eth0, disabling it
Oct  5 03:27:18 sveh1hdbsrv01 kernel: [11560779.662744] bond0: link status definitely down for interface eth2, disabling it
Oct  5 03:27:18 sveh1hdbsrv01 kernel: [11560779.662755] bond0: now running without any active interface!
Oct  5 03:27:18 sveh1hdbsrv01 kernel: [11560779.713532] bond0: Removing slave eth0
Oct  5 03:27:18 sveh1hdbsrv01 kernel: [11560779.713918] bond0: Releasing backup interface eth0
Oct  5 03:27:18 sveh1hdbsrv01 kernel: [11560779.713923] bond0: the permanent HWaddr of eth0 - a0:36:9f:f5:3f:ac - is still in use by bond0 - set the HWaddr of eth0 to a different address to avoid conflicts
Oct  5 03:27:18 sveh1hdbsrv01 kernel: [11560779.742926] bond0: Removing slave eth2



Oct 5 01:34:26 sveh1hdbsrv01 kernel: [11554007.868272] ixgbe 0000:41:00.0 eth0: NIC Link is Down
Oct 5 01:34:26 sveh1hdbsrv01 kernel: [11554007.896312] bond0: link status definitely down for interface eth0, disabling it
Oct 5 01:34:30 sveh1hdbsrv01 kernel: [11554012.276497] ixgbe 0000:41:00.0 eth0: NIC Link is Up 10 Gbps, Flow Control: RX/TX
Oct 5 01:34:30 sveh1hdbsrv01 kernel: [11554012.299948] bond0: link status definitely up for interface eth0, 10000 Mbps full duplex
Oct 5 03:27:17 sveh1hdbsrv01 kernel: [11560778.996091] ixgbe 0000:41:00.0: removed PHC on eth0
Oct 5 03:27:18 sveh1hdbsrv01 kernel: [11560779.332841] bond0: link status definitely down for interface eth0, disabling it
Oct 5 03:27:18 sveh1hdbsrv01 kernel: [11560779.713532] bond0: Removing slave eth0
Oct 5 03:27:18 sveh1hdbsrv01 kernel: [11560779.713918] bond0: Releasing backup interface eth0
Oct 5 03:27:18 sveh1hdbsrv01 kernel: [11560779.713923] bond0: the permanent HWaddr of eth0 - a0:36:9f:f5:3f:ac - is still in use by bond0 - set the HWaddr of eth0 to a different address to avoid conflicts
Oct 5 03:27:18 sveh1hdbsrv01 wicked[77324]: eth0           device-ready
Oct 5 03:27:19 sveh1hdbsrv01 kernel: [11560780.326562] ixgbe 0000:41:00.0: registered PHC device on eth0
Oct 5 03:27:19 sveh1hdbsrv01 kernel: [11560780.447576] 8021q: adding VLAN 0 to HW filter on device eth0
Oct 5 03:27:19 sveh1hdbsrv01 kernel: [11560780.448031] bond0: Enslaving eth0 as a backup interface with a down link
Oct 5 03:27:23 sveh1hdbsrv01 kernel: [11560784.898191] ixgbe 0000:41:00.0 eth0: NIC Link is Up 10 Gbps, Flow Control: RX/TX
Oct 5 03:27:23 sveh1hdbsrv01 kernel: [11560784.934559] bond0: link status definitely up for interface eth0, 10000 Mbps full duplex
Oct 5 03:27:23 sveh1hdbsrv01 kernel: [11560784.934564] bond0: making interface eth0 the new active one
Oct 5 03:27:48 sveh1hdbsrv01 wicked[77584]: eth0           enslaved

--------------------------------------------------------------------------------------------------

8 Oct





1-342892971
Processor_load_is_too_high_on_ms3wdcwapp08.imzcloud.ibmammsap.local


1-342973871    2-Urgent    Raycap GmbH (RYC)    Summary: Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local  



1-342765901	10.134.2.11	sev1
Zabbix_agent_on_tngprodeapp00.imzcloud.ibmammsap.local_is_unavailable
[root@tngprodeapp00 ibmrmalik]# uptime
 10:59:40 up 107 days, 15:33,  1 user,  load average: 0.01, 0.08, 0.09
[root@tngprodeapp00 ibmrmalik]# /etc/init.d/zabbix-agent status
zabbix_agentd (pid  8961) is running...





1-342630641	sev1	10.204.4.19
Zabbix_agent_on_dradnaeldb.imzcloud.ibmammsap.local_is_unavailable




1-342794781	sev2 10.4.12.11
Lack_of_free_memory_on_server_ECCPROD02



1-342876731	sev2	10.4.20.31
Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.local

top - 23:18:19 up 13 days, 23:37,  1 user,  load average: 0.05, 0.03, 0.00
Tasks: 301 total,   1 running, 300 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.5%us,  0.2%sy,  0.0%ni, 99.3%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    11.626G total,   11.217G used,  418.555M free,  200.344M buffers
Swap:   13.766G total, 6704.406M used, 7391.590M free, 5936.746M cached




1-342533061		sev2  	10.13.1.18 
Processor_load_is_too_high_on_DLBPCSDA00.imzcloud.ibmammsap.local
[root@DLBPCSDA00 ibmrmalik]# uptime
 09:59:43 up 478 days, 21:14,  1 user,  load average: 0.10, 0.04, 0.01



1-342566571	sev2	10.13.1.12
Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local
[root@DLBPECAP01 ibmrmalik]# uptime
 10:56:19 up 33 days,  7:06,  1 user,  load average: 0.56, 0.54, 0.67




1-342571791	10.13.1.18	sev2
Processor_load_is_too_high_on_PCSDA00.imzcloud.ibmammsap.local
[root@DLBPCSDA00 ibmrmalik]# uptime
 09:59:43 up 478 days, 21:14,  1 user,  load average: 0.10, 0.04, 0.01




1-341581381:   sev3
NFS Issue: DF Hung
[root@DLBPECDB00 ibmrmalik]# df -h
df: `/Staging/sapsft': Stale file handle
Filesystem            Size  Used Avail Use% Mounted on
/dev/sda3              49G  9.7G   37G  21% /
tmpfs                 127G  8.0K  127G   1% /dev/shm
/dev/sda1             190M   69M  112M  39% /boot
/dev/mapper/vghanadata-lv_hana_data
                      768G  431G  338G  57% /sapmnt/data
/dev/mapper/vghanadata-lv_hana_shared
                      256G  145G  112G  57% /sapmnt/shared
/dev/mapper/vghanadata-lv_usr_sap
                       50G  1.8G   49G   4% /usr/sap
/dev/sdd1             258G   28G  231G  11% /sapmnt/log
146.89.140.30:/storage/library
                      3.6T  2.6T  828G  77% /storage/library




 
1-343022241 

ECT system OS is not responding - Please check Upgrent 
Host - ARMFKSAP103
IP - 10.7.103.20

Create virtual machine snapshot
armfksap103
An error 
occurred 
while saving 
the 
snapshot: 
msg.snaps-
hot.error-Q-
UIESCINGE-
RROR.
View details...
IMZCLOUD\tsm4ve
AMMFRA02VCS001.imzcloud.ibmammsap.local
10/7/2018 4:58:49 PM
10/7/2018 4:58:49 PM
10/7/2018 5:13:50 PM

------------------------------------------------------------------------------------------------------------------

9 Oct


1-343085021		ECT system OS is not responding sev3




1-342768531-Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local[	sev2
10.73.10.44
top - 03:35:40 up 107 days, 19:05,  1 user,  load average: 0.16, 0.18, 0.14
Tasks: 451 total,   1 running, 450 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.8%us,  1.1%sy,  0.0%ni, 98.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    62.900G total,   36.379G used,   26.521G free,  945.621M buffers
Swap:   97.000G total, 1384.000k used,   96.999G free, 5954.262M cached




1-342797731	sev2
Free_disk_space_is_less_than_10%_on_volume_/sapmnt/log
10.73.10.13 





1-342952181	sev2
Lack_of_free_swap_space_on_snchtnapd61.imzcloud.ibmammsap.local
10.73.10.114 



1-342961201	sev2
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/DZ1[



1-342963081	sev2
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/QR1
[root@snchecaqa20 ibmrmalik]# df -h /usr/sap/QR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/qr1appvg-qr1usrQR1_lv
                       20G  8.0G   11G  43% /usr/sap/QR1


-----------------------------------------------------------------------------------------------------------

10 Oct

1-342536421	sev2
Processor_load_is_too_high_on_IA1S4HPRDAPP.imzcloud.ibmammsap.local[
10.133.15.13
top - 09:42:39 up 79 days, 23:03,  1 user,  load average: 1.29, 0.90, 0.87
Tasks: 340 total,   4 running, 336 sleeping,   0 stopped,   0 zombie
Cpu(s): 60.2%us,  3.4%sy,  0.0%ni, 35.2%id,  0.1%wa,  0.0%hi,  1.2%si,  0.0%st
Mem:    31.341G total,   31.048G used,  300.137M free,   24.492M buffers
Swap:   64.000G total, 9201.883M used,   55.014G free,   19.586G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 44700 sp1adm    20   0 28.6g 6.4g 6.2g R 65.4 20.5   7:08.13 SP1_00_DIA_W48
 17447 sp1adm    20   0 28.6g 9.0g 8.8g R 62.4 28.9  12:17.86 SP1_00_DIA_W54
129794 sp1adm    20   0 28.6g 5.2g 5.0g R 44.8 16.6   2:38.18 SP1_00_DIA_W41
 36240 sp1adm    20   0 28.6g 4.9g 4.8g S 25.2 15.7   3:54.04 SP1_00_DIA_W49
100173 sp1adm    20   0 28.7g 9.4g 9.1g S 18.9 30.1  38:17.33 SP1_00_DIA_W46
 35239 sp1adm    20   0 28.6g 5.6g 5.4g S 12.9 17.9   5:27.47 SP1_00_DIA_W44
 85685 sp1adm    20   0 28.6g  12g  12g S 11.0 39.4  26:03.03 SP1_00_DIA_W55
 76864 sp1adm    20   0 28.6g 6.8g 6.6g S  5.6 21.8   7:45.61 SP1_00_DIA_W52
 88361 sp1adm    20   0 28.6g 690m 606m S  4.0  2.2  29:56.25 SP1_00_UPD_W33
 66324 sp1adm    20   0 28.6g 6.3g 6.1g S  3.7 20.1   4:14.25 SP1_00_DIA_W47



------------------------------------------------------------------------------------------------------------

11 Oct

1-343123513	JPP, XPP, FPP, OPP & PPP restart sev3
10.6.3.15 OS hung after clear cache	A0EASG014XVM025


SCO - 1-343143441 - SL-Hong Kong-02 - Limited Brands Inc. (LBD) - SAP HEC-AMM - TQ1 system is not available 515664/2018
LBDTQ1APP00
10.8.8.51
HK

knife node delete -y LBDTQ1App00.imzcloud.ibmammsap.local;knife client delete -y LBDTQ1App00.imzcloud.ibmammsap.local

./root/bootstrap_v12.sh -o lbd -n LBDTQ1App00 -l -d imzcloud.ibmammsap.local -t osonly -e lbd_production


[root@LBDTQ1App00 ~]# rpm -qa|grep -i chef
chef-12.19.33-1.el6.x86_64

[root@HKG02AMMCHEF01 ibmrmalik]# export CHEF_ORG=lbd
[root@HKG02AMMCHEF01 ibmrmalik]# knife environment list
_default


knife node list |grep -i nodename

[root@HKG02AMMCHEF01 ~]# export CHEF_ORG=lbd
[root@HKG02AMMCHEF01 ~]# echo $CHEF_ORG
lbd
[root@HKG02AMMCHEF01 ~]# knife node list
LBDTQ1App00.imzcloud.ibmammsap.local
[root@HKG02AMMCHEF01 ~]# knife node show LBDTQ1App00.imzcloud.ibmammsap.local
Node Name:   LBDTQ1App00.imzcloud.ibmammsap.local
Environment: lbd_production


[root@HKG02AMMCHEF01 ibmrmalik]# knife node list
LBDTQ1App00.imzcloud.ibmammsap.local.imzcloud.ibmammsap.local



1-343181276
SUNCOR :Addtion of Disk space on SNCHDSBTD11
Hi team,

We have noticed that there is a disk utlization of above 95% on the below host and we would need to add 5Gb and 10GB disk space to mount /sybase/T1D  and /sybase/T1D/saplog1 on below mentioned VM.

SNCHDSBTD11   10.73.11.37
Mount : /sybase/T1D     5GB
Mount : /sybase/T1D/saplog1  10GB

Kindly do the needful

Thanks

Shaik Arshad
PDL
Toronto

/dev/mapper/t1dlogvg-t1dsyblog1_lv
                       32G   29G  1.2G  97% /sybase/T1D/saplog1

[root@snchdsbtd11 ibmrmalik]# df -h /sybase/T1D/saplog1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/t1dlogvg-t1dsyblog1_lv
                       42G   29G   11G  74% /sybase/T1D/saplog1


Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/t1ddatavg-t1dsybase_lv
                      7.9G  7.2G  322M  96% /sybase/T1D


[root@snchdsbtd11 ibmrmalik]# df -h /sybase/T1D
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/t1ddatavg-t1dsybase_lv
                       13G  7.2G  5.0G  59% /sybase/T1D


-------------------------------------------------------------------------------------------------------------------------------

13 Oct

1-343310591    1-Critical    Limited Brands, Inc. - SAP HEC-AMM    Summary: Zabbix_agent_on_LBDTP1PRDApp1.imzcloud.ibmammsap.local_is_unavailable
10.8.8.80



1-343311331    1-Critical    Limited Brands, Inc. - SAP HEC-AMM    Summary: Zabbix_agent_on_LBDFP1PRDDB1.imzcloud.ibmammsap.local_is_unavailable
10.8.8.66



1-343305051    1-Critical    IBM AMM Infrastructure    Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable





1-343313431    1-Critical    American Airlines SAP HEC-AMM    Summary: Zabbix_agent_on_AHPOQ2SAP01.imzcloud.ibmammsap.local_is_unavailable
 10.4.10.53


1-343313541     1-Critical    CMA CGM (CMA)    Summary: Zabbix_agent_on_smemdevdm1.imzcloud.ibmammsap.local_is_unavailable
10.78.22.39 


1-343313091    1-Critical    CMA CGM (CMA)    Summary: Zabbix_agent_on_smemuatum3.imzcloud.ibmammsap.local_is_unavailable  
10.78.26.21



1-343315401    1-Critical    IBM AMM Infrastructure    Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var/opt/chef-backup
fmsprdchef001	 169.55.28.62
Chef main server is out of space Squad: Chef Infra  #1257 


1-343317641 sev1	London
Zabbix_agent_on_PSPRDDB.imzcloud.ibmammsap.local_is_unavailable
10.197.2.30



1-343317131, sev1
Zabbix_agent_on_PSDEVASJAVA.imzcloud.ibmammsap.local_is_unavailable
10.197.2.43



1-343317011-Computer Systems Integration LLC    CSY    1-Critical 
Zabbix_agent_on_PSDEVAP.imzcloud.ibmammsap.local_is_unavailable
10.197.2.11




1-343318221    Computer Systems Integration LLC    CSY    1-Critical
Summary: PSWEB.imzcloud.ibmammsap.local_has_just_been_restarted
10.197.2.41


1-343317751    Computer Systems Integration LLC    CSY    1-Critical
PSDEVASJAVA.imzcloud.ibmammsap.local_has_just_been_restarted
10.197.2.43



1-343317671    Computer Systems Integration LLC    CSY    1-Critical
Summary: SAProuter_is_not_running


1-343317111    Computer Systems Integration LLC    CSY    1-Critical
PSQASAP.imzcloud.ibmammsap.local_has_just_been_restarted
10.197.2.21


1-343317061    Computer Systems Integration LLC    CSY    1-Critical
Summary: PSDEVAP.imzcloud.ibmammsap.local_has_just_been_restarted
 10.197.2.11




1-343316971    Computer Systems Integration LLC    CSY    1-Critical
 Dataserver_process_is_not_running


Your ticket number is (INC2026272).

------------------------------------------------------------------------------------------------

14 Oct

1-343315681	sev2
Zabbix_agent_on_DAL09AMMTS002_is_unavailable
146.89.140.21




1-343281441    2-Urgent    SMRT Corp - SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.local
10.198.0.213

1-343281791    2-Urgent    Dilip Buildcon Limited (DLB)    Summary: Lack_of_free_swap_space_on_DLBPECAP01.imzcloud.ibmammsap.local
10.13.1.12


1-343282121    2-Urgent    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    Summary: Processor_load_is_too_high_on_pncapeccd.imzcloud.ibmammsap.local
10.199.2.13


1-343282271    2-Urgent    St Jude Medical  Dallas - SAP HEC    Summary: Processor_load_is_too_high_on_juddtrans02.imzcloud.ibmammsap.local
10.196.4.13


1-343282651    2-Urgent    AGEAS - SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_sved1srv0.imzcloud.ibmammsap.local
10.6.1.11


1-343283511    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM    Summary: Processor_load_is_too_high_on_LBDWD3App80.imzcloud.ibmammsap.local
10.8.8.32


1-343283601    2-Urgent    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    Summary: Processor_load_is_too_high_on_pncapeccq.imzcloud.ibmammsap.local
10.199.2.15


1-343328371 Free_disk_space_is_less_than_5%_on_volume_/var/log




1-343356961  -Delta Airlines, Inc. - SAP HEC-AMM  - P1
P1-B2B server not responding[0530409/2018]
DLTHPEHP1 	10.4.5.53	10.250.17.53 		A0DBUS014XVM017
Dallas



1-343366821 IBM AMM Infrastructure 2-Urgent


---------------------------------------------------------------------------------------------------------------------------

16 Oct

1-343432981 Dilip Buildcon Limited (DLB) sev2
Free_disk_space_is_less_than_10%_on_OS_volume_/var
10.13.2.12


	1-343398541 sev2
 Processor_load_is_too_high_on_CTUBWQB4DB01.imzcloud.ibmammsap.local
top - 12:43:23 up 79 days,  7:24,  1 user,  load average: 0.27, 0.38, 0.47
Tasks: 1683 total,   1 running, 1602 sleeping,   0 stopped,  80 zombie
%Cpu(s):  0.2 us,  0.1 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  42276331+total, 13715968+used, 40904734+free,   323228 buffers
KiB Swap:        0 total,        0 used,        0 free. 38585228 cached Mem


	

1-343437331	: Processor_load_is_too_high_on_C1BWP.imzcloud.ibmammsap.local	sev2
10.199.1.30



1-342241166  16-Oct 530 PM 	CEM-AMM 3.x: Apply latest Q418 bundle  patches on RH Linux OS Ver 5.x/6.x

[root@smemdevdm1 ibmrmalik]# vmware-toolbox-cmd -v
10.1.10.63510 (build-6082533)
VMware-Tools-10.1.10-core-6082533.iso



1-343437971 , SMECCQUAQE1, 10.78.24.19





1-343435151 IBM AMM Infrastructure 1-Critical
Zabbix_agent_on_tor01ammsol01.imzcloud.ibmammsap.local_is_unavailable

-------------------------------------------------------------------------------------------------------------------------

17 Oct


1-343483441    SAP09    2-Urgent    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    PNC
Processor_load_is_too_high_on_C1BWP.imzcloud.ibmammsap.local
 10.199.1.30



1-343485611  - DB3, SMBODEVDB3 full on /usr/sap/DB3
[root@smbodevdb3 ibmrmalik]# df -h /usr/sap/DB3
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/db3appvg-db3usrDB3_lv
                       48G   48G     0 100% /usr/sap/DB3
[root@smbodevdb3 ibmrmalik]# vgs db3appvg-
  Volume group "db3appvg-" not found
  Cannot process volume group db3appvg-
[root@smbodevdb3 ibmrmalik]# vgs db3appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  db3appvg   1  13   0 wz--n- 128.00g    0



1-343484521 - Sev2 - Raycap GmbH (RYC) - Siebel - Not Validated - Summary:  Processor_load_is_too_high_on_deeh11ryc1007.imzcloud.ibmammsap.local
10.7.64.12




1-341240889
(CMS-SQ-SAP-TRIO-WIN) OS SME approves the change starting on OCT 19, 8:00PM PST for 4.5 hours
on OCT 19, 8:00PM PST for 4.5 hours



1-343492991 - COTY Inc (CTU) - Sev1
Free_disk_space_is_less_than_5%_on_volume_/var/log
ctubwqb1ap03.imzcloud.ibmammsap.local 
NodeAlias: 10.12.10.151


-----------------------------------------------------------------------------------------------------------------------

21 Oct


1-343571641 Clone TROO DEV OTS server TROO hotfix server 

Source server    			  	
10.92.99.127 svtd1srv1 (internal ip 10.6.1.28)		A0EASG012XVM005			
Administrator/May55now#		svth1srv0_new
to

Target server (existing to be replaced by clone of above) 
10.92.99.165    svth1srv0
(internal ip 10.6.1.165)



1-343636041    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_wdc04ammtsm001.imzcloud.ibmammsap.local
: Processor_load_is_too_high_on_wdc04ammtsm001.imzcloud.ibmammsap.loca




1-343639591   sev1
dev/mapper/dz1appvg-dz1usrDZ1_lv
                      62G   59G   38M 100% /usr/sap/DZ1
10.72.1.103
10.73.11.103

[root@snchzrada11 ibmrmalik]# df -h /usr/sap/DZ1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/dz1appvg-dz1usrDZ1_lv
                       62G   59G  6.8M 100% /usr/sap/DZ1
[root@snchzrada11 ibmrmalik]# vgs dz1appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  dz1appvg   2  13   0 wz--n- 142.99g 516.00m

[root@snchzrada11 ibmrmalik]# df -h /usr/sap/DZ1                                Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/dz1appvg-dz1usrDZ1_lv
                       72G   59G  9.4G  87% /usr/sap/DZ1






1-343654381    1-Critical  CMA CGM (CMA) Summary: Zabbix_agent_on_smemdevdm1.imzcloud.ibmammsap.local_is_unavailable
Zabbix_agent_on_smemdevdm1.imzcloud.ibmammsap.local_is_unavailable
10.78.22.39



1-343653551    1-Critical  CMA CGM (CMA)     Summary: Zabbix_agent_on_SMBWUATUW3.imzcloud.ibmammsap.local_is_unavailable  
10.78.26.28



1-343653541 1-Critical  CMA CGM (CMA) "Zabbix_agent_on_smedidevdu1.imzcloud.ibmammsap.local_is_unavailable
 10.78.22.55


1-343653561 1-Critical  CMA CGM (CMA) "Zabbix_agent_on_smediuatuu3.imzcloud.ibmammsap.local_is_unavailable
10.78.26.25


1-343656791    1-Critical  CMA CGM (CMA) Summary: Zabbix_agent_on_smedidevdu3.imzcloud.ibmammsap.local_is_unavailable
10.78.22.35



1-343665791  CMA CGM (CMA) - P1 - monitoring - not validated- "Zabbix_agent_on_smemdevdm1.imzcloud.ibmammsap.local_is_unavailable
10.78.22.39


1-343666581- P2 - CMA CGM (CMA) -portal-not validated- "Summary: Zabbix_agent_on_SMBWUATUW3.imzcloud.ibmammsap.local_is_unavailable
10.78.26.28


1-343589111	PENDING deviation remediation
LBDBOPPRDAPP4	Windows 2012 R2 
LBDBOQQASAPP4	Windows 2012 R2
How to re-run the scan :-
1. Login to https://9.58.92.198/request/sod/sod.html
2. Fill the info as below for your email ID as requester and for your VM listed in your SR....see screen shot below.
3. You will receive an email with zip files, please check CSV file and results file and there should be no deviations or failed policy.
4. Please save the files and attach to your SR. Me and Melissa needs that clean scan file to submit in NCI(CIRATS) for closure. 


1-343669131
1-Critical    Suncor Energy Inc. (SNC)    Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/DR1 ResourceId: snchecada1
 10.73.11.99

/dev/mapper/dr1appvg-dr1usrDR1_lv
                      200G  180G  9.2G  96% /usr/sap/DR1

[root@snchecada11 ibmrmalik]# df -h /usr/sap/DR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/dr1appvg-dr1usrDR1_lv
                      200G  180G  9.2G  96% /usr/sap/DR1



1-343668111- Sev1 - CMA - IC4SAP-SL - Siebel - Not Validated -Summary: Zabbix_agent_on_SMBWUATUW3.imzcloud.ibmammsap.local_is_unavailable 
10.78.26.28





lonmagbob0006	A0D8UK014XVM046
lonmagsbd0004	A0D8UK014XVM040

--------------------------------------------------------------------------------------------------------------------------


22 Oct

Sev1-  1-343701751 - SL-Dallas-13 - Wellnext (WNX)



AGESVBPPHSRV0 	10.6.3.55	
SPSLBPDBHDB01 	10.6.3.17
samba~3.6.23-35.el6_8


SR# 1-343234050		1-343710684 sev1   HANON :Servers were powered off while performing the cha
handvsdtsrv01	App+DB	SDT	 	10.15.192.17	
handvwddsrv01	App+DB	WDD		10.15.192.19	




1-343713356    SAP10    SMRT Corp - SAP HEC-AMM    SM5
Please delete the file as below 
 
File location - /usr/interfaces/vacs_to_sap/FI/
File name -  ERR01GLACCTAXI20180928175931-319.txt



1-343713545 sev3
Please unlock user ecdadm on pncapeccdc 10.199.2.13

------------------------------------------------------------------------------------------------------------------------------

23 Oct

1-343758351 IBM MSD Infras - Cloud APPS 1-Critical-
 Zabbix_agent_on_dal09ammsol01.imzcloud.ibmammsap.local_is_unavailable
146.89.140.30


1-343025679	Patching change in SNG
CEM-AMM 3.x: Apply latest Q418 bundle  patches on RH Linux OS Ver 5.x/6.x



1-342246342	4 server patching change in Paris
CEM-AMM 3.x: Apply latest Q418 bundle  patches on RH Linux OS Ver 5.x/6.x
VMware ESXi, 6.0.0, 7967664
Marco Castro Ramirez/Costa Rica/IBM

SMEDIUATUU3	10.78.26.25



9/28/2018
9/28/2018
10/05/2018
10/05/2018
10/12/2018
10/12/2018
10/19/2018
10/19/2018
10/26/2018
10/26/2018


--------------------------------------------------------------------------------------------------------------------


24 Oct

SCO - 1-343818521 - SL-Singapore-01 - AGEAS (AGE) - SAP HEC-AMM - Development Server not reachable
svad1srv0 10.6.1.18	A0EASG014XVM009




1-343823061 - PT Blue Bird TBK (PBB) - Sev2
Processor_load_is_too_high_on_PBBbwhdap00.imzcloud.ibmammsap.local
 10.6.7.18




1-343822711 - AGEAS - SAP HEC-AMM    AGE - Sev2
 XP_process_is_not_running
10.6.1.18


1-343796191    Incident    1    CTU    10/23/2018    ctubwsb3db01.
ctubwsb3db01	HANA	
10.12.10.11



1-343836971  - Sev1 - CTU - SAP HEC-AMM - Siebel Ticket - Not Validated - Summary: Zabbix_agent_on_ctubwsb3db01.imzcloud.ibmammsap.local_is_unavailable

 Active: active (running) since Wed 2018-10-24 14:52:00 CEST; 44min ago

ctubwsb3db01:/home/ibmrmalik # uptime
 15:37pm  up 172 days 18:15,  3 users,  load average: 0.55, 0.85, 1.17

------------------------------------------------------------------------------------------------------------------------------

25 Oct


1-343025611	sev3
CEM-AMM 3.x: Apply latest Q418 bundle  patches on RH Linux OS Ver 5.x/6.x 


1-343897431 - IAG GBS Limited (IA1) - Sev2
Processor_load_is_too_high_on_IA1S4HSBXAPP.imzcloud.ibmammsap.loca



1-343696031	sev3
Login issue helped SAP person to fix login error


1-342925171
<sidadm> user password issue for CI2 customer
Hi, 
most of the systems for CI2 customer having password issue on OS level, the password for <SIDADM> user is asking to change after login,which should not ask to change the <sidadm> user password

please reset the  password (Security#1) and it should be never expired

Below are the users and system details for which password needs to be set and make it never expired.

i)
User :	M2DADM 
host : 	CI2DEVAPP
IP :	10.5.242.16

ii)
User :	DH1ADM 
host : 	CI2DEVDB
IP :	10.5.242.11

iii)
User :	M2QADM 
host : 	CI2QAAPP
IP :	10.5.242.14

iv)
user :	QH1ADM
Host :	CI2QADB : 
IP :	10.5.242.13

v)
user :	M2PADM
Host :	CI2PRDAPP
IP :	10.5.242.12

vi)
user :	M2PADM   PH1ADM
Host :	CI2PRDDB
IP :	10.5.242.15

vii)
user :	SOL  &  SOJ	soladm  sojadm
host :	CI2SOL
IP :	10.5.242.17


Please send a confirlamtion mail to below contacts after completion of task


Mushtaq : email : mushtaque@in.ibm.com
Joel : joelnag@my.ibm.com


--------------------------------------------------------------------------------------------------------------


26 Oct

1-343954381/Sev1/Limited Brands, Inc. - SAP HEC-AMM/ Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/tmp 
 10.8.8.40



1-343954621 Dilip Buildcon Limited (DLB) 2-Urgent
Lack_of_free_swap_space_on_DLBQECAP01.imzcloud.ibmammsap.local
 10.13.2.12




1-343954931 IBM MSD Infras - Cloud MONITORING 1-Critical-
Free_disk_space_is_less_than_5%_on_OS_volume_/var/opt/chef-backup
 146.89.140.23


1-343959641    SAP11    Tecnologia De Materiales S.A.    TDM    2-Urgent
Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.loca
: 10.4.20.31


1-343956261  login issue and time diff in 2 servers withs ame time zone  sev2

SAP BW on HANA BD1 DEV System DB	LONMAGHAN0013    10.69.0.142
SAP BW on HANA BD1 DEV System APP	FRAMAGBWH0006	    10.69.0.151




1-343968473  sev3
OS team - Kindly install telnet on SPSPNAS - 10.78.22.11

---------------------------------------------------------------------------------------------------------------------

29 Oct


1-344026961    2-Urgent    IBM AMM Infrastructure    Summary: Zabbix_agent_on_DAL09AMMTS002_is_unavailable

1-344026831    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_sng01ammtsm001.imzcloud.ibmammsap.local
146.89.140.178


1-344032261    2-Urgent    IBM AMM Infrastructure    Summary: Lack_of_free_swap_space_on_fmsprdrtem006.imzcloud.ibmammsap.local 



1-344031701    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_MON01AMMSOL04.imzcloud.ibmammsap.local 


1-344025651 sev3  Please reset password  for MMPADM and SYBMMP



Sev1 - 1-344033381 - Manchester City Airport Group - SAP HEC-AMM - SPA: Low free DATA space in database saptools: 2.00%
16G   14G  1.8G  89% /sybase/SPA/sapdiag 

/dev/mapper/spadatavg-spasybase_lv
                       27G   23G  3.0G  89% /sybase/SPA
spadatavg has space can be extended


/dev/mapper/spaarchvg-spalogarch_lv
                       50G   41G  6.4G  87% /sybase/SPA/log_archive
spaarchvg no space will need toadd a new dissk


/dev/mapper/spalogvg-spasybdiag_lv
                       16G   14G  1.8G  89% /sybase/SPA/sapdiag
[root@LONMAGSLM0003 ibmrmalik]# vgs spalogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  spalogvg   2   4   0 wz--n- 47.99g 5.99g


/dev/mapper/spalogvg-spasyblog1_lv
                       22G   20G  1.2G  95% /sybase/SPA/saplog1 

[root@LONMAGSLM0003 ibmrmalik]# vgs spalogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  spalogvg   2   4   0 wz--n- 47.99g 5.99g


16G   14G  1.8G  89% /sybase/SPA/sapdiag
27G   23G  3.0G  89% /sybase/SPA



1-344030751
PL2SAPPRD    RedHat Linux Enterprise 6.x    Sybase ASE    PRD    Production    App-DB    SAP    PIP    20    PRD    10.10.10.13    10.7.33.13

/dev/mapper/pipappvg-archibox_lv
                      976M   14M  911M   2% /sybase/archibox
/dev/mapper/pipappvg-controlling_lv
                      976M  223M  703M  25% /sybase/controlling
/dev/mapper/pipappvg-metel_lv
                      976M   24M  901M   3% /sybase/metel
/dev/mapper/pipappvg-docfinance_lv
                      976M   13M  912M   2% /sybase/docfinance

PL2SAPPRD (10.7.33.13)

1) echo 'Y' > /sys/module/nfsd/parameters/nfs4_disable_idmapping
2) service nfs reload



1-344025881	sev3
Addtion of Disk space on OS of  snchsmapa11
Hi OS team,

We have noticed that there is a disk utlization of above 99% on the below host and we would need to add 10GB disk space to mount /usr/sap/ccms on below mentioned VM.

SNCHSMAPA11  10.73.10.76
Mount : /usr/sap/ccms

Kindly do the needful

Thanks

Shaik Arshad
PDL




1-343835519	sev2

551790 / 2018 MAS - SFTP setup on OD1 and OQ1 

OD1 / CLDPROAPDD1 / 10.198.0.201	/home/postman/.ssh	.ppk
[root@cldproapdd1 ibmrmalik]#  sftp _massapsftpd1@172.31.10.20
Connecting to 172.31.10.20...
Enter passphrase for key '/root/.ssh/public__fmssapsftpd.ppk':
Enter passphrase for key '/root/.ssh/public__fmssapsftpd.ppk':
Enter passphrase for key '/root/.ssh/public__fmssapsftpd.ppk':


OQ1 / CLDPROAPDT1 / 10.198.0.217
/home/oq1adm/.ssh

SFTP server                        : CLDSFTPSVRP1 [172.31.10.20]
Username                           : _massapsftpd1
Password                            : @ma5s@psftpd1
Keystore = SFTP_massapsftpd1
Keystore Entry = sftp_keystore_mas


1-343755667	16 Nov 330 PM IST
OS Engineer :  Ravi Malik (rmalik@us.ibm.com)

1-343755749
OS Engineer :  Sandeep Gaur (sgaur@us.ibm.com)



1-343755341
OS Engineer :  Balaji Reddappa (balajikr11@in.ibm.com)
SAP Engineer :  Ravi Malik (rmalik@us.ibm.com)
17-Nov 5.30 AM IST  

-----------------------------------------------------------------------------------------------------------------------------------

30 Oct

1-343944941	sev3
Request for Windows service users
*** Details of Generic Service Request - DO NOT CHANGE ***

Please ensure profile user is local.  Member of administrators group with logon as a service authorization

WWIUser	System	WWIUSER	Yes	n/a		Windows	Administrator	DYSW1DAWWD40	10.6.12.26	
WWIUser	System	WWIUSER	Yes	n/a		Windows	Administrator	DYSW2DAWWD40	10.6.12.23




Sev-1--1-344065261
add 3 GB space to /usr/sap/TM1 for 
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/TM1
146.89.141.100


1-344073171 - Sev1 - IBM MSD Infras - Cloud APPS - Siebel - Not Validated - Summary: Zabbix_agent_on_dal09ammsol01.imzcloud.ibmammsap.local_is_unavailable




1-344066641    2-Urgent    IBM MSD Infras - Cloud MONITORING    Summary: Zabbix_agent_on_DAL09AMMTS001_is_unavailable
146.89.140.20


1-344068561    2-Urgent    IBM AMM Infrastructure    Summary: Zabbix_agent_on_DAL09AMMTS002_is_unavailable
WIN 146.89.140.21

1-344074371 - Sev2 - SNC - SAP HEC-AMM - Siebel Ticket - Not Validated - High Swap Space Usage (2%) -COLO team


1-344065381    2-Urgent    Delta Airlines, Inc. - SAP HEC-AMM    Summary: Lack_of_free_swap_space_on_dlthsehap.imzcloud.ibmammsap.local  



1-342779091	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/
 10.73.10.13




1-344052151	sev2
 10.7.64.12  /db2/RQ2/log_dir
/dev/mapper/rq2appvg-lv_db2_RQ2_log_dir
                       50G   47G   74M 100% /db2/RQ2/log_dir
deeh11ryc1007



[postman@CLDERPAPPQ1 .ssh]$ pwd
/home/postman/.ssh
odb_dr_private.ppk



1-344062753 for Account AGEAS
SVGD1SRV0 	10.6.1.31
SVGD1SRV1 	10.6.1.32
SVYD1SRV0 	10.6.1.19	
------------------------------------------------------------------------------------------------------------------------------

31 Oct

1-344102971 -- OS Linux - Urgent Fix required for Independent Disk

Urgent Fix required for Independent Disk

BOP	conspbobdapp	Prod Zone	imz:{"ip":"10.16.1.109"
B4P	conspbw4happ	Prod Zone	imz:{"ip":"10.16.1.108"
TDP	conspdfdbapp	Prod Zone	imz:{"ip":"10.16.1.104"
ECP	conspeccapp	Prod Zone	imz:{"ip":"10.16.1.105"
GTP	conspgwapp	Prod Zone	imz:{"ip":"10.16.1.97"
POP	consppoapp	Prod Zone	imz:{"ip":"10.16.1.103"
S4P	consps4happ	Prod Zone	imz:{"ip":"10.16.1.101"
TDQ	consptdfapq	Non-Prod Zone    imz:{"ip":"10.16.1.30"
TTP	consptms4happ	Prod Zone	imz:{"ip":"10.16.1.102"





1-344108731 -- Sev1 - Restore VM ms3archqa01 from last successful snapshot

*** Details of Generic Service Request - DO NOT CHANGE ***

HI Team,

Please restore this server using last successful snapshot taken this afternoon. Snapshot completed around 4 PM CST.below is the email confirmation from PDL Phil.


From: Phillip Payne [mailto:philpayne@us.ibm.com] 
Sent: Tuesday, October 30, 2018 2:51 PM
To: Dominic Arulsamy <Dominic.Arulsamy@mscdirect.com>
Cc: IS Basis <ISBasis@mscdirect.com>; Kenneth Welsh <welshk@us.ibm.com>
Subject: RE: EXTERNAL: RE: 1-343978941 - VM Backup/Snapshot - Arch



Snapshot has been completed




1-344125361  - Sev1 - DAL - SAP HEC-AMM - Siebel Ticket - Not Validated - Zabbix_agent_on_dltwm2hwd.imzcloud.ibmammsap.local_is_unavailable




1-344118891    COTY Inc (CTU)    2-Urgent    Summary: Processor_load_is_too_high_on_ctuwdprdap02.imzcloud.ibmammsap.local[PROBLEM:9235576] Date: 10.12.12.14




1-344118771    COTY Inc (CTU)    2-Urgent    Summary: Processor_load_is_too_high_on_ctuwdprdap01.imzcloud.ibmammsap.local[PROBLEM:9235459] Date:  10.12.12.13



1-344124791 - Sev1 - PNC - AMM-SAP - Siebel Ticket - Not Validated - Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local 
10.199.1.10
[root@C1ECCP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
OK



1-344127411  Delta Airlines, Inc. - SAP HEC-AMM P1
 10.4.5.31
: Zabbix_agent_on_dlthmehap2.imzcloud.ibmammsap.local_is_unavailable



1-344129611  Delta Airlines, Inc. - SAP HEC-AMM P1
 10.4.5.46
: Zabbix_agent_on_dlthmggat1.imzcloud.ibmammsap.local_is_unavailable






[postman@CLDERPAPPQ1 .ssh]$ sftp -v odbdr2
Connecting to odbdr2...
OpenSSH_5.3p1, OpenSSL 1.0.1e-fips 11 Feb 2013
debug1: Reading configuration data /home/postman/.ssh/config
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: Applying options for *
ssh: Could not resolve hostname odbdr2: Name or service not known
Couldn't read packet: Connection reset by peer

postman@CLDERPAPPQ1 .ssh]$ sftp odb_user@172.21.1.9
Connecting to 172.21.1.9...
Enter passphrase for key '/home/postman/.ssh/odb_dr_private.ppk':
Enter passphrase for key '/home/postman/.ssh/odb_dr_private.ppk':



1-344062753  shut down servers   sev3
svgc1srv0 10.70.110.28 	down        
svgc1srv1 10.70.110.29	down  
svgq1srv0 10.70.110.30  down         
svgq1srv1 10.70.110.31	down
svgq1srv2 10.70.110.32	down
svgq1srv3 10.70.110.33	down
svgi1srv0 10.70.110.34	chk svq and svg  down
svgi1srv1 10.70.110.35  down     
svgi1srv2 10.70.110.36	down         
svgi1srv3 10.70.110.37	down	  
svgi1srv4 10.70.110.38  down 
svgi1srv5 10.70.110.39	down
svud1srv0 10.92.99.137	down
svuq1srv0 10.70.110.44	down



1-344126587 Suncor Energy Inc. (SNC) SUNCOR :Addtion of Disk for for FS /sybase/P1B/saplog1 on  snchbibpd51  P3 -- RFS
Hi OS team,

We have noticed that there is a disk utlization of above 90% on the below host and we would need to add 10GB disk space to mount /sybase/P1B/saplog1  on below mentioned VM.

snchbibpd51   10.73.10.111
Mount : /sybase/P1B/saplog1 


Kindly do the needful

Thanks

Shaik Arshad
PDL



1-344136671 	sev3
SMGWQUAQQ1 	10.78.24.14

10.5.26.11
10.5.26.11:/usr/sap/trans       /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    0       0


NFS server SMGWUATUQ3 	10.78.26.11

---------------------------------------------------------------------------------------------------------------------------------

1 Nov

CSR 1-344102971.
Urgent Fix required for Independent Disk
Urgent Fix required for Independent Disk

BOP	conspbobdapp	Prod Zone	imz:{"ip":"10.16.1.109"		complete
B4P	conspbw4happ	Prod Zone	imz:{"ip":"10.16.1.108"		complete
TDP	conspdfdbapp	Prod Zone	imz:{"ip":"10.16.1.104"		complete
ECP	conspeccapp	Prod Zone	imz:{"ip":"10.16.1.105"		complete
GTP	conspgwapp	Prod Zone	imz:{"ip":"10.16.1.97"		complete
POP	consppoapp	Prod Zone	imz:{"ip":"10.16.1.103"		complete
S4P	consps4happ	Prod Zone	imz:{"ip":"10.16.1.101"		complete
TDQ	consptdfapq	Non-Prod Zo	ne    imz:{"ip":"10.16.1.30"	complete
TTP	consptms4happ	Prod Zone	imz:{"ip":"10.16.1.102"		complete



1-343804758  SMRT
__________________
Description
10/24/2018   00:55:37   S0016320183Hi Team,Please  running the script on 1st Nov 2018 on EP1date: 1st Nov 2018
time: 10 AM SGT/home/postman/HR/hrdsssb_in.sh
/home/postman/HR/hrdsbus_in.sh




1-344176401    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local


1-344172411    Limited Brands, Inc. - SAP HEC-AMM    2-Urgent    Summary: Processor_load_is_too_high_on_LBDSP1App00.imzcloud.ibmammsap.local
10.8.8.63





1-344174011- P1 - Hadi Hamad Al-Hammam Contracting Co (HHH)- portal-not validated- "Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/var
10.7.14.39





1-344043531	sev3
Create mount point in ECQ System DB host from ECP DB host
Hi OS team,

Please create a mount point as below in
eccdb0qas	10.198.2.71	172.28.28.71
mount -o soft 172.28.28.142:/hana/data/BAK /BACKUP

from
eccdb0prd	10.198.2.142	172.28.28.142

Ganesh PDL




1-343702727 > we have CSR
TBO_ Disk Configuration Impacting BackupsServers

Convert Independent disk to dependent disk

Servers:
tbosmabap  <J1S >	100.126.48.17	10.69.20.18
tbosmjava < J2S>	100.126.48.16	10.69.20.15 	




1-344183091    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    1-Critical    Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[

/mnt/sapexchangePT /mnt/sapexchangePT




1-344185941    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Ruuning_out_of_available_memory_on_server_snchtripa11.imzcloud.ibmammsap.local



1-344185931    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Ruuning_out_of_available_memory_on_server_snchtriqa11.imzcloud.ibmammsap.local 



RFS # 1-344123180 
spsvhpigsql01 10.70.111.38	10.6.3.38	down
spsvwplwapp11 10.70.111.39	10.6.3.39	down
spsvwplwapp12 10.70.111.40`	10.6.3.40	down	
spsvcpicapp11 10.70.111.41	10.6.3.41	down	
spsvcpicapp12 10.70.111.42	10.6.3.42	down
spsvdpidapp01 10.70.111.43	10.6.3.43	down

------------------------------------------------------------------------------------------------------------------------

2 Nov



1-344218411    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    1-Critical    Summary: FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local
 /mnt/sapexchangePT
10.199.1.10

[root@C1ECCP ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
rm: cannot remove `/mnt/sapexchangeIT/testfile': Invalid argument
rm: cannot remove `/mnt/sapexchangeIT/testfile': Invalid argument
CRITICAL |  /mnt/sapexchangeIT /mnt/sapexchangeIT filesystems are read-only
//10.3.1.1/sapexchange /mnt/sapexchangeIT cifs credentials=/etc/sapexchangeIT_credential,uid=908,gid=5003

mount //10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/   -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003




1-344206211    Suncor Energy Inc. (SNC)    2-Urgent    Summary: snc_mem_rlzc_redhat[(Net_Memory_Used_Pct>=85 ) ON snc_snchdmdqd12:LZ (Net_Memory_Used_Pct=8 




1-344223331    Dilip Buildcon Limited (DLB)    2-Urgent    Summary: Lack_of_free_swap_space_on_PECAP01.imzcloud.ibmammsap.local




1-344226291    MSC Industrial Supply Co.    2-Urgent    Summary: SAP SolMan Sys=WM1_WDC04AMMSOL04,MO=MS3PH203,Alert=Minimum CPU rate (MHz),Desc=A low CPU fr 
 	146.89.142.36	



1-344228061    Delta Airlines, Inc. - SAP HEC-AMM
 Zabbix_agent_on_dlthmehap5.imzcloud.ibmammsap.local_is_unavailable
---------------------------------------------------------------------------------------------------------

6 Nov

1-344365941      Incident    1    JGC  ==> OS
: jgcs4sbxdb.imzcloud.ibmammsap.local_has_just_been_restarted
10.199.31.27


1-344366631    Incident    1    JGC ==> OS 
 jgcs4sbxdb.imzcloud.ibmammsap.local_has_just_been_restarted
10.199.31.27


SCO - 1-344358504 - SL-Toronto-01 - Suncor Energy Inc. (SNC) - SAP HEC-AMM - Issues On PR1 And The servers SNCHECAPA14 / SNCHECAPA20 Were Not Accessible
VM Name :
SNCHECAPA14 - Linux	10.73.10.18	
SNCHECAPA20 - Linux	10.73.10.24

snchecapa11	 	10.73.10.15

statfs("/usr/sap/transecc",

[root@snchecapa11 ibmrmalik]# cat /etc/fstab |grep -i /usr/sap/transecc
10.72.1.99:/usr/sap/transecc /usr/sap/transecc nfs _netdev,defaults 1 2

10.72.1.99	10.73.11.99	snchecada11
statfs("/SHARE/MNT/FILE056/SAP_DATA_nonprd01
[root@snchecada11 ibmrmalik]# cat /etc/fstab |grep -i /SHARE/MNT/FILE056/SAP_DATA_nonprd01
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0

file056 10.145.96.186


Toll-free dial-in number (Canada/US): 1 855-453-6957
Local dial-in number: 403-410-3051

Conference ID: 2531346

	SNCHECAPA11	rebooted	back up
	SNCHECAPA12	rebooted	back up	c
	SNCHECAPA13	rebooted	back up	c
	SNCHECAPA14	rebooted	back up
	SNCHECAPA15	rebooted	back up
	SNCHECAPA16	rebooted	back up
	SNCHECAPA17	rebooted	disk replication error
	SNCHECAPA18	rebooted	back up	c
	SNCHECAPA19	rebooted	back up
SNCHECAPA20	rebooted	back up

14 11 17 12 13 16 15 17 18   gud


[root@snchecapa11 ibmrmalik]# cat /etc/fstab |grep -i file
# Accessible filesystems, by reference, are maintained under '/dev/disk'
file063:/SAP_DATA_prd01/SAP_DATA_prd01 /SHARE/MNT/FILE063/SAP_DATA_prd01 nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0
file063:/SAP_DATA_prd01/SAP_ARCH_prd01 /SHARE/MNT/FILE063/SAP_ARCH_prd01 nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0
file063:/SAP_DATA_prd01/SAP_LOAD_prd01 /SHARE/MNT/FILE063/SAP_LOAD_prd01 nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0

[root@snchecapa12 ibmrmalik]# cat /etc/fstab |grep -i nfs
snchecapa11:/sapmnt/PR1           /sapmnt/PR1 nfs   defaults  1  2


sapnfscgy100:/SAP_SBO/SAP_ARCHIVE/PROD /SAP_ARCHIVE nfs vers=3,proto=tcp,sec=sys,hard,intr,link,symlink,rsize=32768,wsize=32768,retrans=5,timeo=60000



mount -t nfs file063:/SAP_DATA_prd01/SAP_DATA_prd01 /SHARE/MNT/FILE063/SAP_DATA_prd01;mount -t nfs file063:/SAP_DATA_prd01/SAP_ARCH_prd01 /SHARE/MNT/FILE063/SAP_ARCH_prd01;mount -t nfs file063:/SAP_DATA_prd01/SAP_LOAD_prd01 /SHARE/MNT/FILE063/SAP_LOAD_prd01



SNCHEPJPA11	10.73.10.60	rebooted
SNCHEPJPA12	10.73.10.61	
SNCHEPJPA13	10.73.10.62
SNCHEPJPA14	10.73.10.63	rebooted
SNCHEPJPA15	10.73.10.64
SNCHEPJPA16  	10.73.10.65 


SNCHEPJDA11 	10.73.11.112	10.72.1.112 	
10.72.1.112:/usr/sap/transep /usr/sap/transep nfs _netdev,defaults 1 2



10.72.1.99	10.73.11.99	snchecada11
[root@snchecada11 ibmrmalik]# cat /etc/fstab |grep -i /SHARE/MNT/FILE056/SAP_DATA_nonprd01
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 /SHARE/MNT/FILE056/SAP_DATA_nonprd01  nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600    0       0

file056 10.145.96.186


on snchepjpa14
10.72.0.60:/sapmnt/PP6/ /sapmnt/PP6 nfs    rw,hard,intr,rsize=32768,wsize=32768    0  0
10.72.1.112:/usr/sap/transep /usr/sap/transep nfs _netdev,defaults 1 2


mount -t nfs 10.72.0.60:/sapmnt/PP6/ /sapmnt/PP6;mount -t nfs 10.72.1.112:/usr/sap/transep /usr/sap/transep



sncheuapd11	00	PE1	10.73.10.128
sncheuapd12	00	PE1	10.73.10.129
sncheuapa11	SCS 50, CI  51	PE1	10.73.10.130	rebooted
sncheuapa12	SCS 50, CI  51	PE1	10.73.10.131	rebooted
sncheuapa13	SCS 50, CI  51	PE1	10.73.10.132	rebooted


snchcuapd11	00	PU1	10.73.10.92
snchcuapd51	00	PU1	10.73.10.93
snchcuapa11	SCS 35 IN 36	PU1	10.73.10.94
snchcuapa12	IN 36	PU1	10.73.10.95

snchsmapd11	00	HE5	10.73.10.73
snchsmapd51	00	PS1	10.73.10.74
snchsmjpa50	SCS 87 IN 88	PS1	10.73.10.75
snchsmapa11	SCS 85 IN 86	PS1	10.73.10.76



DR1 - snchecada11	10.73.11.99
10.73.10.63    snchepjpa14 



D1M	snchmdada11	10.73.11.104



DS1	snchsmjda11	10.73.11.54  	back up

1:16:11 PM: DV6	snchbdjda11	10.73.11.116 	back up  

1:16:35 PM: DP6	snchepjda11	10.73.11.112 `back up
 

1:16:44 PM: DX6	snchpijda11	10.73.11.114  	back up

passcode 30873722    

12:23:10 PM: 000117
Toll Free:    1-888-426-6840


DB6	snchbwjda11	10.73.11.135	back up
DI6	snchdijpa11	10.73.10.11	back up
DS1	snchsmada11	10.73.11.53	back up


10.73.11.138 SNCHEUADA11 DE1 	DEV	sncheuada11
[root@TOR01AMMCHEF01 ~]# knife environment list
_default
snc_development
snc_production
snc_production_68


./bootstrap_v12.sh -o snc -n SNCHEUADA11 -l -d imzcloud.ibmammsap.local -t osonly -e snc_development 



DR1 - snchecada11	10.73.11.99  

/dev/mapper/dr1appvg-usrtrans_lv
                      41153856  19422668  19634036  50% /usr/sap/transecc

snchecapa11	SCS 00 IN 01	PR1	10.73.10.15	already there
snchecapa12	IN 01	PR1	10.73.10.16	done
snchecapa13	IN 01	PR1	10.73.10.17	done
snchecapa14	IN 01	PR1	10.73.10.18	done
snchecapa15	IN 01	PR1	10.73.10.19	done
snchecapa16	IN 01	PR1	10.73.10.20	done
snchecapa17	IN 01	PR1	10.73.10.21	done
snchecapa18	IN 01	PR1	10.73.10.22	done
snchecapa19	IN 01	PR1	10.73.10.23	done
snchecapa20	IN 01	PR1	10.73.10.24	done

--------------------------------------------------------------------------------------------------------------

10 Nov

1-344257281	sev3
 Free_disk_space_is_less_than_20%_on_volume_C:
10.4.3.18



1-344498101




1-344502341    Delta Airlines, Inc. - SAP HEC-AMM    2-Urgent    Summary: Free_disk_space_is_less_than_10%_on_volume_/var/log
 10.4.5.25



1-344503091 sev2
Free_disk_space_is_less_than_10%_on_volume_C:
 10.4.5.50



1-344494401 A.P. Moller Maersk (APM) P1
Free_disk_space_is_less_than_5%_on_volume_/var/log
100.126.64.139



1-344508441 IBM AMM Infrastructure P2
Processor_load_is_too_high_on_dal09ammtsm001.imzcloud.ibmammsap.local
146.89.140.50



1-343949811	sev3
Please map the drives
*** Details of Generic Service Request - DO NOT CHANGE ***

Hello ,

Please map the drives 

(Similar to SR 1-330874481)

From 10.4.3.17 (LZAVTXDEV0). please share the following folders with the respective LSPI ECC servers.  Specifically ...

1) \\Lzavtxdev0\ftp\Blackline\ES1 should be shared with ES1 server (LZAECCSBX0 - 10.4.3.11)
User ID on LZAVTXDEV0 is SAPserviceES1 / PW: Security#1     

2)  \\Lzavtxdev0\ftp\Blackline\ED1 should be shared with ED1 server (LZAECCDEV0 - 10.4.3.13)
User ID on LZAVTXDEV0 is SAPserviceED1 / PW: Security#1

3)  \\Lzavtxdev0\ftp\Blackline\EQ1 should be shared with EQ1 server (LZAECCQAS0 - 10.4.3.15)
User ID on LZAVTXDEV0 is SAPserviceEQ1 / PW: Security#2

4)  \\Lzavtxdev0\Blackline\EP1 should be shared with EP1 server (LZAECCPRD0 - 10.4.2.11)
User ID on LZAVTXDEV0 is SAPserviceEP1 / PW: Security#1






1-344390491    A.P. Moller Maersk (APM)     2-Urgent
Summary: Free_disk_space_is_less_than_10%_on_volume_/var/log
100.126.64.141




1-344508661    Suncor Energy Inc. (SNC)    1-Critical 
10.73.10.76
/dev/mapper/ps1appvg-usrsapccms_lv
                      16513960 13921216   1754064  89% /usr/sap/ccms



--------------------------------------------------------------------------------------------------------------------------------

11 Nov



1-343529217 11/10/2018 08:00:00 PM
PT Anugerah Pharmindo Lestari (PTP)
Convert Independent disk to dependent disk
Convert Independent disk to dependent disk
Affacted systems :Server Name     IFN    CFN     Server purpose     SID     Proposed downtime
PTPBROMO     10.70.31.16    192.168.166.12     Prod    APP    6 hours Downtime as server need to be power off
PTPKOMODO     10.70.31.13    192.168.166.30     Prod    APP    6 hours Downtime as server need to be power off
PTPRAJAAMPAT     10.70.31.22    192.168.166.35     Prod    POP    6 hours Downtime as server need to be power off


a) POP  PTPRAJAAMPAT  First             10.70.31.22

b) APP   PTPKOMODO  application server  10.70.31.13

c) APP central instance  PTPBROMO       10.70.31.16





1-344526221 - Sev1 - RAA - SAP HEC-AMM - Siebel - Not Validated - Summary: Free_disk_space_is_less_than_5%_on_volume_F:
10.4.12.12
F drive is 26% free




1-344527441  -  P3  -  DyStar Singapore Pte Ltd (DYS) 
Confirm GPFS version using the following command:
rpm -qa | grep gpfs

Check value of tokenMemLimit using the following command:
mmlsconfig | grep tokenMemLimit





1-344439525 	sev3
Unmount /usr/sap/trans on dysfrdafrq20 and mount it as /usr/sap/trans_old	10.6.12.32	10.1.162.32 	
/dev/frqappvg/usrtrans_lv       /usr/sap/trans  ext3    _netdev,defaults        1       2



Mount  /usr/sap/trans from dysfrdafrd40 to dysfrdafrq20
DYSFRDAFRD40 	10.6.12.22	10.1.162.20
dysfrdafrq20 	10.6.12.32	10.1.162.32 

/usr/sap/trans *(rw,sync,no_root_squash)

10.1.162.20:/usr/sap/trans     /usr/sap/trans nfs   defaults       0 0


10.4.8.11
penat15sl
pas


/root/bootstrap_v12.sh -o pas -n penat15sl -l -d imzcloud.ibmammsap.local -t osonly -e pas_production



10.4.8.16 

10.4.8.11 

10.4.8.10 

10.4.8.14





1-344529811  -  P2  -  IBM AMM Infrastructure
Lack_of_free_swap_space_on_mon01ammtsm001.imzcloud.ibmammsap.loca





1-344530121	sev1
Zabbix_agent_on_USSAPAFD.imzcloud.ibmammsap.local_is_unavailable


------------------------------------------------------------------------------------------------------------------------


13 Nov


1-344590174	sev3	Paris
Please increase required swap size on below servers

CI3S4HANAQAA	10.210.1.14	    	required swap size 64 gb	current is 8 need to extend by 56G
[root@CI3S4HANAQAA ibmrmalik]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0
unused disk available to be used


CI3S4HANAPRDA	10.210.1.12		required swap size 64 gb	48 GB to be extended current is 16	need to add disk
[root@CI3S4HANAPRDA ibmrmalik]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0
[root@CI3S4HANAPRDA ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   2   7   0 wz--n- 71.50g 19.00g	


CI3SOLMAN	10.210.1.17	                required swap size 64 gb  add 56 GB swap current is 8
[root@CI3SOLMAN ibmrmalik]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0


CI3SRPRD	10.210.1.24	                required swap size 32 gb	add 24 GB current is 8
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0
[root@CI3SRPRD ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   1   7   0 wz--n- 39.51g 2.50g


contacts:
mushtaque@in.ibm.com
joelnag@my.ibm.com




1-344589730 	clear cache
svjd1srv0	10.6.1.12
svld1srv0	10.6.1.20 
 


1-344234626 - Linux - Approved

Fiori AB/DB (SSGSA0119)

2018/11/19 (Mon) JST  22:00 - 2018/11/20 (Tues) 02:30 AM - 4.5 HRS
2018/11/19 ( Mon) PST 05:00 AM - 09:30 AM - 4.5  HRS

OS:Ravi Malik (rmalik@us.ibm.com)




SMRT request from Pilla
We need to immediately  pull the CRONTAB entries from the below servers - for a CRITICAL MIGRATION on SMRT servers.

clderpappd1 - postman, root , ed1adm	10.198.0.208	
clderpappq1 - postman , root. eq1adm	10.198.0.211	
clderpappp1 - postman. root . ep1adm	10.198.0.75
cldproapdd1 - postman. root , od1adm	10.198.0.201
cldproapdt1 - postman, root , oq1adm	10.198.0.217	
cldproappp1 - postman, root , op1adm	10.198.0.71




1-342246840	CMA	Paris
CEM-AMM 3.x: Apply latest Q418 bundle  patches on RH Linux OS Ver 5.x/6.x
		
jazril@my.ibm.com

OS Engineer : ravi malik (rmalik@us.ibm.com)
 AG  Julio Cesar Bermudez Robles/Costa Rica/IBM  
SAP Engineer :  stopsap-Bogdan Bardos/Romania/IBM, startsap-Marco Castro Ramirez/Costa Rica/IBM

EMEA SAP: Iulia Bumbar
PEM suppression is required

	
SMBWDEVDW3	10.78.22.46	done
		
		
SMBWUATUW3	10.78.26.28	done
		
		
MMGRAS	10.78.22.12	done
		
		
SPSPNAS	10.78.22.11	done





Sev1 ticket, 1-344495921, /interface/dev - 100% full
MMGRAS	10.78.22.12
[root@mmgras ibmrmalik]# df -h  /interface/dev
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/interfaces_vg-lv_dev
                       50G   44G  2.9G  94% /interface/dev


----------------------------------------------------------------------------------------------------------------------

14 Nov


1-344638141	pw reset account unlock and login issue
10.6.1.155    eh1adm



1-344640131	CPU RAM performance	sev3	Paris
SMBWDEVDW3 >>	10.78.22.46	ammpar01clustex007
SMTMDEVDT3 >>	10.78.22.16	ammpar01clustex002
SMTMUATUT3 >>	10.78.26.14	ammpar01clustex007




1-344638152	sev3
Snapshot to be taken 
SNG svls1srv0 - 10.6.1.144



SCO - 1-344638048 - SL-Singapore-01 - AGEAS (AGE) - SAP HEC-AMM - svad1srv0 server not reachable
svad1srv0       10.6.1.18	A0EASG014XVM009

--------------------------------------------------------------------------------------------------------------------------------

15 NOv


1-344638152	sev3
Snapshot to be taken 
SNG svls1srv0 - 10.6.1.144


	
1-343505861	sev2
Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[
10.133.15.25




1-344355581	sev2
Lack_of_free_swap_space_on_juddtrans03.imzcloud.ibmammsap.local




1-344097781	sev2
Lack_of_free_memory_on_server_GRC01





1-344387061	sev2
Free_disk_space_is_less_than_10%_on_OS_volume_/[




1-344399321	sev2
Processor_load_is_too_high_on_juddtrans02.imzcloud.ibmammsap.local[
10.196.4.13



1-344395891	sev2
Processor_load_is_too_high_on_juddtrans02.imzcloud.ibmammsap.loca



1-344666971 	sev2
Processor_load_is_too_high_on_ms3wdcladb13.imzcloud.ibmammsap.local
10.12.6.29 



1-344710281	sev1
Free_disk_space_is_less_than_5%_on_OS_volume_/
IA1POQASDB




1-342624891	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/
10.68.212.10

[root@ciarh02 log]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   13G   12G  54% /




1-344732811 - SL-Paris-01 - CMA CGM (CMA) - IC4SAP-SL - Users facing performance issue on 3 Prod servers
SMBWDEVDW3 >>    10.78.22.46    ammpar01clustex007
SMTMDEVDT3 >>    10.78.22.16    ammpar01clustex002
SMTMUATUT3 >>    10.78.26.14    ammpar01clustex007


1-344740851 - Sev1 -  SDM Test  - Siebel Ticket - Not Validated - Free_disk_space_is_less_than_5%_on_volume_/var/log
 10.138.11.25






1-344711650	sev3
[root@cldproapdd1 ibmrmalik]# id daaadm
uid=505(daaadm) gid=503 groups=503,502(sapinst)


/usr/sap/OD1/SYS/profile

-rw-r--r--  1 od1adm daaadm  1142 Jul 13 18:38 DEFAULT.PFL

-------------------------------------------------------------------------------------------------------------------

18 Nov


MSC issue with SNC post patching
10.12.7.12
10.12.7.13
for EP1



MP1 DB - MS3WDCLADB33    10.12.7.17
MP1/WPP - MS3WDCLAPP33B    10.12.7.33



GP1 - MS3WDCLAPP39    172.17.156.26    Production
GP1 - MS3WDCLAPP38    172.17.156.25    Production



AP1 - MS3WDCLADB44	10.12.7.31   snapshot  AP1_postQ4Patch







1-344855601	sev2	
Processor_load_is_too_high_on_IA1S4HQASAPP.imzcloud.ibmammsap.local	10.133.17.140
top - 04:32:31 up 40 days, 20:19,  1 user,  load average: 0.11, 0.11, 0.09
Tasks: 275 total,   2 running, 273 sleeping,   0 stopped,   0 zombie
Cpu(s):  4.8%us,  1.0%sy,  0.0%ni, 94.2%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    15.561G total,   15.146G used,  424.441M free,  223.805M buffers
Swap:   31.996G total,   11.111G used,   20.885G free, 7237.035M cached



1-344821721	sev2	transfer to SAP
Lack_of_free_swap_space_on_ms3wdcladb23.imzcloud.ibmammsap.local	10.12.6.42

top - 03:35:10 up 7 days,  7:15,  1 user,  load average: 0.14, 0.20, 0.20
Tasks: 263 total,   3 running, 260 sleeping,   0 stopped,   0 zombie
Cpu(s): 43.2%us, 15.2%sy,  0.0%ni, 39.7%id,  1.7%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    11.625G total,   11.225G used,  409.141M free,  636.504M buffers
Swap: 8191.996M total, 4176.465M used, 4015.531M free, 3752.102M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
33336 jq1adm    20   0 7001m 3.0g  13m S  6.6 26.2 239:56.90 166m jstart
 8902 sapadm    20   0 1501m 358m 5660 S  0.0  3.0  13:39.72 109m sapstartsrv
 9964 daaadm    20   0 2117m 310m 8096 S  0.3  2.6  57:52.01  30m jstart



1-344762281	sev3	10.12.6.65 
Free_disk_space_is_less_than_20%_on_OS_volume_/var[

[root@ms3wdcappsd1 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  3.4G  1.2G  75% /var




1-344762311	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var	
[root@ms3wdcappsd1 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  3.4G  1.2G  75% /var






1-344770841  sev3
FS_is_read_only_on_mdcserverp1.imzcloud.ibmammsap.local
run/user/71024 		10.12.7.41
mdcserverp1:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
OK



1-344770141
FS_is_read_only_on_mdcserverp2.imzcloud.ibmammsap.local
run/user/2535 
10.12.7.42 
mdcserverp2:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
OK




1-344745071	sev2	
Processor_load_is_too_high_on_IA1S4HPRDAPP.imzcloud.ibmammsap.local[
10.133.15.13
top - 05:02:39 up 27 days, 20:59,  1 user,  load average: 0.81, 0.62, 0.30
Tasks: 356 total,   1 running, 355 sleeping,   0 stopped,   0 zombie
Cpu(s):  8.4%us,  5.6%sy,  0.0%ni, 85.9%id,  0.0%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    31.341G total,   29.517G used, 1867.535M free,   29.191M buffers
Swap:   64.000G total,   10.494G used,   53.506G free,   18.577G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
103451 sp1adm    20   0 28.7g 7.1g 6.8g S 12.0 22.5  18:33.52 SP1_00_BTC_W50




1-344742231	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var[
10.133.15.13
[root@IA1S4HPRDAPP ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  3.2G  1.5G  69% /var




1-344723961	sev3	10.4.3.26 
Free_disk_space_is_less_than_20%_on_volume_C:
Cleaned up temp fiels to create 28% free space on C drive




1-344719651	sev2	10.12.6.30	transfer to SAP
Lack_of_free_swap_space_on_ms3wdcladb14.imzcloud.ibmammsap.local
top - 04:26:43 up 14 days, 10:24,  1 user,  load average: 0.31, 0.43, 0.43
Tasks: 285 total,   1 running, 284 sleeping,   0 stopped,   0 zombie
Cpu(s):  7.5%us,  6.5%sy,  0.0%ni, 84.9%id,  1.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    11.625G total, 9410.078M used, 2493.793M free,  493.531M buffers
Swap: 8191.996M total, 6475.387M used, 1716.609M free, 1011.371M cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
24221 ad1adm    20   0 1429m  10m 1644 S  0.0  0.1   1:13.23 787m en.sapAD1_SCS02
28237 ad1adm    20   0 7027m 2.1g 9812 S  0.0 18.4  96:50.18 489m jstart
27392 ad1adm    20   0 7123m 2.4g  14m S  2.1 20.3 278:19.62 416m jstart
 8936 sapadm    20   0 1169m 162m 5252 S  0.0  1.4  22:49.79 248m sapstartsrv
27848 ad1adm    20   0 1691m  20m 5684 S  0.0  0.2   1:57.05 103m icman
26113 ad1adm    20   0 1693m  29m 6244 S  0.0  0.2   2:21.83  96m icman
 9937 daaadm    20   0 1856m  67m 2972 S  0.0  0.6  25:53.65  87m jstart
10588 da1adm    20   0 2130m 354m 4904 S  0.0  3.0  92:30.25  64m jstart




1-344713171	sev2	10.12.7.17 	
Lack_of_free_swap_space_on_ms3wdcladb33.imzcloud.ibmammsap.local[
[root@ms3wdcladb33 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         19         11          9          0         17
-/+ buffers/cache:          1         29
Swap:            7          0          7








1-344744381	sev2	10.68.210.15 
Lack_of_free_memory_on_server_GRC01
memory used is less than 40%




1-344734471	sev2	10.68.211.11
Free_disk_space_is_less_than_10%_on_volume_C:
mail sent to DPE




1-344436591	sev3	10.196.4.15 
Free_disk_space_is_less_than_20%_on_OS_volume_/var[
[root@juddtrans03 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  3.5G  1.2G  76% /var





1-344810641 - SL-Dallas-09 - American Airlines

QAS2 â€“ ERP on HANA  App Server    PQ2    AHECQ2SAP01    10.4.10.51
QA2 - ERP on HANA  DB Server    PQ2    AHECQ2HDB01    10.4.10.50

ping erpsfqa2.aa.amm.ibmcloud.com

-----------------------------------------------------------------------------------------------------------

19 Nov


1-344767471	sev2
Add 6GB space on  ADNAELAPP1
 ADNAELAPP1 available in /usr/sap/ccms
10.198.200.12	SNG
[root@ADNAELAPP1 ibmrmalik]# df -h /usr/sap/ccms
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/alpappvg-usrsapccms_lv
                      9.9G  138M  9.3G   2% /usr/sap/ccms




smtmsbxst1, 10.78.20.13
1-344569701 - Summary: Free_disk_space_is_less_than_5%_on_OS_volume_/home[PROBLEM:9486632] Date: Nov 12,2018 13:2 
[root@smtmsbxst1 ibmrmalik]# df -h /home
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_home
                      2.0G   76M  1.8G   5% /home



1-344234626Â 	Mitsubishi Motors Corporation (MMD)		SNG		
					
			uname -a	date	redhat release
	SSGSA0119	100.126.0.13	Linux SSGSA0119 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux	Tue Nov 13 11:58:00 UTC 2018	Red Hat Enterprise Linux Server release 6.9 (Santiago)



1-344808881	sev1	10.12.12.14 
Zabbix_agent_on_ctuwdprdap02.imzcloud.ibmammsap.local_is_unavailable[




1-344663731	sev2	10.4.12.11
Lack_of_free_memory_on_server_ECCPROD02




1-344877581    IBM AMM Infrastructure    2-Urgent
Processor_load_is_too_high_on_dal13ammsol04.imzcloud.ibmammsap.loca



1-344881261    MSC Industrial Supply Co.    2-Urgent	 10.12.6.71
 Processor_load_is_too_high_on_ms3wdclapp21B.imzcloud.ibmammsap.local



1-344806791	sev2	146.89.140.178 
PBBffpapdb00 10.6.7.22 , DF is hung on this server , Please check NFS mounts 






1-344888071 sev3
Request 1 :
Source : 
Server : SMPOQUAQX8, 10.78.24.22
FS : /usr/sap/QX8/PI/SFTP/PGP
Task : upload the enzipped attached PGP file (so pubring.pgp file) to this folder (to create): /usr/sap/QX8/PI/SFTP/PGP

Request 2 :
Mount the SMECCQUAQE1, 10.78.24.19 folder "/interface/qua/ecc2po/trax" to SMPOQUAQX8, 10.78.24.22


Request 3 : 
Source : 
Server : SMPOUATUX8, 10.78.26.19
FS : /usr/sap/UX8/PI/SFTP/PGP
Task : upload the enzipped attached PGP file (so pubring.pgp file) to this folder (to create): /usr/sap/UX8/PI/SFTP/PGP


Request 4 :
Mount the SMECCUATUE3, 10.78.26.16 folder "/interface/uat/ecc2po/trax" to SMPOUATUX8, 10.78.26.19



SMECCQUAQE1 	10.78.24.19	10.5.24.19
SMPOQUAQX8 	10.78.24.22	10.5.24.22
SMECCUATUE3 	10.78.26.16	10.5.26.16 	
SMPOUATUX8 	10.78.26.19	10.5.26.19



-------------------------------------------------------------------------------------------------------------------------------

20 Nov


(CMS-SQ-SAP-TRIO-LIN) OS SME approves the change starting on 20th November 2018 @ 5AM PST for 4 hours
 11/20/2018 05.00 AM PDT for 4 hour



DLB issue-->1-344588401
DLBDCSDA00    Development    10.13.2.23




1-344944941	sev1	
Zabbix_agent_on_crprdhanadb1.imzcloud.ibmammsap.local_is_unavailable




1-344590174
CI3SOLMAN	10.210.1.17	                required swap size 64 gb

[root@CI3SOLMAN ibmrmalik]# cat /etc/fstab |grep swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0


[root@CI3SOLMAN ibmrmalik]# vgs VolGroup
  VG       #PV #LV #SN Attr   VSize  VFree
  VolGroup   1   7   0 wz--n- 39.51g 1.50g

[root@CI3SOLMAN ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         24          7          8          0         10
-/+ buffers/cache:         12         19
Swap:            7          5          2


Disable swapping for the associated logical volume:

    # swapoff -v /dev/mapper/VolGroup-lv_swap

    Resize the LVM2 logical volume by 256 MB:

    #lvextend /dev/mapper/VolGroup-lv_swap -L +56G

    Format the new swap space:

    # mkswap /dev/mapper/VolGroup-lv_swap

    Enable the extended logical volume:

    # swapon -va



1-344280681	sev2	10.6.7.21 
Processor_load_is_too_high_on_PBBffdapdb00.imzcloud.ibmammsap.local[



1-344898211	sev2	10.198.12.15
Lack_of_free_swap_space_on_sjmqgpdb01.imzcloud.ibmammsap.local[
top - 14:36:33 up 89 days,  3:30,  1 user,  load average: 1.30, 1.06, 0.80
Tasks: 420 total,   1 running, 419 sleeping,   0 stopped,   0 zombie
Cpu(s): 10.0%us,  0.2%sy,  0.0%ni, 89.7%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.349G total,   21.149G used,   10.200G free, 1672.504M buffers
Swap: 8191.996M total, 3016.031M used, 5175.965M free, 9060.918M cached



1-343561041	sev2	
Lack_of_free_swap_space_on_fbtprdfirwd.imzcloud.ibmammsap.local[ 



1-344169471	sev2	10.4.27.14 
Free_disk_space_is_less_than_10%_on_OS_volume_/var
[root@fbtprdhanapp2 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  3.2G  1.4G  70% /var




1-344672851	sev2	10.4.27.13 
Processor_load_is_too_high_on_fbtprdhanapp1.imzcloud.ibmammsap.local



1-344819691	sev2
Free_disk_space_is_less_than_10%_on_volume_/var/log




1-344949271    SAP07    2-Urgent    Raycap GmbH (RYC)    RYC 
Free_disk_space_is_less_than_10%_on_DB_volume_/db2/RT4/log_archiv



1-344949111    SAP10    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM    LBD
Processor_load_is_too_high_on_LBDSP1App00.imzcloud.ibmammsap.local
 10.8.8.63




1-344954531		sev3
Add 1GB space on  ADNAELAPP1
1GB to be added on ADNAELAPP1 available in /home/sapadm
10.198.200.12	SNG
[root@ADNAELAPP1 ibmrmalik]# df -h /home/sapadm
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/alpappvg-sapadm_lv
                     1008M   34M  924M   4% /home/sapadm





1-344948871	sev2	10.69.1.14
Lack_of_free_swap_space_on_LONCFGCGQ0001.imzcloud.ibmammsap.loca
[root@LONCFGCGQ0001 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         29          1          8          0         15
-/+ buffers/cache:         13         17
Swap:           13          6          7

--------------------------------------------------------------------------------------------------

21 Nov


1-344969707 ----> also to be executed in 2nd shfit as HO
Fix required for Independent Disk
Noncompliance Issue	106490643
:
Due to a disk configuration that was automatically set during provisioning, disks other then roovg were set to not get backed up on Redhat and SLES VM's built in 3.x. The error has been fixed on VM's that are being provisioned now, however, we have to go back and fix the disk setting on the VM. A reboot is required. 
VMs 
lbdcp1app02 
lbdcq1app02 
lbdwdp6app80 
lbdwdp7app80 
lbdwdp8app80 
lbdwdp9app80


1-344969593----> these two need to be excuted in the 2nd shift Please take this HO
Fix required for Independent Disk
Noncompliance Issue	106490646 :
Due to a disk configuration that was automatically set during provisioning, disks other then roovg were set to not get backed up on Redhat and SLES VM's built in 3.x. The error has been fixed on VM's that are being provisioned now, however, we have to go back and fix the disk setting on the VM. A reboot is required. 
VMs 
mgggbjtgtsx01 
mgggbjveccx09




1-341504471	 CRITICAL | /usr/interfaces /usr/interfaces	sev3	10.198.0.75
FS_is_read_only_on_cldproappp1.imzcloud.ibmammsap.local
[root@CLDPROAPPP1 ibmrmalik]# cat /etc/fstab |grep -i /usr/interfaces
//10.168.1.71:/usr/interfaces/SAP_to_ARIBA      /usr/interfaces/SAP_to_ARIBA   nfs       rw,hard,intr,rsize=32768,wsize=32768       0 0
(10.168.1.71    10.198.0.71


1-342683011	sev3	
NTP_time_is_driffted_on_CLDBOBIADWT1.imzcloud.ibmammsap.loca




1-344955481	sev3	
NTP_time_is_driffted_on_CLDERPAPPQ1.imzcloud.ibmammsap.loca




1-344966701	sev2	10.198.0.209
Ruuning_out_of_available_memory_on_server_CLDBOBIADWD1.imzcloud.ibmammsap.loca




1-344285831	sev2	10.133.18.193
Free_disk_space_is_less_than_10%_on_OS_volume_/var[
/var is now 53% full




1-345005291    SAP07    2-Urgent    Raycap GmbH (RYC)    RYC
processor load is high	10.7.64.14




1-344998271 sev2 swap space 


1-344763851	sev2	10.133.18.25 
Free_disk_space_is_less_than_10%_on_OS_volume_/[



1-344946591 
permission issue write didnt work




1-342611651	sev2	
Free_disk_space_is_less_than_10%_on_OS_volume_/var



1-342799681	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var




1-344429111	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/var



1-344569691	sev3
Free_disk_space_is_less_than_20%_on_OS_volume_/home




1-344623791	3
Free_disk_space_is_less_than_20%_on_OS_volume_/var





1-344623801  2
Free_disk_space_is_less_than_10%_on_OS_volume_/var

----------------------------------------------------------------------------------------------------------------------------------------

22 NOv


1-345036361
Host: 10.198.11.16 
Cleared cache


1-344645881	 10.7.33.12	sev2
NTP_time_is_driffted_on_PL2SAPQAS.imzcloud.ibmammsap.local


1-344432481	10.133.18.167	sev3	CRITICAL | /Fribourg
FS_is_read_only_on_MGGGBJQECCX01.imzcloud.ibmammsap.local
[root@MGGGBJQECCX01 ~]# sh /var/lib/zabbix/check_rw_mounts.sh
OK
[root@MGGGBJQECCX01 Fribourg]# vi testrm
[root@MGGGBJQECCX01 Fribourg]# ls -ltr testrm
-rwx------ 1 eeqadm sapsys 10 Nov 22  2018 testrm
[root@MGGGBJQECCX01 Fribourg]# rm testrm
rm: remove regular file `testrm'? y
[root@MGGGBJQECCX01 Fribourg]#



1-344728691	sev3	
Free_disk_space_is_less_than_20%_on_volume_/var/log	



1-344169431 Free_disk_space_is_less_than_20%_on_OS_volume_/var	sev3
10.4.27.14


1-344544741 Meggitt Plc (MGG) sev3
NTP_time_is_driffted_on_MGGGBJQECCX01.imzcloud.ibmammsap.loca
10.133.18.167



1-341880281	sev3	
Free_disk_space_is_less_than_20%_on_volume_/db2/SB1/db2dump
[root@smbosbxsb1 ~]# df -h /db2/SB1/db2dump
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/sb1archvg-sb1db2dump_lv
                     1008M  833M  125M  88% /db2/SB1/db2dump
[root@smbosbxsb1 ~]# vgs sb1archvg
  VG        #PV #LV #SN Attr   VSize  VFree
  sb1archvg   1   3   0 wz--n- 64.00g 12.00g



1-342162671	sev3	10.78.24.27
Free_disk_space_is_less_than_20%_on_volume_/db2/QO1/sapdata3



1-342163351	sev3	10.78.24.27
Free_disk_space_is_less_than_20%_on_volume_/db2/QO1/sapdata2




1-342763491	sev2	 10.78.26.14 
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/UT3



1-343825761	sev3 	10.78.24.27	
Free_disk_space_is_less_than_20%_on_volume_/db2/QO1/db2dump
[root@smdsquaqo1q71 ~]# df -h /db2/QO1/db2dump
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/qo1archvg-qo1db2dump_lv
                     1008M  877M   81M  92% /db2/QO1/db2dump
[root@smdsquaqo1q71 ~]# vgs qo1archvg
  VG        #PV #LV #SN Attr   VSize  VFree
  qo1archvg   1   3   0 wz--n- 64.00g 12.00g




1-343901901	sev3		10.78.26.12
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/UB3
[root@smbouatub3 ~]# df -h /usr/sap/UB3
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ub3appvg-ub3usrUB3_lv
                       87G   72G   12G  87% /usr/sap/UB3
[root@smbouatub3 ~]# vgs ub3appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  ub3appvg   3  13   0 wz--n- 179.99g 12.00g



1-344357661	sev3	10.78.26.16
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/UE3




1-344395281	sev2	10.78.20.12
Free_disk_space_is_less_than_10%_on_volume_/sapmnt/shared
[root@smdbsbxst1 ~]# df -h /sapmnt/shared
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_shared
                      256G  226G   31G  88% /sapmnt/shared
[root@smdbsbxst1 ~]# vgs vghanadata
  VG         #PV #LV #SN Attr   VSize VFree
  vghanadata   2   3   0 wz--n- 1.05t 4.99g





1-344417231	sev3	10.78.22.16
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/DT3
[root@smtmdevdt3 ~]# df -hT /usr/sap/DT3
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/dt3appvg-dt3usrDT3_lv
                     ext3   24G   20G  3.0G  87% /usr/sap/DT3
[root@smtmdevdt3 ~]# vgs dt3appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  dt3appvg   2  13   0 wz--n- 227.99g    0



1-345061231 Suncor Energy Inc. (SNC) 1-Critical
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/QR1
 10.73.12.20



1-344467641	sev2	10.78.24.21
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/QR3



1-344485951	sev2	10.78.22.12
Free_disk_space_is_less_than_10%_on_volume_/interface/dev
[root@mmgras ~]# df -h /interface/dev
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/interfaces_vg-lv_dev
                       50G   44G  3.3G  93% /interface/dev
[root@mmgras ~]# vgs interfaces
  Volume group "interfaces" not found
  Cannot process volume group interfaces
[root@mmgras ~]# vgs interfaces_vg
  VG            #PV #LV #SN Attr   VSize   VFree
  interfaces_vg   3   5   0 wz--n- 197.99g 1012.00m

[root@mmgras ~]# df -h /interface/dev
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/interfaces_vg-lv_dev
                       69G   44G   22G  67% /interface/dev



1-344569781	sev2	10.78.22.16
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/trans
[root@smtmdevdt3 ~]# df -h /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/dt3appvg-usrtrans_lv
                      162G  136G   19G  89% /usr/sap/trans
[root@smtmdevdt3 ~]# vgs dt3appvg
  VG       #PV #LV #SN Attr   VSize   VFree
  dt3appvg   3  13   0 wz--n- 243.99g 11.00g




1-344703331	sev3	
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/trans






1-344882171	sev3	10.78.26.18
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/UR3


[root@smcrmuatur3 ~]# df -h /usr/sap/UR3
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/ur3appvg-ur3usrUR3_lv
                       24G   11G   12G  49% /usr/sap/UR3

-----------------------------------------------------------------------------------------------------------------------

23 NOv


1-345100721    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var





IP: 10.198.12.12 

CSR# 1-345036396
[root@sjmqbdba01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         22          9          0          2          5
-/+ buffers/cache:         14         17
Swap:            7          0          7
[root@sjmqbdba01 ibmrmalik]# sync; echo 1 > /proc/sys/vm/drop_caches
[root@sjmqbdba01 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         14         17          0          0          0
-/+ buffers/cache:         14         17
Swap:            7          0          7




1-341725891    sev3	
NTP_time_is_driffted_on_LBDTQ1QASApp1.imzcloud.ibmammsap.local
10.8.8.50


1-345100461	sev3
: Processor_load_is_too_high_on_A0B4HK012VUM002




1-345111911    PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)    1-Critical
FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local
 CRITICAL | /mnt/sapexchange




1-341731031	10.8.8.59	sev3
NTP_time_is_driffted_on_LBDBOQQASApp3.imzcloud.ibmammsap.local





1-341747151	sev3	 10.70.1.15 
NTP_time_is_driffted_on_ecqahanadb1.imzcloud.ibmammsap.local





1-341747161	sev3	10.70.1.13
NTP_time_is_driffted_on_eCDEVHANADB1.imzcloud.ibmammsap.loca




1-341963861	sev3	 10.138.1.18
NTP_time_is_driffted_on_iplsawdap01.imzcloud.ibmammsap.local



1-342030681	sev3	10.8.8.73
Free_disk_space_is_less_than_20%_on_OS_volume_/tmp



1-342258971	sev3	
Not able to login in server 10.8.8.114





1-345117321 Egyptian Refining Company sev 3 
NTP_time_is_driffted_on_ercnwd01.imzcloud.ibmammsap.local
 10.5.1.104



1-344901781	CRITICAL | /run/user/3040	146.89.141.178
FS_is_read_only_on_mon01ammtsm001.imzcloud.ibmammsap.loca


-------------------------------------------------------------------------------------------------------------------
26 Nov


1-344664831 Windows engineer needed to check on folder permissions. Folder path to be specified by SAP engineer Alexander Canales.
Source: LZAECCPRD0 - 10.4.2.11 - EP1
Target:   LZAECCSBX0 - 10.4.3.11 - ES1




1-345185723 install vnc
cldgrcapdd1 - 10.198.0.199



1-345187031    2-Urgent    Province of Nova Scotia (PS1)

PS1DB511 	10.138.10.10	10.232.15.10  on monhana-1024-10.xsportal.local 	
 10.140.48.162	root/MTg4Ocr6dm@






1-345191221    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var 
 10.73.10.15

[root@snchecapa11 ibmrmalik]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                       16G  4.9G   11G  33% /var





SNOW P3  - INC6399156
Memory Virtual CRITICAL: Free Memory 9.99% 	sev2	10.197.1.13 
top - 05:48:32 up 370 days, 13:43,  2 users,  load average: 0.20, 0.24, 0.23
Tasks: 610 total,   1 running, 609 sleeping,   0 stopped,   0 zombie
Cpu(s):  3.4%us,  0.5%sy,  0.0%ni, 96.1%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:   126.036G total,  124.039G used, 2045.215M free,  258.281M buffers
Swap:   50.000G total, 6398.445M used,   43.752G free,   10.401G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 6699 hdvadm    20   0  103g  94g 2.5g S  1.3 75.2  57379:37 hdbindexserver
 6567 hdvadm    20   0 6525m 2.3g 439m S  0.3  1.8   1176:53 hdbnameserver
 6701 hdvadm    20   0 6452m 1.4g 231m S  1.0  1.1   1360:50 hdbxsengine




1-345192611    2-Urgent    Dilip Buildcon Limited (DLB)    Summary: Processor_load_is_too_high_on_DLBPBWAP01.imzcloud.ibmammsap.local



SNOW P3 - INC6399807
Memory Virtual CRITICAL: Free Memory 9.99%
10.197.5.12 	sev2




61606161

-----------------------------------------------------------------------------------------------------------------

27 Nov


1-339321791	sev1	10.12.14.13 	server name not listed hence cannot close the ticket
Zabbix_agent_on_trgrkptus11.imzcloud.ibmammsap.local_is_unavailable[




1-339408351	sev1	10.12.14.17
Zabbix_agent_on_trgrkptusw2.imzcloud.ibmammsap.local_is_unavailable




INC6406939    West African Cotton Company    P2 - Major    Memory Virtual CRITICAL: Free Memory 4.97% (thresh 5:) 
Memory Virtual CRITICAL: Free Memory 4.97% 
10.197.0.11



1-344347781	sev3	10.15.192.14 
Free_disk_space_is_less_than_20%_on_OS_volume_/home[
[root@handvh4dsrv02 home]# df -h .
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-homelv
                      586M  397M  159M  72% /home



1-345152991	sev1	10.12.254.146
Zabbix_agent_on_pn4us7leccmp.imzcloud.ibmammsap.local_is_unavailable



1-344439001	sev3
FS_is_read_only_on_lnasv218.imzcloud.ibmammsap.local[



1-343681231	sev3	10.133.15.27
Free_disk_space_is_less_than_20%_on_volume_C:



1-344132771	sev3	10.69.2.24	
NTP_time_is_driffted_on_loncfgchp0004.imzcloud.ibmammsap.local





1-344136291	sev3
NTP_time_is_driffted_on_IA2SCCDEVAGE.imzcloud.ibmammsap.local[
[root@IA2SCCDEVAGE ~]# ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
+lon02ammadc001. 146.89.140.75    5 u   56   64    1  114.533    3.342  18.224
*lon02ammadc002. 146.89.140.75    5 u   55   64    1  115.882  -16.774  16.748
[root@IA2SCCDEVAGE ~]# ntpstat
unsynchronised
   polling server every 64 s




1-345258661    2-Urgent    Raycap GmbH (RYC)    Summary: Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local
 10.7.64.14




1-345248411    2-Urgent    Limited Brands, Inc. - SAP HEC-AMM        Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/home



1-345259011	sev1
dd 1 GB of space for FS /sybase/MP1/sapdiag  on  LBDMP1PRDDB1  10.8.8.72
[root@LBDMP1PRDDB1 ibmrmalik]# df -h /sybase/MP1/sapdiag
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/mp1logvg-mp1sybdiag_lv
                      8.9G  6.6G  1.9G  78% /sybase/MP1/sapdiag




1-345035531 Adani Enterprises Ltd  Free_disk_space_is_less_than_20%_on_volume_/usr/sap
could you please add 0.5 GB to /usr/sap on  adnaelapp1 10.198.200.12
[root@ADNAELAPP1 ibmrmalik]# df -h /usr/sap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/alpappvg-usrsap_lv
                      1.5G  796M  641M  56% /usr/sap




1-345216043    {IAG GBS Limited (IA1)}     3-Standard -   chef case #1517
SFTP DEV & QUALITY Connectivity issue 
IA1FTSPRDAPP 	10.133.15.24	66.248.244.24 10.133.15.24
resource usage is high mem consumed is 7.5 GB odf 8 GB tota seems server is hung



1-341632661	sev3	 10.78.20.30
NTP_time_is_driffted_on_smgrcsbxsg1.imzcloud.ibmammsap.local



1-341709211	sev3	 10.78.22.52
NTP_time_is_driffted_on_smdbdevdt5.imzcloud.ibmammsap.local




ST Jude
DNS issue

sjmdfpaa01	10.198.11.17	
-------------------------------------------------------------------------------------------------------------------------

28 Nov



1-345288501	PANARIAGROUP INDUSTRIE CERAMICHE SPA (PNC)	1-Critical	Summary: FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local
CRITICAL | /mnt/sapexchange
 10.199.1.30



1-345155761	sev2	10.69.1.14
Lack_of_free_swap_space_on_LONCFGCGQ0001.imzcloud.ibmammsap.local[
top - 02:32:58 up 45 days, 20:10,  1 user,  load average: 0.10, 0.05, 0.01
Tasks: 357 total,   1 running, 356 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.3%us,  0.2%sy,  0.0%ni, 99.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.352G total,   30.835G used,  528.973M free,  607.164M buffers
Swap:   13.766G total, 7559.676M used, 6536.320M free,   15.612G cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND
16638 root      20   0 10.8g 189m 2600 S  0.0  0.6  30:32.53  24m java -Dupdateagent -Djava.endorsed.dirs=. -Dsun.net.inetaddr.ttl=60 -Dsun.net.inetaddr.negative.ttl
59045 root      35  15 1085m  65m 1400 S  0.0  0.2  38:01.24 6300 /opt/monitor/tivoli/client/../_jvm-client/jre/bin/java -Djava.compiler=NONE -Xmx1024m -Djlog.logCmd
 1024 cgqadm    20   0 17.2g 497m 275m S  0.0  1.6   2:02.77 6156 dw.sapCGQ_DVEBMGS00 pf=/usr/sap/CGQ/SYS/profile/CGQ_DVEBMGS00_LONCFGCGQ0001
 1025 cgqadm    20   0 17.2g 504m 278m S  0.0  1.6   2:14.30 4032 dw.sapCGQ_DVEBMGS00 pf=/usr/sap/CGQ/SYS/profile/CGQ_DVEBMGS00_LONCFGCGQ0001
 2415 root      20   0 1060m  93m 5940 S  0.0  0.3  42:41.95 2048 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
  999 cgqadm    20   0 17.1g 889m 768m S  0.0  2.8   0:50.93 2044 dw.sapCGQ_DVEBMGS00 pf=/usr/sap/CGQ/SYS/profile/CGQ_DVEBMGS00_LONCFGCGQ0001
 1000 cgqadm    20   0 17.0g 853m 733m S  0.0  2.7   0:39.77 2044 dw.sapCGQ_DVEBMGS00 pf=/usr/sap/CGQ/SYS/profile/CGQ_DVEBMGS00_LONCFGCGQ0001
 1023 cgqadm    20   0 17.2g 519m 290m S  0.0  1.6   2:15.85 1972 dw.sapCGQ_DVEBMGS00 pf=/usr/sap/CGQ/SYS/profile/CGQ_DVEBMGS00_LONCFGCGQ0001
 1007 cgqadm    20   0 17.2g 1.0g 788m S  0.0  3.2  37:03.84  276 dw.sapCGQ_DVEBMGS00 pf=/usr/sap/CGQ/SYS/profile/CGQ_DVEBMGS00_LONCFGCGQ0001
 1005 cgqadm    20   0 17.1g 911m 773m S  0.0  2.8   0:42.47  140 dw.sapCGQ_DVEBMGS00 pf=/usr/sap/CGQ/SYS/profile/CGQ_DVEBMGS00_LONCFGCGQ0001




1-344982971	sev2 	10.68.210.15
Lack_of_free_memory_on_server_GRC01




1-345309501	sev2	10.12.6.37 
Lack_of_free_swap_space_on_ms3wdclapp19.imzcloud.ibmammsap.local
top - 02:44:21 up 17 days,  7:15,  1 user,  load average: 0.07, 0.04, 0.00
Tasks: 216 total,   1 running, 215 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.2%us,  0.3%sy,  0.0%ni, 98.3%id,  0.0%wa,  0.0%hi,  0.2%si,  0.0%st
Mem:    15.569G total, 6693.668M used, 9249.074M free,   51.055M buffers
Swap: 8191.996M total, 2061.055M used, 6130.941M free,  759.855M cached




1-345292341	sev2	10.12.6.43 
Processor_load_is_too_high_on_ms3wdcladb24.imzcloud.ibmammsap.local[



1-345300881    sev2	10.133.15.25 
Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local




1-345308461  Meghna Group Of Industries (MG2)   P3 Meghna: OS version -
Hello Team, please check and advise the OS level for the servers below:

MG2ERPDEVCAPP	10.198.4.12
[root@MG2ERPDEVCAPP ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.9 (Santiago)

MG2ERPDEVDB	10.198.4.11	HANA DB
[root@MG2ERPDEVDB ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)


MG2ERPPRDAPP	10.198.3.12
[root@MG2ERPPRDAPP ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.9 (Santiago)

MG2ERPPRDDB	10.198.3.11	HANA
[root@MG2ERPPRDDB ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

MG2ERPQASAPP	10.198.5.12
[root@MG2ERPQASAPP ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.9 (Santiago)

MG2ERPQASDB	10.198.5.11	HANA
[root@MG2ERPQASDB ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)


1-344965981	sev2	10.133.17.140
Processor_load_is_too_high_on_IA1S4HQASAPP.imzcloud.ibmammsap.local[



1-345318341 / PTP / SEV1 / not validated / Summary: Free_disk_space_is_less_than_5%_on_volume_/usr/sap/APP 
ptpbromo:/home/ibmrmalik # df -h /usr/sap/APP
Filesystem                         Size  Used Avail Use% Mounted on
/dev/mapper/appappvg-appusrAPP_lv   56G   51G  3.0G  95% /usr/sap/APP




610337 / 2018 Scripts not working on EP1 (1-345316277)
10.198.0.71

------------------------------------------------------------------------------------------------------------

29 NOv

1-345216043    {IAG GBS Limited (IA1)}     3-Standard -   chef case #1517 new one 1550
SFTP DEV & QUALITY Connectivity issue 
IA1FTSPRDAPP 	10.133.15.24	66.248.244.24 10.133.15.24
resource usage is high mem consumed is 7.5 GB odf 8 GB tota seems server is hung




1-344234429	ETRO SPA	LON02

ECCDAS00	10.5.2.11	check FS mounts
[root@ECCDAS00 ibmrmalik]# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       27G   15G   11G  57% /
tmpfs                 5.9G  8.0K  5.9G   1% /dev/shm
/dev/sda1             477M  106M  347M  24% /boot
/dev/mapper/vg_app-lv_usrsap
                      187G   87G   92G  49% /usr/sap
/dev/mapper/vg_app-lv_sapmnt
                      9.8G   23M  9.2G   1% /sapmnt
/dev/mapper/vg_app-ITMLV
                      4.8G  522M  4.1G  12% /opt/monitor
172.16.1.9:/srv/ftp/SAP/DEV/
                       27G   14G   14G  51% /ETROIT1
172.16.1.9:/srv/ftp/FILENET/
                       27G   14G   14G  51% /FILENET	



Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       27G   15G   11G  57% /
tmpfs                 5.9G  8.0K  5.9G   1% /dev/shm
/dev/sda1             477M  108M  344M  24% /boot
/dev/mapper/vg_app-lv_usrsap
                      187G   86G   92G  49% /usr/sap
/dev/mapper/vg_app-lv_sapmnt
                      9.8G   23M  9.2G   1% /sapmnt
/dev/mapper/vg_app-ITMLV
                      4.8G  517M  4.1G  12% /opt/monitor
172.16.1.9:/srv/ftp/SAP/DEV/
                       27G   14G   14G  51% /ETROIT1
172.16.1.9:/srv/ftp/FILENET/
                       27G   14G   14G  51% /FILENET


	
SSMCI000	10.5.2.10
[root@SSMCI000 ibmrmalik]# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   15G  9.3G  62% /
tmpfs                 5.9G  8.0K  5.9G   1% /dev/shm
/dev/sda1             477M   95M  357M  21% /boot
/dev/mapper/vg_app-lv_usrsap
                       40G   16G   23G  41% /usr/sap
/dev/mapper/vg_app-lv_sapmnt
                      9.8G  1.5G  7.9G  16% /sapmnt
/dev/mapper/vg_data-lv_db
                      345G  162G  166G  50% /sybase
/dev/mapper/vg_app-lv_sapmnttrans
                       51G   17G   31G  36% /usr/sap/trans
/dev/mapper/vg_tmp-lv_software
                       99G   88G  6.0G  94% /software
/dev/mapper/vg_app-ITMLV
                      4.8G  609M  4.0G  14% /opt/monitor
172.16.1.9:/srv/ftp/SAP/PRD/
                       27G   14G   14G  51% /ETROIT1

[root@SSMCI000 ibmrmalik]# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                       26G   15G  9.3G  62% /
tmpfs                 5.9G  8.0K  5.9G   1% /dev/shm
/dev/sda1             477M  101M  351M  23% /boot
/dev/mapper/vg_app-lv_usrsap
                       40G   16G   23G  41% /usr/sap
/dev/mapper/vg_app-lv_sapmnt
                      9.8G  1.5G  7.9G  16% /sapmnt
/dev/mapper/vg_data-lv_db
                      345G  162G  166G  50% /sybase
/dev/mapper/vg_app-lv_sapmnttrans
                       51G   17G   31G  36% /usr/sap/trans
/dev/mapper/vg_tmp-lv_software
                       99G   88G  6.0G  94% /software
/dev/mapper/vg_app-ITMLV
                      4.8G  594M  4.0G  13% /opt/monitor
172.16.1.9:/srv/ftp/SAP/PRD/
                       27G   14G   14G  51% /ETROIT1


1-345359481 - Sev2 - IBM - Siebel Ticket - Not Validated - Summary: Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local




1-345358401    Suncor Energy Inc. (SNC)    1-Critical
Free_disk_space_is_less_than_5%_on_OS_volume_/var



 1-345361409	sev3	
SUNCOR : Adding disk to FS SNCHEUADD11

SNCHEUADD11  10.73.11.137
FS : /sybase/DE1    ADD 5 GB

[root@sncheuadd11 ibmrmalik]# df -h /sybase/DE1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/de1datavg-de1sybase_lv
                       17G   16G  170M  99% /sybase/DE




1-345377431    A.P. Moller Maersk (APM)    3-Standard    Summary: Free_disk_space_is_less_than_20%_on_volume_/var/log 
100.126.64.18






INC6360572	Perfdata Process-SybaseBackupServer CRITICAL: bcksrvr.exe=stopped
10.197.0.14	


INC6360574	Perfdata Process-SybaseBackupServer CRITICAL: bcksrvr.exe=stopped
10.197.0.14

------------------------------------------------------------------------------------------------------------------------------

30 Nov


mhqadm user on MG2ERPQASAPP  10.198.5.12



1-345413161    1-Critical    COTY Inc (CTU)    Summary: Zabbix_agent_on_ctubwpb0db03.imzcloud.ibmammsap.local_is_unavailable
10.12.10.13
ctubwpb0db03:/home/ibmrmalik # rczabbix-agentd status
â— zabbix-agentd.service - Zabbix Monitor Agent
   Loaded: loaded (/usr/lib/systemd/system/zabbix-agentd.service; enabled; vendor preset: disabled)
   Active: active (running) since Fri 2018-11-30 01:13:43 CET; 1h 12min ago
 Main PID: 9379 (zabbix-agentd)


1-345413181    1-Critical    COTY Inc (CTU)    Summary: Zabbix_agent_on_ctubwpb0db02.imzcloud.ibmammsap.local_is_unavailable
10.12.10.29



1-345413701    1-Critical    COTY Inc (CTU)    Summary: Zabbix_agent_on_CTUBWQB1DB01.imzcloud.ibmammsap.local_is_unavailable
10.12.10.22


INC6434773    P3 - Minor    Dixons Carphone        Memory Virtual CRITICAL: Free Memory 9.85% (thresh 10:) 
10.197.5.12



1-345385327    3-Standard    AGEAS - SAP HEC-AMM 
P2 : Temporary directory in 10.92.99.164 (63501/2018)
10.92.99.164 with 50GB of space
10.6.1.164   WIn2k12




INC6435706    P3 - Minor    West African Cotton Company        Memory Virtual CRITICAL: Free Memory 9.97% (thresh 10:) 
10.197.1.13





SR #  	1-344662210
/sapstage  file system	--->  400 GB space 
svld1srv0 - 10.6.1.20  new LV with LD1 lv name	A0EASG014XVM010
sdj 500 GB disk

/dev/mapper/tempvg-LD1

mount -t ext4 /dev/mapper/tempvg-LD1 /LD1

lvrename /dev/tempvg/LD1 /dev/tempvg/upgrade


/dev/mapper/vg_data-lv_db



svjd1srv0 10.6.1.12	A0EASG014XVM003
add a disk of 100GB and extend /dev/mapper/vg_app-lv_usrsap
[root@svjd1srv0 ibmrmalik]# df -h /dev/mapper/vg_app-lv_usrsap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                       55G   42G   11G  80% /usr/sap

[root@svjd1srv0 ibmrmalik]# df -h /dev/mapper/vg_app-lv_usrsap
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                      154G   42G  105G  29% /usr/sap


svfd1srv0 10.6.1.24 	A0EASG012XVM003	win2k12
add a disk of 100GB and extend the partition DATA (E:) or new partion  

9:26:38 AM: i will add this to SR 

9:30:40 AM: create new LV with 400 




1-345421321    1-Critical    IBM AMM Infrastructure    Summary: Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable
146.89.142.30

--------------------------------------------------------------------------------------------------------------------

3 Dec


10.70.110.71	10.6.2.71	AGESVEQMHSRV1 	10.6.2.71	10.70.110.71 	30641
TRIO 9    1-345504631    Incident    2    AGE    12/2/2018    N/A    P2 : Cannot connect to HANA public IP
agesveqmhsrv1




1-344897891
Free_disk_space_is_less_than_10%_on_volume_/hana/shared
10.198.0.207 	sev2
root@clderpdtbd1 shared]# find . -xdev -type f -size +1000000
./ED1/exe/linuxx86_64/HDB_1.00.097.03.1443520413_2401334/libhdbcs.so
./ED1/exe/linuxx86_64/HDB_1.00.097.03.1443520413_2401334/libhdbcsapi.so
./ED1/exe/linuxx86_64/HDB_1.00.122.13.1507793622_4101635/libhdbcs.so
./ED1/exe/linuxx86_64/HDB_1.00.122.13.1507793622_4101635/libhdbrskernel.so
./ED1/HDB00/clderpdtbd1/trace/backint.log
./ED1/HDB00/clderpdtbd1/trace/old_traces/sqltrace_clderpdtbd1_30003_000.py
./ED1/HDB00/clderpdtbd1/trace/sqltrace_clderpdtbd1_30003_000.py
./ED1/HDB00/backup/data/COMPLETE_DATA_BACKUP_databackup_3_1
./ED1/hdbstudio_update/HANA_STUDIO_ED1.tgz
./SAP_HANA_DATABASE/server/BIN.TGZ




1-345508541    2-Urgent    CONTROLADORA DE NEGOCIOS    Summary: Processor_load_is_too_high_on_cidrh03.imzcloud.ibmammsap.local 
 10.68.211.10



1-345052031	sev2
Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.local[
10.198.0.213 



1-345533441    1-Critical    Manchester City Airport Group - SAP HEC-AMM
cleared cache for app restart




1-345444961
Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.loca
10.198.0.208



1-345444971
ack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local
10.198.0.208



1-345481981
Lack_of_free_swap_space_on_LBDPQ1App00.imzcloud.ibmammsap.local[
10.8.8.53 

[root@LBDPQ1App00 ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:            31         15         15          0          0          1
-/+ buffers/cache:         13         18
Swap:            7          1          6



1-345494681
Lack_of_free_swap_space_on_LBDBOQQASApp1.imzcloud.ibmammsap.local[
10.8.8.57 




1-342699151
Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.8.8.73 



1-342931231
Free_disk_space_is_less_than_20%_on_OS_volume_/[
10.8.8.111 
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000004.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000010.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000008.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000025.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000020.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000013.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000012.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000002.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000006.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000016.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000017.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000007.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000003.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000011.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000021.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000005.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000014.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000022.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000023.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000015.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000018.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000009.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000000.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000024.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000019.dat
./sapmnt/log/mnt00001/hdb00002.00003/logsegment_000_00000001.dat
./sapmnt/log/mnt00001/hdb00002.00004/logsegment_000_00000002.dat
./sapmnt/log/mnt00001/hdb00002.00004/logsegment_000_00000006.dat
./sapmnt/log/mnt00001/hdb00002.00004/logsegment_000_00000005.dat
./sapmnt/log/mnt00001/hdb00002.00004/logsegment_000_00000000.dat
./sapmnt/log/mnt00001/hdb00002.00004/logsegment_000_00000001.dat




NC6463931    Dixons Carphone    Memory Virtual CRITICAL: Free Memory 9.77% (thresh 10:    Sev 3
Memory Virtual CRITICAL: Free Memory 9.77% 
10.197.5.12 



1-345529780	sev3	
P2: SFTP Folder for East West in Production (64297/2018)
Hi IBM,
 
Please create the following sub-folders at /usr/sap/sftp/EWBC/CREDIT in
EPP.
10.6.3.12

- Archive_Billing_File
- Archive_Response
- Intermediate_BillingFile




1-345540041    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_tor01ammsol02.imzcloud.ibmammsap.local 
 146.89.141.93

------------------------------------------------------------------------------------------------------------------------------------

4 Dec


INC6469236    West African Cotton Company    P2 - Major    Ping Availability CRITICAL - AFRS4HQADB: rta nan, lost 100%
10.197.1.11 



INC6469234    West African Cotton Company    P2 - Major    Ping Availability CRITICAL - AFRFIORIQA: rta nan, lost 100%
10.197.1.15 


INC6469231    Dixons Carphone    P2 - Major    Ping Availability CRITICAL - dcghanaprdap1: rta nan, lost 100%
 10.197.5.14 



INC6469229    West African Cotton Company    P2 - Major    Ping Availability CRITICAL - AFRS4HDEVDB: rta nan, lost 100%
10.197.1.13



1-345595761 - Sev1 - CON - IC4SAP-SL - Siebel Ticket - Not Validated - Summary: Zabbix_agent_on_conspeccdbq.imzcloud.ibmammsap.local_is_unavailable
10.16.1.36



1-345541034    SMRT Corp - SAP HEC-AMM    3-Standard    P2 : cronjob UXSCR_STRIDES_PRD.SH issue
Kindly check whether the cronjob with the script  UXSCR_STRIDES_PRD.SH
executed since Friday i.e 30.Nov.2018 or not.
 
Also, provide the number of the times this script exected since Friday
and if failed to run then provide the reasons.
 
Run manually if it didn't execute from Friday and update us the output.
 



SNG
Soruce :- Server
Hostname: ptpbromo 	 	10.70.31.16	


Destination :- client

Hostname: ptpkelimutu3
IP:10.70.31.15

Mount Point name : /Hana_Backup

vgcreate Hana_Backup /dev/sdj (PV)
lvcreate -L 3072G -n HANA_Backup Hana_Backup
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab

/dev/Hana_Backup/HANA_Backup

/dev/mapper/VG_temp-1TB_Disk_lv


192.168.166.12:/idocs/dev /idocs nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0


192.168.166.12:/Hana_Backup  /Hana_Backup  nfs rw,hard,intr,rsize=32768,wsize=32768    0       0




1-345599921 - Sev1 -IBM AMM Infrastructure - Siebel Ticket - Not Validated -  Zabbix_agent_on_wdc04ammsol01.imzcloud.ibmammsap.local_is_unavailable[





add 2 GB space to /usr/sap/TM1 for  1-345594311
added space to Lv




146.89.140.28	A0CXUS014XVM006		1-345596611	sev2
[root@dal09ammsrtr2 saprouter]# df -h .
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                  196G  186G   17M 100% /usr/sap



1-345455351
Free_disk_space_is_less_than_10%_on_OS_volume_/var
10.73.10.15





IA1FTSPRDAPP 	10.133.15.24   LOn02  IAG GBS Limited (IA1)  ia1

ia1_production



./bootstrap_v12.sh -o ORG -n IA1FTSPRDAPP -l -d imzcloud.ibmammsap.local -t osonly -e ia1_production 

IA1FTSPRDAPP.imzcloud.ibmammsap.local


----------------------------------------------------------------------------------------------------------------------

5 Dec


1-345634891    ETRO SPA (ETO)    1-Critical    Summary: Zabbix_agent_on_ECCDAS00.imzcloud.ibmammsap.local_is_unavailable[
 10.5.2.11



1-345494201	sev2	10.8.8.184 
Ruuning_out_of_available_memory_on_server_LBDBIPPRDApp2.imzcloud.ibmammsap.local[




1-345637631    Suncor Energy Inc. (SNC)    2-Urgent 
Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.loca



1-345495301	sev2	10.133.18.172 
Free_disk_space_is_less_than_10%_on_volume_/sapmnt/log
[root@MGGGBJVECCX02 ~]# df -h /sapmnt/log
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdd1       1.5T  831G  659G  56% /sapmnt/log




1-345520791	sev2 	10.8.8.91 
Ruuning_out_of_available_memory_on_server_LBDWP5App80.imzcloud.ibmammsap.local




1-345533541	sev2	10.133.18.26 
Free_disk_space_is_less_than_10%_on_volume_/interface/EGP
[root@MGGGBJPGTSX01 ~]# df -h /interface/EGP
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/egpappvg-egpIntface_lv
                       70G   20G   47G  30% /interface/EGP






1-345567001	sev2	10.198.0.209
Processor_load_is_too_high_on_CLDBOBIADWD1.imzcloud.ibmammsap.local[



1-345639391 Suncor Energy Inc. (SNC) p2
Lack_of_free_swap_space_on_snchbdwpw51.imzcloud.ibmammsap.local[
10.73.10.116



Amcor Rigid Plastics USA, Inc.
monhdbsrv01   10.10.0.21


1-345640141    ETRO SPA (ETO)    1-Critical	
Zabbix_agent_on_ECCQAS00.imzcloud.ibmammsap.local_is_unavailable



1-345643261    ETRO SPA (ETO)    1-Critical 
ECCQAS00.imzcloud.ibmammsap.local_has_just_been_restarted
 10.5.2.12





1-345541034
P2 : cronjob UXSCR_STRIDES_PRD.SH issue(632783/2018)	3rd dec

Kindly check whether the cronjob with the script  UXSCR_STRIDES_PRD.SH	 /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh
executed since Friday i.e 30.Nov.2018 or not.

cat /var/log/cron |grep  /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh

[postman@CLDERPAPPP1 ~]$ crontab -l |grep -i UXSCR_STRIDES_PRD.SH
0 10,13,16,19 * * * /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1
40 21 * * * /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1

HQDSFTPAPPP1 [172.19.1.76]
 
Also, provide the number of the times this script exected since Friday
and if failed to run then provide the reasons.
 
Run manually if it didn't execute from Friday and update us the output.

This is in EP1 system 
 
IP : 10.168.1.71	10.198.0.71
Hostname : CLDERPAPPP1


[root@CLDERPAPPP1 log]# cat /var/log/cron.6.gz |zgrep  /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh
Nov 29 10:00:02 CLDERPAPPP1 CROND[51003]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 29 13:00:02 CLDERPAPPP1 CROND[16971]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 29 16:00:02 CLDERPAPPP1 CROND[47410]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 29 19:00:02 CLDERPAPPP1 CROND[11845]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 29 21:40:01 CLDERPAPPP1 CROND[37252]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)


[root@CLDERPAPPP1 log]# cat /var/log/cron.5.gz |zgrep  /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh
Nov 30 10:00:01 CLDERPAPPP1 CROND[32875]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 30 13:00:02 CLDERPAPPP1 CROND[64580]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 30 16:00:01 CLDERPAPPP1 CROND[30351]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 30 19:00:02 CLDERPAPPP1 CROND[59387]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Nov 30 21:40:01 CLDERPAPPP1 CROND[19406]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)

[root@CLDERPAPPP1 log]# cat /var/log/cron.4.gz |zgrep  /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh
Dec  1 10:00:02 CLDERPAPPP1 CROND[14735]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  1 13:00:02 CLDERPAPPP1 CROND[45065]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  1 16:00:02 CLDERPAPPP1 CROND[10606]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  1 19:00:02 CLDERPAPPP1 CROND[39363]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  1 21:40:01 CLDERPAPPP1 CROND[64357]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)

[root@CLDERPAPPP1 log]# cat /var/log/cron.3.gz |zgrep  /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh
Dec  2 10:00:02 CLDERPAPPP1 CROND[52245]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  2 13:00:01 CLDERPAPPP1 CROND[60009]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  2 16:00:02 CLDERPAPPP1 CROND[24610]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  2 19:00:01 CLDERPAPPP1 CROND[53474]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  2 21:40:01 CLDERPAPPP1 CROND[13423]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)

[root@CLDERPAPPP1 log]# cat /var/log/cron.2.gz |zgrep  /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh
Dec  3 10:00:02 CLDERPAPPP1 CROND[9393]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  3 13:00:02 CLDERPAPPP1 CROND[39961]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  3 16:00:01 CLDERPAPPP1 CROND[5266]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  3 19:00:01 CLDERPAPPP1 CROND[34380]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  3 21:40:01 CLDERPAPPP1 CROND[59302]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)

[root@CLDERPAPPP1 log]# cat /var/log/cron.1.gz |zgrep  /home/postman/tibsscript/UXSCR_STRIDES_PRD.sh
Dec  4 10:00:01 CLDERPAPPP1 CROND[56131]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  4 13:00:02 CLDERPAPPP1 CROND[22265]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  4 16:00:01 CLDERPAPPP1 CROND[52618]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  4 19:00:03 CLDERPAPPP1 CROND[16496]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)
Dec  4 21:40:02 CLDERPAPPP1 CROND[41627]: (postman) CMD (/home/postman/tibsscript/UXSCR_STRIDES_PRD.sh > /home/postman/tibsscript/UXSCR_STRIDES_PRD.log 2>&1)



1-345632411	sev2	10.8.8.20 
Free_disk_space_is_less_than_10%_on_OS_volume_/home
[root@LBDMQ1App00 home]# du -a . |sort -n -r |head -n 15
20280   .
14916   ./mq1adm
8796    ./mq1adm/R3trans
3792    ./mq1adm/R3trans_619-10011224.SAR
792     ./mq1adm/.vnc
712     ./ibmmsharma
668     ./ibmmsharma/lib_dbsl_611-70000607.sar
604     ./ibmyespinoza
268     ./mq1adm/.vnc/LBDMQ1App00:15.log
268     ./mq1adm/.vnc/LBDMQ1App00:12.log
232     ./dabadm
220     ./daaadm
188     ./dacadm
152     ./mq1adm/.pulse
144     ./mq1adm/.gconf




1-345646471	sev3
password for "ssfadm" on hanadb host cpwHANAsolmDB

----------------------------------------------------------------------------------------------------------------------

6 Dec


1-345699921    1-Critical    American Airlines SAP HEC-AMM --- 
[root@a1axd2pi01 ibmrmalik]# df -h /usr/sap/XD2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/xd2appvg-xd2usrXD2_lv
                       30G   29G     0 100% /usr/sap/XD2



1-345703951    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Processor_load_is_too_high_on_snchgraqa12.imzcloud.ibmammsap.local
 10.73.12.36



1-345703961    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
 10.73.10.45




1-340226225





1-345678621	10.198.0.211	sev2
Processor_load_is_too_high_on_CLDERPAPPQ1.imzcloud.ibmammsap.local




1-345699751	sev2	10.4.10.67
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/XD2



1-345694661	sev2	10.4.10.51
Free_disk_space_is_less_than_10%_on_volume_/interface/PQ2



1-345684811	sev2	10.4.10.14
Lack_of_free_swap_space_on_AHPOSSAP01.imzcloud.ibmammsap.local



1-345697931	sev2	10.8.8.77 
Lack_of_free_swap_space_on_LBDBP1App00.imzcloud.ibmammsap.local



1-345697511	sev2	10.8.8.64 
Processor_load_is_too_high_on_LBDSP1App01.imzcloud.ibmammsap.local[



1-345698101	sev2	10.138.10.30 
Processor_load_is_too_high_on_br3dsapa50.imzcloud.ibmammsap.local[




1-345690161	sev2	10.210.1.15
Processor_load_is_too_high_on_CI3S4HANADEV.imzcloud.ibmammsap.local




1-344915191	sev3   DYSFTPDAPRD01 was down
Case 70326049 has been successfully created.




1-345669227    Rexel Holdings (HGM) SAP HEC-AMM    3-Standard    P3: Add disk space on REXPCGSSQL1 : (0639277/2018)
 	10.135.1.65	 could you please add 100 more Gb to drive F on REXPCGSSQL1 server ?
A0CVDE012XVM001



1-344381779	sev2
dyss4apsbq21    10.6.12.34 , DF is hung on this server , Backup missing for several days. Please fix NFS mounts.




1-345710671    2-Urgent    Raycap GmbH (RYC)    Summary: Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.loca
 10.7.64.14




take snapshot

SR # 1-345257529 - JD1 - svjd1srv0	A0EASG014XVM003	
SR # 1-345257570 - FD1 - svfd1srv0	A0EASG012XVM003
ED1/RD1 - sved1srv0	A0EASG014XVM002

--------------------------------------------------------------------------------------------------------------

7 Dec


1-345722077    St Jude Medical Singapore - SAP HEC    3-Standard    P3:root user not working in Development SFT(0642168/2018) 



1-345743041
Destination
SID    Hostname    CFN IP Address     IFN IP Address
PD2    A1AERPPD2AP01    10.100.2.56    10.4.10.58

temp ip
10.4.10.199




1-345762513	sev3
Can you please create a /Hana_backup og 3TB





1-345767911    Suncor Energy Inc. (SNC)    2-Urgent    Summary: Free_disk_space_is_less_than_10%_on_OS_volume_/var
 10.73.10.16




1-345768011    Raycap GmbH (RYC)    2-Urgent    Summary: Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local


1-345770701- P1 -IBM MSD Infras - Cloud APPS-portal-not validated- "Summary: Zabbix_agent_on_dal09ammsol01.imzcloud.ibmammsap.local_is_ --
146.89.140.30




1-345717831    SR Technics Switzerland Ltd. (SRT)    3-Standard    Modify the /etc/hosts for new system go live
Action needed:
- save  the local /etc/hosts file for failback reason 
- change these IP's in the /etc/hosts file

old: 10.210.113.92  chbbssrt013.zrh.srtechnics.com chbbssrt013 
new: 10.96.20.22  chbbssrt013.zrh.srtechnics.com chbbssrt013 

old: 10.210.113.94  chbbssrt015.zrh.srtechnics.com chbbssrt015
new: 10.96.20.24 chbbssrt015.zrh.srtechnics.com chbbssrt015

old: 10.210.113.89 chbbcsrt030.zrh.srtechnics.com chbbssrt030
new: 10.96.20.25 chbbcsrt030.zrh.srtechnics.com chbbssrt030

risk: low ; /etc/hosts can be copied back in case of problems 
failback: copy the saved /etc/hosts back




1-345769341    AGEAS - SAP HEC-AMM    2-Urgent    Summary: SVMD1SRV0_has_just_been_restarted
 10.6.1.34
win



1-345541034
P2 : cronjob UXSCR_STRIDES_PRD.SH issue(632783/2018)
CLDERPAPPP1	10.198.0.71
UXSCR_STRIDES_PRD.SH
executed since Friday i.e 30.Nov.2018 or not.

------------------------------------------------------------------------------------------------------------------

10 Dec

1-345896621    2-Urgent    IBM AMM Infrastructure    Summary: Processor_load_is_too_high_on_dal13ammsol04.imzcloud.ibmammsap.local 
146.89.142.207



 1-345904403
svfs1srv0 - pls reset FS1ADM user



1-345909541 - Sev1 -  AGEAS - SAP HEC-AMM  - siebel - Not Validated - Dataserver_process_is_not_running




SMRT issue
2018-12-10 17:54:18 sftp _rfidwmssftpp2@hqdsftpappp1
  439  2018-12-10 17:55:14 sftp egdsftpuser@hqdsftpappp1
  440  2018-12-10 17:56:15 sftp hqis2_sap2@hqsftp1
  441  2018-12-10 17:57:15 sftp wmsftpuser@hqdsftpappp1



1-345793781   sev2	10.4.10.67 
Free_disk_space_is_less_than_10%_on_OS_volume_/tmp[




1-345833631	10.198.0.208   sev2
Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local[




1-345909191	sev3	10.4.1.179
NTP_time_is_driffted_on_DALTFSBOA0005.imzcloud.ibmammsap.local



1-345881021
Processor_load_is_too_high_on_PHSBWDEV01
 10.5.6.20 win 
-------------------------------------------------------------------------------------------------------------------------------

11 Dec

1-345949571    SAP09    1-Critical    City Football Group - SAP HEC-AMM    CF9
Zabbix_agent_on_a0b4uk013cfgvyatta001_is_unavailabl	

1-345949421    SAP09    1-Critical    ETRO SPA (ETO)    ETO
Zabbix_agent_on_a0b4uk013etrovyatta002_is_unavailable

1-345950551    SAP10    1-Critical    American Airlines SAP HEC-AMM    A1A
Free_disk_space_is_less_than_5%_on_OS_volume_/tmp
 10.4.10.67


Ticket : 1-345893981

Description : 
smgwuatuq3      10.78.26.11 , One of file systems in this server is missing - Causing backup failure. Please check

[root@smgwuatuq3 bin]# df -h
df: `/migrations/DQ1_ARCHIVE': No such file or directory  
MMGRAS, 10.78.22.12 ,





1-345951721    SAP09    3-Standard    LSPI (LSP)    LSP (Please exeute the step at LZAMOBDEV0) 
Please exeute the step at LZAMOBDEV0






Hrrost_out.sh
[postman@CLDERPAPPP1 HR]$ ls -ltr hrrost_out.sh
-rwxr-x---. 1 postman sapsys 304 Aug 16  2016 hrrost_out.sh

[root@CLDERPAPPP1 HR]# crontab -l -u postman |grep hrrost_out.sh
35 17 * * * /home/postman/HR/hrrost_out.sh > /home/postman/HR/hrrost_out.log 2>&1

[postman@CLDERPAPPP1 HR]$ cat hrrost_out.sh |grep -i sftp
sftp ODB2 << EOF


Hrdsbus_in.sh
[postman@CLDERPAPPP1 HR]$ ls -ltr hrdsbus_in.sh
-rwxr-x---. 1 postman sapsys 713 Aug 16  2016 hrdsbus_in.sh

[root@CLDERPAPPP1 HR]# crontab -l -u postman |grep hrdsbus_in.sh
#00 08 16 * * /home/postman/HR/hrdsbus_in.sh > /home/postman/HR/hrdsbus_in.log 2>&1
00 13 * * * /home/postman/HR/hrdsbus_in.sh > /home/postman/HR/hrdsbus_in.log 2>&1

[postman@CLDERPAPPP1 HR]$ cat hrdsbus_in.sh |grep -i sftp
sftp odb2 << EOF >> $log
sftp odb2 << EOF >> $log


Hrempm_out.sh
[postman@CLDERPAPPP1 HR]$ ls -ltr hrempm_out.sh
-rwxr-x---. 1 postman sapsys 586 Aug  6  2016 hrempm_out.sh

[root@CLDERPAPPP1 HR]# crontab -l -u postman |grep hrempm_out.sh
12 2 * * * /home/postman/HR/hrempm_out.sh > /home/postman/HR/hrempm_out.log 2>&1

[postman@CLDERPAPPP1 HR]$ cat hrempm_out.sh |grep -i sftp
# SFTP File
sftp ODB2 << EOF

hrempd_out.sh
[postman@CLDERPAPPP1 HR]$ ls -ltr hrempd_out.sh
-rwxr-x---. 1 postman sapsys 597 Aug  6  2016 hrempd_out.sh

[root@CLDERPAPPP1 HR]# crontab -l -u postman |grep hrempd_out.sh
12 2 * * * /home/postman/HR/hrempd_out.sh > /home/postman/HR/hrempd_out.log 2>&1

[postman@CLDERPAPPP1 HR]$ cat hrempd_out.sh |grep -i sftp
# SFTP File
sftp ODB2 << EOF


hrlevh_out.sh
[postman@CLDERPAPPP1 HR]$ ls -ltr hrlevh_out.sh
-rwxr-x---. 1 postman sapsys 224 Aug  6  2016 hrlevh_out.sh

[postman@CLDERPAPPP1 HR]$ cat hrlevh_out.sh |grep -i sftp
sftp ODB2 << EOF

[root@CLDERPAPPP1 HR]# crontab -l -u postman |grep hrlevh_out.sh
00 13 * * * /home/postman/HR/hrlevh_out.sh > /home/postman/HR/hrlevh_out.log 2>&1


hrlevd_out.sh
[postman@CLDERPAPPP1 HR]$ ls -ltr hrlevd_out.sh
-rwxr-x---. 1 postman sapsys 224 Aug  6  2016 hrlevd_out.sh

[postman@CLDERPAPPP1 HR]$ cat hrlevd_out.sh |grep -i sftp
sftp ODB2 << EOF

[root@CLDERPAPPP1 HR]# crontab -l -u postman |grep hrlevd_out.sh
00 13 * * * /home/postman/HR/hrlevd_out.sh > /home/postman/HR/hrlevd_out.log 2>&1

hrobjt_out.sh
[postman@CLDERPAPPP1 HR]$ cat hrobjt_out.sh |grep -i sftp
sftp ODB2 << EOF
hi Deepdhree
[postman@CLDERPAPPP1 HR]$ ls -ltr hrobjt_out.sh
-rwxr-x---. 1 postman sapsys 225 Aug  6  2016 hrobjt_out.sh


hrorgu_out.sh
[postman@CLDERPAPPP1 HR]$ cat hrorgu_out.sh |grep -i sftp
sftp ODB2 << EOF



hrusrid_out.sh
[postman@CLDERPAPPP1 HR]$ cat hrusrid_out.sh |grep -i sftp
echo 'sftp ODB2 << EOF' >> ftpusrid.sh

hrempcard_out.sh
[postman@CLDERPAPPP1 HR]$ cat hrempcard_out.sh |grep -i sftp
echo '#!/bin/ksh' > sftpempcard.sh
echo 'sftp ODB2 << EOF' >> sftpempcard.sh
echo "cd /usr04/SAP/sap_to_hr/hqdb2" >> sftpempcard.sh
echo "lcd /usr/interfaces/hr/outbound/empcard/working" >> sftpempcard.sh
echo "mput HREMPCARD_$suffix*.txt" >> sftpempcard.sh
echo "bye" >> sftpempcard.sh
echo "EOF" >> sftpempcard.sh
#echo "sftp cas_sap2@hqsftp1 << EOF" >> sftpempcard.sh
#echo "cd /systems/prd_cas/hrmapping" >> sftpempcard.sh
#echo "lcd /usr/interfaces/hr/outbound/empcard/working" >> sftpempcard.sh
#echo "mput *" >> sftpempcard.sh
#echo "bye" >> sftpempcard.sh
#echo "EOF" >> sftpempcard.sh
echo "mv /usr/interfaces/hr/outbound/empcard/working/HREMPCARD_$suffix*.txt /usr/interfaces/hr/outbound/empcard/archive" >> sftpempcard.sh
chmod 774 sftpempcard.sh
./sftpempcard.sh > sftpempcard.log



---------------------------------------------------------------------------------------------

12 Dec


1-344439742	St Jude Medical Singapore - SAP HEC



1-346065171    Tecnologia De Materiales S.A.  2-Urgent
: Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.loca
10.4.20.31




1-346065001    CI3 Certified IT Consultants for TMG (CICTMG)    2-Urgent
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/PRD



P3 - INC6559280 sev2
CPU CPU-Utilization CRITICAL: CPU Usage 100% (threshold=95) user=0.00% system=0.00% iowait=0.00% idle=0.00%



---------------------------------------------------------------------------------------------------------------------------------------
15 Dec


PHSBWPRD01 	10.5.6.6	10.25.6.40

London	 146.89.140.104 





1-346234461    2-Urgent    Meggitt Plc (MGG)    Summary: Processor_load_is_too_high_on_MGGGBJQECCY01.imzcloud.ibmammsap.local 
10.133.18.181



INC6590328    P3 - Minor    Dixons Carphone        NTP_time_is_driffted_on_DCGPFEAPP12.imzcloud.ibmammsap.local 
10.197.5.21 




1-345853450 >> VM snapshot >> Ravi Malik (OS)
Host name	IFN IP	                  Snapshot time
MG2ERPPRDAPP	SNG	10.198.3.12               15/12/2018 9.30 PM IST  (15/12/2018 08.00 AM PST) to 15/12/2018 10.30 PM IST  (15/12/2018 09.00 AM PST)-----> App host
MG2ERPPRDDB	SNG	10.198.3.11               15/12/2018 9.30 PM IST  (15/12/2018 08.00 AM PST) to 15/12/2018 10.30 PM IST  (15/12/2018 09.00 AM PST)-----> DB host	sng01ammhana005.xsportal.local 	10.116.103.221	root/SMiSrl3c6B@   or ibmvmadmin/ExeJS43j9yeM


MG2ERPPRDDBDR    10.204.3.10              15/12/2018 9.30 PM IST  (15/12/2018 08.00 AM PST) to 15/12/2018 10.30 PM IST  (15/12/2018 09.00 AM PST)-----> DR DB host
bond0     Link encap:Ethernet  HWaddr 00:0C:29:9E:CF:81
          inet addr:10.110.135.55  Bcast:10.110.135.63  Mask:255.255.255.192

eth1      Link encap:Ethernet  HWaddr 00:0C:29:9E:CF:6D
          inet addr:10.204.3.10  Bcast:10.204.3.255  Mask:255.255.255.0






1-346225441
top - 15:49:29 up 10 days, 23:16,  1 user,  load average: 5.47, 5.48, 5.47
Tasks: 340 total,   2 running, 338 sleeping,   0 stopped,   0 zombie
Cpu(s):  9.5%us, 16.1%sy,  0.0%ni, 74.4%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    23.451G total,   14.103G used, 9572.910M free,  950.805M buffers
Swap:   47.996G total,    0.000k used,   47.996G free, 5854.988M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  9144 root      20   0 27364 4916 2060 R 99.9  0.0 233:07.21 saposcol




1-346222091 	sev2
IBM AMM Infrastructure Free_disk_space_is_less_than_10%_on_volume_/usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/tm1appvg-usrsapdaa_lv
                      4.0G  3.6G  228M  95% /usr/sap/DAA




1-344701327	630PM IST today	 Apply latest Q418 bundle  patches on RH Linux OS Ver 5.x/6.x
IPLSASMAP01	10.11.1.29	Non-Production
IPLSASMAP02	10.11.1.30	Non-Production
10.11.1.29:/usr/sap/trans /usr/sap/trans nfs rw,hard,intr,rsize=32768,wsize=32768 0 0
IPLSATXAP01	10.11.1.32	Non-Production




1-346072920 ( Unable to login to snchecapa11 & snchecapa12 ) 


INC6591627        West African Cotton Company    P4 - Minimal    Ping Availability OK - AFRS4HDEV: rta 156.069ms, lost 0%
INC6591616        Dixons Carphone    P4 - Minimal    Ping Availability OK - 10.197.5.14: rta 155.568ms, lost 0%
INC6590709        West African Cotton Company    P3 - Minor    NTP_time_is_driffted_on_AFRSH4PRD.imzcloud.ibmammsap.local[PROBLEM:10099503]





./root/bootstrap_v12.sh -o snc -n snchecapa11 -l -d imzcloud.ibmammsap.local -t osonly -e snc_production




1-346166694	sev3 change
PP1 :

Change the Timezone to HKT on below servers

LBDPP1APP00     10.8.8.83
LBDPP1APP01     10.8.8.84
LBDPP1DB02       10.8.8.82

[root@LBDPP1App00 etc]# date
Sat Dec 15 19:16:33 HKT 2018


[root@LBDPP1App01 etc]# date
Sat Dec 15 19:17:48 HKT 2018
 

[root@LBDPP1DB02 etc]# date
Sat Dec 15 19:18:39 HKT 2018



1-346240661- P1 - Limited Brands, Inc. - SAP HEC-AMM-portal-not validated- "Summary: Zabbix_agent_on_lbdcp1app02.imzcloud.ibm
10.8.8.250



1-346242691 Limited Brands, Inc. - SAP HEC-AMM 1-Critical- (clearing event received)-Summary: Zabbix_agent_on_lbdcp1app02.imzcloud.ibmammsap.local_is_unavailable



----------------------------------------------------------------------------------------------------------------------------------

16 Dec


1-346238281	sev2 
Processor_load_is_too_high_on_MGGGBJPECCX03.imzcloud.ibmammsap.local
10.133.18.20



1-346264381    2-Urgent    Suncor Energy Inc. (SNC)    Summary: Ruuning_out_of_available_memory_on_server_snchtripa11.imzcloud.ibmammsap.loca
 10.73.10.125



1-345912431	sev3 	change for snapshot
PSPRDASJAVA / 10.197.2.42  snapshot
PSPRDASJAVA 	10.197.2.42	172.31.10.42 LOn02	A0FTUK014XVM007



1-346214801 ( P3-Please upload the attached file ) sev-3
Server details are not mentioned in ticket. Mail has been sent to PDL to get details.
Please upload the attached files to 
/infa_sftp/infaprd/concur/inbound/
FBTPRDHANAPP1 	10.4.27.13	192.168.167.13 	






1-346097170	sev2		

Please assist create new keystore for SMARTRoom in OD1 (10.168.1.201)
and OQ1 (10.168.1.217).
OD1 / CLDPROAPDD1 / 10.198.0.201
OQ1 / CLDPROAPDT1 / 10.198.0.217	instead of postman use OQ1adm
 
 
FTP Server: CLDSFTPSVRP1
IP Address: 172.31.10.20
 
sFTP Account Name: _rbssapsftpd1
Password: @rbss@psftpd1
 
Keystore: SFTP_rbssapsftpd1
Keystore Entry: sftp_keystore_rbssapsftpd1


CLDPROAPDT1:oq1adm 52> pwd
/home/oq1adm
CLDPROAPDT1:oq1adm 53> sftp _rbssapsftpd1@172.31.10.20
Connecting to 172.31.10.20...
sftp>



[postman@cldproapdd1 ~]$ pwd
/home/postman
[postman@cldproapdd1 ~]$  sftp _rbssapsftpd1@172.31.10.20
Connecting to 172.31.10.20...
sftp>





INC6586159	Processor_load_is_too_high_on_IPLSAUTLD01	10.138.2.28 	Win	sev2


INC6598408 	Processor_load_is_too_high_on_MS3WDCWADB16	sev2


1-346265041- P2 - Panasonic Europe Ltd (PEU)- "Summary: Free_disk_space_is_less_than_10%_on_volume_/var/log
 100.126.65.15

INC6600364        Dixons Carphone    P3 - Minor    System NTP Drift CRITICAL: ERROR - server 146.89.140.76, stratum 0, offset 0.000000, delay 0.00000 16 Dec 11:09:42 ntpdate[8105]: no server suitable for synchro



INC6601303        MSC Industrial Supply Co.    P3 - Minor    Processor_load_is_too_high_on_MS3WDCWADB16
10.12.6.32


-------------------------------------------------------------------------------------------------------------------------------

18 Dec

INC6614474	sev3
Processor_load_is_too_high_on_PTPRINJANI[PROBLEM:1014101



INC6619318
pw reset
ser - fs1adm
server: svfs1srv0 (10.6.1.145) - Windows


1-345641713	change via BIg fix	PT Anugerah Pharmindo Lestari (PTP)	Sev3
PTPSEMERU	10.70.30.142	SNG	
PTPTOBA1	10.70.30.147	SNG

Password file :
https://apps.na.collabserv.com/docs/app/doc/lcfiles/c5c2304b-4d38-4c47-af2e-fd5366080403/edit/content


--------------------------------------------------------------------------------------------------------------------

19 Dec


INC6623296 - SL-Singapore-01 - PT Anugerah Pharmindo Lestari (PTP) - IC4SAP-SL - Server PTPSEMERU 10.70.30.142 is not booting after a reboot





1-346411061    SAP07    2-Urgent    Raycap GmbH (RYC)    RYC
Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.loca
10.7.64.14



10.121.75.9/root/5kXa3T1As1@




INC6629143    Tecnologia De Materiales S.A.    P2 - Major    Lack_of_free_swap_space_on_TDMprdecc.imzcloud.ibmammsap.local


------------------------------------------------------------------------------------------------------------------------------------


20 Dec


INC6639352

Please help to configure the sftp keys on CLDPROAPPP1 ( OP1 )  (OP1)CLDPROAPPP1- 10.198.0.75 
 
Keystore            = SFTP_WMS_NEW
Keystore Entry = sftp_keystore_wms_new
 
SFTP server: HQDSFTPAPPP1
Username    : wmsftpuser






INC6636074 
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/QR1




, INC6636064 and INC6636043 





[root@sjmqfpaa01 ibmrmalik]# chage -l root
Last password change                                    : Jul 30, 2018
Password expires                                        : Oct 28, 2018
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 1
Maximum number of days between password change          : 90
Number of days of warning before password expires       : 7





SR0013528
SUNCOR :  Extend disk space for snchecada11
snchecada11   10.73.11.99
DFS : /usr/sap/DR1   Extend by 75GB

[root@snchecada11 ibmrmalik]# df -h /usr/sap/DR1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/dr1appvg-dr1usrDR1_lv
                      392G  272G  101G  74% /usr/sap/DR1

-------------------------------------------------------------------------------------------------------------------------------------

23 Dec


HO INC6656962 - Reset root passwd
Zabbix_agent_on_consptms4hapd.imzcloud.ibmammsap.local_is_unavailable
10.16.1.22 	SL SaoPaulo
Mendez Mauricio [MHAS]
Work notesâ€¢23/12/2018 05:44:16
Hello Team, please assist with this request. Server is still unaccessible: consptms4hapd / IFN: 10.16.1.22 / CFN: 10.80.1.22 

If server restart is required please proceed and use this update as PDL approval. 
Please send me an email once the server is back up: mmendez@cr.ibm.com 

Thanks in advance.



INC6671279    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local
Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local[
10.73.10.44



INC6671260    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
10.73.10.45




INC6671502    P3 - Minor    MSC Industrial Supply Co.    FS_is_read_only_on_mdcserverp1.imzcloud.ibmammsap.local
CRITICAL | /run/user/54716
10.12.7.41 



INC6668946
Processor_load_is_too_high_on_SNCHCIIDA11
10.73.11.113


INC6671981    P2 - Major    Limited Brands Inc.    Lack_of_free_swap_space_on_LBDBD1App00.imzcloud.ibmammsap.local 
10.8.8.22 





add space in /usr/sap/SP1--->INC6670780	 169.60.136.225 



INC6672209    P3 - Minor    Bombardier Recreational Products In    FS_is_read_only_on_br3dhana50.imzcloud.ibmammsap.local  
CRITICAL | /run/user/1001
10.138.10.27 
br3dhana50:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /run/user/1001 filesystems are read-only
br3dhana50:/home/ibmrmalik # cd  /run/user/1001
bash: cd: /run/user/1001: No such file or directory

br3dhana50:/home/ibmrmalik # cd /run/user
br3dhana50:/run/user # ls -ltr
total 0
drwx------ 6 gdm         gdm          120 Oct 19 14:15 482
drwx------ 3 root        root          60 Nov  1 17:30 0
drwx------ 3 ibmjalpizar domain users  60 Nov 22 14:45 18009
drwx------ 3 ibmmkayal   domain users  60 Dec 23 00:00 82203
drwx------ 3 ibmrmalik   domain users  60 Dec 23 01:16 82584




INC6672379    P2 - Major    COTY Inc.    Ruuning_out_of_available_memory_on_server_ctuboqr2ap02.imzcloud.ibmammsap.local
10.12.10.92




INC6672689
dev/mapper/sp1appvg-sp1usrSP1_lv
                       49G   41G  5.0G  90% /usr/sap/SP1


[root@LBDSP1App00 SP1]# df -h .
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/sp1appvg-sp1usrSP1_lv
                       49G   41G  5.4G  89% /usr/sap/SP1




INC6672990    P2 - Major    St Jude Medical    Processor_load_is_too_high_on_juddtrans02.imzcloud.ibmammsap.local 
10.196.4.13 





1-346174923
login issue on PSPRDDB and unlocked 2 user accounts
-----------------------------------------------------------------------------------------------------------------------------


24 Dec


INC6679463 - Sev2 - IBM AMM Infrastructure - Service Now Ticket - Not Validated - ntpd_check_win 




INC6678325    P3 - Minor    Raycap GmbH    Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.7.64.12




INC6680065    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local
10.73.10.44



1-346471001
Zabbix_agent_on_PSQASDB.imzcloud.ibmammsap.local_is_unavailable





1-346474691	PSQASDB.imzcloud.ibmammsap.local_has_just_been_restarted
[root@PSQASDB ~]# egrep "reboot|down" /var/log/messages
Dec 21 05:54:57 PSQASDB kernel: IPv6: Loaded, but administratively disabled, reboot required to enable

[root@PSQASDB ~]# last reboot
reboot   system boot  2.6.32-573.el6.x Fri Dec 21 05:54 - 04:22 (2+22:27)
wtmp begins Tue Dec 18 08:16:50 2018

[root@PSQASDB ~]# last -x|grep boot
reboot   system boot  2.6.32-573.el6.x Fri Dec 21 05:54 - 04:23 (2+22:28)





SR0013713
Add new FS Mount points for Quality Upgrade - EQ1, RQ1, LQ1
LQ1 -  svlq1srv0 (10.6.2.19)	A0EASG014XVM023


RQ1 - SVEQ1SRV0 (10.6.2.11)	A0EASG014XVM001
/temprq1upg	-----> Mount 128 GB new FS	/dev/tempvg/temprq1upg_lv
/tempeq1upg	-----> Mount 250 GB new FS	/dev/tempvg/tempeq1upg_lv

sdg                                 8:96   0  384G  0 disk
â”œâ”€tempvg-temprq1upg_lv (dm-26)    253:26   0  129G  0 lvm
â””â”€tempvg-tempeq1upg_lv (dm-27)    253:27   0  253G  0 lvm

ext3

/dev/tempvg/temprq1upg_lv    /temprq1upg  ext3        defaults    1 2
/dev/tempvg/tempeq1upg_lv    /tempeq1upg  ext3        defaults    1 2


vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab

/dev/mapper/tempvg-temprq1upg_lv



INC6680590    P2    IBM AMM Infrastructure - Service Now Ticket - Not Validated -Lack_of_free_memory_on_server_AMMWDC04VCS01
Lack_of_free_memory_on_server_AMMWDC04VCS01
146.89.142.40



1-345642180
 CEM-AMM 3.x- Apply latest Q418 Patches on Linux Servers


INC6681236 sev2
Free_disk_space_is_less_than_20%_on_OS_volume_/var

-----------------------------------------------------------------------------------------------------------------------------

25 Dec


INC6688411	{Manchester Airport Group --> 10.69.0.35/LONMAGSPO0001}    P1-Severe - Assigned
IP1: Low free LOG space in database IP1: 4.97%

df -h hung
[root@LONMAGSPO0001 ibmrmalik]# cat /etc/fstab |grep -i /storage/library
146.89.140.30:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr 0       0

 

SR # INC6689344 

jD1 - svJd1srv0 Snapshot	A0EASG014XVM003
& jQ1 (svJq1srv0) FS extension
JQ1 - svjq1srv0	10.6.2.12	A0EASG014XVM004
/tempjq1upg	-----> Mount 100 GB new FS

ext3

vgcreate vg_NAME /dev/sdX (PV)	tempvg
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name	 tempjq1upg_lv 
mkfs.ext2/3/4 path of lvdisplay	/dev/tempvg/tempjq1upg_lv
mkdir /sybase
mount
vi /etc/fstab
/dev/tempvg/tempjq1upg_lv    /tempjq1upg  ext3        _netdev,defaults    1 2



1-346478581/Sev1/Arnoldo Mondadori Editore SpA  (ARM)/Siebel monitoring ticket not validated/Summary: Zabbix_agent_on_armfksap101.imzcloud.ibmammsap.local_is_unavailable
 10.7.103.21



1-346579221
Login issue with imz login





1-346180401/Sev1/Amcor Rigid Plastics USA, Inc./Siebel monitoring ticket not validated/Summary: Zabbix_agent_on_sapsybase1.imzcloud.ibmammsap.local_is_unavailable





1-346176171/Sev1/Amcor Rigid Plastics USA, Inc./Siebel monitoring ticket not validated/Summary: sapsybase1.imzcloud.ibmammsap.local_has_just_been_restarted
-----------------------------------------------------------------------------------------------------------------------------------

26 Dec


INC6697023    Suncor Energy Inc.    P2 - Major    Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local
10.73.10.44



INC6628359	SEV2
<TBO> Please tell us what scale of impact would be on the system performance while DB FULL backup is running.



1-346500781 	
Processor_load_is_too_high_on_LBDSP1App00.imzcloud.ibmamsap.local[
10.8.8.63



1-346500051
Processor_load_is_too_high_on_LBDSP1App01.imzcloud.ibmammsap.local
10.8.8.64



1-346502151
Processor_load_is_too_high_on_PSDEVAP.imzcloud.ibmammsap.local[
10.197.2.11



1-346579841
NTP_time_is_driffted_on_AHFIPSAP01.imzcloud.ibmammsap.local[
10.4.9.13 



1-346140291
Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local
10.198.0.208 





1-346149001
Lack_of_free_swap_space_on_DALTFSECCP001.imzcloud.ibmammsap.local
10.4.1.188




1-346266711
Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.loca
10.198.0.213



1-346266781
Lack_of_free_swap_space_on_USSAPASP.imzcloud.ibmammsap.local
10.68.213.14
----------------------------------------------------------------------------------------------------------------------------------

27 Dec


1-346486731	sev1
FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local
10.199.1.30 
CRITICAL | /mnt/sapexchange




1-346493981	sev1
Free_disk_space_is_less_than_5%_on_OS_volume_/tmp
10.133.15.25



1-346505241	sev3
NTP_time_is_driffted_on_IA1ADSPRDAPP.imzcloud.ibmammsap.local
10.133.15.30



1-346504831	sev3
NTP_time_is_driffted_on_IA1HCCDEVWD.imzcloud.ibmammsap.local
10.133.16.37




1-346507001		sev3
NTP_time_is_driffted_on_IA1POPRDAPP.imzcloud.ibmammsap.local[
10.133.15.19



1-346508991	sev3
NTP_time_is_driffted_on_LONCFGCGD0001.imzcloud.ibmammsap.local
10.69.1.20



INC6706268 - Sev1 - IBM AMM Infrastructure - Service Now Ticket - Not Validated - Zabbix_agent_on_dal09ammsol05.imzcloud.ibmammsap.local_is_unavailable
146.89.140.4 



INC6697529	sev1	146.89.140.4
Zabbix_agent_on_dal09ammsol05.imzcloud.ibmammsap.local_is_unavailable[




1-346515411	sev3	10.69.1.11
NTP_time_is_driffted_on_loncfgceq0001.imzcloud.ibmammsap.local


1-344288921	sev3	10.68.210.15
Free_disk_space_is_less_than_20%_on_volume_C:



1-345800401	sev3
NTP_time_is_driffted_on_LONCFGCHQ0003.imzcloud.ibmammsap.local
10.69.1.25


INC6707213    COTY Inc.    P2 - Major    Ruuning_out_of_available_memory_on_server_ctuboqr2ap02.imzcloud.ibmammsap.local



SR0013820	
Add Disk space to extend FS for SNCHDSBSD11	10.73.11.225
/sybase/S1D/sapdata1	25GB
/sybase/S1D/sapdata2	25GB
/sybase/S1D/sapdata3	25GB
/sybase/S1D/sapdata4	25GB

[root@snchdsbsd11 ibmrmalik]# df -h /sybase/S1D/sapdata1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/s1ddatavg-s1dsapdata1_lv
                       43G   38G  3.0G  93% /sybase/S1D/sapdata1

[root@snchdsbsd11 ibmrmalik]# df -h /sybase/S1D/sapdata2
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/s1ddatavg-s1dsapdata2_lv
                       46G   43G     0 100% /sybase/S1D/sapdata2

[root@snchdsbsd11 ibmrmalik]# df -h /sybase/S1D/sapdata3
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/s1ddatavg-s1dsapdata3_lv
                       46G   33G   11G  75% /sybase/S1D/sapdata3

[root@snchdsbsd11 ibmrmalik]# df -h /sybase/S1D/sapdata4
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/s1ddatavg-s1dsapdata4_lv
                       46G   33G   11G  75% /sybase/S1D/sapdata4



1-345800401	sev3	10.69.1.25 
NTP_time_is_driffted_on_LONCFGCHQ0003.imzcloud.ibmammsap.local




1-346346131
Free_disk_space_is_less_than_20%_on_volume_/var/log
10.199.1.29





LQ1 - svlq1srv0 : need vm snapshot 

-----------------------------------------------------------------------------------------------------------------------------------

28 Dec

INC6712350    Suncor Energy Inc.    P2 - Major    HANA Cloud Integration (HEC) Server are not connecting from Jump Host.
Target Servers - IFN

23-HANA-CLOUD-INT-NODB:     Hostname: SNCHCIIDA11	   IFN: 10.73.11.113	Windows server use RDP instead of putty
23-HANA-CLOUD-INT-NODB:     Hostname: SSNCHCIIQA11	   IFN: 10.73.12.59	Windows server use RDP instead of putty
23-HANA-CLOUD-INT-NODB:    Hostname: S SNCHCIIPA11	   IFN: 10.73.10.70	Windows server use RDP instead of putty
23-HANA-CLOUD-INT-NODB:    Hostname: S SNCHCIIPA12	   IFN: 10.73.10.71	Windows server use RDP instead of putty


Jump Host Server - From where are trying to connect over putty
66.248.236.4
66.248.236.5



INC6714463    sev3
SVEQ1SRV user ED1ADM need reset





RCA  238390   for SCI - INC6623296 - SL-Singapore-01 - PT Anugerah Pharmindo Lestari (PTP)
https://mbpsjazz.austin.ibm.com:9443/jazz/web/projects/CMS%20NG#action=com.ibm.team.workitem.viewWorkItem&id=238390
PRB0044761   PRB0044761




SR0013913
Snapshot of 4 servers
sveq1srv0	A0EASG014XVM001
svcq1srv0	A0EASG014XVM017
svfd1srv0	A0EASG012XVM003	
svjq1srv0	A0EASG014XVM004	



INC6714719-Sev2 - IBM AMM Infrastructure -Service Now Ticket -Not Validated- Zabbix_agent_on_LON02AMMRBOT1_is_unavailable


INC6715337
Zabbix_agent_on_dal09ammsol01.imzcloud.ibmammsap.local_is_unavailable



1-346455661	10.73.12.92
Ruuning_out_of_available_memory_on_server_snchtriqa11.imzcloud.ibmammsap.local[
---------------------------------------------------------------------------------------------------------------------------

31 Dec

INC6738077	Free_disk_space_is_less_than_5%_on_volume_/sapmnt/log
fbsdbd01fgcl
HANA server






INC6740053
SVEQ1SRV0 - VM Backup for RQ1 Downtime
A0EASG014XVM001




INC6740127
Processor_load_is_too_high_on_lon02ammtsm001.imzcloud.ibmammsap.local[
146.89.140.114 



INC6703100
Free_disk_space_is_less_than_10%_on_volume_/var/log



INC6740647    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
10.73.10.45 




INC6622837
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/OTA




INC6705278
FS_is_read_only_on_br3psape50.imzcloud.ibmammsap.local[
/run/user/82203 





INC6703795
Free_disk_space_is_less_than_20%_on_OS_volume_/var



INC6725273
FS_is_read_only_on_MGGGBJVECCX03.imzcloud.ibmammsap.local
/Fribourg 




INC6728223
Processor_load_is_too_high_on_PHSSAPDEV01
10.5.6.21




INC6735693
Processor_load_is_too_high_on_PHSSAPDEV01





INC6717028
Ruuning_out_of_available_memory_on_server_bmtmon1vhha1.imzcloud.ibmammsap.local



INC6620760
Summary: Free_disk_space_is_less_than_20%_on_OS_volume_/var[
10.8.8.66 





INC6712287
Free_disk_space_is_less_than_20%_on_OS_volume_/[
10.198.0.208 




INC6740884 - Sev2 - IBM AMM Infrastructure - Service Now Ticket - Not Validated - Processor_load_is_too_high_on_MON01AMMSOL04.imzcloud.ibmammsap.local 




INC6742026-Sev2 - IBM AMM Infrastructure -Service Now Ticket -Not Validated- ntpd_check_win




INC6742295
Processor_load_is_too_high_on_ptpbromo.imzcloud.ibmammsap.local[


-------------------------------------------------------------------------------------------------------------------------------

1st Dec 19

INC6660819
NTP_time_is_driffted_on_MGGGBJPECCX10.imzcloud.ibmammsap.local



INC6652924
Free_disk_space_is_less_than_20%_on_volume_/usr



INC6750612  -  P2  -  Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local
10.7.64.14




INC6698769
10.198.201.14 
NTP_time_is_driffted_on_ADNDMSDEV.imzcloud.ibmammsap.local




INC6751016 - Sev2 - IBM AMM SAP Client Tribe Infrastruc
Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local
146.89.140.36 




NC6751059 - Sev2 - IBM AMM Infrastructure



INC6751053- Sev2 - IBM AMM SAP Client Tribe Infrastruc
Processor_load_is_too_high_on_SNG01AMMSOL04.imzcloud.ibmammsap.loca
146.89.140.164




1-345762981
Please unmount nfs in ptpkomodo
PTPBROMO 	10.70.31.16
PTPKOMODO 	10.70.31.13	192.168.166.3

ptpkomodo:

192.168.166.12:/wigo                 24G   14G   11G  56% /

192.168.166.12:/wigo                 11G  7.2G  3.2G  70% /wigo


UUID=a6a0a7ca-fed5-4aa6-9680-38f6638b620a /                    btrfs      defaults              0 0

mount -o remount,rw UUID=a6a0a7ca-fed5-4aa6-9680-38f6638b620a / 

ptpkomodo:/home/ibmrmalik # df -h |grep -i 192.168.166.12:/wigo
192.168.166.12:/wigo                 24G   14G   11G  56% /
192.168.166.12:/wigo                 11G  7.2G  3.2G  70% /wigo

--------------------------------------------------------------------------------------------------------------------------

2 Jan


INC6757211
NTP_time_is_driffted_on_IA2SCCDEVSTA.imzcloud.ibmammsap.local[



INC6750592
Processor_load_is_too_high_on_SNCHCIITA11



INC6746190
Processor_load_is_too_high_on_snchciisa11.imzcloud.ibmammsap.local[




INC6728270
Free_disk_space_is_less_than_20%_on_volume_/sapmnt/DS1





INC6757731
Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local[




INC6725977
Processor_load_is_too_high_on_SNCHCIIDA11[





INC6725493
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/DR1[




INC6720302
Server login failed



INC6660563
Ping Availability CRITICAL - AFRS4HQA: rta nan, lost 100%




INC6758023-Sev2 - IBM AMM Infrastructure -Service Now Ticket -Not Validated- Lack_of_available_memory_on_server_ammsng01custesx012.imzcloud.ibmammsap.local
dispatch to Area: CMS-TR-PHYS-INFRA           Sub Area: CMS-SQ-BLUEMIX-INFRA           Bin: CMS-SQ-BLUEMIX-INFRA



INC6758663-Sev2 - IBM AMM SAP Client Tribe Infrastruc -Service Now Ticket -Not Validated- Zabbix_agent_on_SNG01AMMRBOT1_is_unavailable



INC6731603
Processor_load_is_too_high_on_SSGSA0121.imzcloud.ibmammsap.local



INC6683747    Ravi mallik    IBM AMM Infrastructure    P2 - Major    Lack_of_free_memory_on_server_FMS-PRD-RD01[PROBLEM:10258739]    Queued        SQ-SAP-MONITORING   server not accessible or found on Dal09 vcenter FMS server assign to Infra team

INC6758857    Ravi mallik    IBM AMM Infrastructure    P2 - Major    Lack_of_available_memory_on_server_a0b4ca013esx037.imzcloud.ibmammsap.local[PROBLEM:10425875]    Queued        SQ-SAP-MONITORING	dispatch to Area: CMS-TR-PHYS-INFRA           Sub Area: CMS-SQ-BLUEMIX-INFRA           Bin: CMS-SQ-BLUEMIX-INFR

INC6617428    Ravi mallik    IBM AMM Infrastructure    P2 - Major    Lack_of_free_memory_on_server_FMS-PRD-OR01[PROBLEM:10146309]    In Progress        SQ-SAP-MONITORING	server not accessible or found on Dal09 vcenter FMS server assign to Infra team

INC6716268    Ravi mallik    IBM AMM Infrastructure    P2 - Major    Lack_of_free_memory_on_server_FMSPRDWCA001[PROBLEM:10328466]    Queued        SQ-SAP-MONITORING	server not accessible or found on Dal09 vcenter FMS server assign to Infra team

INC6716144    Ravi mallik    IBM AMM Infrastructure    P2 - Major    Lack_of_free_memory_on_server_FMSPRDWCA001[PROBLEM:10328201]    Queued        SQ-SAP-MONITORING	server not accessible or found on Dal09 vcenter FMS server assign to Infra team

INC6652857    Ravi mallik    IBM AMM Infrastructure    P2 - Major    Lack_of_free_memory_on_server_FMS-PRD-DB03[PROBLEM:10218456]    Queued        SQ-SAP-MONITORING	server not accessible or found on Dal09 vcenter FMS server assign to Infra team

INC6697212    Ravi mallik    SOUTH CENTRAL CONNECTICUT REGIONAL    P2 - Major    Lack_of_free_memory_on_server_CRWBI1VW126[PROBLEM:10293062]    In Progress        SQ-SAP-TRIO-9	Assign to DB or SAP team comments updated

INC6744765    Ravi mallik    West African Cotton Company    P2 - Major    Lack_of_free_swap_space_on_AFRFIORIPRD.imzcloud.ibmammsap.local[PROBLEM:10383055]    In Progress        SQ-SAP-TRIO-11




INC6759198- Sev2 - IBM AMM Infrastructure  - Service Now Ticket - Not Validated - Processor_load_is_too_high_on_tor01ammsol01.imzcloud.ibmammsap.local[PROBLEM:10426674]  @Ravi Malik (3x OS Suppport)


INC6759235-Sev2 - IBM AMM SAP Client Tribe Infrastruc -Service Now Ticket -Not Validated- Processor_load_is_too_high_on_tor01ammsol01.imzcloud.ibmammsap.local[PROBLEM:10426728] @Ravi Malik (3x OS Suppport)

------------------------------------------------------------------------------------------------------------------------------------

3 Jan

INC6766481    P1 - Severe    J Garcia Carrion    Zabbix_agent_on_jgcs4sbxdb.imzcloud.ibmammsap.local_is_unavailable
jgc-fra02-phana-2048-01.imzcloud.ibmammsap.local	10.199.31.27	

SLES for SAP HANA

10.85.139.247 (Private)

Frankfurt 2

root/JPrPPxG7

IPMI console
root/SZVm3eRnm5

Case # 71734039  raised on 3rd jan
Server is down/inaccessible. Cant ping or connect. Shows disconnected.Pls fix ASAP

Checking console, IPMI shows power on and console shows no signal. I rebooted the server and now server is back up and running. Please check if you're now able to access the following device. on 3rd jan 8.657 am


71089201
Hi Team,

We are experiencing the issue with this server and the issue looks similar to the old one https://control.softlayer.com/support/tickets/67987303

Could you please restart the bare metal and re-apply network configuration and we will be able to check what about LACP configuration on our server.

Note: quick resolution is very important for us.
 December 20, 2018, 3:31 pm

71088269



INC6767895 -Sev2 - IBM AMM SAP Client Tribe Infrastruc  Processor_load_is_too_high_on_brspsol011amm.imzcloud.ibmammsap.local



age
age_development
[root@SNG01AMMCHEF01 ~]# knife node list|grep -i svld1srv0
svld1srv0.imzcloud.ibmammsap.local

./root/bootstrap_v12.sh -o age -n svld1srv0 -l -d imzcloud.ibmammsap.local -t osonly -e age_development




lonhana-1024-4.xsportal.local
10.164.30.252
root/JSDmAo5o2G@




INC6760570
APD-ptptoraja:Sys: ICM service name or port number 10000 is not active
10000
lsof -i -P -n | grep LISTEN. sudo netstat -tulpn | grep LISTEN. sudo nmap -sTU -O IP-address-Here
ksaagent   10540      root    9u  IPv4    25412      0t0  TCP *:10000 (LISTEN)



INC6764880
Free_disk_space_is_less_than_20%_on_OS_volume_/var
10.143.21.20 
[root@WNXECCAPPP01 var]# df -h /var
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                      4.9G  2.8G  1.8G  61% /var



INC6656396
Ping Availability CRITICAL - 10.197.5.11: rta nan, lost 100%




INC6656346
Ping Availability CRITICAL - dcghanaqasdb: rta nan, lost 100%
10.197.6.11




INC6656373
Ping Availability CRITICAL - CPWHANAdevDB: rta nan, lost 100%
10.197.6.15 



INC6660613
Ping Availability CRITICAL - 10.197.5.27: rta nan, lost 100%
10.197.5.27

------------------------------------------------------------------------------------------------------------------------------

4th Jan


INC6660584
Ping Availability CRITICAL - 10.197.6.29: rta nan, lost 100%



INC6660567
Ping Availability CRITICAL - 10.197.6.24: rta nan, lost 100%


INC6772080
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/DAA
146.89.141.100
extended the LV with 4GB
[root@TOR01AMMSOL04 ibmrmalik]# df -h /usr/sap/DAA
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/tm1appvg-usrsapdaa_lv
                      8.9G  4.5G  4.0G  54% /usr/sap/DAA




INC6576186
Ping Availability CRITICAL - 10.197.0.11: rta nan, lost 100%



INC6776202    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
10.73.10.45 


INC6776198    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgraqa12.imzcloud.ibmammsap.local
10.73.12.36


INC6576196
Ping Availability CRITICAL - 10.197.5.18: rta nan, lost 100%


INC6776694 - Sev2 - IBM AMM SAP Client Tribe Infrastruc Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local 
146.89.142.30


Helped Backup team with login issue.




INC6776766
SAP-HEC-SWIVEL : 	 Document upload issue port 8080

SOurce : 10.92.99.140 & 10.92.99.110 (10.6.1.140 & 10.6.1.11)
Target: 10.6.1.28  

10:46:28 AM: 10.6.1.28 is windows & mounted on 10.6.1.140 & 10.6.1.11  

[root@sved1srv0 ibmrmalik]# cat /etc/fstab |grep -i cifs
//10.92.99.127/STRS_Spool  /usr/sap/OpenText/STRS_Spool  cifs   credentials=/root/usercred.txt,iocharset=utf8,file_mode=0777,dir_mode=0777 0    0

sveq1srv0
-----------------------------------------------------------------------------------------------------------

7 Jan


CTASK0082590    CHG0088789

SMDSQUAQO1Q71	10.5.24.27	QA
SMBWQUAQW3	10.5.24.41	QA
#tools-nfs.cma-cgm.com:/VOL_TOOLS/Q_TOOLS /tools nfs     vers=4 0 2


	SMSLTQUAQK1	10.5.24.39	QA
	SMCRMQUAQR3	10.5.24.21	QA
[root@smcrmquaqr3 ibmrmalik]# vmware-toolbox-cmd -v
10.1.10.63510 (build-6082533)







INC6805317    P2 - Major    Suncor Energy Inc.    Ruuning_out_of_available_memory_on_server_snchtriqa11.imzcloud.ibmammsap.local
10.73.12.92 
top - 01:32:16 up 74 days, 10:43,  2 users,  load average: 0.00, 0.05, 0.24
Tasks: 303 total,   1 running, 302 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.2%us,  0.4%sy,  0.0%ni, 99.4%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:    31.341G total,   28.306G used, 3108.055M free,   55.938M buffers
Swap:   64.000G total,   21.585G used,   42.415G free, 2066.688M cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
112627 qt1adm    20   0 39.0g  24g 9.8m S  0.3 78.5   1454:37 TREXIndexServer.x -port 30103






Source Server: 10.92.99.140, 10.92.99.110
Target Server: 10.92.99.127    imzcloud.ibmammsap.local
Port No: 8080

netstat -an |grep ":8080" 




2:13:22 PM: IMZ IPs:
Source Server: 10.6.1.140, 10.6.1.11
Target Server: 10.6.1.28  

works with 10.6.2.25	








INC6805677    P2 - Major    CONTROLADORA DE NEGOCIOS    Processor_load_is_too_high_on_cidrh03.imzcloud.ibmammsap.loca
10.68.211.10 






SR0014394
Ageas - FS - create the FS layout as per IBM standard for DB backup setup
create the FS layout as per IBM standard for DB backup setup
/backup			50 GB

Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/lq1appvg-backup_lv
                      6.9G  3.6G  3.1G  55% /backup

Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/lq1appvg-backup_lv
                       50G  3.6G   44G   8% /backup


/sybase/LQ1/log_archive	50 GB

already at 50GB
[root@svlq1srv0 ~]# df -h /sybase/LQ1/log_archive/
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/lq1archvg-lq1logarch_lv
                       50G  348M   47G   1% /sybase/LQ1/log_archive

svlq1srv0	10.6.2.19	A0EASG014XVM023
sdq 






SR0014411
snapshot request
A0EASG014XVM004	svjq1srv0	10.6.2.12

----------------------------------------------------------------------------------------------------------------------------------------------

8 Jan



INC6814906    Panasonic North America    P2 - Major    Lack_of_free_swap_space_on_penap15sl.imzcloud.ibmammsap.local
10.4.8.13



INC6815707    COTY Inc.    P1 - Severe    Zabbix_agent_on_ctubwqb2ap03.imzcloud.ibmammsap.local_is_unavailable
10.12.10.142

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
 2743 qb2adm    35  15   56648   6860   4960 R 100.0 0.010 137616:06 sappfpar pf=/usr/sap/QB2/SYS/profile/QB2_D02_ctubwqb2ap03
26667 daaadm    35  15   55208   6176   4932 R 93.81 0.009 100183:18 sappfpar pf=/usr/sap/DAA/SYS/profile/DAA_SMDA98_ctubwqb2ap03
 4910 root      20   0 33.710g 0.033t   4364 S 44.27 53.53  5125063h /usr/sap/hostctrl/exe/sapcimb -format tree -tracelevel 1 -nonull -continue-on-error -itsam



INC6817039    COTY Inc.    P1 - Severe    Zabbix_agent_on_ctubwqb2ap03.imzcloud.ibmammsap.local_is_unavailable






INC6814628	 add space in GWP DB node - armfksap301d1 ( IFN IP - 10.7.102.65 )
/sybase/GWP    -  10 GB   
armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP
Filesystem                         Size  Used Avail Use% Mounted on
/dev/mapper/gwpdbvg-sybase_gwp_lv   28G   23G  5.7G  80% /sybase/GWP	new 16 GB disk added

armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP
Filesystem                         Size  Used Avail Use% Mounted on
/dev/mapper/gwpdbvg-sybase_gwp_lv   38G   23G   16G  59% /sybase/GWP

/sybase/GWP/sapdata1 - 24 GB
armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata1
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata1_lv   30G   16G   15G  51% /sybase/GWP/sapdata1

armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata1
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata1_lv   54G   16G   39G  28% /sybase/GWP/sapdata1


/sybase/GWP/sapdata2 - 24 GB
armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata2
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata2_lv   30G   16G   15G  51% /sybase/GWPsapdata2

armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata2
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata2_lv   54G   16G   39G  28% /sybase/GWP/sapdata2

/sybase/GWP/sapdata3 - 24 GB
armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata3
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata3_lv   30G   16G   15G  51% /sybase/GWPsapdata3

armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata3
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata3_lv   54G   16G   39G  28% /sybase/GWP/sapdata3

/sybase/GWP/sapdata4 - 24 GB
armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata4
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata4_lv   30G   16G   15G  51% /sybase/GWsapdata4

armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/sapdata4
Filesystem                                    Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata4_lv   54G   16G   39G  28% /sybase/GWP/sapdata4

/sybase/GWP/saplog1 -   32 GB
armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/saplog1
Filesystem                                  Size  Used Avail Use% Mounted on
/dev/mapper/gwplogvg-sybase_gwp_saplog1_lv   30G   28G  3.0G  91% /sybase/GWP/saplog1

armfksap301d1:/home/ibmrmalik # df -h /sybase/GWP/saplog1
Filesystem                                  Size  Used Avail Use% Mounted on
/dev/mapper/gwplogvg-sybase_gwp_saplog1_lv   62G   28G   35G  44% /sybase/GWP/saplog1



CHG0088790
Host Name	CFN IP	Asset Purpose
SMECCTRNTE1	10.5.28.17	Training	10.78.28.17	
SMEDIQUAQU3	10.5.24.32	QA	 	10.78.24.32
SMECCQUAQE1	10.5.24.19	QA		10.78.24.19
SMECCUATUE3	10.5.26.16	Test		10.78.26.16  




SR0014524
vm snapshot required for host svjq1srv0	10.6.2.12

-------------------------------------------------------------------------------------------------------------------------

9 Jan


INC6823796    IBM AMM Infrastructure    P3 - Minor    Access issue & I/O error -- 



INC6816811   sev2
NTP time diff issue and login issue 
App server - smtmuatut3, 10.78.26.14 - having issue
DB server - SMDBUATUT3, 10.78.26.13 - just need to double check




SPSVPPALASE01 	10.6.3.22	10.70.111.22
[root@SNG01AMMCHEF01 ~]# knife node list|grep -i spsvppalase01
spsvppalase01.imzcloud.ibmammsap.local
./root/bootstrap_v12.sh -o age -n spsvppalase01 -l -d imzcloud.ibmammsap.local -t osonly -e age_production

[root@SNG01AMMCHEF01 ~]# knife node list|grep -i spsvppalase01
spsvppalase01.imzcloud.ibmammsap.local
[root@SNG01AMMCHEF01 ~]# knife node delete -y spsvppalase01.imzcloud.ibmammsap.local;knife client delete -y spsvppalase01.imzcloud.ibmammsap.local
Deleted node[spsvppalase01.imzcloud.ibmammsap.local]
Deleted client[spsvppalase01.imzcloud.ibmammsap.local]

cd /root

./bootstrap_v12.sh -o age -n spsvppalase01 -l -d imzcloud.ibmammsap.local -t osonly -e age_production




INC6824480    IBM AMM Infrastructure    P3 - Minor    Unable to connect to server 
brspsol041amm   146.89.143.16 , Unable to connect to this server. Backup affected, Please check



INC6826612    AGEAS    P1 - Severe    Zabbix_agent_on_svjq1srv0.imzcloud.ibmammsap.local_is_unavailable
10.6.2.12 



PRB0044761 	Server PTPSEMERU    10.70.30.142 is not booting after a reboot 



INC6826875	sev3
Requesting to unlock and reset ecdadm user for the server---eccdb0dev---10.198.2.11 

8:46:23 PM: password :-Security#1 

8:46:33 PM: *password: Security#1 

----------------------------------------------------------------------------------------------------------------------------------------

10 Jan

INC6833011    St Jude Medical    P2-Major
Processor_load_is_too_high_on_juddtrans02.imzcloud.ibmammsap.local
10.196.4.13 



INC6833637    SMRT    P2 - Major
Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.local
10.198.0.213 



IBM     FRDAL13ASCS01   169.60.136.228  root pw expired
IBM     FRDAL13ASCS02   169.60.136.229  can access
IBM     FRDAL13ABAP01   169.60.136.223	nothing happens when i try ssh
IBM     FRDAL13ABAP02   169.60.136.224 can access
IBM     FRDAL13ABAP03   169.60.136.225 can access




SR0014708
SAP HEC SWIVEL- PQ2-PayCompare folders
SID Hostname CFN IP Address IFN IP Address
PQ2 AHECQ2SAP01 10.100.2.51 10.4.10.51

/interface/PQ2/310/PayCompare/1B
/interface/PQ2/310/PayCompare/2B
/interface/PQ2/310/PayCompare/1S
/interface/PQ2/310/PayCompare/RatifiedGp
/interface/PQ2/310/PayCompare/AdvancePay


-----------------------------------------------------------------------------------------------------------------

11 Jan


INC6829434





SR0014824
SAP-HEC-SWIVEL Add new Abbott SMTP mail server hostname
ECC Quality	QEP	sjmqepaa01.sjm.com	10.195.3.13	 	10.198.12.13
CRM Quality	QRP	sjmqcpaa01.sjm.com	10.195.3.18		10.198.12.18
GRC Quality	QGP	sjmqgpdb01.sjm.com	10.195.3.15		10.198.12.15
PI Quality	QXP	sjmqxpaa01.sjm.com	10.195.3.21		10.198.12.21
Portal Quality	QPQ	sjmqpqja01.sjm.com	10.195.3.16		10.198.12.16
BoBJ Quality	QBJ	sjmqbdba01.sjm.com	10.195.3.12		10.198.12.12

Abbott SMTP hostname: mail.abbott.com
IP address : 10.254.0.99

10.254.0.99 mail.abbott.com




INC6842378	sev2
add FS space as below details to Production host  - ARMFKSAP301DB (IFN IP 10.7.102.66)
 add space in GWP DB node - ARMFKSAP301DB ( IFN IP 10.7.102.66)
 /sybase/GWP/sapdata1 - 24 GB
armfksap301db:/home/ibmrmalik # df -hT  /sybase/GWP/sapdata1
Filesystem                                   Type  Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata1_lv xfs    30G   16G   15G  51% /sybase/GWP/sapdata1

/sybase/GWP/sapdata2 - 24 GB
armfksap301db:/home/ibmrmalik # df -hT  /sybase/GWP/sapdata2
Filesystem                                   Type  Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata2_lv xfs    30G   16G   15G  51% /sybase/GWP/sapdata2

/sybase/GWP/sapdata3 - 24 GB
fksap301db:/home/ibmrmalik # df -hT  /sybase/GWP/sapdata3
Filesystem                                   Type  Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata3_lv xfs    30G   16G   15G  51% /sybase/GWP/sapdata3

/sybase/GWP/sapdata4 - 24 GB
armfksap301db:/home/ibmrmalik # df -hT  /sybase/GWP/sapdata4
Filesystem                                   Type  Size  Used Avail Use% Mounted on
/dev/mapper/gwpdatavg-sybase_gwp_sapdata4_lv xfs    30G   16G   15G  51% /sybase/GWP/sapdata4

/sybase/GWP/saplog1 -   32 GB
armfksap301db:/home/ibmrmalik # df -h /sybase/GWP/saplog1
Filesystem                                  Size  Used Avail Use% Mounted on
/dev/mapper/gwplogvg-sybase_gwp_saplog1_lv   30G   30G  977M  97% /sybase/GWP/saplog1




INC6842973        SMRT    P2 - Major    Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.local[
10.198.0.213



cache clear
CHG0090053
[root@eccdb0dev ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:           126         23        102          0          0         16
-/+ buffers/cache:          6        119
Swap:           49 1717986847        761
[root@eccdb0dev ibmrmalik]# sync; echo 1 > /proc/sys/vm/drop_caches
[root@eccdb0dev ibmrmalik]# free -g
             total       used       free     shared    buffers     cached
Mem:           126          6        119          0          0          0
-/+ buffers/cache:          6        119
Swap:           49 1717986847        761





INC6701898
NTP time sync






INC6841553
restart of server 10.198.0.209 - cldbobiadwd1 as per request from Pilla Kumar



SR0014862

SAP HEC SWVIEL-/SAP_ARCHVIE/ file system is not mounted
10.73.10.15
10.146.96.46:/SAP_SBO/SAP_ARCHIVE/PROD /SAP_ARCHIVE/


-------------------------------------------------------------------------------------------------------------------------------------

13 Jan


INC6858584	Restore ms3archprd01 with backup taken with this INC6855579
10.12.7.35





INC6853228	sev2
ms3iccprd01 - OS Snapshot


SR0014933    Low    MSC Industrial Supply Co.    perform VM snapshot 
APP1: 10.12.7.12 
VMname/hostname: ms3wdclapp29

APP2: 10.12.7.13
VMname/hostname: ms3wdclapp30
 

  
SR0014926    Medium    MSC Industrial Supply Co.    perform VM snapshot
MP1 APP1
10.12.7.33
Hostname/vmname: ms3wdclapp33b

MP1 DB
10.12.7.17
hostname/vmname: ms3wdcladb33




INC6856951    P1 - Severe    CMA CGM    Zabbix_agent_on_SMGRCDEVDG1.imzcloud.ibmammsap.local_is_unavailable[
10.78.22.48 

INC6856946    P1 - Severe    CMA CGM        Zabbix_agent_on_smemdevdm3.imzcloud.ibmammsap.local_is_unavailable
10.78.22.29 

INC6856942    P1 - Severe    CMA CGM    Zabbix_agent_on_smbwdevdw3.imzcloud.ibmammsap.local_is_unavailable
10.78.22.46



INC6859277    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
10.73.10.45 




INC6860679     P2 - Major    IBM AMM Infrastructure   Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local



ERCSOLPRD1	10.10.0.105	10.5.1.106	A0DDUK014XVM006	 


------------------------------------------------------------------------------------------------------------------------------------

14 Jan

INC6870435    P2 - Major    Suncor Energy Inc.    Lack_of_free_swap_space_on_snchtripa11.imzcloud.ibmammsap.local
10.73.10.125




INC6870774 : SUNCOR - IMZ access not working for the hosts  SNCHECAQA11 and SNCHECAQA20

[root@TOR01AMMCHEF01 ibmrmalik]# CHEF_ORG=snc knife node show snchecaqa11.imzcloud.ibmammsap.local
Node Name:   snchecaqa11.imzcloud.ibmammsap.local
Environment: snc_production
FQDN:        snchecaqa11.hec.network.qut
IP:          10.72.2.11
Run List:    role[baseos_pdns]
Roles:       baseos_pdns, itcs104

snc_production

knife node delete -y snchecaqa11.imzcloud.ibmammsap.local;knife client delete -y snchecaqa11.imzcloud.ibmammsap.local

./bootstrap_v12.sh -o snc -n snchecaqa11 -l -d imzcloud.ibmammsap.local -t osonly -e snc_production




SR0014981
install Compat c++




CSR # CHG0091007 
10.6.2.19 - svlq1srv0
clear cache




SR0014972
SAP-HEC-SWIVEL :  Mount point creation in SQ5
Can you please mount /interfaces directory present on SFTP server
 
(66.248.245.57) to SQ5 server(66.248.245.158).10.133.17.158
 
Same has been done for on SD5 server.

-------------------------------------------------------------------------------------------------------------------

15 Jan


INC6879748
PR1 (HANADB)|HDB_EXP_030_DISK_FULL_ALRT|Internal Disk-Full Event



INC6880494    Raycap GmbH    P2 - Major    Processor_load_is_too_high_on_deeh11ryc1008.imzcloud.ibmammsap.local




INC6880918
 CHEF_ORG=cma knife node show smedidevdu1.imzcloud.ibmammsap.local
[root@PAR01AMMCHEF01 ibmrmalik]#  CHEF_ORG=cma knife node show smedidevdu1.imzcloud.ibmammsap.local
Node Name:   smedidevdu1.imzcloud.ibmammsap.local
Environment: cma_production
FQDN:        smedidevdu1
IP:          10.5.22.55


./bootstrap_v12.sh -o cma -n smedidevdu1 -l -d imzcloud.ibmammsap.local -t osonly -e cma_production

[root@PAR01AMMCHEF01 ~]# knife node list|grep -i smedidevdu1
smedidevdu1.imzcloud.ibmammsap.local




INC6855618
Lack_of_free_swap_space_on_CLDERPAPPD1.imzcloud.ibmammsap.local[




INC6876446 - -NTP_time_is_driffted_on_bmtmon1vhha1.imzcloud.ibmammsap.local


---------------------------------------------------------------------------------------------------------------------------------------

16 Jan

INC6886161    Arnoldo Mondadori Editore SpA    P1 - Severe    Free_disk_space_is_less_than_5%_on_volume_/var/log
Node: armfksap301ap.imzcloud.ibmammsap.local NodeAlias: 10.7.102.64 


SAP 09 Trio - 671 vms
SAP 10 Trio - 538 Vms
SAP 11 Trio -568 Vm
SAP 12 Trio - 661 vms


INC6882149    CMA CGM    P1 - Severe    Zabbix_agent_on_smgwdevdq1.imzcloud.ibmammsap.local_is_unavailable
10.78.22.13





DEC	            DLBDECAP01	         10.13.2.14	                172.16.22.14

Java Version: 1.8.0_131 




INC6887679    AGEAS    P1 - Severe    Zabbix_agent_on_spsvppalase01.imzcloud.ibmammsap.local_is_unavailable
10.6.3.22



INC6883228
Zabbix_agent_on_hnosolmn.imzcloud.ibmammsap.local_is_unavailable
10.20.0.15




INC6882149    CMA CGM    P1 - Severe    Zabbix_agent_on_smgwdevdq1.imzcloud.ibmammsap.local_is_unavailable
--------------------------------------------------------------------------------------------------------------------------------


17 Jan


INC6896638    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgraqa11.imzcloud.ibmammsap.local
10.73.12.35



INC6894049
NTP_time_is_driffted_on_svud1srv0.imzcloud.ibmammsap.local[
10.6.1.137



INC6893442
NTP_time_is_driffted_on_LONCFGCHP0001.imzcloud.ibmammsap.local




INC6897058	SPSVEPAEAPP01
Add New FS for SAP Upgrade
File system name: /temprppupg - 128 GB
it will be located at the root directory
Volume group: create a new volume group for this file system, call it tempvg
ownership: rppadm:sapsys
chmod: 775
Host: spsvepaeapp01 (10.6.3.12)

vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount  <full lv path >   <fs>
vi /etc/fstab

 /dev/tempvg/temprppupg     ext3


nmon 

/dev/tempvg/temprppupg    /temprppupg  ext3        _netdev,defaults    1 2




SR0015283
SAP-HEC-SWIVEL  Run Zip Commands in ED1 System (Developm
Hi SAP Support,
 
Please assist to run the following ZIP commands in our ED1 system.
 
Kindly do a test at the OS level of ED1. Zip a file (eg. Testfile.txt,
please have that ready) with the command .
      7za -psmrt1234 Testfile.7z Testfile.txt
 
 2. Test the zipped file.  
      7za | -slt Testfile.7z
 
Provide the screenshot of output of the commands above.





SR0015204 --EGR - Request screenshot with the antiviruses installed on the OS hosts of EGR Account 
ERCERPD1    10.5.1.101

ERCERPQ1    10.5.1.102

ERCERPP1    10.5.1.103

ERCNWD01    10.5.1.104

ERCNWQ01    10.5.1.105

ERCSOLPRD1    10.5.1.106

Sites : London (LON02)

Kindly email to Muhammad Haddad (mhaddad@ERCEGYPT.COM) and cc Rizal Rosli/Malaysia/IBM, Daniela Petolea/Romania/IBM, 





INC6891517 - Transport issue in QM3 system
/usr/sap/trans mount issue on SMEMQUAQM3, 10.78.24.26 




SR0015298
create new FS /tempeq1upg on SPSVEPAEAPP01	A0EASG014XVM024
1. create new FS /tempeppupg on SPSVEPAEAPP01 for EPP upgrade
265 GB under root
Host: spsvepaeapp01 (10.6.3.12)

2. copy files & folders from EQ1 server /tempeq1upg (10.6.2.11) to /tempeppupg (10.6.3.12)

SPSVEPAEAPP01 	10.6.3.12	10.70.111.12
SVEQ1SRV0 	10.6.2.11	10.70.110.11

vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount  <full lv path >   <fs>
vi /etc/fstab


tmpvg 
tempeppupg
/dev/tmpvg/tempeppupg
/dev/tmpvg/tempeppupg    /tempeppupg  ext3        _netdev,defaults    1 2

----------------------------------------------------------------------------------------------------------------------------------------------

Jan21

INC6922386    P1 - Severe    IBM AMM Infrastructure    DAL13AMMCHEF01.imzcloud.ibmammsap.local_has_just_been_restarted
146.89.142.213 




INC6910903
Processor_load_is_too_high_on_lon02ammtsm001.imzcloud.ibmammsap.local[




INC6833433

Kindly provide the users & screenshots who have access to the below
folder
 
/usr/interfaces/hr/outbound/fullerton/working
CLDERPDTBP1 - DB
CLDERPAPPP1 - App



INC6925774  - Sev2 - IBM AMM SAP Client Tribe Infrastruc Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local
146.89.140.36 

----------------------------------------------------------------------------------------------------------------------------------------

22 Jan

INC6930145    PANARIAGROUP INDUSTRIE CERAMICHE SP    P2 - Major    FS_is_read_only_on_C1ECCD.imzcloud.ibmammsap.local
CRITICAL | /mnt/sapexchange



INC6930350
svlq1srv0-10.6.2.19	A0EASG014XVM023




SR0015646
snapshot request




INC6930191    PEPSICO INC    P1 - Severe    Pepsapgssdi01.imzcloud.ibmammsap.local_has_just_been_restarted
ref INC6911466


SR0015292
S/4 Hana Apps(HNOAPDEV - 10.20.0.16)
HNODBDEV
HNOSOLMN





INC6931188    Suncor Energy Inc.    P1 - Severe    Zabbix_agent_on_snchgrapa12.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10754600]
10.73.10.45

INC6931187    Suncor Energy Inc.    P1 - Severe    Zabbix_agent_on_snchgrada11.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10754598]
10.73.11.105

INC6931186    Suncor Energy Inc.    P1 - Severe    Zabbix_agent_on_snchcrapa11.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10754595]
10.73.10.31

INC6931173    Suncor Energy Inc.    P1 - Severe    Zabbix_agent_on_snchapapa11.imzcloud.ibmammsap.local_is_unavailable
10.73.10.27



vsappe6-app6/10.9.4.204





INC6931658    COTY Inc.    P3 - Minor    FS_is_read_only_on_ctubwqb4ap03.imzcloud.ibmammsap.local[PROBLEM:10756648]
10.12.10.155	CRITICAL | /run/user/54716


INC6931644    COTY Inc.    P3 - Minor    FS_is_read_only_on_ctubwqb1ap03.imzcloud.ibmammsap.local[PROBLEM:10756642]
10.12.10.151


INC6910925
Free_disk_space_is_less_than_10%_on_volume_/usr/sap	10.6.2.61
-------------------------------------------------------------------------------------------------------------------------------


23 Jan


TRIO 11    INC6937536    Incident    1    CTU SAP & OS for 3.x -- Need OS Linux need 3.x help and join #scx-sap11-ctu
ctuboqr3ap06	10.12.10.115	
[root@ctuboqr3ap06 ~]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /var /tmp /usr/sap/QR3 filesystems are read-only



	
ctuboqr3ap07	10.12.10.116
[root@ctuboqr3ap07 var]# df -h /tmp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_tmp
                      2.0G   71M  1.8G   4% /tmp
                      
("/usr/sap/QR3/FRS",

/dev/qr3appvg/qr3usrQR3_lv      /usr/sap/QR3    ext3    _netdev,defaults       12


/dev/mapper/qr3appvg-usrsap_lv
                     1008M  605M  353M  64% /usr/sap
                     
[root@ctuboqr3ap07 var]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /usr/sap/QR3 /usr/sap/DAA /usr/sap/ccms /usr/sap/trans /usr/sap/QR3/FRS /usr/sap/QR3/FRS filesystems are read-only
                     




ctuboqr3ap08	10.12.10.117


CTUBOQR3AP01	done
CTUBOQR3AP02	done
CTUBOQR3AP03
statfs("/usr/sap/QR3/FRS", ^Z

CTUBOQR3AP04
CTUBOQR3AP05
CTUBOQR3AP06  - Done at 20:01 ET
CTUBOQR3AP07	done
CTUBOQR3AP08  done 
CTUBOQR3DB01  done

/usr/sap/QR3/FRS from the db server

DB(CTUBOQR3DB01)-10.12.10.109 first and then the APP(CTUBOQR3AP02   	10.12.10.111	, CTUBOQR3AP07 10.12.10.116 , CTUBOQR3AP01 10.12.10.110	, CTUBOQR3AP03 10.12.10.112	, CTUBOQR3AP04 10.12.10.113, CTUBOQR3AP05 10.12.10.114, CTUBOQR3AP06 & CTUBOQR3AP08) services in sequence

172.22.64.109:/usr/sap/QR3/FRS	/usr/sap/QR3/FRS nfs defaults 0 0

 mount -t nfs 172.22.64.109:/usr/sap/QR3/FRS /usr/sap/QR3/FRS


INC6938931    COTY Inc.    P1 - Severe    Zabbix_agent_on_ctuboqr3ap01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10767066]
10.12.10.110

INC6938912    COTY Inc.    P1 - Severe    Zabbix_agent_on_ctuboqr3ap04.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10767037]
10.12.10.113

INC6938904    COTY Inc.    P1 - Severe    Zabbix_agent_on_ctuboqr3ap03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10767034]


INC6938870    COTY Inc.    P1 - Severe    Zabbix_agent_on_ctuboqr3ap07.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10766995]


INC6938864    COTY Inc.    P1 - Severe    Zabbix_agent_on_ctuboqr3ap05.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10766993]




10:16:08 AM: INC6939190 
pl add 2GB space for /usr/sap  FS 





INC6928011        IBM AMM Infrastructure    P1 - Severe    CHE01AMMZAB001.imzcloud.ibmammsap.local_has_just_been_restarted[





INC6939950    Dilip Buildcon Limited    P2 - Major    Processor_load_is_too_high_on_DLBPECAP01.imzcloud.ibmammsap.local




INC6936327    DyStar Singapore Pte Ltd    P1 - Severe    Zabbix_agent_on_dysfrdafrq20.imzcloud.ibmammsap.local_is_unavailable
10.6.12.32 





SR0015757    Suncor Energy Inc.    Medium    SAP-HEC-SWIVEL Mount file056 on SR1
File056 is not mounted on SR1 server.
Kindly please mount and confirm once done.
 
file056:/SAP_DATA_nonprd01/SAP_DATA_nonprd01 197G 180G 18G 91%
/SHARE/MNT/FILE056/SAP_DATA_nonprd01
 
SNCHECASA11 	10.73.11.210	10.72.1.210 	Sandbox 	Deployed 	SBX	SR1	00	SNC	SAP12	7819




INC6939533    AGEAS    P3 - Minor    NTP_time_is_driffted_on_spsvepajapp01.imzcloud.ibmammsap.local
10.6.3.13



INC6922391
Zabbix_agent_on_DAL13AMMZAB001.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10724130]


-------------------------------------------------------------------------------------------------------------------------------------

24 Jan



INC6946386    P2 - Major    Panasonic Europe Ltd
Please validate why below VMs rebooted on 23/1/2019, it cause cluster falure and system down for hours

PEU-A4Q-DB	100.126.65.227
peu-a4q-db:/home/ibmrmalik # last reboot
reboot   system boot  4.4.121-92.95-de Wed Jan 23 17:16 - 03:58  (10:42)

PEU-A4Q-DB-HA	100.126.65.228
peu-a4q-db-ha:/home/ibmrmalik # last reboot
reboot   system boot  4.4.121-92.95-de Wed Jan 23 17:35 - 04:20  (10:44)


Jan 23 23:53:55 peu-a4q-db systemd-logind[4659]: Removed session 30.
Jan 23 23:53:55 peu-a4q-db systemd[1]: Stopping User Manager for UID 71990...
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Stopped target Default.
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Stopped target Basic System.
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Stopped target Timers.
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Stopped target Sockets.
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Reached target Shutdown.
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Starting Exit the Session...
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Stopped target Paths.
Jan 23 23:53:55 peu-a4q-db systemd[49282]: Received SIGRTMIN+24 from PID 33751 (kill).
Jan 23 23:53:55 peu-a4q-db systemd[1]: Stopped User Manager for UID 71990.
Jan 23 23:53:55 peu-a4q-db systemd[1]: Removed slice User Slice of ibmashevni.
Jan 23 23:53:55 peu-a4q-db kernel: [23858.914557] [4659(systemd-logind)]: gsch_umount_hook_fn(/run/user/71990,2) doing
Jan 23 23:53:55 peu-a4q-db kernel: [23858.914599] gsch_redirfs_rem_mnt(/run/user/71990 @ Unknown[1021994(tmpfs)]) done: 0
Jan 23 23:53:55 peu-a4q-db kernel: [23858.916001] [4659(systemd-logind)]: gsch_umount_hook_fn(/run/user/71990,2) done(0)



PEU-A4Q-DB-HA	100.126.65.228
peu-a4q-db-ha:/home/ibmrmalik # last reboot
reboot   system boot  4.4.121-92.95-de Wed Jan 23 17:35 - 04:20  (10:44)






INC6948117	SAP-HEC-SWIVEL HEC: URGENT - SFTP PROD not accessible
[root@spsvmplmapp01 ibmrmalik]# pam_tally2 --user
Login           Failures Latest failure     From
zabbix              9    01/24/19 10:15:30
[root@spsvmplmapp01 ibmrmalik]#




INC6948250
SAP-HEC-SWIVEL Restore LQ1 with VM snap dated 22 Jan 19



SR0015791    Medium    Delta Airlines    SAP HEC SWIVEL: EMS Request : P3: DSQ Repositories Configuration



SR0015877
SAP-HEC-SWIVEL Increase memory & CPU - EPP/RPP - Tempor
Requesting to temporarily increase the memory & CPU of EPP/RPP
application host:
 
RAM 128GB
CPU 16

final values : 16 CPU & 128 GB RAM
spsvepaeapp01 - 10.6.3.12 




SR0015875
Please add 3GB space to /usr/sap/hostctrl on 
10.6.12.19
dysadsdadsd40:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/dsdappvg-usrsap_lv  976M  250M  676M  27% /usr/sap
dysadsdadsd40:/home/ibmrmalik # vgs dsdappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  dsdappvg   2  13   0 wz--n- 172.99g 18.99g
  
  dysadsdadsd40:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/dsdappvg-usrsap_lv  4.0G  250M  3.5G   7% /usr/sap



10.6.12.20
dyswdapwdd40:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/wddappvg-usrsap_lv  976M  117M  808M  13% /usr/sap
dyswdapwdd40:/home/ibmrmalik # vgs wddappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  wddappvg   1  13   0 wz--n- 128.00g 24.00g
  
  dyswdapwdd40:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/wddappvg-usrsap_lv  4.0G  118M  3.7G   4% /usr/sap


10.6.12.31
dyswdapwdq20:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/wdqappvg-usrsap_lv  976M  117M  809M  13% /usr/sap
dyswdapwdq20:/home/ibmrmalik # vgs wdqappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  wdqappvg   1  13   0 wz--n- 128.00g 24.00g
  
  dyswdapwdq20:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/wdqappvg-usrsap_lv  4.0G  118M  3.7G   4% /usr/sap



INC6948263   reboot below server
CLDBOBIADWD1 - 10.198.0.209
[root@CLDBOBIADWD1 ibmrmalik]# uptime
 15:22:45 up 1 min,  1 user,  load average: 1.53, 0.55, 0.19



INC6950378 - CMA CGM - Kindly check if mount point, /usr/sap/trans is good on SMEDIDEVDU3
Kindly check if mount point, /usr/sap/trans is good on SMEDIDEVDU3, 10.78.22.35




INC6949120
edd#vedci003#The host lost connectivity to a Network File System (NFS) server






INC6950783  sev2
Hana db backup issue

-------------------------------------------------------------------------------------------------------------------

25 Jan


CHG0091223
OS Time zone changes from CET to GMT +2 on SAP and database server  and PRD SAP Parameter Change according with build plan

CHANGE TIMELINE:  25th of January 2019 01:00 AM CET - 04:00 AM CET  or 24th of January 2019 16:00 PM PST - 19:00 PM PST 
duration 3 hours
SAP Performer:   Reddappa, Balaji K   ( balajikr11@in.ibm.com ) and  Nath Esquival Email nesquive@cr.ibm.com
Linux OS Performer:     ( rmalik@us.ibm.com ) and Priscila Hernandez Email sphernan@cr.ibm.com
Affected Server: Production SAP System "PRD": 
CI3S4HANAPRDA  /  10.210.1.12 (SAP Central Instance)
C13S4HANAPRD  /   10.210.1.11 (Hana Database)
SID: PRD 



AGEAS SFTP issue
cust call




INC6827042
FS_is_read_only_on_agesveqmhsrv1.imzcloud.ibmammsap.local[
agesveqmhsrv1:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
rm: cannot remove '/usr/sap/EQM/home/.gvfs/testfile': Permission denied
CRITICAL |  /usr/sap/EQM/home/.gvfs filesystems are read-only

agesveqmhsrv1:/usr/sap/EQM/home # ls -ltr |grep -i .gvfs
ls: cannot access '.gvfs': Permission denied
d????????? ? ?      ?          ?            ? .gvfs



SR0015866
RAM upgrade on one DLB server
16-48 GB




INC6959361    P2    IBM AMM Infrastructure Processor_load_is_too_high_on_lon02ammtsm001.imzcloud.ibmammsap.local
146.89.140.114




INC6958017
SAP-HEC-SWIVEL : Time discrepancy between two nodes of T




10.182.200.21	ADNABPDB	10.198.200.21
ADNABPDB 	10.198.200.21	10.182.200.21 	
(DR) DRADNABPDB 10.182.203.20(CFN)/10.204.4.20(IFN) => hkghana-1024-1.xsportal.loca



SR0015995
root pw reset for  spsvppalase01  (10.6.3.22)

-------------------------------------------------------------------------------------------------------------

27 Jan


https://www.thegeekdiary.com/centos-rhel-how-to-collect-sosreport/
yum install sos
sosreport


CASE 02301362

PYQ    AHECQHDB01        10.4.10.30		 /tmp/sosreport-RaviMAlik.RHELCASE-20190127053426.tar.xz

PYQ    AHECQSAP01        10.4.10.31	 /tmp/sosreport-RaviMAlik.RHELCASE-20190127054232.tar.xz

PRD is:
PYP    AHECPHDB01        10.4.9.10	/tmp/sosreport-RaviMalik.RHELCASE-20190127054353.tar.xz
PYP    AHECPSAP01         10.4.9.11	/tmp/sosreport-RaviMAlik.RHELCASE-20190127054752.tar.xz
PYP    AHECPSAP02        10.4.9.16	/tmp/sosreport-RaviMAlik.RHELCASE-20190127055038.tar.xz
PYP    AHECPSAP03        10.4.9.17	/tmp/sosreport-RAviMAlik.RHELCASE-20190127055025.tar.xz

--------------------------------------------------------------------------------------------------------------------------

28 Jan


INC6981662    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local
10.73.10.44


INC6981612    P2 - Major    Suncor Energy Inc.Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local
10.73.10.45


INC6981931    IBM AMM Infrastructure Processor_load_is_too_high_on_WDC04AMMSOL04.imzcloud.ibmammsap.local


Steps to be followed to fix the servers.

1) Login to the VM and remove the routes that were added by the script:
- Remove the entry from network-script(158.87.44.128,158.87.46.128)
- route del -net 158.87.44.128 netmask 255.255.255.128 gw <check in routing table> <device/ethX>
- route del -net 158.87.46.128 netmask 255.255.255.128 gw <check in routing table> <device/ethX>

2) Run netstat -nr | grep 0.0.0.0, verify the value of the default route

3) If the route is in fact incorrect, remove the default route and install the correct default route.
- route del -net 0.0.0.0 netmask 0.0.0.0 gw <check in routing table> <device/ethX>
- route add -net 0.0.0.0 netmask 0.0.0.0 gw <check in routing table> <device/ethX>

4) Execute sudo cat /etc/sysconfig/network | grep -i gateway, verify the value of the gateway

5) If the gateway is incorrect in the file, update the file with the proper gateway

6) check the default route and the /etc/sysconfig/network file one more time and confirm that the gateways are correct



1) Login to the VM and remove the routes that were added by the script:
- Remove the entry from network-script(158.87.44.128,158.87.46.128)
- route del -net 158.87.44.128 netmask 255.255.255.128 gw <check in routing table> <device/ethX>
- route del -net 158.87.46.128 netmask 255.255.255.128 gw <check in routing table> <device/ethX>

2) Run netstat -nr | grep 0.0.0.0, verify the value of the default route

3) If the route is in fact incorrect, remove the default route and install the correct default route.
- route del -net 0.0.0.0 netmask 0.0.0.0 gw <check in routing table> <device/ethX>
- route add -net 0.0.0.0 netmask 0.0.0.0 gw <check in routing table> <device/ethX>


397  2019-01-28 12:32:42 ifconfig
  398  2019-01-28 12:33:20 netstat -rn
  399  2019-01-28 12:45:24 pwd
  400  2019-01-28 12:48:50 cd /etc/sysconfig
  401  2019-01-28 12:48:55 cat network
  402  2019-01-28 13:08:53 cd network-scripts
  403  2019-01-28 13:08:56 ls -l
  404  2019-01-28 13:09:07 cat route-eth1
  405  2019-01-28 13:09:22 route -n
  406  2019-01-28 13:10:19 route del -net 158.87.44.128 netmask 255.255.255.128 gw 10.204.4.1 eth1
  407  2019-01-28 13:10:38 route del -net 158.87.46.128 netmask 255.255.255.128 gw 10.204.4.1 eth1
  408  2019-01-28 13:10:43 route -n
  409  2019-01-28 13:11:22 netstat -nr | grep 0.0.0.0
  410  2019-01-28 13:16:33 cd ..
  411  2019-01-28 13:16:37 cat network



10.6.3.21	decom pending
10.6.3.30	spsvwpawapp11	 this is gud 
10.6.3.50	smpsp1dbsrv0	server is gud
10.6.1.50	CFN gateway entry in  /etc/sysconfig/network
HOSTNAME=smpsd1dbsrv0
NETWORKING=yes
GATEWAY=10.92.99.1

10.70.110.11	A0EASG014XVM001
cleaned up the entry 


10.92.99.137	A0EASG014XVM015


10.6.1.159	svhh1srv0	no changes done all gud
10.6.1.160	svlh1srv0	no changes done all gud
100.126.64.140





add 2 GB for INC6982013    P1 - Severe    PT Anugerah Pharmindo Lestari
/usr/sap



INC6982139	sev1
DLBPSMDA00	10.13.1.19
DEC System is down...
10.13.2.14	DLBDECAP01



INC6982429    P1 - Severe    Dilip Buildcon Limited
DLBPSMDA00	10.13.1.19



PEU-A4Q-DB 100.126.65.227	 /var/log/nts_SR101214946891_peu-a4q-db_190128_0903.tbz
Jan 23 16:14:10 peu-a4q-db su: (to a4qadm) root on none
Jan 23 16:15:11 peu-a4q-db su: (to a4qadm) ibmpteran on none
Jan 23 17:16:25 peu-a4q-db rsyslogd-2184: action '*' treated as ':omusrmsg:*' - please change syntax, '*' will not be supported in the future [try http://www.rsyslog.com/e/2184 ]
Jan 23 17:16:25 peu-a4q-db kernel: [ 0.000000] Initializing cgroup subsys cpuset
Jan 23 17:16:25 peu-a4q-db kernel: [ 0.000000] Initializing cgroup subsys cpu
Jan 23 17:16:25 peu-a4q-db kernel: [ 0.000000] Initializing cgroup subsys cpuacct

PEU-A4Q-DB-HA 100.126.65.228		 /var/log/nts_SR101214946891_peu-a4q-db-ha_190128_0907.tbz

Jan 23 16:30:11 peu-a4q-db-ha su: (to a4qadm) root on none
Jan 23 16:31:13 peu-a4q-db-ha su: (to a4qadm) ibmpteran on none
Jan 23 16:31:43 peu-a4q-db-ha su: (to a4qadm) ibmpteran on none
Jan 23 16:33:00 peu-a4q-db-ha su: (to a4qadm) root on none
Jan 23 17:35:56 peu-a4q-db-ha rsyslogd-2184: action '*' treated as ':omusrmsg:*' - please change syntax, '*' will not be supported in the future [try http://www.rsyslog.com/e/2184 ]
Jan 23 17:35:56 peu-a4q-db-ha systemd-sysctl[1398]: Couldn't write '0' to 'dev/cdrom/autoclose', ignoring: No such file or directory
Jan 23 17:35:56 peu-a4q-db-ha systemd-sysctl[1398]: Couldn't write '0' to 'net/bridge/bridge-nf-call-ip6tables', ignoring: No such file or directory
Jan 23 17:35:56 peu-a4q-db-ha systemd-sysctl[1398]: Couldn't write '0' to 'net/bridge/bridge-nf-call-iptables', ignoring: No such file or directory
Jan 23 17:35:56 peu-a4q-db-ha kernel: [ 0.000000] Initializing cgroup subsys cpuset
Jan 23 17:35:56 peu-a4q-db-ha kernel: [ 0.000000] Initializing cgroup subsys cpu
Jan 23 17:35:56 peu-a4q-db-ha kernel: [ 0.000000] Initializing cgroup subsys cpuacct  


CHG0093115
svjq1srv0	10.6.2.12  -- JQ1	A0EASG014XVM004
svjd1srv0	10.6.1.12  -- JD1 	A0EASG014XVM003


-------------------------------------------------------------------------------------------------------------------------------------

29 Jan

INC6986238    Incident    2    PN4    1/28/2019    pn4us7leccp1c    Mount /idocs FS to CP1
Rename "/interface/CP1" fs to /interfaces" on below server

Destination:
pn4us7leccp1c  10.12.254.17

ssapp-pn4-cp1.us.panasonic.com (10.142.41.59
pn4us7leccp1c:/home/ibmrmalik # df -h /interface/CP1
Filesystem                           Size  Used Avail Use% Mounted on
ssapp-pn4-cp1:/export/interface/CP1 1014M   32M  982M   4% /interface/CP1


Once above done mount the "/interfaces" to below server
pn4ushleccp1c  10.12.254.18



SR0016199
Dilip Buildcon - Login issue - 10.13.2.11



INC6922391        IBM AMM Infrastructure    P1 - Severe    Zabbix_agent_on_DAL13AMMZAB001.imzcloud.ibmammsap.local_is_unavailable




SR0016250
Please add space 



SR0016264
Please create users in server 10.6.12.18 - dyss4apsbd41  as per attachment

useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -m dsusragt1 -s /bin/csh -c "Data Services Agent 01"

useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -m dsusragt2 -s /bin/csh -c "Data Services Agent 02"

useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -m dsusragt3 -s /bin/csh -c "Data Services Agent 03"

useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -m dsusragt4 -s /bin/csh -c "Data Services Agent 04"




INC6989446 
FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local[PROBLEM:10842851]


INC6989445
FS_is_read_only_on_C1ECCP.imzcloud.ibmammsap.local[PROBLEM:10842847]
10.199.1.10



INC6886161        Arnoldo Mondadori Editore SpA    P1 - Severe    Free_disk_space_is_less_than_5%_on_volume_/var/log




INC6915329        IBM AMM Infrastructure    P1 - Severe    Free_disk_space_is_less_than_5%_on_volume_/TSMDB/TSMDB2
146.89.140.179




INC6574916
INC000003344027 - Gbcnvpldbs13 Host Reboot



SR0016277
Ageas - New FS - 10.6.3.13 - spsvepajapp01 - PP 	A0EASG014XVM039
 Please create new mount /backup_FSQUO with 30 GB
Hostname: spsvepajapp01  IP: 10.6.3.13 
sdc

vgcreate vg_NAME /dev/sdX (PV)		temp
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name	backup_FSQUO
mkfs.ext2/3/4 path of lvdisplay       /dev/temp/backup_FSQUO
mount
vi /etc/fstab

jppadm:sapsys

/dev/temp/backup_FSQUO  /backup_FSQUO  ext3        _netdev,defaults    1 2 



SR0016291
Ageas - VM snapsht for Hostname: spsvepajapp01  IP: 10.6.3.13  




INC6946154	P3 - Minor	Service vmtoolsd CRITICAL: vmtoolsd is not running


INC6946159	P3 - Minor	Service vmtoolsd CRITICAL: vmtoolsd is not running auto closed
-----------------------------------------------------------------------------------------------------------------------------------------

30 Jan


SR0016397
upscale memory from 16GB to 32GB on ED1, EQ1 hosts
ED1: sved1srv0 - 10.6.1.11	A0EASG014XVM002
EQ1: sveq1srv0 - 10.6.2.11	A0EASG014XVM001


INC6992419        CMA CGM    P1 - Severe    Free_disk_space_is_less_than_5%_on_OS_volume_/var[PROBLEM:10849356] 


INC6986294        Dilip Buildcon Limited    P2 - Major    Lack_of_free_swap_space_on_DLBPSMDA00.imzcloud.ibmammsap.local[PROBLEM:10834510]    Queued        SQ-SAP-TRIO-10


INC6708518        IBM AMM Infrastructure    P2 - Major    Lack_of_free_memory_on_server_FMSPRDWCA001[PROBLEM:10314544]    Queued        SQ-SAP-TRIO-9


INC6996340
Please reset  user edpadm on eCPRDHANADB4	10.70.2.19




INC6875449        SMRT    P2 - Major    Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.local[PROBLEM:10646594]    In Progress        SQ-SAP-TRIO-10


 
 TBOS4DEVAP 	100.126.48.20	10.69.20.20



INC6963532        Panasonic North America    P1 - Severe    PACEMAKER_service_not_running[PROBLEM:10797116]    Queued        SQ-SAP-BUILD-MON @Ravi Malik (3x OS Suppport)
10.12.254.42
pn4ushlmiip1:/home/ibmrmalik # rcpacemaker status
â— pacemaker.service - Pacemaker High Availability Cluster Manager
   Loaded: loaded (/usr/lib/systemd/system/pacemaker.service; enabled; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:pacemakerd
           https://clusterlabs.org/pacemaker/doc/en-US/Pacemaker/1.1/html-single/Pacemaker_Explained/index.html

Jan 23 12:00:27 pn4ushlmiip1 systemd[1]: Dependency failed for Pacemaker High Availability Cluster Manager.
Jan 23 12:00:27 pn4ushlmiip1 systemd[1]: pacemaker.service: Job pacemaker.service/start failed with result 'dependency'.



INC6963685        Panasonic North America    P1 - Severe    PACEMAKER_service_not_running[PROBLEM:10797400]    Queued        SQ-SAP-BUILD-MON
ervice Node: pn4ushlapsp1.imzcloud.ibmammsap.local NodeAlias: 10.12.254.44

-----------------------------------------------------------------------------------------------------------------------------------------

31 Jan


INC7002796  - Sev1 - AGE - SAP HEC-AMM  - Sppctriage Ticket -Singapore, Jurong East (SL) -  Critical CMAS Account-  SAP HEC Swivel P1: SAP Production Not Accessbile-057134/2019
APP: JQ1-svjq1srv0                HANA DB: EQM - MDC Quality HANA DB    agesveqmhsrv1
APP: JPP - spsvepajapp01      HANA DB: EPM - MDC Production HANA DB    agesvepmhsrv1 (edited)

agesvepmhsrv1 - 10.6.3.58 (HANA DB) we are not able to connect

svcq1srv0	10.6.2.16	10.70.110.16 	
spsvcpacapp01	10.6.3.15	10.70.111.15	can access via console gateway has 0000 entry
svjq1srv0	10.6.2.12	10.70.110.12	
spsvepajapp01	10.6.3.13	10.70.111.13
agesvepmhsrv1	10.6.3.58	10.70.111.59
agesvcqmhsrv1	10.6.2.72	10.70.110.70
agesvcpmhsrv1	10.6.3.59	10.70.111.60
agesveqmhsrv1	10.6.2.71	10.70.110.71
agesvbpphsrv1	10.6.3.60	10.70.111.61
agesvcqmhsrv1   10.6.2.72

sng01-pod2-4tb-host01.imzcloud.ibmammsap.local
Private IP: 10.116.205.251
root/zX2ssKltV1@

73319165 case to SL




TRIO 9     INC7002285	issue due to esx issue with memory being replaced by Softlayer vide  73319165. Master ticket INC7002796
   TRIO 9    INC7002282 Zabbix_agent_on_agesvcpmhsrv1.imzcloud.ibmammsap.local_is_unavailable
   TRIO 9    INC7002281 Zabbix_agent_on_agesveqmhsrv1.imzcloud.ibmammsap.local_is_unavailable
   TRIO 9    INC7002273 Zabbix_agent_on_agesvbpphsrv1.imzcloud.ibmammsap.local_is_unavailable




INC7003920 - P2 -IBM AMM SAP Client Tribe Infrastruc  - Service Now Ticket - Not Validated - Processor_load_is_too_high_on_brspsol011amm.imzcloud.ibmammsap.local






SR0016529 
create a snapshot for both ms3wdcadbsd1 (10.12.6.66) and ms3wdcappsd1 (10.12.6.65) and call them SPAU


SR0016530 
create a snapshot for both ms3wdcadbsd1 (10.12.6.66) and ms3wdcappsd1 (10.12.6.65) and call them SPAU




LD_LIBRARY_PATH = /usr/sap/J1S/hdbclient 


/home/j1sadm 

# SAP HDBCLIENT Env
LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/sap/J1S/hdbclient; export $LD_LIBRARY_PATH


# SAP HDBCLIENT Env
LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/sap/J1S/hdbclient;




-INC7004164 - P2 -IBM AMM SAP Client Tribe Infrastruc  - Service Now Ticket - Not Validated - Processor_load_is_too_high_on_dal09ammsol01.imzcloud.ibmammsap.local




SR0015283
SAP-HEC-SWIVEL  Run Zip Commands in ED1 System (Developm	CLDERPAPPD1 10.198.0.208
Please assist to run the following ZIP commands in our ED1 system.
 
Kindly do a test at the OS level of ED1. Zip a file (eg. Testfile.txt,
please have that ready) with the command .
      7za -psmrt1234 Testfile.7z Testfile.txt
 
 2. Test the zipped file.  
      7za | -slt Testfile.7z
 
Provide the screenshot of output of the commands above.

[root@CLDERPAPPD1 ibmrmalik]# 7za -psmrt1234 Testfile.7z Testfile.txt

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz (406F1),ASM,AES-NI)



Command Line Error:
Unsupported command:
Testfile.7z

----------------------------------------------------------------------------------------------------------------------------------------

1 Feb


INC6936945
dysfrdafrq20    10.6.12.32 , IMZ login to this server is failing, Backup affected.



INC7013496    P2 - Major    Ruuning_out_of_available_memory_on_server_ctuboqr3ap02.imzcloud.ibmammsap.local[PROBLEM:1087952
]  10.12.10.111 


INC7013486    P2 - Major    Lack_of_free_swap_space_on_LBDBIPPRDApp2.imzcloud.ibmammsap.local[PROBLEM:10879515]
10.8.8.184



INC7013850    P2 - Major      Lack_of_free_swap_space_on_LBDBIPPRDApp1.imzcloud.ibmammsap.local
10.8.8.183



INC7013656    P2 - Major    Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local
10.133.15.25

hdfc limited loan ac no xxx of ravi malik  nbfc



MSC and name them each DOWNTIME.  This is for SUM upgrade on Solution Manager instance, SD1:
ms3wdcappsd1 - 10.12.6.65 = SR0016651




ms3wdcadbsd1 - 10.12.6.66 = SR0016652




ms3wdcadbsd1 - 10.12.6.66 = SR0016652
-----------------------------------------------------------------------------------------------------------------

3 Feb


INC7001110	Free_disk_space_is_less_than_5%_on_volume_/db2/MP1/db2dump	pn4us7lewmp1	10.12.254.20 sev1

INC6981055	Free_disk_space_is_less_than_5%_on_volume_/db2/MP1/log_dir	pn4us7lewmp1	10.12.254.20

INC7020251	Free_disk_space_is_less_than_5%_on_volume_/var/log		pn4us7lewmp1	10.12.254.20

INC7025450 	Vertex SIC service failing - server restart requested ms3vertexprd1	device restart,  performed already
Infra | 


INC7026799 (edited)	Lack_of_free_memory_on_server_DAL13AMMAD001[
146.89.142.208



INC7027341    P2 - Major    Apple Leisure Group    Lack_of_free_swap_space_on_USSAPASP.imzcloud.ibmammsap.local	10.68.213.14

INC7027239    P2 - Major    IAG GBS Limited    Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local	10.133.15.25

INC7026801    P2 - Major    Limited Brands Inc.    Lack_of_free_swap_space_on_LBDMP1App00.imzcloud.ibmammsap.loca	10.8.8.73


INC7027221  Free_disk_space_is_less_than_10%_on_volume_/var/log	10.12.10.11


INC7029279    P2 - Major    IAG GBS Limited        Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local	10.133.15.24


INC7029584 Manitoba Telecom Services P1-Severe	10.74.6.40
Zabbix_agent_on_r3dev.imzcloud.ibmammsap.local_is_unavailable



SR0016753    AGEAS    AGE-01    (empty)    Request a Service    Medium    SAP-HEC-SWIVEL Increase memory temporarily
Increase the memory of ED1 ( sved1srv0  A0EASG014XVM002 ) & EQ1 (sveq1srv0  A0EASG014XVM001) from 16GB
to 32GB.

-----------------------------------------------------------------------------------------------------

4 Feb

INC7002273
Zabbix_agent_on_agesvbpphsrv1.imzcloud.ibmammsap.local_is_unavailable[
10.6.3.60


INC7002285	10.6.2.72
Zabbix_agent_on_agesvcqmhsrv1.imzcloud.ibmammsap.local_is_unavailable



INC7002281
Zabbix_agent_on_agesveqmhsrv1.imzcloud.ibmammsap.local_is_unavailable
10.6.2.71



INC7002290	10.6.3.58
Zabbix_agent_on_agesvepmhsrv1.imzcloud.ibmammsap.local_is_unavailab



INC7002282	10.6.3.59
Zabbix_agent_on_agesvcpmhsrv1.imzcloud.ibmammsap.local_is_unavailable




INC7035846	146.89.140.178
Node Name:   sng01ammtsm001.imzcloud.ibmammsap.local
Environment: ammprdsng01-imzcloud
FQDN:        sng01ammtsm001.ibmammsap.local
IP:          146.89.140.178
Run List:    role[baseos_satellite], role[sla_cc]
Roles:       baseos_satellite, itcs104, sla_cc


Environment: ammprdsng01-imzcloud
Node Name:   sng01ammtsm001.imzcloud.ibmammsap.local

./bootstrap_v12.sh -o fmsprodinfra -n sng01ammtsm001 -l -d imzcloud.ibmammsap.local -t osonly -e ammprdsng01-imzcloud



INC6981055    Panasonic North America    CMS-SAP    PN4-02    P1 - Severe    PN4        Free_disk_space_is_less_than_5%_on_volume_/db2/MP1/log_dir
10.12.254.20	pn4us7lewmp1


INC7001110    Panasonic North America    CMS-SAP    PN4-02    P1 - Severe    PN4        Free_disk_space_is_less_than_5%_on_volume_/db2/MP1/db2dump[PROBLEM:10863660]    Queued    SQ-SAP-BUILD-MON  @Ravi Malik (3x OS Suppport)
 10.12.254.20	pn4us7lewmp1


INC7033055    Panasonic North America    CMS-SAP    PN4-02    P1 - Severe    PN4        Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:10915208]    Queued    SQ-SAP-BUILD-MON  @Ravi Malik (3x OS Suppport)
10.12.254.20	pn4us7lewmp1


INC7035041    Panasonic North America    CMS-SAP    PN4-02    P1 - Severe    PN4        Free_disk_space_is_less_than_5%_on_volume_/db2/MP1/log_dir[PROBLEM:10918373]    Queued    SQ-SAP-BUILD-MON
10.12.254.40	pn4ushlewmp1



INC7038127    Manchester Airport Group    CMS-SAP    MNG-01    P1 - Severe    MNG    SAP11    Zabbix_agent_on_MNGDRHAN002.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10926481]


INC7038121    Dixons Carphone    CMS-SAP    CPW-01    P1 - Severe    CPW    SAP11    Zabbix_agent_on_dcghanaprddb3.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10926463]


INC7038119    Rexel    CMS-SAP    HGM-02    P1 - Severe    HGM    SAP11    Zabbix_agent_on_rexbfchana1-dr_is_unavailable[PROBLEM:10926466]



INC6990238    TAQA Arabia    CMS-Infrastructure    TQA-01    P3 - Minor    TQA    SAP11    IMZ Login issue    Queued    SQ-SAP-TRIO-11
TQAERPDEVH      10.7.1.33 , IMZ login to this server is failing , Backup affected. Please check
tqa

CHEF_ORG=tqa knife node show TQAERPDEVH.imzcloud.ibmammsap.local
FRA02AMMCHEF01.ibmammsap.local: ~ # CHEF_ORG=tqa knife node show TQAERPDEVH.imzcloud.ibmammsap.local
Node Name:   TQAERPDEVH.imzcloud.ibmammsap.local
Environment: tqa_production
FQDN:        TQAERPDEVH.local.tmg.com
IP:          10.200.0.33
Run List:    role[baseos]
Roles:       baseos, itcs104

FRA02AMMCHEF01.ibmammsap.local: ~ # knife environment list
_default
tqa_production

FRA02AMMCHEF01.ibmammsap.local: ~ # knife node list|grep -i TQAERPDEVH
TQAERPDEVH.imzcloud.ibmammsap.local


./bootstrap_v12.sh -o tqa -n TQAERPDEVH -l -d imzcloud.ibmammsap.local -t osonly -e tqa_production


SR0016821
extend swap size on 4 servers - CI2-M2 customer
CI2DEVAPP -> 16 GB disk need to add
IP :  10.5.242.16
sde                           8:64   0   16G  0 disk

CI2QAAPP -> 40 GB disk
IP :  10.5.242.14
sde                           8:64   0   40G  0 disk

CI2PRDAPP -> 40 GB disk
IP :  10.5.242.12
sde                           8:64   0   40G  0 disk

CI2SOL ->  40 GB disk
IP :  10.5.242.17
sdg                              8:96   0   40G  0 disk


101214946891  Suse case
PEU-A4Q-DB 100.126.65.227

PEU-A4Q-DB-HA 100.126.65.228


----------------------------------------------------------------------------------------------------

5th Feb

Tue, Feb 5, 2019 1:30 PM - 3:30 PM
Location	MTP-G1-Board Room-8F - https://ibm.webex.com/join/gomathinayagam



INC7046137    PANARIAGROUP INDUSTRIE CERAMICHE SP    P1 - Severe    SAP09    pnc1dbhbwpea.imzcloud.ibmammsap.local_has_just_been_restarted




SR0016908
SAP-HEC-SWIVEL : P2- Create directory [0066350/2019]
Please create below directories under /usr/sap/DB0/interfaces/inbound/
on ctubwdb0ap01
 
POS
POS/Archive



SR0016909
SAP-HEC-SWIVEL : Create directory [00066413/2019]
Please create below directories under /usr/sap/QB0/interfaces/inbound/
on application servers
QB0
CTUBWQB0AP01
10.12.10.140
172.22.64.140

CTUBWQB0AP02
10.12.10.139
172.22.64.139

 
POS
POS/Archive


INC7046642
add 1gb to the FS



INC7046803
Unlock and reset odi2sap unix account on mmgras01

------------------------------------------------------------------------------------------------------------------------------

6 Feb


 10.6.12.18 - dyss4apsbd41
useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -s /bin/csh -c "Data Services Agent 01" dsusragt1
useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -s /bin/csh -c "Data Services Agent 02" dsusragt2
useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -s /bin/csh -c "Data Services Agent 03" dsusragt3
useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -s /bin/csh -c "Data Services Agent 04" dsusragt4

useradd -g func -p p@ssw0rd@123 -d /home/DataServiceAgent -m dsusragt1 -s /bin/csh -c "Data Services Agent 01" dsusragt1


@sapsys soft data -1
@sapsys soft nproc -1
@sapsys soft fsize -1
@sapsys soft core 2097151
@sapsys hard data -1
@sapsys hard nproc -1
@sapsys hard fsize -1
@sapsys hard core 2097151

@func soft  

dyss4apsbd41:/home/ibmrmalik # ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 47987
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 47987
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited



10.6.3.12
/dev/mapper/eppappvg-eppusrtrans_lv
                      331G  274G   40G  88% /usr/sap/trans

rename above to trans_old

[root@spsvepaeapp01 sap]# cat /etc/fstab |grep -i /usr/sap/trans
/dev/eppappvg/eppusrtrans_lv    /usr/sap/trans_old ext3   _netdev,defaults    1 2
10.92.99.110:/usr/sap/trans     /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    1 2

[root@spsvepaeapp01 sap]# df -h  /usr/sap/trans
Filesystem            Size  Used Avail Use% Mounted on
10.92.99.110:/usr/sap/trans
                      331G  274G   40G  88% /usr/sap/trans
[root@spsvepaeapp01 sap]# df -h  /usr/sap/trans_old
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/eppappvg-eppusrtrans_lv
                       43G   23G   18G  57% /usr/sap/trans_old




APQ PP server	PTPBATUR	10.70.31.75 
login issue



PRB0045043




INC7043581
Add 1GB  on the /dev/mapper/bdaappvg-usrsap_lv mount  on BDA SAP Host: FBSAPD01FGCL





INC7049845 	sev2
Password never expire applied on ids sftpsap4h and sftpsap4a in November  asp per Siebel ticket 1-344736511 does not hold now, expiring on 10th Feb
10.250.98.11	FBSAPD01FGCL	10.199.98.11	done
10.250.99.11	FBSAPP01FGCL	10.199.99.11	done
10.250.99.13	FBSAPP02FGCL	10.199.99.13	done
10.250.98.13	FBSAPD02FGCL	10.199.98.13	done

 sftpsap4h and sftpsap4a	 
 
------------------------------------------------------------------------------------------------------------------------------

7 Feb


Github issue #214 - CMS 3.x BES client Linux





10.6.12.20	root pw reset and cleaned up /var/log
10.6.12.31	could not login
10.6.12.19	root pw reset and cleaned up /var/log
10.6.12.38	root pw reset


INC7055934  Suncor Energy Inc. P2-Major
Free_disk_space_is_less_than_10%_on_OS_volume_/
10.73.10.128



INC7056738
Please install the NMON tool for OS performance monitoring and the log files should stored in the location /var/log/nmon

Account - PEU
Site - FRA02
Servers -

PEU-AFQ-DB 100.126.65.208
PEU-AFQ-CI 100.126.65.215
PEU-AFQ-CI-HA 100.126.65.207
PEU-AFQ-DB-HA 100.126.65.216



1801207777


INC7056816    Meggitt Plc    P2 - Major
Free_disk_space_is_less_than_10%_on_volume_/usr/sap/NEP



INC7054206    IBM AMM Infrastructure    CMS-Infrastructure    IBMAMMINFRA-03    P1 - Severe            Free_disk_space_is_less_than_5%_on_OS_volume_/
146.89.140.50




SR0017002

On QB2 application server: CTUBWQB2AP01.COTYWW.COM	10.12.10.143	



Need mount point /usr/sap/QB2/interfaces of 50 GB from file share.



Please note that this file system has to be then NFS mounted to all
other application servers of QB2

Please find the below application servers for QB2
CTUBWQB2AP01.COTYWW.COM (PAS)	10.12.10.143	172.22.64.143	
CTUBWQB2AP02.COTYWW.COM (AAS)	10.12.10.144	172.22.64.142
CTUBWQB2AP03.COTYWW.COM (AAS)	10.12.10.142	172.22.64.144
CTUBWQB2AP04.COTYWW.COM (AAS)	10.12.10.141	172.22.64.141

Also, create below directories once filesystem is available.


under /usr/sap/QB2/interfaces/inbound



ChinaCB

ChinaCB/Archive

HFM

HFM/Archive

LuxAsia

LuxAsia/Archive

Mapics

Mapics/Archive

POS

POS/Archive



under /usr/sap/QB2/interfaces/outbound



HERMES

HERMES/Archive

INFOTRACS

INFOTRACS/Archive

TREX

TREX/Archive

ZPLANNING

ZPLANNING/Archive

POS

POS/Archive

This setup and permission needs to be similar to the one done in
QB0(/usr/sap/QB0/interfaces) of (CTUBWQB0AP01/AP02/AP03/AP04)

--------------------------------------------------------------------------------------------------------------------

11 Feb

SR0017205
lv extension task




INC7107377 - CMA CGM - Kindly copy files from SMPOQUAQX8  to SMPODEVDX8




cache clear for SVCS1SRV0


INC7036726    Saudi Business Machines LTD    CMS-SAP    SBM-01    P1 - Severe    SBM        Zabbix_agent_on_sbmimdevsol.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10921651]
10.199.199.17

INC7036752    Saudi Business Machines LTD    CMS-SAP    SBM-01    P1 - Severe    SBM        Zabbix_agent_on_sbmimdeverp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10921718]
10.199.199.14


INC7036755    Saudi Business Machines LTD    CMS-SAP    SBM-01    P1 - Severe    SBM        Zabbix_agent_on_sbmimdeverpas.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:10921719]
10.199.199.13




CHG0094163

SMEDIQUAQU3	10.78.24.32	Mon Feb 11 13:04:46 UTC 2019	Linux smediquaqu3 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Linux smediquaqu3 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Mon Feb 11 14:24:07 UTC 2019
SMGRCQUAQG1	10.78.24.43	Mon Feb 11 13:05:12 UTC 2019	Linux SMGRCQUAQG1 2.6.32-754.9.1.el6.x86_64 #1 SMP Wed Nov 21 15:08:21 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Linux SMGRCQUAQG1 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Mon Feb 11 14:25:59 UTC 2019
SMGWQUAQQ1	10.78.24.14	Mon Feb 11 13:22:51 UTC 2019	Linux smgwquaqq1 2.6.32-754.9.1.el6.x86_64 #1 SMP Wed Nov 21 15:08:21 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Linux smgwquaqq1 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Mon Feb 11 14:25:25 UTC 2019
SMIFAQUAQF1	10.78.24.44	Mon Feb 11 13:24:01 UTC 2019	Linux smifaquaqf1 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux		Linux smifaquaqf1 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Mon Feb 11 14:24:47 UTC 2019
Linux smifaquaqf1 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Mon Feb 11 14:24:47 UTC 2019
SMPOQUAQX8	10.78.24.22	Mon Feb 11 13:24:52 UTC 2019	Linux SMPOQUAQX8 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux		Linux SMPOQUAQX8 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Mon Feb 11 14:28:23 UTC 2019
SMBOQUAQB3	10.78.24.15	Mon Feb 11 13:25:48 UTC 2019	Linux smboquaqb3 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux		Linux smboquaqb3 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux		Mon Feb 11 14:28:53 UTC 2019

------------------------------------------------------------------------------------------------------------------------------

12 Feb


CHG0095376
svjd1srv0	10.6.1.12



1. dyss4dbsbd40   10.6.12.13	no access via imz or root  sapadm might have worked but it is locked

2. dyss4apsbd41 10.6.12.18	access only via sapadm from chef

3. dyss4apsbq21 10.6.12.34 /dev/mapper/rootvg-vloglv  976M  960M     0 100% /var/log   
/dev/mapper/sbqappvg-usrtrans_lv     40G   37G  378M 100% /usr/sap/trans_old
/dev/mapper/sbqappvg-sbqusrSBQ_lv    24G   21G  1.8G  93% /usr/sap/SBQ

4. dysadsdadsq20 10.6.12.33	can login with sapadm only no access via root or imz id al fs have space

5. dysfrdafrd40 10.6.12.22	can login only with sapadm all fs ok but cannot login with root or imz id

6. dysfrdafrq20 10.6.12.32 	could login with imz id
 /dev/mapper/rootvg-homelv                    488M  421M   32M  93% /home







INC7117478
saps11db00      100.126.32.108 
saps11db00:/home/ibmrpradyumnan # systemctl daemon-reload
Failed to execute operation: Activation of org.freedesktop.systemd1 timed out
saps11db00:/home/ibmrpradyumnan #




INC7117979 - Unable to create TR in PS0 due to /usr/sap/trans mount issue in DU1 

4:48:35 PM: Server : SMEDIDEVDU1, 10.78.22.55
Mount issue : /usr/sap/trans 

statfs("/backup", {f_type="EXT2_SUPER_MAGIC", f_bsize=4096, f_blocks=1290144, f_bfree=1254785, f_bavail=1189249, f_files=327680, f_ffree=327669, f_fsid={-1756834869, -380257516}, f_namelen=255, f_frsize=4096}) = 0
statfs("/usr/sap/trans"




INC7098697
lv extend  /sapmnt/shared  10.133.18.180	MGGGBJDECCY02
new disk additiona nd extension of 50GB
[root@MGGGBJDECCY02 ibmrmalik]# df -hT /sapmnt/shared                           Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vghanadata-lv_hana_shared
                     xfs   132G  131G  461M 100% /sapmnt/shared




handvh4ssrv02
handvlb3srv01
handvh4dsrv01	not found
handvh4dsrv02
handvwddsrv01
handvsdtsrv01
handvlb1srv01
handvsdasrv01
handvsdjsrv01
handvlb2srv01
handvlb4srv01
handvh4qsrv01	not found
handvh4qsrv02
handvlb5srv01
handvhppsrv01	not found
handvhppsrv02
handvlb6srv01





INC7118761 - CMA CGM - Kindly copy file from SMPODEVDX8 /usr/sap/trans/SPS13_patches to SMPOSBXSX8

Kindly copy file from SMPODEVDX8  10.78.22.22	 /usr/sap/trans/SPS13_patches to SMPOSBXSX8	10.78.20.20

SMPODEVDX8	10.78.22.22
SMPOSBXSX8	10.78.20.20 




INC7118861
Zabbix_agent_on_r3dev.imzcloud.ibmammsap.local_is_unavailable




Ticket : INC7117160
Description :     please create ticket with Suse linux to know about reboot - On VM - ECP armfksap303a1 (node1-SAP application
Severity : 3
CDIR : ARM


https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W1685fd698977_41e3_a38f_5c601e92ea41/page/3.X Deployment Update (https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/W1685fd698977_41e3_a38f_5c601e92ea41/page/3.X Deployment Update)

10.186.255.76 

8:08:04 PM: root 

8:08:10 PM: FA4bFEQdwT@ 

------------------------------------------------------------------------------------------------------------------------------------------

13 Feb


INC7128375    P2 - Major    SMRT Lack_of_free_swap_space_on_CLDSLDAPPP1.imzcloud.ibmammsap.local
10.198.0.213



CHG0093303	LON02
SSMCI000	10.5.2.10	A0DMUK014XVM001	Linux SSMCI000 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux	  Linux SSMCI000 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Wed Feb 13 08:39:23 GMT 2019   Wed Feb 13 10:25:07 GMT 2019

ECCDAS00	10.5.2.11	A0DMUK014XVM002	Linux ECCDAS00 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux	Linux ECCDAS00 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Wed Feb 13 09:40:29 CET 2019	Wed Feb 13 11:25:09 CET 2019

DPE: Ram RajMuthu Krishnan <ramr@my.ibm.com>
PDL: ramr@my.ibm.com,DTILEA@ro.ibm.com





dyss4apsbq21 Â  10.6.12.34 /dev/mapper/rootvg-vloglv Â 976M Â 960M Â  Â  0 100% /var/log
Â  Â  Â  Â  Â  Â /dev/mapper/sbqappvg-usrtrans_lv Â  Â  40G Â  37G Â 378M 100% /usr/sap/trans_old
Â  Â  Â  Â  Â  Â /dev/mapper/sbqappvg-sbqusrSBQ_lv Â  Â 24G Â  21G Â 1.8G Â 93% /usr/sap/SBQ
Â  Â  Â  Â  Â  Â 
cmsadmin:x:3033:3033:cmsadmin,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/cmsadmin:/bin/bash
sapadm:x:3050:3050:sapadm,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/sapadm:/bin/csh
smdadm:x:3054:3050:smdadm,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/smdadm:/bin/csh
daaadm:x:3051:3050:daaadm,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/daaadm:/bin/csh
sbqadm:x:20210:3050:sbqadm,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/sbqadm:/bin/csh



SR0017560

Please add 3GB space to /usr/sap/hostctrl on below servers

10.6.12.33 dysadsdadsq20
dysadsdadsq20:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/dsqappvg-usrsap_lv  4.0G  251M  3.5G   7% /usr/sap

10.6.12.18 dyss4apsbd41
dyss4apsbd41:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/sbdappvg-usrsap_lv  4.0G  229M  3.6G   6% /usr/sap

10.6.12.34 dyss4apsbq21	no access

10.6.12.22 dysfrdafrd40
dysfrdafrd40:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/frdappvg-usrsap_lv  4.0G  252M  3.5G   7% /usr/sap

10.6.12.32 dysfrdafrq20
dysfrdafrq20:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/frqappvg-usrsap_lv  4.0G  250M  3.5G   7% /usr/sap

10.6.12.21 dyssmdasmd40
dyssmdasmd40:/home/ibmrmalik # df -h /usr/sap/hostctrl
Filesystem                      Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrsap_lv  4.0G  438M  3.3G  12% /usr/sap



SR0017437
Add space to /usr/sap/DAA on 10.6.12.21 <dyssmdasmd40>
dyssmdasmd40:/home/ibmrmalik # df -h /usr/sap/DAA
Filesystem                         Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrsapdaa_lv  2.9G  1.7G  1.2G  60% /usr/sap/DAA


INC7127737
Password reset for 10.6.12.22 (dysfrdafrd40)  & 10.6.12.33 -(dysadsdadsq20) server reboot (15th Feb 2019 @ 9.30pm SGT)7:00 pm IST

dysfrdafrd40:/home/ibmrmalik # df -h /usr
Filesystem                Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-usrlv  6.8G  4.9G  1.6G  76% /usr


dysadsdadsq20:/home/ibmrmalik # df -h /var/log
Filesystem                 Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-vloglv  2.6G  1.3G  1.2G  53% /var/log

dysadsdadsq20:/home/ibmrmalik # df -h /usr
Filesystem                Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-usrlv  6.8G  4.9G  1.6G  76% /usr



INC7129710
Free_disk_space_is_less_than_5%_on_OS_volume_/home[PROBLEM:11047078]

---------------------------------------------------------------------------------------------------------------------

14 Feb


INC7084363
Free_disk_space_is_less_than_20%_on_volume_/usr/sap[PROBLEM:10986577]



SR0017657


imzcloud\ibmrmalik



SR0017623 - RAM + Reboot on server smidmsbxvds  
RAM + Reboot on server smidmsbxvds 
SMIDMSBXVDS, 10.78.20.34 




INC7138279
SAP HEC SWIVEL - sncedevhec001 Domain:network.dev - {Dela[089481/2019]
sncedevhec001 Domain:network.dev - {Delayed Write Failed} \n Windows
was unable to save all the data for the file
\Extend\$UsnJrnl:$J:$DATA. The data has been lost. \n This error may
be caused by a failure of your computer hardware or network
connection.(snow incident ID  :INC0383731)




INC7138637    Manitoba Telecom Services    CMS-SAP    MTS-01    P1 - Severe    MTS    SAP09    Zabbix_agent_on_r3dev.imzcloud.ibmammsap.local_is_unavailable
10.74.6.40


INC7139791    Suncor Energy Inc.    P1-Severe
Free_disk_space_is_less_than_5%_on_volume_/sapstage
10.73.11.80


handvh4ssrv02
handvlb3srv01

handvh4dsrv02
handvwddsrv01
handvsdtsrv01
handvlb1srv01
handvsdasrv01
handvsdjsrv01
handvlb2srv01
handvlb4srv01

handvh4qsrv02
handvlb5srv01

handvhppsrv02
handvlb6srv01





INC7136496
SAP-HEC-SWIVEL 	 unable to connect BSI DEV/QAS server
add 16 GB RAM

---------------------------------------------------------------------------------------------------------------------------------

15 Feb



INC6834167
Account : SDM  - Server not reachable






CHG0094729
JU1-SNG01-NON Prod- Apply Latest Q119 Patches on Linux  Servers
Host Name	CFN IP	Asset Purpose

SNG

SJMDPQJA01	10.198.11.19	Non-Production	A0FGSG014XVM011
Linux sjmdpqja01 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Linux sjmdpqja01 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb 15 09:58:37 UTC 2019
Fri Feb 15 10:31:29 UTC 2019


SJMDWDWD01	10.198.13.10	Non-Production	A0FGSG014XVM013
Linux sjmdwdwd01 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Linux sjmdwdwd01 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb 15 09:58:31 UTC 2019
Fri Feb 15 10:31:26 UTC 2019


Update from CTask: CTASK0088563 02-14-2019 18:14:36 - Albert Thevaraj [MHAS] (Work notes)
Please ignore server SAPDPQDB01 from this change task as it will be patch in change CHG0094728.

DPE: AlbertThevaraj <albert.thevaraj@my.ibm.com>
PDL: albert.thevaraj@my.ibm.com,prabhakardev@in.ibm.com



INC7148265
Zabbix_agent_on_ECCQAS00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:11079379]
10.5.2.12



SR0017669
SAP-HEC-SWIVEL : Share NFS Mountpoint (Temporary) - DEV t
HANDVH4QSRV02 	10.15.192.28	10.23.192.28

Source server IP: 10.100.38.56 
Source mount point: /interface/SAP_PO_FTP 
Target server IP: 10.15.192.28

10.23.192.13:/usr/sap/trans /usr/sap/trans nfs rsize=8192,wsize=8192,timeo=14,intr
10.100.38.56:/interface/SAP_PO_FTP /interface/SAP_PO_FTP nfs vers=4  0       0



Targert mount point: /interface/SAP_PO_FTP Permission R,W,X NFS 
version : NFSv4
10.100.38.56:/interface/SAP_PO_FTP /interface/SAP_PO_FTP


ref handvh4dsrv02
146.89.140.93:/storage/library/ /Staging/sapsft nfs rsize=8192,wsize=8192,timeo=14,intr
10.100.38.56:/interface/SAP_PO_FTP /interface/SAP_PO_FTP nfs rsize=8192,wsize=8192,timeo=14,intr

146.89.140.93:/storage/library/
                      6.6T  2.7T  3.6T  44% /Staging/sapsft
10.100.38.56:/interface/SAP_PO_FTP
                       40G   15G   25G  38% /interface/SAP_PO_FTP
10.100.38.56:/interface/SAP_PO_FTP
                       40G   15G   25G  38% /interface/SAP_PO_FTP




CTASK0089348
OS support During Maintenance Window
10.6.1.12 - svjd1srv0  (please clear os cache)  	A0EASG014XVM003

 clear cache in svld1srv0	10.6.1.20 aswe		A0EASG014XVM010
 
 JQ1 10.6.2.12 imz pwd not working 
 
 
 
 ps -ef|grep vnc   10.6.1.184
 
 
 
 svbq1srv0	10.6.2.14  	A0EASG014XVM018
 
 
 
 10.6.2.12
 
 
 

 
DCG would like an extract of all users {i.e. User ID, Status of the ID, Last log-on date, Last Password Rest date (if available) etc} who has got access to their SAP4HANA Production service {including both application and database servers}. This is request to perform access validation as part of their wider Security remediation exercise.
 
 

PTASK0015038
RCA for J Garcia Carrion 
 
 
 
--------------------------------------------------------------------------------------------------------


18 Feb


CHG0094951  1830-2230
IBM AOD security alert and recommended remediation on Linux OS
DPE: Jazril NaaimMohd Jaffar <jazril@my.ibm.com>

PDL: jazril@my.ibm.com,bogdan.bardos@ro.ibm.com

SMCRMQUAQR3	10.78.24.21	QA
Linux smcrmquaqr3 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux	Mon Feb 18 13:41:32 CET 2019
Linux smcrmquaqr3 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux Mon Feb 18 15:18:25 CET 2019

SMSLTQUAQK1	10.78.24.39	QA
Linux SMSLTQUAQK1 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux	Mon Feb 18 12:44:22 UTC 2019
Linux SMSLTQUAQK1 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux Mon Feb 18 14:21:37 UTC 2019

SMBWQUAQW3	10.78.24.41	QA
Linux SMBWQUAQW3 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux	Mon Feb 18 12:47:48 UTC 2019
Linux SMBWQUAQW3 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux	Mon Feb 18 14:12:53 UTC 2019

SMDSQUAQO1Q71	10.78.24.27	QA
Linux smdsquaqo1q71 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux  Mon Feb 18 07:50:08 EST 2019
Linux smdsquaqo1q71 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux Mon Feb 18 09:15:10 EST 2019	

SMECCQUAQE1	10.78.24.19
Linux smeccquaqe1 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux	Mon Feb 18 13:53:33 CET 2019
Linux smeccquaqe1 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux Mon Feb 18 15:24:22 CET 2019

SMEMQUAQM3	10.78.24.26	QA
Linux smemquaqm3 2.6.32-754.9.1.el6.x86_64 #1 SMP Wed Nov 21 15:08:21 EST 2018 x86_64 x86_64 x86_64 GNU/Linux	Mon Feb 18 12:55:29 UTC 2019
Linux smemquaqm3 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux  Mon Feb 18 14:22:42 UTC 2019







PEU-A4Q-DB 100.126.65.227

PEU-A4Q-DB-HA 100.126.65.228

----------------------------------------------------------------------------------------------------------------------------------

20 Feb

SR0018054
URGENT: Need SAP and Linux Resources to help troubleshoot SAP printer issues on QA servers. 
Need SAP and Linux Resources to help troubleshoot SAP printer issues on QA servers.   Call will begin at 9:30 EST AM. 

Affected Printers: MX01, ZM15, OF01

Affected Servers: PN4US7LECCQP.us.panasonic.com
PN4US7EWMQP.us.panasonic.com	10.12.254.151
pn4us7lewmqp:/home/ibmrmalik # lpstat -pMX01
printer MX01 disabled since Tue Feb 19 19:20:51 2019 -
        Unable to connect to CIFS host after (tried 3 times)


Call Details:

+1 (770) 302-2333 (USA)                   English (United States) 
+1 (770) 486-2222 (USA)                    English (United States)  



server 10.140.34.44  

8:20:06 AM: printer MX01
DeviceURI smb://papaprint:eM%2B49%21%26%24@AMERICA/10.140.34.44/OF01
DeviceURI smb://papaprint:eM%2B49%21%26%24@AMERICA/10.140.34.44/ZM15
DeviceURI smb://AMERICA%5CPAPAPRINT:eM%2B49%21%26%24@10.140.34.44/MX01


lpstat -p MX01

/etc/cups/printers.conf

/etc/samba


10.140.34.44/MX01
ID - AMERICA\papaprint
Pass - eM+49!&$  

smb://AMERICA\papaprint:eM+49!&$@10.140.34.44/MX01




SR0018128    Low    Suncor Energy Inc.    SNC-02    SNCHBIBTD11    Request a Service    Low    File System Increase: SID :T1B / HOST NAME: SNCHBIBTD11 / IFN: 10.73.11.28


INC7187876    P2 - Major    Limited Brands Inc.        Ruuning_out_of_available_memory_on_server_LBDBOPPRDApp3.imzcloud.ibmammsap.local
10.8.8.89




SR0017991
SAP-HEC-Swivel:Increase CPU/memory HME, HQE, HPE
Please increase the CPU and memory on the 5 apps servers for HME, HQE
and HPE from 64X12 to 128X32
Please add 64GB of memory and 8 vCPUs to each of the apps 1-5 on HQE, HME and HPE

HPE - CI App1 
dlthpehp1.hrhec.delta.com 10.250.17.53 HPE - App2	A0DBUS014XVM017 done
dlthpehp2.hrhec.delta.com 10.250.17.54 HPE - App3	A0DBUS014XVM018	done
dlthpehp3.hrhec.delta.com 10.250.17.55 HPE - App4	A0DBUS014XVM019	done	
dlthpehp4.hrhec.delta.com 10.250.17.56 HPE - App5	A0DBUS014XVM020 done
DLTHPEHP5.hrhec.delta.com 10.250.17.44 HME - CI App	done
DLTHMEHAP.hrhec.delta.com 10.250.17.49 HME - App2	done
dlthmehap2.hrhec.delta.com 10.250.17.31 HME - App3	hotplug disabled cannot change CPU MEM without reboot
dlthmehap3.hrhec.delta.com 10.250.17.19 HME - App4	hotplug disabled cannot change CPU MEM without reboot
dlthmehap4.hrhec.delta.com 10.250.17.23 HME - App5	hotplug disabled cannot change CPU MEM without reboot	
dlthmehp5.hrhec.delta.com 10.250.17.13			hotplug disabled cannot change CPU MEM without reboot
HQE - CI App1 
dlthqehap.hrhec.delta.com 10.250.17.33 HQE - App2	A0DBUS014XVM012 done
dlthqehap3.hrhec.delta.com 10.250.17.38 HQE - App3		A0DBUS014XVM026 done
dlthqehap4.hrhec.delta.com 10.250.17.39 HQE - App4		A0DBUS014XVM027 done
DLTHQEHAP2.hrhec.delta.com 10.250.17.37 HQE - App5		A0DBUS014XVM025 done
dlthqehap5.hrhec.delta.com 10.250.17.46			hotplug disabled cannot change CPU MEM without reboot




SR0018152
Request to setup mount points in SBD to map to FTP server folders
SBD App	dyss4apsbd41	10.6.12.18
ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP

10.1.161.14  10.6.11.14(imz)  WIndows server DYSFTPDAPRD01

ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\IBP



INC6892848 â€“ non sap - os team	Processor_load_is_too_high_on_DYSDCR01[PROBLEM:10669137]


INC6925769 â€“ non sap â€“ OS team  Processor load is high



INC6634175 â€“ non sap â€“ os team

--------------------------------------------------------------------------------------------------------------------------

21 Feb

INC7196217    COTY Inc.    P3 - Minor    SAP HEC Swivel : SB3-: 099904/2019
please check if below Coty server is reachable from SB3
HANA ? If not, you might have to check the power DNS. Server details:
10.73.4.137- ussalxsap192t.cotyww.com Please also send the response
to below commands from SB3 HANA
 
nslookup ussalxsap192t
 
telnet ussalxsap192t.cotyww.com 5050 telnet ussalxsap192t.cotyww.com
5051
 
 
ctubwsb3db01:/home/ibmrmalik # nslookup ussalxsap192t
;; Got SERVFAIL reply from 146.89.142.12, trying next server
Server:         146.89.142.13
Address:        146.89.142.13#53

** server can't find ussalxsap192t: SERVFAIL

ctubwsb3db01:/home/ibmrmalik # telnet ussalxsap192t.cotyww.com 5050
Trying 10.73.4.137...
Connected to ussalxsap192t.cotyww.com.
Escape character is '^]'.
'^]'
Connection closed by foreign host.

ctubwsb3db01:/home/ibmrmalik # telnet ussalxsap192t.cotyww.com 5051
Trying 10.73.4.137...
telnet: connect to address 10.73.4.137: Connection refused




INC7198756  - Sev1 - CON - IC4SAP-SL - Service Now Ticket - Not Validated - S4P: The Printers Are Not Working

printer Queue  -  LP01 
consps4happ.riogaleao.net 
FQDN

SL-SAOPAULO-SAO01

/etc/cups/printers.conf

/etc/samba



SR0018214    Raycap GmbH    High    Set the password to never expired
deeh11ryc1008 10.7.64.19: raycapdb



SR0018294
SUNCOR: Extending FS for host SNCHBDWQW11
Host : SNCHBDWQW11	10.73.12.86
FS : /usr/sap        ADD 20GB

PDL approved to extend FS and add disk if needed.




INC7168947
Processor_load_is_too_high_on_DYSD3DAD3D40[PROBLEM:11122236]
10.6.12.50		win




INC7196218
Free_disk_space_is_less_than_10%_on_volume_/usr/sap[PROBLEM:11194466]
10.69.0.18




INC7117655
FS_is_read_only_on_dysadsdadsd40.imzcloud.ibmammsap.local[PROBLEM:1102821
10.6.12.19
dysadsdadsd40:/home/ibmrmalik # sh /var/lib/zabbix/check_rw_mounts.sh
rm: cannot remove '/home/dsdadm/.gvfs/testfile': Permission denied
CRITICAL |  /home/dsdadm/.gvfs filesystems are read-only



 INC7193395    CMA CGM    P1 - Severe    Free_disk_space_is_less_than_5%_on_OS_volume_/home
 10.78.24.13




INC7193393    CMA CGM    P2 - Major    Free_disk_space_is_less_than_10%_on_OS_volume_/home
10.78.24.13




INC7200487    MSC Industrial Supply Co.    P3 - Minor    NTP_time_is_driffted_on_ms3wdclapp34.imzcloud.ibmammsap.local
10.12.7.19



NC7200128
Free_disk_space_is_less_than_20%_on_volume_/var/log[PROBLEM:11205554]



INC7201040
Lack_of_free_swap_space_on_fbtprdhanapp2.imzcloud.ibmammsap.local[PROBLEM:11207468]
10.4.27.14

--------------------------------------------------------------------------------------------------------------------------------

22 Feb

INC7204085    Aceros Chilca - MEPSA    P3 - Minor    AV Notification : VM - Salesforce is not reporting to Trend  DSM manager
VM - SALESFORCE 

IP Details : 128.0.4.32		10.4.11.32	 win 2k12R2




INC7206854    IAG GBS Limited    P2 - Major    Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local
10.133.15.25



INC7203829    Wakefern Food Corporation    P2 - Major    IMZ login issue
wkfsltadb1      10.139.100.65 , IMZ login to this server is not working. Please check


SR0018214
Set the password to never expired 


INC7207549    Limited Brands Inc.    P2 - Major    Ruuning_out_of_available_memory_on_server_LBDBOPPRDApp3.imzcloud.ibmammsap.local
10.8.8.89



INC7209020   sev3
Allow "BOQADM" user to login to below users and reset the password to "Security#1"
LBDBOQQASAPP1	10.8.8.57
LBDBOQQASAPP2	10.8.8.58
LBDBOQQASAPP3	10.8.8.59
LBDBOQQASAPP4	10.8.8.60 ( Windows )




INC7209335    IAG GBS Limited    P2 - Major    Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local
10.133.15.24



INC7209484/P2/IBM AMM SAP Client Tribe Infrastruc/Service now Monitoring ticket not validated/Processor_load_is_too_high_on_dal09ammsol02.imzcloud.ibmammsap.local 
146.89.140.29 



Referance: 10.6.3.12 (Target2 working system)
Ticket: INC7014256 
Source : 10.6.1.14 - /usr/sap/trans    coming from SVED1SRV0 	10.6.1.11	10.92.99.110
mounted on Target 1 & target 2
Target 1 : 10.6.2.14
Target 2 ; 10.6.3.18 


Source: 10.6.1.14	/usr/sap/trans	SVBD1SRV0 	10.6.1.14	10.92.99.113
Target1: 10.6.2.14	svbq1srv0
Target2: 10.6.3.18 	spsvbpabapp01

11:04:44 AM: Target 2 : BPPADM user should be able to read all files 

 


[root@spsvepaeapp01 trans]# cat /etc/fstab |grep -i /usr/sap/trans
/dev/eppappvg/eppusrtrans_lv    /usr/sap/trans_old ext3   _netdev,defaults    1 2
10.92.99.110:/usr/sap/trans     /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    1 2


10.92.99.110:/usr/sap/trans     /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    1 2



SR0018134  access issue fixed
Create local FS as specified
SID 	Hostname 	File system Name  Size         IBM IP address 	Customer IP
BP1 	LBDBP1DB02 	/export/BP1 	500GB 	10.8.8.76 	10.65.2.76
CP1 	LBDCP1DB02 	/export/CP1 	100GB 	10.8.8.70 	10.65.2.70
	FP1 	LBDFP1PRDDB1 	/export/FP1 	100GB 	10.8.8.66 	10.65.2.66
SP1 	LBDSP1DB02 	/export/SP1 	500GB 	10.8.8.62 	10.65.2.62
	TP1 	LBDTP1PRDAPP1 	/export/TP1 	100GB 	10.8.8.80 	10.65.2.80
	PP1 	LBDPP1DB02 	/export/PP1 	100GB 	10.8.8.82 	10.65.2.82



INC7209148    IAG GBS Limited    P3 - Minor    NTP_time_is_driffted_on_IA1POQASAPP.imzcloud.ibmammsap.local[
10.133.17.145


----------------------------------------------------------------------------------------------------------------------------------

24 Feb


INC7224231 & INC7224623
MSD:URL: URL Status: 500: unspecified server error

----/sapmnt/log/XVT/mnt00001/hdb00001  

10.133.18.178    
/sapmnt/log/XVT/mnt00001/hdb00001

  4304 Feb 19 03:31 messages.6.gz
-rw-------  1 root   root       4142 Feb 20 03:41 messages.5.gz
-rw-------  1 root   root       4641 Feb 21 03:39 messages.4.gz
-rw-------  1 root   root       4903 Feb 22 03:25 messages.3.gz
-rw-------  1 root   root      56948 Feb 23 03:29 messages.1
-rw-------  1 root   root       5051 Feb 23 03:38 messages.2.gz
-rw-------  1 root   root     165695 Feb 24 01:49 messages



INC7227905    P2 - Major    IAG GBS Limited        Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local
10.133.15.24


INC7225776    P2 - Major    Limited Brands Inc.    Ruuning_out_of_available_memory_on_server_LBDBOPPRDApp3.imzcloud.ibmammsap.local
10.8.8.89
cancel the ticket as the Server is being decomm


INC7228437    P1 - Severe    PANARIAGROUP INDUSTRIE CERAMICHE SP        FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local
10.199.1.30



INC7193366
Please provide the resource usage history for below servers on priority
 balajikr11@in.ibm.com, rakkorap@in.ibm.com
RAM and CPU for last 1 month

yhieds01
yhibwds01
YHIBIDS01
YHISMDS01
yhiwdds01
yhieqs01
yhieps01
yhibwps01
YHIBIPS01
yhiwdps01



INC7228960    P2 - Major    IAG GBS Limited Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local
10.133.15.24


INC7230035    P2 - Major    IAG GBS Limited    Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local
10.133.15.24


--------------------------------------------------------------------------------------------------------------------------------------

25 Feb

Performance report
yhieds01
yhibwds01
YHIBIDS01
YHISMDS01
yhiwdds01
yhieqs01
yhieps01
yhibwps01
YHIBIPS01
yhiwdps01




INC7235522    P2    IBM AMM SAP Client Tribe Infrastruc Processor_load_is_too_high_on_WDC04AMMSOL04.imzcloud.ibmammsap.local
146.89.142.36


INC6634175
Processor_load_is_too_high_on_DYSFTPDAPRD01[PROBLEM:10183521]


INC7074670	scheduled reboot activity

INC7201057
FS_is_read_only_on_dyssmdasmd40.imzcloud.ibmammsap.local[PROBLEM:11207512]
10.6.12.21


INC7235161	scheduled reboot activity 

INC7219584	
Processor_load_is_too_high_on_DYSD3DAD3D40[PROBLEM:11251517]
10.6.12.50


SR0018519
Please add 10GB to each of the below file systems on dyssmdasmd40 <10.6.12.21>

/sybase/SMA/sapdata1 
/sybase/SMA/sapdata2 
/sybase/SMA/sapdata3 
/sybase/SMA/sapdata4 
/sybase/SMA/saplog1 

dyssmdasmd40:/home/ibmrmalik # df -h /sybase/SMA/sapdata1
Filesystem                            Size  Used Avail Use% Mounted on
/dev/mapper/smadatavg-smasapdata1_lv   38G   27G  9.2G  75% /sybase/SMA/sapdata1
dyssmdasmd40:/home/ibmrmalik # df -h /sybase/SMA/sapdata2
Filesystem                            Size  Used Avail Use% Mounted on
/dev/mapper/smadatavg-smasapdata2_lv   38G   27G  9.2G  75% /sybase/SMA/sapdata2
dyssmdasmd40:/home/ibmrmalik # df -h /sybase/SMA/sapdata3
Filesystem                            Size  Used Avail Use% Mounted on
/dev/mapper/smadatavg-smasapdata3_lv   38G   27G  9.2G  75% /sybase/SMA/sapdata3
dyssmdasmd40:/home/ibmrmalik # df -h /sybase/SMA/sapdata4
Filesystem                            Size  Used Avail Use% Mounted on
/dev/mapper/smadatavg-smasapdata4_lv   38G   27G  9.2G  75% /sybase/SMA/sapdata4
dyssmdasmd40:/home/ibmrmalik # df -h /sybase/SMA/saplog1
Filesystem                          Size  Used Avail Use% Mounted on
/dev/mapper/smalogvg-smasyblog1_lv   28G   21G  6.1G  77% /sybase/SMA/saplog1





INC7200338	TSM
INC7200359	TSM
INC7174011	closed alreday by TSM


INC7236112    P3 - Minor    Egyptian Refining Company



Node Name:   DLBQECAP01.imzcloud.ibmammsap.local
Environment: _default
FQDN:        DLBQECAP01.dilipbuildcon.co.in
IP:          172.16.22.12
Run List:
Roles:
Recipes:
Platform:    redhat 6.9
Tags:
[root@CHE01AMMCHEF  

1:35:06 PM: seems environment assigned is incorrect  

1:35:46 PM: [root@CHE01AMMCHEF01 ~]# knife environment list
_default
dlb_production


./root/bootstrap_v12.sh -o dlb -n DLBQECAP01 -l -d imzcloud.ibmammsap.local -t osonly -e dlb_production


---------------------------------------------------------------------------------------------------------------------------------------

26 Feb


INC7240672    P3 - Minor    Suncor Energy Inc.
SAP-HEC-Swivel:File system read-only in PN1 - app12
We have an issue where the below file systems are read/ write from
snchtnapa11	10.73.10.109		 while read -only from snchtnapa12	10.73.10.110
 
nasprdstj001v2:/ifs/cifs/file136/corp/East_Coast/SAP/SAPReports
                      333T  202T  124T  62%
/SHARE/MNT/FILE136/SAPReports
nasprdstj001v2:/ifs/cifs/file136/corp/Finance/Department/Terra
Nova/VisionCraft                       333T  202T  124T  62%
/SHARE/MNT/FILE136/VisionCraft 
 


DYSWDAPWDD40	could login with sapadm
/dev/mapper/rootvg-vloglv           976M  677M  232M  75% /var/log  need space addition
/dev/mapper/rootvg-usrlv            5.8G  4.9G  656M  89% /usr	need space addition

RAM increase recommended
dyswdapwdd40 /home/sapadm% free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          0          1          5
-/+ buffers/cache:          3          7
Swap:           35          0         35



DYSWDAPWDQ20
/dev/mapper/rootvg-usrlv            5.8G  4.9G  657M  89% /usr    need space addition
RAM upgrade recomended
dyswdapwdq20 /home/sapadm% free -g
             total       used       free     shared    buffers     cached
Mem:            23         22          0          0          1         17
-/+ buffers/cache:          3         19
Swap:           47          0         47


DYSS4APSBQ21
RAM upgrade recomended
dyss4apsbq21 /home/sapadm% free -g
             total       used       free     shared    buffers     cached
Mem:            23         23          0          5          1         10
-/+ buffers/cache:         11         12
Swap:           47          0         47

/dev/mapper/rootvg-usrlv            5.8G  4.9G  657M  89% /usr
/dev/mapper/rootvg-homelv           488M  385M   69M  85% /home
/dev/mapper/rootvg-vloglv           976M  960M     0 100% /var/log
/dev/mapper/sbqappvg-usrtrans_lv     40G   37G  378M 100% /usr/sap/trans_old
/dev/mapper/sbqappvg-sbqusrSBQ_lv    24G   21G  1.8G  93% /usr/sap/SBQ




DYSS4DBSBD40




INC7244484  -  P2
Processor_load_is_too_high_on_DLBPSMDA00.imzcloud.ibmammsap.local[PROBLEM:11319264]


INC7244548  -  P2
Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:11319429]
10.133.15.24
-----------------------------------------------------------------------------------------------------------------------

27 Feb


INC7252223    P2 - Major    AGEAS    Lack_of_free_swap_space_on_spsvspdsase01.imzcloud.ibmammsap.local
10.6.3.32


INC7252193    P2 - Major    Suncor Energy Inc.    Processor_load_is_too_high_on_snchgraqa11.imzcloud.ibmammsap.local
10.73.12.35



SR0018716 - SUNCOR : Extend FS for host SNCHTNAQD11 (QN1)

SNCHTNAQD11	10.73.12.76

FS  :   /sybase/QN1   ADD  20 GB




INC7253026
Adani NTP issueon HANA

ADNABPDB	10.198.200.21



CHG0097248 
restart of server for a change


imzcloud\ibmrmalik



SNCHDSBQA11	10.73.12.46	cant connect
SNCHDSBQA12	10.73.12.47
SNCHDSBQA13	10.73.12.48

-------------------------------------------------------------------------------------------------------------------------
28 Feb

INC7244610
Snapshots
DEC
DLBDECAP01	10.13.2.14   App Host
DLBDECDB00	10.13.2.13  DB host	172.16.22.13	chehana-1024-01.xsportal.local
Private IP: 10.162.24.196
root/gVFlJIEIsz@

chehana-1024-03.xsportal.local
(Chennai 1)
Private IP: 10.162.24.199
root/qcYQ0aQPWJ@


DBW
DLBDBWAP01	10.13.2.20  App Host
DLBDBWDB00	10.13.2.19  DB host 	172.16.22.95	dlbqbwdb01	10.13.2.40




SEV1
INC7260461    Incident  ==> @Ravi Malik (3x OS Suppport)
Zabbix_agent_on_eccpdb00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:11367003]
10.5.2.20



SEV1
INC7259917    Incident  ==> @Ravi Malik (3x OS Suppport)
Zabbix_agent_on_eccpdb00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:11365524]


saphana128, aasdemo002, sydo1tets1



INC7261259    MSC Industrial Supply Co.    P2 - Major    Lack_of_free_swap_space_on_ms3wdcladb27.imzcloud.ibmammsap.local[
10.12.6.46


SR0018794
dlthmehap 10.4.5.49
CHEF_ORG=dal knife node show DLTHMEHAP.imzcloud.ibmammsap.local
Node Name:   DLTHMEHAP.imzcloud.ibmammsap.local
Environment: dal_production
FQDN:        DLTHMEHAP.imzcloud.ibmammsap.local
IP:          10.250.17.49
Run List:    role[baseos]
Roles:       baseos, itcs104

knife node delete -y DLTHMEHAP.imzcloud.ibmammsap.local;knife client delete -y DLTHMEHAP.imzcloud.ibmammsap.local
./root/bootstrap_v12.sh -o dal -n DLTHMEHAP -l -d imzcloud.ibmammsap.local -t osonly -e dal_production
DLTHMEHAP.IMZCLOUD.IBMAMMSAP.LOCAL:hmeadm 51>



dlthmehap2 10.4.5.31
dlthmehap3 10.4.5.20
dlthmehap4 10.4.5.25
dlthmehap5 10.4.5.58   



SR0018830
provisioned space for servers of 7 servers





SR0018778    American Airlines    Medium    SAP HEC Swivel : P3: Add 4 CPUs and 32GB RAM to PQ2-0000118581/2019
 
Please perform below infrastructure changes to PQ2 system Increase
storage on #/interface# directory (AL11) by 100GB for PQ2 Add 4 CPUs
and 32GB RAM to  PQ2
AHECQ2SAP01
/dev/mapper/pq2appvg-pq2Intface_lv
                       98G   33G   60G  36% /interface/PQ2
                       
exixting CPU  4			new CPU expected is 8
existing RAM  32GB		new RAM expected is 64 GB
                       
                       

SR0018833    Dilip Buildcon Limited    Low    Mounting of /Bank folder from DWD to QEC
Mounting of /Bank folder from DWD to QEC
Please mount /Bank folder from Web Dispatcher development to QEC application server 
DLBDWDAP00	10.13.2.24  DWD webdispatcher
DLBQECAP01	10.13.2.12  QEC 

172.16.22.24:/Bank         nfs4   rw,soft,timeo=30,rsize=8192,wsize=8192 0

172.16.22.24:/Bank     /Bank nfs   defaults       0 0

CHEF_ORG=dlb knife node show DLBQECAP01.imzcloud.ibmammsap.local

Node Name:   DLBQECAP01.imzcloud.ibmammsap.local
Environment: dlb_production
FQDN:        DLBQECAP01.dilipbuildcon.co.in
IP:          172.16.22.12
Run List:
Roles:
Recipes:
Platform:    redhat 6.9
Tags:

knife node delete -y DLBQECAP01.imzcloud.ibmammsap.local;knife client delete -y DLBQECAP01.imzcloud.ibmammsap.local
-o dlb -n DLBQECAP01 -l -d imzcloud.ibmammsap.local -t osonly -e dlb_production


CHG0097451
MGGGBJDGTSX03 / 10.133.18.191 (SAP Application)
MGGGBJDGTSX04 / 10.133.18.192 (Hana database)

OS engineer:
2. On host MGGGBJDGTSX04 backup /etc/security/limits.conf  file and change stack size of jgdadm user from unlimited to value 8192 as per SAP Note 2488924
jgdadm          -       nofile          1048576
smdadm          hard    stack           8192


3. Restart host MGGGBJDGTSX04
Note: Check that "stack size" default value is set after the host restart.

-----------------------------------------------------------------------------------------------------------------------------------

4 Mar


INC7295405    Suncor Energy Inc.    P1 - Severe    Zabbix_agent_on_snchecapa18.imzcloud.ibmammsap.local_is_unavailable
10.73.10.22


INC7295404    Suncor Energy Inc.    P2 - Major    Processor_load_is_too_high_on_snchecaqa18.imzcloud.ibmammsap.local
10.73.12.18




INC6983389  df -h and nfs access issue
statfs("/storage",




dcghanaprdap1
cpw
CHEF_ORG=dcg knife node show dcghanaprdap1.imzcloud.ibmammsap.local

cpw_production
[root@LON02AMMCHEF01 ~]# knife node list|grep -i dcghanaprdap1
DCGHANAPRDAP1.imzcloud.ibmammsap.local

knife node delete -y DCGHANAPRDAP1.imzcloud.ibmammsap.local;knife client delete -y DCGHANAPRDAP1.imzcloud.ibmammsap.local

-o cpw -n dcghanaprdap1 -l -d imzcloud.ibmammsap.local -t osonly -e cpw_production




INC7295173	Difference in timing between Source system and BW system.
ADNAELAPP1 10.198.200.12
ADNAELAPP2 10.198.200.11
ADNAELDB 10.198.200.20

ADNABPAPP1 10.198.200.13
ADNABPAPP2 10.198.200.14
ADNABPDB 10.198.200.21





INC7202085   sev2
Unable to connect to server : IMZ login issue



INC7296455 sev2
SUNCOR:  unable to access teh file structure at OS level for the produciton application PR1
SNCHECAPA12	10.73.10.16
statfs("/SAP_ARCHIVE",
[root@snchecapa12 ~]# cat /etc/fstab |grep -i /SAP_ARCHIVE
10.146.96.46:/SAP_SBO/SAP_ARCHIVE/PROD /SAP_ARCHIVE nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0


10.73.10.17  NFS is ok
[root@snchecapa13 ~]# cat /etc/fstab |grep -i /SAP_ARCHIVE
10.146.96.46:/SAP_SBO/SAP_ARCHIVE/PROD /SAP_ARCHIVE nfs rw,hard,intr,rsize=32768,wsize=32768,nfsvers=3,proto=tcp,sec=sys,retrans=5,timeo=600 0 0

	10.73.10.18
	10.73.10.19
	10.73.10.20
	10.73.10.21
	10.73.10.22
10.73.10.23
	10.73.10.24



INC7297244    needs to be transferred to IBM Security / OS Linux team for account reset


----------------------------------------------------------------------------------------------------------------------------------

5 March

SBD App	dyss4apsbd41	10.6.12.18
ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP


INC7302309    P1 - Severe    Meggitt Plc        Zabbix_agent_on_MGGGBJPECCX10.imzcloud.ibmammsap.local_is_unavailable


INC7301915   dyss4apsbq21 in SNG
root pw reset and vmtoolpdation
dyss4apsbq21	10.6.12.34
found the version of vmtools from working server, searched for the iso on chef regional server and then followed the steps in that wiki link 

 503  2018-11-13 14:58:57 vmware-uninstall-tools.pl
  504  2018-11-13 14:59:46 mkdir /mnt/vmware-tools
  505  2018-11-13 15:00:25 mount -o loop /tmp/VMware-Tools-10.1.10-core-6082533.iso /mnt/vmware-tools/
  506  2018-11-13 15:00:54 cp /mnt/vmware-tools/VMwareTools-10.1.10-6082533.tar.gz /tmp/
  507  2018-11-13 15:01:03 cd /tmp/
  509  2018-11-13 15:01:57  tar -xzvf VMwareTools-10.1.10-6082533.tar.gz
  510  2018-11-13 15:02:07 cd vmware-tools-distrib/
  511  2018-11-13 15:02:19 ./vmware-install.pl --default
  
  




INC7302575    Meggitt Plc    P1 - Severe    SAP10  
Zabbix_agent_on_MGGGBJQECCX01.imzcloud.ibmammsap.local_is_unavailable



INC7254488

/backup
10.201.0.12:/backup   /backup  nfs4   rw,soft,intr,rsize=32768,wsize=32768    0       0




INC7303493    Suncor Energy Inc.    P2 - Major    SAP12    Processor_load_is_too_high_on_snchcuata11.imzcloud.ibmammsap.local
10.73.11.69




CHEF_ORG=cma knife node show smecctrnte1.imzcloud.ibmammsap.local
Node Name:   smecctrnte1.imzcloud.ibmammsap.local
Environment: cma_production
FQDN:        smecctrnte1.blx.cma-cgm.com
IP:          10.5.28.17


[root@PAR01AMMCHEF01 ~]# knife environment list
_default
cma_production


smecctrnte1.imzcloud.ibmammsap.local

knife node delete -y smecctrnte1.imzcloud.ibmammsap.local;knife client delete -y smecctrnte1.imzcloud.ibmammsap.local

-o cma -n smecctrnte1 -l -d imzcloud.ibmammsap.local -t osonly -e cma_production




CHG0096399
A1A-DAL09-NON Prod- Apply Latest Q119 Patches on Linux  Servers
A1AERPPD2AP01	10.4.10.58
	
	
A1AXD2PI01	10.4.10.67	OK
10.100.2.56:/interface/PD2
                       61G   34G   24G  60% /interface/PD2


-------------------------------------------------------------------------------------------------------------------------------------

6 Mar


INC7307678 - SL-Frankfurt-02 - TAQA Arabia (TQA) - AMM-SAP - SAP: HED-TQAERPDEV_HED_00:Ins:HED: an alert of class:System occured. Lost connection to mySAP system
FRAnkfurt
TAQA Arabia (TQA) 	TQAERPDEVH 	10.7.1.33  
 GSSAPI Error: Unspecified GSS failure.  Minor code may provide more information (Server not found in Kerberos database)
 Need to update a conf file permanently via chef receipe Squad: Chef Infra #2087


INC7201370 
ITM Agent Offline: IA1PODEVAPP
10.133.16.32



INC7201399
ITM Agent Offline: SQ1-ia1s4hqa:ia1s4hqasapp:mySAP
10.133.17.140



INC7309363 Raycap GmbH P1-Severe Zabbix_agent_on_deeh11ryc1009.imzcloud.ibmammsap.local_is_unavailable
10.7.64.17


INC7309919 Raycap GmbH P1
Zabbix_agent_on_deeh11ryc1009.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:11520306]
10.7.64.17


INC7310317  Zabbix_agent_on_deeh11ryc1009.imzcloud.ibmammsap.local_is_unavailable
10.7.64.17


INC7310468    Raycap GmbH    P1-Severe
Zabbix_agent_on_deeh11ryc1009.imzcloud.ibmammsap.local_is_unavailable
10.7.64.17


INC7308164
reboot and pw reset

WDD - dyswdapwdd40	10.6.12.20




INC7310767    Raycap GmbH    P1-Severe





username=YSRVSAPEC,password=EC_SAP00
SR0018152
Request to setup mount points in SBD to map to FTP server folders
SBD App	dyss4apsbd41	10.6.12.18
ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP

10.1.161.14  10.6.11.14(imz)  WIndows server DYSFTPDAPRD01

ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\IBP

//10.1.161.14/Dystar-FTP\S4HANA_DC\SBD\FC /usr/sap/s4hana/SBD/S4HANA_DC/FC  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003

mount -t cifs //10.1.161.14/Dystar-FTP\S4HANA_DC\SBD\FC /usr/sap/s4hana/SBD/S4HANA_DC/FC \osec=ntlmv2,domain=MYDOMAIN,username=myusername,password=mypassword


---------------------------------------------------------------------------------------------------------------------------------------
7 Mar

INC7316035 - Password reset for 10.6.12.31 DYSWDAPWDQ20 server reboot (7th March 2019 @ 4.30pm SGT) 



INC6991650
Error on FS  updated vmtools 




INC7317423    Limited Brands Inc.    P2 - Major
Lack_of_free_swap_space_on_LBDMQ1App00.imzcloud.ibmammsap.local
10.8.8.20



CHG0096406
AHBSISBX01	patching    A0F0US014XVM018   10.4.10.12



CHG0096407
A0F0US014XVM026	AHFIQSAP01	10.4.10.32
		
		
A0F0US014XVM021	AHPOQSAP01	10.4.10.33
10.4.10.21:/usr/sap/trans
                      247G  135G  100G  58% /usr/sap/trans
10.100.2.31:/interface/PYQ
                       99G   67G   27G  72% /interface/PYQ
                       
                       [root@AHPOQSAP01 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /interface/PYQ /interface/PYQ filesystems are read-only

AHECQSAP01 	10.4.10.31	10.100.2.31

	
		
A0F0US014XVM029	AHECQSAP01	10.4.10.31



CHG0099127
Task - CTASK0093778 - set to inprogress & take VM snapshot (after 5min ) 
VM snapshot of spsvepajapp01 - 10.6.3.13




INC7259993
backup failure VMtools upn



INC7318385    AGEAS    P1 - Severe    Zabbix_agent_on_spsvepajapp01.imzcloud.ibmammsap.local_is_unavailable



6:59:06 PM: DCGHANAQASAPP 	10.197.6.12	10.197.3.12
  
------------------------------------------------------------------------------------------------------------------------------------
8 Mar


INC7322472
dyss4apsbd41 not acccessible   10.6.12.18

ibmrmalik@dyss4apsbd41:~> free -g
             total       used       free     shared    buffers     cached
Mem:            11         11          0          5          0          5
-/+ buffers/cache:          5          6
Swap:           35          5         30

dys
Node Name:   dyss4apsbd41.imzcloud.ibmammsap.local
Environment: dys_development
FQDN:        dyss4apsbd41.dystar.com
IP:          10.1.162.18
Run List:    role[baseos_sles]
Roles:       baseos_sles, itcs104

[root@SNG01AMMCHEF01 ~]# knife environment list
_default
dys_development
dys_production

[root@SNG01AMMCHEF01 ~]# knife node list|grep -i dyss4apsbd41
dyss4apsbd41.imzcloud.ibmammsap.local


knife node delete -y dyss4apsbd41.imzcloud.ibmammsap.local;knife client delete -y dyss4apsbd41.imzcloud.ibmammsap.local

./root/bootstrap_v12.sh -o dys -n dyss4apsbd41 -l -d imzcloud.ibmammsap.local -t osonly -e dys_development






INC7322893. The customer need this entry added to the /etc/host file at the earliest.


Account - PEU
Site - FRA02
Servers -
SID    *Host name    *CFN IP        *IFN IP        *Bean IP
A4D    PEU-A4D-DB    10.110.48.25    100.126.65.24    10.85.220.53
A4D    PEU-A4D-CI    10.110.48.20    100.126.65.19    NA
Request - Please add the below host entries in the AD4 server /etc/hosts

10.100.178.5	deeh05sl-be01
10.100.178.5	deeh05sl-be01.pan.eu
10.100.178.5	deeh05sl-be01.eu.gds.panasonic.com


All should resolve as ip: 10.100.178.5




INC7310767
Zabbix_agent_on_deeh11ryc1009.imzcloud.ibmammsap.local_is_unavailable




AGEAS-P1-INC7323502-Need Open Text server (10.70.111.35) - spsvopltapp01 reboot in Production environment
Customer Raised - Requested Ravi Malik to Pick please inform CIM channel in right format
@Ravi Malik (3x OS Suppport): Please take P1 to your bin for IaaS server restart
A0EASG012XVM042



SR0019447
SUNCOR :  Extend FS  on Host SNCHTRITA11
SNCHTRITA11	10.73.11.144  snchtrita11
FS /sapmt/TT1  Add 20GB





ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAvZVEQoQNCDeV79Qkq1AWnZkvXCJrXUJKmg1/oorhUayjCplTNh8HSajBmeCdwqxxlHvHNHXYahCi+C1uYHPDkBvkJDzsucJ+Id3jC96euKxQzwLm6SN5ZNv2k4lW71XIX5/3TDiZDUsjSM/1qeOcutxaPXDQkbNCmuiAudUp1P24p3IIUQlb8Ib2NcJl0Ztwc50kpW2hww5KDLzOnYu5nAx3sizxDkSPKYxjMJjSJzQIx/3IUgRoyhzok9d9+lfg3AtrN22eEb+V4UGjBFw32+corqVGimFagc0MwxzPeOt2HfBcowGW28ij/CEwGCOP4kyuGpU11ntYk6fnz2LqlQ==



INC7323569 GKN Driveline Newton LLC P1-Severe 
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/EPJ/SCS11
10.15.80.20


Installed:
  telnet.x86_64 1:0.17-48.el6

Complete!
[root@spsvppalase01 ibmrmalik]# 



INC7324060    Raycap GmbH    P1-Severe
Zabbix_agent_on_deeh11ryc1009.imzcloud.ibmammsap.local_is_unavailable
10.7.64.17


[root@smgwquaqq1 ibmrmalik]# vmware-toolbox-cmd -v
10.0.9.55972 (build-3917699)



username=YSRVSAPEC,password=EC_SAP00
SR0018152
Request to setup mount points in SBD to map to FTP server folders
SBD App	dyss4apsbd41	10.6.12.18
ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP

10.1.161.14  10.6.11.14(imz)  WIndows server DYSFTPDAPRD01

ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP	map to FTP server folder	D:\Dystar-FTP\S4HANA_DC\SBD\IBP

//10.1.161.14/Dystar-FTP\S4HANA_DC\SBD\FC /usr/sap/s4hana/SBD/S4HANA_DC/FC  -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003



mount command
mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/IBP /usr/sap/s4hana/SBD/S4HANA_DC/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev

fstab entry 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/FC /usr/sap/s4hana/SBD/S4HANA_DC/FC cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/MM /usr/sap/s4hana/SBD/S4HANA_DC/MM cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/QM /usr/sap/s4hana/SBD/S4HANA_DC/QM cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/SD /usr/sap/s4hana/SBD/S4HANA_DC/SD cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/EHS /usr/sap/s4hana/SBD/S4HANA_DC/EHS cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/PP /usr/sap/s4hana/SBD/S4HANA_DC/PP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/WM /usr/sap/s4hana/SBD/S4HANA_DC/WM cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/IBP /usr/sap/s4hana/SBD/S4HANA_DC/IBP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 

-----------------------------------------------------------------------------------------------------------------------------------------------------

10 Mar

CHG0094934
Please deploy above Q119-patches to the following servers.

Host Name	CFN IP	Asset Purpose
LZASOLPRD0	10.4.2.18	vmtools updated
LZAECCPRD0	10.4.2.11	vmtools updated
LZAWEBPRD0	10.4.2.20	vmtools updated
LZAMOBPRD0	10.4.2.21	vmtools updated	
LZAGWPRD0	10.4.2.19	PENDING	

CTASK0088831   Castillo Esteban 


INC7337850    LSPI    P2 - Major    ITM Agent Offline: LZAWEBPRD0:UA
10.4.2.20

INC7337835    LSPI    P2 - Major    ITM Agent Offline: LZAMOBPRD0 HTTPdp:UAGENT00
10.4.2.21


INC7337911    LSPI    P2 - Major    ITM Agent Offline: LZABJPRD0	HTTPdp:UAGENT00



INC7336056    Hanon Systems    P1 - Severe    SAP: H4P-handvh4psrv02_H4P_02:Ins:H4P: an alert of class:System occured. Lost connection to mySAP system
10.15.193.15

INC7336045    Hanon Systems    P1 - Severe    SAP: HPP-handvhppsrv02_HPP_03:Ins:HPP: an alert of class:System occured. Lost connection to mySAP system
10.15.192.39

Changed the time zone from EST to EDT to match the time with 10.15.193.60 as suggested by Chandini V.


 489  2019-03-10 06:50:39 cd /etc
  490  2019-03-10 06:50:51 cp localtime /tmp/localtime.old
  491  2019-03-10 06:51:00 rm localtime
  492  2019-03-10 06:51:29 ln -s /usr/share/zoneinfo/America/New_York localtime
  493  2019-03-10 06:51:45 date

---------------------------------------------------------------------------------------------------------------------------------

11 Mar


INC7343857    Panasonic Europe Ltd    P2 - Major    Free_disk_space_is_less_than_10%_on_volume_/var/log[
100.126.65.26




INC6991650	sev2
Error on FS


INC7320320	TSM
An error occurred while saving the snapshot: Failed to quiesce the virtual machine
dysfrdafrq20	10.6.12.32	SNG



INC7255021 sev2
Processor_load_is_too_high_on_DYSDCR01[PROBLEM:1134887




INC7303799
ITM Agent Offline: dyswdapwdd40:INTERNE
10.6.12.20	

User: root Groups: root sapinst
Host name : dyswdapwdd40         Installer Lvl:06.23.03.00
CandleHome: /opt/monitor/IBM/ITM
***********************************************************
Host          Prod  PID    Owner  Start  ID    ..Status
dyswdapwdd40  um    17339  root   16:12  None  ...running

./itmcmd agent -o FQ1 start sa  




INC7343986    AGEAS    P2 - Major    SAP09    Processor_load_is_too_high_on_SVCC1SRV0.imzcloud.ibmammsap.local[
10.6.2.61



SR0019550
Please extend the sapdatas file systems on 10.6.12.32 <dysfrdafrq20> by 5GB each
Please extend the sapdatas file systems on 10.6.12.32
/dev/mapper/frqdatavg-frqsapdata1_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata1
/dev/mapper/frqdatavg-frqsapdata2_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata2
/dev/mapper/frqdatavg-frqsapdata3_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata3
/dev/mapper/frqdatavg-frqsapdata4_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata4



handvh4psrv02	10.15.193.15	10.23.193.15	Red Hat
handvh4psrv03	10.15.193.45	10.23.193.50	Red Hat
handvh4psrv04	10.15.193.21	10.23.193.21	Red Hat
h4padm:sapsys


handvh4psrv02_restore_03102019	10.15.193.15	10.23.193.15
MAC 1  00:50:56:9a:2e:4b
MAC2   00:50:56:9a:34:8e




CHG0098882
SMECCUATUE3	10.5.26.16	Test	done
SMEDIUATUU3	10.5.26.25	Test
SMEMUATUM3	10.5.26.21	Test
SMGWUATUQ3	10.5.26.11	Test	done
SMPOUATUX8	10.5.26.19	Test
SMBOUATUB3	10.5.26.12	Test






INC6991650, INC7150095 and INC7154210

-----------------------------------------------------------------------------------------------------------------------------------

12 Mar

SR0019550
Please extend the sapdatas file systems on 10.6.12.32 <dysfrdafrq20> by 5GB each
Please extend the sapdatas file systems on 10.6.12.32
/dev/mapper/frqdatavg-frqsapdata1_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata1
/dev/mapper/frqdatavg-frqsapdata2_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata2
/dev/mapper/frqdatavg-frqsapdata3_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata3
/dev/mapper/frqdatavg-frqsapdata4_lv          23G   19G  3.4G  85% /sybase/FRQ/sapdata4

sdg



INC7350305
we need to extend F Drive @ 430 PM IST 
Host: svtd1srv0	(10.6.1.27/10.92.99.126) 	A0EASG012XVM004	


dysfrdafrq20:~ # df -h /usr/sap/trans_old
Filesystem                        Size  Used Avail Use% Mounted on
/dev/mapper/frqappvg-usrtrans_lv   40G   25G   14G  66% /usr/sap/trans_old



CHG0097930
SMGWSBXSQ1	10.5.20.31	Sandbox
SMIFASBXSF1	10.5.20.32	Sandbox
SMPOSBXSX8	10.5.20.20	Sandbox
SMBOSBXSB1	10.5.20.11	Sandbox
SMSMSBXSS0	10.5.20.25	Sandbox
SMTMSBXST1	10.5.20.13	Sandbox

SMGWSBXSQ1
SMIFASBXSF1
SMPOSBXSX8
SMBOSBXSB1
SMSMSBXSS0
SMTMSBXST1

uname -a;date;cat /etc/redhat-release




00:50:56:9a:57:7c
00:50:56:9a:02:56


00:50:56:9a:46:fe
00:50:56:9a:5b:05





INC7351572    Arnoldo Mondadori Editore SpA    P2 - Major    SAP10    Processor_load_is_too_high_on_armfksap103.imzcloud.ibmammsap.local[
10.7.103.20

------------------------------------------------------------------------------------------------------------------------
13 March



SR0019762
spsvspdsase01 - 10.6.3.32     A0EASG014XVM035  add 48GB RAM make it 64GB

spsvcpivsql01 - IaaS server (OPENTEXT CONTENT)	A0EASG012XVM047  increase RAM by 16 GB make it 32GB






INC7360170	sev1   zabbix
S4HANA-DB-QAS 	RHEL 	DB 	10.71.5.12 	192.168.25.12 	vHana 	fraha-1024-15.xsportal.local
Zabbix_agent_on_S4HANA-DB-QAS.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:11615691]


root/m9gfUud00a@
10.135.10.222



INC7360126
Lack_of_free_swap_space_on_dlthdpspi.imzcloud.ibmammsap.local[PROBLEM:11615589

---------------------------------------------------------------------------------------------------------

14 March

INC7367368
Please change the Vcentre name to the host nam


INC7360743
extend /usr/sap/DO1 with 100GB




SR0019881 - Mount FTP interface folders to S/4HANA (SBQ) 
(please grant the folder as chmod -R 775 /usr/sap/s4hana/SBQ/* and sbqadm as folder owner for read/execute/write acc
ZFTP_S4HANA_DC_FC
ZFTP_S4HANA_DC_MM
ZFTP_S4HANA_DC_QM
ZFTP_S4HANA_DC_SD
ZFTP_S4HANA_DC_EHS
ZFTP_S4HANA_DC_PP
ZFTP_S4HANA_DC_WM
ZFTP_S4HANA_DC_IBP



INC7364475 - FRQ reboot for fixing / backup issue and vm backup issue
dysfrdafrq20     10.6.12.32    SLES SNG

dysfrdafrq20:/home/ibmrmalik # df -h /
Filesystem                 Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-rootlv  9.8G  1.8G  7.5G  20% /

umount the fs
then
fsck -y /dev/mapper/rootvg-rootlv


INC7367692    ETRO SPA    P3 - Minor
yum install salt-minion

eccdas00
[root@ECCDAS00 ~]# rpm -qa |grep -i salt-minion
salt-minion-2018.3.3-1.el6.noarch

eccddb00    Red Hat Enterprise Linux Server release 6.7 (Santiago)
[root@eccddb00 ~]# rpm -qa |grep -i salt-minion
salt-minion-2019.2.0-1.el6.noarch

eccpas00
[root@ECCPAS00 ibmrmalik]# rpm -qa |grep -i salt-minion
salt-minion-2018.3.3-1.el6.noarch

ECCPDB00
[root@eccpdb00 ~]# rpm -qa |grep -i salt-minion
salt-minion-2018.3.3-1.el6.noarch

eccqas00
[root@ECCQAS00 ~]#  rpm -qa |grep -i salt-minion
salt-minion-2018.3.3-1.el6.noarch

eccqdb00	Red Hat Enterprise Linux Server release 6.7 (Santiago) 
[root@eccqdb00 ~]#  rpm -qa |grep -i salt-minion
salt-minion-2019.2.0-1.el6.noarch


ssmci000
[root@SSMCI000 ~]# rpm -qa |grep -i salt-minion
salt-minion-2018.3.3-1.el6.noarch




SR0019899 IAG GBS Limited Medium
SAP-HEC-SWIVEL:	 BA_ SR5 server restart
 set HTTPS port to 8500 and SMTP port 25000

--------------------------------------------------------------------------------------------------------------------

18 March

INC7395108    Inter Pipeline Fund    P2 - Major    Lack_of_free_swap_space_on_IPLsafiax01.imzcloud.ibmammsap.local
10.138.2.33



SR0019996    INC7396709
10.6.11.14 (Windows )
and 
FTP client ( imz ip) = 10.6.11.14 (Suse Linux)

SBD App	dyss4apsbd41	10.6.12.18
ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBD/S4HANA_DC/FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBD/S4HANA_DC/MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBD/S4HANA_DC/QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBD/S4HANA_DC/SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBD/S4HANA_DC/EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBD/S4HANA_DC/PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBD/S4HANA_DC/WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBD/S4HANA_DC/IBP

10.1.161.14  10.6.11.14(imz)  WIndows server DYSFTPDAPRD01



INC7396709	sev3
FTP dysftpdaprd01 server mount points not working in dyss4apsbd41



INC7396683    COTY Inc.    P2 - Major    Processor_load_is_too_high_on_ctubwqb3db01.imzcloud.ibmammsap.local
10.12.10.103




INC7397112    Suncor Energy Inc.    P1 - Severe    Zabbix_agent_on_snchcrapa12.imzcloud.ibmammsap.local_is_unavailable
10.73.10.32



INC7397154    Suncor Energy Inc.    P1 - Severe    Zabbix_agent_on_snchcraqa13.imzcloud.ibmammsap.local_is_unavailable
10.73.12.27



CHG0100839	PQM SCA Deployement in Dev on 3.18.2019 on 5 PM PHT	
CTASK0095720	VM snap Shot of JD1 - SJD1SRV0
SVJD1SRV0 - 10.6.1.12	A0EASG014XVM003



SR0019881
Mount FTP interface folders to S/4HANA (SBQ)
(please grant the folder as chmod -R 775 /usr/sap/s4hana/SBQ/* and sbqadm as folder owner for read/execute/write access)

Similar setup in SBD as shown below

ZFTP_S4HANA_DC_FC	/usr/sap/s4hana/SBQ/FC	D:\Dystar-FTP\S4HANA_DC\SBQ\FC
ZFTP_S4HANA_DC_MM	/usr/sap/s4hana/SBQ/MM  D:\Dystar-FTP\S4HANA_DC\SBQ\MM
ZFTP_S4HANA_DC_QM	/usr/sap/s4hana/SBQ/QM  D:\Dystar-FTP\S4HANA_DC\SBQ\QM
ZFTP_S4HANA_DC_SD	/usr/sap/s4hana/SBQ/SD  D:\Dystar-FTP\S4HANA_DC\SBQ\SD
ZFTP_S4HANA_DC_EHS	/usr/sap/s4hana/SBQ/EHS  D:\Dystar-FTP\S4HANA_DC\SBQ\EHS
ZFTP_S4HANA_DC_PP	/usr/sap/s4hana/SBQ/PP  D:\Dystar-FTP\S4HANA_DC\SBQ\PP
ZFTP_S4HANA_DC_WM	/usr/sap/s4hana/SBQ/WM  D:\Dystar-FTP\S4HANA_DC\SBQ\WM
ZFTP_S4HANA_DC_IBP	/usr/sap/s4hana/SBQ/IBP  D:\Dystar-FTP\S4HANA_DC\SBQ\IBP

mount command
mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev 0 0

	  \\10.6.11.14\Dystar-FTP\S4HANA_DC\SBQ\IBP
	  
	  smbclient \\\\10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP \\source -W DOMAIN -U My.User.Name%my.password
	uid=20210(sbqadm) gid=3050(sapsys)  

mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev,nofail

fstab entry 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=20201,gid=3050,_netdev,nofail 0 0
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/WM /usr/sap/s4hana/SBQ/WM cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev,nofail 0 0
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/PP /usr/sap/s4hana/SBQ/PP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev,nofail 0 0
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/EHS /usr/sap/s4hana/SBQ/EHS cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev,nofail 0 0
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/SD /usr/sap/s4hana/SBQ/SD cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev,nofail 0 0
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/QM /usr/sap/s4hana/SBQ/QM cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev,nofail 0 0
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/MM /usr/sap/s4hana/SBQ/MM cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev,nofail 0 0
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/FC /usr/sap/s4hana/SBQ/FC cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev,nofail 0 0

//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=20210,gid=3050,_netdev,nofail 0 0

But map to SBQ folders instead of SBD folders.

source ip in cfn: 10.1.162.34   DYSS4APSBQ21 	10.6.12.34
10.1.161.14  10.6.11.14(imz)  WIndows server DYSFTPDAPRD01


S/4 Hana SBQ - UAT (SIT)        IP Address        Hostname

                 10.6.12.34      10.1.162.34	dyss4apsbq21

---------------------------------------------------------------------------------------------------------------------------------------
19 March


SR0019893
Create a directory and mount a CIFS share on SAP System DP1 (APLBREDP1)
Please create the directory /usr/data-exchange and mount the following share via CIFS permanent to this directory.

Source  APLBREDP1 	170.225.68.11	10.92.144.11
Server: DC000PCA079.epmassetis.com (10.92.146.173)
Share: \\10.92.146.173\DP1
User: epmassetis\SAP_DP1_KOM
Password: ez-1KFV6gKf3Xv

uid=20000(dp1adm) gid=3050(sapsys) 

hmm
mount.cifs //10.92.146.173/DP1 /usr/data-exchange  -o domain=epmassetis username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,_netdev,nofail,sec=ntlm

mount.cifs //10.92.146.173/DP1 /usr/data-exchange cifs -o domain=epmassetis,username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,_netdev,nofail,sec=ntlm



//10.92.146.173/DP1 /usr/data-exchange cifs domain=epmassetis,username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,uid=20000,gid=3050,_netdev,nofail 0 0

//10.92.146.173/DP1 /usr/data-exchange cifs domain=epmassetis,username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,uid=20000,gid=3050,_netdev,nofail,sec=ntlm 0 0


SR0020173    Low    MSC Industrial Supply Co
IBM perform modification at the OS level on Java SSO server AD1 and restart the SSO application
MS3WDCLADB14 	10.12.6.30	172.17.154.30
To get the logon working 
1) open the configtool at OS level  navigate to: cluster_config/system/custom_global/cfg/services/com.sap.security.core.ume.service
-open propertsheet.properties where you will be able to restore the default for value ume.logon.application.ui_resources_alias to /logon_ui_resources. 

Then restart the system

See https://help.sap.com/doc/saphelp_snc_uiaddon_10/1.0/en-US/47/c5978ee5d92d65e10000000a42189c/frameset.htm for details on the config tool.



INC7405989  server login issue. / was 100% and botstrapping done.
MGGGBJPECCX04	10.133.18.21	10.5.255.21 	
mgg
CHEF_ORG=mgg knife node show MGGGBJPECCX04.imzcloud.ibmammsap.local

Node Name:   MGGGBJPECCX04.imzcloud.ibmammsap.local
Environment: mgg_production
FQDN:        MGGGBJPECCX04.meggitt.net
IP:          10.5.255.21

mgg_production

MGGGBJPECCX04.imzcloud.ibmammsap.local


rake bootstrap:cms3x[root,10.133.18.21,production,cms3x_cfg,MGGGBJPECCX04.imzcloud.ibmammsap.local,LON02AMM]
rake bootstrap:cms3x[root,10.133.18.21,cms3x_cfg,production,MGGGBJPECCX04.imzcloud.ibmammsap.local]

--------------------------------------------------------------------------------------------------------------------------------------------

20 Mar

INC7411424
ECQ (HANADB)|HDB_ALERT_METRIC_2001|High Hana service ping time // SYSTEM not reachable via OS 
hc1hoecchadbq	HC1HOECCHADBQ 	10.211.80.85	10.10.80.84
Hortus Comercio de Alimentos SA			dalla13
dal13-pod1-4tb-host01.imzcloud.ibmammsap.local
10.186.255.38	root/oX0HrSu8uH@	dallas13

dal13-pod1-4tb-host02
10.186.255.76  root/jxOJjFz0eU@


dal13-pod1-4tb-host03
10.186.255.60   root/kANhKfGUqg@


dal13-pod1-4tb-host04
10.186.255.43  root/kiAwNMeGEa@


dal13-pod1-4tb-host05
10.186.255.69	root/Sdw5MASyIc@



dal13-pod1-4tb-host06
10.186.10.31  root/iChnbPHSiu@
VM found in this host



76584421 raised in SL

IPMI  root/P8x3PqC7Vf
ecqadm	Security#1


INC7410774    P1 - Severe    Certified IT Consultants        Zabbix_agent_on_CI2DEVAPP.imzcloud.ibmammsap.local_is_unavailable
10.5.242.16


INC7410771    P1 - Severe    Certified IT Consultants        Zabbix_agent_on_CI2PRDDB.imzcloud.ibmammsap.local_is_unavailable
10.5.242.15


INC7410728    P1 - Severe    Certified IT Consultants        Zabbix_agent_on_CI2QADB.imzcloud.ibmammsap.local_is_unavailable



SR0020214    Low    Inter Pipeline Fund





INC7414541    P2 - Major    Dixons Carphone    SQ-SAP-TRIO-11    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DCGHANAPRDDB2- KB0016174    03/20/2019 00:52:14    DCGHANAPRDDB2
10.197.5.18

INC7414540    P2 - Major    Dixons Carphone    SQ-SAP-TRIO-11    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DCGHANASOLAPP- KB0016174    03/20/2019 00:52:13    DCGHANASOLAPP
10.197.5.11
Unclear on what is to be checked in such tickets. Sent mail to Mauricio to get an insight as to what is expected here.

INC7414539    P2 - Major    Dixons Carphone    SQ-SAP-TRIO-11    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DCGHANAQASDB- KB0016174    03/20/2019 00:52:12    DCGHANAQASDB
10.197.6.11
-------------------------------------------------------------------------------------------------------------------------------------

21 Mach


SR0020378
Adjust the timezone to EDT
pn4us7lewmd1      10.12.254.120
pn4us7lewmd1:/etc # date
Thu Mar 21 02:35:44 EDT 2019

pn4us7leccd1         10.12.254.89
pn4us7leccd1:/etc # date
Thu Mar 21 02:56:34 EDT 2019


pn4us7lmiid1         10.12.254.96
pn4us7lmiid1:/etc # date
Thu Mar 21 06:19:14 UTC 2019
pn4us7lmiid1:/etc # ln -s /usr/share/zoneinfo/America/New_York localtime
pn4us7lmiid1:/etc # date
Thu Mar 21 02:19:25 EDT 2019


pn4us7lapsd1        10.12.254.97
pn4us7lapsd1:/home/ibmrmalik # cd /etc
pn4us7lapsd1:/etc # cp localtime /tmp/localtime.old
pn4us7lapsd1:/etc # rm localtime
pn4us7lapsd1:/etc # date
Thu Mar 21 05:19:24 UTC 2019
pn4us7lapsd1:/etc # ln -s /usr/share/zoneinfo/America/New_York localtime
pn4us7lapsd1:/etc # date
Thu Mar 21 01:20:21 EDT 2019




SR0019974




CHG0098880
SU6-CHE01- Prod- Apply Latest Q119 Patches on Linux  Servers
SU6SUNECP00	10.10.10.141	Production
Linux SU6SUNECP00 2.6.32-754.9.1.el6.x86_64 #1 SMP Wed Nov 21 15:08:21 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Linux SU6SUNECP00 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 21 10:29:03 IST 2019
Thu Mar 21 10:58:14 IST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Red Hat Enterprise Linux Server release 6.10 (Santiago)



SR0020398
Dystar ip change
dysdcr01 CFN IP 10.1.161.11, IFN 10.6.11.13



INC7420589
INC7420598




INC7424312    P1    IBM AMM SAP Client Tribe Infrastruc     Zabbix_agent_on_dal09ammsol05.imzcloud.ibmammsap.local_is_unavailable
146.89.140.4






Task : CTASK0096211
SVLD1SRV0 - 10.6.1.20	 snapshot taken

SVSD1SRV0- 10.6.1.26

-----------------------------------------------------------------------------------------------------------------------------

22 March


INC7237101 | ASE Data Space ...> OS resource is needed in order to increase the sapdatas
IBMCTU70 (DBSYSTEM)|ASE_SPACE_MANAGEMENT|ASE Data Space
169.60.136.225
 The sapdata3 and apdata4 in QR4 system needs to add some space, in order to bring the sapdata to 75%. 
- OS resource is required. 

/dev/mapper/qr4datavg-qr4sapdata3_lvncr 
35G 27G 6.7G 80% /sybase/QR4/sapdata3 
/dev/mapper/qr4datavg-qr4sapdata4_lv 
35G 27G 6.7G 80% /sybase/QR4/sapdata4


/dev/mapper/qr4datavg-qr4sapdata3_lv
                       40G   27G   12G  70% /sybase/QR4/sapdata3
/dev/mapper/qr4datavg-qr4sapdata4_lv
                       40G   27G   12G  70% /sybase/QR4/sapdata4


CHG0101629 	snapshot reuest pre patch for Yun's change
PTPLORENTZ01	192.168.166.139	Development
PTPSEMERU	192.168.166.142	Development
PTPTOBA1	192.168.166.147	Development 





SR0020413
On SUSE Linux 12 patch level 1, 2 and 3 servers, the parameter DefaultTasksMax may be set to an incorrect value which may lead to a server hang.

How to determine Applicability
This issue is only applicable for GPFS based SUSE Linux 12 patch level
1, 2 and 3 with parameter DefaultTasksMax not set to infinity.

Run the following command  to determine the SUSE Linux version and patch level.
cat /etc/SuSE-release

Run the following command to find the value of parameter 
DefaultTasksMax:
systemctl show --property DefaultTasksMax

If system is GPFS based and the results are SUSE Linux version 12 patch level 1, 2 or 3 and the value of DefaultTasksMax is something other than the word 'infinity' then mark this as applicable.

agesvedmhsrv1	10.6.1.179	not applicable as GPFS not installed
agesvcqmhsrv1	10.6.2.72	not applicable as GPFS not installed
agesvepmhsrv1	10.6.3.58	not applicable as GPFS not installed



 QEP,QBJ & QWD
 Server List - Quality				
SID	OS Type	Hostname	IFN IP	CFN IP
QEP	RedHat Linux	sjmqepaa01	10.198.12.13	10.195.3.13
QEP	RedHat Linux	SJMQEPDB01	10.198.12.10	10.195.3.10
QRP	RedHat Linux	SJMQCPAA01	10.198.12.18	10.195.3.18 
QRP	RedHat Linux	SJMQCPDB01 	10.198.12.11	10.195.3.11
QRQ	RedHat Linux	sjmqcpja01	10.198.12.19	10.195.3.19
QGP	RedHat Linux	sjmqgpdb01	10.198.12.15	10.195.3.15
QXP	RedHat Linux	sjmqxpaa01	10.198.12.21	10.195.3.21
QXP	RedHat Linux	sjmqxpdb01	10.198.12.22	10.195.3.22
QPQ	RedHat Linux	sjmqpqja01	10.198.12.16	10.195.3.16
QPQ	RedHat Linux	sjmqpqdb01	10.198.12.17	10.195.3.17
QWD	RedHat Linux	sjmqwdaa01	10.198.13.11	10.195.0.11
QBJ	RedHat Linux	SJMQBDBA01	10.198.12.12	10.195.3.12
QFP	RedHat Linux	sjmqfpaa01	10.198.12.14	10.195.3.14
 
------------------------------------------------------------------------------------------------------------------------------------

24 March


CHG0101999  change timezone to EDT
App server ( PAS)	MP1	pn4us7lewmp1c	10.12.254.21
pn4us7lewmp1c:/etc # date
Sat Mar 23 21:17:38 EDT 2019
App server ( AAS)	MP1	pn4ushlewmp1c	10.12.254.22
pn4ushlewmp1c:/etc # date
Sat Mar 23 21:19:54 EDT 2019
DB server ( Primary)	MP1	pn4us7lewmp1 	10.12.254.20 
pn4us7lewmp1:/etc # date
Sat Mar 23 21:22:06 EDT 2019
			CP1	pn4us7leccp1c	10.12.254.17
App server ( AAS)	CP1	pn4ushleccp1c	10.12.254.18
DB server ( Primary)	CP1	pn4us7leccp1 	10.12.254.14 
App server ( PAS)	SP1	pn4us7lapsp1c	10.12.254.38
App server ( AAS)	SP1	pn4ushlapsp1c	10.12.254.39
DB server ( Primary)	SP1	pn4us7lapsp1	10.12.254.43
DB server ( HA)	SP1	pn4ushlapsp1	10.12.254.44
pn4ushlapsp1:/etc # date
Sat Mar 23 21:30:46 EDT 2019




CHG0099590  24 Mar 730-1530	padmava@my.ibm.com,prabhakardev@in.ibm.com
PTPKOMODO	10.70.31.13
PTPBROMO	10.70.31.16	done timezone update
PTPRAJAAMPAT	10.70.31.22	done timezone update

rcm qa date




CHG0096774 24 Mar 0930 AM	
A0FAUS014XVM004	acerosprdecc	10.4.11.31


geovanni.cruz@ibm.com
Mario Alberto Ramirez Sandoval <mramirez@cr.ibm.com>, 
Jorge Carrillo Zavaleta <jcarrillo@mepsa.com>



INC7447433    Delta Airlines    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_/var/log - @Ravi Malik (3x OS Suppport)
10.4.5.137


INC7447339    Panasonic North America    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_/var/log -
10.12.254.44


--------------------------------------------------------------------------------------------------------------------------------

25 Mar


INC7427935
Zabbix_agent_on_DYSDCR01_is_unavailable[PROBLEM:11867850]
10.6.11.13 

INC7364357
Zabbix_agent_on_DYSW1DAWWD40_is_unavailable[PROBLEM:11621648]
10.6.12.26 

INC7364212
Zabbix_agent_on_DYSOTDAOTD40_is_unavailable[PROBLEM:11621498]


INC7348810
Processor_load_is_too_high_on_DYSFTPDAPRD01[PROBLEM:11596850]
10.6.11.14

INC7255021	sev3
Processor_load_is_too_high_on_DYSDCR01[PROBLEM:11348878]
10.6.11.13 


INC7361227  not OS ticket


INC7451992    Suncor Energy Inc.    P4 - Minimal    Suncor DNS Name resoltuion Issues #2177


SR0020587
Please check if there are any issues on dyss4dbsbd40	10.6.12.13 <SBD db> and dyss4dbsbq20	10.6.12.38<SBQ db>



INC7453951    Panasonic North America    P1 - Severe    COROSYNC_service_not_running[PROBLEM:11932869]
10.12.254.41

INC7453929    Panasonic North America    P1 - Severe    COROSYNC_service_not_running[PROBLEM:11932849]
10.12.254.42



SR0020589



INC7454051    Panasonic North America    P1 - Severe    COROSYNC_service_not_running
10.12.254.37




INC7454084    Panasonic North America    P1 - Severe    COROSYNC_service_not_running
10.12.254.36




INC7454388  -  P1  -  COROSYNC_service_not_running[PROBLEM:11933822]  -  PN4US7LMIIP1C
10.12.254.36 


INC7454371  -  P1  -  COROSYNC_service_not_running[PROBLEM:11933811]  -  PN4USHLMIIP1C
ongoing change


INC7455240    Inter Pipeline Fund    P2 - Major    Ping Availability CRITICAL - 10.138.2.16: rta nan, lost 100%


INC7455404    Inter Pipeline Fund    P2 - Major    Ping Availability CRITICAL - 10.138.2.11: rta nan, lost 100%


INC7455403    Inter Pipeline Fund    P2 - Major    Ping Availability CRITICAL - 10.138.2.33: rta nan, lost 100%


INC7455400    Inter Pipeline Fund    P2 - Major    Ping Availability CRITICAL - 10.138.3.17: rta nan, lost 100%



INC7455577    Panasonic North America    P1 - Severe    COROSYNC_service_not_running


INC7455625    Panasonic North America    P1 - Severe    COROSYNC_service_not_running


SR0020623
Please reset the password for user ia2iccdev\ICCMaintAcc in ia2iccdev
(66.248.245.73) server. 

-----------------------------------------------------------------------------------------------------------------------

26 Mar


INC7460246    P1 - Severe    IBM AMM Infrastructure    LON02AMMZAB001.imzcloud.ibmammsap.local_has_just_been_restarted



INC7461769   ptpbromo	10.70.31.16	192.168.166.12 Can you please unlock the user appadm


SR0020721
JD1 - SVJD1SRV0 - 10.6.1.12	A0EASG014XVM003
VM snashot of JD1 application host before CSR # CHG0102286 



SR0020718    Low    Unique S.A.    UNQ-01    UNQSAPBPCPRD    Request a Service        It is required to know the OS version of the equipment managed by AMM4SAP	dallas09
unqsapbpcprd Unique SAP 10.28.25.16 / 169.53.21.183
[root@unqsapbpcprd ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.10 (Santiago)

unqsapbpcqas Unique SAP 10.28.25.17 / 169.53.21.184
[root@unqsapbpcqas ~]#  cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.10 (Santiago)

unqsapbpcdev Unique SAP 10.28.25.18 / 169.53.21.185
[root@unqsapbpcdev ~]#  cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.10 (Santiago)

yanbalbodev Unique SAP 10.28.25.13 / 169.53.21.182
[root@yanbalbodev ~]#  cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.10 (Santiago)

yanbalboprd Unique SAP 10.28.25.15 / 169.53.21.180	non HANA
[root@yanbalboprd ~]#  cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

yanbalboqas Unique SAP 10.28.25.14 / 169.53.21.181
[root@yanbalboqas ~]#  cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.10 (Santiago)

yanbalhdev Unique SAP 10.28.25.10	HANA
[root@yanbalhdev ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

yanbalhprd Unique SAP 10.28.25.12	HANA
[root@yanbalhprd ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

yanbalhqas Unique SAP 10.28.25.11	HANA
[root@yanbalhqas ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)


INC7462592    P2    IBM AMM SAP Client Tribe Infrastruc     Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local


SR0020723
Change password appadm



INC7463026    P1 - Severe    MHAS    Free_disk_space_is_less_than_5%_on_volume_/var/log/opscode
169.55.28.62 



SR0020726
Suncor : Extend FS for hist SNCHTRITA11



INC7463960    P1 - Severe    IBM AMM SAP Client Tribe Infrastruc    Zabbix_agent_on_dal09ammsol01.imzcloud.ibmammsap.local_is_unavailable



INC6919612	{St Jude Medical --> sjmpxpaa01/10.198.10.19}    P3 - Minor - Assigned
Free_disk_space_is_less_than_20%_on_volume_/usr/sap[PROBLEM:10718313]		extended 500MB


INC7126387	{St Jude Medical --> sjmppqaa02/10.198.10.11}    P3 - Minor - Assigned
Free_disk_space_is_less_than_20%_on_volume_/usr/sap[PROBLEM:10718313]


2:52:23 PM: DYSCIARD2200 	10.6.12.45	10.1.162.45 	 
2:52:39 PM: YSCIERU2800 	10.6.12.44	10.1.162.44 
2:52:55 PM: DYSCIBWT2400 	10.6.12.47	10.1.162.47

2:53:13 PM: DYSFTPDAPRD01 	10.6.11.14	10.1.161.14

-------------------------------------------------------------------------------------------------------------------------------------

27 Mar

INC7472403    P1    Bombardier Recreational Products Inc    Zabbix_agent_on_br3psape50.imzcloud.ibmammsap.local_is_unavailable
10.138.10.24




SR0020739
Folder -   D:\Dystar-FTP
FTP Server - DYSFTPDAPRD01 	10.6.11.14	   10.1.161.14  (Windows)

Linux
DYSCIARD2200 	10.6.12.45	   10.1.162.45	
dysciard2200:/usr/sap # id ardadm
uid=20220(ardadm) gid=3050(sapsys) groups=3050(sapsys)

DYSCIERU2800 	10.6.12.44	   10.1.162.44 
dyscieru2800:/home/ibmrmalik # id eruadm
uid=20280(eruadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)


DYSCIBWT2400 	10.6.12.47	   10.1.162.47
dyscibwt2400:/home/ibmrmalik # id bwtadm
uid=20240(bwtadm) gid=3050(sapsys) groups=3050(sapsys),54746(sapinst),2401(dba),2402(oper)


mount command
mount.cifs //10.1.161.14/Dystar-FTP /Dystar-FTP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev,nofail,sec=ntlm
mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev,nofail
mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev,nofail,sec=ntlm


fstab entry 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/FC /usr/sap/s4hana/SBD/S4HANA_DC/FC cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 

//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=20210,gid=3050,_netdev,nofail 0 0

//10.1.161.14/Dystar-FTP /Dystar-FTP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=20240,gid=3050,_netdev,sec=ntlm 0 0




CHG0102471
Snapshot for a change
svjq1srv0	10.6.2.12	A0EASG014XVM004

-----------------------------------------------------------------------------------------------------------------------------------

28 March

INC7476235  - Lack_of_free_swap_space_on_fbdhanaapp
10.4.26.12 



INC7409848	cancelled	Ping Availability CRITICAL - 10.197.5.11: rta nan, lost 100%
 10.197.5.11

INC7409856	Ping Availability CRITICAL - 10.197.5.15: rta nan, lost 100%
10.197.5.15

INC7409857
Ping Availability CRITICAL - 10.197.5.25: rta nan, lost 100%

INC7409858
Ping Availability CRITICAL - 10.197.6.26: rta nan, lost 100%

INC7409859
Ping Availability CRITICAL - 10.197.6.16: rta nan, lost 100%

INC7409863
Ping Availability CRITICAL - 10.197.5.27: rta nan, lost 100%

INC7409864
Ping Availability CRITICAL - 10.197.5.20: rta nan, lost 100%

INC7409866
Ping Availability CRITICAL - 10.197.5.13: rta nan, lost 100%

INC7409868
Ping Availability CRITICAL - 10.197.5.14: rta nan, lost 100%

INC7409875
Ping Availability CRITICAL - 10.197.6.27: rta nan, lost 100%


INC7481661
cache clear for JQ1, LQ1, WQ1.
10.6.2.12
10.6.2.19



INC7481685    P2 - Major    Raycap GmbH    Processor_load_is_too_high_on_deeh11ryc1008.imzcloud.ibmammsap.local
10.7.64.19 




10.136.33.38:/usr/sap/trans                  4.8G  4.3G  299M  94% /usr/sap/trans



INC7483258    P1 - Severe    Panasonic North America        Zabbix_agent_on_pn4us7lewmp1.imzcloud.ibmammsap.local_is_unavailable
-----------------------------------------------------------------------------------------------------------------------------------------

1 April

INC7525403    IBM AMM SAP Client Tribe Infrastruc    P1 - Severe    Zabbix_agent_on_dal09ammsol05.imzcloud.ibmammsap.local_is_unavailable
146.89.140.4



INC7525807    PT Anugerah Pharmindo Lestari    P1 - Severe
Free_disk_space_is_less_than_5%_on_volume_/usr/local[
10.70.31.16 


INC7525826    PT Anugerah Pharmindo Lestari    P1 - Severe
Free_disk_space_is_less_than_5%_on_volume_/var/log
10.70.31.16


CTASK0097805: VM Snapshot of 4 Servers Liste
12-ERP-TN-ABAP-ASE	SNCHTNAQD11	10.73.12.76	done
13-BOBJ-ASE	                SNCHBIBQD11	        10.73.12.37
14-BODS-ASE	                SNCHDSBQD11	10.73.12.45	done
11-NWG-ABAP-ASE	         SNCHEUAQD11	10.73.12.95

DO not delete the snapshot as it will be reverted in a week.



INC7526570    Bombardier Recreational Products Inc    P1 â€“ Severe
10.138.10.62
Zabbix_agent_on_br3qgtss36.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12191070]



A0GIDE014XVM006
A0GIDE014XVM001  




INC7292990    Panasonic Europe Ltd    CMS-SAP    PEU-01    P1 - Severe    PEU        Free_disk_space_is_less_than_5%_on_volume_/usr/local[PROBLEM:11468214]
100.126.65.228


INC7352135    Panasonic Europe Ltd    CMS-SAP    PEU-01    P1 - Severe    PEU        AFQ: Low free DATA space in database saptools: 0.07%
100.126.65.208

INC7352253    Panasonic Europe Ltd    CMS-SAP    PEU-01    P1 - Severe    PEU        Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:11602670]
100.126.65.26

INC7510290    Panasonic Europe Ltd    CMS-SAP    PEU-01    P1 - Severe    PEU        AFQ: Low free LOG space in database AFQ: 4.97%



INC7006072    IBM AMM Infrastructure    CMS-Infrastructure    IBMAMMINFRA-03    P1 - Severe            Free_disk_space_is_less_than_5%_on_OS_volume_/
146.89.140.28
-rw-r--r--. 1 smdadm sapsys 17394954240 Apr  1 10:15 dev_rout
[root@dal09ammsrtr2 smdadm]# pwd
/home/smdadm



INC7329198  Free_disk_space_is_less_than_5%_on_volume_/usr/sap/EPJ/SCS11[PROBLEM:11562636]
10.15.80.20



pw reset and enable account login

-----------------------------------------------------------------------------------------------------------------------

2 April

INC7533374    P1 - Severe    Panasonic North America        Zabbix_agent_on_pn4us7lap1q1.imzcloud.ibmammsap.local_is_unavailable

 systemctl status besclient.service



SR0021255
Set crontab entry in s4padm

Set below crontab entry in s4padm
0,10,20,30,40,50 * * * * /home/s4padm/fileperm.sh 

Server details:
10.6.7.16  -- PBBs4hpap00

This entry was set some time back. Now we are seeing it missing.




SR0019893
Create a directory and mount a CIFS share on SAP System DP1 (APLBREDP1)
Please create the directory /usr/data-exchange and mount the following share via CIFS permanent to this directory.

Source  APLBREDP1 	170.225.68.11	10.92.144.11
Server: DC000PCA079.epmassetis.com (10.92.146.173)
Share: \\10.92.146.173\DP1
User: epmassetis\SAP_DP1_KOM
Password: ez-1KFV6gKf3Xv


uid=20000(dp1adm) gid=3050(sapsys) 


mount.cifs //10.92.146.173/DP1 /usr/data-exchange  -o domain=epmassetis username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,_netdev,nofail,sec=ntlm

mount.cifs //10.92.146.173/DP1 /usr/data-exchange cifs -o domain=epmassetis,username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,sec=ntlm

mount.cifs //10.92.146.173/DP1 /usr/data-exchange cifs credentials=/etc/DP1credentials,uid=20000,gid=3050,_netdev,sec=ntlm
username=epmassetis\SAP_DP1_KOM
password=ez-1KFV6gKf3Xv


//10.92.146.173/DP1 /usr/data-exchange cifs domain=epmassetis,username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,uid=20000,gid=3050,_netdev,nofail 0 0

//10.92.146.173/DP1 /usr/data-exchange cifs domain=epmassetis,username=SAP_DP1_KOM,passwd=ez-1KFV6gKf3Xv,uid=20000,gid=3050,_netdev,nofail,sec=ntlm 0 0






INC7534445-
IMZlogin issue -H4S db server-handvh4ssrv01    10.15.192.21
dal13-pod1-4tb-host02.imzcloud.ibmammsap.local vsphere 10.186.255.76 root/m1gyoF6v4z@

Wr*35|S_



INC7305252
SNCEDEVHEC001 	10.73.11.159
ANE4174E Full VM backup of VMware Virtual Machine 'sncedevhec001' failed with RC=4379 mode=Incremental Forever - Incremental, target node name='AMM_A0B4CA01_DC'

------------------------------------------------------------------------------------------------------------------------

3 April


SR0021355    Medium    Hanon Systems
Please provide the usage data for Marc-2019 



INC7543775
ERCSOLPRD1    ESM    10.10.0.105    10.5.1.106



INC7544413
Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:12256474]

-----------------------------------------------------------------------------------------------------------------------------

4 April

SR0021455
snchbwjpd11
SAP-HEC-Swivel:Managed system configuration-PB6
installed telnet on 2 servers







CHG0103794	330 to 730 PM IST 
DBJ:  sjmdbjdb01   10.198.11.16   10.195.2.16	A0FGSG014XVM008
[root@sjmdbjdb01 tmp]# uname -a;date;cat /etc/redhat-release
Linux sjmdbjdb01 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Thu Apr  4 10:33:24 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@sjmdbjdb01 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux sjmdbjdb01 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Apr  4 10:54:30 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

DWD:  SJMDWDWD01   10.198.13.10   10.195.0.10	A0FGSG014XVM013	
[root@sjmdwdwd01 tmp]# uname -a;date;cat /etc/redhat-release
Linux sjmdwdwd01 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Thu Apr  4 10:34:21 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@sjmdwdwd01 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux sjmdwdwd01 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Apr  4 10:54:28 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

DMP:  sjmdmpdb01   10.198.11.12   10.195.2.12	A0FGSG014XVM005
[root@sjmdmpdb01 tmp]# uname -a;date;cat /etc/redhat-release
Linux sjmdmpdb01 2.6.32-754.10.1.el6.x86_64 #1 SMP Thu Nov 29 15:44:01 EST 2018 x86_64 x86_64 x86_64 GNU/Linux
Thu Apr  4 10:32:10 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@sjmdmpdb01 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux sjmdmpdb01 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Apr  4 10:54:32 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


10.73.10.166
10.73.10.58


on dal13-pod1-4tb-host02.imzcloud.ibmammsap.local vsphere 10.186.255.76 root/m1gyoF6v4z@


INC7549856 - Free_disk_space_is_less_than_5%_on_volume_/hana/data




systemctl status besclient.service

-----------------------------------------------------------------------------------------------------------------------------------

5 April

SR0021457
  i) login to host
snchpijpa12 and ping 'snchsmapa11.hec.network.lan'. ii) Telnet to host
'snchsmapa11.hec.network.lan' and port 6001 from snchpijpa12.
let us know the output of both the commands.


INC7559417	sev3
TSM: wdc04ammtsm001.ibmammsap.local ANR2579E Schedule DLY_INC_0030 in domain NFL_N_FIL for node CRW_CRWBI1VW126_FIL failed (return code 12).~



INC7561366    Raycap GmbH    P1 - Severe    RYC    SAP07    Free_disk_space_is_less_than_5%_on_OS_volume_/home
10.7.64.13



NC7561213    Raycap GmbH    CMS-SAP    RYC-01    P2 - Major    RYC    SAP07    Free_disk_space_is_less_than_10%_on_OS_volume_/home
10.7.64.13


INC7562962 Bombardier Recreational Products Inc P1
Zabbix_agent_on_br3dsapa52.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12321059]



INC7561150
Free_disk_space_is_less_than_10%_on_volume_/var/log[


INC7292990
Free_disk_space_is_less_than_5%_on_volume_/usr/local[PROBLEM:11468214]
100.126.65.228 





INC7560346

Account name- PEU
Site - FRA02

Servers -

PEU-POP-CI	100.126.65.139
PEU-POT-CI	100.126.65.26
PEU-AEP-CI	100.126.66.76	
PEU-AET-CI	100.126.66.75

Request - On each of the above servers, please perform the following task.

1) Install FTP service on the above service and configured the FTP as "Server"
2) Create a directory "Interface" in the root
3) Create a user Id 'PEU-FTP" and add it to the group " PEU-FTP-GRP"
4) The "PEU-FTP" user should have Read/Write permission to the " Inteface" directory
5) The "PEU-FTP" user Id should also have access to run TELNET


usermod -m -d /interface username

Note - 

If the OS does not support having the sign "-" in the user and group name then you can create the user Id as "PEUFTP" & group as "PEUFTPGRP"





SC8SANS4D22   DAL13	10.186.10.28	SANCOR Argentina	Dallas 13	Development	SC8	10.15.31.12	

CHEF_ORG=SC8 knife node show SC8SANS4D22.imzcloud.ibmammsap.local
Node Name:   SC8SANS4D22.imzcloud.ibmammsap.local
Environment: sc8_production_sles
FQDN:        SC8SANS4D22.hec.sancorseguros.net
IP:          169.60.162.215
Run List:    role[baseos]
Roles:       baseos, itcs104


[root@DAL13AMMCHEF01 ~]# knife environment list
_default
sc8_development
sc8_production
sc8_production_sles

rake bootstrap:cms3x[root,10.15.31.12,development,cms3x_cfg,SC8SANS4D22.imzcloud.ibmammsap.local}





saps09db00   DAL13	10.186.10.49	Pepsico	Customer	Dallas 13	pep 	100.126.32.106	QA
CHEF_ORG=pep knife node show saps09db00.imzcloud.ibmammsap.local


------------------------------------------------------------------------------------------------------------------------

7 April

: INC7292990 >>Free_disk_space_is_less_than_5%_on_volume_/usr/local[PROBLEM:11468214
root
9rJMtTF8
peu-a4q-db-ha	100.126.65.228 

fra02-pod2-4tb-host05.imzcloud.ibmammsap.local
root/cv19oEYOs3@



INC7582767    Bombardier Recreational Products Inc    P1 - Severe
Zabbix_agent_on_br3tgtsas25.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12376208]
10.138.10.79



INC7451913
Free_disk_space_is_less_than_10%_on_volume_/usr/local[PROBLEM:11929125]
10.15.192.21	handvh4ssrv01 Dal13
dal13-pod1-4tb-host02.imzcloud.ibmammsap.local vsphere 10.186.255.76 root/m1gyoF6v4z@


INC7582942    PT Anugerah Pharmindo Lestari    P2 - Major    Free_disk_space_is_less_than_10%_on_volume_/var/log
10.70.31.87    SNG


INC7584259 AGEAS P1-Severe : Zabbix_agent_on_SVCC2SRV0.imzcloud.ibmammsap.local_is_unavailable
10.6.3.101


------------------------------------------------------------------------------------------------------------------------------------------

8 April




INC7588266    MSC Industrial Supply Co.    P2 - Major    Lack_of_free_swap_space_on_ms3wdcadbsd1.imzcloud.ibmammsap.loca
10.12.6.66



INC7588497    PT Anugerah Pharmindo Lestari    P2 - Major    Free_disk_space_is_less_than_10%_on_volume_/usr/local
10.70.31.16 	root /-MOI?aRt


INC7588288    Panasonic Europe Ltd    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_/var/log


INC7589332    IBM AMM Infrastructure    P2 - Major    Free_disk_space_is_less_than_10%_on_volume_/TSMLOGS/TLOG
146.89.140.50 

INC7589084    IBM AMM Infrastructure    P2 - Major    Free_disk_space_is_less_than_10%_on_volume_/TSMLOGS/TLOG
146.89.140.178


INC7589022	sev3
Request for utilization report for Dilip


--------------------------------------------------------------------------------------------------------------------------

9 April

INC7594458
br3qgtsss35    10.138.10.38		br3qgtsss36	 	10.138.10.62
SAP HANA DB node1( Cluster )    br3qgtsdb36    10.138.10.58
SAP HaNA DB node2 ( Cluster)    br3qgtsdb37    10.138.10.82

SBD_DEVICE="/dev/mapper/sbddisk1" on 36

sbd -d â€œ/dev/mapper/sbddisk1" message br3qgtsdb36 clear

SBD_DEVICE="/dev/mapper/sbddisk1" on 37



INC7597725    P1    Bombardier Recreational Products Inc  Zabbix_agent_on_br3qfiodb34.imzcloud.ibmammsap.local_is_unavailable
10.138.10.42 


DPE: Kuganeswaran KisnianKrishnan <kuganesw@my.ibm.com>

PDL: kuganesw@my.ibm.com,razvan.segneanu@ro.ibm.com

SAP Client Tribe: SAP Client Tribe OS Team@WWPDL

cat /etc/redhat-release ; uname -a ; date
/var/lib/zabbix/check_rw_mounts.sh

CHG0103556	LON	1030-1330 IST	CTASK0098440	
MGGGBJVECCX01 / 10.133.18.171 / QA                         / EVT/EVJ SAP System - SAP Application ABAP and JAVA
[root@MGGGBJVECCX01 tmp]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX01 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Sun Apr  7 13:38:52 BST 2019

[root@MGGGBJVECCX01 ibmrmalik]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX01 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Apr  9 06:35:11 BST 2019


MGGGBJVECCX09	 / 10.133.18.155 / Non-Production  / EVT SAP System - SAP Application ABAP
root pw 9HrvEJoe
[root@mgggbjveccx09 tmp]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux mgggbjveccx09 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Sun Apr  7 13:52:51 BST 2019

[root@mgggbjveccx09 ibmrmalik]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux mgggbjveccx09 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Apr  9 06:30:32 BST 2019


MGGGBJTGTSX01	 / 10.133.18.150 / Non-Production  / EGT SAP System - SAP Application ABAP
[root@mgggbjtgtsx01 tmp]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux mgggbjtgtsx01 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Sun Apr  7 12:54:58 UTC 2019

[root@mgggbjtgtsx01 ibmrmalik]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux mgggbjtgtsx01 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Apr  9 05:28:00 UTC 2019

MGGGBJVECCX03	 / 10.133.18.173 / QA                         / TVT/TVJ SAP System - SAP Application ABAP and JAVA
[root@MGGGBJVECCX03 tmp]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX03 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Sun Apr  7 05:57:51 PDT 2019

[root@MGGGBJVECCX03 ibmrmalik]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX03 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Apr  8 23:04:59 PDT 2019

MGGGBJVECCX05	 / 10.133.18.175 / QA                         / NVT/NVJ SAP System - SAP Application ABAP and JAVA
[root@MGGGBJVECCX05 tmp]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX05 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Sun Apr  7 05:59:31 PDT 2019

[root@MGGGBJVECCX05 ibmrmalik]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX05 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Apr  8 23:05:02 PDT 2019

MGGGBJVECCX07 / 10.133.18.177 / QA                         / XVT/XVJ SAP System - SAP Application ABAP and JAVA
[root@MGGGBJVECCX07 tmp]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX07 2.6.32-754.6.3.el6.x86_64 #1 SMP Tue Sep 18 10:29:08 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux
Sun Apr  7 14:01:15 BST 2019

[root@MGGGBJVECCX07 ibmrmalik]# cat /etc/redhat-release ; uname -a ; date
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJVECCX07 2.6.32-754.11.1.el6.x86_64 #1 SMP Tue Jan 22 17:25:23 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Apr  9 07:05:01 BST 2019

subscription-manager attach

MGGGBJVECCX01	10.133.18.171	/ EVT/EVJ SAP System - SAP Application ABAP and JAVA   completed
MGGGBJVECCX09	10.133.18.155	/ EVT SAP System - SAP Application ABAP		       completed	
MGGGBJTGTSX01	10.133.18.150	/ EGT SAP System - SAP Application ABAP		       completed	

MGGGBJVECCX03	10.133.18.173	/ TVT/TVJ SAP System - SAP Application ABAP and JAVA
MGGGBJVECCX05	10.133.18.175	/ NVT/NVJ SAP System - SAP Application ABAP and JAVA
MGGGBJVECCX07	10.133.18.177	/ XVT/XVJ SAP System - SAP Application ABAP and JAVA 




SR0021825  Mounting of SBI folder from PWD to PEC
PEC
DLBPECAP01	10.13.1.12
DLBPECAP02	10.13.1.13

PWD
DLBPWDAP00	10.13.1.20	172.16.20.20


dir_sharing_nfs 192.168.101(rw,sync,no_root_squash)

/Bank *(rw,sync,no_root_squash)
172.16.20.20:/Bank /Bank nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0




INC7560346

Account name- PEU
Site - FRA02

Servers -

PEU-POP-CI	100.126.65.139
PEU-POT-CI	100.126.65.26
PEU-AEP-CI	100.126.66.76	
PEU-AET-CI	100.126.66.75

Request - On each of the above servers, please perform the following task.

1) Install FTP service on the above service and configured the FTP as "Server"
2) Create a directory "Interface" in the root
3) Create a user Id 'PEU-FTP" and add it to the group " PEU-FTP-GRP"
4) The "PEU-FTP" user should have Read/Write permission to the " Inteface" directory
5) The "PEU-FTP" user Id should also have access to run TELNET

----------------------------------------------------------------------------------------------------------------------------------------

10 April


SR0021927
Please reboot below servers
Host Name 	SID	IFN IP 		CFN IP
PN4US7LAP1Q1 	CQ1	10.12.254.156	10.142.41.155
PN4US7LECCQ1 	CQ1	10.12.254.159	10.142.41.159
PN4US7LEWMQ1 	MQ1	10.12.254.160	10.142.41.162

MH190409V4626390


Host Name 	SID	IFN IP 		CFN IP
PN4US7LAP1Q1 	CQ1	10.12.254.156	10.142.41.155   client
PN4US7LECCQ1 	CQ1	10.12.254.159	10.142.41.159 	server
 


10.12.254.156	-App
10.12.254.159	-CI 


INC7608889    P2 - Major    AGEAS        Processor_load_is_too_high_on_svjd1srv0.imzcloud.ibmammsap.loca


PTPDIENG   (10.70.30.145)
PTPRINJANI (10.70.30.146)



SR0021928
ERU- DYSCIERU2800, 10.1.162.44 (CFN)	10.6.12.44	   10.1.162.44
ARD - DYSCIARD2200, 10.1.162.45 (CFN)	10.6.12.45	   10.1.162.45

ERU

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PEGASO/ERU/outbound	 	/usr/sap/interfaces/ERU/PEGASO

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PEGASO/ERU/inbound	 	/usr/sap/interfaces/ERU/PEGASO/inbound

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PEGASO/ERU/trigger		/usr/sap/interfaces/ERU/PEGASO/trigger

//10.1.161.14/FTP/Dystar-FTP/LocalUser/AXIT/ERU/trigger		 	/usr/sap/interfaces/ERU/AXIT/trigger

//10.1.161.14/FTP/Dystar-FTP/LocalUser/AXIT/ERU/inbound		 	/usr/sap/interfaces/ERU/AXIT/inbound

//10.1.161.14/FTP/Dystar-FTP/LocalUser/AXIT/ERU/outbound		/usr/sap/interfaces/ERU/AXIT/outbound

//10.1.161.14/FTP/Dystar-FTP/LocalUser/SIRON                       	/usr/sap/interfaces/ERU/SIRON

//10.1.161.14/FTP/Dystar-FTP/LocalUser/LOGWIN/ERU/outbound         	/usr/sap/interfaces/ERU/LOGWIN/outbound 

//10.1.161.14/FTP/Dystar-FTP/LocalUser/LOGWIN/ERU/archive          	/usr/sap/interfaces/ERU/LOGWIN/archive 

//10.1.161.14/FTP/Dystar-FTP/LocalUser/FEL/ERU                     	/usr/sap/interfaces/ERU/FEL 

//10.1.161.14/FTP/Dystar-FTP/LocalUser/LOGWIN/ERU/INV              	/usr/sap/interfaces/ERU/LOGWIN/INV 

//10.1.161.14/FTP/Dystar-FTP/LocalUser/LOGWIN/ERU/INV/archive      	/usr/sap/interfaces/ERU/LOGWIN/INV/archive

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PDMS/ERU                    	/usr/sap/interfaces/ERU/PDMS

ARD

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PanAsia/DN/ARD/outbound       	/usr/sap/interfaces/ARD/PanAsia  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PanAsia/IB/ARD/outbound       	/usr/sap/interfaces/ARD/PanAsia/IB  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PanAsia/IB/ARD/archive        	/usr/sap/interfaces/ARD/PanAsia/IB/archive

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PanAsia/IB/ARD/GR             	/usr/sap/interfaces/ARD/PanAsia/IB/GR  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PanAsia/IB/ARD/GR/archive     	/usr/sap/interfaces/ARD/PanAsia/IB/GR/archive  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PanAsia/IB/ARD/INV            	/usr/sap/interfaces/ARD/PanAsia/IB/INV  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PanAsia/IB/ARD/INV/archive    	/usr/sap/interfaces/ARD/PanAsia/IB/INV/archive  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/SIRON                         	/usr/sap/interfaces/ARD/SIRON  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PIL/DN/ARD/outbound           	/usr/sap/interfaces/ARD/PIL

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PIL/DN/ARD/archive            	/usr/sap/interfaces/ARD/PIL/DN/archive    

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PIL/IB/ARD/outbound           	/usr/sap/interfaces/ARD/PIL/IB  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PIL/IB/ARD/archive            	/usr/sap/interfaces/ARD/PIL/IB/archive  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PIL/IB/ARD/GR                 	/usr/sap/interfaces/ARD/PIL/IB/GR  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PIL/IB/ARD/GR/archive         	/usr/sap/interfaces/ARD/PIL/IB/GR/archive  

//10.1.161.14/FTP/Dystar-FTP/LocalUser/PIL/IB/ARD/INV                	/usr/sap/interfaces/ARD/PIL/IB/INV  

-----------------------------------------------------------------------------------------------------------------------------------------

11 April


HO - sev1 - INC7616072
Zabbix_agent_on_ptpbelitung.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12509366]


INC7616082
Zabbix_agent_on_ptpprambanan.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12509394]



egrs4hdevapp	10.135.6.11	 Active: active (exited) (Result: exit-code) since Thu 2019-04-11 03:51:48 +02; 3s ago
egrsolmanprd	10.135.5.11	 Active: active (exited) (Result: exit-code) since Thu 2019-04-11 03:55:45 +02; 9s ago
egrwd-qas	10.135.6.13 	 Active: active (exited) since Thu 2019-04-11 01:59:09 GMT; 6s ago
egrwd-prd	10.135.5.14	 Active: active (exited) since Thu 2019-04-11 04:02:48 +02; 5s ago
egrwd-dev	10.135.6.17	 Active: active (exited) since Thu 2019-04-11 04:06:12 +02; 4s ago



CQ1 - PN4US7LECCQ1 	CQ1	10.12.254.159	WDC	10.12.254.159
Panasonic North America (PN4)
CQ1


CHEF_ORG=CQ1 knife node show smdbuatum3.imzcloud.ibmammsap.local



INC7621943
Zabbix_agent_on_br3qfiodb34.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12519554]
10.138.10.42



CHG0105034
cache clean


INC7622960    P3 - Minor    DyStar Singapore Pte Ltd Processor_load_is_too_high_on_DYSFTPDAPRD01
10.6.11.14 	win


INC7623766	df -h hung	sev2
10.134.17.94:/TSMSTG/TSMSTG21 /lon02ammtsm001-metacopy nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
146.89.140.242



INC7621929    P2 - Major    Bombardier Recreational Products Inc
Free_disk_space_is_less_than_10%_on_volume_/var/log[PROBLEM:12519527]
10.138.10.105



CHG0103450
CTASK0099824 

1:51:19 PM: SID: PPP
Hostname: spsvepdpase01 - 10.6.3.27 (IFN IP) 



INC7624307
FRA TSM down
----------------------------------------------------------------------------------------------------------------------------

15 April

INC7666450    PANARIAGROUP INDUSTRIE CERAMICHE SP    P2 - Major    Processor_load_is_too_high_on_pncdbpop.imzcloud.ibmammsap.local
10.199.1.35


INC7671878    CMA CGM    P2 - Major    Processor_load_is_too_high_on_smboquaqb3.imzcloud.ibmammsap.local
10.78.24.15 


INC7670524    St Jude Medical    P2 - Major    CPU CPU-Utilization CRITICAL: CPU Usage 100% (threshold=98) user=0.00% system=0.00% iowait=0.00% idle=0.00% -



INC7672532--Unable to access the server---MS3WDCLPDB200----10.12.6.78



INC7673182    A.P. Moller Maersk    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_/var/log
100.126.64.139



INC7671531    Limited Brands Inc.    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_/var/log
10.8.8.187 


INC7669379    Panasonic Europe Ltd    P1 - Severe    Zabbix_agent_on_peu-a4q-db-ha.imzcloud.ibmammsap.local_is_unavailable
100.126.65.228 



INC7673401    Raycap GmbH    P2 - Major    Processor_load_is_too_high_on_deeh11ryc1005.imzcloud.ibmammsap.local
10.7.64.14 



INC7618221
Free_disk_space_is_less_than_10%_on_volume_C:[PROBLEM:12514124]
10.6.11.17

INC7640193
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/trans[PROBLEM:12573557]
10.6.11.16 

INC7640215
Disk Utilization /usr/sap/trans 
10.6.11.16 

INC7653315
Processor_load_is_too_high_on_DYSD3DAD3P01[PROBLEM:12618211]
10.6.11.18 	Win


INC7656129 
Processor_load_is_too_high_on_DYSW2DAWWD40[PROBLEM:12629599]
10.6.12.23	Win



INC7609404
DYSD3DAD3P01_has_just_been_restarted[PROBLEM:12493133]
10.6.11.18   win
System Boot Time:          4/10/2019, 6:56:41 AM


*SR0022266 - SUNCOR : Copying Files between servers*
kindly help in mvoing the files from the below sourse and destination as the files are more than 200GB and we cannot use out IMZ user id

Source  : 
SNCHECADD11	10.73.11.88	10.73.11.88		46RF-z!C
Location : /usr/sap/HE1/HDB00/backup/data/DB_DR1


Destination
SNCHECASD11	10.73.11.194 			YeWh*YpA
location :  /usr/sap/HE5/HDB00/backup/data/DB_REF

-----------------------------------------------------------------------------------------------------------------------

15 April

INC7688546    IAG GBS Limited    P2 - Major    @Ravi Malik (3x OS Suppport)
Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:12739572]
10.133.15.25



INC7688544    FCA Bank S.p.A    P2 - Major 
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.199.98.20



INC7688263
FS_is_read_only_on_dyss4apsbq21.imzcloud.ibmammsap.local[PROBLEM:12738937]
10.6.12.34
dyss4apsbq21:/home/ibmrmalik # /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /usr/sap/s4hana/SBQ/IBP /usr/sap/s4hana/SBQ/WM /usr/sap/s4hana/SBQ/PP /usr/sap/s4hana/SBQ/EHS /usr/sap/s4hana/SBQ/SD /usr/sap/s4hana/SBQ/QM /usr/sap/s4hana/SBQ/MM /usr/sap/s4hana/SBQ/FC filesystems are read-only




INC7689930 - P1- AGEAS - SAP-HEC-Swivel:HEC: Mount of Opentext is missing
customer reported moint point missing on Production
Please perform urgent action to mount F:\OpenText\StreamServe\Data\STRS_Spool (OpenText PROD - spsvopltapp01) in spsvepaeapp01 (10.70.111.12) server
//SPSVOPLTAPP01/STRS_Spool      /usr/sap/OpenText/STRS_Spool    cifs    username=admtmp,password=Welcome-1,dir_mode=0777,file_mode=0777 0 0

PTASK0015475  RCA link https://ibmmhas.service-now.com/nav_to.do?uri=problem_task.do?sys_id=a1e0a95edb30fb40d9c4776baf961984

[root@spsvepaeapp01 log]# cat messages.3.gz |zgrep -i STRS_Spool
Apr 14 00:53:41 spsvepaeapp01 kernel: [24502(umount)]: gsch_umount_hook_fn(/usr/sap/OpenText/STRS_Spool,0) doing
Apr 14 00:53:45 spsvepaeapp01 kernel: [24502(umount)]: gsch_umount_hook_fn(/usr/sap/OpenText/STRS_Spool,0) done(0)

[root@spsvepaeapp01 log]# cat /var/log/messages |grep -i STRS_Spool
Apr 16 11:58:25 spsvepaeapp01 kernel: gsch_redirfs_add_mnt(/usr/sap/OpenText/STRS_Spool @ //SPSVOPLTAPP01/STRS_Spool/[ff534d42(cifs)]) done: -1
Apr 16 11:58:25 spsvepaeapp01 kernel: [14367(mount.cifs)]: gsch_mount_hook_fn(//SPSVOPLTAPP01/STRS_Spool/,.,cifs,0,00007feeebb0b0b0) done

[root@spsvepaeapp01 log]# last reboot
wtmp begins Sun Apr 14 03:56:11 2019



INC7689852    FCA Bank S.p.A    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.199.98.20



D3 server down - INC7677787




INC7690749    FCA Bank S.p.A    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.199.98.20



INC7690606    DEGASA S.A. de C.V.    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DG1ERPSLMDG- KB0016174
10.143.30.12

--------------------------------------------------------------------------------------------------------------------------------

17 April

INC7700307    Panasonic North America    P2 - Major



INC7700314    COTY Inc.    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.58


INC7702343

--------------------------------------------------------------------------------------------------

18 April

INC7706605 - HO for OS - ITM Agent Offline: IP1:ms3wdcladb43:SYB - Device not accessiblew
ms3wdcladb43 NodeAlias: 10.12.7.30



INC7714557    P3 - Minor    Hanon Systems
Disk Utilization /tmp CRITICAL: Free 4807.48MB/20.00% (thresh @10.01:20)
 	10.15.192.21	


INC7713148    P2 - Major    Hanon Systems
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.15.192.13 

INC7712020    P3 - Minor    Hanon Systems
Free_disk_space_is_less_than_20%_on_volume_/var/log[PROBLEM:12803697]
10.15.192.21


INC7713171    P2 - Major    DyStar Singapore Pte Ltd
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.6.11.15


INC7716696    P2 - Major    Dixons Carphone
Disk Utilization /usr/sap/QFE CRITICAL: Timeout or no data available for usr/sap/QFE
10.197.6.29


INC7716694    P2 - Major    Dixons Carphone
Disk Utilization /sapstage CRITICAL: Timeout or no data available for sapstage
10.197.6.29


ptpkelimutu3   cpu utilization


INC7713619    P2 - Major    DyStar Singapore Pte Ltd
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.6.11.29

INC7712442    P4 - Minimal    Hanon Systems
Disk Utilization /var/lib/libvirt/images OK: Free 4821.13MB/20.06% (thresh @10.01:20)
10.15.192.21


INC7714482    P2 - Major    CMA CGM
Processor_load_is_too_high_on_smtmquaqt3.imzcloud.ibmammsap.local[PROBLEM:12812162]
10.78.24.17 


INC7714736    P2 - Major    PT Anugerah Pharmindo Lestari
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.70.30.143 


INC7714636    P2 - Major    PT Anugerah Pharmindo Lestari
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.70.31.75 


INC7714549    P2 - Major    COTY Inc.
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.179 


INC7716007    P2 - Major    Dixons Carphone
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DCGQFEAPP30- KB0016174
10.197.6.29

INC7716005    P2 - Major    Dixons Carphone
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DCGHANAPRDDB2- KB0016174
10.197.5.18




INC7715544
Create below ids on respective servers
CD1 :

Server ip : pn4us7leccd1 	10.12.254.89
id : sapcp1  ( this is should be copy of "sapcd1" with same groups )

pn4us7leccd1:/home/ibmrmalik # id sapcd1
uid=70002(sapcd1) gid=70004(dbcd1mon) groups=70004(dbcd1mon),3051(sapinst)
sapcd1:x:70002:70004:sapcd1,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/sapcd1:/bin/csh

sapcp1:x:54717:70004::/home/sapcp1:/bin/bash
pn4us7leccd1:/home/ibmrmalik # cat /etc/passwd |grep -i sapcd1
sapcd1:x:70002:70004:sapcd1,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/sapcd1:/bin/csh

MD1 :

Server Ip : pn4us7lewmd1	10.12.254.120
id : sapmp1 ( this is should be copy of "sapmd1" with same groups)

pn4us7lewmd1:/home/ibmrmalik # id sapmd1
uid=70002(sapmd1) gid=70004(dbmd1mon) groups=70004(dbmd1mon)

useradd -g dbmd1mon -p Security#1 sapmp1




CHG0106097-Certified IT Consultants - TMG(CI3)-18-Apr-2019 08:30:00 PM



INC7717336    P4 - Minimal    Hanon Systems
Disk Utilization /var/lib/mariadb OK: Free 5298.05MB/22.05% (thresh @10.01:20)
10.15.192.21 


INC7717086    P2 - Major    Dassault Aviation
Disk Utilization /var/lib/mailman CRITICAL: Free 1383.37MB/9.91% (thresh @5.01:10)
 10.78.30.22


INC7717083    P2 - Major    Dassault Aviation
Disk Utilization /var/lib/libvirt/images CRITICAL: Free 1383.37MB/9.91% (thresh @5.01:10)
10.78.30.22

INC7716866    P2 - Major    Dassault Aviation
Disk Utilization /var/cache CRITICAL: Free 1384.41MB/9.92% (thresh @5.01:10)
10.78.30.22


SR0022642
Host file entry
10.170.63.25

--------------------------------------------------------------------------------------------------------------------------

19 April

INC7717849    P2 - Major    COTY Inc.
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.177


INC7717734    P2 - Major    PT Anugerah Pharmindo Lestari
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:
10.70.30.142 


INC7729104
Zabbix_agent_on_br3qfiodb35.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12851842]
10.138.10.104 


INC7730021    P2 - Major    Hadi Hamad Al-Hammam Contracting Co
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.7.14.75 




INC7729809    P2 - Major    Dassault Aviation
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.78.30.22 


INC7729554    P2 - Major    DyStar Singapore Pte Ltd
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.6.11.11


INC7729652    P2 - Major    COTY Inc.
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.12


INC7729599    P2 - Major    COTY Inc.
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.177 


INC7729461    P2 - Major    COTY Inc.
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.11



INC7730720    P1    Bombardier Recreational Products Inc    Zabbix_agent_on_br3qsapas31.imzcloud.ibmammsap.local_is_unavailable
10.138.10.33




CHG0106097-Certified IT Consultants - TMG(CI3)-18-Apr-2019 08:30:00 PM
i) please create below files systems on CI2DEVAPP server with corresponding given sizes

File Systems required size :
-------------------- ------------------
/usr/sap/M2D 120 GB  	vg_app   lv_m2d		/dev/vg_app/lv_m2d
/usr/sap/trans 30 GB	vg_app   lv_trans
/usr/sap/ccms 5 GB  	vg_app   lv_ccms      
/usr/sap/DAA 5 GB	vg_app   lv_daa
/interface/M2D 2 GB	vg_app   lv_im2d

/sapmnt/M2D 20 GB   	vg_app   lv_sm2d   
/sapstage 5 GB          vg_app   lv_sapstage

/home/m2dadm 2 GB  	VolGroup    lv_m2dadm    
/home/daaadm 2 GB	VolGroup    lv_daaadm 
/home/sapadm 2 GB	VolGroup    lv_sapadm

ii)  take copy of /usr/sap/* into a temporary FS (/tmpfs) 
note: (keep the same ownership and permission, do not change it) 
server details : : CI2DEVAPP : 10.5.242.16	LON02


lvcreate -L 6G -n usrsapdaa_lv VolGroup
mkfs.ext4 path of lvdisplay


/dev/mapper/VolGroup-usrsapdaa_lv /usr/sap/DAA ext4 defaults 1 2
mkfs.ext4 path of lvdisplay

/dev/vg_app/lv_m2d    /usr/sap/M2D  ext4        _netdev,defaults    1 2
/dev/vg_app/lv_trans    /usr/sap/trans  ext4        _netdev,defaults    1 2
/dev/vg_app/lv_ccms    /usr/sap/ccms  ext4        _netdev,defaults    1 2
/dev/vg_app/lv_daa    /usr/sap/DAA  ext4        _netdev,defaults    1 2
/dev/vg_app/lv_im2d    /interface/M2D  ext4        _netdev,defaults    1 2
/dev/vg_app/lv_sm2d    /sapmnt/M2D  ext4        _netdev,defaults    1 2
/dev/vg_app/lv_sapstage    /sapstage  ext4        _netdev,defaults    1 2
/dev/VolGroup/lv_m2dadm    /home/m2dadm  ext4        _netdev,defaults    1 2
/dev/VolGroup/lv_daaadm    /home/daaadm   ext4        _netdev,defaults    1 2
/dev/VolGroup/lv_sapadm    /home/sapadm  ext4        _netdev,defaults    1 2


INC7731688
Free_disk_space_is_less_than_10%_on_volume_/usr/sap
10.69.0.18 




INC7732500    P1 - Severe    COTY Inc.   Zabbix_agent_on_ctubwqb2ap01.imzcloud.ibmammsap.local_is_unavailable
10.12.10.143 	 root/%FgwMVKo

ctubwqb2ap01:/home/ibmrmalik # date
Fri Apr 19 10:05:38 CEST 2019
ctubwqb2ap01:/home/ibmrmalik # uptime
 10:05am  up 168 days 10:20,  3 users,  load average: 0.08, 0.06, 0.04
ctubwqb2ap01:/home/ibmrmalik # systemctl status zabbix-agentd.service
â— zabbix-agentd.service - Zabbix Monitor Agent
   Loaded: loaded (/usr/lib/systemd/system/zabbix-agentd.service; enabled; vendor preset: disabled)
   Active: active (running) since Fri 2019-04-19 10:01:48 CEST; 3min 57s ago
 Main PID: 7042 (zabbix-agentd)
    Tasks: 9 (limit: 512)






INC7732605    COTY Inc.    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.58

INC7732565    Delta Airlines    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.4.5.156 



INC7732549    COTY Inc.    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.137 


INC7732176    PT Anugerah Pharmindo Lestari    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.70.31.16 


INC7731054    P2 - Major    DyStar Singapore Pte Ltd
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.6.11.28


INC7730353    P2 - Major    DyStar Singapore Pte Ltd
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.6.11.11


INC7733782    COTY Inc.    P2 - Major @Ravi Malik (3x OS Suppport)
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.137



INC7733437    Bombardier Recreational Products Inc    P2 - Major
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.138.10.61



RCA    case number 02365299
[ibmrmalik@spsvepaeapp01 ~]$ sosreport     10.6.3.12	10.70.111.12

sosreport (version 3.2)

no valid plugins were enabled

root/wr5?;!DT

Also, I noticed the NFS-shares are not marked with _netdev. Without the _netdev option, entries within /etc/fstab may attempt to mount before networking is initialized causing the mount request to fail due to complete lack of connectivity. It is advised to make the necessary changes as below in /etc/fstab: 10.92.99.110:/usr/sap/trans /usr/sap/trans nfs rw,hard,intr,rsize=32768,wsize=32768,_netdev 1 2 10.70.111.46:/sftp/prd /usr/sap/sftp nfs defaults,_netdev 0 0

[root@spsvepaeapp01 ~]# cat /etc/fstab |grep -i nfs
10.92.99.110:/usr/sap/trans     /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    1 2
10.70.111.46:/sftp/prd  /usr/sap/sftp           nfs     defaults        0 0

10.92.99.110:/usr/sap/trans     /usr/sap/trans  nfs     _netdev,rw,hard,intr,rsize=32768,wsize=32768    1 2
10.70.111.46:/sftp/prd  /usr/sap/sftp           nfs     -netdev,defaults        0 0

10.92.99.110:/usr/sap/trans /usr/sap/trans nfs rw,hard,intr,rsize=32768,wsize=32768,_netdev 1 2 
10.70.111.46:/sftp/prd /usr/sap/sftp nfs defaults,_netdev 0 0



---------------------------------------------------------------------------------------------------------------------------------

21 April


Worked on AGEAS RCA


SR0022716
CHG0106564 	SNG
ECP CI	eccci0prd	10.198.2.140	A0EGSG014XVM005
ECP App	eccap1prd	10.198.2.141	A0EGSG014XVM006
ECP Hana DB	eccdb0prd	10.198.2.142	A0EGSG014XVM007  
snghana-1024-30.xsportal.local	10.116.205.149	root/Kcj0zc2pJv@




CHG0105700	CTASK0101091
reboot SNCHECAPD61 in MON
Restart of  SNCHECAPD61 ; SNCHECAPD11; & SNCHECAPD51 when SAP Performer asks for the Restart during window
SNCHECAPD11 	10.73.10.13	TOR	Between : Sat, Apr 20, 21:00 - 23:00
SNCHECAPD51 	10.73.10.14	TOR	Between : Sat, Apr 20, 13:00 - 01:00
SNCHECAPD61 	10.72.3.10	10.74.0.10	MON	Between : Sat, Apr 20, 19:00 - 21:00




INC7757141   login to one SNC server
10.73.10.24





INC7757224    Toyota Boshoku    CMS-SAP    TBO-01    P1 - Severe    TBO    SAPPJ    Free_disk_space_is_less_than_5%_on_volume_/sapmnt/shared[PROBLEM:12962652]	100.126.48.22


INC7756583    Toyota Boshoku    CMS-SAP    TBO-01    P2 - Major    TBO    SAPPJ    Free_disk_space_is_less_than_10%_on_volume_/sapmnt/shared[PROBLEM:12961467]


INC7755227    Toyota Boshoku    CMS-SAP    TBO-01    P3 - Minor    TBO    SAPPJ    Free_disk_space_is_less_than_20%_on_volume_/sapmnt/shared[PROBLEM:12958592]


INC7756452    Dixons Carphone    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DCGHANAPRDAP2-DR- KB0016174
158.87.44.192		dcghanaprdap2	DCGHANAPRDAP2-DR



INC7756448    Dixons Carphone    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DCGHANAPRDAP2- KB0016174
10.197.5.15 
----------------------------------------------------------------------------------------------------------------------

22 April

MCOT1 EMEA INC7761978 SL-London-02
LONMAGHAN0014	10.69.0.143	10.69.0.143 	root/emXUsz!g  
hosted on lon02drhana006  Private IP: 10.112.13.132
root/b80tP9dI6a@	
IPMI root/LhA9Vpj68V
Redhat CASE 02365920
SL case Case # 78951773





INC7765374    IBM Netcool Auto Ticketing Integration [MHAS]    LONMAGHAN0014    P1 - Severe    Queued    lonmaghan0014.imzcloud.ibmammsap.local_has_just_been_restarted[PROBLEM:13008842]    SQ-SAP-TRIO-11 


INC7764288    Manchester Airport Group    P1 - Severe    lonmaghan0014.imzcloud.ibmammsap.local_has_just_been_restarted


INC7761911 - SL-Frankfurt-02 - TAQA Arabia (TQA) - AMM-SAP - Lost connection to TQP app
App (TQAERPPRD1) and DB (TQAERPPRDH).

---------------------------------------------------------------------------------------------------------------------------------

23 April


INC7773231    2    JGC
Provide CPU and Memory Reports every 3 hours
JGC is currently working on an ongoing migration and as part of the agreement between IBM (DPE and Malcolm Ridge) and customer is to provide a CPU and Memory Report every three hours.
You can use the ones on the attachment as the example, and send it to the following contacts:

1. Adriana Merollo: adriana.merollo@ro.ibm.com
2. Fabian Valverde Lara: fvalverd@cr.ibm.com
3. Alvin Thew: thewayy@my.ibm.com
4. Victor Liviu: victor.sangeorzan@ro.ibm.com

The servers are:

A) P01 (HANA DB) jgcs4prddb 10.199.30.59 - MEM usage normal, CPU usage a bit high but normal, not critical.
B) P01 (S/4HANA APP1) jgcs4prdapp 10.199.30.57 - MEM usage high, but a lot of cached memory and not critical , CPU usage normal 

using "sar -u -f" for CPU and "sar -r -f" for memory and save them each in a separate file


SR0022903 for IMZ request



INC7775803    P2    IBM AMM SAP Client Tribe Infrastruc     Processor_load_is_too_high_on_wdc04ammsol01.imzcloud.ibmammsap.local
146.89.142.30 


INC7776915    P2 - Major    Dassault Aviation
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DASSOLDB- KB0016174
10.78.30.15


INC7776932    P3 - Minor    Hadi Hamad Al-Hammam Contracting Co
System NTP Drift CRITICAL: ERROR - server 146.89.140.204, stratum 0, offset 0.000000, delay 0.00000 23 Apr 07:57:31 ntpdate[78684]: no server suitable for synch
10.7.14.31 



INC7776015
df -h hung so TSM backup affected
TSM: par01ammtsm001.ibmammsap.local ANR2578W Schedule DLY_INC_0430 in domain NFL_N_FIL for node CMA_SMGWDEVDQ2_FIL has missed its scheduled start up window.~
10.78.22.24

-------------------------------------------------------------------------------------------------------------------------------------

24 April

INC7773231    2    JGC     jgcs4prddb    Provide CPU and Memory Reports every 3 hours
You can use the ones on the attachment as the example, and send it to the following contacts:

1. Adriana Merollo: adriana.merollo@ro.ibm.com
2. Fabian Valverde Lara: fvalverd@cr.ibm.com
3. Alvin Thew: thewayy@my.ibm.com
4. Victor Liviu: victor.sangeorzan@ro.ibm.com

The servers are:

A) P01 (HANA DB) jgcs4prddb 10.199.30.59 - MEM usage normal, CPU usage a bit high but normal, not critical.
B) P01 (S/4HANA APP1) jgcs4prdapp 10.199.30.57 - MEM usage high, but a lot of cached memory and not critical , CPU usage normal 

using "sar -u -f" for CPU and "sar -r -f" for memory and save them each in a separate file




INC7701080
Service master CRITICAL: 0 master processes running (thresh 1:)
10.133.16.32



SR0022945    High    Limited Brands Inc
SAP-HEC-SWIVEL-sudo access is mssing at server MPJ ap


3.x - SCO - INC7745677 - SL-Hong Kong-02 - Limited Brands Inc. (LBD) - SAP HEC-AMM - (BD1 / BQ1) System/Instance Is Not Available
INC7789620    P1 - Severe    Limited Brands Inc.    Zabbix_agent_on_LBDBD1DB06.imzcloud.ibmammsap.local_is_unavailable
10.8.8.21   honhana-2048-1.xsportal Private IP: 10.110.7.74	root/mSazJZMDyi@      IPMI root/AWR3Jx7tcY



INC7790734    P2 - Major    COTY Inc.    Memory Virtual CRITICAL: Free Memory 1.40% (thresh 2:)   
10.12.10.46
 
INC7790688    P2 - Major    COTY Inc.       Memory Virtual CRITICAL: Free Memory 1.34% (thresh 2:)
10.12.10.46


A0E3CA014XVM008	Dollar City	Customer	Toronto	Dollar City
A0EASG014XVM015	Ageas	Customer	Singapore	Ageas
A0D4US014XVM011	Toyota	Customer	Dallas	Toyota
A0D4US014XVM003	Toyota	Customer	Dallas	Toyota
A0D4US014XVM014	Toyota	Customer	Dallas	Toyota
 
 
 
 
 vHana	A0ETUS018VHAN11	 	Apple Leisure Group	Customer	Dallas   USSAPAEQDB(A0ETUS018VHAN11) 	RHEL 	QAS 	10.254.3.10 	10.68.215.10
vHana	A0ETUS018VHAN01	 	Apple Leisure Group	Customer	Dallas	USSAPAEDDB(A0ETUS018VHAN01) 	RHEL 	DEV 	10.254.2.10 	10.68.214.10
vHana	A0ETUS018VHAN02	 	Apple Leisure Group	Customer	Dallas  USSAPAEPDB(A0ETUS018VHAN02) 	RHEL 	PRD 	10.254.1.10 	10.68.213.10
vHana	A0DSDE014XVM004	 	Panaria	Customer	Frankfurt
vHana	A0CTHK014XVM030	 	SMRT	Customer	Hong Kong
vHana	A0D8UK014XVM041	 	Manchester Airport Group	Customer	London  A0D8UK014XVM041 	LONMAGHAN0008 	Redhat 	HANA 	London 	UAT 	BU1 	172.22.0.53 	10.69.0.53
vHana	A0D8UK014XVM038	 	Manchester Airport Group	Customer	London  LONMAGHAN0007 	Redhat 	HANA 	London 	UAT 	EU1 	172.22.0.50 	10.69.0.50
vHana	A0D8UK014XVM036	 	Manchester Airport Group	Customer	London	LONMAGHAN0005 	Redhat 	HANA 	London 	PRD 	OP1 	172.22.0.23 	10.69.0.23
vHana	A0EASG014XVM004	 	Ageas	Customer	Singapore	svjq1srv0 	Redhat 	10.6.2.12 	10.70.110.12
vHana	A0EASG014XVM006	 	Ageas	Customer	Singapore
vHana	A0EASG014XVM106	 	Ageas	Customer	Singapore	svcq1hdbsrv01 	Redhat 	10.6.2.15 	10.70.110.15
vHana	A0EASG014XVM109	 	Ageas	Customer	Singapore	10.116.103.217(sng01ammhana004)->A0EASG014XVM109,spsvepdehdb01
vHana	A0EGSG014XVM002	 	Home Control	Customer	Singapore	eccdb0dev 	10.198.2.11 	172.28.28.11 	Hana 	SG 	AGEAS-SVBD1HDBSRV01-SVCD1HDBSRV01.xsportal.local
vHana	A0DIML014XVM028	 	Cerebos	Customer	Singapore
vHana	A0DIML014XVM018	 	Cerebos	Customer	Singapore
vHana	A0CTSG014XVM030	 	SMRT	Customer	Singapore	CLDBPCDTBP1 	10.198.0.142 	10.168.0.142

------------------------------------------------------------------------------------------------------------------------------------------

25 April

INC7773231    2    JGC     jgcs4prddb    Provide CPU and Memory Reports every 3 hours
You can use the ones on the attachment as the example, and send it to the following contacts:

1. Adriana Merollo: adriana.merollo@ro.ibm.com
2. Fabian Valverde Lara: fvalverd@cr.ibm.com
3. Alvin Thew: thewayy@my.ibm.com
4. Victor Liviu: victor.sangeorzan@ro.ibm.com

The servers are:

A) P01 (HANA DB) jgcs4prddb 10.199.30.59 - MEM usage normal, CPU usage a bit high but normal, not critical.
B) P01 (S/4HANA APP1) jgcs4prdapp 10.199.30.57 - MEM usage high, but a lot of cached memory and not critical , CPU usage normal 

using "sar -u -f" for CPU and "sar -r -f" for memory and save them each in a separate file


INC7792125	sev3
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/trans
10.6.12.18 


SR0023125    Medium    American Airlines    A1A-01  
Please help to the deletion of below empty WB retro time file from HEC
production system application server folder.
   Filepath: 
/interface/PYP/300/I/PYI008/INPUT/WB_HEC_RTIME_BIWEEKLY_20190423070802.t
xt

moved the file to /tmp from AHECPSAP01, ahecpsap02 and ahecpsap03


      
SR0023113    Low    Concessionaria Aeroporto Rio de Jan




INC7800969    P1 - Severe    PANARIAGROUP INDUSTRIE CERAMICHE SP    pncapeccp1.imzcloud.ibmammsap.local_has_just_been_restarted
10.199.1.36 
reboot   system boot  4.4.143-94.47-de Thu Apr 25 03:55 - 04:24  (00:28)
reboot   system boot  4.4.143-94.47-de Thu Apr 25 03:31 - 04:24  (00:53)
Apr 25 03:32:51 pncapeccp1 stonith-ng[3312]:   notice: Operation reboot of pncapeccp1 by pncapeccp for crmd.2067@pncapeccp.74858dea: OK
Apr 25 03:32:51 pncapeccp1 pacemakerd[3259]:  warning: The crmd process (3316) can no longer be respawned, shuting the cluster down.
Apr 25 03:55:58 pncapeccp1 kernel: [    0.128716] NMI watchdog: Shutting down hard lockup detector on all cpus





INC7800980    P1 - Severe    PANARIAGROUP INDUSTRIE CERAMICHE SP     COROSYNC_service_not_running
10.199.1.36 



INC7801230    P1 - Severe    PANARIAGROUP INDUSTRIE CERAMICHE SP        PACEMAKER_service_not_running
10.199.1.36 
SBD_DEVICE="/dev/disk/by-id/wwn-0x6000c2982d9d0eac50625effa8669a1e-part1"

sbd -d â€œdev/disk/by-id/wwn-0x6000c2982d9d0eac50625effa8669a1e-part1 message pncapeccp1 clear




INC7801213    P2 - Major    Apple Leisure Group    Lack_of_free_swap_space_on_ussapaeqap01.imzcloud.ibmammsap.local











INC7802147   access issue
IMZ id is not working on Linux servers .
IMZ id " ibmesturgeon " is not working on below servers 
10.70.31.15
10.70.31.16
10.70.31.13
10.70.31.22


INC7802212    P1 - Severe    Bombardier Recreational Products Inc    Zabbix_agent_on_br3dsapa51.imzcloud.ibmammsap.local_is_unavailable
10.138.10.31 




INC7802339    PANARIAGROUP INDUSTRIE CERAMICHE SP    P1 - Severe
Zabbix_agent_on_pncapeccp.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:13166327]
10.199.1.25





INC7783360_P1-Free_disk_space_is_less_than_5%_on_volume_/sapmnt/shared[



INC7801202 
Processor_load_is_too_high_on_pncapeccp3.imzcloud.ibmammsap.local[PROBLEM:13153394]
10.199.1.27 



INC7558847   sev3
LPP: Percentage of maximum logons: 82.00%



INC7398939		sev2
ptpkelimutu3     10.116.245.180
ptpdreamland    10.116.245.177

IMZ login to these servers not working . Please check




INC7718195
Zabbix_agent_on_dal09ammsol05.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:12817198]
146.89.140.4 



INC7721083
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/SBQ[PROBLEM:12822735]

-------------------------------------------------------------------------------------------------------------------------

12 May

SR0024475 for IAM issue


INC8039494    IBM AMM SAP Client Tribe Infrastruc    P2 - Major    Processor_load_is_too_high_on_DAL09AMMSOL04.imzcloud.ibmammsap.local



INC8039622    DyStar Singapore Pte Ltd    P2 - Major    VM CPI-DS Agent (10.150.3.23) as itâ€™s not responding via PING


INC8040016    Apleona GmbH Grounding    P2 - Major    Processor_load_is_too_high_on_APLBREDP1.imzcloud.ibmammsap.local


INC8040072    St Jude Medical    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 23.73 (thresh: 16) -
10.196.4.14



SR0024490    IAG GBS Limited    High    SAP-HEC-SWIVEl: SFTP Quality server connectivity issue -[000273595/2019] -


PTASK0015523 worked on RCA task updation

-------------------------------------------------------------------------------------------------------------------------------------------------
14 May


INC8053994    SNCHTRITA11    P2 - Major    Queued    Memory Swap CRITICAL: Swap free 32.83% (thresh 50:%)    SQ-SAP-TRIO-12
10.73.11.144 


INC8052909
add 10Gb to  /sybase/J1S/saplog1


SR0024607
Please Add 15GB space to below mentioned FS.

1) Add 15 GB space to /usr/sap/transmdg on SNCHMDADA11	10.73.11.104
[root@snchmdada11 ~]# df -h /usr/sap/transmdg
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/d1mappvg-usrtrans_lv
                       59G   38G   18G  68% /usr/sap/transmdg

2) Add 15 GB space to /usr/sap/transslt on SNCHLTADA11	10.73.11.115
[root@snchltada11 ~]# df -h /usr/sap/transslt
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/d1tappvg-usrtrans_lv
                       55G   35G   17G  68% /usr/sap/transslt

Github issue (#1760) Fix Hostname and DNS name discrepancy


INC8056790    Fitbit Inc    P2 - Major    Processor_load_is_too_high_on_fbtprdfirapp.imzcloud.ibmammsap.local[PROBLEM:13957616]
10.4.27.16 

INC8056799    Fitbit Inc    P2 - Major    Processor_load_is_too_high_on_fbtprdfirwd.imzcloud.ibmammsap.local[PROBLEM:13957653]
10.4.27.17 



SR0024614    Suncor Energy Inc.    Medium    SAP HEC Swivel P3 :   Check Telnet and ping to the below desti (269647/2019
Hi Team, Request you to try telnet and ping from our
Development - DX6 	10.73.11.114
Quality - QX6 10.73.12.57  10.73.12.58	10.73.12.56
Production - PX6  10.73.10.68   10.73.10.66   10.73.10.67    10.73.10.69
to the below destination and port.

https://toolkit-api.dnb.com   IP 158.151.242.29            port 443               Standard HTTPS
https://uat.equifax.ca IP 204.19.232.41                port 443               Standard HTTPS
https://www.equifax.ca/ IP 204.19.232.39                port 443               Standard HTTPS


--------------------------------------------------------------------------------------------------------------------------------------

15 May


SR0024700 
DLBSECDB00 	10.13.2.15	172.16.22.15 	Chennai
Please mount below mount points on to DLBSECDB00	10.13.2.15

1.che01ammsol01.imzcloud.ibmammsap.local:/sds  3.6T  2.8T  677G  81% /sds

2./sapmnt/shared/S04/HDB00/backup/data/DB_PEC  from (DLBPECDB01 	10.13.1.23	172.16.20.24)  to   DLBSECDB00 	10.13.2.15	172.16.22.15

mount this FS che01ammsol01.imzcloud.ibmammsap.local:/sds 3.6T 2.8T 677G 81% /sds on App server DLBSECAP01 10.13.2.16





SR0024682
Please take VM snapshot of below server
DLBSECAP01	10.13.2.16
DLBSECDB00	10.13.2.15
chehana-1024-01.xsportal.local	
10.162.24.196
root/D4E04lRjzQBF8Z@

CHG0109442

che01ammsol01.imzcloud.ibmammsap.local:/sds  3.6T  2.8T  677G  81% /sds
reboot   system boot  4.12.14-95.54-de Fri Dec 18 03:30 - 09:26  (05:56)





SR0024776
Take snapshot of a VM pre changes
A0EASG014XVM003 	svjd1srv0



INC7974208
Processor_load_is_too_high_on_dyscierp0100.imzcloud.ibmammsap.local[PROBLEM:13721749]
10.6.11.11 



INC7974290
Processor_load_is_too_high_on_dysdberp0100.imzcloud.ibmammsap.local[PROBLEM:13721916]
10.6.11.15


INC7691788
Processor_load_is_too_high_on_DYSD3DAD3P01[PROBLEM:12746548]
10.6.11.18



INC7693480
Processor_load_is_too_high_on_DYSW2DAWWD40[PROBLEM:12751004]
10.6.12.23 Win



INC7970752
Processor_load_is_too_high_on_dyscibwt2400.imzcloud.ibmammsap.local[PROBLEM:13702781]
10.6.12.47	no access to the server


INC7970848
Processor_load_is_too_high_on_dysciscp0500.imzcloud.ibmammsap.local[PROBLEM:13702953]
10.6.11.16 



INC7602437
ITM Agent Offline: LS1-SVLS1SRV0_LS1_00:Ins
10.6.1.144 

INC7737775
ITM Agent Offline: RQ1-sveq1hdbsrv01:Sys
10.6.2.11 

INC7749189
ITM Agent Offline: EPP-spsvepaeapp01_EPP_00:In
10.6.3.12

INC7764659
ITM Agent Offline: EPP-agesvep:spsvepaeapp01:mySAP
10.6.3.12 

INC7764679
ITM Agent Offline: ES1-sves1srv0:sves1srv0:mySAP
10.6.1.139 


INC7764682
ITM Agent Offline: EQ1-agesveqmhsrv0:Sys
10.6.2.11 


INC7764704
ITM Agent Offline: ED1-sved1hdbsrv01:Sys
10.6.1.11 


INC7764772
ITM Agent Offline: HH1-svch1hdbsrv01:Sys
10.6.1.159 



INC7326740
Free_disk_space_is_less_than_10%_on_volume_/usr[PROBLEM:11558632]
100.126.64.18



SR0024799
10.6.12.21  login issue

---------------------------------------------------------------------------------------------------------------------------------

16 MAy

INC8084750    Manitoba Telecom Services    P1 - Severe    Zabbix_agent_on_r3dev.imzcloud.ibmammsap.local_is_unavailable
10.74.6.40 

INC8086753    FCA Bank S.p.A    P2 - Major    Lack_of_free_swap_space_on_fbsdbd01fgcl.imzcloud.ibmammsap.local[PROBLEM:14058632]
10.199.98.20 


INC8086722    FCA Bank S.p.A    P2 - Major    Memory Swap CRITICAL: Swap free 48.66% (thresh 50:%)
 158.87.44.172


INC8086223
cpwHANAsolApp   and CPWHANASOLMDB
clear cache




HANDVSDASRV01 	10.15.192.16	10.23.192.14




INC8086179    PANARIAGROUP INDUSTRIE CERAMICHE SP    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_/var/log
10.199.1.23 




INC8054107
Memory Virtual CRITICAL: Free Memory 0.81% (thresh 2:%)
10.73.10.125 

---------------------------------------------------------------------------------------------------------------------------

19 May


INC8132798    P1 - Severe    West African Cotton Company        Disk Utilization /usr/sap CRITICAL: Timeout or no data available for /usr/sap

INC8132796    P1 - Severe    West African Cotton Company        Disk Utilization /sapmnt/data CRITICAL: Timeout or no data available for /sapmnt/data
10.197.1.11 

INC8132763    P1 - Severe    West African Cotton Company        Disk Utilization /sapmnt/log CRITICAL: Timeout or no data available for /sapmnt/log
10.197.1.11



INC8132917    P3 - Minor    Hadi Hamad Al-Hammam Contracting Co        Disk Utilization /var/spool CRITICAL: Free 1502.18MB/10.92% (thresh @10.01:20%)
10.7.14.14

INC8132911    P3 - Minor    Hadi Hamad Al-Hammam Contracting Co        Disk Utilization /opt CRITICAL: Free 1502.14MB/10.92% (thresh @10.01:20%)
 10.7.14.14 



INC8134103    P2 - Major    Suncor Energy Inc.        Memory Virtual CRITICAL: Free Memory 0.93% (thresh 2:%)  autoresolved
INC8134099    P2 - Major    Suncor Energy Inc.        Memory Swap CRITICAL: Swap free 49.32% (thresh 50:%)	autoresolved
INC8134045    P2 - Major    Suncor Energy Inc.        Memory Swap CRITICAL: Swap free 28.58% (thresh 50:%)	autoresolved


INC8134752    P1 - Severe    Arnoldo Mondadori Editore SpA Zabbix_agent_on_armfksap301a1.imzcloud.ibmammsap.local_is_unavailable



INC8134929    P1 - Severe    Arnoldo Mondadori Editore SpA        Zabbix_agent_on_armfksap301db.imzcloud.ibmammsap.local_is_unavailable




CTASK0109463
snapshot for A0EASG014XVM039 VM snapshot spsvepajapp01


08956201345 
-----------------------------------------------------------------------------------------------------------------

20 May

root/TR3\jNdP   AGESVEDMHSRV1 	10.6.1.179	10.92.99.176



INC8148002    P1 - Severe    West African Cotton Company        Disk Utilization / CRITICAL: Timeout or no data available for


INC8148137    P1 - Severe    West African Cotton Company        Disk Utilization /usr/sap CRITICAL: Timeout or no data available for /usr/sap


INC8148348    P1 - Severe    West African Cotton Company    Disk Utilization /sapmnt/data CRITICAL: Timeout or no data available for /sapmnt/data
 10.197.1.11 


INC8149477    P2 - Major    Delta Airlines    Processor_load_is_too_high_on_dlthpehdb.imzcloud.ibmammsap.local
10.4.5.52


INC8150185    P2 - Major    Suncor Energy Inc.        Ping Availability CRITICAL - 10.73.10.25: rta nan, lost 100%    


INC8150172    P2 - Major    Suncor Energy Inc.        Ping Availability CRITICAL - 10.73.10.26: rta nan, lost 100%


INC8150965    P2 - Major    Suncor Energy Inc.        Ping Availability CRITICAL - 10.73.11.15: rta nan, lost 100%


INC8150955    P2 - Major    Suncor Energy Inc.        Ping Availability CRITICAL - 10.73.10.25: rta nan, lost 100%


INC8151436    P1 - Severe    PT Anugerah Pharmindo Lestari        Zabbix_agent_on_ptpprambanan.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:14257013]


INC8151403    P1 - Severe    PT Anugerah Pharmindo Lestari        Zabbix_agent_on_ptpborobudur.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:14256989]

--------------------------------------------------------------------------------------------------------------------------------------------------

21 MAy

INC8096562    2    CNG    CROSFLTAM01    Big Fix relay not responding in crosfltam01
 	10.68.210.27	10.68.200.27 	Dallas09
 	
 	
INC8172929 	
crosflsua01	10.68.210.28	Windows 2012 	
https://ibm.box.com/s/ro2zl5cevd59omkav5lcoic89eo7erk5 
http://software.bigfix.com/download/bes/95/util/BESRemove9.5.13.130.exe 
 	
 	
 	
 	
INC8156006    Promociones Habitat S.A.    P3 - Minor    Storage disk required urgently for export works
Please add a new disk of 1.5TB on PHSSAPPRD01(10.5.6.7)
 	10.5.6.7	10.25.0.7
 	

INC8165879  sev2
Login issue on
(DYS) 	DYSFRDAFRQ20 	10.6.12.32	10.1.162.32 




INC8166808    Manitoba Telecom Services    
P1 - Severe    Zabbix_agent_on_r3dev.imzcloud.ibmammsap.local_is_unavailable





ogysj1029  bigfix fixed


provided storage info for 4 servers to a DPE

----------------------------------------------------------------------------------------------------------------------

22 May

INC8178287
MTS    N/A    Zabbix_agent_on_r3dev.imzcloud.ibmammsap.local_is_unavailable


frsaoprxy01
bes   sles sao paulo   	146.89.143.32   


INC8180564  -  P1 -  Disk Utilization / CRITICAL: Timeout or no data available for /



INC8172929 	
crosflsua01	10.68.210.28	Windows 2012 	
fixed besclient 


SR0025448
Perform connection test from DD1 to SolMan PS0
Bluemix DD1 to Solman Ã  Kindly test this please.
NWDI(DD1) Host name = smdi-dev-dd1
NWDI P4 Port = 51004
(smdi-dev-dd1) [root] /root > telnet as-prd-1-ps0.cma-cgm.com 50004
SMDIDEVDD1 	10.78.22.49	10.5.22.49 	Development 	Deployed 	Development	DD1  





INC8155375
Processor_load_is_too_high_on_dyscibwt2400.imzcloud.ibmammsap.local[PROBLEM:14266462]




INC8151412
Zabbix_agent_on_dysfrdafrq20.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:14256993]


Pending config & log files for frlon02prxy02 and DAL09AMMSRTR001


10.20.0.16



INC8183759    P2 - Major    PEPSICO INC    Processor_load_is_too_high_on_pepsapgmqdi01.imzcloud.ibmammsap.local


INC8183608    P2 - Major    PEPSICO INC    Processor_load_is_too_high_on_Pepsapg2qdi00.imzcloud.ibmammsap.local



SR0025481
kindly unlock the IMZ user ibmsmuzavor on the below host
SNCHECAPD11	10.73.10.13

-----------------------------------------------------------------------------------------------------------

23 May


INC8196574    West African Cotton Company    P1 - Severe    Disk Utilization / CRITICAL: Timeout or no data available for /
10.197.1.13


SR0025501
ATTN: RAVI MALIK: Hino Motors Ltd:  Please provide pvs, vgs and df -hT --total output for the below servers


SR0025521    CMA CGM    Low    CMA CGM - Mount request from 10.78.22.12 to 2 servers
mount FS /migrations from IP 10.78.22.12 to following servers: 

smgrcdevdg1 IFN: 10.78.22.48 
smgrcsbxsg1 IFN: 10.78.20.30



INC8198280    AGEAS    
P2 - Major    Processor_load_is_too_high_on_SVCC1SRV0.imzcloud.ibmammsap.local


INC8198689  -  P1  -  Disk Utilization /sapmnt/shared CRITICAL: Timeout or no data available for /sapmnt/shared  -  AFRS4HDEVDB


INC8198743    MSC Industrial Supply Co.
P2 - Major    Lack_of_free_swap_space_on_ms3wdcladb27.imzcloud.ibmammsap.local -


10.20.0.16
10.20.0.18
10.20.0.15
10.20.0.20




lonhana-1024-10.xsportal.local
(London 2)
Private IP: 10.164.30.155

-----------------------------------------------------------------------------------------------------------------

27 May


INC8258209    P2 - Major    Wakefern Food Corporation    Processor_load_is_too_high_on_wkfsw1wd03.imzcloud.ibmammsap.local
10.139.100.18



INC8259206    P2 - Major    Dilip Buildcon Limited    Processor_load_is_too_high_on_DLBQECAP01.imzcloud.ibmammsap.local
10.13.2.12 


INC8258262    P2 - Major    GKN Driveline Newton LLC    Processor_load_is_too_high_on_gknfioriprd.imzcloud.ibmammsap.local
10.15.80.18 


uname -a;date;cat /etc/redhat-release

CHG0110664-CMA CGM (CMA)-27-May-2019    Paris   27/05/2019 17:30:00  21:30:00   not approved yet
CMA PAR01/NON PROD Apply Latest Q219 Patches on <<LINUX>> Servers.
	SMBOUATUB3	10.78.26.12	10.5.26.12	Test
Linux smbouatub3 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 11:17:07 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

Linux smbouatub3 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 13:21:33 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


	SMCRMUATUR3	10.78.26.18	10.5.26.18	Test
Linux smcrmuatur3 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 13:18:42 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

Linux smcrmuatur3 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 15:13:13 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


	SMBWUATUW3	10.78.26.28	10.5.26.28	Test
Linux SMBWUATUW3 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 11:19:41 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

Linux SMBWUATUW3 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 13:17:31 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)



SMGWUATUQ2	 	10.78.26.23	10.5.26.34	QA
Linux smgwuatuq2 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 11:20:41 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

Linux smgwuatuq2 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon May 27 13:44:49 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@smgwuatuq2 tmp]# cat /etc/sysconfig/clock
UTC=true




CHG0110877-Tata Steel Limited (TTA)-27-May-2019   not yet requested
27/05/2019 13:00:00  15/06/2019 08:30:00
Internal/Customer DR Test for TATA Steel (TTA)
Production = Chennai
DR = Hong Kong

Application Servers : 

sapapp19 10.170.61.74(CFN)/10.207.61.215(IFN)
sapapp20 10.170.61.48(CFN)/10.207.61.195(IFN)
sapcrmapp1 10.170.61.27(CFN)/10.207.61.24(IFN)
ewmapp1	10.170.61.68(CFN)/10.207.61.77(IFN)
tsgpprd	10.170.61.20(CFN)/10.207.61.41(IFN)
tscmlprd 10.170.61.15(CFN)/10.207.61.36(IFN)
prdrep	10.170.61.32(CFN)/10.207.61.220(IFN)
biprdapp3 10.170.61.17(CFN)/10.207.61.31(IFN)
adsprds	10.170.61.25(CFN)/10.207.61.29(IFN)
sapboprd 10.170.61.58(CFN)/10.207.61.205(IFN)
sapcrmdi 10.170.61.69(CFN)/10.207.61.83(IFN)
essmssdev 10.170.61.63(CFN)/10.207.61.210(IFN)
ttar3dev 10.170.61.22(CFN)/10.207.61.72(IFN)

HANA DR Servers are the only once to be worked on :
(PROD) TSLEECPRDDB 10.170.61.59(CFN)/10.207.61.78(IFN) => (DR) jsitrs0101-dr 10.170.64.15(CFN)/10.204.64.13(IFN)
(PROD) TSLBWPRDDB 10.170.61.53(CFN)/10.207.61.200(IFN) => (DR) TSLBWPRDDB-DR 10.170.64.25(CFN)/10.204.64.11(IFN)





INC8259495    P2 - Major    Wakefern Food Corporation        Processor_load_is_too_high_on_wkfsw1wd01.imzcloud.ibmammsap.local
10.139.100.15 


INC8259570    P3 - Minor    CMA CGM        CPU utilization on QT3
CPU utilization on QT3
DESCRIPTION :CPU utilization of QT3 observed at 80% today 24th May. Slowness observed in QT3 23rd May.
Please check.
AFFECTED USER CONTACT DETAIL :
AFFECTED USER EMAIL : Shilpadesai_B@infosys.com

SMDBQUAQT3 	10.78.24.16	10.5.24.16
[root@smdbquaqt3 ~]# uptime
 10:12:25 up 24 days, 47 min,  1 user,  load average: 0.40, 0.99, 1.54
 
top - 10:13:01 up 24 days, 48 min,  1 user,  load average: 0.45, 0.94, 1.50
Tasks: 2795 total,   1 running, 2794 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.3%us,  0.1%sy,  0.0%ni, 98.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  1009.597G total,  438.665G used,  570.932G free,  322.184M buffers
Swap:   50.000G total,    0.000k used,   50.000G free,  193.400G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
101160 qt3adm    20   0  243g 238g  31g S 156.9 23.6   5219:02 hdbindexserver


SMTMQUAQT3 	10.78.24.17	10.5.24.17
top - 10:13:43 up 6 days, 17:23,  1 user,  load average: 5.23, 6.18, 5.98
Tasks: 409 total,   7 running, 402 sleeping,   0 stopped,   0 zombie
Cpu(s): 76.5%us,  2.0%sy,  0.0%ni, 20.1%id,  1.1%wa,  0.0%hi,  0.3%si,  0.0%st
Mem:    62.901G total,   62.356G used,  557.918M free,   10.438M buffers
Swap:   48.000G total, 8913.496M used,   39.295G free,   38.679G cached

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 37208 qt3adm    20   0 58.6g 7.1g 5.4g R 94.8 11.3  74:57.98 QT3_10_BTC_W56
 56806 qt3adm    20   0 59.5g 3.4g 759m R 92.4  5.4  32:54.59 QT3_10_BTC_W47
 39802 qt3adm    20   0 59.9g 3.5g 428m R 92.1  5.5  51:19.54 QT3_10_BTC_W57
 52064 qt3adm    20   0 57.8g 3.5g 2.5g R 91.5  5.6  15:44.18 QT3_10_BTC_W58
 56429 qt3adm    20   0 57.0g 3.1g 3.0g S 73.3  5.0   0:42.10 QT3_10_DIA_W6
 56537 qt3adm    20   0 57.0g  12g  11g R 69.3 19.3   6:42.79 QT3_10_DIA_W4
109596 qt3adm    20   0 57.1g  25g  24g S 28.4 39.9  56:42.46 QT3_10_DIA_W25
 56401 qt3adm    20   0 57.0g 6.2g 6.1g R 27.7  9.9   3:13.18 QT3_10_DIA_W20
109443 qt3adm    20   0 57.0g  22g  21g S 16.5 35.2  26:13.00 QT3_10_DIA_W22
108073 qt3adm    20   0 57.1g  21g  21g S 11.2 34.6  31:01.57 QT3_10_DIA_W15
109262 qt3adm    20   0 57.0g  25g  24g S  9.6 40.0  48:25.59 QT3_10_DIA_W17
106367 qt3adm    20   0 57.0g  17g  17g S  3.3 28.4  30:06.06 QT3_10_DIA_W2
109587 qt3adm    20   0 57.0g  20g  19g S  2.6 31.9  38:46.30 QT3_10_DIA_W21
  9940 qt3adm    20   0 57.0g  13g  13g S  2.3 21.2   6:42.53 QT3_10_DIA_W9
106516 qt3adm    20   0 57.0g  22g  22g S  2.3 36.5  46:00.61 QT3_10_DIA_W39



Sanvisiya@01jit


INC8260047    CMA CGM    CMS-SAP    CMA-01    P1 - Severe    CMA    SAP12    Free_disk_space_is_less_than_5%_on_OS_volume_/var[PROBLEM:14567639]    Queued    SQ-SAP-TRIO-12
10.78.26.18 


pw reset SR0025983  ref CHG0112426
SJMQCPAA01 10.198.12.18  CI qrpadm 

sjmqepaa01 10.198.12.13  CI qepadm


INC8262098 - SL-Montreal-01 - Bombardier Recreational Products In - SAPHEC-IC4SAP-SL - Client cannot acess the PSA Solution manager.
br3phana50    10.138.10.25
mon01-pod1-4tb-host01.imzcloud.ibmammsap.local
MOntreal  10.140.48.187		root/zZNP1H%9HNNdcC@

-----------------------------------------------------------------------------------------------------------------------------------------------

28 May

INC8265196    Bombardier Recreational Products Inc    P1 - Severe    (Received during suppression) Disk Utilization /var/lib/pgsql CRITICAL: Free 1160.39MB/4.88% (thresh @0:5%)
10.138.10.66




INC8265172    Bombardier Recreational Products Inc    P1 - Severe    (Received during suppression) Disk Utilization /var/lib/mariadb CRITICAL: Free 1188.79MB/5.00% (thresh @0:5%)
10.138.10.66 




INC8272590    Inter Pipeline Fund    
P1 - Severe    Host Reboot CRITICAL: Uptime 5 minutes (thresh 60 min) - @Ravi Malik (3x OS Suppport)
10.138.3.19

[root@iplsapodt01 ~]# egrep "reboot|down" /var/log/messages
May 28 00:57:10 iplsapodt01 sssd[pam]: Shutting down
May 28 00:57:10 iplsapodt01 sssd[nss]: Shutting down
May 28 00:57:10 iplsapodt01 sssd[be[imzcloud.ibmammsap.local]]: Shutting down
[root@iplsapodt01 ~]#

[root@iplsapodt01 ~]# who
ibmavadgave pts/0        2019-05-28 00:48 (146.89.142.60)
ibmvkosgi pts/1        2019-05-28 00:49 (146.89.140.60)
root     pts/3        2019-05-28 00:56 (146.89.141.151)
root     pts/4        2019-05-28 01:14 (146.89.141.151)
root     pts/5        2019-05-28 01:17 (146.89.141.151)




INC8272732    Inter Pipeline Fund    
P1 - Severe    Host Reboot CRITICAL: Uptime 17 minutes -
10.138.1.24 



INC8265171    Bombardier Recreational Products Inc    P1 - Severe    (Received during suppression) Disk Utilization /var/opt/BESClient CRITICAL: Free 1158.31MB/4.89% (thresh @0:5%)


INC8265162    Bombardier Recreational Products Inc    P1 - Severe    (Received during suppression) Disk Utilization /var/crash CRITICAL: Free 1188.79MB/5.00% (thresh



INC8274841    P1 - Severe    COTY Inc.    Disk Utilization /backup CRITICAL: Free 193.45MB/4.04% (thresh @0:5%)    
10.12.10.90 


INC8274832    P1 - Severe    COTY Inc.    Free_disk_space_is_less_than_5%_on_DB_volume_/backup
10.12.10.90 


INC8274826    P2 - Major    COTY Inc.    SQ-SAP-TRIO-11    Free_disk_space_is_less_than_10%_on_DB_volume_/backup
10.12.10.90 


INC8273983
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/QO1[PROBLEM:14601741]
10.78.24.27	smdsquaqo1q71
[root@smdsquaqo1q71 ibmrmalik]# df -hT /usr/sap/QO1
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/qo1appvg-qo1usrQO1_lv
                     ext3  104G   79G   21G  80% /usr/sap/QO1



INC8275095    P2 - Major    St Jude Medical        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.70
10.196.4.14 


INC8276082
OS Pre-requitites of customer Sancor - FRUN
we want to access the Servers of customer Sancor via OPENVPN (ssh).
Actually, we can only access via Putty.


Mandatory Pre-Requisites for onboarding:
As we could view, there are some OS Parameters which are wrong.
PLease check them at all Sancor Servers and correct them:

ALL sap and database user MUST have umask 022 and not 077! Please change it.
Users: <sid>adm, sapadm, syb<sid>, daaadm, dabadm...

E.g.:
[root@SC8SANS4D21 ibmfwarnke]# su - dhdadm
SC8SANS4D21:dhdadm 4> umask
77
SC8SANS4D21:dhdadm 5> logout
[root@SC8SANS4D21 ibmfwarnke]# su - hd0adm
uSC8SANS4D21:hd0adm 51> umask
77
SC8SANS4D21:hd0adm 52> logout

Also user root should have umask 022.

User sapadm login:
[root@SC8SANS4D21 ibmfwarnke]# su - sapadm
This account is currently not available.
Please change in the file /etc/passwd the following line: 
sapadm:x:3050:3050:sapadm,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/sapadm:/sbin/nologin
to:
sapadm:x:3050:3050:sapadm,897/F/^AMM-SAP//IM-Code-Owned,CD=XXXXXXXX,,#FUNC#:/home/sapadm:/bin/csh
The user sapadm must have en environment. Please login as user sapadm and check the umask. If 077 please change to 022!

If any of the named users have a shell based at /etc/passwd: .../bin/sh, please change to /bin/csh

PLEASE restart all affected SAP-Systems and Databases incl. the server OS.


Without this OS-Prerequisites, we can not start the FRUN Onboarding process, because it will FAIL!!!



INC8273695
Processor_load_is_too_high_on_asdtstap.imzcloud.ibmammsap.local[PROBLEM:14600879]
10.7.20.86 



INC7808383
Ping Availability CRITICAL - 10.198.2.142: rta nan, lost 100%





INC8276611

I have been trying to share /usr/sap/trans. but unsuccessful. i have edited the fstab and exports file

source: wkfdf1adb1 - 10.139.100.51 
target: wkfqf1ap01 - 10.139.100.130



INC8276783
Hi OS team,
I seem to not be able to see the file systen when I do "ls"  df -h hung
wkfqf1db01 10.139.100.53
stat("/sapmnt/QF1"
-----------------------------------------------------------------------------------------------------------------------------------

29 May


INC8282923	{COTY Inc --> ctuboqr0db01/10.12.10.72}    P1 - Severe - Assigned
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/QR0/FRS[PROBLEM:14643360]
extended by 20GB


INC8283125	{COTY Inc --> ctuboqr0ap02/10.12.10.74}    P1 - Severe - Assigned
Disk Utilization /usr/sap/QR0 CRITICAL: Free 3403.53MB/4.87%



INC8283220	{COTY Inc --> ctuboqr0ap02/10.12.10.74}    P1 - Severe - Assigned
Free_disk_space_is_less_than_5%_on_volume_/usr/sap/QR0
[root@ctuboqr0ap02 ibmrmalik]# df -h /usr/sap/QR0
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/qr0appvg-qr0usrQR0_lv
                       78G   66G  8.6G  89% /usr/sap/QR0



SR0026177    American Airlines    Medium    SAP HEC Swivel :P3: Interface folder structure for PD2-100-0000299727/2019    - @Ravi Malik (3x OS Suppport) pls kindly check
Hi Support team
Please create interface folder structure for PD2-100 client
Source path: /interface/PD2/120/<all folders & sub-folders>
Target path: /interface/PD2/100/<all folders & sub-folders>
Note: Folder structure only need to be created same as PD2-120, don't
copy the content/data.
JEREMY GALBERT 	Eileen Welsh 	


 
INC8283236    P3 - Minor    PEPSICO INC        TSM: dal13ammtsm001.imzcloud.ibmammsap.local ANR2578W Schedule DLY_INC_2030 in domain NFL_N_FIL for node PEP_PEPSAPGDCDI01_FIL has missed its scheduled start up




INC8284325    P3 - Minor    PEPSICO INC        TSM: dal13ammtsm001.imzcloud.ibmammsap.local ANR2578W Schedule DLY_INC_2230 in domain NFL_N_FIL for node PEP_PEPSAPGSBDI01_FIL has missed its scheduled start up

Hostname : PEPSAPGSBDI01    root/IzTJdRum
login error fixed
umounted /Staging/sapsft


INC8285651
PEPSAPGDBDI00 100.126.32.129
df -h hung
stat("/Staging/sapsft"
pepsapgdbdi00:/home/ibmrmalik # cat /etc/mtab |grep -i sapsft
146.89.140.93:/storage/library /Staging/sapsft nfs4 rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=100.126.32.129,local_lock=none,addr=146.89.140.93 0 0
MuraliGodavari 	KennethWelsh



CHG0112907
A0EASG014XVM003 	svjd1srv0   snapshot


    
INC8287344    P1 - Severe    COTY Inc. 
added 20GB disk to fs



INC8288358    P2 - Major    Hadi Hamad Al-Hammam Contracting Co        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on HHHPHDB
 10.7.14.14 



INC8282727
server inaccessible.




SR0026239



INC8290301  sev1
please reboot server - cannot login and not able to restart DB - SAPS06DB00
pepsi-hana-mdc06.imzcloud.ibmammsap.local
Public IP: 169.48.114.142 (Dallas 13)
Private IP: 10.186.10.18

root/APubn8Rt



ipmi  root/R9RsTdl6Zy
-------------------------------------------------------------------------------------------------------------------------

30 May  48591


SR0026239
Hino Motors Ltd (HNO )- Remove the below unutilized Disks

Tokyo
HNOAPDEV 	10.20.0.16	192.168.16.80	    sdd 200 GB deleted	
HNOSOLMN 	10.20.0.15	192.168.16.79 	    sdn 600gb deleted   sdh 128 GB    hdd 12 vcenter

1. S/4 HANA AP HNOAPDEV HAD >>>>>>>>>>>>>>> SDD 200 GB - 0 disk allocation   deleted

2. HNOSOLMN HSA/HSJ >>>>>>>>>>>>>>>>>>>>>> SDH 128GB - 0 disk allocation
                                                                                                          SDN 600 GB - 0 disk allocation
sdh                          8:112  0  128G  0 disk
sdh - SCSI 0:0:8:0




INC7764767 
11:58:52 AM: my credntials (ibmskurapati) are not working on the server scrbwpdefra20/100.126.64.139 


INC8300774
10.12.10.18 CTUBODR1DB01  need to add 10 gb space for this /dev/mapper/dr1datavg-dr1sapdata2_lv
                       23G   20G  2.1G  91% /sybase/DR1/sapdata2
                       
                       

 lon06ammtsmr001  /  146.89.143.163   no info on relay server
[Software\BigFix\EnterpriseClient\Settings\Client\__Relay_Control_Server1]
value                          = http://fmsprdbfs01.prdcloud.fms.ibmcloud.com:52311
effective date                 = Wed,%2029%20May%202019%2023:13:19%20-0400

[Software\BigFix\EnterpriseClient\Settings\Client\__Relay_Control_Server2]
value                          = ""
effective date                 = Wed,%2029%20May%202019%2023:13:19%20-0400

LON06AMMYUM01 | 146.89.143.158   no besclient installed
lon06ammtsmr001 | 146.89.143.163  reporting to bes



Github #626	Fix OS issue with SLES for SAP VM:  tbos4qasdb (Toyota Boshoku (TBO) SLES for SAP VM)
SLES for SAP VM | tbos4qasdb | Toyota Boshoku (TBO) | Tokyo | SUSE SLES for SAP HANA12.2-64 for SAP HANA
Tokyo  100.126.48.15



INC8302614    MSC Industrial Supply Co.    P2 - Major
Lack_of_free_swap_space_on_ms3wdcwapp09.imzcloud.ibmammsap.local[PROBLEM:14695275]
10.12.6.24



INC8300774
/sybase/DR1/sapdata2
 10.12.10.18 

----------------------------------------------------------------------------------------------

31 May


INC8315695
Free_disk_space_is_less_than_10%_on_volume_/sapmnt/SP1[PROBLEM:14749070]
10.133.15.13 


MOntreal
svorar11v	10.138.12.149	IBM AMMSAP DEV/Test	Non-Customer	Montreal	SDM	SDM ; Development ; Development SAPOS Server <Last Backup (IBM Spectrum Protect)> Last Run Time='04/30/2019 19:21:50' Status='Successful' Data Transmitted='173.82 MB' Duration='00:02:54' Type='Incremental Forever - Incremental' Schedule='DLY_VM_1800' Data Mover='AMM_MON01AMMTSMD001_DM' Snapshot Type='VMware Tools' Application Protection=' ' </Last Backup>	svorar11v	svorar11v	poweredOn	/AMMMON01/SDM - TEST CUSTOMER/NFL-APP oh


SR0026528
Provide the post patching proofs for the 4 servers




INC8316808
ITM Agent Offline: APP-ptpkelimutu:ptpbromo:mySAP
10.70.31.16




INC8316849
ITM Agent Offline: PSA-br3phana50:br3psape50:mySAP
10.138.10.24 




INC8316882
ITM Agent Offline: QB3-ctubwqb3ap01_QB3_02:Ins
10.12.10.145



INC8316949
ITM Agent Offline: MP1-vhlbimp1db01:Slm
10.8.8.73


INC8317431    SR Technics Switzerland Ltd.    CMS-SAP    SRT-01    P1 - Severe    SRT    SAP03    Disk Utilization /home/sapadm CRITICAL: Timeout or no data available for /home/sapadm    Queued    SQ-SAP-TRIO-3
10.71.73.11

INC8317430    SR Technics Switzerland Ltd.    CMS-SAP    SRT-01    P1 - Severe    SRT    SAP03    Disk Utilization /tmp CRITICAL: Timeout or no data available for /tmp    Queued    SQ-SAP-TRIO-3
10.71.73.11 

INC8317370    SR Technics Switzerland Ltd.    CMS-SAP    SRT-01    P1 - Severe    SRT    SAP03    Disk Utilization /home/mdqadm CRITICAL: Timeout or no data available for /home/mdqadm    Queued    SQ-SAP-TRIO-3
10.71.73.11

INC8317331    SR Technics Switzerland Ltd.    CMS-SAP    SRT-01    P1 - Severe    SRT    SAP03    Disk Utilization /home/sapadm CRITICAL: Timeout or no data available for /home/sapadm    Queued    SQ-SAP-TRIO-3
10.71.73.11 


INC8318316    SR Technics Switzerland Ltd.    P1 - Severe
Disk Utilization /usr/sap CRITICAL: Timeout or no data available for /usr/sap
10.71.73.11 

-------------------------------------------------------------------------------------------------------------------------------------------

3 June

INC8348812    COTY Inc.    P3 - Minor    Disk Utilization /var CRITICAL: Free 842.45MB/18.08% (thresh @10.01:20%)
10.12.10.47 


INC8348948    COTY Inc.    
P2 - Major    Free_disk_space_is_less_than_10%_on_OS_volume_/var
10.12.10.47 


SR0026674
Please extend /usr/sap FS by 3 Gb on PTPUMANG / 10.70.31.78



tbos4prdd1	100.126.48.27
tbos4prdd2	100.126.48.25


INC8350596    Suncor Energy Inc.    
P2 - Major    SAP HEC Swivel P2 : SR1 SC1 and SO1 systems are not accessib



SR0026695
Tata Steel Limited -iPERF3 installation on SAPPOQA 10.170.63.50 10.207.63.29 



INC8213357
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/SBQ[PROBLEM:14425149]
10.6.12.34 

--------------------------------------------------------------------------------------------------------------------------------------------

4 June

INC8213357
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/SBQ[PROBLEM:14425149]
10.6.12.34 


INC8362276    IBM AMM Infrastructure    
P2 - Major    Ruuning_out_of_available_memory_on_server_DAL13AMMZAB001.imzcloud.ibmammsap.local
146.89.142.215 



CTASK0113195
spsvepajapp01	10.6.3.13     A0EASG014XVM039




INC8364805 - WDC04-SL - SOUTH CENTRAL CONNECTICUT REGIONAL - IC4SAP-SL - Support team notified CIM stating system is not able to be connected host ID BI1VW140
CRWBI1VW126
CRWBI1VW127
CRWBI1VW128
CRWBI1VW129
CRWBI1VW131
CRWBI1VW138
CRWBI1VW139
CRWBI1VW140
CRWBI1VW141
CRWBI1VW143

---------------------------------------------------------------------------------------------------------------------------------------

5 June

INC8201852    p3
Disk Utilization /home CRITICAL: Free 369.98MB/20.00% (thresh @10.01:20%)
10.197.0.13




INC8023103   AFRS4HQADB    P2  Major   Ping Availability CRITICAL  10.197.1.11: rta nan, lost 100% 
10.197.1.11
                  
                               
                                 

INC8202360   AFRFIORIPRD   P3  Minor   Free_disk_space_is_less_than_20%_on_OS_volume_/home[PROBLEM:14406507]                         
10.197.0.13 



INC8023110
Ping Availability CRITICAL - 10.197.1.14: rta nan, lost 100%
 10.197.1.14 


INC8377925    Dilip Buildcon Limited    P3 - Minor    Request for latest utilization report for Dilip
DLBPBIDA00
DLBPBWAP01
DLBPBWDB00
DLBPCSDA00
DLBPECAP01
DLBPECAP02
DLBPECDB00
DLBPEPDA00
DLBPNGDA00
DLBPWDAP00




SR0027027
Reg: Copy the host files 
Hi,

We have to new systems namely:
RSA and FSA.  Update the hosts files of these 2 servers with the  rest of the landscape servers. ( ATTACHED is the list).

Already this activity was done...but some of the servers entries are missing..so please do the activity with no missing entries.
Make sure the format is same as other servers.

RSA 
iplsas4ad02	10.138.2.19
iplsas4dd04	10.138.2.23

FSA:

iplsafiad02	10.138.2.21

Thanks.

-----------------------------------------------------------------------------------------------------------------

7 Jun

INC8247007
Disk Utilization / CRITICAL: Free 2782.09MB/19.98% (thresh @10.01:20
10.199.99.15	FRA

INC8247003
Disk Utilization /var/log CRITICAL: Free 2783.05MB/19.99% (thresh @10.01:20%)
10.199.99.15


INC8246711
Disk Utilization /opt OK: Free 2794.33MB/20.07% (thresh @10.01:20%)
10.199.99.15

INC8246672
Disk Utilization /var/tmp CRITICAL: Free 2784.12MB/19.99% (thresh @10.01:20%)
10.199.99.15


INC8246671
Disk Utilization /var/cache CRITICAL: Free 2784.12MB/19.99% (thresh @10.01:20%)
10.199.99.15 


SR0027304
Please create directories and mount shares as listed in the attachment


mount.cifs //10.92.146.173/DE1      /usr/data-exchange       cifs -o username=SAP_DE1_KOM,domain=epmassetis,passwd=xxxFrankfurt1#,uid=de1adm,gid=sapsys _netdev,sec=ntlmsspi

//10.92.146.173/DE1 /usr/data-exchange cifs  -o username=SAP_DE1_KOM,domain=epmassetis,passwd=xxxFrankfurt1#,uid=de1adm,gid=sapsys


Create a directory and mount a CIFS share on SAP System DI3 (APLBCSDI2)
Please create the directory /usr/data-exchange and mount the following share via CIFS permanent to
this directory. Owner for this directory is di3adm.
Server: DC000PCA079.epmassetis.com (10.92.146.173)
Share: \\10.92.146.173\DI3
User: epmassetis\SAP_DI3_KOM
Password: xxxLondon1#

mount.cifs //10.92.146.173/DI3 /usr/data-exchange cifs  -o username=SAP_DI3_KOM,domain=epmassetis,passwd=xxxLondon1#,uid=di3adm,gid=sapsys





SR0027313

iplsas4ad02    10.138.2.19	10.11.2.19 	
iplsas4dd04    10.138.2.23	10.11.2.23



ODA    iplsaboad01    10.138.2.20	10.11.2.20


OTA    iplsaboat01    10.138.3.22	10.11.3.22


OPA    iplsaboap01    10.138.1.24	10.11.1.24


OPA    iplsabodp01    10.138.1.23	10.11.1.23



login issue
SCRBWPDEFRA20
SCRBWRDEFRA60

---------------------------------------------------------------------------------------------------------------------

9 June

INC8423291	P2
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.63 (thresh: 16)



INC8420180    Panasonic North America    CMS-SAP    PN4-02    P2 - Major    PN4    SAP10    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN4US7LAPSQP- KB0016174    Queued    SQ-SAP-TRIO-10
10.12.254.152



INC8419518
Disk Utilization /home CRITICAL: Free 4781.20MB/19.99% (thresh @10.01:20%)
170.225.68.25



INC8425509    Panasonic North America    CMS-SAP    PN4-02    P2 - Major    PN4    SAP10    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN4US7LAPSQP- KB0016174    Queued    SQ-SAP-TRIO-10
 10.12.254.152



INC8425729
Disk Utilization /opt CRITICAL: Free 2739.68MB/19.95%
10.199.99.15



INC8426589
Disk Utilization / CRITICAL: Free 2780.23MB/20.00% (thresh @10.01:20%)
10.199.98.20



INC8425876
Disk Utilization /var/lib/mailman CRITICAL: Free 2745.61MB/20.00% (thresh @10.01:20%)
 10.199.99.15



INC8425880
Disk Utilization /home CRITICAL: Free 2745.61MB/20.00% (thresh @10.01:20%)
10.199.99.15




INC8425726
Disk Utilization /var/log CRITICAL: Free 2739.68MB/19.95% (thresh @10.01:20%)
10.199.99.15




INC8426595
Disk Utilization /var/lib/libvirt/images CRITICAL: Free 2780.31MB/20.00% (thresh @10.01:20%)
10.199.98.20 


INC8426367
Free_disk_space_is_less_than_20%_on_volume_/usr/local[PROBLEM:15211213]
10.199.98.20

---------------------------------------------------------------------------------------------------------------------------------------

10 Jun


INC8431521    FCA Bank S.p.A    P2 - Major    Processor_load_is_too_high_on_FBSAPD02FGCL.imzcloud.ibmammsap.local -
10.199.98.13




INC8432430  P1 Panasonic CDIR: PN4 WDC04. Received alert that DB2 instance: db2cp5 restarted 354 seconds ago. Affected CI: PN8US7LDBCP5â€¦.
 ! Critical /CP5MockMig is 94%
! Info Cluster status  Good!





PEU-A4D-DB    100.126.65.24



INC8430680    Apleona GmbH Grounding    P3 - Minor    Disk Utilization /var/spool CRITICAL: Free 4695.27MB/19.61%
 170.225.68.25



INC8430672    Apleona GmbH Grounding    P3 - Minor    Disk Utilization /var/crash CRITICAL: Free 4695.27MB/19.61% (thresh @10.01:20%)
170.225.68.25



INC8416466
Memory Swap CRITICAL: Swap free 48.95% (thresh 50:%)
 10.199.98.20



INC8435444    St Jude Medical    P3 - Minor    System Read Only File Systems CRITICAL: /usr/sap/trans filesystems are read-only
10.196.4.15

[root@juddtrans03 ibmrmalik]# sh /var/lib/zabbix/check_rw_mounts.sh
rm: cannot remove `/usr/sap/trans/testfile': Operation not permitted
rm: cannot remove `/usr/sap/trans/testfile': Operation not permitted
CRITICAL |  /usr/sap/trans /usr/sap/trans filesystems are read-only

mounted on JUDDTRANS01 	10.196.4.11	10.193.0.11




INC8427033    FCA Bank S.p.A    P3 - Minor    Disk Utilization /var/lib/machines CRITICAL: Free 2770.23MB/19.93%
 10.199.98.20
 
 fbsdbd01fgcl:~ # df -h /var/lib/machines
Filesystem               Size  Used Avail Use% Mounted on
/dev/mapper/system-root   15G   11G  3.8G  75% /var/lib/machines

-----------------------------------------------------------------------------------------------------------------------

11 June

INC8443731    AGEAS    P3 - Minor    SAP-HEC-SWIVEL: HEC: Mount directory in 10.70.111.35  SPSVOPLTAPP01 	10.6.3.35   win2k12
 /usr/sap/OpenText/STRS_output is already mounted in 
10.70.111.46   SPHVMPLMAPP01-DR 	10.6.3.46   linux

//spsvopltapp01/AFP /sftp/prd/opentext/ cifs _netdev,username=fileshare,password=Welcome-1,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0

//SPSVOPLTAPP01/STRS_Output /sftp/prd/opentext/ cifs _netdev,username=fileshare,password=Welcome-1,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0

//SPSVOPLTAPP01/OpenText/StreamServe/Data/STRS_Output  /usr/sap/OpenText/STRS_output/ cifs _netdev,username=fileshare,password=Welcome-1,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0

F:\OpenText\StreamServe\Data\STRS_Output in sftp
prod to allow CD to access it via FileZilla.


STRS_Output (file://SPSVOPLTAPP01/STRS_Output)


mount.cifs //SPSVOPLTAPP01/STRS_Output  /usr/sap/OpenText/STRS_output/ cifs  -o username=fileshare,password=Welcome-1,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0




tbos4qasdb 
INC8447535	
Fix OS issue on tbos4qasdb (Toyota Boshoku (TBO) SLES for SAP VM)




----------------------------------------------------------------------------------------------------------------------------------------------

12 June


CHG0110708
System	Production Host Name	CFN IP	IFN IP	DR Host Name	CFN IP	IFN IP
SNG	                                                                         HK 																							
CRM-PRP-HANA 10.116.103.231 sng01ammhana003.xsportal.local
sjmpcpdb01 A0FGSG014XVM039	10.195.1.15	10.198.10.15	SNG	sjmpcpdb01dr 10.110.7.121 honhana-1024-8.xsportal.local
10.195.4.11	10.204.1.11	HK
 
ERP-PEP-HANA 10.116.205.149	snghana-1024-30.xsportal.local
sjmpepdb01 A0FGSG014XVM031	10.195.1.6	10.198.10.6	sjmpepdb01dr 10.110.214.194 honhana-1024-6.xsportal.local
10.195.4.10	10.204.1.10

CRM-PRP-App	sjmpcpaa01 A0FGSG014XVM037	10.195.1.13	10.198.10.13	sjmpcpaa01	10.195.1.13	10.198.10.13
ERP-PEP-APP	sjmpepaa01 A0FGSG014XVM029	10.195.1.4	10.198.10.4	sjmpepaa01	10.195.1.4	10.198.10.4
	Enterprise portal-PPQ	sjmppqdb01 A0FGSG014XVM036	10.195.1.12	10.198.10.12	sjmppqdb01	10.195.1.12	10.198.10.12  KAvGva/J
EP-PPQ	sjmppqaa01 A0FGSG014XVM034	10.195.1.9	10.198.10.9	sjmppqaa01	10.195.1.9	10.198.10.9
web dispatcher	sjmpwdaa01 A0FGSG014XVM042	10.195.0.12	10.198.13.12	sjmpwdaa01	10.195.0.12	10.198.13.12
PO-PXP	sjmpxpdb01 A0FGSG014XVM044	10.195.1.20	10.198.10.20	sjmpxpdb01	10.195.1.20	10.198.10.20
PO-PXP	sjmpxpaa01 A0FGSG014XVM043	10.195.1.19	10.198.10.19	sjmpxpaa01	10.195.1.19	10.198.10.19
SFTP server	sjmpfpaa01 A0FGSG014XVM032	10.195.1.7	10.198.10.7	sjmpfpaa01	10.195.1.7	10.198.10.7


-------------------------------------------------------------------------------------------------------------------------------

13 June

INC8473806  P2
ITM Agent Offline: CTUBOSR1SP02:INTERNET00




tbos4prdd1/tbos4prdd2

Team, can someone from  Morning shift tomorrow will check the following things  on this server?  

1:10:35 PM: tbos4prdd1   100.126.48.27  

the data is being collected from 10am JST, 6:30am IST as requested
- TZ stays JST, no more GMT  

need  to check it at 6.30AM tomorrow  



INC8474092
Free_disk_space_is_less_than_20%_on_volume_/var/log[PROBLEM:15426974]



INC8474199
Free_disk_space_is_less_than_20%_on_volume_/usr/local[PROBLEM:15426975]




INC8474732
Service vmtoolsd CRITICAL: vmtoolsd is not running
10.12.10.129 


INC8475052
Service vmtoolsd CRITICAL: vmtoolsd is not running
10.12.10.111



INC8475030
Free_disk_space_is_less_than_20%_on_volume_/usr/local[PROBLEM:15427323]
170.225.68.25




INC8474071
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.12.10.137 




SR0027699
SAP HEC SWIVEL :P3:Please mount /interface/SAP_PO_FTP in HP-0000329084/2019
Please mount /interface/SAP_PO_FTP to HPP same as in H4Q. Attaching
screenshot for your reference.
 
HPP: (10.15.192.39) handvhppsrv02.hec.hanonsystems.com


 	
HANDVH4QSRV02 	10.15.192.28	10.23.192.28 	
10.100.38.56:/interface/SAP_PO_FTP
                       40G   15G   25G  38% /interface/SAP_PO_FTP
                       
10.100.38.56:/interface/SAP_PO_FTP /interface/SAP_PO_FTP nfs vers=4  0       0







INC8476412
System Read Only File Systems CRITICAL: /SHARE/MNT/FILE063/SAP_ARCH_prd01 filesystems are read-only
-----------------------------------------------------------------------------------------------------------------

16 June


INC8500856
Disk Utilization /var CRITICAL: Free 38.94MB/0.70% (thresh @0:5%)
pn4us7lewmp1c    10.12.254.21	




INC8503292 - SL-Washington-04 - Panasonic North America (PN4) - IC4SAP-SL - Support/Client Teams reported that both systems for PN4: CP1 and SP1 are down

pn4us7lewmp1c:/var/lib/systemd/coredump # ls -ltrS
total 4487544
-rw-r-----+ 1 root root    5732152 Jun 15 09:40 core.gwrd.200000.7b5672f2e7da403cacc4ab7493f01d15.22808.1560606003000000.xz
-rw-r-----  1 root root    7864320 Jun 15 09:42 .#core.MP1_00_DP.200000.7b5672f2e7da403cacc4ab7493f01d15.22684.1560606060000000.xzde02d2247f486375
-rw-r-----  1 root root   15073280 Jun 15 09:42 .#core.MP1_00_DIA_W1.200000.7b5672f2e7da403cacc4ab7493f01d15.22537.1560606003000000.xzce819ba5588680aa
-rw-r-----  1 root root  271577088 Jun 15 09:40 core.ksaagent.0.7b5672f2e7da403cacc4ab7493f01d15.7634.1560606004000000
-rw-r-----  1 root root 2147482624 Jun 15 09:41 .#core.MP1_00_DP.200000.7b5672f2e7da403cacc4ab7493f01d15.22684.15606060600000009646d454058b86ed
-rw-r-----  1 root root 2147482624 Jun 15 09:40 .#core.MP1_00_DIA_W1.200000.7b5672f2e7da403cacc4ab7493f01d15.22537.1560606003000000696432a6fd9fef9b




reboot   system boot  4.4.121-92.98-de Sat Jun 15 18:52 - 22:25  (03:33)
-rw------- 1 root             root         1454 Jun 15 19:04 krb5ccmachine_IMZCLOUD.IBMAMMSAP.LOCAL
-rw------- 1 ibmncastro       domain_users 1574 Jun 15 20:26 krb5cc_82175
-rw------- 1 ibmlmuddalapuram domain_users 1712 Jun 15 21:12 krb5cc_20180
-rw------- 1 ibmsgaur         domain_users 1720 Jun 15 21:15 krb5cc_82565
-rw------- 1 ibmgmorales      domain_users 1577 Jun 15 22:00 krb5cc_96152
-rw------- 1 ibmrmalik        domain_users 1747 Jun 15 22:20 krb5cc_82584





ibmncast pts/0        146.89.140.60    Sat Jun 15 20:26 - 22:03  (01:37)
(unknown :0           :0               Sat Jun 15 18:56   still logged in
reboot   system boot  4.4.121-92.98-de Sat Jun 15 18:52 - 22:32  (03:39)



Jun 15 18:56:52 pn4us7leccp1c salt-minion[2822]: [ERROR   ] Error while bringing up minion for multi-master. Is master at 146.89.142.29 responding?
Jun 15 19:01:47 pn4us7leccp1c sssd[2166]: ; TSIG error with server: tsig verify failure

Jun 15 18:55:37 pn4us7leccp1c salt-minion[2822]: Could not refresh the repositor      ies because of errors.

Jun 15 19:57:55 pn4us7leccp1c chef-client[2782]: [2019-06-15T19:57:55-04:00] ERR     OR: Failed to load data bag item: "linuxad_auth" "customer_realms"


/var/log/messages /var/log/pacemaker.log /var/log/corosync/corosync.log

pn4us7leccp1c    10.12.254.17	
pn4ushleccp1c    10.12.254.18
CP1:



pn4us7lapsp1c    10.12.254.38
pn4ushlapsp1c    10.12.254.39
SP1:


SR0027726
login issue with a sap id



INC8504517    Whirlpool Corporation    SAP    001967-00    P1 - Sever
------------------------------------------------------------------------------------------------------

7 June

INC8511098    Panasonic North America    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.30
10.12.254.14 
top - 22:44:53 up 90 days,  9:59,  2 users,  load average: 10.67, 14.10, 14.86
Tasks: 559 total,   3 running, 556 sleeping,   0 stopped,   0 zombie
%Cpu(s): 99.3 us,  0.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.5 si,  0.0 st
KiB Mem:  32947588 total, 32576024 used,   371564 free,   538660 buffers
KiB Swap: 50331644 total,  1132688 used, 49198956 free. 28453588 cached Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
 9845 db2cp1    20   0 22.331g 9.084g 8.423g S 398.0 28.91 103308:08 db2sysc 0



INC8510978    Panasonic North America    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.33
10.12.254.14



apscnida@cn.ibm.com


INC8509592    AGEAS    P2 - Major    SPSVCPIVSQL01_has_just_been_restarted
10.6.3.36 
System Boot Time:          6/17/2019, 2:49:11 AM
The process C:\Windows\system32\shutdown.exe (SPSVCPIVSQL01) has initiated the restart of computer SPSVCPIVSQL01 on behalf of user IMZCLOUD\ibmepicado for the following reason: No title for this reason could be found
 Reason Code: 0x800000ff


SR0028086
Pls take VM snapshot for SCA file deployment (SVJD1SRV0 - 10.6.1.12)  A0EASG014XVM003





INC8509480    Panasonic North America    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.48 (thresh: 16)
10.12.254.14

INC8509294    Panasonic North America    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.01 (thresh: 16)
10.12.254.14

INC8508270    Panasonic North America    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.06 (thresh: 16)
10.12.254.14



SR0027170
A0EASG012XVM042   F drive extnd
10.6.3.35	SPSVOPLTAPP01




INC8512870    PT Anugerah Pharmindo Lestari    
P2 - Major    Processor_load_is_too_high_on_ptpbromo.imzcloud.ibmammsap.local
10.70.31.16




INC8132681
(Received during suppression) FS_is_read_only_on_spsvmplmapp01.imzcloud.ibmammsap.local[PROBLEM:14188474]
[root@spsvmplmapp01 ibmrmalik]# /var/lib/zabbix/check_rw_mounts.sh
CRITICAL |  /usr/sap/OpenText/STRS_output/OfficialReceipt /usr/sap/OpenText/STRS_output/OfficialReceipt filesystems are read-only

//SPSVOPLTAPP01/STRS_Output  /usr/sap/OpenText/STRS_output/OfficialReceipt/ cifs _netdev,username=fileshare,password=Welcome-1,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
10.6.3.35

//SPSVOPLTAPP01/OfficialReceipt  /usr/sap/OpenText/STRS_output/ cifs _netdev,username=fileshare,password=Welcome-1,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0





INC8460944
(Received during suppression) ITM Agent Offline: CS1-SVCS1SRV0_CS1_00:Ins

INC8513433
(Received during suppression) ITM Agent Offline: CS1-svcs1srv0_CS1_00:Ins
10.6.1.142



INC8512223    {Suncor Energy Inc --> snchbibpd51/10.73.10.111}    P3 - Minor - Disk Utilization /sybase/P1B/sapdata3 CRITICAL: Free 16151.98MB/18.38%
[root@snchbibpd51 ibmrmalik]# df -h /sybase/P1B/sapdata3
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/p1bdatavg-pn1sapdata3_lv
                       95G   71G   20G  79% /sybase/P1B/sapdata3


INC8512224    {Suncor Energy Inc --> snchbibpd51/10.73.10.111}    P3 - Minor - Disk Utilization /sybase/P1B/sapdata2 CRITICAL: Free 15127.98MB/17.21%
[root@snchbibpd51 ibmrmalik]# df -h /sybase/P1B/sapdata2                        Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/p1bdatavg-pn1sapdata2_lv
                       95G   72G   19G  80% /sybase/P1B/sapdata2


INC8512225    {Suncor Energy Inc --> snchbibpd51/10.73.10.111}    P3 - Minor - Disk Utilization /sybase/P1B/sapdata1 CRITICAL: Free 16151.98MB/18.38%
[root@snchbibpd51 ibmrmalik]# df -h /sybase/P1B/sapdata1                        Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/p1bdatavg-pn1sapdata1_lv
                       95G   71G   20G  79% /sybase/P1B/sapdata1


INC8513135    {Suncor Energy Inc --> snchdijpa11/10.73.10.11}    P3 - Minor - Free_disk_space_is_less_than_20%_on_volume_/usr/sap/DI6[PROBLEM:15509938]
[root@snchdijpa11 ibmrmalik]# df -h /usr/sap/DI6
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/di6appvg-di6usrDI6_lv
                       28G   19G  7.4G  72% /usr/sap/DI6




INC8514034   sev2
Server not reachable




10.127.155.126	root/UCkFqv%3paqS2E@
parhana-1024-17.xsportal.local

-----------------------------------------------------------------------------------------------------------------------------------------

18 Jun

SR0027689  SNC  Restore the VM from backup
the mount point /sapmnt/QP6 from the server SNCHEPJQA11    10.73.12.50
SNCHEPJQA12    10.73.12.51
SNCHEPJQA13    10.73.12.52
SNCHEPJQA15    10.73.12.54
SNCHEPJQA16    10.73.12.55

SNCHEPJQA14
Delete virtual machine




INC6913360
NTP_time_is_driffted_on_TNGDEVEAPP40.imzcloud.ibmammsap.local[PROBLEM:10709271]
 10.134.2.14




INC8469575	DFJ Trung Nguyen Group Corporation	TNG-01	P3 - Minor	TNG	SAP09	Service vmtoolsd CRITICAL: vmtoolsd is not running
10.134.2.13

INC8470081	DFJ Trung Nguyen Group Corporation	TNG-01	P3 - Minor	TNG	SAP09	Service vmtoolsd CRITICAL: vmtoolsd is not running
10.134.2.13


SR0028232    Dilip Buildcon Limited    Low    Please provide CPU and RAM utilisation
DLBPSMDA00	10.13.1.19

-----------------------------------------------------------------------------------------------------------------------------------------------
19 June

INC8529581  PT Anugerah Pharmindo Lestari   Processor_load_is_too_high_on_ptpbromo.imzcloud.ibmammsap.local[PROBLEM:15560594]   P2
10.70.31.16

R@viAnj@li@411041



INC8526284
SAP HEC SWIVEL -- SMTP Rejecting Inflow Mails (00343382/2019)
URL:https://documents.support.sap.com/customerincident/xFJuSLTYYkSscq2OW
Bn2SeWNA7uK3befw-iKJV-avfQ

We have observed that, SMTP is rejecting inflow of mails. User is
getting rejection from eccprd.mag.local SMTP address.
 
I have attached error screenshot here with. 
 
Invoice is route from Mail box to VIM (LONMAGSSP0001) server.	10.69.0.41  win
I suspect something is missing after OS patching. Something getting
blocked. 

Windows server LONMAGSSP0001 failed to connect to SMTP Linux server LONMAGERP0002

not able to telnet port 25 on LONMAGERP0002 from LONMAGHAN0001
LONMAGERP0002 	10.69.0.12
LONMAGHAN0001 	10.69.0.11

[root@LONMAGHAN0001 ibmrmalik]# nslookup eccprd.mag.local
Server:         146.89.140.76
Address:        146.89.140.76#53

** server can't find eccprd.mag.local: NXDOMAIN


[root@LONMAGHAN0001 etc]# nslookup -type=mx eccprd.mag.local
Server:         146.89.140.76
Address:        146.89.140.76#53

** server can't find eccprd.mag.local: NXDOMAIN



CHG0115931. JD1 snapshot pls 

svjd1srv0	10.6.1.12      A0EASG014XVM003




INC8530440  Delta Airlines   Disk Utilization /interface/QEA CRITICAL: Timeout or no data available for /interface/QEA  P1
10.4.5.175


INC8530548  Delta Airlines   Disk Utilization /usr/sap CRITICAL: Timeout or no data available for /usr/sap   P1
10.4.5.175 


INC8530681
DLBPSMDA00 	10.13.1.19	172.16.20.19   no accessible  Chennai



INC8530752  Delta Airlines   Disk Utilization /home/qeaadm CRITICAL: Timeout or no data available for /home/qeaadm   P1
10.4.5.175 



INC8530726  Delta Airlines  Disk Utilization /home/sapadm CRITICAL: Timeout or no data available for /home/sapadm   P1



INC8469274
Disk Utilization / CRITICAL: Free 2271.03MB/20.00% (thresh @10.01:20%)
10.73.10.108
[root@snchtnapd11 backup]# df -h /
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                       12G  9.1G  2.1G  82% /



SR0028393
Tata Steel Limited -  Regarding host entry in Eproc and EasyBuy App Server
Server	*CFN IP	*IFN IP
SAPPOQA	10.170.63.50	10.207.63.29
remove host entry of 

-------------------------------------------------------------------------------------------------------------------------------------

20 JUn


INC8538606    IBM Netcool Auto Ticketing Integration [MHAS]    Delta Airlines    P1 - Severe    Disk Utilization /home CRITICAL: Timeout or no data available for /home    Queued    SQ-SAP-TRIO-11
10.4.5.175


INC8538738    IBM Netcool Auto Ticketing Integration [MHAS]    Delta Airlines    P1 - Severe    SAP11    Disk Utilization /usr/sap/trans CRITICAL: Timeout or no data available for /usr/sap/trans    Queued    SQ-SAP-TRIO-11
10.4.5.175

INC8538714    IBM Netcool Auto Ticketing Integration [MHAS]    Delta Airlines    P1 - Severe    SAP11    Disk Utilization /usr/sap/ccms CRITICAL: Timeout or no data available for /usr/sap/ccms    Queued    SQ-SAP-TRIO-11
 10.4.5.175 


INC8538705    IBM Netcool Auto Ticketing Integration [MHAS]    Delta Airlines    P1 - Severe    SAP11    Disk Utilization /sapstage CRITICAL: Timeout or no data available for /sapstage    Queued    SQ-SAP-TRIO-11
10.4.5.175 


tbos4qa2ap	100.126.48.23
 

tbos4prdap	100.126.48.24


CSR CHG0116106  . JD1 snapshot
VM snapshot of svjd1srv0 (10.6.1.12)
A0EASG014XVM003



Jun 20 05:11:40 ptpkelimutu3 sshd[45035]: pam_sss(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=146.89.140.178 user=ibmrpradyumnan
Jun 20 05:11:40 ptpkelimutu3 sshd[45035]: pam_sss(sshd:auth): received for user ibmrpradyumnan: 4 (System error)
Jun 20 05:11:42 ptpkelimutu3 sshd[45033]: error: PAM: System error for ibmrpradyumnan from 146.89.140.178



SR0028495
spsvppalase01	10.6.3.22   A0EASG014XVM040



Host Name	*CFN IP	*IFN IP
SAPAPP20	10.170.61.48	10.207.61.195
SAPBOPRD	10.170.61.58	10.207.61.205
TSGPPRD	10.170.61.20	10.207.61.41
ADSPRDS	10.170.61.25	10.207.61.29
PRDREP	10.170.61.32	10.207.61.220
ESSMSSDEV	10.170.61.63	10.207.61.210
EWMAPP1	10.170.61.68	10.207.61.77
SAPCRMAPP1	10.170.61.27	10.207.61.24
TSCMLPRD	10.170.61.15	10.207.61.36
SAPAPP19	10.170.61.74	10.207.61.215
SAPCRMDI	10.170.61.69	10.207.61.83
TTAR3DEV	10.170.61.22	10.207.61.72






-------------------------------------------------------------------------------------------------------------------------------------

24 Jun

CHG0115962-CMA CGM (CMA)-24-Jun-2019 05:00:00 AM
 <<CMA>>-<<PAR01/NON POD  Apply Latest Q219 Patches on <<Linux>> Servers.
 SMBOUATUB3	10.5.26.12	Test	 	10.78.26.12
 [root@smbouatub3 ibmrmalik]# uname -a; date; cat /etc/redhat-release
Linux smbouatub3 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 09:28:26 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@smbouatub3 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux smbouatub3 2.6.32-754.15.3.el6.x86_64 #1 SMP Thu Jun 13 22:49:44 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 12:30:01 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

 
SMCRMUATUR3	10.5.26.18	Test		10.78.26.18
[ibmrmalik@smcrmuatur3 ~]$ sudo su
uname -a;date;[root@smcrmuatur3 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux smcrmuatur3 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 11:30:44 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@smcrmuatur3 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux smcrmuatur3 2.6.32-754.15.3.el6.x86_64 #1 SMP Thu Jun 13 22:49:44 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 14:32:53 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


SMBWUATUW3	10.5.26.28	Test		10.78.26.28
[root@SMBWUATUW3 ibmrmalik]# uname -a; date; cat /etc/redhat-release
Linux SMBWUATUW3 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 09:47:24 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@SMBWUATUW3 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux SMBWUATUW3 2.6.32-754.15.3.el6.x86_64 #1 SMP Thu Jun 13 22:49:44 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 12:32:58 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

	
SMGWUATUQ2	10.5.26.34	QA		10.78.26.23
[root@smgwuatuq2 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux smgwuatuq2 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 09:57:58 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

uname -a;[root@smgwuatuq2 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux smgwuatuq2 2.6.32-754.15.3.el6.x86_64 #1 SMP Thu Jun 13 22:49:44 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Jun 24 12:58:02 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)




CHG0116499
SVJQ1SRV0  snapshot
svjq1srv0A0EASG014XVM004



INC8576605	10.12.254.14	/db2/db2cp1/db2_software
INC8576601	10.12.254.14 	/db2/CP1/saptmp2
INC8576603	 10.12.254.14 	/db2/CP1/log_dir
INC8576599	10.12.254.14	/db2/CP1/saptmp3 
These tickets are for  PN4US7LECCP1. Discussion is this is going on in #scx-sap11-pn4



INC8579002    COTY Inc.    
P1 - Severe    ctubwqb1ap03.imzcloud.ibmammsap.local_has_just_been_restarted
 10.12.10.151


INC6891018
brspsol041amm   146.89.143.16 , IMZ login to this server is not working, Backup affected .


INC8402948
Processor_load_is_too_high_on_DYSD3DAD3D40[PROBLEM:15076723]



INC8526357
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DYSW1DAWWP11- KB0016174




INC8526356
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DYSW2DAWWP11- KB0016174



SR0028795
Please verify - pncapeccp & pncapeccp1 - CPU and RAM assigned to the VM 
PNCAPECCP  10.126.71.25		10.199.1.25	8 CPU 96 GB RAM
pncapeccp:/home/ibmrmalik # cat /proc/cpuinfo | grep processor | wc -l
8
pncapeccp:/home/ibmrmalik # cat /proc/meminfo |grep -i MemTotal
MemTotal:       99007308 kB


PNCAPECCP1  10.126.71.36	10.199.1.36	8 CPU 96 GB RAM
cat /roc/cpuinfopncapeccp1:/home/ibmrmalik #  cat /proc/cpuinfo | grep processor | wc -l
8
pncapeccp1:/home/ibmrmalik # cat /proc/meminfo |grep -i MemTotal
MemTotal:       99007308 kB



coty-wdc04-phana-4096-8.imzcloud.ibmammsap.local	CTUBWQB3DB01
ipmi root/UMR75CFyCn



CLDWDPWEBP2DR / 10.168.2.71
CLDERPAPPQ2 / 10.198.0.221	
CLDERPDTBD1 / 10.198.0.207	A0CTSG014XVM016
CLDERPDTBP2 / 10.168.1.146
CLDERPDTBX5 / 10.198.0.234	A0CTSG013XVM042
CLDERPDTBQ3 / 10.168.1.140


----------------------------------------------------------------------------------------------------------------------------------------
25 June


CHG0115969-CMA CGM (CMA)-25-Jun-2019 05:00:00 AM
Please deploy above Q219-patches to the following <<Linux>> servers.

Host Name	CFN IP	Asset Purpose

MMGRAS	10.5.22.12	Non-Production
SPSPNAS	10.5.22.11	Non-Production


MMGRAS	10.78.22.12	10.5.22.12	Non-Production
[root@mmgras ibmrmalik]# uname -a;date;cat /etc/redhat-release;sh /var/lib/zabbix/check_rw_mounts.sh
Linux mmgras 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun 25 06:55:31 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
OK

[root@mmgras ibmrmalik]# uname -a;date;cat /etc/redhat-release;sh /var/lib/zabbix/check_rw_mounts.sh
Linux mmgras 2.6.32-754.15.3.el6.x86_64 #1 SMP Thu Jun 13 22:49:44 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun 25 12:13:58 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
OK


SPSPNAS	10.78.22.11	10.5.22.11	Non-Production
[root@spspnas tmp]# uname -a;date;cat /etc/redhat-release;sh /var/lib/zabbix/check_rw_mounts.sh
Linux spspnas 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun 25 08:54:55 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
OK

[root@spspnas ibmrmalik]# uname -a;date;cat /etc/redhat-release;sh /var/lib/zabbix/check_rw_mounts.sh
Linux spspnas 2.6.32-754.15.3.el6.x86_64 #1 SMP Thu Jun 13 22:49:44 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun 25 14:36:37 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
OK


25/06/2019 17:30:00   to 21:30 



INC8594168    Hortus Comercio de Alimentos SA    P2 - Major    Filesystem /backup 100%
HC1HONFEDBAPP 	10.212.80.16	10.80.0.19		Sau Paulo


INC7811326
Lack_of_free_swap_space_on_YHISMDS01.imzcloud.ibmammsap.local[PROBLEM:13182750]
10.6.4.204



INC8063541
Lack_of_free_swap_space_on_LBDWD1App80.imzcloud.ibmammsap.local[PROBLEM:13979721]
10.8.8.13





INC8416102
Disk Utilization /usr/local CRITICAL: Free 2779.94MB/19.99% (thresh @10.01:20%)



INC8392071
Disk Utilization /usr/sap/ccms CRITICAL: Free 1527.57MB/19.96% (thresh @10.01:20%)



INC8500622
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.04 (thresh: 16)
10.12.254.14




INC7879013
Service chef-client CRITICAL: 0 chef-client processes running (thresh 1:)
10.138.1.32



INC8493133
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.26 (thresh: 16)
10.12.254.37 



INC8472611
Disk Utilization /var/log CRITICAL: Free 4756.01MB/20.00% (thresh @10.01:20%)
 170.225.68.25 
 
 
 
INC8345439
Disk Utilization /var/lib/mailman CRITICAL: Free 2745.46MB/19.99% (thresh @10.01:20%)



INC8516046
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.76 (thresh: 16)



INC7808346
Ping Availability CRITICAL - 10.70.31.16: Host unreachable @ 158.87.44.165. rta nan, lost 100%


INC8599185    MHAS            P1 - Severe            z-pup.imzcloud.ibmammsap.local_has_just_been_restarted
 
 
 
 [root@spspnas tsmcld1]# su - tsm4cma
su: warning: cannot change directory to /home/tsm4cma: Permission denied
-bash: /home/tsm4cma/.bash_profile: Permission denied

-------------------------------------------------------------------------------------------------------------------------

26 Jun

INC8608759`	sev2		Case # 84024613
chehana-1024-01.xsportal.loca
DLBSECDB00 	10.13.2.15    Chennai

chehana-1024-01.xsportal.local
(Chennai 1)
Private IP: 10.162.24.196
root/sx8rRi%P8Kqnfu@

root/  xKK3lq*-

IPMI
root
UZDnCB9q3h


INC8608638    Tata Steel Limited    SAP12
P2 - Major    Disk Utilization /usr CRITICAL: Free 410.29MB/7.33% (thresh @5.01:10%)    Queued        MHAS-DL-PREPROD ALERTS    (empty)
10.207.61.210


INC8608666    Tata Steel Limited    SAP12
P2 - Major    Disk Utilization /usr CRITICAL: Free 410.24MB/7.33% (thresh @5.01:10%)    Queued        MHAS-DL-PREPROD ALERTS    (empty)
10.207.61.210 


INC8608693    Tata Steel Limited    SAP12
P2 - Major    Disk Utilization /usr CRITICAL: Free 410.20MB/7.33% (thresh @5.01:10%)    Queued        MHAS-DL-PREPROD ALERTS    (empty)
10.207.61.210



hidden oasis (buy2 get1 free) 9821130354 and Giriraj hill resort(20% off) 9421081300



SR0029120
mount /tmpfs from host : CI2DEVAPP  to  host : CI2PRDAPP

Please mount /tmpfs from host : CI2DEVAPP  to  host : CI2PRDAPP

source host :	CI2DEVAPP	10.5.242.16
target host : 	CI2PRDAPP 	10.5.242.12




INC8512603
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.59 (thresh: 16)
10.12.254.14



INC8515883
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.62 (thresh: 16)
10.12.254.14 



INC8382021
Disk Utilization /var/log CRITICAL: Free 2779.37MB/19.99% (thresh @10.01:20%)
10.199.98.20	



INC7078982
Free_disk_space_is_less_than_20%_on_volume_/usr/sap/SD1[PROBLEM:10979271]
10.8.8.11



INC8551851
Disk Utilization /sapmnt/data CRITICAL: Free 89953.51MB/17.17% (thresh @10.01:20%)
170.225.68.25 


INC8515120
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.72 (thresh: 16)
10.12.254.14 


INC7787724
Lack_of_free_swap_space_on_LBDWP4App80.imzcloud.ibmammsap.local[PROBLEM:13087169]
10.8.8.85


INC7725639
Processor_load_is_too_high_on_LBDWQ4App80.imzcloud.ibmammsap.local[PROBLEM:12837989]
10.8.8.55



INC8497841
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.33 (thresh: 16)
10.12.254.14 





INC8514731
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.08 (thresh: 16)
 10.12.254.14 
 
 
 
 INC8494936
 LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.94 (thresh: 16
 10.12.254.14
 
 
INC8470876
Disk Utilization /var/cache CRITICAL: Free 2770.20MB/19.98% (thresh @10.01:20%)
 10.199.98.20
 
 
 INC8494303
 LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.14 (thresh: 16)
 10.12.254.22
 
 
INC8383742
Disk Utilization /home CRITICAL: Free 4654.64MB/19.73% (thresh @10.01:20%)
170.225.68.25



SR0029151
Please  take a vm snapshot of server dysadsdadsd40 (10.6.12.19).

-----------------------------------------------------------------------------------------------------------------------------------
27 June


INC7766053
Free_disk_space_is_less_than_20%_on_volume_/var/log[PROBLEM:13010284]
10.8.8.187


INC8586362
Disk Utilization /var/log CRITICAL: Free 1718.55MB/19.93% (thresh @10.01:20%)




INC8066100
Free_disk_space_is_less_than_20%_on_volume_/var/log[PROBLEM:13992279]



INC8383740
Disk Utilization /tmp CRITICAL: Free 4654.64MB/19.73% (thresh @10.01:20%)
170.225.68.25




INC8584553
FS_is_read_only_on_pn4us7leccp1.imzcloud.ibmammsap.local[PROBLEM:15665982]
CRITICAL | /db2/CP1/sapdata1 /db2/CP1/sapdata2 /db2/CP1/sapdata3 



INC7246890
NTP_time_is_driffted_on_iplsapoap01.imzcloud.ibmammsap.local[PROBLEM:11326341]
10.138.1.21 



INC8338877
Disk Utilization /var/opt CRITICAL: Free 2747.08MB/20.00% (thresh @10.01:20%)
10.199.99.15



INC8617158
mdcserverp2     10.12.7.42
WDC SuSE
MZ login should work
Any FS should not in readonly mode
VMtool should be up and running
Snapshot should be completed manually



INC8406346
Disk Utilization / CRITICAL: Free 2778.10MB/19.98% (thresh @10.01:20%)




INC8383565
Disk Utilization /var/tmp OK: Free 2771.59MB/20.16% (thresh @10.01:20%)



INC8344612
Disk Utilization /.snapshots OK: Free 5650.99MB/23.68% (thresh @10.01:20%)


INC7918291
Processor_load_is_too_high_on_armfksap001.imzcloud.ibmammsap.local[PROBLEM:13510317]
10.7.103.28



INC8383138
Disk Utilization /var/tmp CRITICAL: Free 4657.16MB/19.74% (thresh @10.01:20%)
170.225.68.25



INC7781027
Lack_of_free_swap_space_on_LBDSD1App01.imzcloud.ibmammsap.local[PROBLEM:13051863]
10.8.8.12 


FS /if with 4 GB  - permission 755 and owner ship root:system  

10.20.21.15 
[root@ckdpopoc ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  pq2appvg    1  12   0 wz--n- 128.00g   23.00g
  pq2archvg   1   2   0 wz--n- 128.00g   28.00g
  pq2datavg   1   7   0 wz--n- 128.00g 1020.00m
  pq2logvg    1   4   0 wz--n-  32.00g 1020.00m
  rootvg      2   9   0 wz--n- 145.49g   22.49g


10.20.21.15
lvcreate -L 4G -n if_lv pq2appvg

mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab



# umount /dev/myvg/homevol
# lvremove /dev/myvg/homevol
lvremove -- do you really want to remove "/dev/myvg/homevol"? [y/n]: y
lvremove -- doing automatic backup of volume group "myvg"
lvremove -- logical volume "/dev/myvg/homevol" successfully removed

LV Path                /dev/rootvg/if_lv
  LV Name                if_lv
  LV Path                /dev/pq2appvg/if_lv
  LV Name                if_lv

[root@ckdpopoc /]# dmsetup info -c | grep if_lv
rootvg-if_lv             254  34 L--w    1    1      0 LVM-axTsygU5uUAv2shCNdLsU1GzgkZ0f9Cj2goxG3OW2BEElLqKxH2lyeQs2Kb23Hl1
pq2appvg-if_lv           254  35 L--w    1    1      0 LVM-mZC6VKhpT226WpeNbf2sQusVVTEmuGVvQaW7If2PfncftdhNJaIIcOGpy5YuqEd0



[root@ckdpopoc ibmrmalik]# lvdisplay |grep if_lv
  LV Path                /dev/rootvg/if_lv
  LV Name                if_lv



mkfs.ext4  /dev/rootvg/if_lv
/if mount karo naye lv se 22 gb from pq2appvg


INC8394013
Processor_load_is_too_high_on_IPLSAUTLD01[PROBLEM:15028953]
10.138.2.28


INC7247305
NTP_time_is_driffted_on_ADNBIDEVDB.imzcloud.ibmammsap.local[PROBLEM:11327461]
10.198.201.19 


----------------------------------------------------------------------------------------------------------

28 June

INC8626868    Delta Airlines    P2 - Major    Processor_load_is_too_high_on_DLTHPEHP5.imzcloud.ibmammsap.local[PROBLEM:15761923]
10.4.5.44 



INC8626990    CMA CGM    P2 - Major    Processor_load_is_too_high_on_smeccuatue3.imzcloud.ibmammsap.local[PROBLEM:15762053]
10.78.26.16


INC8627181    Suncor Energy Inc.    P2 - Major    Processor_load_is_too_high_on_snchwdwpw12.imzcloud.ibmammsap.local[PROBLEM:15762188]
10.73.10.107



sng01-pod2-4tb-host02.imzcloud.ibmammsap.local
AGESVBQ1HSRV1 	10.6.2.70	10.70.110.72 	
Private IP: 10.116.205.226
root/  3D30D6%9MstO2j@

https://10.116.205.226/vsphere-client/

IPMI
root  ZE9eqkqJkj



INC8628174 - DT1 performance issue
Host Name	>>	SID	>>	IFN IP
SMTMDEVDT1	>>	DT1	>>	10.78.22.41
Kindly increase FS for /usr/sap/DT1 as it is full :
/dev/mapper/dt1appvg-dt1usrDT1_lv
                       48G   45G     0 100% /usr/sap/DT1

[root@smtmdevdt1 ibmrmalik]# df -hT /usr/sap/DT1                     Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/dt1appvg-dt1usrDT1_lv
                     ext3   58G   47G  8.2G  86% /usr/sap/DT1


INC8628080 - CMA CGM - Kindly add new disk to  /usr/sap/trans as we need total space of 188 Gb
Kindly add new disk to  /usr/sap/trans as we need total space of 188 Gb

Host Name	>>	SID	>>	IFN IP
SMTMDEVDT1	>>	DT1	>>	10.78.22.41



INC8624042
Hi,

I am in-between a change and facing OS related issues.

1. Please check if the below are there  with the correct versions :

Required components for Red Hat Enterprise Linux 6
glibc-2.12-1.7-el6.i686 
libstdc++-4.4.4-13.el6.i686

2. Give FULL access to the user : otaadm

Server details:
iplsaboat01	10.138.3.22

glibc-2.12-1.7-el6.i686 
libstdc++-4.4.4-13.el6.i686




CHG0117183
now JD1 snapshot pls
svjd1srv0	10.6.1.12	A0EASG014XVM003


CHG0117181
agesvcdmhsrv1
agesvcdmhsrv1	10.6.1.180  reboot
sng01-pod2-4tb-host02




INC8628754  - apfslppdb       10.15.16.17 , DF is hung on this server

APFSLPPDB 	10.15.16.17	10.221.16.17
statfs("/usr/sap/trans",
APFSLPPAS 	10.15.16.18	10.221.16.18


INC8630500    Suncor Energy Inc.    CMS-SAP    SNC-02    P1 - Severe

-----------------------------------------------------------------------------------------------------------------

30 June


CHG0116336 and CHG0116722
msc-phana-1024-6.imzcloud.ibmammsap.local
root/T765cFt8A7    ipmi

root/JljbK7ER

10.148.59.154

Case # 84223289
PIM --- root    HA/JzbvyKQTlWPm

10.12.7.42     10.12.7.41

MDCSERVERP1 	10.12.7.41	172.17.156.41

MDCSERVERP2 	10.12.7.42	172.17.156.42

cat /proc/net/bonding/bond0


msc-phana-1024-5.imzcloud.ibmammsap.local
(Washington 4)
Private IP: 10.148.59.176

root / B;cBK%NhVH)Cb?c

ol pw in SL  C2yYj5pZ





INC8650963    Manitoba Telecom Services    P1 - Severe    Zabbix_agent_on_r3dev.imzcloud.ibmammsap.local_is_unavailable
10.74.6.40




shwetali's eerver
LONCFGCHP0002 	10.69.2.22	192.168.31.22 	Lon02	A0D9UK014XVM024





INC8651265    MSC Industrial Supply Co.    P2 - Major




SR002854


INC8592708	sev1
dyswdapwdp00.imzcloud.ibmammsap.local_has_just_been_restarted[PROBLEM:15679511]




INC8646330    THE OGILVY GROUP INC    P1 - Severe    (Received during suppression) Disk Utilization /var/log CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)
Disk Utilization /var/log CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)
10.139.9.39


INC8650401    Suncor Energy Inc.    P2 - Major
Free_disk_space_is_less_than_10%_on_volume_/sapmnt/log[PROBLEM:15783599]
10.73.11.193



INC8646973
Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:15673153]
10.4.5.163


INC8647529
Free_disk_space_is_less_than_5%_on_OS_volume_/tmp[PROBLEM:14942800]
10.13.2.20



INC8652331    MSC Industrial Supply Co.    P1-Severe

--------------------------------------------------------------------------------------------------------------------------------

1 July


INC8659365    City Football Group 1    
P1 - Severe    loncfgceq0001.imzcloud.ibmammsap.local_has_just_been_restarted
 10.69.1.11 



INC8659367    City Football Group 2    
P1 - Severe    LONCFGCHP0002.imzcloud.ibmammsap.local_has_just_been_restarted[
10.69.2.22 
-rw-------. 1 ibmschowdesh domain_users 1604 Jun 30 10:30 krb5cc_99606



INC8658754
VSAPPE6-APP6 	10.9.4.204	192.168.10.204
a0e3ca014xvm015   vmtoolsnot installed


INC8560905
Processor_load_is_too_high_on_DYSW2DAWWD40[PROBLEM:15641655]
10.6.12.23 windows



INC8643859
Disk Utilization /mnt/IBMDT393684-1 CRITICAL: Timeout or no data available for /mnt/IBMDT393684-1
[root@dysdberp0100 mnt]$ cat /etc/mtab |grep -i /mnt
/dev/sdn1 /mnt/IBMDT393684-1 fuseblk rw,relatime,user_id=0,group_id=0,allow_other,blksize=4096 0 0

[root@dysdberp0100 mnt]$ cd /mnt
[root@dysdberp0100 mnt]$ ls -ltr
total 8
drwxr-xr-x 2 root root 4096 Feb 19 23:27 cdrom
drwx------ 2 root root 4096 Jun 16 17:15 IBMDT393684-1
[root@dysdberp0100 mnt]$ cd IBMDT393684-1/
[root@dysdberp0100 IBMDT393684-1]$ ls -ltr
total 0


INC8645444
Zabbix_agent_on_dltwb1hwd.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15678862]
10.4.5.156 
DLTWB1HWD 	10.4.5.156	10.250.17.156 		Dallas09
server is hung, RAM over consumed, need to reboot VMtools not installed



INC8645487  (same CI - DLTWB1HWD)
Free_disk_space_is_less_than_5%_on_volume_/var/log
dltwb1hwd.imzcloud.ibmammsap.local NodeAlias: 10.4.5.156
Dal09 


INC8643163
10.4.5.18 
(Received during suppression) Service bobjrestart CRITICAL: bobjrestart.sh not runnin




INC8667030    Province of Nova Scotia    CMS-SAP    PS1-01    P1 - Severe    PS1    SAP11    PS1AS1055.imzcloud.ibmammsap.local_has_just_been_restarted[PROBLEM:15795643]    Queued    SQ-SAP-TRIO-1
PS1AS1055 	10.138.10.11	10.232.15.11	Montreal
VM tools not installed on the VM.



INC8667879    Wakefern Food Corporation    CMS-SAP    WKF-04    P1 - Severe    WKF        Disk Utilization /var/log CRITICAL: Free 44.58MB/4.91% (thresh @0:5%)    Queued    SQ-SAP-PROJ-TEAM
10.139.100.150



INC8667897
Disk Utilization /var/log CRITICAL: Free 39.47MB/4.34% (thresh @0:5%) 


INC8649197
Disk Utilization /var/log CRITICAL: Free 165.59MB/18.22% (thresh @10.01:20%)
10.12.15.72



INC8649328
Disk Utilization /var/log CRITICAL: Free 176.62MB/19.44% (thresh @10.01:20%)
10.12.15.72



INC8669185    PANARIAGROUP INDUSTRIE CERAMICHE SP    CMS-SAP    PNC-01    P1 - Severe    PNC    SAP09    Zabbix_agent_on_C1ECCQ.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15799715]    Queued    SQ-SAP-TRIO-9

-------------------------------------------------------------------------------------------------------------------------------------

2 Jul

INC8676590    Suncor Energy Inc.    
P1 - Severe    snchpijda11.imzcloud.ibmammsap.local_has_just_been_restarted
10.73.11.114




INC8676589    Suncor Energy Inc.    
P2 - Major    SNCHBIBQA13_has_just_been_restarted
10.73.12.38




INC8676643    Dilip Buildcon Limited    
P2 - Major    Processor_load_is_too_high_on_DLBQECAP01.imzcloud.ibmammsap.local



INC8677720 
DyStar Production ERP is extremely slow



INC8655070
(Received during suppression) Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:15277579]
10.73.12.78 



INC8646571 (Same CI),   INC8643157,  

INC8643996   
Zabbix_agent_on_gknadscih.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15598682]


INC8646583



SR0029701
Please create a VM snapshot of HR2 system APLHRHK1   170.225.68.23
once completed send mail to  balajikr11@in.ibm.com and pavol.vanek@cz.ibm.com



INC8649173    (Received during suppression) Service vmtoolsd CRITICAL: vmtoolsd is not running



INC8648028    (Received during suppression) Service vmtoolsd CRITICAL: vmtoolsd is not running



INC8680400    Wakefern Food Corporation    CMS-SAP    WKF-04    
P1 - Severe    WKF        Disk Utilization /var/log CRITICAL: Free 42.22MB/4.65%



INC8627821
Free_disk_space_is_less_than_10%_on_volume_/usr[PROBLEM:15762782]



SR0029733
please extend /upgrade FS by 50 GB : CI3BWHANADEVA

-------------------------------------------------------------------------------------------------------------------------

3 July


SR0029885
Extend FS /usr/sap/QV6 on  SNCHBDJQA12 10.73.12.67





ERU (DYSCIERU2800); ERQ (DYSCIERQ2000); ERP (DYSCIERP0100); ARP (DYSCIARP0200); ARQ (DYSCIARQ2000); ARD (DYSCIARD2200); APP (DYSCIAPP0600); BWP (DYSCIBWP0400) 
SR0029566
Request to setup the FTP server mount points in ARQ (DYSCIARQ2000-10.6.12.62	10.1.162.62)  and ERQ (DYSCIERQ2000-10.6.12.63	10.1.162.63)
DYSFTPDAPRD01 	10.6.11.14	10.1.161.14

//10.1.161.14/masterdata/ARQ /masterdata cifs credentials=/etc/Dystar_credentials,uid=20200,gid=3050,_netdev,nofail

/interfaces/ARD/PIL/IB/INV/archive      cifs credentials=/etc/Dystar_credentials,uid=20220,gid=3050,sec=ntlm

[root@dysciard2200 ibmrmalik]$ cat /etc/Dystar_credentials
username=YSRVSAPEC
password=EC_SAP00
ports 139 and 445 neds to be opened



INC8688010    Tata Steel Limited    CMS-SAP    TTA-02    P2 - Major
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.05 (thresh: 16)
 10.207.61.19 


INC8687797    St Jude Medical    CMS-SAP    JUD-01    P2 - Major
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.92 (thresh: 16)
 10.196.4.14 




INC8686609
System Read Only File Systems CRITICAL: /run/user/20011/gvfs filesystems are read-only
10.6.11.11 	dyscierp0100		server has high mem usage and so cant login, root pw is not available on PIM

INC8676624
Disk Utilization /var/log CRITICAL: Free 175.35MB/19.30% (thresh @10.01:20%)



INC8678244
System Read Only File Systems CRITICAL: /run/user/20011/gvfs filesystems are read-only
10.6.11.11


INC8686984  
Disk Utilization /var/log CRITICAL: Free 180.66MB/19.88% (thresh @10.01:20%)
10.6.11.15 



INC8642856
(Received during suppression) Disk Utilization /usr/sap/trans_old CRITICAL: Free 32096.14MB/12.89% (thresh @10.01:20%)
10.6.12.44


INC8690923    CMA CGM    CMS-SAP    CMA-01    P1 - Severe    CMA    SAP12    Disk Utilization / CRITICAL: Free 23.81MB/0.05% (thresh @0:5%)    Queued    SQ-SAP-TRIO-12
10.78.22.40


INC8690939    Apple Leisure Group    CMS-SAP    AV1-01    P1 - Severe    AV1    SAP10    USSAPAEDAP01.imzcloud.ibmammsap.local_has_just_been_restarted[PROBLEM:15831903]    Queued    SQ-SAP-TRIO-10
10.68.214.11 


INC8690941    Aceros Chilca - MEPSA    CMS-SAP    AC5-01    P1 - Severe    AC5    SAP11    acerosdevhana.imzcloud.ibmammsap.local_has_just_been_restarted[PROBLEM:15831905]    Queued    SQ-SAP-TRIO-11
10.4.11.10


unable to login to BQ1HANA server	sev
root  /  g}JTwCBJ8(3NAL6

-------------------------------------------------------------------------------------------------------------

4 July

INC8698293    -    Service vmtoolsd CRITICAL: vmtoolsd is not running


INC8697250    -    Service vmtoolsd CRITICAL: vmtoolsd is not running


INC8469052    -    Service vmtoolsd CRITICAL: vmtoolsd is not running
10.73.11.214


INC8468956    -    Service vmtoolsd CRITICAL: vmtoolsd is not running


INC8642358


INC8698546
Disk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)




IA2MDGPRDAPP 	10.133.15.34	66.248.244.37
[root@ia2mdgprdapp ibmrmalik]$ vmware-toolbox-cmd -v
10.2.0.1608 (build-7253323)





INC8700325    Adani Enterprises Ltd.    CMS-SAP    ADN-02    P1 - Severe    ADN    SAP10    ADNMP1DEVDB.imzcloud.ibmammsap.local_has_just_been_restarted[PROBLEM:15842806]    Queued    SQ-SAP-TRIO-10
10.198.201.20



ewmapp2	10.170.61.241

ibmdrtest/May55now#



SAPCRMAPP1	10.170.61.27


tscmlprd		ibmdrtest/May55now#   root/Set44now@
adsprds			ibmdrtest/May55now#   root/Set44now@
essmssdev		ibmdrtest/May55now#   root/Set44now@

---------------------------------------------------------------------------------------------------------------------------------

8 Jul

INC8735995    1    TRIO 10    MGG    MGGGBJPECCX05    Disk Utilization /opt CRITICAL: Free 473.02MB/5.00%



INC8736271    OSRAM GmbH    
P2 - Major    Processor_load_is_too_high_on_os1tazqtr.imzcloud.ibmammsap.local


INC8736645    MSC Industrial Supply Co.    
P2 - Major    Memory Swap CRITICAL: Swap free 49.99%


INC8717848 - Disk Utilization /var/log CRITICAL: Free 181.77MB/20.00% (thresh @10.01:20%) 



SR0027831
Please keep size same for folder /usr/sap/PEC/D00/log/ in PEC both application server to 100GB
bmmkumar2@DLBPECAP01 ~]$ df -h /usr/sap/PEC/D00/log/ 
Filesystem Size Used Avail Use% Mounted on 
/dev/mapper/pecappvg-pecusrPEC_lv 
87G 52G 31G 63% /usr/sap/PEC<========== Need to add 14GB disk 


[ibmmkumar2@DLBPECAP02 ~]$ df -h /usr/sap/PEC/D00/log/ 
Filesystem Size Used Avail Use% Mounted on 
/dev/mapper/pecappvg-pecusrPEC_lv 
27G 23G 3.2G 88% /usr/sap/PEC<==============Need to add 73GB Disk



DLBPECAP01 	10.13.1.12	172.16.20.12
[root@DLBPECAP01 ibmrmalik]$ df -h /usr/sap/PEC
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pecappvg-pecusrPEC_lv
                      107G   75G   27G  75% /usr/sap/PEC

DLBPECAP02 	10.13.1.13	172.16.20.13 	
[root@DLBPECAP02 ibmrmalik]$ df -h /usr/sap/PEC
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/pecappvg-pecusrPEC_lv
                       29G   20G  8.1G  71% /usr/sap/PEC


/usr/sap/PEC to 100GB


SR0030239
Please add 4GB space to below FS:

[root@sapborepo audit]$ df -i /oracle/BOP/saptrace
Filesystem                               Inodes  IUsed IFree IUse% Mounted on
/dev/mapper/boplogvg-ORACLE_BOP_SAPTRACE 262144 262144     0  100% /oracle/BOP/saptrace
[root@sapborepo audit]$ 


IP: 10.207.61.40
02:23:00 ET  and 07-07-2019 00:58:00 ET       06 July 21:58
INC8719582 :07-06-2019 02:23:00  ET	      06 July 23:23
INC8720196:07-06-2019 03:43:00 ET	      7 July 00:43 
 
SLES ref 101243566821


INC8737254    Celestica International Inc.    CMS-SAP    CLC-01    P3 - Minor    CLC        Free_disk_space_is_less_than_20%_on_volume_/var/log
10.9.2.13



INC8737760    Celestica International Inc.    CMS-SAP    CLC-01    P3 - Minor    CLC        Free_disk_space_is_less_than_20%_on_volume_/var/log
10.9.2.22

--------------------------------------------------------------------------------------------------------------------------------------

9 Jul


SJMPCPAA01 	10.198.10.13	10.195.1.13
SJMPEPAA01 	10.198.10.4	10.195.1.4 



CHG0117942	CTASK0120509
svjd1srv0	10.6.1.12	A0EASG014XVM003



INC8743734     1        MI8    HLTTST1    Zabbix_agent_on_hlttst1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15897544]
 INC8743733     1        MI8    HLTHON1    Zabbix_agent_on_hlthon1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15897530]
 INC8743730     1        MI8    SAPTST1    Zabbix_agent_on_saptst1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15897529]
 INC8743729     1        MI8    SAPKAI1    Zabbix_agent_on_sapkai1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15897527]

Server was inaccessible because of the reason that License on virtual FW expired, generated a new one and added to the FW


SR0030385
SNCHECASA11	10.73.11.210
/usr/sap/        ADD 5GB
[root@snchecasa11 ibmrmalik]$ df -h /usr/sap/
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/sr1appvg-usrsap_lv
                      5.0G  770M  4.0G  17% /usr/sap


SNCHEPJTA16	10.73.11.47
/usr/sap/        ADD 5GB
[root@snchepjta16 ibmrmalik]$ df -h /usr/sap/
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/tp6appvg-usrsap_lv
                      5.0G  771M  4.0G  17% /usr/sap



SR0030388
Additional Storage & Memory - Validation



INC8646426
Read Only File Systems CRITICAL: /home/dsqadm/.gvfs /run/user/0/gvfs /run/user/20200/gvfs /run/user/3050/gvfs filesystem

--------------------------------------------------------------------------------------------------------------------------------

10 Jul

INC8757273    IBM Netcool Auto Ticketing Integration [MHAS]    Wellnext    P2 - Major    SAP11    Processor_load_is_too_high_on_WNXECCDBP01.imzcloud.ibmammsap.local[PROBLEM:15912418]    07/10/2019 06:40:28

INC8757247    IBM Netcool Auto Ticketing Integration [MHAS]    MSC Industrial Supply Co.    P2 - Major    SAP09    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.07 (thresh: 16)    07/10/2019 06:37:17


Both servers needs port 139 and 445 opened bidirectional.
DYSFTPDAPRD01 10.6.11.14 10.1.161.14 
to 
ARQ (DYSCIARQ2000-10.6.12.62 10.1.162.62) and ERQ (DYSCIERQ2000-10.6.12.63 10.1.162.63)



CTASK0120561
VM snapshots for SVJD1SRV0 (A0EASG014XVM003) & SVFD1SRV0(A0EASG012XVM003)






a1ahecsmdap01	10.4.10.15	DAL09	
/home/.ssh/



INC8643186
Lack_of_free_swap_space_on_dyss4apsbd41.imzcloud.ibmammsap.local[



PEP
PEPSAPGGDDI01	
[cmschefadmin@DAL13AMMCHEF01 cms-chef]$ knife status -r | grep PEPSAPGGDDI01
10694 hours ago, PEPSAPGGDDI01.imzcloud.ibmammsap.local, ["role[baseos]", "recipe[sei_nagios]"], suse 12.2.
"ad_ou": "IBM AMM Customers/Pepsico (0000023866)/Servers - Linux"


knife node delete -y PEPSAPGGDDI01.imzcloud.ibmammsap.local;knife client delete -y PEPSAPGGDDI01.imzcloud.ibmammsap.local

rake bootstrap:cms3x[root,100.126.32.65,cms3x_cfg,development,PEPSAPGGDDI01,,]



SR0029566
Request to setup the FTP server mount points in ARQ (DYSCIARQ2000)  and ERQ (DYSCIERQ2000)
ERU (DYSCIERU2800); ERQ (DYSCIERQ2000); ERP (DYSCIERP0100); ARP (DYSCIARP0200); ARQ (DYSCIARQ2000); ARD (DYSCIARD2200); APP (DYSCIAPP0600); BWP (DYSCIBWP0400) 
Request to setup the FTP server mount points in ARQ (DYSCIARQ2000-10.6.12.62	10.1.162.62)  and ERQ (DYSCIERQ2000-10.6.12.63	10.1.162.63)
DYSFTPDAPRD01 	10.6.11.14	10.1.161.14

//10.1.161.14/masterdata/ARQ /masterdata cifs credentials=/etc/Dystar_credentials,uid=20200,gid=3050,_netdev,nofail

/interfaces/ARD/PIL/IB/INV/archive      cifs credentials=/etc/Dystar_credentials,uid=20220,gid=3050,sec=ntlm

[root@dysciard2200 ibmrmalik]$ cat /etc/Dystar_credentials
username=YSRVSAPEC
password=EC_SAP00

//10.1.161.14/Dystar-FTP/LocalUser/PanAsia/DN/ARD/outbound              /usr/sap/interfaces/ARD/PanAsia                 cifs credentials=/etc/Dystar_credentials,uid=20220,gid=3050,sec=ntlm
//10.1.161.14/Dystar-FTP/LocalUser/PanAsia/IB/ARD/outbound              /usr/sap/interfaces/ARD/PanAsia/IB 




INC8759095    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.22.21
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMSLDDEVDL0- KB0016174

INC8759093    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.24.18
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBQUAQE1- KB0016174

INC8759092    CMA CGM    CMS-SAP    CMA-01    P2 - Major  	10.78.20.32
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMIFASBXSF1- KB0016174

INC8759091    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.24.39
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMSLTQUAQK1- KB0016174

INC8759089    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.22.44
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMSLTDEVDK1- KB0016174

INC8759088    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.20.26 
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMSLTSBXSK1- KB0016174

INC8759087    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.20.31
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMGWSBXSQ1- KB0016174

INC8759086    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.22.11
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SPSPNAS- KB0016174

INC8759085    CMA CGM    CMS-SAP    CMA-01    P2 - Major	10.78.22.41
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMTMDEVDT1- KB0016174

INC8759084    CMA CGM    CMS-SAP    CMA-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMPODEVDX8- KB0016174

------------------------------------------------------------------------------------

11 July


INC8776507  MSC Industrial Supply Co.   P2
Processor_load_is_too_high_on_ms3wdcladb27.imzcloud.ibmammsap.local[PROBLEM:15923759]
10.12.6.46 



INC8776762  AGEAS   P2
Disk Utilization /usr/sap/LPP CRITICAL: Free 1914.32MB/10.00% (thresh @5.01:10%)
 10.6.3.22


CSR CHG0118206
svjd1srv0	10.6.1.12	A0EASG014XVM003


INC8777344    Apleona GmbH Grounding    CMS-SAP    AP5-01    P2 - Major
Processor_load_is_too_high_on_APLERPPD6.imzcloud.ibmammsap.local[PROBLEM:15924571]
170.225.68.20



INC8762639ã€€Free_disk_space_is_less_than_5%_on_volume_/db2/KAI/sapdata2[PROBLEM:15916701]
INC8762638ã€€Free_disk_space_is_less_than_5%_on_volume_/db2/KAI/sapdata4[PROBLEM:15916703]
INC8762633ã€€Free_disk_space_is_less_than_5%_on_volume_/db2/KAI/sapdata3[PROBLEM:15916702]
INC8762630 Free_disk_space_is_less_than_5%_on_volume_/db2/KAI/sapdata1[PROBLEM:15916700]  


/dev/mapper/kaidatavg-kaisapdata1_lv          25G   25G  716M  98% /db2/KAI/sapdata1
/dev/mapper/kaidatavg-kaisapdata2_lv          25G   25G  716M  98% /db2/KAI/sapdata2
/dev/mapper/kaidatavg-kaisapdata3_lv          25G   25G  716M  98% /db2/KAI/sapdata3
/dev/mapper/kaidatavg-kaisapdata4_lv          25G   25G  716M  98% /db2/KAI/sapdata4

Added new 128 disk vide a separate ticket from DPE and extended 15 GB




INC8778084    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB0DB02- KB0016174
10.12.10.81


INC8778083    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB0AP01- KB0016174
10.12.10.140 

INC8778082    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWPB0AP13- KB0016174
10.12.10.174

INC8778081    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWPB0AP12- KB0016174
10.12.10.180


INC8778080    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWPB0AP11- KB0016174
10.12.10.177 


INC8778079    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWDB3AP01- KB0016174
10.12.10.14 


INC8778078    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWPB0AP08- KB0016174
10.12.10.179


INC8778077    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWDB3DB01- KB0016174
10.12.10.58 

INC8778076    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWPB0AP01- KB0016174
 10.12.10.30 

-----------------------------------------------------------------------------------------------------------------
12 July


SR0030674    Panasonic North America    Low    Set the password change to NEVER for all ids in /etc/passwd
Set the password change to NEVER for all ids in /etc/passwd ( Server should NOT force the users to change password after 90 which may cause issues for service users)

CS1  pn4us7leccs1  10.12.254.101
MS1 pn4us7ewms1 10.12.254.94
IS1 pn4us7lmiis1  10.12.254.125
SS1 pn4us7lapss1 10.12.254.102


INC8787307    IBM Netcool Auto Ticketing Integration [MHAS]    Suncor Energy Inc.    P2 - Major    SAP12    Processor_load_is_too_high_on_snchgraqa11.imzcloud.ibmammsap.loca
10.73.12.35


SR0030751
Remove/Delete below listed FS from respective hosts (which mounted for Upgrade project)

LS1 - svls1srv0 (10.6.1.144)	DOne
/sapstage

LQ1 - svlq1srv0 (10.6.2.19)	DOne
/sapstage

LPP - spsvppalase01 (10.6.3.22)	DOne
/sapstage

JQ1 - svjq1srv0 (10.6.2.12)	A0EASG014XVM004	done
/tempjq1upg

JPP - spsvepajapp01 (10.6.3.13)	A0EASG014XVM039	DOne
/backup_FSQUO

EQ1/RQ1 - sveq1srv0 (10.6.2.11)		Done
/tempeq1upg
/temprq1upg

EPP/RPP - spsvepaeapp01 (10.6.3.12)
/tempeppupg
/temprppupg




SR0030843
svjd1srv0	10.6.1.12



SR0030844
lvextend by 12 GB
[root@spsvepajapp01 ibmrmalik]$ df -h /usr/sap/
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/jppappvg-jppusrsap_lv
                       54G   35G   17G  68% /usr/sap




INC8788761  Suncor Energy Inc.  P2
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.15 (thresh: 16
10.73.12.10




INC8788850  Suncor Energy Inc.  P2
Memory Virtual CRITICAL: Free Memory 0.88% (thresh 2:%)
10.73.11.145





SR0030845
hare the disk utilization details for FS  /sapmnt/log of  tsleecprddb (10.170.61.59) between 10-Jul-2019 till 12-Jul-2019

-----------------------------------------------------------------------------------------------------------------------------------

14 July

INC8806555    Inter Pipeline Fund    P3 - Minor    Need OS team to check disk errors
IPLSAS4DP04 	10.138.1.53	10.11.1.49



INC8807264    IAG GBS Limited    P2 - Major    Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:15960947]
10.133.15.25 



INC8807623    Inter Pipeline Fund    
P1 - Severe    Host Reboot CRITICAL: Uptime 0 minutes -
Host Node: iplsas4dp03 NodeAlias: 10.138.1.73


INC8807618    Inter Pipeline Fund    
P1 - Severe    Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min) 



INC8807717    Apleona GmbH Grounding    
P2 - Major    Processor_load_is_too_high_on_APLBREDK1.imzcloud.ibmammsap.local



INC8807803
Need NFS mound from App server to both the DB nodes (iplsas4dp03 & iplsas4dp04)
PRD - S4HANA  App Server    RPA    iplsas4ap01    10.138.1.13    10.11.1.13
IPLSAS4DP03 	10.138.1.14	10.11.1.44
IPLSAS4DP04 	10.138.1.53	10.11.1.49



INC8808349    Concessionaria Aeroporto Rio de Jan    
P2 - Major    Processor_load_is_too_high_on_CONSPECCAPD.imzcloud.ibmammsap.local -
10.16.1.12



INC8808425    Houghton Mifflin Harcourt    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on HPCCCPAP01- KB0016174
10.12.15.74


INC8808426    Houghton Mifflin Harcourt    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on HPCCCPAP03- KB0016174
10.12.15.76 


INC8809233    Raycap GmbH    
P2 - Major    Processor_load_is_too_high_on_deeh11ryc1006.imzcloud.ibmammsap.local -



INC8809280 - SL-Frankfurt-02 - TAQA Arabia (TQA) - AMM-SAP - Prod Server TQAERPPRD1-APP, TQAERPPRDH was down
VM TQAERPPRD1-APP, TQAERPPRDH -DB

----------------------------------------------------------------------------------------------------------------------gm
15 July


INC8815945    AGEAS    
P2 - Major    Processor_load_is_too_high_on_agesvcdmhsrv1.imzcloud.ibmammsap.local



INC8816217    Suncor Energy Inc.    
P2 - Major    Processor_load_is_too_high_on_snchltada11.imzcloud.ibmammsap.local




INC8816180    Unique S.A.    P3 - Minor    Free_disk_space_is_less_than_20%_on_OS_volume_/ - @Ravi Malik (3x OS Suppport)


INC8816354    Suncor Energy Inc.    P2 - Major    Processor_load_is_too_high_on_snchgrapa12.imzcloud.ibmammsap.local[



fra02-pod2-4tb-host10.imzcloud.ibmammsap.local
VSphere
10.194.67.87 (Private)
Frankfurt 2 

9:20:46 AM: Password from Password tab = jSCTm2%dOCug1c@
root/jSCTm2%dOCug1c@ 



INC8815226    COTY Inc.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB4DB01- KB0016174



INC8817353    Apleona GmbH Grounding    
P1 - Severe    Zabbix_agent_on_ap5server7.imzcloud.ibmammsap.local_is_unavailable


INC8817365    Apleona GmbH Grounding    
P1 - Severe    Host Reboot CRITICAL: Uptime 0 minutes


INC8817764    Panasonic North America    
P2 - Major    Processor_load_is_too_high_on_pn8us7lbcd0.imzcloud.ibmammsap.local
10.12.255.84 


Panaria - PNC - System Read Only File Systems CRITICAL: /mnt/sapexchangePT filesystems are read-only
INC8797957
INC8797948
INC8797912	System Read Only File Systems CRITICAL: /mnt/sapexchangePT filesystems are read-only
INC8797333
INC8797329
INC8797324
INC8797323
INC8797321

---------------------------------------------------------------------------------------------------------------------

16 July

INC8822117    2    TRIO 9    IPL    IPLSAS4DP03    10.138.1.73 â€” HANA 2.0 RPA Need OS to check access.
IPLSAS4DP03 	10.138.1.73	10.11.1.74 	MON
10.138.1.73 â€” HANA 2.0 RPA i can't access at the OS level. getting access denied
Need OS to check access - ibmashevni

INC8798574    P1 - Severe    Zabbix_agent_on_hlthon1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15951676]
INC8798573    P1 - Severe    Zabbix_agent_on_saptst1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15951675]
INC8798518    P1 - Severe    Zabbix_agent_on_sapkai1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15951664]
INC8798515    P1 - Severe    Zabbix_agent_on_hlttst1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15951658
Mitsubishi Steel (MI8)
Host Name	    IFN		               CFN
SAPKAI1		10.20.131.11	10.232.131.11
SAPTST1		10.20.131.12	10.232.131.12	 
HLTTST1		10.20.131.13	10.232.131.14	 
HLTHON1		10.20.130.12 	10.232.130.11


INC8826981    OSRAM GmbH    
P2 - Major    Processor_load_is_too_high_on_os1a2bap01.imzcloud.ibmammsap.local



CHG0118255   snapshot
DEP	        DLBDEPDA00	         Development	10.13.2.26
DNG		DLBDNGDA00	 	 Development	10.13.2.22
DBI	        DLBDBIDA00	         Development	10.13.2.21



INC8827435   
DYSCIERP0100  10.6.11.11	10.1.161.18 
DYSDBERP0100  10.6.11.15	10.1.161.19



SR0031033
Please create  VM snapshot of host   APLHRHP1 	170.225.68.22
once completed send mail to balajikr11@in.ibm.com



JD1 snapshot pls 
svjd1srv0	10.6.1.12	A0EASG014XVM003
CHG0118611 

----------------------------------------------------------------------------------------------------------------------
17 July


Cache clear
[root@dysdberp0100 ibmrmalik]$ free -g
             total       used       free     shared    buffers     cached
Mem:            62          7         55          2          0          4
-/+ buffers/cache:          2         60
Swap:           47          0         47



INC8836022    IBM Netcool Auto Ticketing Integration [MHAS]    CMA CGM    P2 - Major    SAP12    Free_disk_space_is_less_than_10%_on_volume_/sapmnt/UW3


INC8789893	
Direct link Connection Status From IBM to T-System
PTPKOMODO 	10.70.31.13	192.168.166.30




SR0031282
Please provide the usage of memory and swap in server - dyss4apsbd41




INC8835785    PANARIAGROUP INDUSTRIE CERAMICHE SP    Free_disk_space_is_less_than_20%_on_volume_/var/log






CHG0118744
svjq1srv0	10.6.2.12  A0EASG014XVM004	snapshot


--------------------------------------------------------------------------------------------------------------
18 July


INC8847593  IAG GBS Limited  P2
Processor_load_is_too_high_on_IA1HCCPRDWD.imzcloud.ibmammsap.local[PROBLEM:16032141]
10.133.15.28



INC8847703  AGEAS   p2
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.91 (thresh: 16)
10.6.1.180


Case # 85794869		INC8848396
root/  TWjbaD%9X3dzMG@



INC8830273   sev3
<MI8> Inquiry request regarding HULFT DEV "/TST_Scripts/" directory
 723  2019-07-10 14:25:19 rm -r TST_scripts.tar.gz
  724  2019-07-10 14:27:20 tar -ztvf TST_scripts.tar.gz
  726  2019-07-10 14:28:21 tar -tvf TST_scripts.tar
  727  2019-07-10 14:29:27 tar -tvf TST_scripts.tar | more
  728  2019-07-10 14:30:21 cd /TST_scripts/
  729  2019-07-10 14:32:41 tar -xvf /tmp/TST_scripts.tar
  778  2019-07-10 14:59:43 cd TST_scripts/



SAPTST1
SAPKAI1

-----------------------------------------------------------------------------------------------------------
22 July

INC8885894    Certified IT Consultants - TMG    P2 - Major    (Received during suppression) Ping Availability CRITICAL - 10.210.1.20: rta nan, lost 100%
INC8885891    Certified IT Consultants - TMG    P2 - Major    (Received during suppression) Ping Availability CRITICAL - 10.210.1.20: rta nan, lost 100%	10.210.1.20
INC8885889    Certified IT Consultants - TMG    P2 - Major    (Received during suppression) Ping Availability CRITICAL - 10.210.1.20: rta nan, lost 100%
INC8885887    Certified IT Consultants - TMG    P2 - Major    (Received during suppression) Ping Availability CRITICAL - 10.210.1.20: rta nan, lost 100%


INC8777907
SAP: HostActive: partial and HostStatus: warning on host agesvbq1hsrv1
VM name from score host - agesvbq1hsrv1 (VM - A0EAML018VL1149)



INC8886401
Disk Utilization /usr/sap/PB6 CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)
extended teh FS 6GB


CHG0118886	CTASK0122603
QEP	        DLBQEPDA00	         QA	     10.13.2.25  snapshot



INC8863799
Processor_load_is_too_high_on_GRC01[PROBLEM:16066639]
10.68.210.15



INC8887034    COTY Inc.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWDB3DB01- KB0016174	10.12.10.58
INC8887033    COTY Inc.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB2AP01- KB0016174	10.12.10.143
INC8887031    COTY Inc.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB0DB02- KB0016174	10.12.10.81 
INC8887030    COTY Inc.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWPB0AP09- KB0016174	10.12.10.175



INC8887799    IAG GBS Limited    
P2 - Major    SAP-HEC-Swivel:SFTP Quality server connectivity issue
IA1FTSPRDAPP 	10.133.15.24	66.248.244.24


SR0031606
Request to setup FTP server mount points for SBD and SBQ

dyss4apsbd41 - SBD	10.6.12.18	10.1.162.18
[root@dyss4apsbd41 ibmrmalik]$ id sbdadm
uid=20410(sbdadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)



dyss4apsbq21 - SBQ	10.6.12.34	10.1.162.34
[root@dyss4apsbq21 ibmrmalik]$ id sbqadm
uid=20210(sbqadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)



ports 139 and 445
NFS server  DYSFTPDAPRD01 	10.6.11.14	10.1.161.14 	




INC8888438	P2
URGENT <MI8> Request to restart SAPTST1


INC8819754
Disk Utilization /home CRITICAL: Free 101.23MB/15.82% (thresh @10.01:20%)



INC8652798
Processor_load_is_too_high_on_tsleecprddb.imzcloud.ibmammsap.local[PROBLEM:15785905]


INC8770885
Processor_load_is_too_high_on_sapapp21.imzcloud.ibmammsap.local[PROBLEM:15921148]
10.207.61.80 

-------------------------------------------------------------------------------------------------------------------------

23 July

SR0031606
Request to setup FTP server mount points for SBD and SBQ

dyss4apsbd41 - SBD	10.6.12.18	10.1.162.18
[root@dyss4apsbd41 ibmrmalik]$ id sbdadm
uid=20410(sbdadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)



dyss4apsbq21 - SBQ	10.6.12.34	10.1.162.34
[root@dyss4apsbq21 ibmrmalik]$ id sbqadm
uid=20210(sbqadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)



ports 139 and 445
NFS server  DYSFTPDAPRD01 	10.6.11.14	10.1.161.14 




SR0031854
 setT0d@y0722  Welcome#1  for ARAUCOFTP



SR0031909
cron job not working issue




INC8645487	sev1
 Free_disk_space_is_less_than_5%_on_volume_/var/log




INC8895337
Processor_load_is_too_high_on_DG1erpqasdg.imzcloud.ibmammsap.local[PROBLEM:16109871]
10.143.31.12


INC8645444
Zabbix_agent_on_dltwb1hwd.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:15678862]



INC8896047    Delta Airlines    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)



INC8897192    Dilip Buildcon Limited    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 27.31
10.13.1.23


INC8897202    St Jude Medical    CMS-SAP    JUD-01    P2 - Major    JUD    SAP09    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.26 (thresh: 16)    Queued    SQ-SAP-TRIO-9

INC8895630    DyStar Singapore Pte Ltd    P2 - Major    Service sshd CRITICAL: 0 sshd processes running (thresh 1:)
INC8895628    DyStar Singapore Pte Ltd    P2 - Major    Service cron CRITICAL: 0 cron processes running (thresh 1:)


INC8872912	#tta-dev_qa_final
Unmount file system  /BWQA_IMPORT from server  "SAPAPP18" (CFN-10.170.61.116, IFN-10.207.61.70)

and

Mount  /BWQA_IMPORT to server "SAPBIQA"    (CFN -10.170.63.40, IFN-10.207.63.24)



SR0031922
Please mount below FS on listed hosts
che01ammsol01.imzcloud.ibmammsap.local:/sds  3.6T  2.7T  786G  78% /sds  

MG2ERPDEVDB     10.198.4.11   mrdadm
MG2ERPQASDB	10.198.5.11  --> mhqadm
MG2ERPPRDDB	10.198.3.11  --> mhpadm



INC8898163
URGENT <MI8>  Please reboot  SAPKAI1 (10.232.131.11)

--------------------------------------------------------------------------------------------------------------------

24 Jul


INC8904616    IBM Netcool Auto Ticketing Integration [MHAS]    AGEAS    P2 - Major    SAP09    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.29 (thresh: 16)






SR0032051
Please mount /tempFS residing on 10.6.12.19 onto 10.6.12.33
DYSADSDADSD40 	10.6.12.19	10.1.162.19
Destination: dysadsdadsq20	10.6.12.33

[root@iplsas4ap01 ibmrmalik]$ cat /etc/exports
/tempFS *(rw,async,no_subtree_check,insecure,no_root_squash)
/backup_new *(rw,async,no_subtree_check,insecure,no_root_squash)



SR0032049
Please provide RAM and CPU usage on DLBPECAP01
Please provide RAM and CPU usage on DLBPECAP01 10.13.1.12

for Date jun 28th 2019




INC8790410
Extended the VG, extended the 8 LVs and validated all the created and missing lvs from the list




INC8892839 _ tsleecqa 10.207.63.14 , DF is hung on this server
[root@tsleecqa ibmrmalik]$ cat /etc/fstab |grep -i /qasbackup
10.170.63.25:/qasbackup /qasbackup      nfs     soft,vers=3     0 0
10.207.63.19	



INC8907476  URGENT <MI8>  Please reboot  SAPKAI1 (10.232.131.11) 24th July
[root@sapkai1 ibmrmalik]# uptime
 17:41pm  up   0:02,  2 users,  load average: 4.14, 1.41, 0.50

------------------------------------------------------------------------------------------------------------------------------

25 July

 SCO - INC8913154 - SL-Dallas-09 - Fitbit Inc (FBT) - SAP HEC-AMM - S4D HANA DB Log FS is full
root@dal09ammtsm001
https://control.softlayer.com/support/tickets/86921204
146.89.140.50
SL no 86921204
Disk Utilization /sapmnt/log CRITICAL: Free 12358.30MB/4.68% (thresh @0:5%)
10.4.26.10  fbdhanadb	


INC8912877    1    TRIO 11    FBT    N/A    SAP HEC SWIVEL :p1:  SAP Production S4 having critical proble-0000444824/2019


DAL09AMMTSM001 	146.89.140.50	146.89.140.50

Check for any resource bottlenecks, FS utilization & possible OS issues on DAL09AMMTSM001 


INC8915853
<MI8>  Please reboot  SAPKAI1 (10.232.131.11) and SAPTST1(10.232.131.12) 25th July
SAPKAI1 	10.20.131.11	10.232.131.11
SAPTST1 	10.20.131.12	10.232.131.12



INC8867583  P1....need to reboot the host DYSCIAPP0600 	10.6.11.24 



svjq1srv0	10.6.2.12    snapshot     A0EASG014XVM004	CHG0119647


-------------------------------------------------------------------------------------------------------------------------------------------

26 July

INC8912877
SAP HEC SWIVEL :P1:  SAP Production S4 having critical proble-0000444824/2019
FBTPRDBWDB / 10.4.27.18
FBTPRDFIRDB / 10.4.27.15
FBTPRDHANDB / 10.4.27.10

xfs_repair /dev/mapper/vghanadata-lv_usr_sap




dalhana-1024-52
10.121.75.75     
1wDTMR%wzuzvsj@

Case # 86876180

scan disk for badsectors

1. Reboot VM in single user mode.
2. Unmount file system related to /dev/sdb which has 9 bad blocks and it has xfs file system.
3. Run file system check using following command:

xfs_check /dev/mapper/vghanadata-lv_hana_data
xfs_check  /dev/mapper/vghanadata-lv_usr_sap
xfs_check  /dev/mapper/vghanadata-lv_hana_shared


4. Repair file system using command:

xfs_repair /dev/mapper/vghanadata-lv_hana_data
xfs_repair  /dev/mapper/vghanadata-lv_usr_sap
xfs_repair  /dev/mapper/vghanadata-lv_hana_shared

Also using -L option in above command to force repair the file system.



INC8927601
Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)




INC8929526
Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)



INC8927527
Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)


INC8929752
Ping Availability CRITICAL - 10.4.27.15: Host unreachable @ 192.168.0.46. rta nan, lost 100%




INC8930516
Host Reboot CRITICAL: Uptime 13 minutes (thresh 60 min)



INC8929752
Ping Availability CRITICAL - 10.4.27.15: Host unreachable @ 192.168.0.46. rta nan, lost 100%



INC8930183
Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)



INC8930213
Zabbix_agent_on_FBTPRDFIRDB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16172323]



INC8927777
Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)



FBTPRDFIRDB:/usr/sap/FIP/HDB00/fbtprdfirdb/trace
24th til now
move to usr/sap/FIP/HDB00/fbtprdfirdb/

------------------------------------------------------------------------------------------------------------------------

28 July

INC8957217    Methanol Chemicals Company-Chemanol    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOECCD- KB0016174
10.7.12.31
started nscp service which was hung


INC8957216    Panasonic North America    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN4USHLEWMP1C- KB0016174
10.12.254.22


INC8957212    MSC Industrial Supply Co.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3WDCWADB16- KB0016174
10.12.6.32 



INC8953783    MSC Industrial Supply Co.    CMS-SAP    MS3-02    P2 - Major    MS3    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ARCHPRD01- KB0016174

INC8953784    MSC Industrial Supply Co.    CMS-SAP    MS3-02    P2 - Major    MS3    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ICC01- KB0016174

INC8953785    MSC Industrial Supply Co.    CMS-SAP    MS3-02    P2 - Major    MS3    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3WDCLADB20- KB0016174


INC8953787    MSC Industrial Supply Co.    CMS-SAP    MS3-02    P2 - Major    MS3    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3WDCWADB36- KB0016174


INC8953788    MSC Industrial Supply Co.    CMS-SAP    MS3-02    P2 - Major    MS3    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ICCPRD01- KB0016174


INC8953789    MSC Industrial Supply Co.    CMS-SAP    MS3-02    P2 - Major    MS3    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ARCHQA01- KB0016174


INC8953791    Panasonic North America    CMS-SAP    PN4-02    P2 - Major    PN4    SAP10    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN4US7LECCD1- KB0016174
10.12.254.89    done

INC8953794    Methanol Chemicals Company-Chemanol    CMS-SAP    CH5-01    P2 - Major    CH5        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOBID- KB0016174


INC8953795    Methanol Chemicals Company-Chemanol    CMS-SAP    CH5-01    P2 - Major    CH5        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOECCP- KB0016174
10.7.12.44  pending to connect via diff server

INC8953796    Methanol Chemicals Company-Chemanol    CMS-SAP    CH5-01    P2 - Major    CH5        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOECCQ- KB0016174


INC8953797    Methanol Chemicals Company-Chemanol    CMS-SAP    CH5-01    P2 - Major    CH5        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOBOBJD- KB0016174


INC8953798    Methanol Chemicals Company-Chemanol    CMS-SAP    CH5-01    P2 - Major    CH5        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOPORD- KB0016174
INC8953799    Methanol Chemicals Company-Chemanol    CMS-SAP    CH5-01    P2 - Major    CH5        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOPORP- KB0016174


INC8953800    Methanol Chemicals Company-Chemanol    CMS-SAP    CH5-01    P2 - Major    CH5        Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOBOBJC- KB0016174


INC8957134    PANARIAGROUP INDUSTRIE CERAMICHE SP    CMS-SAP    PNC-01    P2 - Major    PNC    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on C1DC03- KB0016174

INC8957135    PANARIAGROUP INDUSTRIE CERAMICHE SP    CMS-SAP    PNC-01    P2 - Major    PNC    SAP09    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on C1DC04- KB0016174

INC8953782
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ARCHDEV01- KB0016174


INC8953355    Panasonic North America    CMS-SAP    PN8-04    P2 - Major    PN8    SAP11    CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%    Queued    SQ-SAP-TRIO-11


INC8952076    PT Anugerah Pharmindo Lestari    CMS-SAP    PTP-01    P2 - Major    PTP    SAP11    CPU CPU-Utilization CRITICAL: CPU Usage 98.67% (thresh 98%) user=0.66% system=0.00% iowait=0.00% idle=1.33%    Queued    SQ-SAP-TRIO-11


INC8959095    Dilip Buildcon Limited    CMS-SAP    DLB-01    P2 - Major    DLB    SAP10    CPU CPU-Utilization CRITICAL: CPU Usage 99.5% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.50%    Queued    SQ-SAP-TRIO-10


INC8960484    Suncor Energy Inc.    CMS-SAP    SNC-02    P2 - Major    SNC    SAP12    Memory Virtual CRITICAL: Free Memory 1.84% (thresh 2:%)    Queued    SQ-SAP-TRIO-12


INC8959955    Suncor Energy Inc.    CMS-SAP    SNC-02    P2 - Major    SNC    SAP12    Memory Swap CRITICAL: Swap free 41.36% (thresh 50:%)    Queued    SQ-SAP-TRIO-12

INC8958922    Suncor Energy Inc.    CMS-SAP    SNC-02    P2 - Major    SNC    SAP12    Memory Swap CRITICAL: Swap free 47.01% (thresh 50:%)    Queued    SQ-SAP-TRIO-11



INC8960047    Companhia Brasileira de Distribuicao    CMS-SAP    MVO-01    P1 - Severe    MVO        Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:16220869]

INC8961613    IBM GLOBAL SAP Educational LAB    CMS-SAP    QSL-02    P1 - Severe    QSL        Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:16222094]




INC8912877/INC8941726
Production DB    S4P    fbtprdhandb    10.4.27.10
Production FIORI DB    FIP    FBTPRDFIRDB    10.4.27.15
DB server    BPP    FBTPRDBWDB    10.4.27.18

OS version: RHEL 6.7
SID name: S4P
HANA version: 1.0 SP12 Rev 12
Instance number: 00
CFN IP: 192.168.167.10
IFN IP: 10.4.27.10
Servers name: fbtprdhandb
VLAN details: NA
ESX host: NA
HANA type : vHANA


OS version: RHEL 6.7
SID name: FIP
HANA version: 1.0 SP12 Rev 12
Instance number: 00
CFN IP: 192.168.167.15
IFN IP: 10.4.27.15
Servers name: FBTPRDFIRDB
VLAN details: NA
ESX host: NA
HANA type : vHANA


OS version: RHEL 6.7
SID name: BPP
HANA version: 1.0 SP12 Rev 12
Instance number: 00
CFN IP: 192.168.167.18
IFN IP: 10.4.27.18
Servers name: FBTPRDBWDB
VLAN details: NA
ESX host: NA
HANA type : vHANA
these are the servers
we need to check for any errors basically in /var/log/messages file and dmesg
for xfs related issue
and any temperature errors on cpu



Update: Server looks good
1)FBTPRDFIRDB 10.4.27.15
ERRORS on: /var/log/messages:
  NONE
Sun Jul 28 07:59:43 PDT 2019

2)FBTPRDBWDB 10.4.27.18
ERRORS on: /var/log/messages:
NONE
Sun Jul 28 08:04:39 PDT 2019


3) FBTPRDHANDB 10.4.27.10
ERRORS on: /var/log/messages:
NONE
Sun Jul 28 08:07:43 PDT 2019

---------------------------------------------------------------------------------------------------------------

29 Jul

INC8968422    DyStar Singapore Pte Ltd    P2 - Major    Memory Swap CRITICAL: Swap free 49.51% (thresh 50:%)



INC8970379    Delta Airlines    P1 - Severe    Disk Utilization / CRITICAL: Free 15.95MB/0.07% (thresh @0:5%)  
10.4.5.57


INC8970599    Delta Airlines    CMS-SAP    DAL-01    P1 - Severe    DAL    SAP11    Free_disk_space_is_less_than_5%_on_OS_volume_/


INC8970597    Delta Airlines    P2 - Major    Free_disk_space_is_less_than_10%_on_OS_volume_/[PROBLEM:16229200]  -


CHG0119899
VM snapshot of JD1 and FD1 pls 
svjd1srv0	10.6.1.12	A0EASG014XVM003
svfd1srv0	10.6.1.24	A0EASG012XVM003


SR0032323
After the data migration of APP and APT the below mount points are not working now. 

Z_MASTERDATA                       /masterdata

It should map to below FTP folder.

For APP

masterdata (\\10.1.161.14) (Y:) > APP


For APT

masterdata (\\10.1.161.14) (Y:) > APT

Host name for APP is dysciapp0600	10.6.11.24	10.1.161.24 		appadm
Host name for APT is dysciapt2600	10.6.12.57	10.1.162.57		aptadm

DYSFTPDAPRD01 	10.6.11.14	10.1.161.14
//10.1.161.14/masterdata /masterdata cifs credentials=/etc/Dystar_credentials,uid=20060,gid=3050,_netdev,nofail

//10.1.161.14/masterdata /masterdata cifs credentials=/etc/Dystar_credentials,uid=20260,gid=3050,_netdev,nofail

[root@dysciapp0600 /]# id appadm
uid=20060(appadm) gid=3050(sapsys) groups=3050(sapsys),54717(sapinst),2401(dba),2402(oper)

[root@dysciapt2600 ibmrmalik]$ id aptadm
uid=20260(aptadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst),2401(dba),2402(oper)




CHG0119788
svjq1srv0	10.6.2.12  snapshot



SR0032616
reset pw for custsap for 55 vms



INC8830273
<MI8> Inquiry request regarding HULFT DEV "/TST_Scripts/" directory
HLTTST1(10.232.131.14)


[root@hlttst1 log]# free -g
             total       used       free     shared    buffers     cached
Mem:             3          3          0          0          0          2
-/+ buffers/cache:          1          2
Swap:           11          0         11


10th July to 29th July sample memory



SR0032481  snapshot request

SID	        HOSTNAME	IFN IP
--------------------------------------------------
SV6 	       SNCHBDJSA11    10.73.11.217
SP6 	       SNCHEPJSA11    10.73.11.219
SX6            SNCHPIJSA11    10.73.11.220
SB6            SNCHBWJSA11    10.73.11.152

SE1            SNCHEUASD11    10.73.11.154
SN1            SNCHTNASD11    10.73.11.228
S1B            SNCHBIBSD11    10.73.11.222  2 vms and both off
S1D            SNCHDSBSD11    10.73.11.225

SNCHEUASA11 10.73.11.155

SNCHTNASA11 10.73.11.229
SNCHTNASA12 10.73.11.230

SNCHBIBSA11 10.73.11.223  2 vms and both off
SNCHBIBSA12 10.73.11.224

SNCHDSBSA11 10.73.11.226
SNCHDSBSA12 10.73.11.227




SV6 SNCHBDJSA11 10.73.11.217
SP6 SNCHEPJSA11 10.73.11.219
SX6 SNCHPIJSA11 10.73.11.220
SB6 SNCHBWJSA11 10.73.11.152

--------------------------------------------------------------------------------------------------------------------------------------

31 Jul


INC8995260    CELULOSA ARAUCO Y CONSTITUCION S.A.    CMS-SAP    APF-03    P1 - Severe    APF        Disk Utilization /temp



INC8996185    St Jude Medical    CMS-SAP    JUD-01    P2 - Major
10.196.4.14 




INC8994568 Drive-Space E critical



INC8994519




INC8997163    PANARIAGROUP INDUSTRIE CERAMICHE SP    CMS-SAP    PNC-01    P1 - Severe
FS_is_read_only_on_C1BWP.imzcloud.ibmammsap.local[PROBLEM:16262020]
/mnt/sapexchangeIT 
10.199.1.30



INC8997323    PT Anugerah Pharmindo Lestari    CMS-SAP    PTP-01    P1 - Severe    PTP    SAP11    Disk Utilization /opt CRITICAL: Free 1474.93MB/4.86% (thresh @0:5%)	10.70.31.16

INC8997321    PT Anugerah Pharmindo Lestari    CMS-SAP    PTP-01    P1 - Severe    PTP    SAP11    Disk Utilization /var/lib/named CRITICAL: Free 1474.93MB/4.86% (thresh @0:5%)

INC8997320    PT Anugerah Pharmindo Lestari    CMS-SAP    PTP-01    P1 - Severe    PTP    SAP11    Disk Utilization /var/cache CRITICAL: Free 1454.51MB/4.79% (thresh @0:5%)


INC8997057    COTY Inc.    CMS-SAP    CTU-01    P2 - Major
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.15 (thresh: 16)
10.12.10.28



INC9000699    Toyota Financial Services    CMS-SAP    TOY-02    P1 - Severe    TOY    SAP10    Zabbix_agent_on_wdctfshnadr01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16267050] 

-----------------------------------------------------------------------------------------------------------------------------------------------

1 Aug


INC9008167   Suncor Energy Inc.   Memory Virtual CRITICAL: Free Memory 0.82% (thresh 2:%)  P2


INC9007978    Apleona GmbH Grounding    CMS-SAP    AP5-01    P2 - Major
Memory Swap CRITICAL: Swap free 40.74% (thresh 50:%)
170.225.68.20 



INC9008724    Panasonic North America    CMS-SAP    PN8-04    P2
CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=1.00% system=0.00% iowait=0.00% idle=0.00%


SR0033061
Extend the FS by 20 GB on SNCHDMDSD11
Request you to extend the FS by 20GB on SNCHDMDSD11 /sapmnt/data.


INC9008797
(Received during suppression) Disk Utilization /sapmnt/data CRITICAL: Free 25976.80MB/3.30% (thresh @0:5%)


INC9009613    Suncor Energy Inc.    CMS-SAP    SNC-02    P1 - Severe
Free_disk_space_is_less_than_5%_on_volume_/home/tt1adm[PROBLEM:16281819]
10.73.11.144



INC9009612    Suncor Energy Inc.    CMS-SAP    SNC-02    P2 - Major
Processor_load_is_too_high_on_snchtrita11.imzcloud.ibmammsap.local[PROBLEM:16281815]
10.73.11.144

INC9010162    Suncor Energy Inc.    CMS-SAP    SNC-02    P2 - Major
CPU CPU-Utilization CRITICAL: CPU Usage 99.75% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.25%
 10.73.11.144 




SR0033081
Tatat Steel Limited - Hosts entries of ECM FQDN in S4H QA




Customer : Panaria - PNC
INC8976563    Uptime System-Rebooted CRITICAL: uptime: 0:4m, boot: 2019-07-29 08:30:19 (UTC)
10.199.1.82

INC8976523    Uptime System-Rebooted CRITICAL: uptime: 0:5m, boot: 2019-07-29 08:26:13 (UTC)
INC8910066    Uptime PatchesRequired CRITICAL: Uptime: 30w 1d 06:4d. Patches should be applied and server rebooted every 30 days.
INC8910056    Uptime PatchesRequired CRITICAL: Uptime: 18w 1d 23:8d. Patches should be applied and server rebooted every 30 days.
INC8910051    Uptime PatchesRequired CRITICAL: Uptime: 28w 6d 18:37d. Patches should be applied and server rebooted every 30 day



INC9010750  sev3
df -h hung and backup haulted

-------------------------------------------------------------------------------------------------------------

5 Aug

INC9050789    PANARIAGROUP INDUSTRIE CERAMICHE SP    P2 - Major    Free_disk_space_is_less_than_10%_on_volume_/var/log[PROBLEM:16335316]
10.199.1.23


INC9051557    GKN Driveline Newton LLC    P1 - Severe    Zabbix_agent_on_gkneccdevqa.imzcloud.ibmammsap.local_is_unavailable
10.15.81.24


INC9050183
Disk Utilization /var/log CRITICAL: Free 184.77MB/9.97% (thresh @5.01:10%)



INC8986162 <MI8>  Please delete /KAI_scriptsã€LV(filesystem) 
[root@sapkai1 ibmrmalik]# lvs |grep -i KAI_scripts
  lv_KAI_scripts othervg   -wi-a----- 15.00g 
  
  
  [root@sapkai1 ibmrmalik]# cat /etc/fstab |grep -i KAI_scripts
#/dev/othervg/lv_KAI_scripts  /KAI_scripts        xfs    defaults        1 2





INC9051602  Certified IT Consultants - TMG    P2 - Major    (Received during suppression) Ping Availability CRITICAL - 10.210.1.20: rta nan, lost 100%



INC9051948    Publiacqua S.p.A    P2 - Major    Processor_load_is_too_high_on_pbl-z-pag-a.imzcloud.ibmammsap.local
10.199.18.19


INC9051973    OSRAM GmbH    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.49



INC9052172    Suncor Energy Inc.    P2 - Major    Ping Availability (Service check timed out after 15.01 seconds)
10.73.10.12	



INC9052785    Suncor Energy Inc.    P2 - Major    Memory Swap CRITICAL: Swap free 45.59% (thresh 50:%)


INC9052682    St Jude Medical    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.31 (thresh: 16)



INC9055770    IAG GBS Limited    P2 - Major    SAP-HEC-SWIVEL: SFTP Quality server connectivity issue
IA1FTSPRDAPP.iag.amm.ibmcloud.com (66.248.244.24), kindly kill the
hung sshd sessions.



INC9057236    Suncor Energy Inc.    P2 - Major    Lack_of_free_swap_space_on_snchtrita12.imzcloud.ibmammsap.local
 10.73.11.145 

------------------------------------------------------------------------------------------------------------------------------------------

6 Aug

INC9065794    Meggitt Plc    P1 - Severe    Zabbix_agent_on_MGGGBJVECCX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16350824]



INC9059517    Arnoldo Mondadori Editore SpA    P3 - Minor    ARM account - no alerts were raised for FS /sapmnt/ECP full
The FS /sapmnt/ECP not under monitoring on Zabbix(old) and Nagios(new).
armfksap303a1 (node1)    10.7.102.57
armfksap303ap (node2)    10.7.102.59



SR0033423    TAQA Arabia    Medium    TAQA(TQA) - SAP Cloud Connector OS User creation




pepsi-hana-mdc02.imzcloud.ibmammsap.local	saps02db00	100.126.32.24 // 30.64.0.24
Public IP: 169.48.114.136 (Dallas 13)
Private IP: 10.186.10.39

		IPMI NYBrw3g96k

root/S4Qp9PFr





pepsi-hana-mdc01.imzcloud.ibmammsap.local	saps01db00   100.126.32.11 // 30.64.0.11
Public IP: 169.60.162.220 (Dallas 13)
Private IP: 10.186.10.5

IPMI AGjvEb5Dzg
root/ARuhqvT2



CHG0120729    CTASK0126285
svjd1srv0	10.6.1.12	A0EASG014XVM003




INC9066940    OSRAM GmbH    P2 - Major    Processor_load_is_too_high_on_os1a2bap01.imzcloud.ibmammsap.local[PROBLEM:16352079]
10.135.8.25


CHG0120740	CTASK0126304
svjq1srv0	10.6.2.12	A0EASG014XVM004


INC9074511    IBM Netcool Auto Ticketing Integration [MHAS]    CMA CGM    P2 - Major    SAP12    Disk Utilization /usr/sap/QE1 CRITICAL: Free 1580.81MB/6.88% (thresh @5.01:10%)

INC9074502    IBM Netcool Auto Ticketing Integration [MHAS]    MSC Industrial Supply Co.    P2 - Major    SAP09    Lack_of_free_swap_space_on_ms3wdcladb14.imzcloud.ibmammsap.local[PROBLEM:16369727]


CHG0120874	CTASK0126589
snapshot
svjq1srv0	10.6.2.12	A0EASG014XVM004



INC9075794  St Jude Medical   LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.55 (thresh: 16)  P2


INC9075787   Suncor Energy Inc.   Memory Virtual CRITICAL: Free Memory 0.84% (thresh 2:%)   P2


INC9076536    IBM Netcool Auto Ticketing Integration [MHAS]    MSC Industrial Supply Co.    P2 - Major    SAP09    Lack_of_free_swap_space_on_ms3wdclapp19.imzcloud.ibmammsap.local[PROBLEM:16373079]


INC9076459    IBM Netcool Auto Ticketing Integration [MHAS]    City Football Group 2    P2 - Major    SAP09    ITM Agent Offline: LONCFGCIP0004:UA
10.69.2.35

	

------------------------------------------------------------------------------------------------------------------------

8 Aug

INC9084096  Dixons Carphone   Memory Virtual CRITICAL: Free Memory 1.99% (thresh 2:%)  P2
10.197.5.22


INC9084177   Dilip Buildcon Limited   LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 73.01 (thresh: 16)   P2
10.13.2.40



INC9084350  Suncor Energy Inc.   P2
Processor_load_is_too_high_on_snchgraqa11.imzcloud.ibmammsap.local[PROBLEM:16386167]
10.73.12.35


INC9084355   Suncor Energy Inc.   P2
Processor_load_is_too_high_on_snchgrapa11.imzcloud.ibmammsap.local[PROBLEM:16386188]
10.73.10.44



shps4pdb    fixed

shdqs4dqd	sao01-pod1-4tb-host01.imzcloud.ibmammsap.local	10.151.21.175	pre deployment state    root/7SaFO6%3jB4WSz@

nfenwdb		sao01-pod1-4tb-host01.imzcloud.ibmammsap.local   	10.16.4.23	pre deployment 


CHG0120987	CTASK0126889
svjd1srv0	10.6.1.12	A0EASG014XVM003



INC9084922    Toyota Boshoku    CMS-SAP    TBO-01    P3 - Minor    TBO    SAPPJ    Windows Disk size snapshot    Queued    SQ-SAP-TRIO-9
requesting disk structure with size, drives size/used,  for the below four VMs.

TBOS4PRDAP	100.126.48.24		
TBOS4QA2AP	100.126.48.23	
TBOS4DEVAP	100.126.48.20	
TBOSUBV	100.126.48.13


CHG0120996
svjq1srv0	10.6.2.12    A0EASG014XVM004

-------------------------------------------------------------------------------------

9 Aug

CHG0117025
reg  Hadi Hamad Al-Hammam Contracting Co
====================================================
<HHH>FRA02/NON POD  Apply Latest Q319 Patches on <<Linux>> Servers.
================================================================
Security Alert Remediation- IBM AOD security alert and recommended remediation on <<Linux>> Servers.

Please deploy above Q319-patches to the following <<Linux>> servers.

Host Name    CFN IP    Asset Purpose

HHHQAPP    10.20.10.39    QA	10.7.14.39
[root@HHHQAPP tmp]$ uname -a;date;cat /etc/redhat-release
Linux HHHQAPP 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
Fri Aug  9 04:24:19 +03 2019
Red Hat Enterprise Linux Server release 6.9 (Santiago)
	
[root@HHHQAPP ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux HHHQAPP 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Fri Aug  9 04:47:46 +03 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)	
	
HHHQPO    10.20.10.32    QA	10.7.14.32
[root@HHHQPO tmp]$  uname -a;date;cat /etc/redhat-release
Linux HHHQPO 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
Fri Aug  9 04:26:41 +03 2019
Red Hat Enterprise Linux Server release 6.9 (Santiago)

[root@HHHQPO ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux HHHQPO 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Fri Aug  9 04:55:45 +03 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


Thanks and regards,
SAP Client Tribe CEM Team.



INC9093228    Meggitt Plc    P2 - Major    Disk Utilization / CRITICAL: Free 4753.72MB/10.00% (thresh @5.01:10%)


Low memory




ATLDSMR
ATLDRPDB
ATLDHRR

INC9076738
INC9009578
INC9014843
INC9010041
INC9010263
INC9030037



SR0033912    CMA CGM    Low    For QT3 : Folder creation for ABP flowback interface
Regarding SR0033912,
Server details : 
Host Name	>>	SID	>>	IFN IP
SMTMQUAQT3	>>	QT3	>>	10.78.24.17

Folder to be created : 
/interface/qua/odi/qt3/ABP_NON_PROCESSED
/interface/qua/odi/qt3/ABP_PROCESSED



INC9094561    COTY Inc.    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.25 (thresh: 16)
10.12.10.28



INC9094451    COTY Inc.    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.22 (thresh: 16)
10.12.10.28


INC9094722    Delta Airlines    P1 - Severe    Disk Utilization /interface/QEB CRITICAL: Timeout or no data available for /interface/QEB - @Ravi Malik (3x OS Suppport)



INC9094723    Delta Airlines    P2 - Major    Disk Utilization /interface/QEB CRITICAL: Timeout or no data available for /interface/QEB - @Ravi Malik (3x OS Suppport)
10.4.5.208



INC9095044    Delta Airlines    P1 - Severe    Disk Utilization /interface_old/QEB CRITICAL: Timeout or no data available for /interface_old/QEB
10.4.5.208

INC9095042    Delta Airlines    P2 - Major    Disk Utilization /interface_old/QEB CRITICAL: Timeout or no data available for /interface_old/QEB
10.4.5.208



torhana-1024-23.xsportal.local	10.166.156.250   
snchldjdd11
root/jWuZOv%cg3OyjV@




CHG0121157  CTASK0127282
svjq1srv0	10.6.2.12     A0EASG014XVM004

-------------------------------------------------------------------------------------------------------------------------------------

11 Aug

INC9100355 Sev1 





INC9104636
Disk Utilization / CRITICAL: Free 92748.68MB/20.00% (thresh @10.01:20%)




SR0034064    Panasonic North America    Low    Increase CPU and RAM on CS1 Server
PN4US7LECCS1 	10.12.254.101	10.142.41.92 	Sandbox 	Deployed 	ERP 6 EHP8 SP11	CS1	00	PN4	SAP11	9162   WDC

SR0034065    Panasonic North America    Low    Increase CPU and RAM on MS1 Server
PN4US7LEWMS1 	10.12.254.94	10.142.41.104 	Sandbox 	Deployed 	Netweaver 7.5 SP12 with EWM 9.	MS1	00	PN4	SAP11	9162 WDC

SR0034066    Panasonic North America    Low    Increase CPU and RAM on PN4US7LEWMS1A Server


INC9113728    MSC Industrial Supply Co.    P2 - Major    (Received during suppression) Ping Availability CRITICAL - 10.12.6.35: rta nan, lost 100%



INC9114626    COTY Inc.    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.49 (thresh: 16)
INC9113794    COTY Inc.    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.86 (thresh: 16)



INC9114339    CELULOSA ARAUCO Y CONSTITUCION S.A.    P1 - Severe    Disk Utilization /var/opt/BESClient CRITICAL: Timeout or no data available for /var/opt/BESClient
INC9114315    CELULOSA ARAUCO Y CONSTITUCION S.A.    P1 - Severe    Disk Utilization /tmp CRITICAL: Timeout or no data available for /tmp


INC9114314    CELULOSA ARAUCO Y CONSTITUCION S.A.    P1 - Severe    Disk Utilization /home/sapadm CRITICAL: Timeout or no data available for /home/sapadm
INC9114313    CELULOSA ARAUCO Y CONSTITUCION S.A.    P1 - Severe    Disk Utilization /usr CRITICAL: Timeout or no data available for /usr
INC9113792    CELULOSA ARAUCO Y CONSTITUCION S.A.    P1 - Severe    Disk Utilization /usr CRITICAL: Timeout or no data available for /usr




Please clarify the server name/ip as we dont recognize servers by the SIDs.
Also please confirm if you will be bringing the apps down during the upgrade or else you may need to restart the apps/db post the changes for it to reflect in the app.



INC9115592    Fitbit Inc    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on FBTPRDHANDB- KB0016174 - @Ravi Malik (3x OS Suppport)



INC9115583    Apleona GmbH Grounding    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AP5SERVER7- KB0016174



TATA steel
Tata Steel Limited- BW QA Cutover #1976
Server	*CFN IP	*IFN IP

SAPBIQA	10.170.63.40	10.207.63.24    current cpu 30 RAM 15   desired CPU 7 RAM 32

TSLBWQADB	10.170.63.120	10.207.63.20
che01-pod1-4tb-host03.imzcloud.ibmammsap.local
10.162.186.195   root/ VOh1Hb%R57MOtB@


SR0034079

Quality.
Server	*CFN IP	*IFN IP

SAPBIQA	10.170.63.40	10.207.63.24    - App

TSLBWQADB	10.170.63.120	10.207.63.20  -vHana DB   


This is Dev servers 
Server	*CFN IP	*IFN IP
SAPBIDEV	10.170.62.65	10.207.62.21
TSLBWDEVDB	10.170.62.30	10.207.62.14

rename the /usr/sap/trans to /usr/sap/trans_old  on server SAPBIQA  

then mount the /urs/sap/trans from SAPBIDEV   to SAPBIQA




INC9115451    Lindt and Sprungli North America In    P2 - Major    
Processor_load_is_too_high_on_lnasv206.imzcloud.ibmammsap.local


INC9113594
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOSOLMNJ- KB0016174



INC9113593    Methanol Chemicals Company-Chemanol    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOBIP- KB0016174



INC9113592    OSRAM GmbH    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on OS1BODAD- KB0016174



INC9113586    MSC Industrial Supply Co.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ARCHQA01- KB0016174

INC9113587    MSC Industrial Supply Co.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ICC01- KB0016174

INC9113590    MSC Industrial Supply Co.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3LOADRUNTMP- KB0016174

INC9113589    MSC Industrial Supply Co.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3WDCWADB16- KB0016174



INC9113571    LSPI    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAECCSBX0- KB0016174


INC9113579    MSC Industrial Supply Co.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MDCSERVERP2DR- KB0016174

INC9113588    MSC Industrial Supply Co.    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MS3ARCHDEV01- KB0016174


INC9117254    Tata Steel Limited    CMS-SAP    TTA-02    P1 - Severe    TTA    SAP12    Zabbix_agent_on_tslbwqadb.imzcloud.ibmammsap.local_is_unavailable




INC9117317    COTY Inc.    CMS-SAP    CTU-01    P2 - Major

INC9116948    COTY Inc.    CMS-SAP    CTU-01    P2 - Major

INC9116770    COTY Inc.    CMS-SAP    CTU-01    P2 - Major

----------------------------------------------------------------------------------------

12 Aug


 INC9121919    Panasonic Europe Ltd    P1 - Severe    Zabbix_agent_on_peu-afq-db-ha.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16434311]
 
 
CHG0117036   CTASK0118644
 Please deploy above Q319-patches to the following <<Linux>> servers.

Host Name	CFN IP	Asset Purpose

HHHPSOL	10.20.10.40	Production	10.7.14.40
[root@HHHPSOL tmp]$ uname -a;date;cat /etc/redhat-release
Linux HHHPSOL 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 12 04:42:56 +03 2019
Red Hat Enterprise Linux Server release 6.9 (Santiago)

[root@HHHPSOL ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux HHHPSOL 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 12 05:47:30 +03 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

HHHPAPP	10.20.10.35	Production	10.7.14.35
[root@HHHPAPP tmp]$ uname -a;date;cat /etc/redhat-release
Linux HHHPAPP 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 12 04:45:07 +03 2019
Red Hat Enterprise Linux Server release 6.9 (Santiago)

[root@HHHPAPP ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux HHHPAPP 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 12 05:47:28 +03 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


HHHPPO	10.20.10.31	Production	10.7.14.31
[root@HHHPPO tmp]$ uname -a;date;cat /etc/redhat-release
Linux HHHPPO 2.6.32-696.10.3.el6.x86_64 #1 SMP Thu Sep 21 12:12:50 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 12 04:45:02 +03 2019
Red Hat Enterprise Linux Server release 6.9 (Santiago)

[root@HHHPPO ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux HHHPPO 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 12 05:47:26 +03 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


INC9012361
Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)




INC9119950
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BS5JMPSRVR- KB0016174


INC9119949
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ASDDEV- KB0016174
10.207.62.25 


INC9122575    Dixons Carphone    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.99% (thresh 2:%)
10.197.5.18

INC9122512    Apple Leisure Group    P2 - Major    Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)



INC9120015, INC9120014, INC9119993, INC9119991, INC9119990, INC9119989, INC9119949


INC9120015
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TSLEECQA- KB0016174
10.207.63.14


INC9120014
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPBODEV- KB0016174



INC9119993
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on JBDAIX4- KB0016174



INC9119991
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on EWMQA- KB0016174


INC9119990
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on EWMDEV- KB0016174



INC9119989
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GRCDEVNEW- KB0016174


INC9119949
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ASDDEV- KB0016174


INC9123270	
Disk Utilization /tmp CRITICAL: Free 1117.32MB/11.86% (thresh @10.01:20%)
10.207.62.22 



INC9123459--- starting and HostStatus: warning on host loncfgccp0004---     10.69.2.29,Need OS assistance

---------------------------------------------------------------------------------------------------------------------

13 Aug

CS0001109    Zabbix_agent_on_DLTHMEHDB.imzcloud.ibmammsap.local_is_unavailable	10.4.5.48
10.143.69.165	dalhana-1024-60.xsportal.local
root/G9E3pcqh

[root@DLTHMEHDB log]$ cat messages |grep error
Aug 12 23:58:58 DLTHMEHDB kernel: HEST: Enabling Firmware First mode for corrected errors.
Aug 12 23:59:11 DLTHMEHDB ntpd[10208]: restrict: error in address '::' on line 30. Ignoring...
Aug 12 23:59:11 DLTHMEHDB ntpd[10208]: restrict: error in address '::1' on line 31. Ignoring...

We see that this host is up and responding to ping requests. Although, when remoting in through KVM we see that the screen times out after a short period of time. This can be due to the old firmware versions you have on the Remote Management Card and the Motherboard. It is recommended that you keep all firmware up to date on all components for better hardware integrity. 

nmap 10.143.69.165
Starting Nmap 5.51 ( http://nmap.org ) at 2019-08-12 23:03 CDT
Nmap scan report for 10.143.69.165
Host is up (0.0015s latency).
Not shown: 995 closed ports
PORT STATE SERVICE
22/tcp open ssh
111/tcp open rpcbind
139/tcp open netbios-ssn
445/tcp open microsoft-ds
8000/tcp open http-alt
Nmap done: 1 IP address (1 host up) scanned in 0.25 seconds

As mentioned in update 6, the cause of the issues is likely related to the out-of-date firmware on both your motherboard and your IPMI device. In order to prevent future instances of downtime like this, we recommend pushing a firmware update from the customer portal to update the firmware for both the motherboard and the IPMI device. Please let us know if you have any further questions or concerns and we will be  to assist.


CS0001337    Zabbix_agent_on_dlthbehdb.imzcloud.ibmammsap.local_is_unavailable[
delta-dal09-phana-4096-01.imzcloud.ibmammsap.local





  [root@asddev ibmrmalik]$ tail /usr/local/ncpa/var/log/ncpa_passive.log

 File "/usr/lib/python2.7/site-packages/requests/sessions.py", line 494, in request
   :param \*\*kwargs: Optional arguments that ``request`` takes.
 File "/usr/lib/python2.7/site-packages/requests/sessions.py", line 437, in prepare_request
   :type allow_redirects: bool
 File "/usr/lib/python2.7/site-packages/requests/models.py", line 305, in prepare

 File "/usr/lib/python2.7/site-packages/requests/models.py", line 379, in prepare_url
   scheme = scheme.encode('utf-8')
MissingSchema: Invalid URL '158.87.44.154/nrdp/': No schema supplied. Perhaps you meant http://158.87.44.154/nrdp/?

[12h]
David Hayes  Edit /usr/local/etc/ncpa.cfg.  Find the line that starts with "parent" and make sure the URL is correctly entered.  I believe there was a Chef recipe bug where the "https://" was missing





CHG0120939
CTASK0126743
ADNPODEV	10.198.201.15	snapshot


CS0004660    Tata Steel BSL Ltd -- BS5    P2 - Major    Perfdata FileWriteBPS CRITICAL: \2\18 = 319823
10.141.133.18

CS0004616    Tata Steel BSL Ltd -- BS5    P2 - Major    Perfdata FileReadBPS CRITICAL: \2\16 = 335833
CS0004522    Tata Steel BSL Ltd -- BS5    P2 - Major    Perfdata FileReadBPS CRITICAL: \2\16 = 361759
CS0004508    Tata Steel BSL Ltd -- BS5    P2 - Major    Perfdata FileWriteBPS CRITICAL: \2\18 = 321293


dlthbehdb       10.4.5.154 , NFS issue is causing DF to hang. Request OS assistance - CS0005730
/hana/data_temp

------------------------------------------------------------------------------------------------------------------------------

19 Aug


CS0082990    Suncor Energy Inc. -- SNC    SNC    SNC SAPHEC-IC4SAP-SL SAP LOB    Service Request        New        SUCNOR : Node SNCHBWATA12 node accessible.


consps4hdbp		10.80.1.106
shdqs4dqd		10.133.4.19
nfenwdb		10.133.4.34
nfenwqb		10.133.4.39

4:06:34 PM: those 4 are in Sao Paolo, i had provided the TEM URLs (2 servers)



CS0083171    Egyptian Refining Company -- EGR    EGR    EGR AMM-SAP SAP LOB    Service Request        New        EGR - Request to check the latest utilization of the ERCSOLPRD1 after increase memory 64 GB and swap memory 64 GB    SQ-SAP-TRIO-9


--------------------------------------------------------------------------------------------------

20 Aug


CS0096755    Manitoba Telecom Services -- MTS    MTS    MTS SAP HEC-AMM SAP LOB    Incident    P3 - Minor    New        FS_is_read_only_on_mtsbodsqas01.imzcloud.ibmammsap.local[PROBLEM:16553051]    SQ-SAP-TRIO-9
10.74.6.47
 /IFRS

CS0096753    Manitoba Telecom Services -- MTS    MTS    MTS SAP HEC-AMM SAP LOB    Incident    P3 - Minor    New        FS_is_read_only_on_mtsbodsdev01.imzcloud.ibmammsap.local[PROBLEM:16553049]    SQ-SAP-TRIO-9
10.74.6.46
/IFRS




CONSPS4HDBP 	10.16.1.111	10.80.1.106		bigfix is gud
SHDQS4DQD 	10.16.4.18	10.133.4.19
NFENWDB 	10.16.4.23	10.133.4.34
NFENWQB 	10.16.4.17	10.133.4.39



agesvepmhsrv1        10.70.111.59
agesvcpmhsrv1        10.70.111.60


100.126.32.106     saps09db00.ibmcloud.intra.pepsico.com
saps09db00	


----------------------------------------------------------------------------------------------------------------------------------------------

22 Aug

CS0125296    Panasonic North America -- PN8    P2 - Major    Processor_load_is_too_high_on_pn8us7leccd5.imzcloud.ibmammsap.local[PROBLEM:16589182]
CS0110856    Panasonic North America -- PN8    P3 - Minor    Disk Utilization /home CRITICAL: Free 85.80MB/18.98% (thresh @10.01:20%)
10.12.255.18

CS0108537    Panasonic North America -- PN8    P2 - Major    Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)




CS0125970 (urgent) 
BS5SOLMAN 	10.141.132.14	132.132.0.14 Chennai	
Please map the following file system on the Solman BS5SOLMAN (132.132.0.14). These FS are needed to start the installation of application.

File System:

/sybase - 10GB     sybase_lv					/dev/soaappvg/sybase_lv

/sybase/SOA - 20GB		SOA_lv					/dev/soaappvg/SOA_lv
/sybase/SOA/sapdiag - 10GB		sapdiag_lv		/dev/soaappvg/sapdiag_lv	
/sybase/SOA/sybtemp - 5GB		sybtemp_lv		/dev/soaappvg/sybtemp_lv
/sybase/SOA/sybsystem - 10GB	sybsystem_lv	/dev/soaappvg/sybsystem_lv
/sybase/SOA/saplog_1 - 50GB		saplog_1_lv		/dev/soaappvg/saplog_1_lv
/sybase/SOA/sapdata1 - 250GB	sapdata1_lv		/dev/soaappvg/sapdata1_lv
/sybase/SOA/sapdata2 - 250GB	sapdata2_lv		/dev/soaappvg/sapdata2_lv
/usr/sap - 50GB					sap_lv			/dev/soaappvg/sap_lv
/software - 100GB				software_lv		/dev/soaappvg/software_lv
/usr/sap - 50GB
/usr/sap/SOA - 50GB			SOA2_lv				/dev/soaappvg/SOA2_lv
/usr/sap/trans - 50GB		trans_lv			/dev/soaappvg/trans_lv
/sapmnt/SOA - 50GB		SOA3_lv					/dev/soaappvg/SOA3_lv


/dev/sdf   soaappvg  lvm2 a--    1.50t   1.50t

ext4

lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab


  
  
CS0126453    COTY Inc. -- CTU    CTU    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.45 (thresh: 16)
10.12.10.81

CS0125415    COTY Inc. -- CTU    CTU    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.76 (thresh: 16)
10.12.10.81

CS0125143    COTY Inc. -- CTU    CTU    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBOQR1DB01- KB0010973
10.12.10.24

CS0125141    COTY Inc. -- CTU    CTU    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB1AP03- KB0010973
10.12.10.151

CS0125139    COTY Inc. -- CTU    CTU    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB3DB02- KB0010973
10.12.10.104

CS0125135    COTY Inc. -- CTU    CTU    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBOSR1SP02- KB0010973
10.12.10.17 


CS0125028    CMA CGM -- CMA    CMA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMSMDEVDS1- KB0010973
10.78.22.43

CS0125027    CMA CGM -- CMA    CMA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMECCQUAQE1- KB0010973
10.78.24.19

CS0125025    CMA CGM -- CMA    CMA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMIDMDEVDN3- KB0010973
10.78.22.37

CS0125024    CMA CGM -- CMA    CMA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMEMQUAQM3- KB0010973
10.78.24.26

CS0125023    CMA CGM -- CMA    CMA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMGRCQUAQG1- KB0010973
10.78.24.43

CS0125020    CMA CGM -- CMA    CMA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBSBXSR1- KB0010973
10.78.20.16

CS0125019    CMA CGM -- CMA    CMA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMECCDEVDE1- KB0010973
10.78.22.18


100.126.32.106     saps09db00.ibmcloud.intra.pepsico.com
saps09db00	
DAL13



CS0119743    Delta Airlines -- DAL    DAL    DAL SAP HEC-AMM SAP LOB    Incident    P3 - Minor    New        SAP HEC SWIVEL :P3: OS Reboot of HSG system @ 6 PM on 08/21/    SQ-SAP-TRIO-11
Received this ticket now, the reboot was requested at 330 AM IST on 22nd  which is already passed due.

CS0119796    Delta Airlines -- DAL    DAL    DAL SAP HEC-AMM SAP LOB    Incident    P3 - Minor    New        SAP HEC SWIVEL :P3: OS Reboot of HSE system @ 6 PM on 08/21/ 0000475883/2019    SQ-SAP-TRIO-11
Received this ticket now, the reboot was requested at 330 AM IST on 22nd  which is already passed due.



SNG
AGESVCPMHSRV1 	10.6.3.59	10.70.111.60
AGESVEPMHSRV1 	10.6.3.58	10.70.111.59




MGGDRDGTSX04		10.5.254.21  Meggitt	Customer	Frankfurt	frahana-1024-4.xsportal.local	Private IP: 10.134.53.146	 root/ftyfYU%zFHS484@   IPMI Dbv4Zu54U9

tstmon01han02		10.10.1.6 IBM Cloud	Non-Customer	Montreal	monhana-1024-11.xsportal.local   Private IP: 10.140.48.189		root/s5j78A%J4eycUu@   IPMI V3b2Svbj65



CS0129712    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /var/opt/BESClient CRITICAL: Timeout or no data available for /var/opt/BESClient
CS0129716    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /hana/shared CRITICAL: Timeout or no data available for /hana/shared
CS0129715    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /home CRITICAL: Timeout or no data available for /home
CS0129714    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /.snapshots CRITICAL: Timeout or no data available for /.snapshots
CS0129713    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /tmp CRITICAL: Timeout or no data available for /tmp

CS0129805    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /var/lib/machines CRITICAL: Timeout or no data available for /var/lib/machines
CS0129807    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /tmp CRITICAL: Timeout or no data available for /tmp
CS0129806    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /var/tmp CRITICAL: Timeout or no data available for /var/tmp

---------------------------------------------------------------------------------------------------------------------------------

23 Aug

CS0138364    Suncor Energy Inc. -- SNC    P1 - Severe    Disk Utilization /home/daaadm CRITICAL: Timeout or no data available for /home/daaadm 
CS0138363    Suncor Energy Inc. -- SNC    P1 - Severe    Disk Utilization /var CRITICAL: Timeout or no data available for /var -
CS0138323    Suncor Energy Inc. -- SNC    P1 - Severe    Disk Utilization /home/daaadm CRITICAL: Timeout or no data available for /home/daaadm -

CS0138452    Suncor Energy Inc. -- SNC    P2 - Major    Ping Availability CRITICAL - snchepjta16: rta nan, lost 100% 	16

CS0138770    Suncor Energy Inc. -- SNC    P1 - Severe

CS0139174    Suncor Energy Inc. -- SNC    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min
10.73.11.46


CS0138777 Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)
 10.134.14.15
 NMI watchdog: Shutting down hard lockup detector on all cpus
 
 
 
 CS0136920
 readonly / FS fixed



SuSE case
TS002644547 


CS0125595
Reduce the RAM by 16GB on below servers to 16 GB

PBBBWHDAP00 	10.6.7.18	172.25.1.18		done
PBBFFDAPDB00 	10.6.7.21	172.25.1.21		done
PBBS4HQAP00 	10.6.7.14	172.25.1.14   sx014    PBBSG016BCB242





CS0140684    Tata Steel Limited -- TTA    Incident    P2 - Major	10.207.62.25	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ASDDEV- KB0010973
CS0140457    Tata Steel BSL Ltd -- BS5    Incident    P2 - Major	10.141.133.18   Perfdata ThreadCount CRITICAL: \2\250 = 1299
CS0140168    Tata Steel BSL Ltd -- BS5    Incident    P2 - Major  	10.141.133.18
CS0139405    Tata Steel BSL Ltd -- BS5    Incident    P2 - Major	10.141.133.18
CS0139386    Tata Steel BSL Ltd -- BS5    Incident    P2 - Major	10.141.133.18
CS0138900    Tata Steel BSL Ltd -- BS5    Incident    P2 - Major	10.141.133.18
CS0138847    Tata Steel BSL Ltd -- BS5    Incident    P2 - Major



CS0141496    Bombardier Recreational Products Inc -- BR3    BR3    BR3 SAPHEC-IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Free_disk_space_is_less_than_5%on_volume/usr/sap[PROBLEM:16626567]
10.138.10.24
CS0141480    Bombardier Recreational Products Inc -- BR3    BR3    BR3 SAPHEC-IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Disk Utilization /usr/sap CRITICAL: Free 93.48MB/5.00% (thresh @0:5%)
10.138.10.24


----------------------------------------------------------------------------------------------------------------
25 Aug


CHG0125751 IA1-LON02-PROD- Apply Latest Q319 Patches on Linux Servers

IA1FIOPRDAPP	66.248.244.15	Production
IA1FIOPRDDB	66.248.244.14	Production
IA1S4HPRDAPP	66.248.244.13	Production

IA1FIOPRDAPP	 	10.133.15.15	66.248.244.15	Lon02
[root@IA1FIOPRDAPP ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux IA1FIOPRDAPP 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Aug 25 08:45:09 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[ibmrmalik@IA1FIOPRDAPP ~]$ uname -a;date;cat /etc/redhat-release
Linux IA1FIOPRDAPP 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Aug 25 09:31:27 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


IA1FIOPRDDB			10.133.15.14	66.248.244.14
[root@IA1FIOPRDDB ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux IA1FIOPRDDB 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Aug 25 08:45:09 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[ibmrmalik@IA1FIOPRDDB ~]$ uname -a;date;cat /etc/redhat-release
Linux IA1FIOPRDDB 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Aug 25 09:31:27 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


IA1S4HPRDAPP		10.133.15.13	66.248.244.13
[root@IA1S4HPRDAPP ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux IA1S4HPRDAPP 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Aug 25 08:45:09 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[ibmrmalik@IA1S4HPRDAPP ~]$ uname -a;date;cat /etc/redhat-release
Linux IA1S4HPRDAPP 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Aug 25 09:31:27 CEST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
vb 


CS0138452
Ping Availability CRITICAL - snchepjta16: rta nan, lost 100%
10.73.11.47


CS0141052
Zabbix_agent_on_PBBffpapdb00.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16626276]
 10.6.7.22

 
 
CS0162727
Disk Utilization /usr/sap/ccms CRITICAL: Timeout or no data available for /usr/sap/ccms
10.133.15.15

------------------------------------------------------------------------------------------------------------

26 Aug

CS0173073    Arnoldo Mondadori Editore SpA -- ARM    ARM    ARM IC4SAP-SL SAP LOB    Incident    P3 - Minor    New        Filesystem /var/log 100% full on armfksap301a1 
ARMFKSAP301A1 	10.7.102.62	10.244.102.37



CHG0126561
svjd1srv0	10.6.1.12	A0EASG014XVM003


CS0156486
increase FS by 30 GB each - CI2SOL
Please extend below 4 File Systems by 30 GB each 
/sybase/SOL/sapdata1/
/sybase/SOL/sapdata2/
/sybase/SOL/sapdata3/
/sybase/SOL/sapdata4/


hostname : CI2SOl
IFN IP : 10.5.242.17




CHG0126105
<<CMA >>-<<PAR01/NON POD Apply Latest Q319 Patches on <<Lin>> Servers.
Host Name	CFN IP	Asset Purpose

 smediquaqu3,smgrcquaqg1,smgwquaqq1

		SMEDIQUAQU3	10.5.24.32	QA
		SMGRCQUAQG1	10.5.24.43	QA
		SMGWQUAQQ1	10.5.24.14	QA
		SMIFAQUAQF1	10.5.24.44	QA
		SMPOQUAQX8	10.5.24.22	QA
		SMBOQUAQB3	10.5.24.15	QA
		SMGWQUAQQ2	10.5.24.28	QA
		SMBWSBXSW1		10.5.20.28   Sandbox

	SMBOQUAQB3 	10.78.24.15	10.5.24.15
	[root@smboquaqb3 tmp]$ uname -a;date;cat /etc/redhat-release
Linux smboquaqb3 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
	
	SMIFAQUAQF1 10.78.24.44	10.5.24.44
	[root@smifaquaqf1 tmp]$ uname -a;date;cat /etc/redhat-release
Linux smifaquaqf1 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
	
	SMGWQUAQQ1 	10.78.24.14	10.5.24.14
	[root@smgwquaqq1 tmp]$ uname -a;date;cat /etc/redhat-release
Linux smgwquaqq1 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
	
	SMGWQUAQQ2 	10.78.24.35	10.5.24.28
	[root@smgwquaqq2 tmp]$ uname -a;date;cat /etc/redhat-release
Linux smgwquaqq2 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
	
	SMPOQUAQX8 	10.78.24.22	10.5.24.22
	[root@SMPOQUAQX8 tmp]$ uname -a;date;cat /etc/redhat-release
Linux SMPOQUAQX8 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
	
	SMBWSBXSW1 	10.78.20.28	10.5.20.28
	[root@smbwsbxsw1 tmp]$ uname -a;date;cat /etc/redhat-release
Linux smbwsbxsw1 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
	
	SMGRCQUAQG1 10.78.24.43	10.5.24.43
	[root@SMGRCQUAQG1 tmp]$ uname -a;date;cat /etc/redhat-release
Linux SMGRCQUAQG1 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
	
	SMEDIQUAQU3 	10.78.24.32	10.5.24.32
	[root@smediquaqu3 tmp]$ uname -a;date;cat /etc/redhat-release
Linux smediquaqu3 2.6.32-754.17.1.el6.x86_64 #1 SMP Thu Jun 20 11:47:12 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Mon Aug 26 12:14:38 UTC 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


 	SMBODEVDB3 	10.78.22.14	10.5.22.14 	
	
--------------------------------------------------------------------------------------------------

27 Aug

System is down (SAP) - CS0142229
APLBREDE1 	170.225.68.12	10.92.144.12
we need to shut down VM - APLBREDE1 and rename from APLBREDE1 to APLBREDE1_old?
n/w1  00:50:56:a8:30:01
n/w2  00:50:56:a8:5f:45

#//10.92.146.173/DE1      /usr/data-exchange       cifs  -o username=SAP_DE1_KOM,domain=epmassetis,passwd=xxxFrankfurt1#,uid=de1adm,gid=sapsys

-------------------------------------------------------------------------------------------------------------

29 Aug


CS0083601
Need your help to run stpf Command at SAP Server
Below is  the command:
sftp SAP01@58.185.33.164:IN/
after that is the command required password fill in with Amos0119
send the screenshot to me so i can know that the sFTP connection is successfully done

sftp is configured on server AM3S4DEVAP01 / 10.70.22.20
58.185.33.164 Port 22




CS0206989    CMA CGM -- CMA    CMA    CMA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%    SQ-SAP-TRIO-12
10.78.24.17

CS0205622    Suncor Energy Inc. -- SNC    SNC    SNC SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        SAP SolMan Sys=TM1_TOR01AMMSOL04,MO=snchdmddd11,Alert=High Virtual CPU Utilization,Desc= ,Cat=Performance


 CS0205167    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Disk Utilization /usr/sap/trans CRITICAL: Timeout or no data available for /usr/sap/trans    SQ-SAP-TRIO-12
CS0204972    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Perfdata CPU-PercentProcessProcessorTime CRITICAL: \Process(*)\% Processor Time = 100    SQ-SAP-TRIO-12
CS0202171    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Perfdata CPU-PercentProcessProcessorTime CRITICAL: \Process(*)\% Processor Time = 65    SQ-SAP-TRIO-12
CS0201324    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Perfdata CPU-PercentProcessProcessorTime CRITICAL: \Process(*)\% Processor Time = 81    SQ-SAP-TRIO-12


CS0205201 

[root@tsleecqa scripts]$ ip route
default via 10.170.63.1 dev vlan1
10.0.0.0/8 via 10.162.24.193 dev bond0
10.162.24.192/26 dev bond0  proto kernel  scope link  src 10.162.24.222
10.170.61.0/24 via 10.170.63.1 dev vlan1
10.170.63.0/24 dev vlan1  proto kernel  scope link  src 10.170.63.15
10.207.63.0/24 dev vlan0  proto kernel  scope link  src 10.207.63.14
146.89.140.0/22 via 10.207.63.1 dev vlan0
146.89.168.0/21 via 10.207.63.1 dev vlan0
158.87.44.0/23 via 10.207.63.1 dev vlan0
158.87.46.0/23 via 10.207.63.1 dev vlan0
169.55.16.128/28 via 10.207.63.1 dev vlan0
169.55.28.32/27 via 10.207.63.1 dev vlan0
169.55.28.64/28 via 10.207.63.1 dev vlan0
169.55.192.96/27 via 10.207.63.1 dev vlan0
169.62.212.64/26 via 10.207.63.1 dev vlan0


[root@tsleecqa scripts]$ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.170.63.1     0.0.0.0         UG    0      0        0 vlan1
10.0.0.0        10.162.24.193   255.0.0.0       UG    0      0        0 bond0
10.162.24.192   0.0.0.0         255.255.255.192 U     0      0        0 bond0
10.170.61.0     10.170.63.1     255.255.255.0   UG    0      0        0 vlan1
10.170.63.0     0.0.0.0         255.255.255.0   U     0      0        0 vlan1
10.207.63.0     0.0.0.0         255.255.255.0   U     0      0        0 vlan0
146.89.140.0    10.207.63.1     255.255.252.0   UG    0      0        0 vlan0
146.89.168.0    10.207.63.1     255.255.248.0   UG    0      0        0 vlan0
158.87.44.0     10.207.63.1     255.255.254.0   UG    0      0        0 vlan0
158.87.46.0     10.207.63.1     255.255.254.0   UG    0      0        0 vlan0
169.55.16.128   10.207.63.1     255.255.255.240 UG    0      0        0 vlan0
169.55.28.32    10.207.63.1     255.255.255.224 UG    0      0        0 vlan0
169.55.28.64    10.207.63.1     255.255.255.240 UG    0      0        0 vlan0
169.55.192.96   10.207.63.1     255.255.255.224 UG    0      0        0 vlan0
169.62.212.64   10.207.63.1     255.255.255.192 UG    0      0        0 vlan0



route del -net 10.0.0.0 gw 10.162.24.193 netmask 255.0.0.0 dev bond0




CS0207998    Memory Swap CRITICAL: Swap free 30.41% (thresh 50:%)
 10.4.27.13
 
 
 
 CS0207997    Fitbit Inc -- FBT    FBT    P2 - Major    Service master CRITICAL: 0 master processes running (thresh 1:)

 
 
 CS0208478
 
 ---------------------------------------------------------------------------------------------------------------------------------------
 
 2 SEPT
 
 consps4hdbp2
 CONSPS4HDBP2 	10.16.1.116	10.80.1.11	sao01-pod1-4tb-host01.imzcloud.ibmammsap.local
 
 consps4hdbp							sao01-pod1-4tb-host01.imzcloud.ibmammsap.local
 CONSPS4HDBP 	10.16.1.111	10.80.1.106
 
 10.151.21.175  
 root/7SaFO6%3jB4WSz@
 
 
 CS0206989
 CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%
 
 
 CS0250004
 FS_is_read_only_on_a1axd2pi01.imzcloud.ibmammsap.local[PROBLEM:16733102]
 
 
 
 CS0044180
 Chef_Client_is_not_running_on_br3tgtsdb26.imzcloud.ibmammsap.local[PROBLEM:16519380]
 BR3TGTSDB26 	10.138.10.70	10.3.112.66
 
 
 CS0252291    PT Blue Bird TBK -- PBB    P2 - Major    Processor_load_is_too_high_on_PBBbwhpap00.imzcloud.ibmammsap.local[PROBLEM:16735142]
 10.6.7.20
 
 
 
 CS0252204    PT Anugerah Pharmindo Lestari -- PTP    P2 - Major    Disk Utilization /var/opt/BESClient CRITICAL: Free 2601.54MB/8.57% (thresh @5.01:10%)	10.70.31.16
CS0252226    PT Anugerah Pharmindo Lestari -- PTP    P2 - Major    Disk Utilization /var/tmp CRITICAL: Free 1643.71MB/5.41% (thresh @5.01:10%)	10.70.31.16
CS0252227    PT Anugerah Pharmindo Lestari -- PTP    P2 - Major    Disk Utilization /var/lib/mailman CRITICAL: Free 1651.79MB/5.44% (thresh @5.01:10%)	 10.70.31.16
CS0252958    St. Jude Medical -- JUD    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 25.05 (thresh: 16)	10.196.4.14


CSR # CHG0127181 
Task - CTASK0136038
SVJQ1SRV0 snapshot  A0EASG014XVM004

--------------------------------------------------------------------------------------------------------------------------------------------------------

3 SEPT

CS0261085	
Disk Utilization /var/lib/mysql CRITICAL: Timeout or no data available for /var/lib/mysql
10.6.1.180


CS0261530    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization / CRITICAL: Timeout or no data available for /


MGGGBJPGTSX04 	10.133.18.29	10.5.255.29



CS0261082    AGEAS -- AGE    P1 - Severe    Disk Utilization /srv CRITICAL: Timeout or no data available for /srv
 10.6.1.180
 
 
 
 CS0262899    Arnoldo Mondadori Editore SpA -- ARM    P2 - Major    Processor_load_is_too_high_on_armfksap002.imzcloud.ibmammsap.local[PROBLEM:16752621]
 10.7.103.26
 
 
 
 CS0263308    IAG GBS Limited -- IA1    P2 - Major    Processor_load_is_too_high_on_IA1WEBDSLBDR.imzcloud.ibmammsap.local[PROBLEM:16753175] 
 
 
 
 CS0262580    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    APQ (HANADB)|HDB_HOST_PHYS_MEM_ALRT_1|Host Physical Memory Usage
 169.60.136.225
 
 
 CS0263969    Apleona GmbH (Grounding) -- AP5    P2 - Major    Processor_load_is_too_high_on_APLBREDE1.imzcloud.ibmammsap.local[PROBLEM:16754569]
 170.225.68.12
 
 
 SAPEPQA 	10.207.63.17	10.170.63.65
 
 
  CS0263861    Apleona GmbH (Grounding) -- AP5    P1 - Severe    Disk Utilization /usr/sap/DE1 CRITICAL: Free 4637.42MB/4.85%
 -----------------------------------------------------------------------------------------------------------------------------------------------------
 4 SEPT
 
 shdqs4dqd - 10.133.4.19 -HS2 / 10.133.4.14 -SHD
nfenwdb - 10.133.4.29 / 10.133.4.34
nfenwqb - 10.133.4.49 / 10.133.4.39 



 CS0270520    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Disk Utilization /var CRITICAL: Free 485.84MB/8.68% (thresh @5.01:10%)
  10.12.254.18
 
 CS0272534    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Disk Utilization /db2/CP1/log_archive CRITICAL: Timeout or no data available for /db2/CP1/log_archive
 10.12.254.16
 
 
 @SandeepKJ (@rmalik) please can you delete the following Dollar City VMs which were not deleted after account left IBM?

below the confirmation from account DPE

VM name	Hostname
A0E3CA014XVM003	vsapdf6-ci		deleted
A0E3CA014XVM016	vsappe6-app7
A0E3CA014XVM015	vsappe6-app6
A0E3CA014XVM007	RP1
vsapqf6-ci2	vsapqf6-ci2
vsapf6-db	vsappf6-db

vsapqf6-db	vsapqf6-db
A0E3CA014XVM002	vsapde6-ci
A0E3CA014XVM005	DP6-DB
ca3qf6app01	ca3qf6app01
CA3DC6APP63	CA3DC6APP63
A0E3CA014XVM006_restore_01230216	DP6
ca3pf6app01	ca3pf6app01
A0E3CA014XVM019	vsappb6-ci



CS0274666    Panasonic North America -- PN8    P2 - Major    Memory Swap CRITICAL: Swap free 45.23% (thresh 50:%)	10.12.255.19
CS0272443    Panasonic North America -- PN8    P3 - Minor    Disk Utilization /usr/sap CRITICAL: Free 97.85MB/10.77% (thresh @10.01:20%)	10.12.255.35
CS0272434    Panasonic North America -- PN8    P3 - Minor    Disk Utilization /usr/sap CRITICAL: Free 96.37MB/10.61% (thresh @10.01:20%)	10.12.255.40
CS0270921    Panasonic North America -- PN8    P2 - Major    Disk Utilization /var/log CRITICAL: Timeout or no data available for /var/log	10.12.255.20
â€”
 
 
 
 CS0275788    COTY Inc. -- CTU    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/var/log[PROBLEM:16784970]
CS0275701    Central American Retail Sourcing -- CA3    P1 - Severe    Zabbix_agent_on_DP6.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16784723]
CS0275687    Central American Retail Sourcing -- CA3    P1 - Severe    Zabbix_agent_on_DP6-DB.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16784682]
CS0275678    Central American Retail Sourcing -- CA3    P1 - Severe    Zabbix_agent_on_vsapde6-ci.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16784649]

--------------------------------------------------------------------------------------------------------------------------------------------------------------

5 SEPT

CS0261068 
<MI8> Request for creating the temporary disk

Logical Volume					VG name				
Name							
sap_migration_lv					honappvg		


size 100GB

Attri-		File system						Owner / Group					
bute													
xfs		/HON_work2						root/root,777					
													
(MI8) 	SAPHON1 	10.20.130.11	10.232.130.15  TOK

/dev/honappvg/sap_migration_lv   /HON_work2


vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 100G -n sap_migration_lv honappvg
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab



CS0284756
[root@co3shsmaddb1 ibmrmalik]# rpm -qa |grep -i TIVsm-BA
TIVsm-BA-8.1.4-0.x86_64
TIVsm-BAcit-8.1.4-0.x86_64
10.211.2.25

[root@co3shsmaddb1 tmp]# rpm -qa |grep -i TIVsm-BA
TIVsm-BAcit-8.1.4-0.x86_64
TIVsm-BA-8.1.4-0.x86_64


[root@co3shsmaddb1 ibmrmalik]# rpm -e TIVsm-BA-8.1.4-0.x86_64
error: Failed dependencies:
        TIVsm-BA = 8.1.4-0 is needed by (installed) TIVsm-BAcit-8.1.4-0.x86_64
----------------------------------------------------------------------------------------------------------------
6 SEPT

CS0289984    Panasonic North America -- PN4    P2 - Major    Processor_load_is_too_high_on_pn4us7leccqp.imzcloud.ibmammsap.local[PROBLEM:16823414]
10.12.254.147

CS0289786    Panasonic North America -- PN8    P2 - Major    Memory Swap CRITICAL: Swap free 47.19% (thresh 50:%)
10.12.255.19



CS0292210    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 185.699MB (200MB), \??\X:\pagefile.sys 1.142GB (40GB), total 1.323GB (40.195GB)
 10.6.1.145
 

CS0292026    CMA CGM -- CMA    P3 - Minor    Disk Utilization /var CRITICAL: Free 932.04MB/20.00% (thresh @10.01:20%)
10.78.26.11



CS0284858    Panasonic Europe Ltd -- PEU    P2 - Major    PEU - Memory Increase Request
Server - PEU-AET-CI
Request - Please add 4GB memory

Note - If any reboot is required, please contact 	Srinivasan Thyagarajan2/India/IBM@IBMIN, 	Samuel Joseph1/India/IBM@IBMIN, George Guliman/Romania/IBM@IBMRO
The PDL George will have to stop the application with customer approval. This is a test server and getting the approval for reboot will not be a challenge   


CS0293493    Manitoba Telecom Services -- MTS    P2 - Major    Processor_load_is_too_high_on_R3QATapp.imzcloud.ibmammsap.local[PROBLEM:16827234]	10.74.6.43

CS0293515    COTY Inc. -- CTU    P3 - Minor    PR0CTUA1 (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory Consumption


CS0294112    Publiacqua S.p.A -- PBL    P2 - Major    Processor_load_is_too_high_on_pbl-z-pag-a.imzcloud.ibmammsap.local[PROBLEM:16827615]	10.199.18.19
CS0293877    Manitoba Telecom Services -- MTS    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.10 (thresh: 16)
CS0293780    Manitoba Telecom Services -- MTS    P2 - Major    Processor_load_is_too_high_on_prdhec1.imzcloud.ibmammsap.local[PROBLEM:16827433]		10.74.5.13


CS0206166
<MI8> Request for create the disk space
SAPHON1 	10.20.130.11	10.232.130.15
sdg                                   8:96   0  200G  0 disk
sdh                                   8:112  0   60G  0 disk


SAPHON2 	10.20.130.13	10.232.130.14



CS0296000    Meggitt PLC -- MGG    P1 - Severe    Zabbix_agent_on_MGGGBJDECCX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16829572]
CS0295973    Meggitt PLC -- MGG    P1 - Severe    Zabbix_agent_on_MGGGBJPECCX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16829548]
CS0295933    Meggitt PLC -- MGG    P1 - Severe    Zabbix_agent_on_MGGGBJPECCX09.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16829519]
CS0296011    Meggitt PLC -- MGG    P1 - Severe    Zabbix_agent_on_mgggbjveccx09.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16829589]




8 SEPT

CHG0126920	LON 02
MGG-LON02-PROD- Apply Latest Q319 Patches on Linux Servers		09-08-2019 04:30:00  09-08-2019 08:30:00
Host Name	CFN IP			Asset Purpose
MGGGBJPBCCX01	10.133.18.40 	10.5.255.40	Production
[root@MGGGBJPBCCX01 ibmrmalik]$ cat /etc/redhat-release;date;uname -a
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Fri Sep  6 01:59:20 UTC 2019
Linux MGGGBJPBCCX01 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux

MGGGBJPCNTX01	10.133.18.32	10.5.255.32	Production
[root@MGGGBJPCNTX01 ibmrmalik]$ cat /etc/redhat-release;date;uname -a
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Thu Sep  5 21:59:20 EDT 2019
Linux MGGGBJPCNTX01 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux

MGGGBJPCNTX02	10.133.18.33	10.5.255.33	Production
[root@MGGGBJPCNTX02 ibmrmalik]$ cat /etc/redhat-release;date;uname -a
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Thu Sep  5 21:59:20 EDT 2019
Linux MGGGBJPCNTX02 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux

MGGGBJPSOLX01	10.133.18.30	10.5.255.30	Production
[root@MGGGBJPSOLX01 ibmrmalik]$ cat /etc/redhat-release;date;uname -a
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Fri Sep  6 02:59:20 BST 2019
Linux MGGGBJPSOLX01 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux



CHG0126920---> Patch finished successfully, SAP performer is starting SAP

CHG0126921-  CTASK0135168	--> Waiting for SAP to stop apps to start with OS tasks. They are confirming if SAP can be stopped on those systems since there is another SAP change in progress
Lon02    

MGGGBJPECCX01	10.133.18.18	10.5.255.18	Production
[root@MGGGBJPECCX01 tmp]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX01 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep  8 02:50:04 BST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
[root@MGGGBJPECCX01 tmp]$ cat /etc/sysconfig/clock
ZONE="America/New_York"

[root@MGGGBJPECCX01 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX01 2.6.32-754.18.2.el6.x86_64 #1 SMP Thu Jul 25 17:15:34 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep  8 03:25:18 BST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

MGGGBJPECCX09	10.133.18.36	10.5.255.36	Production
[root@MGGGBJPECCX09 tmp]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX09 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep  8 02:50:04 BST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
[root@MGGGBJPECCX01 tmp]$ cat /etc/sysconfig/clock
ZONE="America/New_York"

[root@MGGGBJPECCX09 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX09 2.6.32-754.18.2.el6.x86_64 #1 SMP Thu Jul 25 17:15:34 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep  8 03:25:18 BST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

MGGGBJPECCX10	10.133.18.37	10.5.255.37	Production
[root@MGGGBJPECCX10 tmp]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX10 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep  8 02:50:04 BST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
[root@MGGGBJPECCX01 tmp]$ cat /etc/sysconfig/clock
ZONE="America/New_York"

[root@MGGGBJPECCX10 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX10 2.6.32-754.18.2.el6.x86_64 #1 SMP Thu Jul 25 17:15:34 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep  8 03:25:18 BST 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

MGGGBJPECCX03	10.133.18.20 	10.5.255.20	Production
[root@MGGGBJPECCX03 tmp]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX03 2.6.32-754.12.1.el6.x86_64 #1 SMP Thu Mar 7 22:07:44 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Sat Sep  7 18:50:04 PDT 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
[root@MGGGBJPECCX03 tmp]$ cat /etc/sysconfig/clock
ZONE="America/New_York"

[root@MGGGBJPECCX03 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux MGGGBJPECCX03 2.6.32-754.18.2.el6.x86_64 #1 SMP Thu Jul 25 17:15:34 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sat Sep  7 19:25:18 PDT 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)


CS0318281    Meggitt PLC -- MGG    P1 - Severe    Host Reboot CRITICAL: Uptime 2 minutes (thresh 60 min)
CS0318276    Meggitt PLC -- MGG    P1 - Severe    Host Reboot CRITICAL: Uptime 4 minutes (thresh 60 min)


CS0318646    IAG GBS Limited -- IA1    P2 - Major    CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%



CS0317737    Certified IT Consultants - TMG -- CI3    P1 - Severe    Disk Utilization /sybase/BOD CRITICAL: Free 383.07MB/5.00%


Number: CS0319026
Affected CI: PN8US7LECCP3
Short description: SAP: CP3-pn8us7leccp3_CP3_00:Ins:CP3: an alert of class:System occured. Lost connection to mySAP system
PN8US7LECCP3

 10.12.255.22 and 10.12.255.23
 
 
 
 
 CS0319848    Manchester Airport Group -- MNG    P2 - Major    Processor_load_is_too_high_on_LONMAGBOB0004.imzcloud.ibmammsap.loca
 
 
 
 
 Unable to login to LONCFGCIP0005     10.69.2.36,Please assign OS team to check CS0318938
 
 
 
 CS0320177    Dixons Carphone -- CPW    CPW    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.96% (thresh 2:%)
 
 ---------------------------------------------------------------------------------------------------------------------------------
 
 9 SEPT
 
 
 CS0295355
Free_disk_space_is_less_than_10%_on_volume_/sapmnt/EEP[PROBLEM:16828841]	10.133.18.18
 to add space on /dev/mapper/eepappvg-eepsapmnt_lv
                      18G   16G  1.8G  90% /sapmnt/EEP
					  
					  
CS0310950
Please setup  nfs mounting on PBBs4hpap00 host  by execute following steps:	10.6.7.16

1. add new entry in /etc/hosts of PBBs4hpap00:
     192.168.0.136        crmdb
2. umount an existing nfs mounting :
     umount /usr/IDOC
3. remount nfs mounting  :
     mount -o vers=3 crmdb:/usr/IDOC /usr/IDOC
4. verify R/W permission under s4padm user:
     su - s4padm
     cd /usr/IDOC
     touch test 

 
 CS0326703    Publiacqua S.p.A -- PBL    P2 - Major    Processor_load_is_too_high_on_pbl-z-pag-a.imzcloud.ibmammsap.local[PROBLEM:16870321]		10.199.18.19t
 
CS0326697    Delta Airlines -- DAL    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 180.09MB/19.82% (thresh @10.01:20%)		10.4.5.156

CS0326689    IAG - British Airways -- IA2    P2 - Major    Processor_load_is_too_high_on_ia2sftpprd.imzcloud.ibmammsap.local[PROBLEM:16870304]	10.133.15.55
 
 
 
 CS0298013
 SAP-HEC-SWIVEL HEC: Permission issue from RD1/RQ1 to iA
 Please assist to check permission for below folder:
 
10.92.99.127 -->
F:\OpenText\StreamServe\Data\STRS_Spool\NFOReinstatement
10.70.110.25 -->
F:\OpenText\StreamServe\Data\STRS_Spool\NFOReinstatement
 
In AL11, we can view the test file (test.txt) created in above
directory. However, we cannot upload xml file from RD1/RQ1 going to OT
server F:\OpenText\StreamServe\Data\STRS_Spool\NFOReinstatement
 Source : 10.6.1.28 -->SVTD1SRV1 	10.6.1.28	10.92.99.127  DEV		RD1ADM
F:\OpenText\StreamServe\Data\STRS_Spool\NFOReinstatement
10.6.2.25 -->SVTQ1SRV1 	10.6.2.25	10.70.110.25	QA		RQ1ADM
F:\OpenText\StreamServe\Data\STRS_Spool\NFOReinstatement

Mounted on 10.6.1.11 & 10.6.2.11 respectively

RD1ADM & RQ1ADm

[root@sved1srv0 ibmrmalik]$ cat /etc/fstab |grep -i cifs
//10.92.99.127/STRS_Spool  /usr/sap/OpenText/STRS_Spool  cifs   credentials=/root/usercred.txt,iocharset=utf8,file_mode=0777,dir_mode=0777 0    0
//10.92.99.127/STRS_Output  /usr/sap/OpenText/STRS_Output  cifs   credentials=/root/usercred1.txt,iocharset=utf8,file_mode=0777,dir_mode=0777,_netdev 0    0

[root@sveq1srv0 ibmrmalik]# cat /etc/fstab |grep -i cifs
#//SVTQ1SRV1/STRS_Spool         /usr/sap/OpenText/STRS_Spool    cifs    username=cd1adm,password='xStream2015!',file_mode=0777,dir_mode=0777 0 0
//SVTQ1SRV1/STRS_Spool    /usr/sap/OpenText/STRS_Spool   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
 
 
 
 CS0327477    Computer Systems Integration Ltd -- CSY    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.97% (thresh 2:%)	10.197.2.20
CS0327360    Delta Airlines -- DAL    P3 - Minor    Free_disk_space_is_less_than_20%on_volume/var/log[PROBLEM:16870952]	10.4.5.156
CS0327332    Suncor Energy Inc. -- SNC    P2 - Major    Ping Availability (Service check timed out after 15.01 seconds)



CS0327805    Publiacqua S.p.A -- PBL    P2 - Major    Processor_load_is_too_high_on_pbl-z-pag-a.imzcloud.ibmammsap.local[PROBLEM:16871419]
CS0327680    Manchester Airport Group -- MNG    P1 - Severe    Zabbix_agent_on_LONMAGHAN0004.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16871249]


CS0206166
<MI8> Request for create the disk space
Tokyo
SAPHON2 	10.20.130.13	10.232.130.14

sdg                             8:96   0  200G  0 disk
sdh                             8:112  0   60G  0 disk

 vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 100G -n sap_migration_lv honappvg
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab


CS0328166    Delta Airlines -- DAL    P2 - Major    Processor_load_is_too_high_on_dltdwahwd.imzcloud.ibmammsap.local[PROBLEM:16871738]
CS0328084    Panasonic North America -- PN8    P2 - Major    Processor_load_is_too_high_on_pn8us7leccp5.imzcloud.ibmammsap.local[PROBLEM:16871642]
CS0327853    Panasonic North America -- PN4    P2 - Major    Memory Swap CRITICAL: Swap free 49.84% (thresh 50:%)	10.12.254.107


CS0328846    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization / CRITICAL: Timeout or no data available for /	10.197.0.11
CS0329113    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.03 (thresh: 16)	10.207.63.14

---------------------------------------------------------------------------------------------------------------------------------------------------------

10 SEPT

CS0334788    1    TRIO 10    MGG     MGGGBJVECCX09    Zabbix_agent_on_mgggbjveccx09.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16880375]

CS0334876
Zabbix_agent_on_MGGGBJVECCX01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16880632]


CS0334721
Zabbix_agent_on_MGGGBJVECCX02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:16880300]


CS0330288
NFS mounting  check and verification


CS0338240    IAG - British Airways -- IA2    P2 - Major    Processor_load_is_too_high_on_ia2sftpprd.imzcloud.ibmammsap.local[PROBLEM:16886929]
CS0338042    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.06 (thresh: 16)



CS0339126    Manitoba Telecom Services -- MTS    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.98% (thresh 2:%)
CS0338985    PT Anugerah Pharmindo Lestari -- PTP    P2 - Major    Processor_load_is_too_high_on_ptpkomodo.imzcloud.ibmammsap.local[PROBLEM:16887673]


dalhana-1024-14.xsportal.local
Private IP: 10.155.223.97
root QY0o6Y%qzVjVzg@




CS0336276    American Airlines -- A1A    P2 - Major    SAP HEC SWIVEL - Setup connectivity between AA SMTP serve
CS0336390    American Airlines -- A1A    P3 - Minor    Setup connectivity between AA SMTP serve




SAPHON1 	10.20.130.11	10.232.130.15
sdg                                   8:96   0  200G  0 disk
sdh                                   8:112  0   60G  0 disk


SAPHON2 	10.20.130.13	10.232.130.14


Server Type: Production                                                  *
*       Hostname: MGGGBJPECCX02                                               *
*         CFN IP: 10.5.255.19                                                 *
*         IFN IP: 10.133.18.19   
case 02468043 is opened, analysing the logs                                              *



CHG0127846	CTASK0138051
JD! snapshot pls
3:03:15 PM: svjd1srv0	10.6.1.12	A0EASG014XVM003

----------------------------------------------------------------------------------------------------------------------------------------

11 SEPT

CS0352514    TAQA Arabia -- TQA    P3 - Minor    TSM: Percentage of maximum logons: 78.50%



CS0007235    Hanon Systems -- HAN    SR    Please provide the disk usage data for May ,June and July-2019


CS0353735
 Please reset custsap ID 

 
 
 svjd1srv0	10.6.1.12	A0EASG014XVM003
 CHG0127952 CTASK0138300 snapshot
 
 
 
 CS0354171    IAG GBS Limited -- IA1    P2 - Major    Processor_load_is_too_high_on_IA1WEBDSPQAS1.imzcloud.ibmammsap.local[PROBLEM:16911582]	10.133.17.143
CS0354153    IAG GBS Limited -- IA1    P2 - Major    Lack_of_free_swap_space_on_IA1WEBDSLBHA.imzcloud.ibmammsap.local[PROBLEM:16911575]		10.133.15.33
CS0354124    Bombardier Recreational Products Inc -- BR3    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 410.97MB/19.68% (thresh @10.01:20%)	10.138.10.105



Server : SMEDIQUAQU3, 10.78.24.32
FS : /var
Related tickets :
CS0214310	Disk Utilization /var CRITICAL: Free 876.80MB/18.82% (thresh @10.01:20%)
CS0261248	Disk Utilization /var CRITICAL: Free 883.68MB/18.97% (thresh @10.01:20%)


Server : SMGRCDEVDG1, 10.78.22.48
FS : /var
Related tickets : 
CS0064074	Disk Utilization /var CRITICAL: Free 469.26MB/10.07% (thresh @10.01:20%)	10.78.22.48
CS0064760	Disk Utilization /var CRITICAL: Free 468.86MB/10.06% (thresh @10.01:20%)	10.78.22.48


Server : SMSLTDEVDK1, 10.78.22.44
FS : /var
Related tickets : 
CS0187027	Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:16670536]	10.78.22.44
CS0187043	Disk Utilization /var CRITICAL: Free 668.41MB/14.35% (thresh @10.01:20%)	10.78.22.44

Server : SMTMSBXST1, 10.78.20.13
FS : /var
Related tickets : 
CS0186423	Disk Utilization /var CRITICAL: Free 762.30MB/16.36% (thresh @10.01:20%)	10.78.20.13
CS0211152	Free_disk_space_is_less_than_20%_on_OS_volume_/var[PROBLEM:16698410]	10.78.20.13

Server : SMECCUATUE3, 10.78.26.16
FS : /var
Related tickets : 
CS0212933	Disk Utilization /var CRITICAL: Free 731.80MB/15.71% (thresh @10.01:20%)	 10.78.26.16



BS4DE0002 	10.211.8.12	
stat("/auditlogs"
10.211.8.20:/auditlogs  /auditlogs      nfs     rw,rsize=32768,vers=3,wsize=32768,hard,intr,suid,proto=tcp,bg,_netdev



BS4DX0005 	10.211.8.15
stat("/data/PI/interfaces"
10.211.8.20:/data/PI/interfaces /data/PI/interfaces     nfs     rw,rsize=32768,vers=3,wsize=32768,hard,intr,suid,proto=tcp,bg,_netdev

BS4DNG010 	10.211.8.20	172.25.192.59

----------------------------------------------------------------------------------------------------------

12 SEPT

CS0310950
NFS  mounting on S4P system
1. add new entry in /etc/hosts of PBBs4hpap00:
     192.168.0.136        crmdb
2. umount an existing nfs mounting :
     umount /usr/IDOC
3. remount nfs mounting  :
     mount -o vers=3 crmdb:/usr/IDOC /usr/IDOC
4. verify R/W permission under s4padm user:
     su - s4padm
     cd /usr/IDOC
     touch test 
	 
	 
	 
 CS0366956    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.79 (thresh: 16)    SQ-SAP-TRIO-12	10.207.63.14
 
 
 printer config
 10.207.63.19  - IFN ip 

10.170.63.25 - CFN IP


ECCTEST - hostname  
9:22:03 AM: 10.207.63.19  - IFN ip 

10.170.63.25 - CFN IP


ECCTEST - hostname 
9:22:42 AM: 

    The system prints locally if the host spool system (operating system spooler) and the spool work process of the SAP System are on the same host.

    It is irrelevant whether the printer is directly connected to the PC or whether it is a shared network printer.

    The printer must be defined at operating system level of the spool server.
 
 HP LaserJet Flow MFP E52645   test 
 
 10.136.144.66  printer ip
 
 
 
 CS0367809    Delta Airlines -- DAL    09-12-2019 08:46:36    P2 - Major    Cleared and Re-fired: MSD:URL: URL Status: URI authority not found
CS0367801    MSC Industrial Supply Co. -- MS3    09-12-2019 08:44:57    P2 - Major    Lack_of_free_swap_space_on_ms3wdcladb14.imzcloud.ibmammsap.local[PROBLEM:16926341]	10.12.6.30
CS0367755    PT Anugerah Pharmindo Lestari -- PTP    09-12-2019 08:39:08    P2 - Major    Perfdata CPU-PercentProcesorTime CRITICAL: \Processor(*)\% Processor Time = 67	10.70.30.145


CS0369832    COTY Inc. -- CTU    P3 - Minor    PR0CTUA1 (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory Consumption    CTUBOPR0APM1
CS0369737    PT Blue Bird TBK -- PBB    P2 - Major    CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%    PBBBWHPAP00
CS0369706    Manitoba Telecom Services -- MTS    P2 - Major    Free_disk_space_is_less_than_10%on_DB_volume/ARCHIVE[PROBLEM:16930042]    PRDHEC1



CS0239517,CS0240182,CS0240648,CS0240898,CS0241599

---------------------------------------------------------------------------------------------------------------------------------------------------------

16 SEPT

CS0418873    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization /sybase/FPD/sapdiag CRITICAL: Timeout or no data available for /sybase/FPD/sapdiag    AFRFIORIPRD
CS0418857    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization /sybase/FPD/sybtemp CRITICAL: Timeout or no data available for /sybase/FPD/sybtemp    AFRFIORIPRD

Case # 90875302
delta-dal09-phana-4096-03.imzcloud.ibmammsap.local		dlthpehdb4	10.143.69.160	root/EneG2lcb	IPMI CbRbTQt7QJ

dlthpehdb4:/home/ibmrmalik # uptime
 03:59am  up   1:31,  2 users,  load average: 0.85, 0.55, 0.67
dlthpehdb4:/home/ibmrmalik # last reboot
reboot   system boot  4.4.121-92.109-d Mon Sep 16 02:28 - 03:59  (01:31)

dlthpehdb4:/home/ibmrmalik # date
Mon Sep 16 04:00:51 EDT 2019

reboot   system boot  4.4.121-92.109-d Mon Sep 16 02:28 - 04:01  (01:33)

Sep 15 23:52:50 dlthpehdb4 chef-client[7424]:   * remote_file[download_ptyprocess-0.6.0.tar.gz] action create[2019-09-15T23:52:50-04:00] INFO: Processing remote                                               _file[download_ptyprocess-0.6.0.tar.gz] action create (caat::install_suse_linux                                                line 22)
Sep 15 23:52:51 dlthpehdb4 chef-client[7424]: #033[0m  * download_file[TrendMicro_Download_Deep_Security_SUSE12_Package] action download[2019-09-15T23:52:51-04:                                               00] INFO: Processing download_file[TrendMicro_Download_Deep_Security_SUSE12_Pack                                               age] action download (policy_all_deep_security::default line 78)
Sep 16 00:58:52 dlthpehdb4 chef-client[7424]:   * remote_file[download_psutil-5.4.6.tgz] action create[2019-09-16T00:58:52-04:00] INFO: Processing remote_file[d                                               ownload_psutil-5.4.6.tgz] action create (caat::install_suse_linux line 22)
Sep 16 00:58:53 dlthpehdb4 chef-client[7424]:   * remote_file[download_pexpect-4.6.0.tar.gz] action create[2019-09-16T00:58:53-04:00] INFO: Processing remote_fi                                               le[download_pexpect-4.6.0.tar.gz] action create (caat::install_suse_linux line 2                                               2)
Sep 16 00:58:53 dlthpehdb4 chef-client[7424]:   * remote_file[download_ptyprocess-0.6.0.tar.gz] action create[2019-09-16T00:58:53-04:00] INFO: Processing remote                                               _file[download_ptyprocess-0.6.0.tar.gz] action create (caat::install_suse_linux                                                line 22)
Sep 16 00:58:53 dlthpehdb4 chef-client[7424]: #033[0m  * download_file[TrendMicro_Download_Deep_Security_SUSE12_Package] action download[2019-09-16T00:58:53-04:                                               00] INFO: Processing download_file[TrendMicro_Download_Deep_Security_SUSE12_Pack                                               age] action download (policy_all_deep_security::default line 78)
Sep 16 02:02:12 dlthpehdb4 chef-client[7424]:   * remote_file[download_psutil-5.4.6.tgz] action create[2019-09-16T02:02:12-04:00] INFO: Processing remote_file[d                                               ownload_psutil-5.4.6.tgz] action create (caat::install_suse_linux line 22)
Sep 16 02:02:13 dlthpehdb4 chef-client[7424]:   * remote_file[download_pexpect-4.6.0.tar.gz] action create[2019-09-16T02:02:13-04:00] INFO: Processing remote_fi                                               le[download_pexpect-4.6.0.tar.gz] action create (caat::install_suse_linux line 2                                               2)
Sep 16 02:02:13 dlthpehdb4 chef-client[7424]:   * remote_file[download_ptyproces s-0.6.0.tar.gz] action create[2019-09-16T02:02:13-04:00] INFO: Processing remote                                               _file[download_ptyprocess-0.6.0.tar.gz] action create (caat::install_suse_linux                                                line 22)
Sep 16 02:02:14 dlthpehdb4 chef-client[7424]: #033[0m  * download_file[TrendMicro_Download_Deep_Security_SUSE12_Package] action download[2019-09-16T02:02:14-04:                                               00] INFO: Processing download_file[TrendMicro_Download_Deep_Security_SUSE12_Pack                                               age] action download (policy_all_deep_security::default line 78)
Sep 16 02:28:17 dlthpehdb4 systemd[1]: Starting Restore /run/initramfs on shutdown...
Sep 16 02:28:17 dlthpehdb4 systemd[1]: Started Restore /run/initramfs on shutdown.
Sep 16 02:28:17 dlthpehdb4 systemd[1]: Starting Update UTMP about System Boot/Shutdown...
Sep 16 02:28:17 dlthpehdb4 systemd[1]: Started Update UTMP about System Boot/Shutdown.
Sep 16 02:28:21 dlthpehdb4 kernel: [   24.034262] bond0: Enslaving eth2 as a backup interface with a down link
Sep 16 02:28:21 dlthpehdb4 kernel: [   24.436944] bond0: Enslaving eth0 as a backup interface with a down link

dlthpehdb4:/home/ibmrmalik # systemctl status pacemaker.service
â— pacemaker.service - Pacemaker High Availability Cluster Manager
   Loaded: loaded (/usr/lib/systemd/system/pacemaker.service; enabled; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:pacemakerd
           https://clusterlabs.org/pacemaker/doc/en-US/Pacemaker/1.1/html-single/Pacemaker_Explained/index.html

Sep 16 02:30:21 dlthpehdb4 systemd[1]: Dependency failed for Pacemaker High Availability Cluster Manager.
Sep 16 02:30:21 dlthpehdb4 systemd[1]: pacemaker.service: Job pacemaker.service/start failed with result 'dependency'.

Sep 16 02:28:17 dlthpehdb4 kernel: [    0.000000] Booting paravirtualized kernel on bare hardware
Sep 16 02:28:17 dlthpehdb4 kernel: [   14.621247] [Firmware Warn]: GHES: Poll interval is 0 for generic hardware error source: 4, disabled.
Sep 16 02:28:17 dlthpehdb4 kernel: [   19.032989] iTCO_wdt: unable to reset NO_REBOOT flag, device disabled by hardware/BIOS
Sep 16 02:28:17 dlthpehdb4 kernel: [   19.033040] iTCO_wdt: unable to reset NO_REBOOT flag, device disabled by hardware/BIOS



CS0422745    XP Investimentos Corretora SA -- XPI    P2 - Major    Free_disk_space_is_less_than_10%on_volume/var/log[PROBLEM:17036829]    XPISOLSMNPDA
CS0422637    The Ogilvy Group Inc -- OGY    P2 - Major    Memory Swap CRITICAL: Swap free 49.96% (thresh 50:%)    OGYSJ1029
CS0422211    The Ogilvy Group Inc -- OGY    P2 - Major    Memory Swap CRITICAL: Swap free 49.96% (thresh 50:%)    OGYSJ1029

Tsleecprddb		tata-che01-pod1-phana-6114-1.imzcloud.ibmammsap.local		Private IP: 10.162.24.194	root/T95ycYYe
CPU/RAM report since yesterday until evening today in graphical format
TSLEECPRDDB 	10.207.61.78	10.170.61.59


gkneccdevqa     10.15.81.24 , Error on root FS is causing backup failure. Request OS assistance - CS0407497
Kindly be informed that need one more mount point as  /sapmnt/auditlogs on the below server and its size will be 100GB.
[root@gkneccdevqa ibmrmalik]$ sh /var/lib/zabbix/check_rw_mounts.sh
rm: cannot remove '/sapedi/testfile': Host is down
CRITICAL |  /sapedi filesystems are read-only

[root@gkneccdevqa ibmrmalik]$ cat /etc/fstab |grep -i sapedi
//gknedpapp/sapedi      /sapedi cifs    user=ediuser,password=K{BE{sVu7?Agm[%G,ip=10.255.80.70,domain=IMZCLOUD     0 0


BS5PRDAPP1 	10.141.132.24	chennai
Kindly be informed that need one more mount point as  /sapmnt/auditlogs on the below server and its size will be 100GB.

BS5PRDAPP1 - 132.132.0.11





BS5PRDAPP1 - 132.132.0.11

lvcreate -L 100G -n auditlogs_lv backupvg
mkfs.ext2/3/4 path of lvdisplay		/dev/backupvg/auditlogs_lv
mkdir /sybase
mount
vi /etc/fstab

-------------------------------------------------------------------------------------------------

17 SEPT


CS0370047
[Request]
ã€€ãƒ»Please expand the existing disks.

[æ‹¡å¼µå¯¾è±¡]
ã€€ãƒ»/dev/sdc expand to 200GB
ã€€ãƒ»/dev/sdd expand to 100GB

[Target server]
ã€€ãƒ»SAPHON1
ã€€ãƒ»SAPHON2

SAPHON1 	10.20.130.11	10.232.130.15
SAPHON2 	10.20.130.13	10.232.130.14



CS0434405    Panasonic North America -- PN8    P3 - Minor    Directories got deleted from /interfaces


CS0434786    IAG - British Airways -- IA2    P2 - Major    Processor_load_is_too_high_on_ia2mdgdevapp.imzcloud.ibmammsap.local[PROBLEM:17052224]


https://access.redhat.com/support/cases/#/case/02468043
Meggit case



Tsleecprddb		tata-che01-pod1-phana-6114-1.imzcloud.ibmammsap.local		Private IP: 10.162.24.194	root/T95ycYYe
CPU/RAM report since yesterday until evening today in graphical format
TSLEECPRDDB 	10.207.61.78	10.170.61.59



svjd1srv0	10.6.1.12	A0EASG014XVM003	CHG0128557	CTASK0139931
svjq1srv0	10.6.2.12	A0EASG014XVM004	CHG0128558	CTASK0139926	
CSR CHG0128557 and CHG0128558


CS0435993    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization /sybase/FPD/sapdata4 CRITICAL: Timeout or no data available for /sybase/FPD/sapdata4	 10.197.0.13
CS0435668    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization /sybase/FPD/sybsystem CRITICAL: Timeout or no data available for /sybase/FPD/sybsystem
CS0435751    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization /sapmnt/FPD CRITICAL: Timeout or no data available for /sapmnt/FPD


CS0436916    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization / CRITICAL: Timeout or no data available for /    AFRS4HPRDDB	10.197.0.1
CS0436809    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization /boot CRITICAL: Timeout or no data available for /boot    AFRS4HPRDDB
CS0436677    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization /boot CRITICAL: Timeout or no data available for /boot    AFRS4HPRDDB
CS0437132    West African Cotton Company -- AFR    P1 - Severe    Disk Utilization / CRITICAL: Timeout or no data available for /    AFRS4HPRDDB



Mountpoint /sapmnt/auditlogs which you have mounted on bs5prdapp1, the same mount has to be mapped on below prod application using nfs.
BS5PRDAPP2 132.132.0.19
BS5PRDAPP3 132.132.0.24
BS5PRDAPP4 132.132.0.20
BS5PRDAPP5 132.132.0.12

BS5PRDAPP1 	10.141.132.24	132.132.0.11	NFS server
BS5PRDAPP2 	10.141.132.13	132.132.0.19
BS5PRDAPP3 	10.141.132.18	132.132.0.24
BS5PRDAPP4 	10.141.132.11	132.132.0.20
BS5PRDAPP5 	10.141.132.15	132.132.0.12


132.132.0.11://sapmnt/auditlogs /sapmnt/auditlogs nfs defaults,_netdev 0 0 

Do not create new file system for these 4 application servers.
please remove the mountpoint /sapmnt/auditlogs from these servers and then mapped using nfs


ref 201909088693 stb complaint
201909088721 new card


--------------------------------------------------------------------------------------------------------------------------

18 SEPT

TSLEECPRDDB 	10.207.61.78	10.170.61.59
sun 12am till now  cpu and mem 

sar -r -f sa16
  904  2019-09-17 14:02:48 sar -r -f sa17
  905  2019-09-17 14:03:55 sar -q -f sa16
  906  2019-09-17 14:04:12 sar -q -f sa17
05:30:01    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty


CS0449931    St. Jude Medical -- JUD    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 34.88 (thresh: 16)    JUDHDMART03	 10.196.4.14
CS0449856    Tata Steel Limited -- TTA    P2 - Major    Ping Availability CRITICAL - 10.207.63.14: rta nan, lost 100%    TSLEECQA
CS0449771    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    Free_disk_space_is_less_than_20%on_volume/var/log[PROBLEM:17071505]    PNCAPECCP	10.199.1.25
CS0449695    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 561.62MB/19.76% (thresh @10.01:20%)    PNCAPECCQ	10.199.2.15
CS0448801 - P2 - Drive-Space G critical(OK: Drive G: has 98.045GB of 0.988TB)	 10.138.10.35

CS0451936    Delta Airlines -- DAL    DAL    P1 - Severe    Disk Utilization /sapstage CRITICAL: Timeout or no data available for /sapstage
CS0451810    Delta Airlines -- DAL    DAL    P1 - Severe    Disk Utilization /tmp CRITICAL: Timeout or no data available for /tmp	10.4.5.208



svjq1srv0	10.6.2.12	A0EASG014XVM004

4:26:04 PM: JQ1
4:26:13 PM: CSR CHG0128684	CTASK0140265

----------------------------------------------------------------------------------------------------------------------------

19 SEPT

CS0370047
[Request]
ã€€ãƒ»Please expand the existing disks.

[æ‹¡å¼µå¯¾è±¡]
ã€€ãƒ»/dev/sdc expand to 200GB
ã€€ãƒ»/dev/sdd expand to 100GB

[Target server]
ã€€ãƒ»SAPHON1
ã€€ãƒ»SAPHON2

SAPHON1 	10.20.130.11	10.232.130.15
SAPHON2 	10.20.130.13	10.232.130.14


SAPHON1     10.20.130.11    10.232.130.15
sdc                                   8:32   0   64G  0 disk to 200GB
â””â”€drbd0                             147:0    0   64G  1 disk to be expanded to 200GB by Github Ticket
sdd                                   8:48   0   32G  0 disk to 100GB
â””â”€drbd1                             147:1    0   32G  0 disk to be expanded to 100GB by Github Ticket
â”œâ”€honascsvg-usr_sap_HON_ASCS01_lv 254:18   0   10G  0 lvm  /usr/sap/HON/ASCS01
â””â”€honascsvg-lv_HON_jp1            254:20   0   60G  0 lvm  /HON_jp1


SAPHON2     10.20.130.13    10.232.130.14
sdc                                    8:32   0   64G  0 disk to 200GB
â””â”€drbd0                              147:0    0   64G  0 disk to be expanded to 200GB by Github Ticket
â”œâ”€honnfsvg-export_sapmnt_HON_lv    254:19   0   20G  0 lvm  /export/sapmnt/HON
â”œâ”€honnfsvg-export_interface_HON_lv 254:20   0    1G  0 lvm  /export/interface/
â”œâ”€honnfsvg-export_3rdPartySoftware_HON_lv
â”‚                                  254:21   0    1G  0 lvm  /export/3rdPartySo
â””â”€honnfsvg-export_usr_sap_trans_lv 254:22   0   40G  0 lvm  /export/usr/sap/tr
sdd                                    8:48   0   32G  0 disk to 100GB
â””â”€drbd1                              147:1    0   32G  1 disk to be expanded to 100GB by Github Ticket





CS0192878    [MI8] Query/request about the Linux Servers
CS0251823    [MI8] Query about the HA servers
CS0252648     [MI8] Request for remote logon restriction


CHG0128796	CTASK0140562
svjd1srv0	10.6.1.12	A0EASG014XVM003
svfd1srv0	10.6.1.24	A0EASG012XVM003





[root@ADNBIDEVDB ibmrmalik]$ cat /etc/mtab |grep -i sds
146.89.140.157:/storage/library /sds nfs rw,vers=4,addr=146.89.140.157,clientaddr=10.198.201.19 0 0

[root@ADNMP1DEVDB ibmrmalik]$ cat /etc/mtab |grep -i nfs
sunrpc /var/lib/nfs/rpc_pipefs rpc_pipefs rw 0 0
146.89.140.157:/storage/library /Staging/sapsft nfs rw,vers=4,addr=146.89.140.157,clientaddr=10.198.201.20 0 0
146.89.140.30:/storage/library /storage/library nfs rw,vers=4,addr=146.89.140.30,clientaddr=10.198.201.20 0 0
146.89.141.91:/storage /storage nfs rw,vers=4,addr=146.89.141.91,clientaddr=10.198.201.20 0 0



OS team to mount this NFS in che01ammsol01.imzcloud.ibmammsap.local:/sds  3.6T  2.7T  786G  78% /sds  - on below servers
10.198.202.12  ALQ
10.198.202.11  MPQ

che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs defaults,_netdev 0 0

[root@ADNMP1QADB sds]$ cat /etc/mtab |grep -i /Staging/sapsft
146.89.140.157:/storage/library /Staging/sapsft nfs rw,vers=4,addr=146.89.140.157,clientaddr=10.198.202.11 0 0




ADNBIDEVDB    10.198.201.19  BID
ADNMP1DEVDB    10.198.201.20  MPD
we need this mount point che01ammsol01.imzcloud.ibmammsap.local:/sds  3.6T  2.7T  786G  78% /sds



TSM server : SNG01AMMTSM003 - 146.89.140.180  , ADNMP1DB        10.198.200.22



CS0466876    Panasonic North America -- PN8    P2 - Major    Processor_load_is_too_high_on_pn8us7lap1p3.imzcloud.ibmammsap.local[PROBLEM:17100394]    PN8US7LAP1P3
CS0466867    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.31 (thresh: 16)    TSLBWQADB
CS0466836    Meggitt PLC -- MGG    P2 - Major    EQJ (HANADB)|HDB_DATABASE_AVAILABILITY|Database Unavailable    MGGGBJQECCX02
CS0466821    DyStar Singapore Pte Ltd -- DYS    P2 - Major    Processor_load_is_too_high_on_dyss4apsbp12.imzcloud.ibmammsap.local[PROBLEM:17100372]    DYSS4APSBP12	10.6.11.39
CS0466806    Delta Airlines -- DAL    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 274.57MB/19.89% (thresh @10.01:20%)    DLTHBEHAP2
CS0466788    Panasonic North America -- PN4    P2 - Major    Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)    PN4US7LSMGD1
CS0466774    Delta Airlines -- DAL    P3 - Minor    Free_disk_space_is_less_than_20%on_volume/var/log[PROBLEM:17100304]    DLTHBEHAP2
	CS0466742    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)    CROSFLIEM02
	CS0466718    St. Jude Medical -- JUD    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 27.84 (thresh: 16)    JUDHDMART03	
CS0466712    Panariagroup Industrie Ceramiche SP -- PNC    P2 - Major    Perfdata CPU-PercentProcesorPrivilegedTime CRITICAL: \Processor(*)\% Privileged Time = 43    C1POP
CS0466647    DyStar Singapore Pte Ltd -- DYS    P2 - Major    Processor_load_is_too_high_on_dysciarp0200.imzcloud.ibmammsap.local[PROBLEM:17100018]    DYSCIARP0200
CS0466584    American Airlines -- A1A    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))    A1AHECPSAP01
CS0466742    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)    CROSFLIEM02


SNG01AMMSOL01 	146.89.140.158	146.89.140.157
 Your case number is: CS0873184
My case  no  is  -  CS0873190



/usr/share/zoneinfo/Asia/Bangkok


----------------------------------------------------------------------------------------------------------------------------

20 SEPT

CS0477455    St. Jude Medical -- JUD    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.36 (thresh: 16)	10.196.4.14
CS0478055    Dixons Carphone -- CPW    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.92% (thresh 2:%)	10.197.5.17


CS0478791    CKD Corporation -- CK1    CK1    P1 - Severe    Zabbix_agent_on_ckds4apqas.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17117303]    09-20-2019 12:48:08

CS0479469 AGEAS -- AGE AGESVCDMHSRV1 Disk Utilization /var/crash CRITICAL: Timeout or no data available for /var/crash P1.


CHG0127275 
HostName CFN IP IFN IP Purpose SID Function
	CLSCAD93 10.17.1.32 10.9.2.34 Development CLT App
CLSCBD94 10.17.1.33 10.9.2.31 Development CLT DB		validated
CLSFID01 10.17.1.26 10.9.2.27 Development FD1 App		validated     completed
CLSFID02 10.17.1.24 10.9.2.25 Development FD1 DB		validated	  completed 	
	CLSLTD01 10.17.1.23 10.9.2.21 Development SL1 App		validated
							CLSLTD02 10.17.1.21 10.9.2.22 Development SL2 DB
							stat("/sapmnt/SL1",
[root@clsltd02 ibmrmalik]$ cat /etc/mtab |grep -i /sapmnt/SL1
10.17.1.23:/sapmnt/SL1 /sapmnt/SL1 nfs4 rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.17.1.21,local_lock=none,addr=10.17.1.23 0 0

			
CLSMGD01 10.17.1.22 10.9.2.24 Development MG1 App		validated
CLSMGD02 10.17.1.25 10.9.2.23 Development MG2 DB		validated
CLSDWD01 10.17.1.18 10.9.2.16 Development BD1 App		validated



	CS0482153    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/lib/mysql CRITICAL: Timeout or no data available for /var/lib/mysql    AGESVCDMHSRV1	10.6.1.180
	CS0482095    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/lib/pgsql CRITICAL: Timeout or no data available for /var/lib/pgsql    AGESVCDMHSRV1
	CS0482090    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/opt/BESClient CRITICAL: Timeout or no data available for /var/opt/BESClient    AGESVCDMHSRV1
	CS0481984    AGEAS -- AGE    P1 - Severe    Disk Utilization /tmp CRITICAL: Timeout or no data available for /tmp    AGESVCDMHSRV1
CS0478109    AGEAS -- AGE    P1 - Severe    Disk Utilization /tmp CRITICAL: Timeout or no data available for /tmp    AGESVBD1HSRV1
	CS0481906    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/lib/machines CRITICAL: Timeout or no data available for /var/lib/machines    AGESVEDMHSRV1
	CS0481840    AGEAS -- AGE    P1 - Severe    Disk Utilization / CRITICAL: Timeout or no data available for /    AGESVCDMHSRV1
	CS0481839    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/crash CRITICAL: Timeout or no data available for /var/crash    AGESVCDMHSRV1
	CS0481810    AGEAS -- AGE    P1 - Severe    Disk Utilization /usr/local CRITICAL: Timeout or no data available for /usr/local    AGESVCDMHSRV1
	CS0481779    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/tmp CRITICAL: Timeout or no data available for /var/tmp    AGESVCDMHSRV1
	CS0481763    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/opt CRITICAL: Timeout or no data available for /var/opt    AGESVEDMHSRV1
	CS0481653    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/opt CRITICAL: Timeout or no data available for /var/opt    AGESVCDMHSRV1
	CS0481654    AGEAS -- AGE    P1 - Severe    Disk Utilization /srv CRITICAL: Timeout or no data available for /srv    AGESVCDMHSRV1
	CS0481600    AGEAS -- AGE    P1 - Severe    Disk Utilization / CRITICAL: Timeout or no data available for /    AGESVCDMHSRV1
	
	
	------------------------------------------------------------------------------------------------------------
	
	21 SEPT
	
	CHG0127122
	
	Host Name	CFN IP			Asset Purpose
	SPSVMPLMAPP01	10.70.111.46	Production		10.6.3.46	A0EASG014XVM045	spsvmplmapp01
[root@spsvmplmapp01 tmp]# uname -a;date;cat /etc/redhat-release
Linux spsvmplmapp01.eastwestageaslife.com 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 00:08:46 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@spsvmplmapp01 ibmrmalik]# uname -a;date;cat /etc/redhat-release
Linux spsvmplmapp01.eastwestageaslife.com 2.6.32-754.22.1.el6.x86_64 #1 SMP Fri Aug 16 11:55:16 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 01:04:10 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
-----------------------------
SPSVBPAAAPP01	10.70.111.20	Production		spsvbpaaapp01  10.6.3.20   A0EASG014XVM042
[root@spsvbpaaapp01 tmp]$ uname -a;date;cat /etc/redhat-release
Linux spsvbpaaapp01 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 00:08:46 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@spsvbpaaapp01 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux spsvbpaaapp01 2.6.32-754.22.1.el6.x86_64 #1 SMP Fri Aug 16 11:55:16 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 01:25:37 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
---------------------------------
SPSVBPABAPP01	10.70.111.18	Production		10.6.3.18	A0EASG014XVM026
[root@spsvbpabapp01 tmp]$ uname -a;date;cat /etc/redhat-release
Linux spsvbpabapp01 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 00:08:46 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@spsvbpabapp01 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux spsvbpabapp01 2.6.32-754.22.1.el6.x86_64 #1 SMP Fri Aug 16 11:55:16 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 01:04:14 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
------------------------------
SPSVBPDAASE01	10.70.111.19	Production		SPSVBPDAASE01	10.6.3.19	10.70.111.19	A0EASG014XVM027
[root@spsvbpdaase01 tmp]$ uname -a;date;cat /etc/redhat-release
Linux spsvbpdaase01 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 00:08:46 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@spsvbpdaase01 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux spsvbpdaase01 2.6.32-754.22.1.el6.x86_64 #1 SMP Fri Aug 16 11:55:16 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 01:04:17 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)
-------------------
	SPSVCPACAPP01	10.70.111.15	Production		SPSVCPACAPP01	10.6.3.15	10.70.111.15	A0EASG014XVM025
[root@spsvcpacapp01 tmp]$ uname -a;date;cat /etc/redhat-release
Linux spsvcpacapp01 2.6.32-754.14.2.el6.x86_64 #1 SMP Wed Apr 24 16:18:30 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 00:08:46 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

[root@spsvcpacapp01 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux spsvcpacapp01 2.6.32-754.22.1.el6.x86_64 #1 SMP Fri Aug 16 11:55:16 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 01:04:20 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)



yum clean all
yum check-update
yum update
uname -a to get current kernel version 
reboot
check kernel version uname -a to get updated version
Update the VMtools vmware-config-tools.pl --default
	
	
	
[root@spsvepapapp01 ibmrmalik]$ uname -a;date;cat /etc/redhat-release
Linux spsvepapapp01 2.6.32-754.22.1.el6.x86_64 #1 SMP Fri Aug 16 11:55:16 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Sep 22 02:23:45 +08 2019
Red Hat Enterprise Linux Server release 6.10 (Santiago)

---------------------------------------------------------------------------------------------------------------------

22 SEPT

CS0505747    St. Jude Medical -- JU1    P2 - Major    Free_disk_space_is_less_than_10%on_OS_volume/var[PROBLEM:17147619] 



CS0506833    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/lib/machines CRITICAL: Timeout or no data available for /var/lib/machines		10.6.1.184
CS0506782    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/spool CRITICAL: Timeout or no data available for /var/spool		10.6.1.184
CS0506771    AGEAS -- AGE    P1 - Severe    Disk Utilization /var/cache CRITICAL: Timeout or no data available for /var/cache		10.6.1.180
CS0506764    AGEAS -- AGE    P1 - Severe    Disk Utilization /sapmnt/data CRITICAL: Timeout or no data available for /sapmnt/data-exchange


CS0506781    DyStar Singapore Pte Ltd -- DYS    P1 - Severe    Disk Utilization /var/cache CRITICAL: Timeout or no data available for /var/cache    DYSS4DBSBQ20    10.6.12.38
CS0506759    DyStar Singapore Pte Ltd -- DYS    P1 - Severe    Disk Utilization /var/log CRITICAL: Timeout or no data available for /var/log    DYSS4DBSBQ20    09-21-2019 21:28:48
CS0506423    DyStar Singapore Pte Ltd -- DYS    P1 - Severe    Disk Utilization /var/lib/mailman CRITICAL: Timeout or no data available for /var/lib/mailman    DYSS4DBSBQ20    09-21-2019 20:59:18

CS0506662    Adani Enterprises Ltd. -- ADN    P1 - Severe    Disk Utilization /sapmnt/log CRITICAL: Free 26281.50MB/5.00% (thresh @0:5%)


CS0506834    Panasonic North America -- PN4    P2 - Major    Memory Swap CRITICAL: Swap free 49.96% (thresh 50:%)	10.12.254.107
CS0507372    Panasonic North America -- PN4    P2 - Major    Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)	10.12.254.107
CS0507456    Panasonic North America -- PN4    P2 - Major    Memory Swap CRITICAL: Swap free 49.97% (thresh 50:%)



CS0508005    Meggitt PLC -- MGG    P3 - Minor    NVT (HANADB)|HDB_HOST_PHYS_MEM_ALRT_1|Host Physical Memory Usage
CS0507905    Meggitt PLC -- MGG    P3 - Minor    NVJMGG (HANADB)|HDB_HOST_PHYS_MEM_ALRT_1|Host Physical Memory Usage


CS0506512    Panariagroup Industrie Ceramiche SP -- PNC    P2 - Major    Perfdata CPU-PercentProcesorPrivilegedTime CRITICAL: \Processor(*)\% Privileged Time = 58



[root@dradnmp1db ibmrmalik]$ cat /etc/mtab |grep -i sds
hkg02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.141.28,clientaddr=10.204.4.21 0 0




CHG0128535    BAU Restart :: Memory Swap CRITICAL: Swap free 49.77% (thresh 50:%) ::: SNCHAPAPD11
	CHG0128536	CTASK0140777    BAU Restart:: Drive-Space C critical ::: SNCHBIBPA16		SNCHBIBPA16 	10.73.10.52	10.72.0.52
Reboot VM & Perfrom Disk Cleanup Using Utility enclosed.  ::: Performer - OS/VM Performer
[SNCCA016BCA105] snchbibpa16/snchbibpa16-000001.vmdk

CS0509297    Suncor Energy Inc. -- SNC    P2 - Major    Uptime System-Rebooted CRITICAL: uptime: 0:3m, boot: 2019-09-22 05:39:25 (UTC)

CHG0126654    Swap Space increase on 8 Hosts  (PT1, PW1, P6W, P1D)
21-TREX-STD-NODB	        PT1	SNCHTRIPA11	       10.73.10.125	31	7	Increase Swap Space & make total to 64 GB
21-TREX-STD-NODB	        PT1	SNCHTRIPA12	       10.73.10.126	31	7	Increase Swap Space & make total to 64 GB
21-TREX-STD-NODB	        PT1	SNCHTRIPA13	       10.73.10.127	31	7	Increase Swap Space & make total to 64 GB
22-WEBDISP-STD-NODB	PW1			SNCHWDWPW11			10.73.10.106	7	7	Increase Swap Space & make total to 16 GB

22-WEBDISP-STD-NODB	PW1			SNCHWDWPW12			10.73.10.107	7	7	Increase Swap Space & make total to 16 GB	SNCHWDWPW12 	10.73.10.107	10.72.0.107
/dev/mapper/VolGroup-lv_swap 	swap                    swap    defaults        0 0
[root@snchwdwpw12 ibmrmalik]$ free -g
             total       used       free     shared    buffers     cached
Mem:             7          7          0          0          1          1
-/+ buffers/cache:          4          3
Swap:           15          0         15

22-WEBDISP-STD-NODB	P6W			SNCHBDWPW11			10.73.10.115	7	7	Increase Swap Space & make total to 16 GB	SNCHBDWPW11 	10.73.10.115	10.72.0.115
[root@snchbdwpw11 ibmrmalik]$ cat /etc/fstab |grep -i swap
/dev/mapper/VolGroup-lv_swap 	swap                    swap    defaults        0 0
[root@snchbdwpw11 ibmrmalik]$ free -g
             total       used       free     shared    buffers     cached
Mem:             7          4          2          0          0          1
-/+ buffers/cache:          3          4
Swap:           15          0         15


22-WEBDISP-STD-NODB	P6W			SNCHBDWPW51			10.73.10.116	7	7	Increase Swap Space & make total to 16 GB	SNCHBDWPW51 	10.73.10.116	10.72.0.116
/dev/mapper/VolGroup-lv_swap
[root@snchbdwpw51 ibmrmalik]$ free -g
             total       used       free     shared    buffers     cached
Mem:             7          4          3          0          0          0
-/+ buffers/cache:          2          4
Swap:           15          0         15


14-BODS-ASE	           P1D		SNCHDSBPD11	         10.73.10.54	62	7	Increase Swap space & make total 48 GB 		SNCHDSBPD11 	10.73.10.54		10.72.0.54
/dev/mapper/VolGroup-lv_swap
[root@snchdsbpd11 ibmrmalik]$ free -g
             total       used       free     shared    buffers     cached
Mem:            62         32         30          0          3         24
-/+ buffers/cache:          4         58
Swap:           47          0         47



	CHG0128528    Implement PDNS rules by CHEF team
	CHG0128532    #IBM-INTERNAL ::: HE5 HANA Instance Uninstall from Solman ( Old Install)
CHG0128593    Monthly BAU Restarts of  PE1 & DE1 for VMTools Upgrade


CS0509003    Suncor Energy Inc. -- SNC    P2 - Major    Drive-Space C critical(OK: Drive C: has 5.964GB of 59.655GB)

---------------------------------------------------------------------------------------------------------------------------------

23 SEPT

saps13db00 100.126.32.121




[root@CI2SOL ibmrmalik]$ cat /etc/mtab |grep -i sds
lon02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.140.93,clientaddr=10.5.242.17 0 0




CS0523928    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.98 (thresh: 16)    TSLEECQA
CS0523287    CMA CGM -- CMA    P2 - Major    Ruuning_out_of_available_memory_on_server_smdbsbxse1.imzcloud.ibmammsap.local[PROBLEM:17162468]    SMDBSBXSE1
CS0523218    CMA CGM -- CMA    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.92% (thresh 2:%)    SMDBSBXSE1


PEPSAPG3QDI02 | 30.64.0.98 | Predeployment | Pepsico | Dallas 13 | running on ammdal13custesx026.imzcloud.ibmammsap.local



CHG0129106 CTASK0141229
Hosts: SVJD1SRV0	A0EASG014XVM003
 & SVFD1SRV0		A0EASG012XVM003
 
 
 
 
 10.211.8.35----BS4AU2025

10.211.8.33-----BS4AU3026



CS0523659    Manchester Airport Group -- MNG    P2 - Major    Processor_load_is_too_high_on_MNGDRHAN002.imzcloud.ibmammsap.local[PROBLEM:17163200]    MNGDRHAN002


CS0526342    Manchester Airport Group -- MNG    P1 - Severe    Zabbix_agent_on_MNGDRHAN002.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17167722]


CS0370047
[Request]
ã€€ãƒ»Please expand the existing disks.

[æ‹¡å¼µå¯¾è±¡]
ã€€ãƒ»/dev/sdc expand to 200GB
ã€€ãƒ»/dev/sdd expand to 100GB

[Target server]
ã€€ãƒ»SAPHON1
ã€€ãƒ»SAPHON2

SAPHON1 	10.20.130.11	10.232.130.15
SAPHON2 	10.20.130.13	10.232.130.14


SAPHON1     10.20.130.11    10.232.130.15
sdc                                   8:32   0   64G  0 disk to 200GB
â””â”€drbd0                             147:0    0   64G  1 disk to be expanded to 200GB by Github Ticket
sdd                                   8:48   0   32G  0 disk to 100GB
â””â”€drbd1                             147:1    0   32G  0 disk to be expanded to 100GB by Github Ticket
â”œâ”€honascsvg-usr_sap_HON_ASCS01_lv 254:18   0   10G  0 lvm  /usr/sap/HON/ASCS01
â””â”€honascsvg-lv_HON_jp1            254:20   0   60G  0 lvm  /HON_jp1

sdc - SCSI 0:0:2:0
sdd - SCSI 0:0:3:0



SAPHON2     10.20.130.13    10.232.130.14
sdc                                    8:32   0   64G  0 disk to 200GB
â””â”€drbd0                              147:0    0   64G  0 disk to be expanded to 200GB by Github Ticket
â”œâ”€honnfsvg-export_sapmnt_HON_lv    254:19   0   20G  0 lvm  /export/sapmnt/HON
â”œâ”€honnfsvg-export_interface_HON_lv 254:20   0    1G  0 lvm  /export/interface/
â”œâ”€honnfsvg-export_3rdPartySoftware_HON_lv
â”‚                                  254:21   0    1G  0 lvm  /export/3rdPartySo
â””â”€honnfsvg-export_usr_sap_trans_lv 254:22   0   40G  0 lvm  /export/usr/sap/tr
sdd                                    8:48   0   32G  0 disk to 100GB
â””â”€drbd1                              147:1    0   32G  1 disk to be expanded to 100GB by Github Ticket

sdc - SCSI 0:0:2:0
sdd - SCSI 0:0:3:0





CS0526600    St. Jude Medical -- JUD    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 23.78 (thresh: 16)
CS0526814    Dixons Carphone -- CPW    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.94% (thresh 2:%)


CS0527055 
could not login to 169.55.192.114 10.143.109.103	fmsprdeifp003.fms.ibmcloud.com.. seems to be root password expired as per Sandeep Gaur





	CS0528034    Sancor Cooperativa de Seguros Ltda -- SC8        Update /etc/hosts HD1 - SMS
	CS0528191    Sancor Cooperativa de Seguros Ltda -- SC8        Update /etc/hosts HP0 - SMS
CS0528098    Sancor Cooperativa de Seguros Ltda -- SC8          Update /etc/hosts HC1 - SMS
CS0528208    Sancor Cooperativa de Seguros Ltda -- SC8        IM52 - Enable FTP and create directories
	CS0528129    Sancor Cooperativa de Seguros Ltda -- SC8          Update /etc/hosts HQ1 - SMS

Ravi Malik  k


------------------------------------------------------------------------------------------------------

24 sept


CS0536911    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 30.40 (thresh: 16)    TSLEECQA    SQ-SAP-TRIO-12
CS0537083    St. Jude Medical -- JUD    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 30.74 (thresh: 16)    JUDHDMART03    SQ-SAP-TRIO-9
CS0537031    Dilip Buildcon Limited -- DLB    P2 - Major    Processor_load_is_too_high_on_DLBQECAP01.imzcloud.ibmammsap.local[PROBLEM:17180459]    DLBQECAP01    SQ-SAP-TRIO-10





Sep 24 07:29:32 ADNMP1DB kernel: NFS: server 146.89.141.91 error: fileid changed
Sep 24 07:29:32 ADNMP1DB kernel: fsid 0:1f: expected fileid 0x2, got 0x2ee0001
Sep 24 07:29:48 ADNMP1DB goferd: [INFO][pulp.agent.ca6ec808-5dee-4956-a996-549ba2a274a4] gofer.messaging.adapter.proton.connection:100 - connecting: URL: amqps://sng01ammcaps01.imzcloud.ibmammsap.local:5647|SSL: ca: /etc/rhsm/ca/katello-default-ca.pem|key: None|certificate: /etc/pki/consumer/bundle.pem|host-validation: None
Sep 24 07:29:48 ADNMP1DB goferd: [ERROR][pulp.agent.ca6ec808-5dee-4956-a996-549ba2a274a4] gofer.messaging.adapter.proton.connection:106 - connect: proton+amqps://sng01ammcaps01.imzcloud.ibmammsap.local:5647, failed: SSL failure.
Sep 24 07:29:48 ADNMP1DB goferd: [INFO][pulp.agent.ca6ec808-5dee-4956-a996-549ba2a274a4] gofer.messaging.adapter.proton.connection:108 - retry in 106 seconds

[root@ADNMP1DB ibmrmalik]$ cat /etc/mtab |grep -i nfs
sunrpc /var/lib/nfs/rpc_pipefs rpc_pipefs rw 0 0
146.89.140.30:/storage/library /storage/library nfs rw,vers=4,addr=146.89.140.30,clientaddr=10.198.200.22 0 0
146.89.141.91:/storage /storage nfs rw,vers=4,addr=146.89.141.91,clientaddr=10.198.200.22 0 0

146.89.141.91	TOR01AMMSOL01

a2a274a4] gofer.messaging.adapter.proton.connection:106 - connect: proton+amqps://sng01ammcaps01.imzcloud.ibmammsap.local:5647, failed: SSL failure.

DAL09AMMSOL01 	146.89.140.30	146.89.140.30

mount | grep root
mount -o remount,rw /

 CS0532251 - SL-Singapore-01 - Adani Enterprises Ltd. (ADN) - IC4SAP-SL - Free_disk_space_is_less_than_5%_on_volume_/sapmnt/log
 
 
 
 CS0537138 OS Team this server is only OS support.	10.138.10.35
 
 
 
 
 CHG0127221	CTASK0136231
 CMA patching

 
	CS0539767    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539784    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539804    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539692    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539695    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539684    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539753    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539807    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539803    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539838    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539815    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539845    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
	CS0539830    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
CS0539819    CMA CGM -- CMA    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)


CS0539710    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.62 (thresh: 16)    SMTMQUAQT3
CS0539690    CMA CGM -- CMA    P2 - Major    Service master CRITICAL: 0 master processes running (thresh 1:)    SMEMDEVDM1
CS0539686    CMA CGM -- CMA    P2 - Major    Service sshd CRITICAL: 0 sshd processes running (thresh 1:)    SMECCDEVDE1
CS0539679    CMA CGM -- CMA    P2 - Major    Service crond CRITICAL: 0 crond processes running (thresh 1:)    SMEMDEVDM1
CS0539675    CMA CGM -- CMA    P2 - Major    Service sshd CRITICAL: 0 sshd processes running (thresh 1:)    SMEMDEVDM1
CS0539674    CMA CGM -- CMA    P2 - Major    Service master CRITICAL: 0 master processes running (thresh 1:)    SMECCDEVDE1
CS0539673    CMA CGM -- CMA    P2 - Major    Service crond CRITICAL: 0 crond processes running (thresh 1:)    SMECCDEVDE1
CS0539655    CMA CGM -- CMA    P2 - Major    Service master CRITICAL: 0 master processes running (thresh 1:)    SMDSDEVDO1D71
CS0539649    CMA CGM -- CMA    P2 - Major    Service sshd CRITICAL: 0 sshd processes running (thresh 1:)    SMDSDEVDO1D71
CS0539644    CMA CGM -- CMA    P2 - Major    Service crond CRITICAL: 0 crond processes running (thresh 1:)    SMDSDEVDO1D71


DNS Name	runnin on Host
EEPDEV02	ammfra02custesx30.imzcloud.ibmammsap.local
NAMSHELLFRA04	ammfra02custesx29.imzcloud.ibmammsap.local
EEPPRD04	ammfra02custesx28.imzcloud.ibmammsap.local
EEPACT04	ammfra02custesx37.imzcloud.ibmammsap.local
NAMSHELLFRA03	ammfra02custesx41.imzcloud.ibmammsap.local
NAMSHELLFRA02	ammfra02custesx24.imzcloud.ibmammsap.local
EEPACT01	ammfra02custesx29.imzcloud.ibmammsap.local
eepprd02	ammfra02custesx26.imzcloud.ibmammsap.local
EEPACT02	ammfra02custesx31.imzcloud.ibmammsap.local
EEPTST01	ammfra02custesx38.imzcloud.ibmammsap.local
eepprd01	ammfra02custesx36.imzcloud.ibmammsap.local
EEPTST02	ammfra02custesx28.imzcloud.ibmammsap.local
EEPTST04	ammfra02custesx36.imzcloud.ibmammsap.local
NAMSHELLFRA01	ammfra02custesx26.imzcloud.ibmammsap.local

/etc/vmware-tools/services.sh restart

-----------------------------------------------------------------------------------------------------------------------------

25 SEPT

CS0545483    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.26 (thresh: 16)    SMDBUATUW3
CS0545475    COTY Inc. -- CTU    P3 - Minor    PR0CTUA1 (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory Consumption    CTUBOPR0APM1
CS0545377    City Football Group 1 -- CFO    P2 - Major    Backupserver_process_is_not_running[PROBLEM:17201243]    LONCFGCGP0001
CS0539253    Delta Airlines -- DAL    P3 - Minor    Free_disk_space_is_less_than_20%on_volume/var/log[PROBLEM:17187676]    DLTHBEHAP3


CS0545469
10.1.161.14  10.6.11.14(imz)  WIndows server DYSFTPDAPRD01
SBQ CFN IP 10.1.162.34; SBD CFN IP: 10.1.162.18


CS0546060    COTY Inc. -- CTU    P3 - Minor    CTU00001 (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory Consumption    CTUBOQR4AP03
CS0545708    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.83 (thresh: 16)    SMDBUATUW3
CS0545654    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.56 (thresh: 16)    SMDBUATUW3
CS0545572    MSC Industrial Supply Co. -- MS3    P2 - Major    CPU CPU-Utilization CRITICAL: CPU Usage 98.51% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=1.49%    MS3WDCLADB13


CS0546534	 10.207.61.200 
Tata Steel Limited -- TTA
P2 - Major
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.95 (thresh: 16)


CS0546744
Tata Steel Limited -- TTA	 10.207.61.200
P2 - Major
LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.50 (thresh: 16)




ASDPRDDB-DR    10.14.20.139



CS0546744    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.50 (thresh: 16)    TSLBWPRDDB
CS0546404    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.79 (thresh: 16)    TSLBWPRDDB
CS0546399    Dixons Carphone -- CPW    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.96% (thresh 2:%)    CPWHANADEVDB



CS0547441    CMA CGM -- CMA    
P1 - Severe    Free_disk_space_is_less_than_5%on_OS_volume/var[PROBLEM:17205565]    SMSMSBXSS0
CS0547439    CMA CGM -- CMA    
P1 - Severe    Disk Utilization /var CRITICAL: Free 31.59MB/0.68% (thresh @0:5%)    SMSMSBXSS0




[root@CTUBWSB3AP01 sds]$ mount |grep -i /storage/library
146.89.140.157:/storage/library on /storage/library type nfs4 (rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.12.10.12,local_lock=none,addr=146.89.140.157)
146.89.140.30:/storage/library on /sds type nfs4 (rw,relatime,vers=4.0,rsize=8192,wsize=8192,namlen=255,hard,proto=tcp,port=0,timeo=14,retrans=2,sec=sys,clientaddr=10.12.10.12,local_lock=none,addr=146.89.140.30)


-------------------------------------------------------------------------------------------------------------------------------------------------

26 SEPT


SAPCRMDI 	10.207.61.83	10.170.61.69
 TARGET IP  10.162.127.148

 
 
 CS0553478    COTY Inc. -- CTU    P3 - Minor    QR3CTUA2 (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory Consumption    CTUBOQR3AP04
CS0552340        P3 - Minor    Disk Utilization /var/log CRITICAL: Free 175.51MB/19.31% (thresh @10.01:20%)    	10.199.18.19
CS0162342    Controladora De Negocios -- CNG    P3 - Minor    Processor_load_is_too_high_on_FMZGRCSAP03[PROBLEM:16645626]    FMZGRCSAP03	10.68.211.11	Windows
CS0553703    Delta Airlines -- DAL    P2 - Major    Disk Utilization /var/log CRITICAL: Free 126.18MB/9.80% (thresh @5.01:10%)    DLTHBEHAP3	10.4.5.163

CS0554159 Tata Steel Limited -- TTA TSLEECQA LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 25.54 (thresh: 16) P2	 10.207.63.14


CS0554537    St. Jude Medical -- JUD    
P1 - Severe    Zabbix_agent_on_judhdmart01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17224892]    JUDHDMART01
CS0554532    St. Jude Medical -- JUD    
P1 - Severe    Zabbix_agent_on_judhdmart03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17224820]    JUDHDMART03



dal13ammtsm001 - 146.89.142.204



CHG0129384 
4:52:54 PM: Task - CTASK0141960



CS0555066    Delta Airlines -- DAL    
P1 - Severe    Zabbix_agent_on_DLTHPEHP2.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17226877]    DLTHPEHP2 	10.4.5.54


CS0555190 




CS0555159    PT Anugerah Pharmindo Lestari -- PTP    
P1 - Severe    Reset Password    (empty)



-------------------------------------------------------------------------------------------------------------------------------

30 SEPT

CS0589303        P1 - Severe    Disk Utilization /var/log CRITICAL: Free 41.52MB/4.57% (thresh @0:5%)


CS0596124    Panasonic North America -- PN4    P4 - Minimal    Disk Utilization /var/log OK: Free 404.04MB/29.26% (thresh @10.01:20%)    PN4USHLMIIP1
CS0588648    Panasonic North America -- PN4    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 271.66MB/19.68% (thresh @10.01:20%)    PN4USHLMIIP1


CS0545469
10.1.161.14  10.6.11.14(imz)  WIndows server DYSFTPDAPRD01

SBQ CFN IP 10.1.162.34; DYSS4APSBQ21 	10.6.12.34	10.1.162.34
SBD CFN IP: 10.1.162.18	DYSS4APSBD41 	10.6.12.18	10.1.162.18
DYSFTPDAPRD01 	10.6.11.14	10.1.161.14


CS0605098    AGEAS -- AGE    P2 - Major    Processor_load_is_too_high_on_SVCC2SRV0.imzcloud.ibmammsap.local[PROBLEM:17271585]    SVCC2SRV0	10.6.3.101
CS0605106    AGEAS -- AGE    P2 - Major    Processor_load_is_too_high_on_SVCC1SRV0.imzcloud.ibmammsap.local[PROBLEM:17271600]    SVCC1SRV0	10.6.2.61
CS0605427    Suncor Energy Inc. -- SNC    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.15 (thresh: 16)    SNCHECAPD11	10.73.10.13
CS0607757    PT Anugerah Pharmindo Lestari -- PTP    P2 - Major    Free_disk_space_is_less_than_10%on_volume/var/log[PROBLEM:17272362]    PTPBROMO	10.70.31.16
CS0607688    PT Anugerah Pharmindo Lestari -- PTP    P2 - Major    Free_disk_space_is_less_than_10%on_volume/usr/local[PROBLEM:17272349]    PTPBROMO	10.70.31.16
CS0605582    IAG GBS Limited -- IA1    P2 - Major    Processor_load_is_too_high_on_IA1FTSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:17271756]    IA1FTSPRDAPP	10.133.15.24
CS0605914    Delta Airlines -- DAL    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.80 (thresh: 16)    DLTHQEHDB	10.4.5.32

CS0608062    Tata Steel Limited -- TTA    P4 - Minimal    LoadAverage 15 Minute Load Average OK: 15-Minute Loadavg 14.44 (thresh: 16)    TSLBWDEVDB	10.207.62.14
CS0607965    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.35 (thresh: 16)    TSLBWDEVDB


CS0609574    Tata Steel Limited -- TTA    P1 - Severe    Disk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)    SAPBOPRD


SVJD1SRV0	A0EASG014XVM003
CHG0129642	CTASK0142735


CS0613782    Tata Steel Limited -- TTA    P4 - Minimal    LoadAverage 15 Minute Load Average OK: 15-Minute Loadavg 14.18 (thresh: 16)    TSLBWPRDDB	10.207.61.200
CS0613421    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.81 (thresh: 16)    TSLEECQA
CS0613381    Tata Steel Limited -- TTA    P4 - Minimal    LoadAverage 15 Minute Load Average OK: 15-Minute Loadavg 14.34 (thresh: 16)    TSLEECQA


sdmdbquaqm1 parhana-1024-16.xsportal.local		10.127.155.111	oeiOox%yjMEHKH@
smdbquaqt1  parhana-1024-16.xsportal.local

--------------------------------------------------------------------------------------------------------------------------------------

1 Oct

CS0551964
Please create a mount  as per Github ticket 

https://github.ibm.com/CMS/BuildMigration/issues/2118

Source System:
BAPV590800
IFN IP - 10.134.4.13

Destination
The NFS share has been created, it has been currently set to allow for anonymous sign ins as long as the IP range falls within the 10.116.83.X subnet

You could mount the drive using the map network drive function and using \10.116.83.108\srv\interfaces\ as the target folder.

Alternatively you may modify your host file in Windows under %windir%\System32\drivers\etc and adding the following line to the bottom of the file

bapibmcpac01.BRENNTAG-ASIA.LOCAL 10.116.83.108





RCA
ADNMP1DB 	10.198.200.22	10.182.200.22

Rajendra Kumar (TRM)  @Ravi Malik (3.X OS Suppport) when was the goferd service was restarted ? could you please provide the timeline

Ravi Malik  540  2019-09-24 13:31:03 /etc/init.d/goferd restart





CS0622741    Panasonic North America -- PN8    P2 - Major    Processor_load_is_too_high_on_pn8us7lap1p4.imzcloud.ibmammsap.local[PROBLEM:17288956]    PN8US7LAP1P4
CS0622529    Panasonic North America -- PN8    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.91 (thresh: 16)    PN8US7LECCP4



JQ1 snapshot pls
12:11:41 PM: svjq1srv0	10.6.2.12	A0EASG014XVM004

12:11:47 PM: CSR CHG0129795  CTASK0143244
12:11:53 PM: CSR is at 1PM



CS0624400
Free_disk_space_is_less_than_10%_on_volume_/sapmnt/DEC[PROBLEM:17295086]
extend teh FS by 10GB
DLBDECAP01



CS0422496 ---------Chef_Client_is_not_running_on_sapapp19.imzcloud.ibmammsap.local[PROBLEM:17036566]
CS0422495 ---------Chef_Client_is_not_running_on_sapapp23.imzcloud.ibmammsap.local[PROBLEM:17036575]
[root@tsleecprddb ibmrmalik]$ grep -i "chef run complete" /var/log/chef/client.log |tail -2
[2019-10-02T04:40:42+05:30] INFO: Chef Run complete in 2753.234419299 seconds
[2019-10-02T06:15:15+05:30] INFO: Chef Run complete in 1960.41878072 seconds


CS0421975 ---------Chef_Client_is_not_running_on_tsleecprddb.imzcloud.ibmammsap.local[PROBLEM:17035955]
CS0422432 ---------Chef_Client_is_not_running_on_sapapp20.imzcloud.ibmammsap.local[PROBLEM:17036433]


------------------------------------------------------------------------------------------------------------------------------

2 Oct

CS0628367    1    TRIo 11    TQA    N/A    AV Notification : VM's are not reporting to Trend  DSM manager
hostname: BW-DEV
IFN:      10.7.2.13
BW-Dev 	A0FHDE014XVM004 	10.7.2.13 	10.201.0.13 	(Decomm 1-326563964)




please change VM name for the following three VMs as the systems were rebuilt with a different hostname:

previous VM name New VM name running on
Pepsapg2qdi02 pepsapg1xdi02 ammdal13custesx019
Pepsapg2qdi01 pepsapg1xdi01 ammdal13custesx011
Pepsapg2qdi00 pepsapg1xdi00 ammdal13custesx026




CS0626287
Mount file system /sapexp in S42
Hello, we need that file system /sapexp shared on server apfs4qqas1 be mounted in server apfs42tas

The mount should be in the same way that apfs4ddas

APFS42TAS 	10.15.2.79	10.221.17.86
APFS4QQAS1 	10.15.2.33	10.221.17.34

APFS4DDAS 	10.15.2.37	10.221.17.17


[root@apfs4qqas1 ibmrmalik]$ df -h /sapexp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/s4qappvg-s4qsapexp_lv
                       40G  1.7G   36G   5% /sapexp
					   
					   
[root@apfs4ddas ibmrmalik]$ df -h /sapexp
Filesystem            Size  Used Avail Use% Mounted on
10.221.17.34:/sapexp   40G  1.7G   36G   5% /sapexp

[root@apfs4ddas ibmrmalik]$ cat /etc/fstab |grep -i /sapexp
10.221.17.34:/sapexp    /sapexp   nfs   defaults   0  0



CS0630452  Bumrungrad Hospital Plc -- BUM   Processor_load_is_too_high_on_bumsapwebd01t.imzcloud.ibmammsap.local[PROBLEM:17305963]  P2

CS0630964    PT Blue Bird TBK -- PBB        P2 - Major    Processor_load_is_too_high_on_PBBbwhpap00.imzcloud.ibmammsap.local[PROBLEM:17307315]    SQ-SAP-TRIO-11
CS0630766    St. Jude Medical -- JUD        P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 25.87 (thresh: 16)    SQ-SAP-TRIO-9
CS0630733    Delta Airlines -- DAL        P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))    SQ-SAP-TRIO-11	10.4.5.28 
CS0630713    American Airlines -- A1A    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))    SQ-SAP-TRIO-10


-------------------------------------------------------------------------------------------------------------------------------------------------

3 Oct

10-03-2019 06:30:00
10-03-2019 15:00:00
CHG0129520



CS0635470    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Service Request    P2 - Major    New        PN4 - System release to users - DB2 and OS support required



The system setting for timezone right now is on EST. Since we are in the PH, we need this set at UTC+8 (PH standard time)
MMPS4APDEV 	100.126.49.54	10.34.7.249
MMPS4DBDEV 	100.126.49.59	10.34.7.254



sapdms  10.207.61.23
HANACLDCON      10.207.61.185
CRMTREXPRD      10.207.61.180



CS0637471    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.10 (thresh: 16)    TSLBWPRDDB
CS0637367    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 26.76 (thresh: 16)    TSLEECQA


CHG0129992	CTASK0143785
JD1 snapshot pls 
3:25:26 PM: svjd1srv0	10.6.1.12	A0EASG014XVM003
-----------------------------------------------------------------------------------------------------------------------------------------------------

4 Oct

CHG0129532
Please deploy above Q419-patches to the following <<Linux>> servers.
Host Name	CFN IP	Asset Purpose
WKFQI1AP01	10.3.80.12	QA
WKFQI1AP02	10.3.80.28	QA
WKFQI1DB01	10.3.80.23	QA
WKFQL1AP01	10.3.80.29	QA
WKFQL1DB01	10.3.80.37	QA
WKFQP1AP01	10.3.80.24	QA
WKFQP1AP02	10.3.80.48	QA
WKFQP1DB01	10.3.80.32	QA
WKFQR1AP01	10.3.80.42	QA
WKFQR1AP02	10.3.80.53	QA
WKFQW1WD01 10.3.80.88  QA

10.3.80.42
WKFDR1AP01 	10.139.100.100	10.3.80.216
WKFQR1AP01 	10.139.100.92	10.3.80.42
WKFQP1AP01 	10.139.100.87	10.3.80.24


CS0643403   Suncor Energy Inc. -- SNC   LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.38 (thresh: 16)   P2


CS0643500    Tata Steel Limited -- TTA    P3 - Minor    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.09 (thresh: 16)    SQ-SAP-TRIO-12
CS0643115    Tata Steel Limited -- TTA    P3 - Minor    Disk Utilization /usr/sap/PRD CRITICAL: Free 4965.55MB/12.97% (thresh @10.01:20%)    SQ-SAP-TRIO-12


CS0644570    Tata Steel Limited -- TTA    P3 - Minor    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 23.29 (thresh: 16)    TSLEECQA
CS0644502    Tata Steel Limited -- TTA    P3 - Minor    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.65 (thresh: 16)    TSLEECQA


CS0638343

----------------------------------------------------------------------------------------------------------------------------------------

6 Oct

CHG0129927--> CTASK0143590
1. Wait for SAP's engineer task finish and information that all taks have been completed
2. Restart the following servers:

London02	
dcghanaprdap1 10.197.5.14		DONE
[root@dcghanaprdap1 ibmrmalik]$ cat /etc/fstab |grep -i nfs
10.197.3.16:/usr/sap/trans      /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    0       0

dcghanaprdap2 10.197.5.15	DONE
[root@dcghanaprdap2 ibmrmalik]$ cat /etc/fstab |grep nfs
10.197.5.14:/sapmnt/PSF         /sapmnt/PSF     nfs     defaults,nfsvers=3     0 0
10.197.3.16:/usr/sap/trans      /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    0       0
10.197.2.14:/interface/PSF         /interface/PSF     nfs     defaults,nfsvers=3      0 0

DCGHANAPRDAP3 10.197.5.16
[root@dcghanaprdap3 ibmrmalik]$ cat /etc/fstab |grep -i nfs
10.197.5.14:/sapmnt/PSF         /sapmnt/PSF     nfs     defaults,nfsvers=3      0 0
10.197.3.16:/usr/sap/trans      /usr/sap/trans  nfs     rw,hard,intr,rsize=32768,wsize=32768    0       0
10.197.2.14:/interface/PSF         /interface/PSF     nfs     defaults,nfsvers=3      0 0


3. Validate the system at OS level (especially, make sure that all fstab entries are mounted)
4. Inform the SAP engineer to continue its tasks



CS0655801    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P3 - Minor    Open        Free_disk_space_is_less_than_20%on_volume/usr/sap/PRD[PROBLEM:17351862]    SQ-SAP-TRIO-12
CS0655865    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P3 - Minor    New        Lack_of_free_swap_space_on_sapapp20.imzcloud.ibmammsap.local[PROBLEM:17351949]    SQ-SAP-TRIO-12
CS0655649    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Memory Swap CRITICAL: Swap free 49.38% (thresh 50:%)    SQ-SAP-TRIO-12
CS0654813    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P3 - Minor    New        Processor_load_is_too_high_on_biprdapp1.imzcloud.ibmammsap.local[PROBLEM:17350614]    SQ-SAP-TRIO-12




CHG0128572	CTASK0139969	COMPLETED
Please deploy above Q419-patches to the following <<WIN>> servers.

Host Name	CFN IP	Asset Purpose
MS3ARCHDEV01	172.17.154.57	Development	 	10.12.6.57	172.17.154.57
MS3ICC01	172.17.154.72	Development	10.12.6.72	172.17.154.72



WDC patching	CHG0128568

MS3WDCLAPP01	172.17.154.12	Development 	
MS3WDCADBSD1	172.17.154.66	Development 
MS3WDCAPPSD1	172.17.154.65	Development 
MS3WDCLADB03B	172.17.154.48	Development 	172.17.154.73
MSCVERTEX01	172.17.154.59	Development


CS0655799    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        ITM Agent Offline: sapepqa:UA
CS0656635    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P3 - Minor    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.06 (thresh: 16)



CS0656953    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P3 - Minor    New        Disk Utilization /var CRITICAL: Free 613.94MB/9.53% (thresh @5.01:10%)    SQ-SAP-TRIO-12
CS0656895    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P3 - Minor    New        Disk Utilization /var CRITICAL: Free 815.23MB/12.65% (thresh @10.01:20%)    SQ-SAP-TRIO-12
CS0656935    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P3 - Minor    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 49.24 (thresh: 16)    SQ-SAP-TRIO-12


CS0638343-mapping task Nic
SBQ CFN IP 10.1.162.34; DYSS4APSBQ21 	10.6.12.34	10.1.162.34
SBD CFN IP: 10.1.162.18	DYSS4APSBD41 	10.6.12.18	10.1.162.18
DYSFTPDAPRD01 	10.6.11.14	10.1.161.14

--------------------------------------------------------------------------------------------------------------------------------------

7 Oct

pn4us7leccp1     10.12.254.14
pn4us7lewmp1    10.12.254.20

file system /GoLiveBackups  on 10.12.254.125 server




CS0662243    PT Anugerah Pharmindo Lestari -- PTP    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/var/log[PROBLEM:17361440]
CS0662236    PT Anugerah Pharmindo Lestari -- PTP    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/usr/local[PROBLEM:17361441]


CS0662953    Tata Steel Limited -- TTA    P3 - Minor    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.71 (thresh: 16)    TSLBWPRDDB
CS0662940    Tata Steel Limited -- TTA    P3 - Minor    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 56.97 (thresh: 16)    TSLBWQADB


CS0663835    PT Anugerah Pharmindo Lestari -- PTP    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/usr/local[PROBLEM:17363469]    PTPBROMO
CS0663797    PT Anugerah Pharmindo Lestari -- PTP    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/var/log[PROBLEM:17363395]    PTPBROMO

-------------------------------------------------------------------------------------------------------------------------------------------------------------

8 Oct


Server role/SAPSID	Hostname	IFN IP (IBM)
ALD                             ADNAELDEVDB	10.198.201.18	snghana-1024-18.xsportal.local
BID                               ADNBIDEVDB	10.198.201.19	snghana-1024-18.xsportal.local
MPD                            ADNMP1DEVDB	10.198.201.20	snghana-1024-18.xsportal.local


CS0668413    1    TRIO 10    ADM    ADMESCTXTQ1    Drive-Space X critical(OK: Drive X: has 4.996MB of 12GB)

Issue is with monitoring setup of the pagefile as it is set to allocate the total disk for page file. The page file memory used is very low.
Initial size of the paging file should be 1.5 times of the paging file and max should be double of the initial size. Since the paging is not set as per the Microsoft standards, it is 100% 
Since the paging is configured in such a way to use up the total allocated paging file, it is 100%. Recommendation is to either extend the X drive managing pagefile or reduce the max size of virtual memory to be max upto 79% of the X drive configured as whatever 
size is configured for virtual memory, it will show up as that much used X drive as the monitoring is being done as the disk usage .

==========================
CS0668297    1    TRIO 10    ADM    ADMDECWTSQZ25    Drive-Space X critical(OK: Drive X: has 5.75MB of 48GB)
==========================
CS0668363    1    TRIO 10    ADM    ADMESCTXTQ2    Drive-Space X critical(OK: Drive X: has 5MB of 12GB)
==========================
CS0668359    1    TRIO 10    ADM    ADMSTG02    Drive-Space X critical(OK: Drive X: has 5MB of 12GB)
==========================
CS0668356    1    TRIO 10    ADM    ADMESCDMSD1    Drive-Space X critical(OK: Drive X: has 5.266MB of 24GB)
==========================
	CS0668347    1    TRIO 10    ADM    ADMESCBIZQ1    Drive-Space X critical(OK: Drive X: has 5.266MB of 24GB)	Node: admescbizq1 NodeAlias: 10.71.81.14 paging fiel is not used, its system managed

CS0668307    1    TRIO 10    ADM    ADMESCSYBD1    Drive-Space X critical(OK: Drive X: has 5.266MB of 24GB)

CS0668290    ADM Europe B.V. -- ADM    P1 - Severe    Drive-Space X critical(OK: Drive X: has 5.266MB of 24GB) 



CS0669741    PT Anugerah Pharmindo Lestari -- PTP    P2 - Major    Processor_load_is_too_high_on_ptpbromo.imzcloud.ibmammsap.local[PROBLEM:17375211] 


CS0669965    Tata Steel Limited -- TTA    P3 - Minor    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.27 (thresh: 16)


CHG0130295	CTASK0144684
snapshot
SVJD1SRV0     A0EASG014XVM003



SBD CFN IP: 10.1.162.18	DYSS4APSBD41 	10.6.12.18	10.1.162.18
DYSFTPDAPRD01 	10.6.11.14	10.1.161.14


-----------------------------------------------------------------------------------------------------------------------------------------

9 Oct

CS0676894   Suncor Energy Inc. -- SNC   SNCQC1_26_snchcraqa11_GUI|005056BF37E51EE99B9AA440E84B067B|Toronto Scripts Alerts   P1
CS0676897   Suncor Energy Inc. -- SNC   SNCQC1_26_snchcraqa13_GUI|005056BF37E51EE99B9AA440E84B067B|Toronto Scripts Alerts   P1


CS0677081    AGEAS -- AGE    P3 - Minor    Drive-Space F critical(OK: Drive F: has 38.917GB of 259.531GB)    SPSVOPLTAPP01
CS0676561    IAG GBS Limited -- IA1    P3 - Minor    Disk Utilization /opentext_backup CRITICAL: Free 27433.98MB/19.79% (thresh @10.01:20%)    IA1NFSPRDAPP

------------------------------------------------------------------------------------------------------------------------------------------

10 Oct

CS0645985    2    TRIO 10    CKD    CKDPOPRD    NFS mount setting from CKDPOPRD onto CKDS4A1PRD and CKDS4A2PRD
CKDS4A1PRD 	10.20.21.59	10.15.21.62
[root@ckds4a1prd /]# df | grep if
ssapp-ckd-ep1:/export/if                                 20961280    1617920   19343360   8% /if
/dev/mapper/ep1globalvg-export_if_lv                     20961280    1618936   19342344   8% /export/if
10.15.21.76:/if/flag_erp                                   999424       1024     929792   1% /if/flag


CKDS4A2PRD 	10.20.21.62	10.15.21.66
[root@ckds4a2prd /]# df | grep if
ssapp-ckd-ep1:/export/if                      20961280    1617920   19343360   8% /if
10.15.21.76:/if/flag_erp                        999424       1024     929792   1% /if/flag


CKDPOPRD 	10.20.21.68	10.15.21.76
[root@ckdpoprd if_old280917]# df | grep if
/dev/mapper/pp1archvg-if_flag_erp_lv                999320       1284     929224   1% /if/flag_erp
/dev/mapper/pp1othervg-if_old280917_lv             3030800     280536    2576596  10% /if_old280917

Need it to be like
[root@ckdpoqas if]# df | grep if
/dev/mapper/pq1appvg-lv_if                    15718400    7819912    7898488  50% /if
/dev/mapper/pq1appvg-if_flag_erp_lv             999320       1284     929224   1% /if/flag_erp

1. Please create a new directory "/if/flag_erp" onto a new filesystem of 1GB on CKDPOPRD.

2. Please mount /if/flag_erp of CKDPOPRD onto "/if/flag" of CKDS4A1PRD and onto "/if/flag" of CKDS4A2PRD

3. Set the permission for user pq1adm as writable and readable for "/if/flag" (where /if/flag_erp of CKDPOPRD is mounted) of CKDS4A1PRD and CKDS4A2PRD.

4. Please confirm that the commands and  the outputs be as follows:

[root@CKDPOPRD ~]# df | grep flagâ€¨/dev/mapper/pq1appvg-if_flag_erp_lv nnnnnn nnnn nnnnnn n% /if/flag_erp

[root@CKDS4A1PRD ~]# df | grep flagâ€¨10.15.21.76:/if/flag_erp nnnnnn nnnn nnnnnn n% /if/flag

[root@CKDS4A2PRD ~]# df | grep flagâ€¨10.15.21.76:/if/flag_erp nnnnnn nnnn nnnnnn n% /if/flag



[ibmhkimoto@ckdpoqas ~]$ df | grep if
/dev/mapper/pq1appvg-lv_if 15718400 7817352 7901048 50% /if
/dev/mapper/pq1appvg-if_flag_erp_lv 999320 1284 929224 1% /if/flag_erp

/dev/pq1appvg/lv_if     /if     xfs     _netdev,defaults        1       2
/dev/mapper/pq1appvg-if_flag_erp_lv /if/flag_erp ext4       defaults        1       2
[root@ckdpoqas if]#



CTUBWQB0DB01	10.65.162.249

coty-wdc04-phana-4096-4.imzcloud.ibmammsap.local 
8:04:38 AM: Details from Remote Managment tab
IPMI 
MANAGMENT IP - 10.65.11.18
X7PGgjWK3f



CS0684378
Kindly mount the below File system on host BS5SBXAPP â€“ IP 132.133.0.16.
BS5SBXAPP 	10.141.133.16	132.133.0.16 	
Chennai

sbxappvg   1   1   0 wz--n- 1004.00g 954.00g


File System - Size (GB)

/sybase - 6GB       sybase_lv	/dev/sbxappvg/sybase_lv
/sybase/BFD - 200GB				mkfs.ext4 /dev/sbxappvg/bfd_lv
/sybase/BFD/sapdiag -  10GB		mkfs.ext4 /dev/sbxappvg/sapdiag_lv
/sybase/BFD/sapdata_2 - 30GB	mkfs.ext4 /dev/sbxappvg/sapdata2_lv
/sybase/BFD/saplog_1 - 60GB		mkfs.ext4 /dev/sbxappvg/saplog1_lv
/sybase/BFD/sybsecurity - 10GB	mkfs.ext4 /dev/sbxappvg/sybsecurity_lv
/sybase/BFD/sybtemp	- 10GB		mkfs.ext4 /dev/sbxappvg/sybtemp_lv
/sybase/BFD/sapdata_1 - 100GB	mkfs.ext4 /dev/sbxappvg/sapdata1_lv
/sybase/BFD/sybsystem - 5GB		mkfs.ext4 /dev/sbxappvg/sybsystem_lv
/sybase/BFD/saptemp	- 10GB		mkfs.ext4 /dev/sbxappvg/saptemp_lv
/sapmnt/BFD - 20GB				mkfs.ext4 /dev/sbxappvg/sapmnt_bfd_lv
/usr/sap - 50GB					mkfs.ext4 /dev/sbxappvg/sap_lv
/swdump - 50GB					mkfs.ext4 /dev/sbxappvg/swdump_lv
/usr/sap/trans - 5GB			mkfs.ext4 /dev/sbxappvg/trans_lv


lvcreate -L 6G -n sybase_lv sbxappvg
mkfs.ext2/3/4 path of lvdisplay		/dev/backupvg/auditlogs_lv
mkdir /sybase
mount
vi /etc/fstab


lvcreate -L 5G -n trans_lv sbxappvg

[root@bs5sbxapp ibmrmalik]# df -h /usr/sap/trans
Filesystem                     Size  Used Avail Use% Mounted on
/dev/mapper/sbxappvg-trans_lv   50G   52M   47G   1% /usr/sap/trans

/usr/sap/trans - 5GB

-------------------------------------------------------------------------------------------------------------------------------------------------------------------

14 Oct

CS0716668    COTY Inc. -- CTU    P3 - Minor    CTU00001 (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory Consumption    CTUBOQR4AP03
CS0716624    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))    SVVD1SRV0	
CS0716554    Bombardier Recreational Products Inc -- BR3    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_C:[PROBLEM:17431492]    BR3PMIGA01


CS0717747    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.60 (thresh: 16)    SMDBUATUW3

CS0718228    COTY Inc. -- CTU    P3 - Minor    Free_disk_space_is_less_than_20%on_volume/usr/local[PROBLEM:17434057]    CTUBWQB3DB01
CS0718222    St. Jude Medical -- JU1    P2 - Major    Processor_load_is_too_high_on_sjmqbdba01.imzcloud.ibmammsap.local[PROBLEM:17434054]    SJMQBDBA01
CS0718220    COTY Inc. -- CTU    P3 - Minor    Free_disk_space_is_less_than_20%on_volume/var/log[PROBLEM:17434023]    CTUBWQB3DB01
CS0718067    Panariagroup Industrie Ceramiche SP -- PNC    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 71.75 (thresh: 16)    PNC1DBBWSBX

CS0718545    Panasonic North America -- PN8    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.46 (thresh: 16)    PN8US7LDBCP4


------------------------------------------------------------------------------------------------------------------------------------------------------------------

15 Oct


CS0724632    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.30 (thresh: 16)    TSLBWQADB	10.207.63.20

CS0724597    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.90 (thresh: 16)    TSLBWQADB


CS0725128 


CS0725117    ADM Europe B.V. -- ADM    P2 - Major    Uptime System-Rebooted CRITICAL: uptime: 0:2m, boot: 2019-10-15 07:33:18 


dalhana-1024-52.xsportal.local



CSR # CHG0130868 CTASK0146177	VM Snap shot for host - SVJD1SRV0- can you pls take VM snap shot for SVJD1SRV0   A0EASG014XVM003




CS0689011	
10/11/19 00:30:30 ANS1076E The specified directory path '/usr/sap/trans' could not be found.
/dev/sbxappvg/trans_lv /usr/sap/trans ext4 defaults 1 2



CS0725865    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))    SVVQ1SRV0



Ravi Malik --------------------------------------->151 - 180


CS0726814    IAG GBS Limited -- IA1    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.97% (thresh 2:%)    IA1S4HPRDDBDR	10.199.15.200

----------------------------------------------------------------------------------------------------------------------------------------------------------------------

16 Oct


 CS0730642    Panasonic North America -- PN8    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 38.79 (thresh: 16)    PN8US7LECCD5
 
 
 CS0716890
 Would like to request to mount FTP interface folders to S/4 HANA SBP on all 4 App servers same as SBD (DYSS4APSBD41) and SBQ (DYSS4APSBQ21).  All mount points will need to point to SBP (hostnames below)  folders.
DYSS4APSBP01
DYSS4APSBP02
DYSS4APSBP11
DYSS4APSBP12




CS0734003    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.26 (thresh: 16)    SMDBUATUW3
CS0733796    St. Jude Medical -- JUD    P3 - Minor    Drive_maked_as_BAD_on_host_judhdmart03.imzcloud.ibmammsap.local[PROBLEM:17448630]    JUDHDMART03


CS0735060 Tata Steel Limited -- TTA LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.99 (thresh: 16) TSLEECQA P2
 
 
 
 CS0734165 Panasonic North America -- PN5 Memory Swap CRITICAL: Swap free 49.70% (thresh 50:%) PENAD15SL P2.
 
  CS0729270    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 760.80MB/19.97% (thresh @10.01:20%)    PNCAPECCP1
  
  
CS0735363    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    FS_is_read_only_on_pncapeccq.imzcloud.ibmammsap.local[PROBLEM:17450090]    PNCAPECCQ
/mnt/sapexchange
//10.254.201.40/sapexchange  /mnt/sapexchange cifs sec=ntlm,credentials=/root/.cifs,uid=20200,gid=3050

 Error                                                           x
      x Internal error. Please report a bug report with logs.           x
      x Run save_y2logs to get complete logs.                           x
      x Details: Wrong number of columns in line 11                     x
      x Caller:  /usr/share/YaST2/lib/yast2/etc_fstab.rb:482:in `parse'


CS0735296    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    FS_is_read_only_on_pncapeccp1.imzcloud.ibmammsap.local[PROBLEM:17450058]    PNCAPECCP1
/mnt/sapexchange

//10.254.201.40/SAPEXCHANGE /mnt/sapexchange  cifs  username=YSRVSAPEC,password=EC_SAP00,uid=20000,gid=3050



CS0735253    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    FS_is_read_only_on_pncapeccp.imzcloud.ibmammsap.local[PROBLEM:17450003]    PNCAPECCP
/mnt/sapexchange
//10.254.201.40/SAPEXCHANGE /mnt/sapexchange 


CS0735181    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    FS_is_read_only_on_pncapeccd.imzcloud.ibmammsap.local[PROBLEM:17449805]    PNCAPECCD
CRITICAL |  /mnt/sapexchange
//10.254.201.40/SAPEXCHANGE     /mnt/sapexchange 


CS0735156    Panariagroup Industrie Ceramiche SP -- PNC    P3 - Minor    Free_disk_space_is_less_than_20%_on_volume_C:[PROBLEM:17449797]    C1BOP

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

17 Oct

 CS0716890
 Would like to request to mount FTP interface folders to S/4 HANA SBP on all 4 App servers same as SBD (DYSS4APSBD41) and SBQ (DYSS4APSBQ21).  All mount points will need to point to SBP (hostnames below)  folders.
DYSS4APSBP01	10.6.11.38	10.1.161.34
[root@dyss4apsbp01 ibmrmalik]# mount -a
Couldn't chdir to /usr/sap/s4hana/SBP/PIL/DN/archive: No such file or directory
Couldn't chdir to /usr/sap/s4hana/SBP/PIL/IB: No such file or directory
Couldn't chdir to /usr/sap/s4hana/SBP/PIL/IB/archive: No such file or directory
Couldn't chdir to /usr/sap/s4hana/SBP/PIL/IB/GR: No such file or directory
Couldn't chdir to /usr/sap/s4hana/SBP/PIL/IB/GR/archive: No such file or directory
Couldn't chdir to /usr/sap/s4hana/SBP/PIL/IB/INV: No such file or directory
Couldn't chdir to /usr/sap/s4hana/SBP/PIL/IB/INV/archive: No such file or directory
error 2 (No such file or directory) opening credential file /etc/Dystar_world
error 2 (No such file or directory) opening credential file /etc/Dystar_world
error 2 (No such file or directory) opening credential file /etc/Dystar_world
error 2 (No such file or directory) opening credential file /etc/Dystar_world
error 2 (No such file or directory) opening credential file /etc/Dystar_world
error 2 (No such file or directory) opening credential file /etc/Dystar_world
mount: mount point credentials=/etc/Dystar_credentials,uid=20000,gid=3050,sec=ntlm,_netdev does not exist


DYSS4APSBP02	10.6.11.42	10.1.161.36
DYSS4APSBP11	10.6.11.31	10.1.161.37
DYSS4APSBP12	10.6.11.39	10.1.161.35

[root@dyss4apsbp01 ibmrmalik]# id sbpadm
uid=20000(sbpadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)

DYSFTPDAPRD01 	10.6.11.14	10.1.161.14




CS0743385    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.03 (thresh: 16)    TSLEECQA
CS0743121    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.77 (thresh: 16)    TSLEECQA



CS0744234    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.88 (thresh: 16)    TSLBWPRDDB
CS0743997    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.20 (thresh: 16)    TSLBWPRDDB
CS0743897    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.06 (thresh: 16)    TSLBWPRDDB

---------------------------------------------------------------------------------------------------------------------------------------------------------------

20 Oct

CS0770637    Tata Steel Limited -- TTA    P2 - Major    Processor_load_is_too_high_on_sapboprd.imzcloud.ibmammsap.local[PROBLEM:17506804]	10.207.61.205
CS0770434    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.99 (thresh: 16)
CS0770404    IAG GBS Limited -- IA1    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.89% (thresh 2:%)
CS0769962    Suncor Energy Inc. -- SNC    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.85 (thresh: 16)
CS0769842    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.38 (thresh: 16)


fixed  br3thcias20



CS0769438    Panasonic North America -- PN4    P2 - Major    Service corosync.service CRITICAL: corosync.service is inactive (dead) since Sat 2019-10-19 22:27:16 EDT: 45s ago
CS0769426    Panasonic North America -- PN4    P2 - Major    Resources CRM CRITICAL: Unmanaged resources found: vcenter-fencing-pn4us7leccp1c(stonith:fence_vmware_soap):Stopped (unmanaged) vcenter-fencing-pn4ushleccp1c(st
CS0769419    Panasonic North America -- PN4    P2 - Major    Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)
CS0769414    Panasonic North America -- PN4    P2 - Major    Service pacemaker.service CRITICAL: pacemaker.service is inactive (dead) since Sat 2019-10-19 22:27:15 EDT: 47s ago
CS0769413    Panasonic North America -- PN4    P2 - Major    Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)
CS0769411    Panasonic North America -- PN4    P2 - Major    Service Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)
CS0769409    Panasonic North America -- PN4    P2 - Major    Service Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)
CS0769226    Panasonic North America -- PN4    P2 - Major    Resources CRM CRITICAL: Unmanaged resources found: vcenter-fencing-pn4us7leccp1(stonith:fence_vmware_soap):Started pn4ushleccp1 (unmanaged) vcenter-fencing-pn4u


CS0770051	LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp		10.12.255.17
CS0771297	LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp.
CS0771886    Panasonic North America -- PN4    P2 - Major    Log PaceMaker-crmd Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-20-03-48-37 for details.
CS0771760    Panasonic North America -- PN4    P2 - Major    Log PaceMaker-crmd Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-20-03-33-36 for details.
CS0772509    Panasonic North America -- PN4    P2 - Major    Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7leccp1c(stonith:fence_vmware_soap):Stopped ip-cp1_ers10(ocf::heartbeat:IPaddr2)
CS0772590    Panasonic North America -- PN4    P1 - Severe    Host Reboot CRITICAL: Uptime 6 minutes (thresh 60 min)
CS0772653    Panasonic North America -- PN4    P1 - Severe    Host Reboot CRITICAL: Uptime 9 minutes (thresh 60 min)

CS0773263    Dixons Carphone -- CPW    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.93% (thresh 2:%)

CS0772089



CS0771109    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 197.039MB (200MB)), \??\X:\pagefile.sys 1.713GB (40GB), total 1.906GB (40.195GB)
CS0770985    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS0770983    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS0769262    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 198.535MB (200MB), \??\X:\pagefile.sys 1.727GB (40GB), total 1.921GB (40.195GB)
CS0773913    American Airlines -- A1A    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.984MB (200MB), total 199.984MB (200MB))


10.12.254.17	PN4US7LECCP1C 	10.12.254.17	10.142.41.17
10.12.254.18	PN4USHLECCP1C 	10.12.254.18	10.142.41.18



CS0774562 
-------------------------------------------------------------------------------------------------------------------------------


21 Oct

CS0780343    Tata Steel Limited -- TTA    P2 - Major    Processor_load_is_too_high_on_jbdaix4.imzcloud.ibmammsap.local[PROBLEM:17514962]    JBDAIX4



CS0226187
CS0354458
CS0480641


NAMSHELLFRA05
AGISERVER3


CS0780856    Panasonic North America -- PN4    P3 - Minor    TSM: wdc04ammtsm001.ibmammsap.local ANR2578W Schedule @1424 in domain NFL_N_FIL for node PN4_PN4US7LEWMQ1_FIL has missed its scheduled start up window.~    PN4US7LEWMQ1
10.136.40.58:/usr/sap/trans     /usr/sap/trans  nfs     defaults



CS0780855    Panasonic North America -- PN4    P3 - Minor    TSM: wdc04ammtsm001.ibmammsap.local ANR2578W Schedule @1424 in domain NFL_N_FIL for node PN4_PN4US7LEWMQ1_FIL has missed its scheduled start up window.~    PN4US7LEWMQ1
CS0780854    Panasonic North America -- PN4    P3 - Minor    TSM: wdc04ammtsm001.ibmammsap.local ANR2578W Schedule @1424 in domain NFL_N_FIL for node PN4_PN4US7LEWMQ1_FIL has missed its scheduled start up window.~    PN4US7LEWMQ1


CS0422722 - OS
CS0141016 - OS
CS0312554 - OS
CS0330288 - OS
CS0132398 - OS
CS0355193 - OS

CS0131142
CS0130494
CS0311996

------------------------------------------------------------------------------------------------------------------------------------------------

22 Oct

CS0775210    Panasonic North America -- PN4    P2 - Major    LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp.
CS0774061    Panasonic North America -- PN4    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 269.01MB/19.48% (thresh @10.01:20%)

CS0788509    COTY Inc. -- CTU    P3 - Minor    SAP-HEC-SWIVEL:Copy file from QR2 to PR0[00608670/2019]


S/4 HANA - EP1 (CI)-SuSE Cluster Node1	ckds4a1prd	10.20.21.59	10.15.21.62
S/4 HANA - EP1 (CI)-SuSE Cluster Node2	ckds4a2prd	10.20.21.62	10.15.21.66

-----------------------------------------------------------------------------------------------------------------------------------------------

23 Oct

CS0795737    Tata Steel Limited -- TTA    P1 - Severe    Zabbix_agent_on_tslbwqadb.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17538235]    TSLBWQADB
/bwqa_data



DCGHANAPRDAP1 	10.197.5.14	10.197.2.14


CS0796404    Panasonic North America -- PN8    P3 - Minor    Disk Utilization /var CRITICAL: Free 853.88MB/15.26% (thresh @10.01:20%)    PN8US7LECCQ3
CS0796403    Panasonic North America -- PN8    P3 - Minor    Disk Utilization /var CRITICAL: Free 855.60MB/15.29% (thresh @10.01:20%)    PN8US7LECCQ3


CS0120422 - pls add 25 GB to /usr/sap/APP
PDL Approved to add 25 GB to /usr/sap/APP
/dev/mapper/appappvg-usrsapAPP_lv
125G 95G 24G 81% /usr/sap/APP


CS0796514    IAG GBS Limited -- IA1    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.79% (thresh 2:%)    IA1S4HPRDDBDR
CS0796443    IAG GBS Limited -- IA1    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.42% (thresh 2:%)    IA1S4HPRDDBDR




TOR
TWYSAPXC1APP1 	10.137.10.24	10.184.0.24


CS0796941    Hanon Systems -- HAN    P1 - Severe    Zabbix_agent_on_handvh4psrv03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17538912]    HANDVH4PSRV03





os1o2cad	10.135.7.43  on OSRAM GmbH	Customer	Frankfurt

3:51:15 PM: running on : ammpar01custesx001.imzcloud.ibmammsap.local




atlcacr	
ATLCACR 	10.15.32.23	10.38.32.167   DAL13




CS0797521    Tata Steel Limited -- TTA    P2 - Major    Processor_load_is_too_high_on_jbdaix4.imzcloud.ibmammsap.local[PROBLEM:17539204]    JBDAIX4


CS0797762    COTY Inc. -- CTU    P1 - Severe    Zabbix_agent_on_CTUBWQB0DB01.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17539296]    CTUBWQB0DB01



pn4us7lmiiqp    10.12.254.153


CS0798220    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.66 (thresh: 16)    TSLEECQA

-----------------------------------------------------------------------------------------------------------------------------------

24 Oct

CS0805334    Panasonic North America -- PN8    P3 - Minor    Disk Utilization /var CRITICAL: Free 841.35MB/15.03% (thresh @10.01:20%)    PN8US7LECCQ3
CS0805237    Panasonic North America -- PN8    P3 - Minor    Disk Utilization /var CRITICAL: Free 848.31MB/15.16% (thresh @10.01:20%)    PN8US7LECCQ3

CS0735152 - Free_disk_space_is_less_than_10%_on_volume_/usr


CS0805345    COTY Inc. -- CTU    P3 - Minor    QR0CTUA1 (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory Consumption    CTUBOQR0AP03

CS0806032 CMA CGM -- CMA Disk Utilization /housekeeping CRITICAL: Free 6149.22MB/4.99% (thresh @0:5%) SMEMUATUM3 P1.

ECCDB0PRD 	10.198.2.142	172.28.28.142
ECCDB0QAS 	10.198.2.71	172.28.28.71



CHG0131721	CTASK0148245
svjd1srv0	10.6.1.12	A0EASG014XVM003



CS0807270    Tata Steel Limited -- TTA    P2 - Major    Processor_load_is_too_high_on_biprdapp1.imzcloud.ibmammsap.local[PROBLEM:17545470]    BIPRDAPP1
CS0806762    Tata Steel Limited -- TTA    P3 - Minor    Disk Utilization /tmp CRITICAL: Free 2432.41MB/19.77% (thresh @10.01:20%)    JBDAIX4

--------------------------------------------------------------------------------------------------------------------------------------------

28 Oct


CS0849900    AGEAS -- AGE    P1 - Severe    Disk Utilization /sapmnt/log /usr/local/ncpa/plugins/cmas_check_diskfree.sh: fork: retry: Resource temporarily unavailable



CS0849425    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS0849268    American Airlines -- A1A    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 192.668MB (200MB), total 192.668MB (200MB))


CS0849789    Egyptian Refining Company -- EGR    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 175.79MB/19.35% (thresh @10.01:20%)


CS0850724    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.23


CS0835540    Tata Steel Limited -- TTA    P2 - Major    Disk Utilization /tmp CRITICAL: Free 1472.70MB/9.70% (thresh @5.01:10%)
CS0829959    Tata Steel Limited -- TTA    P3 - Minor    Disk Utilization /tmp CRITICAL: Free 2914.72MB/19.20% (thresh @10.01:20%)

CS0831330    Tata Steel Limited -- TTA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTAR3DEV- KB0010973

CS0839514    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.37 (thresh: 16)
CS0841728    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 28.80 (thresh: 16)


--------------------------------------------------------------------------------------------------------------------------------------------------

29 Oct


CS0860208    DyStar Singapore Pte Ltd -- DYS    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.05 (thresh: 16) 

CS0647836, 	10.6.1.184
CS0648662, 	10.6.1.184 	
CS0650202	10.6.1.184
CS0649128	10.6.1.184 
CS0650440	10.6.1.184 
CS0655034	10.6.1.184
CS0655365	10.6.1.184
CS0656673	10.6.1.184
CS0657025	10.6.1.184
CS0658492	10.6.1.184
CS0658627	10.6.1.184
CS0660663	10.6.1.184
CS0662196 	10.6.1.184 


CS0860424    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-stonith-ng Found 184 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-29-00-24-05 for details.	10.138.13.9 



CS0860315    Controladora De Negocios -- CNG    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.68.210.30
CS0860518    Controladora De Negocios -- CNG    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS0860511    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.68.210.30 


CS0860341    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 197.301MB (200MB)), \??\X:\pagefile.sys 2.396GB (40GB), total 2.589GB (40.195GB)

CS0860903    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 28.47 (thresh: 16)
CS0860864    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.57 (thresh: 16)


JQ1 snapshot pls 
svjq1srv0	10.6.2.12	A0EASG014XVM004
CSR CHG0132070	CTASK0149184

---------------------------------------------------------------------------------------------------------------------------

30 Oct

A0D9UK014XVM051	LONCFGCIP0005



CHG0130003
MTS-MON01-NON POD Apply Latest Q419 Patches on Linux Servers.
Please deploy above Q419-patches to the following <<Linux>> servers.
Host Name	CFN IP	Asset Purpose
SOLNMGRDEV	10.60.6.44	Development
R3DEVEP	10.60.6.45	Development
R3DEVAPP	10.60.6.41	Development
	R3DEV	10.60.6.40	Development		HANA
MTSBODSDEV01	10.60.6.46	Development
	DMARTDEV01	10.60.6.48	Development	HANA

KevinBlair	ANDRESJIMENEZ DEL CASTILLO
DPE:ANDRESJIMENEZ DEL CASTILLO <jimenezc@cr.ibm.com>	

PDL:KevinBlair <kblair@us.ibm.com>	


DPE
Leonard Curry  Mobile number:	
1-202-816-9981

Office email:	
curryleo@us.ibm.com

Job title:	
Delivery Partner Executive (DPE) - Client Experience - Americas


CS0870114    PT Anugerah Pharmindo Lestari -- PTP    PTP    PTP IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Free_disk_space_is_less_than_5%on_volume/var/log[PROBLEM:17590590]    SQ-SAP-TRIO-11


CS0870149    PT Anugerah Pharmindo Lestari -- PTP    PTP    PTP IC4SAP-SL SAP LOB    Incident    P1 - Severe    New        Free_disk_space_is_less_than_5%on_volume/usr/local[PROBLEM:17590593]    SQ-SAP-TRIO-11


CS0871571    PT Anugerah Pharmindo Lestari -- PTP    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/usr/local[PROBLEM:17592032]    PTPBROMO


CS0871795    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /opt CRITICAL: Free 5676.65MB/18.70% (thresh @10.01:20%)    PTPBROMO
CS0871794    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /var/spool CRITICAL: Free 5676.65MB/18.70% (thresh @10.01:20%)    PTPBROMO
CS0871792    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /usr/local CRITICAL: Free 5679.80MB/18.71% (thresh @10.01:20%)    PTPBROMO
CS0871791    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /tmp CRITICAL: Free 5674.87MB/18.69% (thresh @10.01:20%)    PTPBROMO
CS0871790    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /srv CRITICAL: Free 5679.80MB/18.71% (thresh @10.01:20%)    PTPBROMO
CS0871769    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /var/lib/mysql CRITICAL: Free 5820.63MB/19.17% (thresh @10.01:20%)    PTPBROMO
CS0871768    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /var/crash CRITICAL: Free 5820.63MB/19.17% (thresh @10.01:20%)    PTPBROMO
CS0871765    PT Anugerah Pharmindo Lestari -- PTP    P3 - Minor    Disk Utilization /var/opt/BESClient CRITICAL: Free 5820.63MB/19.17% (thresh @10.01:20%)    PTPBROMO
--------------------------------------------------------------------------------------------------------------------------------------

31 Oct


Server - SID                                                     Hostname       IFN IP              CFN IP
S/4 HANA - EP2 - HANA Node1  - Master    ckds4d1poc    10.20.21.58    10.15.21.60
S/4 HANA - EP2 - HANA Node2 - Standby    ckds4d2poc    10.20.21.56    10.15.21.61

Ticket details -
CS0796179
SAP01 CK1 10/23/19 07:17 AM ckds4d1poc - Log PaceMaker-crmd Found 16
errors. See
/usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-23-16-10-54
for details.
CS0796468 SAP01 CK1 10/23/19 07:56 AM ckds4d1poc - Log
PaceMaker-crmd Found 16 errors. See
/usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-23-16-40-57
for details.


CS0881511    Panasonic North America -- PN4    P2 - Major    Memory Swap CRITICAL: Swap free 48.04% (thresh 50:%)    PN4US7LSMGD1



bumsaps4p01p 	10.134.14.7	10.156.1.7	
bumsaps4p02p	10.134.14.8	10.156.1.9	




dcghanaprdap1	10.197.5.14) 	10.197.5.14	  

-------------------------------------------------------------------------------------------------------------------
1st Nov


CS0885922    Celulosa Arauco Y Constitucion S.A. -- APF    P1 - Severe    Host Reboot CRITICAL: Uptime 3 minutes (thresh 60 min)
CS0885817    Celulosa Arauco Y Constitucion S.A. -- APF    P1 - Severe    Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)

CS0883365



crm_mon -1Afr

To put  cluster  in  maintenance  mode  do  ==> crm configure property maintenance-mode=true

crm resource cleanup mountfs-inter
crm resource cleanup <error component found in the error in above command>

crm resource cleanup vcenter-fencing-bumsaps4p01p 

eg for the error below:

Failed Actions:
* vcenter-fencing-bumsappop01p_monitor_600000 on bumsappop02p 'unknown error' (1): call=392, status=Error, exitreason='',
    last-rc-change='Fri Oct  4 03:21:07 2019', queued=0ms, exec=5825ms

cleanup by using 
crm resource cleanup vcenter-fencing-bumsappop01p

zypper up <package>

To remove  cluster  from  maintenance  mode  do  ==> crm configure property maintenance-mode=false



CS0889264    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-20-41-33 for details.	10.138.13.16 
CS0889618    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-21-36-39 for details.	10.138.13.16 
CS0889317    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-20-51-35 for details.
CS0889386    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-21-06-37 for details.
CS0889680    Suncor Energy Inc. -- SNC    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.01 (thresh: 16)

CS0890106    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-23-11-49 for details.
CS0890701    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-00-39-40 for details.
CS0891016    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 24 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-01-24-44 for details.
CS0889947    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-22-36-46 for details.
CS0890503    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-00-11-52 for details.
CS0891076    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-stonith-ng Found 56 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-01-39-47 for details.
CS0890172    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 24 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-23-21-51 for details.
CS0890783    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 32 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-00-49-41 for details.
CS0890865    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 24 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-01-09-43 for details.
CS0890681    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-00-29-42 for details.
CS0889804    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-10-31-22-16-47 for details.
CS0891075    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 53 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-01-39-47 for details.
CS0891117    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-stonith-ng Found 56 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-01-43-13 for details.
CS0891123    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 5 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-01-01-43-13 for details.


CS0890010    Hanon Systems -- HAN    P1 - Severe    Zabbix_agent_on_handvh4psrv02.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17608097]
CS0890047    Hanon Systems -- HAN    P1 - Severe    Zabbix_agent_on_handvh4psrv03.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17608127]
CS0890017    Hanon Systems -- HAN    P1 - Severe    Zabbix_agent_on_handvh4psrv04.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:17608096]


CS0724316 - MMP: 1 vCPU to be removed from ADS Server 
MMPADSDEV	TOK
10.34.7.252
100.126.49.61

before
[root@mmpadsdev ibmrmalik]# lscpu | grep -E '^Thread|^Core|^Socket|^CPU\('
CPU(s):                2
Thread(s) per core:    1
Core(s) per socket:    1
Socket(s):             2

after
[root@mmpadsdev ibmrmalik]# lscpu | grep -E '^Thread|^Core|^Socket|^CPU\('
CPU(s):                1
Thread(s) per core:    1
Core(s) per socket:    1
Socket(s):             1


CS0884726    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 36.19 (thresh: 16)
CS0865437    Tata Steel Limited -- TTA    P2 - Major    Memory Swap CRITICAL: Swap free 48.56% (thresh 50:%)
CS0865736    Tata Steel Limited -- TTA    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTAR3DEV- KB0010973



SBD (DYSS4APSBD41) and SBQ (DYSS4APSBQ21).  All mount points will need to point to SBP (hostnames below)  folders.
DYSS4APSBP01	10.6.11.38	10.1.161.34	
DYSS4APSBP02	10.6.11.42	10.1.161.36
DYSS4APSBP11	10.6.11.31	10.1.161.37	
DYSS4APSBP12 	10.6.11.39	10.1.161.35
//10.150.21.221/Upload/ITInventory/SBP/Scrap/error      /usr/sap/s4hana/SBP/ITInventory/Scrap/error     cifs credentials=/etc/Dystar_world,vers=3.0
	
DYSS4APSBQ21	10.6.12.34	10.1.162.34
//10.1.161.14/Dystar-FTP/LocalUser/ChRobinson/SBQ/Outbound/error        /usr/sap/s4hana/SBQ/ChRobinson/Outbound/error   cifs credentials=/etc/Dystar_credentials,uid=20210,gid=3050,sec=ntlm,_netdev 0 0	


-------------------------------------------------------------------------------------------------------------------------------

3 Nov


CHG0130557 -- 11-03-2019 08:00:00	Frankfurt
C1POP	10.126.71.70	Production	10.199.1.70	10.126.71.70		A0DSDE012XVM006
C1DC03	10.126.71.81	Production	10.199.1.81	10.126.71.81		A0DSDE012XVM008
Mahesh Naik



CHG0131729



BES
sm9h182172006	10.135.224.46	10.139.224.75	done
sm9l182172006	10.135.224.55	10.139.224.197	done
SM9H182172004	10.135.224.18	10.139.224.57	done
clsltd01    done



CS0913673    CMA CGM -- CMA    P1 - Severe    Free_disk_space_is_less_than_5%on_OS_volume/var

CS0913669    CMA CGM -- CMA    P2 - Major    Free_disk_space_is_less_than_10%on_OS_volume/var



CS0917847    IAG GBS Limited -- IA1    P2 - Major    Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:17622023]	10.133.15.25 
CS0917541    IAG GBS Limited -- IA1    P2 - Major    Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:17621868]
CS0917496    IAG GBS Limited -- IA1    P2 - Major    Processor_load_is_too_high_on_IA1NFSPRDAPP.imzcloud.ibmammsap.local[PROBLEM:17621843]



CS0917529    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.62 (thresh: 16)  10.207.62.14 
CS0917427    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.62 (thresh: 16)
CS0915806    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.33 (thresh: 16) 10.207.61.200 




conspeccapp    10.16.1.105
conspeccdbp    10.16.1.110


sap09-con



CS0919136    Bumrungrad Hospital Plc -- BUM    P2 - Major    Processor_load_is_too_high_on_bumsapwebd01t.imzcloud.ibmammsap.local[PROBLEM:17622140]	10.134.15.7 
CS0919007    Bumrungrad Hospital Plc -- BUM    P2 - Major    Processor_load_is_too_high_on_bumsapwebd01t.imzcloud.ibmammsap.local[PROBLEM:17622140]	10.134.15.7
CS0918901    Bumrungrad Hospital Plc -- BUM    P2 - Major    Processor_load_is_too_high_on_bumsapwebd01t.imzcloud.ibmammsap.local[PROBLEM:17622140]	10.134.15.7 

---------------------------------------------------------------------------------------------------------------------------------

4 Nov


CS0938417    MSC Industrial Supply Co. -- MS3    P2 - Major    Processor_load_is_too_high_on_ms3wdcladb13.imzcloud.ibmammsap.local[PROBLEM:17627416]
CS0937605    DyStar Singapore Pte Ltd -- DYS    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.76 (thresh: 16)
CS0937395    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.70 (thresh: 16)


bapv321100	10.134.4.15	10.8.216.17	
NFS server 10.116.83.108


CS0940083    COTY Inc. -- CTU    P2 - Major    Processor_load_is_too_high_on_ctuwdprdap02.imzcloud.ibmammsap.local[PROBLEM:17627834]	10.12.12.14 
CS0938509    Hanon Systems -- HAN    P2 - Major    Processor_load_is_too_high_on_handvsptsrv01.imzcloud.ibmammsap.local[PROBLEM:17627524]	10.15.193.19 
CS0938582    MSC Industrial Supply Co. -- MS3    P2 - Major    Processor_load_is_too_high_on_ms3wdcladb13.imzcloud.ibmammsap.local[PROBLEM:17627562]	10.12.6.29 
CS0938724    MSC Industrial Supply Co. -- MS3    P2 - Major    Processor_load_is_too_high_on_ms3wdcladb13.imzcloud.ibmammsap.local[PROBLEM:17627584]
CS0939789    Suncor Energy Inc. -- SNC    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.33 (thresh: 16)	10.73.12.36 
CS0940079    Suncor Energy Inc. -- SNC    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.33 (thresh: 16)	10.73.12.36 
CS0939910    Suncor Energy Inc. -- SNC    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.33 (thresh: 16)	10.73.12.36 


CS0942490    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.70 (thresh: 16)	10.207.61.205 
CS0942070    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.07 (thresh: 16)	10.207.61.200 

CS0942234    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.26 (thresh: 16)	10.207.61.200 


S0930440    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 33.29 (thresh: 16)    TSLEECQA
CS0932758    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.26 (thresh: 16)    TSLBWPRDDB	10.207.61.200
CS0934095    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.07 (thresh: 16)    TSLBWPRDDB	10.207.61.200
CS0934463    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.26 (thresh: 16)    TSLBWPRDDB	10.207.61.200

-------------------------------------------------------------------------------------------------------------------------

5 Nov


CS0851398
- Size, Used, Avail, Use% for each FS
- Size, Free for each Disk - VG

VMs:
HLTTST1	10.20.131.13	
HLTHON1	10.20.130.12
SAPTST1	10.20.131.12	
SAPKAI1	10.20.131.11
SAPHON2	10.20.130.13	
SAPHON1	10.20.130.11	
SAPSOL2	10.20.130.31	
SAP-DB1	10.20.130.21
SAP-DB2	10.20.130.16	


SBD (DYSS4APSBD41) and SBQ (DYSS4APSBQ21).  All mount points will need to point to SBP (hostnames below)  folders.
DYSS4APSBP01	10.6.11.38	10.1.161.34	
DYSS4APSBP02	10.6.11.42	10.1.161.36
DYSS4APSBP11	10.6.11.31	10.1.161.37	
DYSS4APSBP12 	10.6.11.39	10.1.161.35

DYSS4APSBQ21	10.6.12.34	10.1.162.34




//10.150.21.221/Upload/ITInventory/SBP/Scrap/archive    /usr/sap/s4hana/SBP/ITInventory/Scrap/archive   cifs credentials=/etc/Dystar_world,vers=3.0



//10.150.21.221/Upload/ITInventory/SBQ/Upload/error             /usr/sap/s4hana/SBQ/ITInventory/Upload/error            cifs credentials=/etc/Dystar_world,vers=3.0



JD1 snapshot pls 

svjd1srv0	10.6.1.12	A0EASG014XVM003
CSR CHG0132616	CTASK0150501 

------------------------------------------------------------------------------------------------------------------

6 Nov


dcghanaprdap1



CS0972052    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-05-23-20-19 for details.	10.138.13.19 

Failed Actions:
* rsc_SAPHana_PGT_HDB02_start_0 on br3pgtsdb45 'not running' (7): call=58, status=complete, exitreason='',
    last-rc-change='Tue Nov  5 13:21:49 2019', queued=1ms, exec=3834ms
* rsc_SAPHana_PGT_HDB02_monitor_61000 on br3pgtsdb46 'not running' (7): call=66, status=complete, exitreason='',
    last-rc-change='Tue Nov  5 13:08:42 2019', queued=0ms, exec=5345ms

br3pgtsdb45 br3pgtsdb46

BR3PGTSDB45	10.138.13.17	
BR3PGTSDB46	10.138.13.19	


CS0971964    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-crmd Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-05-23-10-14 for details.


CS0972655    COTY Inc. -- CTU    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 45.53 (thresh: 16)


monhana-1024-1.xsportal.local 

could you login to SL and take snapshot of R3QAT	10.60.6.42	QA 

and mtsdmartqas01 

these two are vhana 

10.140.48.168 is the private IP 
I am not able to proceed after that VPN

----------------------------------------------------------------------------------------------------------------

9 Nov


CHG0132783

HC1HOECCHAAPQ	10.10.80.83	QA
10.211.80.83	10.10.80.83
Dallas13

[root@HC1HOECCHAAPQ tmp]$ uname -a;date;cat /etc/os-release
Linux HC1HOECCHAAPQ 4.4.74-92.38-default #1 SMP Tue Sep 12 19:43:46 UTC 2017 (545c055) x86_64 x86_64 x86_64 GNU/Linux
Fri Nov  8 22:22:28 -03 2019
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"

[root@HC1HOECCHAAPQ ibmrmalik]$ uname -a;date;cat /etc/os-release
Linux HC1HOECCHAAPQ 4.4.121-92.120-default #1 SMP Tue Aug 20 21:40:50 UTC 2019 (30a8591) x86_64 x86_64 x86_64 GNU/Linux
Fri Nov  8 21:19:04 EST 2019
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"


                                        3.2G     0  3.2G   0% /run/user/17875
[root@HC1HOECCHAAPQ tmp]$ cat /etc/fstab |grep -i nfs
#10.10.80.76:/usr/sap/trans     /usr/sap/trans  nfs     default
[root@HC1HOECCHAAPQ tmp]$ cat /etc/fstab |grep -i cifs

[root@HC1HOECCHAAPQ tmp]$ sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
OK: No read-only file systems found


[root@HC1HOECCHAAPQ tmp]$ cat /etc/sysconfig/clock
TIMEZONE="America/New_York"
DEFAULT_TIMEZONE="US/Eastern"
[root@HC1HOECCHAAPQ tmp]$ date
Fri Nov  8 22:31:23 -03 2019

[root@HC1HOECCHAAPQ ibmrmalik]$ cat /etc/sysconfig/clock
TIMEZONE="America/New_York"
DEFAULT_TIMEZONE="US/Eastern"
[root@HC1HOECCHAAPQ ibmrmalik]$ date
Fri Nov  8 21:21:01 EST 2019







CS1015506
COTY Inc. -- CTU
P1 - Severe
Disk Utilization /usr/sap/QR3 CRITICAL: Free 1980.37MB/4.40% (thresh @0:5%)	10.12.10.110 

CS1015572
COTY Inc. -- CTU
P1 - Severe
Disk Utilization /usr/sap/QR3/FRS CRITICAL: Free 1779.78MB/4.65% (thresh @0:5%)

CS1015637
COTY Inc. -- CTU
P1 - Severe
Free_disk_space_is_less_than_5%on_volume/usr/sap/QR3[PROBLEM:17662735]



CS1017198    COTY Inc. -- CTU    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/usr/sap/QR3[PROBLEM:17663115]
CS1017146    COTY Inc. -- CTU    P1 - Severe    Free_disk_space_is_less_than_5%on_volume/usr/sap/QR3[PROBLEM:17663123]


CS1018420
reboot
sapboprd -->10.207.61.205
sapbowapp ---> 10.207.61.73

SAPBOWAPP	10.207.61.73	
SAPBOPRD	10.207.61.205	



CS1013317    COTY Inc. -- CTU    P1 - Severe    (Received during suppression) Host Reboot CRITICAL: Uptime 4 minutes (thresh 60 min)	10.12.10.72 
CS1013270    COTY Inc. -- CTU    P1 - Severe    (Received during suppression) Host Reboot CRITICAL: Uptime 4 minutes (thresh 60 min)	10.12.10.46 
CS1013211    COTY Inc. -- CTU    P1 - Severe    (Received during suppression) Host Reboot CRITICAL: Uptime 4 minutes (thresh 60 min)	10.12.10.48 
CS1013346    COTY Inc. -- CTU    P1 - Severe    (Received during suppression) Host Reboot CRITICAL: Uptime 5 minutes (thresh 60 min)	10.12.10.49 
CS1013292    COTY Inc. -- CTU    P1 - Severe    (Received during suppression) Host Reboot CRITICAL: Uptime 4 minutes (thresh 60 min)


------------------------------------------------------------------------------------------------------------------------------

12 Nov

https://gts-cmas.slack.com/archives/CJZCKJ7AR   sapc2-ci3
ci3s4hanaqa
SofLayer case -- > CS1231364
ci3s4hanaqa / 10.210.1.8 - database server
ci3s4hanaqaa / 10.210.1.14  - application server

server ci3s4hanaqa / 10.210.1.8     , resides on parhana-1024-25.xsportal.local ,  SL Case - CS1231364    Operating system can't boot - kernel panic




CS1047301    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.42 (thresh: 16)



CS1046292    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.51 (thresh: 16)
10.207.61.200


CS1047241
A. V33  --BAPV330900 	10.134.3.7	10.134.3.7	10.8.217.13	

-   change home directory of v33_sftp_user to /home/v33_sftp_user (similar to V32, V59 BAPV590800). It's current home directory is /usr/sap/interfaces/V33
-   change mode of directory /usr/sap/interfaces/V33 to 755
-   change owner of directory /usr/sap/interfaces/V33 to v33_sftp_user
-     r+w permission for all for the following files in /usr/sap/interfaces:
V33/cib/ob/Archive/SG_CAI_1241_GIRO_08112019_150226.pgp

Last request is for me to do tar backup on V33 directory so I can overwrite them with the files from PAC


B. V59  -- BAPV590800 	10.134.4.13	10.134.4.13	10.8.216.14	

-   change password of v59_sftp_user and email to me	Sftp#123
-   r+w permission for all for the following files in /usr/sap/interfaces:
V59/boa/ob/Archive/20191014_095009_SG_BOA_1266_TT_14102019_093535.pgp
V59/boa/ob/Archive/20191014_101008_IN_BOA_1246_TT_14102019_100147.pgp
V59/boa/ob/Archive/20191008_115009_SG_BOA_1241_TT_08102019_105915.pgp1
V59/boa/ob/Archive/20191010_201009_IN_BOA_1246_TT_09102019_094548.pgp1
V59/cib/ob/Archive/SG_CAI_1241_TT_08102019_111923.pgp



nohup kill 110444; sleep 2; usermod -d /home/v33_sftp_user v33_sftp_user &

/home/v33_sftp_user

v59_sftp_user:x:54719:3050::/home/v33_sftp_user:/bin/bash

grep v33_sftp_user /etc/passwd | cut -d ":" -f6


CS1048930    COTY Inc. -- CTU    P2 - Major    Ping Availability CRITICAL - 10.12.10.92: rta nan, lost 100%
CS1048864    COTY Inc. -- CTU    P2 - Major    Ping Availability CRITICAL - 10.12.10.92: rta nan, lost 100%


CS1048887    Delta Airlines -- DAL    P2 - Major    ITM Agent Offline: dltwb1hwdHTTPdp:UAGENT00

---------------------------------------------------------------------------------------------------

13 Nov


CS1050200
10.198.200.22	snghana-1024-22.xsportal.local	ADNMP1DB	10.116.145.37	root/e5inA7%BMlBw2a@
10.198.200.20	snghana-1024-20.xsportal.local	ADNAELDB



CHG0130681
Patching 5 Suse servers



CHG0133324
svjd1srv0	10.6.1.12	A0EASG014XVM003


CS1057499    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.42 (thresh: 16)    TSLBWPRDDB


pn4us7leccp1c	 10.12.254.17	
pn4ushleccp1c	 10.12.254.18

----------------------------------------------------------------------------------------------------------

14 Nov


CS0832599, CS0832625 & CS0832671  CS0696640 & CS0696842





CS0501702 - Service gpsvc critical(gpsvc=stopped (auto))
CS0623521 - Service sshd CRITICAL: ps: error while loading shared libraries: libresolv.so.2: failed to map segment from shared object



BAPV721300 - V72	10.134.4.14
BAPV590800  - V59	10.134.4.13	
BAPV321100 - V32	10.134.4.15	
BAPV520500  -V52 	10.134.4.11	



155.56.209.25	my343442.crm.ondemand.com	        
155.56.209.35	my343442-SSO.crm.ondemand.com	 



svjd1srv0	10.6.1.12	A0EASG014XVM003
CSR CHG0133440  



CS1066200    Panasonic North America -- PN4    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.27 (thresh: 16)    PN4US7LECCP1


Failed Actions:
* vcenter-fencing-pn4us7leccp1_start_0 on pn4ushleccp1 'unknown error' (1): call=152, status=Timed Out, exitreason='',
    last-rc-change='Tue Nov 12 21:37:40 2019', queued=0ms, exec=40033ms
    
     Node pn4us7leccp1:
* Node pn4ushleccp1


---------------------------------------------------------------------------------------------------------------
15 Nov

RCA0001585
PN4 RCA
Application server of CP1 was not accessible by users
Pacemaker Cluster performed a restart of application and host on pn4us7leccp1c server
OS performer was working on clearing the vcenter errors on cluster
incorrect commands are executed when clearing vcenter errors and caused the failover
NA


CS0983423
ARD = DYSCIARD2200, ARQ= DYSCIARQ2000, ARP = DYSCIARP0200

DYSCIARP0200	10.6.11.28	10.1.161.25
DYSCIARD2200	10.6.12.45	10.1.162.45
DYSCIARQ2000	10.6.12.62	10.1.162.62

Hi Nicholas,

Can you help to check with IBM Engineer whether they have granted the below access in ARD, ARQ and ARP?

Please grant the folder as chmod -R 775 /usr/sap/interfaces/ARD/* and ardadm as folder owner for read/execute/write access.
Please grant the folder as chmod -R 775 /usr/sap/interfaces/ARQ/* and arqadm as folder owner for read/execute/write access.
Please grant the folder as chmod -R 775 /usr/sap/interfaces/ARP/* and arpadm as folder owner for read/execute/write access.

On the Indonesia local server side, Romadhani already granted the access for the ARD, ARQ and ARP folders to below user.



ID: Dystar-world\ID.SAPinventory
PW: 6Kc'3m8e+CyZLW

//10.150.21.221/Upload/ITInventory/SBP/Upload/error             /usr/sap/s4hana/SBP/ITInventory/Upload/error            cifs credentials=/etc/Dystar_world,vers=3.0

[root@dyss4apsbd41 ibmrmalik]$ cat /etc/Dystar_world
username=ID.SAPinventory
password=6Kc'3m8e+CyZLW

[root@dysciard2200 ibmrmalik]$ id ardadm
uid=20220(ardadm) gid=3050(sapsys) groups=3050(sapsys)

[root@dysciarp0200 ibmrmalik]$ id arpadm
uid=20020(arpadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)

[root@dysciarq2000 ibmrmalik]$ id arqadm
uid=20200(arqadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)




CS1073537    St. Jude Medical -- JUE    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.49 (thresh: 16)
CS1073858    MSC Industrial Supply Co. -- MS3    P2 - Major    Memory Swap CRITICAL: Swap free 49.88% (thresh 50:%)
CS1073969    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.23 (thresh: 16)


CS1074245
Please your support to obtain IOPS for below servers:

PN8US7LECCP2 wdc04pool4ds285
PN8US7LECCP2H wdc04pool4ds291
PN8US7LDBCP2 wdc04pool4ds335
PN8US7LDBCP2H wdc04pool4ds241
PN8US7LECCP3 wdc04pool4ds335
PN8US7LECCP3H wdc04pool4ds249
PN8US7LDBCP3 wdc04pool4ds313
PN8US7LDBCP3H wdc04pool4ds261
PN8US7LECCP4 wdc04pool4ds291
PN8US7LECCP4H wdc04pool4ds381
PN8US7LDBCP4 WDC04POOL4DS282
PN8US7LDBCP4H WDC04POOL4DS335
PN8US7LECCP5 WDC04POOL4DS313
PN8US7LECCP5 WDC04POOL4DS313
PN8US7LDBCP5 WDC04POOL4DS313
PN8US7LDBCP5H WDC04POOL4DS313
PN8US7LGRP0 WDC04POOL4DS262
PN8US7LGRP0H WDC04POOL4DS335
PN8US7LDBRP0 WDC04POOL4DS335
PN8US7LDBRP0H WDC04POOL4DS335


I/O monitoring

iotop

iostat



CS1074138    MSC Industrial Supply Co. -- MS3    P2 - Major    Memory Swap CRITICAL: Swap free 49.73% (thresh 50:%)


CHG0133445 and task is CTASK0152677


CS1074598    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.00 (thresh: 16)

swap reduction
UUID=0dec6e64-ee5a-4bf7-8ce0-7d62e0ccb887 swap                    swap    defaults        0 0
UUID=849c36aa-3e52-4e9d-a6d4-c605c01dc755 swap                    swap    defaults        0 0



/dev/sda2: LABEL="SWAP" UUID="0dec6e64-ee5a-4bf7-8ce0-7d62e0ccb887" TYPE="swap"

no label, UUID=849c36aa-3e52-4e9d-a6d4-c605c01dc755

/dev/sda2: LABEL="SWAP" UUID="849c36aa-3e52-4e9d-a6d4-c605c01dc755" TYPE="swap"


SNCHMDAQD11    10.73.12.31  50->2GB

2. Comment out the swap entry in /etc/fstab.
#UUIDoftheswapdisk swap swap defaults 0 0
3. fdisk /dev/sda
Type p to list the partition in sda.
Type d to delete partition /dev/sda2 and press enter
Type 2 to select partition /dev/sda2 and press enterNow type p and press enter to confirm partition /dev/sda2 is removed.
Type n to create new partition /dev/sda2 and press enter
Type p to create primary parition and press enter
Press enter to select the first sector as default.
For last sector type +2G and press enter.
Now type p to confirm new partition /dev/sda2 is created.
Type t and press enter to change the partition type.
Type 82 and press enter to assign the parition type.
Type p and press enter to confirm the parition type is "Linux swap / Solaries".
Enter wq and press enter to save the changes.
4. Type partprobe and hit enter. (it might ask to reboot for the changes to reflect).
5. Type "mkswap /dev/sda2" and hit enter.
6. Remove # at the beginning of below line in /etc/fstab.UUIDoftheswapdisk swap swap defaults 0 0
7. swapon -a or swapon /dev/sda2
8. Type free -h to check if swap is listing correctly.
9. If the swap is still showing 50gb, a reboot is required for changes to reflect.
10. reboot and type free -h to confirm its reflecting 2gb as swap space

-----------------------------------------------------------------------------------------------------------------------------------------

9 Nov

CS1126689	

Indonesia local server connection,  can you help to check whether the below access right has been granted in SBP? (attachment1)

Please grant the folder as chmod -R 775 /usr/sap/s4hana/SBP/* and sbpadm as folder owner for read/execute/write access.

Customer found out that the ITInventory mount points are not setup in SBQ (DYSS4APSBQ21) yet (attachment2)

Please setup in SBQ and grant the below right as well.

 Please grant the folder as chmod -R 775 /usr/sap/s4hana/SBQ/* and sbqadm as folder owner for read/execute/write access.


yss4apsbd41 - SBD	10.6.12.18	10.1.162.18
[root@dyss4apsbd41 ibmrmalik]$ id sbdadm
uid=20410(sbdadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)



dyss4apsbq21 - SBQ	10.6.12.34	10.1.162.34
[root@dyss4apsbq21 ibmrmalik]$ id sbqadm
uid=20210(sbqadm) gid=3050(sapsys) groups=3050(sapsys),3051(sapinst)

cifs credentials=/etc/Dystar_world,vers=3.0



CS1126768
Please check access to port 25/tcp and 587/tcp on  host 172.16.0.101 from S4P apps server, by execute following command on S4P apps server (PBBs4hpap00):

#telnet 172.16.0.101 25
#telnet 172.16.0.101 587


CS1126214    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.22 (thresh: 16) 


snapshot	CHG0133794
svjq1srv0	10.6.2.12	A0EASG014XVM004


stat("/usr/sap/trans",
10.24.164.48:/usr/sap/trans /usr/sap/trans  nfs   rw,hard,intr,rsize=32768,wsize=32768    0     0



CS1126470
Please perform online storage migration for server sapapp18 to remove 24K IOPS storage.
Few instructions -
1- Move all disk from "TTACHE01BCA351IOPS24K" TO "CHE01POOL1DS264" except "disk 5"
2- Follow the steps given in this link -
https://nolabnoparty.com/en/move-vmdk-files-different-datastores/


CS1128408    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.52 (thresh: 16)    TSLBWPRDDB    
CS1128399    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.23 (thresh: 16)    TSLBWQADB    
CS1128313    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.95 (thresh: 16)    TSLBWQADB




solsmpd	10.16.5.11	 pre deployment   part of SAPA3 squad	no access to the server en via chef 
shdqs4dqd	10.16.4.18	pre deployment   part of SAPA3 squad   server seems to be down no loo


7906 3594 6162


CS1133598    Panasonic North America -- PN4    P2 - Major    Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4ushlewmp1c(stonith:fence_vmware_soap):Stopped    PN4USHLEWMP1C


CS1133834    Apleona GmbH (Grounding) -- AP5    P1 - Severe    HR3 10.92.144.22 is not reachable they are preparing Paymentrun befor Migration 
[root@APLHRHP1 ibmrmalik]$ uptime
 09:08:51 up 21 min,  3 users,  load average: 0.48, 1.15, 0.70
 
 
   
CS1133815    Apleona GmbH (Grounding) -- AP5    P1 - Severe    Host Reboot CRITICAL: Uptime 3 minutes (thresh 60 min)    APLHRHP1



It is not exactly a monitoring error, but the monitoring is too â€œsensitiveâ€. It actually reports each warning message in cluster log. We limited the nagios filefilter of the cluster log to specific errors only. I believe it should go to production later today. The update of the policy is tracked here (link to my comment where the cms_cluster_monitoring is updated version with the fix): https://github.ibm.com/CMS/cms-chef/issues/3523#issuecomment-16063062 (edited)   

Request for fix: https://github.ibm.com/CMS/MgdSAP-Tribe-Tracker/issues/9083 



CS1131933	10.138.13.15
Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-19-32-34 for details.



CS1132097	10.138.13.15
Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-20-17-39 for details


CS1133261	10.138.13.15
Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-20-00-58-10 for details.


CS1133393	10.138.13.15
Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-20-01-33-14 for details.


CS1130675	10.138.13.48
Log PaceMaker-corosync Found 115 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-14-50-40 for details.



CS1130773	10.138.13.48
Log PaceMaker-corosync Found 115 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-15-10-41 for details.



CS1130851	10.138.13.48
Log PaceMaker-corosync Found 115 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-15-25-42 for details.



CS1131073	10.138.13.50
Log PaceMaker-corosync Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-16-12-49 for details.



CS1130958	10.138.13.50
Log PaceMaker-corosync Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-15-47-46 for details.



CS1131313	10.138.13.50
Log PaceMaker-corosync Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-16-57-54 for details.


CS1130657	10.138.13.50
Log PaceMaker-corosync Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-14-47-42 for details.



CS1130437	10.138.13.50
Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-14-02-37 for details.


CS1134829    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 23.62 (thresh: 16)    TSLBWQADB    10.207.63.20
CS1134030    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.81 (thresh: 16)    TSLBWPRDDB	10.207.61.200


CHG0133704	CTASK0153625
snapshot of 10.13.2.21   DLBDBIDA00	10.13.2.21	172.16.22.21	Chennai


CS1131068	10.138.13.48
Log PaceMaker-crmd Found 60 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-16-10-46 for details.


CS1131140	10.138.13.48
Log PaceMaker-crmd Found 60 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-16-25-47 for details.


CS1130656	10.138.13.50
Log PaceMaker-crmd Found 67 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-14-47-42 for details.


CS1130264	10.138.13.48
Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-13-30-32 for details.


CS1130647	10.138.13.23
Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-14-45-50 for details.


CS1130716	10.138.13.23
Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-15-00-13 for details.


CS1130770	10.138.13.23
Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-11-19-15-10-12 for details.


-------------------------------------------------------------------------------------------------

21 Nov

4089314619

CS1141680    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.14 (thresh: 16)    TSLBWPRDDB
Load is normal wrt the cpu and the cores CPU idle is over 90% at all times
[root@tslbwprddb ibmrmalik]$ uptime
 13:54pm  up 208 days 20:50,  2 users,  load average: 15.83, 23.97, 21.89
[root@tslbwprddb ibmrmalik]$ lscpu | grep -E '^Thread|^Core|^Socket|^CPU\('
CPU(s):                128
Thread(s) per core:    1
Core(s) per socket:    32
Socket(s):             4

CS1141638    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.96 (thresh: 16)    TSLBWPRDDB
CS1141385    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.05 (thresh: 16)    TSLBWPRDDB
CS1141387    Tata Steel Limited -- TTA    P3 - Minor    Disk Utilization /var/log CRITICAL: Free 940.50MB/19.69% (thresh @10.01:20%)    SAPAPP23


Load is normal wrt the cpu and the cores CPU idle is over 90% at all times
[root@tslbwprddb ibmrmalik]$ uptime
 13:54pm  up 208 days 20:50,  2 users,  load average: 15.83, 23.97, 21.89
[root@tslbwprddb ibmrmalik]$ lscpu | grep -E '^Thread|^Core|^Socket|^CPU\('
CPU(s):                128
Thread(s) per core:    1
Core(s) per socket:    32
Socket(s):             4



CS1142047
FS_is_read_only_on_sapborepo.imzcloud.ibmammsap.local[PROBLEM:17781005]
10.207.61.40


CS1142485
Lon02
IA2POQASDBAP	10.133.17.160	66.248.245.160
IA2POQASDBAP


CS1142415    Meggitt PLC -- MGG    P2 - Major    Ruuning_out_of_available_memory_on_server_MGGGBJPCNTX01.imzcloud.ibmammsap.local[PROBLEM:17781874]    MGGGBJPCNTX01
CS1142744    Meggitt PLC -- MGG    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.83% (thresh 2:%)    MGGGBJQGTSY01 



CS1136833
Windows Cloud (new Nexera server):

IP: 10.150.122.169
Hostname: RG3SRV0009
User/Password: request the user and password to erickbrito@riogaleao.com / bernardocaldas@riogaleao.com 

SAP - PRD:

SAP System: S4P (10.80.1.112) 	CONSPS4HAPP	10.16.1.101	10.80.1.112	
SAP Directory Parameter: DIR_SKYLINE_TES_S4P 
Unix Directory: /usr/sap/skyline/s4p/tesouraria 
Windows Directory: C:\Skyline\S4P\TESOURARIA\ 

SAP System: ECP (10.80.1.122) 	CONSPECCAPP	10.16.1.105	10.80.1.122
SAP Directory Parameter: DIR_SKYLINE_PEO_ECP 
Unix Directory: /usr/sap/skyline/ecp/peo 
Windows Directory: C:\Skyline\ECP\RH\ 


CS1142912    Arnoldo Mondadori Editore SpA -- ARM    P1 - Severe    Disk Utilization /var/log CRITICAL: Free 54.39MB/4.96% (thresh @0:5%)    ARMFKSAP302A1


CS1143941    Apleona GmbH (Grounding) -- AP5    P1 - Severe    Cloud connector https://10.92.152.139:8443/ is not reachable
AP5SERVER3	100.126.66.11	10.92.152.139	

------------------------------------------------------------------------------------------------------------------------

22 Nov


CS1149423    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.28 (thresh: 16)    TSLEECQA	10.207.63.14
CS1149436    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.36 (thresh: 16)    TSLBWQADB	10.207.63.20
CS1149247    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.38 (thresh: 16)    TSLBWQADB	10.207.63.20


eco3fibwapdb1    10.211.1.34 , DF hung on this server. Request OS assistance - CS1149481

10.238.2.29:/usr/sap/trans      /usr/sap/trans  nfs     defaults

CO3FIBWADDB1	10.211.2.15	10.238.2.29		Dallas13




172.25.1.21:/usr/sap/trans     /usr/sap/trans          nfs     _netdev,defaults        1       2




CS1150749	BACKUP FS needs to be extended	BS5PRDAPP1	10.141.132.24	
[root@bs5prdapp1 ibmrmalik]# lsblk |grep -i /backup/dbbackup
â”œâ”€backupvg-BACKUP_DBBACKUP  254:9    0   1.6T  0 lvm  /backup/dbbackup

[root@bs5prdapp1 ibmrmalik]# lvdisplay |grep -i DBBACKUP
  LV Path                /dev/backupvg/BACKUP_DBBACKUP
  LV Name                BACKUP_DBBACKUP

[root@bs5prdapp1 ibmrmalik]# df -hT /backup/dbbackup
Filesystem                           Type  Size  Used Avail Use% Mounted on
/dev/mapper/s4pappvg-BACKUP_DBBACKUP ext4  1.5T  1.2T  246G  84% /backup/dbbackup

 /dev/backupvg/BACKUP_DBBACKUP		1.5 to 2.5 TB 

backupvg    1   4   0 wz--n-   2.40t  355.00g
[root@bs5prdapp1 ibmrmalik]# vgs
  VG        #PV #LV #SN Attr   VSize   VFree
  bachup1vg   2   2   0 wz--n- 999.99g    1.50g
  backup4     1   1   0 wz--n- 500.00g   96.00m
  backupvg    1   4   0 wz--n-   2.40t  355.00g
  rootvg      2   9   0 wz--n- 145.49g   22.49g
  s4pappvg    1   3   0 wz--n- 200.00g 1020.00m
[root@bs5prdapp1 ibmrmalik]# vgs s4pappvg
  VG       #PV #LV #SN Attr   VSize   VFree
  s4pappvg   1   3   0 wz--n- 200.00g 1020.00m


[root@bs5prdapp1 ibmrmalik]# lvextend -L +1T /dev/backupvg/BACKUP_DBBACKUP
  Size of logical volume backupvg/BACKUP_DBBACKUP changed from 1.61 TiB (422400 extents) to 2.61 TiB (684544 extents).
  Logical volume BACKUP_DBBACKUP successfully resized
[root@bs5prdapp1 ibmrmalik]# resize2fs /dev/backupvg/BACKUP_DBBACKUP
resize2fs 1.42.11 (09-Jul-2014)
resize2fs: Device or resource busy while trying to open /dev/backupvg/BACKUP_DBBACKUP
Couldn't find valid filesystem superblock.



[root@bs5prdapp1 ibmrmalik]# lsblk |grep -i /backup/logbackup
â”œâ”€backupvg-BACKUP_LOGBACKUP 254:10   0   256G  0 lvm  /backup/logbackup

[root@bs5prdapp1 ibmrmalik]# lvdisplay |grep -i BACKUP_LOGBACKUP
  LV Path                /dev/backupvg/BACKUP_LOGBACKUP
  LV Name                BACKUP_LOGBACKUP

[root@bs5prdapp1 ibmrmalik]# df -hT /backup/logbackup
Filesystem                            Type  Size  Used Avail Use% Mounted on		
/dev/mapper/s4pappvg-BACKUP_LOGBACKUP ext4  252G  207G   33G  87% /backup/logbackup

 backupvg    1   4   0 wz--n-   2.40t  355.00g	


/dev/backupvg/BACKUP_LOGBACKUP		252 to 500GB


https://access.redhat.com/solutions/1142523




CS1151224    Celanese Corporation -- CEZ    P1 - Severe    Host Reboot CRITICAL: Uptime 2 minutes (thresh 60 min)    RALLEGNILERP




CHG0132864
Prod site	LON02POD2
DR Site	FRA02POD1
Client : Meggitt



CS1151546    Apleona GmbH (Grounding) -- AP5    P1 - Severe    Disk Utilization /var CRITICAL: Free 466.30MB/4.95% (thresh @0:5%)    AP5SERVER6

-------------------------------------------------------------------------------------------------------------------------

24 Nov


/dev/mapper/bopdatavg-bopsapdata1_lv
                       23G   21G  1.4G  94% /sybase/BOP/sapdata1
/dev/mapper/bopdatavg-bopsapdata2_lv
                       23G   21G  1.4G  94% /sybase/BOP/sapdata2
/dev/mapper/bopdatavg-bopsapdata3_lv
                       23G   21G  1.4G  94% /sybase/BOP/sapdata3
/dev/mapper/bopdatavg-bopsapdata4_lv
                       23G   21G  1.4G  94% /sybase/BOP/sapdata4

[root@conspbobdapp ibmrmalik]$ vgs bopdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  bopdatavg   2   7   0 wz--n- 327.99g 188.50g




CS1161706    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.53 (thresh: 16)    SQ-SAP-TRIO-C2	10.12.254.16
CS1161913    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.71 (thresh: 16)    SQ-SAP-TRIO-C2	10.12.254.16
CS1161988    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.44 (thresh: 16)    SQ-SAP-TRIO-C2	10.12.254.16

CS1163574    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.73 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.61.205
CS1163575    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Processor_load_is_too_high_on_sapboprd.imzcloud.ibmammsap.local[PROBLEM:17978872]    SQ-SAP-TRIO-C1	10.207.61.205

-------------------------------------------------------------------------------------------------------------------------------------------------


25 Nov


ãƒ»sap-db1(10.232.130.21)	10.20.130.21
ãƒ»sap-db2(10.232.130.20)


saphon1	10.20.130.11
saphon2	10.20.130.13



CS1169652    Dilip Buildcon Limited -- DLB    DLB    DLB IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.98 (thresh: 16)    SQ-SAP-TRIO-C2


CS1168006    Manitoba Telecom Services -- MTS    MTS    MTS SAP HEC-AMM SAP LOB    Incident    P2 - Major    New        CPU CPU-Utilization CRITICAL: CPU Usage 99.75% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.25%    SQ-SAP-TRIO-C1
CS1168876    Manitoba Telecom Services -- MTS    MTS    MTS SAP HEC-AMM SAP LOB    Incident    P2 - Major    New        CPU CPU-Utilization CRITICAL: CPU Usage 99.25% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.75%    SQ-SAP-TRIO-C1



CS0983423
ARP (DYSCIARP0200)	10.6.11.28	10.1.161.25




CS0745898    Certified IT Consultants - TMG -- CI3    P2 - Major    extend /usr/sap/BOD FS by 15 GB on CI3BODEV server 


//10.1.161.14/Dystar-FTP/LocalUser/PIL/IB/ARP/INV      /usr/sap/interfaces/ARP/PIL/IB/INV   cifs credentials=/etc/Dystar_credentials,uid=20020,gid=3050,dir_mode=0775,sec=ntlm,vers=3.0   0   0

DYSFTPDAPRD01	10.6.11.14	10.1.161.14		windows

-------------------------------------------------------------------------------------------------------------------------------

26 Nov

CS1174843, CS1174892, CS1174864, CS1174868, CS1174894


CHG0134307 snapshotSVJQ1SRV0	A0EASG014XVM004


CS1176939    MSC Industrial Supply Co. -- MS3    MS3    MS3 AMM-SAP SAP LOB    Incident    P2 - Major    New        CPU CPU-Utilization CRITICAL: critical(30m: 100%)    SQ-SAP-TRIO-C1	10.12.6.32
CPU being used up by a SAP app, needs immediate action by SAP
Collabservicex64
Vignette  Collaboration

CS1174802    MSC Industrial Supply Co. -- MS3    MS3    MS3 AMM-SAP SAP LOB    Incident    P2 - Major    New        CPU CPU-Utilization CRITICAL: critical(30m: 100%)    SQ-SAP-TRIO-C1	10.12.6.32


CS1175979    MSC Industrial Supply Co. -- MS3    MS3    MS3 AMM-SAP SAP LOB    Incident    P2 - Major    New        CPU CPU-Utilization CRITICAL: critical(30m: 100%)    SQ-SAP-TRIO-C1	10.12.6.32


CS1176930    Dilip Buildcon Limited -- DLB    P2 - Major    Please add space as below
DLBPCSDA00	10.13.1.18	172.16.20.18	Please add 500GB each to sapdata file  systems on 10.13.1.18  (Total 2TB to be added)
DLBPECAP01	10.13.1.12	172.16.20.12	Please add 200GB to /usr/sap/PEC on 10.13.1.12  (to make it 300GB of size)
DLBPECAP02	10.13.1.13	172.16.20.13	Please add 200GB to /usr/sap/PEC on 10.13.1.13  (to make it 300GB of size)	
DLBPSMDA00	10.13.1.19	172.16.20.19	Please add 25GB each to sapdata file systems on 10.13.1.19 (Total 200GB to be added)	




PBBs4hdap00:/usr/sap/trans
                       60G   38G   19G  68% /usr/sap/trans
172.25.1.16:/usr/sap/trans_temp
                      245G   83G  151G  36% /usr/sap/trans_temp


[root@PBBs4hqap00 ibmrmalik]$ cat /etc/fstab |grep -i nfs
r3devsap:/usr/IDOC      /usr/IDOC nfs   vers=3  0       0
PBBs4hdap00:/usr/sap/trans /usr/sap/trans nfs    _netdev,defaults        1       2
PBBS4HPAP00	10.6.7.16	172.25.1.16





CHG0134430
svjd1srv0	10.6.1.12	A0EASG014XVM003

------------------------------------------------------------------------------------------------------------------------------

27 Nov


RD = DYSCIARD2200, ARQ= DYSCIARQ2000, ARP = DYSCIARP0200

DYSCIARP0200	10.6.11.28	10.1.161.25
DYSCIARD2200	10.6.12.45	10.1.162.45
DYSCIARQ2000	10.6.12.62	10.1.162.62

Hi Nicholas,

Can you help to check with IBM Engineer whether they have granted the below access in ARD, ARQ and ARP?

Please grant the folder as chmod -R 775 /usr/sap/interfaces/ARD/* and ardadm as folder owner for read/execute/write access.
Please grant the folder as chmod -R 775 /usr/sap/interfaces/ARQ/* and arqadm as folder owner for read/execute/write access.
Please grant the folder as chmod -R 775 /usr/sap/interfaces/ARP/* and arpadm as folder owner for read/execute/write access.

On the Indonesia local server side, Romadhani already granted the access for the ARD, ARQ and ARP folders to below user.



ID: Dystar-world\ID.SAPinventory
PW: 6Kc'3m8e+CyZLW

//10.150.21.221/Upload/ITInventory/SBP/Upload/error             /usr/sap/s4hana/SBP/ITInventory/Upload/error            cifs credentials=/etc/Dystar_world,vers=3.0




CS1183841    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.78 (thresh: 16)    SQ-SAP-TRIO-C2	10.12.254.16
CS1182696    St. Jude Medical  -- JUE    JUE    JUE St. Jude Medical SAPHEC-IC4SAP-SL    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.54 (thresh: 16)    SQ-SAP-TRIO-C1	10.211.0.16
CS1183177    St. Jude Medical  -- JUE    JUE    JUE St. Jude Medical SAPHEC-IC4SAP-SL    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.39 (thresh: 16)    SQ-SAP-TRIO-C1	10.211.0.16
CS1182942    St. Jude Medical  -- JUE    JUE    JUE St. Jude Medical SAPHEC-IC4SAP-SL    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.49 (thresh: 16)    SQ-SAP-TRIO-C1	10.211.0.16
CS1183603    St. Jude Medical  -- JUE    JUE    JUE St. Jude Medical SAPHEC-IC4SAP-SL    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 25.97 (thresh: 16)    SQ-SAP-TRIO-C1	10.211.0.20


CS1182852    IAG GBS Limited -- IA1    IA1    IA1 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1:)	10.133.17.147
CS1182901    IAG GBS Limited -- IA1    IA1    IA1 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1:)	10.133.17.150
CS1184060    IAG GBS Limited -- IA1    IA1    IA1 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1:)	10.133.15.24		cannot connect

CS1184557    IAG GBS Limited -- IA1    IA1    IA1 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Memory Virtual CRITICAL: Free Memory 1.91% (thresh 2:%)	10.199.15.200
CS1182806    IAG GBS Limited -- IA1    IA1    IA1 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1:)	10.133.15.32
CS1182847    IAG GBS Limited -- IA1    IA1    IA1 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1:)	10.133.17.146



CS1184474 - TTL - Sev 2


CS1182832    IAG - British Airways -- IA2    IA2    IA2 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1:)	10.133.16.44
CS1182819    IAG - British Airways -- IA2    IA2    IA2 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1:)	10.133.16.46
CS1182867    IAG - British Airways -- IA2    IA2    IA2 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Service master CRITICAL: 0 master processes running (thresh 1: 


CS1184762, CS1184751, CS1184703


CS1184705    Dilip Buildcon Limited -- DLB    DLB    DLB IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.32 (thresh: 16)    SQ-SAP-TRIO-C2

Qsq9evf5fL



So, need your favour to mount as an additional File System  on BS5PRDAPP1 10.141.132.24	132.132.0.11 (132.132.0.11) as details given below :
/backup/dbbackup_1     1.5 TB
/Backup/logbackup_1    500GB
Kindly take this call on priority and confirm us once done.

/backup/dbbackup_1     1.5 TB
/Backup/logbackup_1    500GB


------------------------------------------------------------------------------------------------------------------------------
28 Nov

CS1189182    Controladora De Negocios -- CNG    CNG    CNG AMM-SAP SAP LOB    Incident    P2 - Major    New        Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)    SQ-SAP-TRIO-C1	10.68.210.30
CS1189234    Fitbit Inc -- FBT    FBT    FBT SAP HEC-AMM SAP LOB    Incident    P2 - Major    New        Memory Virtual CRITICAL: Free Memory 1.91% (thresh 2:%)    SQ-SAP-TRIO-C2	10.4.26.30
CS1188844    Fitbit Inc -- FBT    FBT    FBT SAP HEC-AMM SAP LOB    Incident    P2 - Major    New        Memory Virtual CRITICAL: Free Memory 1.88% (thresh 2:%)    SQ-SAP-TRIO-C2	10.4.26.30
CS1189879    IAG GBS Limited -- IA1    IA1    IA1 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Memory Virtual CRITICAL: Free Memory 1.39% (thresh 2:%)    SQ-SAP-TRIO-C1
CS1189354    Tecnologia De Materiales S.A. -- TDM    TDM    TDM AMM-SAP SAP LOB    Incident    P2 - Major    New        Memory Swap CRITICAL: Swap free 49.50% (thresh 50:%)    SQ-SAP-TRIO-C2



CS1188960    St. Jude Medical  -- JUE    JUE    JUE St. Jude Medical SAPHEC-IC4SAP-SL    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.03 (thresh: 16)    SQ-SAP-TRIO-C1	10.211.0.16
CS1190516    St. Jude Medical  -- JUE    JUE    JUE St. Jude Medical SAPHEC-IC4SAP-SL    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.74 (thresh: 16)    SQ-SAP-TRIO-C1	10.211.0.20
CS1190416    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.94 (thresh: 16)    SQ-SAP-TRIO-C1



CS1191537    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Disk Utilization /backup/logbackup CRITICAL: Free 21908.92MB/8.32% (thresh @5.01:10%)    SQ-SAP-TRIO-C1	10.141.133.19
CS1190741    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.85 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.61.200
CS1190755    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.23 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.62.14
CS1191468    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 36.71 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.63.20
CS1191499    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 26.77 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.63.20



CHG0134660
svjq1srv0	10.6.2.12    snapshot		A0EASG014XVM004

-------------------------------------------------------------------------------------------------------------------------------------

30 Nov



MSCWDCLPDB200	pHANA WDC	msc-phana-1024-4.imzcloud.ibmammsap.local	no info in the search tool check if decommissioned
dalhana-4048-2	10.121.75.131	VMWare ESX 6.x		check with physical infra
dalhana-4048-3	10.121.75.121	VMWare ESX 6.x		check with physical infra	
DLTHMEHDB	pHANA Dal09	dalhana-1024-59.xsportal.local	fixed	
S/4 HANA
test-mon01-pod2-phana-1024-01
torhdbsrv01	pHANA	TOR	torhana-b1024-1.xsportal.local	no info in the search tool check if decommissioned
torhdbsrv02	pHANA   TOR	torhana-b1024-2.xsportal.local	no info in the search tool check if decommissioned
A0EASG014XVM109	vHANA	SNG	snghana-1024-1.xsportal.local	no info in the search tool check if decommissioned
ctubwsb3db02	server details not found

mgggbjqectemp	10.133.18.147	HANA 	10.133.18.147	10.5.255.218	Development	Deployed	ProjectQA	PEQ	25	MGG	SAPC2	6890		SAP HANA	DB	RazvanSegneanu	Kuganeswaran KisnianKrishnan	HANA	RHEL 6.7	SAP HANA 1.0 SPS 122 Rev 08	Full Service	IC4SAP SL	MGG	SL-LONDON-LON02		Get it checked if still active

nfenwdb	10.16.4.23	cant access seems down, check if active predeployment
nfenwqb	10.16.4.17	cant access seems down, check if active predeployment
shdqs4dqd	10.16.4.18	cant access seems down, check if active predeployment
solsmpd		10.16.5.11	server accessible but annot login, root pw not available in PIM    pre deployment



CS1200899    Egyptian Cement -- ECT    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ECTS4HPRDAP- KB0010973
CS1200974    St. Jude Medical -- JUE    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.46 (thresh: 16)
CS1200972    St. Jude Medical -- JUE    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.46 (thresh: 16)

CS1200910    Hortus Comercio de Alimentos SA -- HC1    P2 - Major    Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on HC1HOSMJAVAP- KB0010973



CS1201430    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.29 (thresh: 16)	10.207.61.200
CS1201464    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.90 (thresh: 16)	10.207.61.200


CS1201713    IAG - British Airways -- IA2    P2 - Major    Memory Swap CRITICAL: Swap free 49.94% (thresh 50:%) 


CS1201806    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.6.1.29
CS1201840    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.6.3.44



SPSVEPAJAPP01	10.6.3.13	10.70.111.13	source
SVJS1SRV0	10.6.1.140	10.92.99.140	destination
source : 10.6.3.13 (production)
Target : 10.6.1.140   
file path : /usr/sap  
under this we have folder called FSQUO on both server  


CS1202028    IAG GBS Limited -- IA1    P2 - Major    Memory Virtual CRITICAL: Free Memory 1.94% (thresh 2:%)


CS1202262    Bumrungrad Hospital Plc -- BUM    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.13 (thresh: 16)  10.134.14.15
CS1202245    St. Jude Medical -- JUE    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 33.60 (thresh: 16)	10.211.0.20



CS1202114    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.6.1.29
CS1202116    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1202139    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.6.3.44
CS1202137    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))


CS1202816    LSPI -- LSP    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 189.188MB (200MB)), \??\X:\pagefile.sys 2.529GB (4.5GB), total 2.714GB (4.695GB)	10.4.2.12



CS1202726    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.6.1.29
CS1202735    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.6.1.29
CS1202752    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.6.3.44
CS1202757    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))

---------------------------------------------------------------------------------------------------------------------------------

3Dec


CS1220000    1    C1-C2    N/A    N/A    Disk Utilization /var/log CRITICAL: Free 45.05MB/4.96% (thresh @0:5%)


BR3PMIGA01     10.138.10.34
CS1220032    1    C1-C2    BR3    N/A    Drive-Space C critical(OK: Drive C: has 3.174GB of 63.656GB



dalhana-4048-2- your comment: check with physical infra
dalhana-4048-3 your comment check with physical infra
test-mon01-pod2-phana-1024-01


CS1221090    Panasonic North America -- PN8    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 51.38 (thresh: 16)



CS1221457
Reboot server DLBDBIDA00 10.13.2.21



CS1221546    Arnoldo Mondadori Editore SpA -- ARM    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.02 (thresh: 16)
CS1221394    Panasonic North America -- PN8    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.20 (thresh: 16)

Tc5v9VPner


CS1221695    Computer Systems Integration Ltd -- CSY    P2 - Major    Memory Swap CRITICAL: Swap free 47.66% (thresh 50:%)


CS1222326    Controladora De Negocios -- CNG    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.68.210.30
CS1222276    Controladora De Negocios -- CNG    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.164MB (200MB), total 199.164MB (200MB))	10.68.210.30
CS1222360    Controladora De Negocios -- CNG    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 198.961MB (200MB), total 198.961MB (200MB))	10.68.210.30
CS1222221    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)		10.68.210.30
CS1222327    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)		10.68.210.30
CS1222298    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.371MB (200MB), total 199.371MB (200MB)		10.68.210.30
CS1222234    Controladora De Negocios -- CNG    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.68.210.30
CS1222344    Controladora De Negocios -- CNG    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.02MB (200MB), total 199.02MB (200MB)		10.68.210.30




CS1220854    AGEAS -- AGE    P2 - Major    Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.6.1.30
CS1220882    AGEAS -- AGE    P2 - Major    Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.6.1.30


CS1222512



CS1222677
snapshot  Please take VM snapshot of DLBDBIDA00  10.13.2.21
------------------------------------------------------------------------------------------------------------------------------
4 Dec


CS1227150    Tata Steel BSL Ltd -- BS5    BS5    BS5 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        Disk Utilization /backup/logbackup CRITICAL: Free 38093.64MB/9.92% (thresh @5.01:10%)    SQ-SAP-TRIO-C1
CS1227825    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.59 (thresh: 16)    SQ-SAP-TRIO-C1


dalhana-4048-2	10.121.75.131	root/bsnegp%iMbzFoW@
dalhana-4048-3  10.121.75.121	root/cuUqPz%17bHUjw@
test-mon01-pod2-phana-1024-01	10.182.134.100	root/Kee5x28Q


CS1228818    Bombardier Recreational Products Inc -- BR3    BR3    BR3 SAPHEC-IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.10 (thresh: 16)    SQ-SAP-TRIO-C1	10.138.13.45
CS1227188    Bumrungrad Hospital Plc -- BUM    BUM    BUM IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.13 (thresh: 16)    SQ-SAP-TRIO-C1	10.134.14.15
CS1229011    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.53 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.62.14
CS1229098    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.88 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.61.200
CS1227024    Bumrungrad Hospital Plc -- BUM    BUM    BUM IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.96 (thresh: 16)    SQ-SAP-TRIO-C1	10.134.14.15
CS1228592    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.18 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.61.200
CS1229091    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.69 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.61.200
CS1229054    Tata Steel Limited -- TTA    TTA    TTA IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.82 (thresh: 16)    SQ-SAP-TRIO-C1	10.207.61.200
CS1228196    St. Jude Medical  -- JUE    JUE    JUE St. Jude Medical SAPHEC-IC4SAP-SL    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.29 (thresh: 16)    SQ-SAP-TRIO-C1	10.211.0.20
CS1229076    Dilip Buildcon Limited -- DLB    DLB    DLB IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.64 (thresh: 16)    SQ-SAP-TRIO-C2	10.13.1.23
CS1227994    Panasonic North America -- PN4    PN4    PN4 IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 32.60 (thresh: 16)    SQ-SAP-TRIO-C2	10.12.254.16
CS1229086    Dilip Buildcon Limited -- DLB    DLB    DLB IC4SAP-SL SAP LOB    Incident    P2 - Major    New        LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 33.87 (thresh: 16)    SQ-SAP-TRIO-C2	10.13.1.23




svjd1srv0	10.6.1.12
 
CSR CHG0135011  	A0EASG014XVM003

CSR is at 3.30..  

--------------------------------------------------------------------------------------------------

5 Dec

CS1235793    Arnoldo Mondadori Editore SpA -- ARM    P3 - Minor    Disk Utilization /var CRITICAL: Free 1108.45MB/19.81% (thresh @10.01:20%)
CS1236143    CMA CGM -- CMA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 23.50 (thresh: 16)

CS1235644    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.32 (thresh: 16)	10.207.61.200
CS1235721    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.56 (thresh: 16)	10.207.61.200
CS1235717    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.03 (thresh: 16)	10.207.61.200
CS1235710    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.03 (thresh: 16)	10.207.61.200
CS1235739    Delta Airlines -- DAL    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 91.91 (thresh: 16)


CS1235618    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-04-19-33-19 for details.	10.138.13.50
CS1235662    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-04-19-43-21 for details.
CS1236285    Bombardier Recreational Products Inc -- BR3    P2 - Major    Log PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-04-22-33-38 for details.
CS1235572    Bombardier Recreational Products Inc -- BR3    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.39 (thresh: 16)


CS1236355    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.42 (thresh: 16)	10.207.61.200
CS1236384    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.11 (thresh: 16)
CS1236516    Bumrungrad Hospital Plc -- BUM    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.09 (thresh: 16)


[root@tslbwprddb ibmrmalik]$ uptime
 10:49am  up 222 days 17:45,  5 users,  load average: 14.59, 17.04, 16.75
[root@tslbwprddb ibmrmalik]$ lscpu | grep -E '^Thread|^Core|^Socket|^CPU\('
CPU(s):                128
Thread(s) per core:    1
Core(s) per socket:    32
Socket(s):             4
[root@tslbwprddb ibmrmalik]$ date
Thu Dec  5 10:49:35 IST 2019


CS1236801    St. Jude Medical -- JUE    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.41 (thresh: 16)
--------------------------------------------------------------------------------------------------------------------

6 Dec

CS1231159    Tata Steel Limited -- TTA    P2 - Major    Memory Swap CRITICAL: Swap free 49.30% (thresh 50:%)
CS1224142    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 52.91 (thresh: 16)

CS1241138	Dal09	otal allocated RAM, Number of CPU's and Total allocated disk
10.4.8.14 - D12		PN5SAPECCD12	
10.4.8.10 - D15		PENAD15SL 
10.4.8.16- T12 		PN5SAPECCT12
10.4.8.11- T15		PENAT15SL 
10.4.8.15 - P12 	PN5SAPECCP12
10.4.8.13 - P15 	PENAP15SL

----------------------------------------------------------------------------------------------------------------

7 Dec


CHG0135233	spsvepajapp01	snapshot	A0EASG014XVM039


OS resource for - CS124370 Tata Steel Limited -- TTA (urgent)



CS1250583    Tata Steel Limited -- TTA    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.20 (thresh: 16)
10.207.61.200


CS1250694    IAG - British Airways -- IA2    P2 - Major    Memory Swap CRITICAL: Swap free 49.91% (thresh 50:%) 


CS1251331    Bumrungrad Hospital Plc -- BUM    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.35 (thresh: 16)


CS1251501    Bumrungrad Hospital Plc -- BUM    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.02 (thresh: 16)


CS1251795    Bumrungrad Hospital Plc -- BUM    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.72 (thresh: 16)    BUMSAPH4P01P



 mount -t nfs 10.70.111.13:/usr/sap/FSQUO /FSQUO_PRD_ReadyOnly 
 
 
 CS1252028    St. Jude Medical -- JUE    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.71 (thresh: 16)    JUEHDMART03
 
 
 CS1252065    Meggitt PLC -- MGG    P2 - Major    Memory Swap CRITICAL: Swap free 49.85% (thresh 50:%)    MGGGBJDCNTX02
 
 
 CS1252129    IAG GBS Limited -- IA1    P2 - Major    Memory Swap CRITICAL: Swap free 49.98% (thresh 50:%)    IA1OTASDEVAPP
 
 
 CS1252193    Panasonic North America -- PN8    P2 - Major    Memory Swap CRITICAL: Swap free 49.93% (thresh 50:%)    PN8US7LAP2P3
 
 
 CS1252384    COTY Inc. -- CTU    P2 - Major    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.35 (thresh: 16)    CTUBWPB0DB03
 
 
 CS1252733    Tata Steel Limited -- TTA    P1 - Severe    Disk Utilization /home CRITICAL: Free 20.12MB/4.45% (thresh @0:5%)    SAPAPP18
 

delta-dal09-phana-2048-02.imzcloud.ibmammsap.local ( dlthpehdbs  )	10.143.69.212/25
dlthpehdb4s delta-dal09-phana-4096-04.imzcloud.ibmammsap.local		10.143.69.254/25	CS1384807
	
------------------------------------------------------------------------------------------------------

10 Dec



[root@DLBPECAP01 ibmrmalik]$ cat /etc/fstab |grep -i /Bank
172.16.20.20:/Bank /Bank nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
	
	
BI1ERPDBPRD01	10.135.3.17	10.199.10.17



PTPKELIMUTU3	10.70.31.15	192.168.166.24
root
gkSNYS[v030,jNh

-----------------------------------------------------------------------------------------------------------

11 Dec



CS1278282	St. Jude Medical -- JU1	P3 - Minor	Disk Utilization /var CRITICAL: Free 1220.36MB/20.00% (thresh @10.01:20%) 	10.198.12.16

CS1277569 AGEAS -- AGEP3 - MinorSAP-HEC-Swivel:HEC: Database restart for 10.92.99.126 


CS1278603	IAG GBS Limited -- IA1	P2 - Major	Memory Virtual CRITICAL: Free Memory 1.73% (thresh 2:%)


CS1278851 Panasonic North America -- PN4P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.61 (thresh: 16)PN4USHLECCP1
10.12.254.16

CS1278850 Panasonic North America -- PN4P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.61 (thresh: 16)PN4USHLECCP1



TS!*9`pi



CHG0135715
OS: rmalik@us.ibm.com(Ravi Malik), sgaur@us.ibm.com(Sandeep Gaur), tyun@cn.ibm.com(Yun Tang), majumdad@in.ibm.com(Deepshree Majumdar),
SAP: hjayadev@in.ibm.com(Jayadevappa, Harsha), naveenpvk@in.ibm.com(KUMAR, PILLA V),

SAPAPP15
SAPAPP18
SAPAPP19
SAPAPP20

-----------------------------------------------------------------------------------------------------------------------------

12 Dec


CS1285562 BRENNTAG PTE LTD -- BAPDNS Override for V12 and V33
V12	BAPV120400	10.134.3.6	10.8.217.8
V33	BAPV330900	10.134.3.7	10.8.217.13	

157.133.70.36	my346449.crm.ondemand.com	
157.133.70.36	my346449-sso.crm.ondemand.com	



[root@br3psape50 ibmrmalik]$ cat /etc/fstab |grep -i /sapmnt/trans
//10.20.20.175/sapmnt/trans /sapmnt/trans cifs auto,gid=sapsys,file_mode=0775,dir_mode=0775,iocharset=iso8859-15,credentials=/etc/winpass       0       0



CS1286257 Tecnologia De Materiales S.A. -- TDMP2 - MajorMemory Virtual CRITICAL: Free Memory 1.16% (thresh 2:%)TDMDEVHANA



CS1286731 Meggitt PLC -- MGGP2 - MajorMemory Swap CRITICAL: Swap free 47.83% (thresh 50:%)MGGGBJQECCY01


CS1286790	IAG GBS Limited -- IA1	P2 - Major	Service master CRITICAL: 0 master processes running (thresh 1:)	IA1S4HSBXAPP
CS1286913	IAG GBS Limited -- IA1	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.05 (thresh: 16)	IA1S4HPRDDB


CS1287146 Dilip Buildcon Limited -- DLBP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.75 (thresh: 16)DLBPECDB01


CS1287722 Tata Steel BSL Ltd -- BS5P2 - MajorProcessor_load_is_too_high_on_bs5solman.imzcloud.ibmammsap.local[PROBLEM:18968019]BS5SOLMAN
10.141.132.14


CS1287738 Manitoba Telecom Services -- MTSP2 - MajorCPU CPU-Utilization CRITICAL: CPU Usage 99.75% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.25% R3QATAPP



ESX	A0D4US014XVM028	DALTFSSLTD203	10.4.1.197, fe80::250:56ff:fe9f:35f2	Toyota is already out of IBM  
ESX	A0D4US014XVM022	DALTFSWDPP001	10.82.177.191, fe80::250:56ff:fe9f:2125	Toyota is already out of IBM
vHana	daltfssltd202	daltfssltd202	Toyota is already out of IBM
ESX	unqsapbpcqas	unqsapbpcqas	10.4.7.17	check with the account DPE if the account is active or cust left or server decommissioned
ESX	unqsapbpcprd	unqsapbpcprd	10.4.7.16 	check with the account DPE if the account is active or cust left or server decommissioned



CS1288440 Panasonic North America -- PN4P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 23.72 (thresh: 16)PN4USHLECCP1
CS1288414 Panasonic North America -- PN4P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.55 (thresh: 16)PN4USHLECCP1


github and copy Jason Yao  for monitoring threshold changes

-----------------------------------------------------------------------------------
13 Dec

CS1278124 
System NTP Drift CRITICAL: ERROR - chronyc and ntpdate not installed or /etc/ntp.conf does not exist	10.198.201.14


CS1278108
System NTP Drift CRITICAL: ERROR - chronyc and ntpdate not installed or /etc/ntp.conf does not exist	10.198.200.18 



CS1278097 
System NTP Drift CRITICAL: ERROR - chronyc and ntpdate not installed or /etc/ntp.conf does not exist	10.198.200.14


CS1294305	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 53.38 (thresh: 16)	10.207.63.14
CS1293976	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.08 (thresh: 16)	10.207.61.47
CS1294269	COTY Inc. -- CTU	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.54 (thresh: 16)	10.12.10.29

CS1294390	IAG GBS Limited -- IA1P2 - MajorMemory Swap CRITICAL: Swap free 49.63% (thresh 50:%)	10.133.16.37 


CS1294824	BRENNTAG PTE LTD -- BAP	P2 - Major	CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%	BAPV321100	SQ-SAP-TRIO-C1
CS1294752	BRENNTAG PTE LTD -- BAP	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.19 (thresh: 16)	BAPV321100	SQ-SAP-TRIO-C1
CS1294529	BRENNTAG PTE LTD -- BAP	P2 - Major	CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%	BAPV321100	SQ-SAP-TRIO-C1


PTPHalimun	10.70.30.156	192.168.166.156	



CS1295500 Panasonic North America -- PN4P1 - SevereHost Reboot CRITICAL: Uptime 8 minutes (thresh 60 min)PN4US7LMIIP1
reboot   system boot  4.4.121-92.109-d Fri Dec 13 04:50 - 05:28  (00:37)


CS1295657 Panasonic North America -- PN4P2 - MajorLog PaceMaker-stonith-ng Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-13-04-57-33 for details.PN4USHLMIIP1	10.12.254.42
CS1295493 Panasonic North America -- PN4P2 - MajorService Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)PN4US7LMIIP1
CS1295491 Panasonic North America -- PN4P2 - MajorService pacemaker.service CRITICAL: pacemaker.service is inactive (dead)PN4US7LMIIP1
CS1295488 Panasonic North America -- PN4P2 - MajorService Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)PN4US7LMIIP1
CS1295523 BRENNTAG PTE LTD -- BAPP2 - MajorCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%BAPV321100

---------------------------------------------------------------------------------------------------------

14 Dec


SAPAPP15	10.207.61.37
SAPAPP18	10.207.61.70
SAPAPP19	10.207.61.215
SAPAPP20	10.207.61.195




che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.207.61.77,local_lock=none,addr=146.89.142.94 0 0

-----------------------------------------------------------------------------------------------------------------------------

15 Dec

ARMFKSAP301A1	10.7.102.62	Production                         GWP SAP system (Cluster application - node 1)
ARMFKSAP301AP	10.7.102.64	Production                         GWP SAP system (Cluster application - node 2)

ON servers with Pacemaker cluster after the apps are down, run the below to stop the resources

Stop cluster gracefully on both nodes (stopping all resources) -> /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --stop-pacemaker-both-gracefull

After patching, reboot the server and run the below to start the pacemaker and other resources

Start cluster along with resources  -> /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --start-pacemaker-both-maintenanceoff

Alternatively
 Start cluster along with resources  -> each node one at a time
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --start-pacemaker-currentnode-maintenanceoff
once all resource started (wait for 2 min )
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --start-pacemaker-othernode-maintenanceoff


1. Stop PAS/AAS
2. Stop cluster gracefully on both nodes (stopping all resources)
3. Patch both nodes
4. Start cluster along with resources
5. Start PAS/AAS


crm_mon -1Afr
crm resource cleanup mountfs-inter
crm resource cleanup <error component found in the error in above command>



CS1315164	Arnoldo Mondadori Editore SpA -- ARM	ARM	ARM IC4SAP-SL SAP LOB	Incident	P1 - Severe	New		Host Reboot CRITICAL: Uptime 2 minutes (thresh 60 min)	SQ-SAP-TRIO-C2
CS1315211	Arnoldo Mondadori Editore SpA -- ARM	ARM	ARM IC4SAP-SL SAP LOB	Incident	P1 - Severe	New		Host Reboot CRITICAL: Uptime 2 minutes (thresh 60 min)	SQ-SAP-TRIO-C2




CS1315488	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.20 (thresh: 16)	TSLBWPRDDB	10.207.61.200
CS1315371	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.36: rta nan, lost 100%	TSCMLPRD
CS1315335	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.41: rta nan, lost 100%	TSGPPRD	10.207.61.41

-------------------------------------------------------------------------------------------------

16 Dec


br3qfioas35	10.138.10.94	cannot login, root pw locked in PIM
br3ssolas12	10.3.112.125	fixed
br3ssapas10	10.138.10.68	fixed
br3ssapdb10	10.140.158.249	fixed
br3ssoldb11	10.140.158.244	fixed
br3dgtsdb55	10.140.158.240	fixed



CS1322402	St. Jude Medical  -- JUE	JUE	JUE St. Jude Medical SAPHEC-IC4SAP-SL	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.63 (thresh: 16)	10.211.0.20
CS1322744	St. Jude Medical  -- JUE	JUE	JUE St. Jude Medical SAPHEC-IC4SAP-SL	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.00 (thresh: 16)	10.211.0.20
CS1319630	St. Jude Medical  -- JUE	JUE	JUE St. Jude Medical SAPHEC-IC4SAP-SL	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 28.60 (thresh: 16)	10.211.0.20
CS1320843	St. Jude Medical  -- JUE	JUE	JUE St. Jude Medical SAPHEC-IC4SAP-SL	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 28.34 (thresh: 16)	10.211.0.20


CS1332711	Computer Systems Integration Ltd -- CSY	P2 - Major	Memory Virtual CRITICAL: Free Memory 1.98% (thresh 2:%)	10.197.2.30
CS1332389	Arnoldo Mondadori Editore SpA -- ARM	P3 - Minor	Disk Utilization /var/log CRITICAL: Free 370.23MB/19.74% (thresh @10.01:20%)	

CS1332725	AGEAS -- AGE	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.6.1.30
CS1332693	AGEAS -- AGE	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.6.1.30
CS1332707	AGEAS -- AGE	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1332841	LSPI -- LSP	P2 - Major	Drive-Space C critical(OK: Drive C: has 4.074GB of 59.655GB)

-------------------------------------------------------------------------------------------------------------------

18 Dec


CS1296743	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.65 (thresh: 16)
CS1296740	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.47 (thresh: 16)

Host Name	       IFN IP	                 Asset Purpose             SAP system
ARMFKSAP303A1	10.7.102.57	Production                      ECP SAP system (Cluster application - node 1)
ARMFKSAP303AP	10.7.102.59	Production                      ECP SAP system (Cluster application - node 2)


CS1335034	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1335033	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))


svjq1srv0	10.6.2.12	A0EASG014XVM004
 CHG0136274  


CS1328020


CS1335295	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.03 (thresh: 16)



CS1334930  Inter Pipeline Fund -- IPLP3 - MinorSAP HEC SWIVEL:P3: Add IPL hostname


RCA PN4
/etc/systemd/system.conf
DefaultTasksMax=65536
systemctl daemon-reload  

2:50:14 PM: In corosync config - 

Token - 30000
Consensus - 36000

https://www.suse.com/pt-br/support/kb/doc/?id=7017597

------------------------------------------------------------------------------

19 Dec

CS1338988 PT Anugerah Pharmindo Lestari -- PTPP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.40 (thresh: 16)


CS1339293	AGEAS -- AGE	P2 - Major	Uptime System-Rebooted CRITICAL: uptime: 0:4m, boot: 2019-12-19 02:47:51 (UTC)
The process C:\Windows\Explorer.EXE (SVMQ1SRV0) has initiated the restart of computer SVMQ1SRV0 on behalf of user SVMQ1SRV0\trootech for the following reason: Other (Unplanned)
 Reason Code: 0x0
 Shutdown Type: restart
 Comment: 

CS1339297	AGEAS -- AGE	P2 - Major	Uptime System-Rebooted CRITICAL: uptime: 0:4m, boot: 2019-12-19 02:47:51 (UTC)



IPLSAS4AT01	10.138.3.11	10.11.3.12	


CS1340385 Tata Steel Limited -- TTAP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.06 (thresh: 16) 
----------------------------------------------------------------------------------------------------------------------------------

21 Dec

CS1363122 Arnoldo Mondadori Editore SpA -- ARMP1 - SevereZabbix_agent_on_armfkdr305a1.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:19352530]
10.14.105.18
[root@armfkdr305a1 ibmrmalik]$ chage -l root
You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required


CS1362930	BRENNTAG PTE LTD -- BAP	P2 - Major	CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%
CS1362783	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.95 (thresh: 16)
CS1362968	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.36 (thresh: 16)
CS1363083	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.18 (thresh: 16)
CS1363279	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.96 (thresh: 16)
CS1363379	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.06 (thresh: 16)
CS1363043	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.43 (thresh: 16)
CS1363331	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.61 (thresh: 16)
CS1363447	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.45 (thresh: 16)
CS1362818	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.11 (thresh: 16)
CS1363000	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.28 (thresh: 16)
CS1363090	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.65 (thresh: 16)
CS1363286	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.93 (thresh: 16)
CS1362955	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.37 (thresh: 16)
CS1363056	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.01 (thresh: 16)
CS1363252	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.49 (thresh: 16)
CS1363378	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.56 (thresh: 16)
CS1363450	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.61 (thresh: 16)
CS1362821	Panasonic North America -- 10.12.254.94	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.36 (thresh: 16)
CS1363014	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.16 (thresh: 16)
CS1363135	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.59 (thresh: 16)
CS1363307	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.33 (thresh: 16)



top - 22:33:52 up 40 days, 51 min, 14 users,  load average: 0.54, 4.97, 6.38
Tasks: 728 total,   2 running, 726 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1.9 us,  1.0 sy,  0.0 ni, 95.7 id,  1.2 wa,  0.0 hi,  0.2 si,  0.0 st
KiB Mem:  66990356 total, 54505548 used, 12484808 free,   262332 buffers
KiB Swap: 37748732 total,    10220 used, 37738512 free. 44866084 cached Mem



CS1363316	AGEAS -- AGE	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)) 


CS1363814	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.01 (thresh: 16)
-------------------------------------------------------------------------------------------------------------------------------

24 Dec

CS1381308	Bombardier Recreational Products Inc -- BR3	P1 - Severe	Disk Utilization /var CRITICAL: Free 37.82MB/0.68% (thresh @0:5%)


CS1381830	CMA CGM -- CMA	P3 - Minor	Disk Utilization /var CRITICAL: Free 741.43MB/13.19% (thresh @10.01:20%)




sapapp22 10.170.61.231(CFN)/10.207.61.63(IFN) 



CS1381945	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.60 (thresh: 16)


CS1383142 IAG - British Airways -- IA2P1 - SevereDisk Utilization /var CRITICAL: Free 277.60MB/4.95% (thresh @0:5%)



CS1382741 -IAG GBS Limited - IA1 -Disk Utilisation Is High 87%_IA1OTASPRDA


CS1382525	Egyptian Cement -- ECT	P2 - Major	Memory Swap CRITICAL: Swap free 49.89% (thresh 50:%)
CS1383417	CMA CGM -- CMA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.13 (thresh: 16)



CS1382717  Bombardier Recreational Products Inc -- BR3P2 - MajorData Migration App Server Down



crm configure property maintenance-mode=true

crm node online br3qgtsdb37


create logs under /sapmnt/data, move logsegment "hdb00002.00003" from /sapmnt/log to new created folder
Create symbolic link & start DB


ln -s  /sapmnt/data/logs/hdb00001 /sapmnt/log/QGT/mnt00001/hdb00001 

Remove the symbolic link:

rm -f /hana/log/<SID>/mnt00001/hdb00003

----------------------------------------------------------------------------------------------

25 Dec

CS1386055	Bombardier Recreational Products Inc -- BR3	BR3	BR3 SAPHEC-IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Disk Utilization /sapmnt/log CRITICAL: Free 16218.46MB/6.19% (thresh @5.01:10%)	SQ-SAP-TRIO-C1
CS1385556	Controladora De Negocios -- CNG	CNG	CNG AMM-SAP SAP LOB	Incident	P2 - Major	New		Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	SQ-SAP-TRIO-C1 


CS1386128	Delta Airlines -- DAL	DAL	DAL SAP HEC-AMM SAP LOB	Incident	P3 - Minor	New		FS_is_read_only_on_dlthmehap14.imzcloud.ibmammsap.local[PROBLEM:19540131]	SQ-SAP-TRIO-C2


CS1376313 - LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.182/nrdp


bs5prdapp1:/backup/logbackup_2     /logbackup2        nfs     defaults,nfsvers=3      0 0
bs5prdapp1:/backup/dbbackup_2     /dbbackup2        nfs     defaults,nfsvers=3      0 0

-----------------------------------------------------------------------------------------------------------------

27 Dec

CS1404808	St. Jude Medical , USA -- JUE	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 36.13 (thresh: 16)
CS1405004	St. Jude Medical , USA -- JUE	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.83 (thresh: 16)
CS1404522	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Processor_load_is_too_high_on_ptpbromo.imzcloud.ibmammsap.local[PROBLEM:19680084]

CS1405408	Bumrungrad Hospital Plc -- BUM	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.54 (thresh: 16)
CS1405630	Panasonic North America -- PN8	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.12 (thresh: 16)


CS1405732	Controladora De Negocios -- CNG	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1405729	10.4.5.27	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 194.238MB (200MB), total 194.238MB (200MB)
CS1405730	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1404512	Delta Airlines -- DALP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)


CS1406191	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1406189	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))



CS1406743	Controladora De Negocios -- 10.68.210.25	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1406514	Controladora De Negocios -- 10.68.210.25	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1406660	Controladora De Negocios -- 10.68.210.25	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1406352	Controladora De Negocios -- 10.68.210.25	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1406739	Controladora De Negocios -- CNG	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)

CS1406758	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))


CS1406809	Delta Airlines -- 10.4.5.27	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.953MB (200MB), total 199.953MB (200MB)
CS1406808	Delta Airlines -- 10.4.5.27 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.969MB (200MB), total 199.969MB (200MB))


Host : SVSD1SRV0 (10.6.1.26)	SVSD1SRV0	10.6.1.26	10.92.99.125	A0EASG014XVM014
500 GB need to be as /sapstage			/dev/temp_ss/sapstage_lv

[root@svsd1srv0 sapstage]$ lvdisplay |grep -i sapstage_lv
  LV Path                /dev/tempss/sapstage_lv
  LV Name                sapstage_lv


Host: agesvsd1srv01
200 GB as /sapstage  	/sapstagetemp	

[root@agesvsd1srv01 ibmrmalik]# lvdisplay |grep -i sapstage_lv
  LV Path                /dev/temp_ss/sapstage_lv
  LV Name                sapstage_lv



CS1407631	Panasonic North America -- 10.12.255.149	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.01 (thresh: 16)

CS1407560	Delta Airlines -- DAL	10.4.5.27	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1407730	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1407448	Delta Airlines -- DAL	10.4.5.27	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1407729	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1407262	Controladora De Negocios -- CNG	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.68.210.25
CS1407801	Controladora De Negocios -- CNG	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	10.68.210.25
CS1407803	Controladora De Negocios -- CNG	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)) 10.68.210.25


CS1408348	Panasonic North America -- PN4P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.65 (thresh: 16)PN4USHLECCP1 


CS1407476	MSC Industrial Supply Co. -- MS3	MDCSERVERP2DR	10.196.5.16	Ping Availability CRITICAL - 10.196.5.16: rta nan, lost 100%	
CS1407402	MSC Industrial Supply Co. -- MS3	MDCSERVERP1DR	10.196.5.15	172.17.157.15 P2 - Major	Ping Availability CRITICAL - 10.196.5.15: rta nan, lost 100%	dal09-p4-phana-1024-1.imzcloud.ibmammsap.local

---------------------------------------------------------------------------------------------------------------------------------------

28 Dec

CS1417662	Apple Leisure Group -- AV1	P2 - Major	Ping Availability CRITICAL - 10.68.213.12: Host unreachable @ 10.143.69.196. rta nan, lost 100%
CS1417934	BRENNTAG PTE LTD -- BAP	P2 - Major	Processor_load_is_too_high_on_bapv120400.imzcloud.ibmammsap.local[PROBLEM:19764458]



CS1418364	Bumrungrad Hospital Plc -- BUM	P2 - Major	Processor_load_is_too_high_on_bumsapwebd01t.imzcloud.ibmammsap.local[PROBLEM:19766895] 


CS1418412	BRENNTAG PTE LTD -- BAPP2 - MajorProcessor_load_is_too_high_on_bapv590800.imzcloud.ibmammsap.local


CS1419023	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-stonith-ng Found 12 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-46-07 for details.	BUMSAPH4P02P
CRITICAL Errors in corosync.log (tag 2:CRITICAL_PaceMaker-stonith-ng)



CS1419004	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-crmd Found 21 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-43-54 for details.	BUMSAPH4P01P
Node bumsaph4p01p:
* Node bumsaph4p02p:


CS1418950	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-stonith-ng Found 108 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-35-58 for details.	BUMSAPH4P02P
CS1418932	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-stonith-ng Found 108 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-33-41 for details.	BUMSAPH4P01P
CS1418894	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-crmd Found 21 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-28-37 for details.	BUMSAPH4P01P
CS1418828	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-stonith-ng Found 32 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-11-02 for details.	BUMSAPH4P02P
CS1418755	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-crmd Found 21 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-13-40 for details.	BUMSAPH4P01P
CS1418753	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-stonith-ng Found 88 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2019-12-28-16-13-40 for details.	BUMSAPH4P01P


CS1420172	Apple Leisure Group -- AV1P1 - SevereZabbix_agent_on_USSAPAWD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:19774353]USSAPAWD
USSAPAWD(A0ETUS014XVM002)  dal09cluster023
us016bca086

------------------------------------------------------------------------------------------------------------------------

31 Dec


handvh4psrv08   10.15.193.57    , DF hung on this server. Request OS assistance to check NFS mounts on this server - CS1446972
statfs("/interface/SAP_PO_FTP",

 cat /etc/fstab |grep -i /interface/SAP_PO_FTP
10.187.123.157:/interface/SAP_PO_FTP /interface/SAP_PO_FTP nfs vers=4  0       

------------------------------------------------------------------------------------------------------------\\
1-Jan 2020

I read this 
http://list.linux-vserver.org/archive/vserver/msg06663.html
and applied :
comment out pam_limits.so from both /etc/pam.d/sshd and
/etc/pam.d/system-auth. 
seems work better 



bs5prdapp1 is being migrated from che01pool1ds322 to che01pool1ds323 in Chennai DC -needs monitoring. This is done to free up the over provisioned dtastore, Migration activity is very slow as teh VM size is huge. It is progressing at ~4% per hour.Will be required to HO to India shift tomorrow morning if not finished

------------------------------------------------------------------------------------------------------------------

2 Jan

CS1466713	BRENNTAG PTE LTD -- BAP	P2 - Major	Processor_load_is_too_high_on_bapv330900.imzcloud.ibmammsap.local[PROBLEM:20063109]	BAPV330900


CS1461786 BQ1 (HANADB)|HDB_STATUS_OF_LOG_BACKUP_ALRT_38|Status of the Most Recent Log Backup , AGESVBQ1HSRV1 	10.6.2.70
agesvbq1hsrv1:/opt/tivoli/tsm/client/ba/bin # /opt/tivoli/tsm/tdp_hana/prole -p tdphana &
[1] 7173
agesvbq1hsrv1:/opt/tivoli/tsm/client/ba/bin # BKI2004E: Socket error while listen to port tdphana - error: Address already in use.



CS1468155 Tata Steel Limited -- TTAP3 - MinorServer : Sales order and money receipt file not available from Tata SteelSAPAPP22

CS1469086 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var CRITICAL: Free 91.43MB/1.21% (thresh @0:5%)SAPAPP23
CS1469075 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)SAPAPP23
CS1469065 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var CRITICAL: Free 173.57MB/2.30% (thresh @0:5%)SAPAPP23



Success! Your new IBM Notes temporary password is:
742a31efe304484

------------------------------------------------------------------------------

3 Jan

CS1477868 Apple Leisure Group -- AV1P1 - SevereZabbix_agent_on_USSAPAWD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:20118385]USSAPAWD
CS1477866 Apple Leisure Group -- AV1P1 - SevereZabbix_agent_on_USSAPAWD.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:20118385]USSAPAWD


CS0420804
the FTP login issue is occurring for me and colleague too.
we are login from Dev System.
am3s4devap01	10.70.22.20	10.65.22.20

User : SAP01
FTP Host : 172.16.10.110 21

We are trying to access FTP client from SAP standard functions but we are not able to connect. it was working and connecting few days back but now it is not. it gives error "user has no access authorization for computer ftp sap" .

 can you please help to check on FTP connection from SAP system.
AM3S4DEVAP01	10.70.22.20	10.65.22.20	

Name        : fuse-sshfs
Arch        : x86_64
From repo   : epel
The package isn't provided from our official IBM repositories so I have to check if it is allowed by IBM for installation.


CS1477527	Server was hung, raised a case with RHEL vide 02552300 	PBBS4HQAP00	10.6.7.14	172.25.1.14	SNG	
/tmp/sosreport-rmalik.02552300-20200103205831.tar.xz
https://access.redhat.com/support/cases/#/case/02552300

CS1479801 PT Blue Bird TBK -- PBBP1 - SevereHost Reboot CRITICAL: Uptime 3 minutes (thresh 60 min)PBBS4HQAP00


SVFS1SRV0  snapshot  CHG0136951


CS1472000	WDC
Please create temporary File system /tmp/backups for 500GB on pn4us7leccd1(10.12.254.89)	10.12.254.89	10.142.41.94  bkptmpvg bkptmp_lv
and nfs mount on to Pn4us7leccq1(10.12.254.159) , pn4us7leccp1 (10.12.254.14) and pn4ushleccp1(10.12.254.16)

10.142.41.94:/tmp/backups /tmp/backups nfs _netdev,defaults 0 0

Please create temporary File system /tmp/backups for 500GB on pn4us7lewmd1(10.12.254.120) 	10.12.254.120	10.142.41.99  bkptmpvg bkptmp_lv	
and nfs mount on to pn4us7lewmq1(10.12.254.160), pn4us7lewmp1(10.12.254.20) and pn4ushlewmp1(10.12.254.40)

vgcreate bkptmpvg /dev/sdX (PV)
lvcreate -L 505G -n bkptmp_lv bkptmpvg
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab

/dev/mapper/bkptmpvg-bkptmp_lv  500G   70M  475G   1% /tmp/backups



CHG0136992, CTASK0160766 for VM snapshot for SVJD1SRV0
----------------------------------------------------------------------------------------------------------

5 Jan

CHG0136612
MS3WDCLADB13	10.12.6.29	Development
10.12.6.29	172.17.154.29	WDC
[root@ms3wdcladb13 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ms3wdcladb13 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Jan  5 01:42:52 UTC 2020
ZONE=UTC
OK
PhillipPayne	HermiloRabago	

[root@ms3wdcladb13 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ms3wdcladb13 2.6.32-754.25.1.el6.x86_64 #1 SMP Wed Nov 20 15:07:26 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Sun Jan  5 02:47:48 UTC 2020
ZONE=UTC
OK




------------------------------------------------------------------------------------------------------------------------

6 Jan

CS1504527	Controladora De Negocios -- CNG	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	10.68.210.25
CS1504492	Delta Airlines -- DAL	10.4.5.27	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1504494	Delta Airlines -- DAL	10.4.5.27	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1504801	AGEAS -- AGE	10.6.2.41	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1504800	AGEAS -- AGE	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))

CS1504947	Controladora De Negocios -- CNG	10.68.210.25	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.695MB (200MB), total 199.695MB (200MB)
CS1504950	Controladora De Negocios -- CNG	10.68.210.25	Perfdata Virtual critical(\??\C:\pagefile.sys 199.215MB (200MB), total 199.215MB (200MB))
CS1505013	Delta Airlines -- DAL	10.4.5.27	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))



CS1505271	Delta Airlines -- DAL	10.4.5.27	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 197.465MB (200MB), total 197.465MB (200MB)
CS1505270	Delta Airlines -- DAL	10.4.5.27	Perfdata Virtual critical(\??\C:\pagefile.sys 197.383MB (200MB), total 197.383MB (200MB))
CS1505267	Controladora De Negocios -- CNG	10.68.210.25	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1505268	Controladora De Negocios -- CNG	10.68.210.25	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))



CS1506286
AGESVBPPHSRV1	10.6.3.60	10.70.111.61
[root@agesvbpphsrv1 tdp_hana]$ /opt/tivoli/tsm/tdp_hana/prole -p tdphana &
[1] 31694
[root@agesvbpphsrv1 tdp_hana]$ BKI2004E: Socket error while listen to port tdphana - error: Address already in use.


CS1506206	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.210: rta nan, lost 100%




[root@agesvbpphsrv1 system]$ ps axo stat,ppid,pid,comm | grep -w defunct
Z     9290  9333 xinitrc <defunct>
[root@agesvbpphsrv1 system]$ ps -ef | grep defunct | more
root      9333  9290  0  2019 ?        00:00:00 [xinitrc] <defunct>
root     28490 12498  0 15:52 pts/4    00:00:00 grep --color=auto defunct


[root@agesvbpphsrv1 system]$ lsof -i :57321
COMMAND     PID   USER   FD   TYPE     DEVICE SIZE/OFF NODE NAME
hdbnamese 29292 bppadm *026u  IPv4 1595276390      0t0  TCP localhost:tdphana->localhost:30601 (ESTABLISHED)
hdbnamese 29292 bppadm *496u  IPv4 1595255568      0t0  TCP localhost:30601->localhost:tdphana (ESTABLISHED)

----------------------------------------------------------------------------------------------------------------------

Tue Jan 07 08:46:31 IST 2020 


CS1515348	Delta Airlines -- DAL	10.4.5.27	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 198.969MB (200MB), total 198.969MB (200MB)
CS1515221	Delta Airlines -- DAL	10.4.5.27	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 193.105MB (200MB), total 193.105MB (200MB)
CS1514448	LSPI -- LSP	10.4.2.12	Perfdata Virtual critical(\??\C:\pagefile.sys 186.039MB (200MB)), \??\X:\pagefile.sys 3.885GB (4.75GB), total 4.067GB (4.945GB)
CS1515261	Controladora De Negocios -- CNG	10.68.210.25	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))


CS1515559	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.62 (thresh: 16)

CS1516223	Panasonic North America -- PN8	P2 - Major	Memory Swap CRITICAL: Swap free 49.66% (thresh 50:%) 


CS1516601	Delta Airlines -- DAL	10.4.5.27 	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1516415	Controladora De Negocios -- CNG	10.68.210.25 	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1516588	Controladora De Negocios -- CNG	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1516589	Controladora De Negocios -- CNG	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)


CS1516906	Tata Steel Limited -- TTA	10.207.61.200 	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.29 (thresh: 20)
CS1516690	Tata Steel Limited -- TTA	 10.207.61.200 	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.12 (thresh: 20)
CS1516836	Tata Steel Limited -- TTA	10.207.61.200	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.54 (thresh: 20)



tor01-pod1-4tb-host01
10.114.60.252
TWYSAPDH1DB2
root pw lD00Nr%wTjXEwp@
IPMI  Qa8a4fnK2x

MIPS4QASDB 	10.7.96.62	10.95.1.62
default pw for system Ready4Hana




TRES4PRDDB 	10.7.15.65	172.24.44.149
Password for SYSTEM user in S4P of S4P is required
------------------------------------------------------------------------------------------------------
Wed Jan 08 06:37:59 IST 2020 


CS1524280	1	C1-C2	PN4 	N/A	add space  50gb to FS /db2/MD1/log_dir on MD1-10.12.254.120
[root@pn4us7lewmd1 ibmrmalik]$ df -h /db2/MD1/log_dir
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/md1logvg-md1db2logdirlv   99G   65G   30G  69% /db2/MD1/log_dir
[root@pn4us7lewmd1 ibmrmalik]$ vgs md1logvg
  VG       #PV #LV #SN Attr   VSize   VFree
  md1logvg   3   4   0 wz--n- 147.99g 42.99g




---- Begin output of chage -l sapadm ----
STDOUT:
STDERR: You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required
---- End output of chage -l sapadm ----
Ran chage -l sapadm returned 1
[2020-01-07T20:57:42-05:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
[root@ralpbidb ibmrmalik]#




---- Begin output of chage -l sapadm ----
STDOUT:
STDERR: You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required
---- End output of chage -l sapadm ----
Ran chage -l sapadm returned 1
[2020-01-08T01:51:06+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)




Running handlers:
[2020-01-07T20:49:32-05:00] INFO: Running report handlers
WARN: Unresolved specs during Gem::Specification.reset:
      thor (~> 0.19)
WARN: Clearing out unresolved specs.
Please report a bug if this causes problems.
[2020-01-07T20:49:37-05:00] INFO: Using InSpec 1.51.25
[2020-01-07T20:49:38-05:00] WARN: No audit tests are defined.
[2020-01-07T20:49:38-05:00] ERROR: Audit report was not generated properly, skipped reporting
  - Chef::Handler::AuditReport
Running handlers complete
[2020-01-07T20:49:38-05:00] INFO: Report handlers complete
Chef Client finished, 51/1160 resources updated in 04 minutes 44 seconds
[root@wkfpr1db01 ibmrmalik]


 * ruby_block[sapadm_password_never_expire] action run[2020-01-07T22:05:50-05:00] INFO: Processing ruby_block[sapadm_password_never_expire] action run (sap_hana::sap_hana_os_users line 53)
[2020-01-07T22:05:50-05:00] INFO: Retrying execution of ruby_block[sapadm_password_never_expire], 2 attempt(s) left
[2020-01-07T22:06:50-05:00] INFO: Retrying execution of ruby_block[sapadm_password_never_expire], 1 attempt(s) left



Running handlers complete
[2020-01-08T04:23:42+01:00] ERROR: Exception handlers complete
Chef Client failed. 31 resources updated in 02 minutes 51 seconds
[2020-01-08T04:23:44+01:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2020-01-08T04:23:44+01:00] FATAL: Please provide the contents of the stacktrace.out file if you file a bug report
[2020-01-08T04:23:44+01:00] ERROR: hana_encryption[MM0_QM0] (sap_hana_encryption::default line 405) had an error: SapHanaEnc::DatabaseConnectionError: SAP HANA SID MM0, tenant QM0 connectivity check failed. Check user/password for user store key MM0AUTOMATIONQM0 is correct. Run python automation to check and/or fix. Instructions provided here 'https://github.ibm.com/CMS/cms-sq-sap-hana-pe-automation_hana/wiki/Operations:-check-create-adjust-hana-users' Details: SID=MM0, INSTANCE_NUM=59, TENANT=QM0, ADMIN_KEY=MM0AUTOMATIONQM0, error_code=10, error_message=authentication failed, error_details=
[2020-01-08T04:23:44+01:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
[root@bacfrab4db057 ibmrmalik]#




Cannot connect with AUTOMATION user to the SYSTEMDB of ND1 system.
Cannot connect with BACKUP user to the SYSTEMDB of ND1 system.
[root@ndcdmdev01 ibmrmalik]#



Cannot connect with AUTOMATION user to the QM0 tenant of MM0 system.
[root@bacfrab4db057 ibmrmalik]#



CS1525387	Bombardier Recreational Products Inc -- BR3	P2 - Major	LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp
pacemaker down

BR3QSAPDB30 	10.138.10.90
Online: [ br3qsapdb30 ]
OFFLINE: [ br3qsapdb31 ]


[root@br3qsapdb31 ibmrmalik]$ cat /etc/sysconfig/sbd | grep DEVICE
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
SBD_DEVICE="/dev/mapper/sbddisk1"



su - s4padm -c "hdbnsutil -sr_register --remoteHost=br3qsapdb30 --remoteInstance=30 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEB"  



CS1526399	IAG - British Airways -- IA2	P2 - Major	Memory Virtual CRITICAL: Free Memory 1.69% (thresh 2:%) 



CS1526781	Bombardier Recreational Products Inc -- BR3	P2 - Major	Resource Pacemaker Active Nodes CRITICAL: CLUSTER OK: 1 node online, 1 standby node, 7 resources configured (thresh 2:2)

CS1527391	COTY Inc. -- CTU	P2 - Major	CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=4.00% iowait=0.00% idle=0.00%

-------------------------------------------------------------------------------------------------------

9 Jan


CS1536317	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Processor_load_is_too_high_on_ptpbromo.imzcloud.ibmammsap.local[PROBLEM:20401027]


Chef Client failed. 9 resources updated in 44 seconds
[2020-01-08T21:49:20-05:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2020-01-08T21:49:20-05:00] FATAL: Please provide the contents of the stacktrace.out file if you file a bug report
[2020-01-08T21:49:20-05:00] ERROR: remote_file[/root/clientSetup4SMT.sh] (smt::configure_client line 16) had an error: SocketError: Error connecting to http://mon01ammsmt01.imzcloud.ibmammsap.local/repo/tools/clientSetup4SMT.sh - Failed to open TCP connection to mon01ammsmt01.imzcloud.ibmammsap.local:80 (getaddrinfo: Temporary failure in name resolution)
[2020-01-08T21:49:20-05:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)


CS1537138	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/lib/mysql CRITICAL: Free 1993.76MB/6.56% (thresh @5.01:10%)
CS1537169	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization / CRITICAL: Free 1961.52MB/6.45% (thresh @5.01:10%)
CS1537108	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /home CRITICAL: Free 5060.53MB/16.65% (thresh @10.01:20%)
CS1537142	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/log CRITICAL: Free 1997.70MB/6.57% (thresh @5.01:10%)
CS1537139	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/tmp CRITICAL: Free 1993.76MB/6.56% (thresh @5.01:10%)
CS1537109	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/lib/mariadb CRITICAL: Free 5060.53MB/16.65% (thresh @10.01:20%)
CS1537146	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/lib/mailman CRITICAL: Free 1981.44MB/6.52% (thresh @5.01:10%)
CS1537141	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/opt CRITICAL: Free 1997.70MB/6.57% (thresh @5.01:10%)
CS1537282	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/lib/pgsql CRITICAL: Free 5246.16MB/17.26% (thresh @10.01:20%)


CS1537801	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.38 (thresh: 16)


CS1538892	AGEAS -- AGE	P2 - Major	Uptime System-Rebooted CRITICAL: uptime: 0:4m, boot: 2020-01-09 05:32:26 (UTC)



SYSTEM password for tenant GT4 of GT4 system
Lindt Sprungli (International) AG 	INTSV004 	10.7.217.25	10.30.217.46 	






 SYSTEM password for tenant GP4 of GP4 system
Lindt Sprungli (International) AG 	INTSV001 	10.7.216.18	10.30.216.19



stat("/CQ4export", ^C
[root@pn8us7leccq4 ibmrmalik]# cat /etc/fstab |grep -i /CQ4export
10.136.33.26:/export /CQ4export nfs nfsvers=3 0 0



default pw for system Ready4Hana
    SYSTEM    SAPibm#1
----------------------------------------------------------------------------------------------------------------------------------------

Sat Jan 11 08:00:54 IST 2020 


CS1560967	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Free_disk_space_is_less_than_5%_on_volume_/usr/local[PROBLEM:20512370]
CS1560966	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:20512369]

CS1560117	BRENNTAG PTE LTD -- BAP	P2 - Major	Processor_load_is_too_high_on_bapv590800.imzcloud.ibmammsap.local[PROBLEM:20510103]
CS1560930	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/lib/mysql CRITICAL: Free 2021.00MB/6.65% (thresh @5.01:10%)
CS1560936	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/log CRITICAL: Free 2021.00MB/6.65% (thresh @5.01:10%)
CS1560933	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /tmp CRITICAL: Free 2021.00MB/6.65% (thresh @5.01:10%)
CS1560931	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/lib/machines CRITICAL: Free 2021.00MB/6.65% (thresh @5.01:10%)
CS1560966	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Free_disk_space_is_less_than_5%_on_volume_/var/log[PROBLEM:20512369]
CS1560929	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/opt/BESClient CRITICAL: Free 2021.00MB/6.65% (thresh @5.01:10%)
CS1560934	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/spool CRITICAL: Free 2034.17MB/6.69% (thresh @5.01:10%)
CS1560846	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Processor_load_is_too_high_on_ptpbromo.imzcloud.ibmammsap.local[PROBLEM:20512177]
CS1560932	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/opt CRITICAL: Free 2021.00MB/6.65% (thresh @5.01:10%)
CS1560968	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Free_disk_space_is_less_than_10%_on_volume_/var/log[PROBLEM:20512371]

CS1561012	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Disk Utilization /var/lib/mariadb CRITICAL: Free 1250.71MB/4.11% (thresh @0:5%)
CS1561016	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Disk Utilization /var/crash CRITICAL: Free 1236.81MB/4.07% (thresh @0:5%)
CS1561013	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Disk Utilization /var/lib/machines CRITICAL: Free 1238.32MB/4.07% (thresh @0:5%)
CS1561018	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Disk Utilization /var/cache CRITICAL: Free 1238.32MB/4.07% (thresh @0:5%)
CS1561015	PT Anugerah Pharmindo Lestari -- PTP	P1 - Severe	Disk Utilization /var/opt/BESClient CRITICAL: Free 1236.81MB/4.07% (thresh @0:5%)


CS1561014PT Anugerah Pharmindo Lestari -- PTPP1 - SevereDisk Utilization /var/lib/mysql CRITICAL: Free 1236.81MB/4.07% (thresh @0:5%)


CS1562021	Tata Steel Limited -- TTA	P2 - Major	Disk Utilization /usr CRITICAL: Free 946.87MB/10.00% (thresh @5.01:10%)

CS1562334 Tata Steel Limited -- TTAP2 - MajorDisk Utilization /usr CRITICAL: Free 946.88MB/10.00% (thresh @5.01:10%) 


CS1562647 Delta Airlines -- DALP2 - MajorDisk Utilization /interfaces/HPE CRITICAL: Free 43126.41MB/9.98% (thresh @5.01:10%) 


CS1564072	LSPI -- LSP	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB)), \??\X:\pagefile.sys 3.328GB (4.75GB), total 3.523GB (4.945GB)
CS1564073	LSPI -- LSP	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), \??\X:\pagefile.sys 3.328GB (4.75GB), total 3.523GB (4.945GB)

----------------------------------------------------------------------------------------------------------------------

Tue Jan 14 06:39:56 IST 2020 

CS1243366 - Standard SSH protocol not working / verify LDAP
Pending run the filesystem check to recover some root partitions.
The recovery disk must be mounted to fix the partitions corrupted

	
iplsadsad01	10.138.2.22  Pending Deactivation		
iplsas4at01	10.138.3.11     correct imz ip is 10.138.3.12		
iplsadsdp01	10.138.1.26  Pending Deactivation 		
iplsatxad01	10.138.1.27	correct imz ip is 10.138.2.27	
iplsautlp01	10.138.1.33	Windows box connecting fine	
iplsadiad01	10.138.2.29  Pending Deactivation	

STATE HOSTNAME Documented IP's Findings
Pending Deactivation IPLSADSAD01 10.138.2.22 It doesn't exist in the vCenter (Montreal)
Deployed IPLSAS4AT01 10.138.3.11 IP configured: 10.138.3.12
Pending Deactivation IPLSADSDP01 10.138.1.26 The vm is powered off in the vCenter (Montreal)
Deployed IPLSATXAD01 10.138.1.27 IP configured: 10.138.2.27
Deployed IPLSAUTLP01 10.138.1.33 Windows Server 2012 R2 - vm up and running
Pending Deactivation IPLSADIAD01 10.138.2.29 In Single User Mode to recover run file system check

--------------------------------------------------------------------------------------------------------------

15 Jan


CS1609882	AGEAS -- AGE	P2 - Major	Uptime System-Rebooted CRITICAL: uptime: 0:4m, boot: 2020-01-15 02:45:29 (UTC)
CS1609918	Tecnologia De Materiales S.A. -- TDM	P2 - Major	Memory Swap CRITICAL: Swap free 49.61% (thresh 50:%)

CS1611904	BRENNTAG PTE LTD -- BAP	P2 - Major	Processor_load_is_too_high_on_bapv110100.imzcloud.ibmammsap.local[PROBLEM:20787338]
CS1611980	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.18 (thresh: 20)

---------------------------------------------------------------------------------------------------

16 Jan

CS1622124  - C3 - Sev1

 487  2020-01-16 00:47:13 shutdown -Fr
  488  2020-01-16 00:48:28 shutdown -r
  489  2020-01-16 00:48:43 shutdown --Fr
  490  2020-01-16 00:49:15 sudo shutdown â€“r
  491  2020-01-16 00:49:34 shutdown â€“r
  492  2020-01-16 00:49:43 shutdown --help
  493  2020-01-16 00:50:03 shutdown -r
  494  2020-01-16 00:51:19 shutdown -r now
  495  2020-01-16 00:35:39 umask 022
  496  2020-01-16 00:35:49 cd /sapstage/SWPM
  497  2020-01-16 00:35:51 ls
  498  2020-01-16 00:36:01 export TEMP=/sapstage/tmp
  499  2020-01-16 00:36:07 export TMP=/sapstage/tmp
  500  2020-01-16 00:36:10 ./sapinst

[root@CI3BWHANADEVA ibmrmalik]$ last reboot
reboot   system boot  2.6.32-696.10.3. Thu Jan 16 00:55 - 01:15  (00:20)

wtmp begins Mon Jan 13 04:21:31 2020
[root@CI3BWHANADEVA ibmrmalik]$ last
ibmrmali pts/3        146.89.142.229   Thu Jan 16 01:13   still logged in
root     pts/2        :1.0             Thu Jan 16 01:05   still logged in
ibmppate pts/0        146.89.140.60    Thu Jan 16 01:04   still logged in
reboot   system boot  2.6.32-696.10.3. Thu Jan 16 00:55 - 01:15  (00:20)
root     pts/3        :10.0            Thu Jan 16 00:35 - down   (00:15)
root     pts/1        :10.0            Thu Jan 16 00:32 - 00:34  (00:02)
root     pts/3        :10.0            Thu Jan 16 00:11 - 00:32  (00:21)
ibmppate pts/0        146.89.140.60    Wed Jan 15 22:35 - down   (02:16)
root     pts/2        :9.0             Wed Jan 15 19:21 - 00:40  (05:19)
ibmppate pts/0        146.89.140.60    Wed Jan 15 16:26 - 22:13  (05:47)



unqsapbpcprd	10.4.7.16	server inaccessible, when checked form console its hung, needs  reboot.
unqsapbpcqas	10.4.7.17	server inaccessible, when checked form console its hung, needs  reboot.


CHG0138320
A0EASG014XVM003 	svjd1srv0


CS1625457



dalhana-1024-59.xsportal.local

SAPCRMAPP1 	10.207.61.24	10.170.61.27
SAPCRMAPP3 	10.207.61.60	10.170.61.96 	
EWMAPP2 	10.207.61.140	10.170.61.241
TTAR3DEV 	10.207.61.72	10.170.61.22

---------------------------------------------------------------------------------------------------------

17 Jan

CS1635558 Delta Airlines -- DALP1 - SevereZabbix_agent_on_dltqeahdb.imzcloud.ibmammsap.local_is_unavailable

dltqeahdb:/home/ibmrmalik # chage -l root
You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required



CS1636060 Delta Airlines -- DALP1 - SevereZabbix_agent_on_dltqeahdb.imzcloud.ibmammsap.local_is_unavailabl


CS1636068	AGEAS -- AGE	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))


CS1636968	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 198.094MB (200MB), total 198.094MB (200MB))

CHG0138329
host - SVJQ1SRV0 VM snapshot	A0EASG014XVM004



CS1637589	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/lib/mailman CRITICAL: Free 5793.73MB/17.30% (thresh @10.01:20%)
CS1637588	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/spool CRITICAL: Free 5793.73MB/17.30% (thresh @10.01:20%)
CS1637585	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /srv CRITICAL: Free 5793.73MB/17.30% (thresh @10.01:20%)
CS1637532	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/opt/BESClient CRITICAL: Free 5912.57MB/17.66% (thresh @10.01:20%)
CS1637381	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/lib/mailman CRITICAL: Free 2324.57MB/6.94% (thresh @5.01:10%)
CS1637379	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Disk Utilization /var/cache CRITICAL: Free 2324.57MB/6.94% (thresh @5.01:10%)
CS1637324	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/lib/machines CRITICAL: Free 4427.64MB/13.22% (thresh @10.01:20%)
CS1637320	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/lib/pgsql CRITICAL: Free 4427.89MB/13.22% (thresh @10.01:20%)
CS1637319	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/tmp CRITICAL: Free 4427.64MB/13.22% (thresh @10.01:20%)
CS1637318	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /var/crash CRITICAL: Free 4427.64MB/13.22% (thresh @10.01:20%)
CS1637317	PT Anugerah Pharmindo Lestari -- PTP	P3 - Minor	Disk Utilization /home CRITICAL: Free 4427.89MB/13.22% (thresh @10.01:20%)


/dev/mapper/system-root                       33G   14G   20G  41% /
/dev/mapper/system-root                       33G   14G   20G  41% /var/lib/pgsql
/dev/mapper/system-root                       33G   14G   20G  41% /srv
/dev/mapper/system-root                       33G   14G   20G  41% /home
/dev/mapper/system-root                       33G   14G   20G  41% /var/lib/mariadb
/dev/mapper/system-root                       33G   14G   20G  41% /usr/local
/dev/mapper/system-root                       33G   14G   20G  41% /var/lib/libvirt/images
/dev/mapper/system-root                       33G   14G   20G  41% /var/lib/mailman
/dev/mapper/system-root                       33G   14G   20G  41% /var/lib/named
/dev/mapper/system-root                       33G   14G   20G  41% /var/spool
/dev/mapper/system-root                       33G   14G   20G  41% /opt
/dev/mapper/system-root                       33G   14G   20G  41% /var/cache
/dev/mapper/system-root                       33G   14G   20G  41% /var/log
/dev/mapper/system-root                       33G   14G   20G  41% /tmp
/dev/mapper/system-root                       33G   14G   20G  41% /var/opt
/dev/mapper/system-root                       33G   14G   20G  41% /var/lib/machines
/dev/mapper/system-root                       33G   14G   20G  41% /var/tmp
/dev/mapper/system-root                       33G   14G   20G  41% /var/crash
/dev/mapper/system-root                       33G   14G   20G  41% /var/lib/mysql
/dev/mapper/system-root                       33G   14G   20G  41% /var/opt/BESC       


handvh4qsrv02	   10.15.192.28


CS1637914	St. Jude Medical -- JUD	P2 - Major	Ping Availability CRITICAL - 10.196.4.13: rta nan, lost 100%	10.196.4.13:
CS1637821	St. Jude Medical -- JUD	P2 - Major	Ping Availability CRITICAL - 10.196.4.10: rta nan, lost 100%
[root@judhdmart01 ~]$ uptime
 04:41:23 up 811 days, 11:16,  1 user,  load average: 5.60, 4.62, 3.92
 
CS1637801	St. Jude Medical -- JUD	P2 - Major	Ping Availability CRITICAL - 10.196.4.12: rta nan, lost 100%
CS1637727	St. Jude Medical -- JUD	P2 - Major	Ping Availability CRITICAL - 10.196.4.15: rta nan, lost 100%
CS1637709	St. Jude Medical -- JUD	P2 - Major	Ping Availability CRITICAL - 10.196.4.16: rta nan, lost 100%
CS1637694	St. Jude Medical -- JUD	P2 - Major	Ping Availability CRITICAL - 10.196.4.14: rta nan, lost 100%
CS1637685	St. Jude Medical -- JUD	P2 - Major	Ping Availability CRITICAL - 10.196.4.11: rta nan, lost 100%



CS1637717	MSC Industrial Supply Co. -- MS3	P2 - Major	Ping Availability CRITICAL - 10.196.5.16: rta nan, lost 100%
CS1637708	MSC Industrial Supply Co. -- MS3	P2 - Major	Ping Availability CRITICAL - 10.196.5.15: rta nan, lost 100%

CS1637433 Tata Steel BSL Ltd -- BS5P1 - SevereDisk Utilization /sybase/SOA CRITICAL: Free 1625.09MB/5.00% (thresh @0:5%) 


CS1639233	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS1639067	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS1639065	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))



CS1638820 -
prdrep ( CFN-10.170.61.32/IFN - 10.207.61.220)
DR site : Hongkong
prod site: Chennai
remove the VM from the protection group

Cause:
Failed to connect to Site Recovery Manager Server at https://146.89.142.95:9086/vcdr/vmomi/sdk. Reason: com.vmware.vim.vmomi.core.exception.CertificateValidationException: Server certificate chain not verified


    On the Site Recovery home tab, select a site pair and click View Details.
    Select the Protection Groups tab, select a protection group, and on the right pane, click the Virtual Machines tab.
    Right-click a virtual machine and select Remove Protection.
    Click Yes to confirm the removal of protection from the virtual machine.




CS1639249
Create a 4TB mount (temporary) on SAPBIQA	10.207.63.24	10.170.63.40
Mount Name: /bpabqaref


Mount this as NFS on (use same FS name):

TSLBWQADB	10.207.63.20	10.170.63.120
TSLBWPRDDB	10.207.61.200	10.170.61.53
SAPBIQA 	10.207.63.24	10.170.63.40


vgcreate tempvg /dev/sde (PV)
lvcreate -L 4T -n templv tempvg
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab

[root@tslbwqadb ibmrmalik]$ df -h  /bpabqaref
Filesystem               Size  Used Avail Use% Mounted on
10.170.63.40:/bpabqaref  4.0T  4.1G  3.8T   1% /bpabqaref


sapbiqa /home/ibmrmalik# df -h /bpabqaref
Filesystem                 Size  Used Avail Use% Mounted on
/dev/mapper/tempvg-templv  4.0T   67M  3.8T   1% /bpabqaref

[root@tslbwprddb ibmrmalik]$ df -h  /bpabqaref
Filesystem               Size  Used Avail Use% Mounted on
10.170.63.40:/bpabqaref  4.0T  4.1G  3.8T   1% /bpabqaref






SPP Application host - 10.6.3.33 (spsvspasapp01)	A0EASG014XVM030
SPP Database Host: 10.6.3.32 (spsvspdsase01)		A0EASG014XVM035
	


CS1638820 Tata Steel Limited -- TTAP2 - MajorRemove VM from existing Protection group<<Tata Steel (TTA)| 17-Jan-2020>>

------------------------------------------------------------------------------------------------------------------------------

18 Jan


CS1653286	LSPI -- LSP	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB)), \??\X:\pagefile.sys 3.663GB (4.75GB), total 3.859GB (4.945GB)	LZABWPRD0
CS1653285	LSPI -- LSP	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), \??\X:\pagefile.sys 3.664GB (4.75GB), total 3.859GB (4.945GB)	LZABWPRD0


CS1652257 Tata Steel Limited -- TTAP2 - MajorTata Steel Limited- Customer OS access(empty)


CS1654538 Dilip Buildcon Limited -- DLBP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.69 (thresh: 16)DLBPECDB01


CS1655120 Apple Leisure Group -- AV1P2 - MajorPing Availability CRITICAL - 10.68.214.12: Host unreachable @ 10.143.69.196. rta nan, lost 100%USSAPAWD


CS1655255	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	DLTHSBBSI02
CS1655253	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	DLTHSBBSI02
CS1655176	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.695MB (200MB), total 199.695MB (200MB)	DLTHSBBSI02
CS1655104	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	DLTHDBBSI02
CS1654935	Delta Airlines -- DAL	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.832MB (200MB), total 199.832MB (200MB)	DLTHSBBSI02



SPP Application host - 10.6.3.33 (spsvspasapp01)	A0EASG014XVM030
SPP Database Host: 10.6.3.32 (spsvspdsase01)		A0EASG014XVM035

lvcreate -L 10G -n upgrade_lv spplogvg
mkfs.ext2/3/4 path of lvdisplay
XFS format a new LV  mkfs.xfs /dev/vg_xfs/xfs_db
mkdir /sybase
mount
vi /etc/fstab


/dev/spplogvg/upgrade_lv

spplogvg    2   2   0 wz--n-  57.49g   18.49g
  toolsvg     1   1   0 wz--n-  20.00g   15.00g
  
  
  /sapstagetemp  FS from host : svsd1srv0  to   spsvspdsase01
  
  SVSD1SRV0 	10.6.1.26	10.92.99.125
  
  SPSVSPDSASE01 	10.6.3.32	10.70.111.32
------------------------------------------------------------------------------------------------------------------------

21 Jan


spsvopitsql01(A0EASG012XVM041)	svts1srv0	
spsvopltapp01(A0EASG012XVM042) 	svts1srv1

    spsvopitsql01    	Windows 2012    10.70.111.34  	to 	svts1srv0	Windows 2012	10.92.99.148
    spsvopltapp01	Windows 2012	10.70.111.35 	to 	svts1srv1	Windows 2012	10.92.99.149

SPSVOPITSQL01 	10.6.3.34	10.70.111.34
SPSVOPLTAPP01 	10.6.3.35	10.70.111.35

SVTS1SRV0 	10.6.1.148	10.92.99.148
SVTS1SRV1 	10.6.1.149	10.92.99.149



IA1OTASPRDAPP	10.133.17.147



CS1692990 A.P. Moller Maersk -- APMP1 - SevereZabbix_agent_on_scrbwqdefra80.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:21232834]SCRBWQDEFRA80
CS1692981 A.P. Moller Maersk -- APMP1 - SevereZabbix_agent_on_scrbwpdefra20.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:21232831]SCRBWPDEFRA20
CS1692964 A.P. Moller Maersk -- APMP1 - SevereZabbix_agent_on_scrbwpdefra30.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:21232809]SCRBWPDEFRA30
CS1692935 A.P. Moller Maersk -- APMP1 - SevereZabbix_agent_on_scrbwddefra11.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:21232593]SCRBWDDEFRA11
CS1692880 A.P. Moller Maersk -- APMP1 - SevereZabbix_agent_on_scrbwrdefra50.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:21232779]SCRBWRDEFRA50
CS1692847 A.P. Moller Maersk -- APMP1 - SevereZabbix_agent_on_scrbwrdefra60.imzcloud.ibmammsap.local_is_unavailable[PROBLEM:21232758]SCRBWRDEFRA60


SVJQ1SRV0	CHG0138766	CTASK0164763



---------------------------------------------------------------------------------------------------------------------

22 Jan

CS1702953	Delta Airlines -- DAL	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 195.824MB (200MB), total 195.824MB (200MB))	DLTHSBBSI02	10.4.5.27



CS1377575	ANS2712W The virtual machine 'PEPSAPGBQDI01' has a VMware Tools running, but VMw
are Tools is out of date.


SVJQ1SRV0	A0EASG014XVM004



CS1705495		P2 - Major	Disk Utilization /var/log CRITICAL: Free 181.07MB/9.65% (thresh @5.01:10%)
CS1705489		P2 - Major	Free_disk_space_is_less_than_10%_on_volume_/var/log[PROBLEM:21285965]


 pn4us7lewmp1c 
 pn4ushlewmp1c
 
 
 CS1669974 - Memory Swap CRITICAL: Swap free 34.64% (thresh 50:%)
  97471 root      20   0  225932   5008   4932 S  0.000 0.001   0:24.50  33272 ncpa_listener
 25033 root      20   0  258956   8000   2496 S  0.000 0.002   0:00.00  19284 salt-minion
 22723 root      20   0  975832  97284  11792 S  0.000 0.019 128:51.00  18632 ds_agent
--------------------------------------------------------------------------------------------------------------------

23 Jan

CS1245347 AGESVBQ1HSRV1 10.6.2.70 - TSM person facing port confit
 prole_hana.service                     loaded failed failed  IBM Tivoli Storage Manager for ERP Data Protection for SAP HANA prole daemon
57321
 
 
 
 stat("/sds"
 
  [root@PEPSAPGBQDI01 ibmrmalik]$ cat /etc/mtab |grep -i /sds
146.89.142.203:/sds /sds nfs rw,relatime,vers=3,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=146.89.142.203,mountvers=3,mountport=20048,mountproto=tcp,local_lock=none,addr=146.89.142.203 0 0
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=7150,timeout=600,minproto=5,maxproto=5,direct 0 0
dal13ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=100.126.32.111,local_lock=none,addr=146.89.142.203 0 0



SVJD1SRV0	A0EASG014XVM003 now as part of CSR # CHG0138331


spsvopitsql01(A0EASG012XVM041)	svts1srv0	
spsvopltapp01(A0EASG012XVM042) 	svts1srv1

    spsvopitsql01    	Windows 2012    10.70.111.34  	to 	svts1srv0	Windows 2012	10.92.99.148
    spsvopltapp01	Windows 2012	10.70.111.35 	to 	svts1srv1	Windows 2012	10.92.99.149

SPSVOPITSQL01 	10.6.3.34	10.70.111.34
SPSVOPLTAPP01 	10.6.3.35	10.70.111.35

SVTS1SRV0 	10.6.1.148	10.92.99.148	admlocal/{fAb|Jq)uj|ipc5  now May55now#			original kJci50Vz
SVTS1SRV1 	10.6.1.149	10.92.99.149	admlocal/k3M?Exur4lKuQT{				original PqSbhR*8Q)*gl7G



CS1714191	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.19: rta nan, lost 100%	ECCTEST
 https://158.87.44.154/nrdp
 [root@ecctest ibmrmalik]$ ping 158.87.44.154
PING 158.87.44.154 (158.87.44.154) 56(84) bytes of data.
^C
--- 158.87.44.154 ping statistics ---
63 packets transmitted, 0 received, 100% packet loss, time 62487ms

[root@ecctest ibmrmalik]$ uptime
 19:39pm  up 55 days 23:31,  3 users,  load average: 2.47, 2.47, 2.63
[root@ecctest ibmrmalik]$ date
Thu Jan 23 19:39:09 IST 2020
 

CS1713902	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.62.16: rta nan, lost 100%	S4HDEV	  10.207.62.16
parent = https://158.87.44.154/nrdp


CS1712980	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.62.25: rta nan, lost 100%	ASDDEV
https://158.87.46.181/nrdp


CS1719692 Chef_Client_is_not_running_on_bs5sbxapp.imzcloud.ibmammsap.local

-----------------------------------------------------------------------------------------------------------

24 Jan

CS1714012	10.6.7.11	
CS1712992	10.6.7.22
CS1712807	10.6.7.16
CS1714255	 10.6.7.12
CS1712692	10.6.7.23
CS1713209	10.6.7.21
CS1712760	10.6.7.26
CS1712655	10.6.7.28 
CS1714148	10.6.7.15
CS1713629	10.6.7.18: 
CS1713213	 10.6.7.17
CS1712644	10.6.7.20 	
CS1713405	 10.6.7.14	parent = https://158.87.44.141/nrdp


CS1726698	10.204.2.190   zabbix	
CS1725850

---------------------------------------------------------------------------------------------------------------------------

26 Jan

PhillipPayne 	HermiloRabago
CHG0136440 Mallikarjuna Vallabaneni(SAP) Ravi Malik(Linux)

ms3wdcladb48	10.12.7.37
	
ms3wdclapp49	10.12.7.38
	
ms3wdcappsp1	10.12.7.39


PhillipPayne 	HermiloRabago
CHG0136438 Ravi Malik(Linux) Surendra R Kurapati(SAP) 

ms3wdclapp35	10.12.7.20
	
ms3wdclapp34	10.12.7.19



CS1748327
MS3WDCLPDB200	10.12.7.48	172.17.156.48



[root@ms3wdcappsp1 tmp]$ cat OS_upgrade.log |grep -i /sapmnt/SP1
#/dev/sp1appvg/sp1sapmnt_lv     /sapmnt/SP1     ext3    _netdev,defaults        1       2
172.17.156.38:/sapmnt/SP1        /sapmnt/SP1      nfs   defaults  1  2
172.17.156.38:/sapmnt/SP1        /sapmnt/SP1      nfs   rw,hard,intr,rsize=32768,wsize=32768 0 0
172.17.156.38:/sapmnt/SP1
                       16G  4.3G   11G  29% /sapmnt/SP1
172.17.156.38:/sapmnt/SP1
                       16G  4.3G   11G  29% /sapmnt/SP1
172.17.156.38:/sapmnt/SP1 on /sapmnt/SP1 type nfs (rw,vers=4,addr=172.17.156.38,clientaddr=172.17.156.39)
172.17.156.38:/sapmnt/SP1 on /sapmnt/SP1 type nfs (rw,hard,intr,rsize=32768,wsize=32768,vers=4,addr=172.17.156.38,clientaddr=172.17.156.39)
[root@ms3wdcappsp1 tmp]$ df -h /sapmnt/SP1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                      9.8G  5.4G  3.9G  58% /


CS1751993	A.P. Moller Maersk -- APM	APM	APM IC4SAP-SL SAP LOB	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 34.76 (thresh: 16)	SQ-SAP-TRIO-C1	100.126.64.140
CS1749875	BRENNTAG PTE LTD -- BAP	BAP	BAP IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Processor_load_is_too_high_on_bapv110100.imzcloud.ibmammsap.local[PROBLEM:21521781]	SQ-SAP-TRIO-C1	10.134.3.11  


------------------------------------------------------------------

27 Jan

CS1761937	Tata Steel Limited -- TTA	TTA	TTA IC4SAP-SL SAP LOB	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 38.26 (thresh: 32)	SQ-SAP-TRIO-C1  
CS1761831	A.P. Moller Maersk -- APM	APM	APM IC4SAP-SL SAP LOB	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 28.40 (thresh: 16)	SQ-SAP-TRIO-C1

CS1761959	Delta Airlines -- DAL	DAL	DAL SAP HEC-AMM SAP LOB	Incident	P2 - Major	New		Memory Pagefile CRITICAL: \??\C:\pagefile.sys 196.453MB (200MB), total 196.453MB (200MB)	SQ-SAP-TRIO-C2


CS1759110	Bumrungrad Hospital Plc -- BUM	BUM	BUM IC4SAP-SL SAP LOB	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.20 (thresh: 16)	SQ-SAP-TRIO-C1	10.134.14.15


CS1761795	Apple Leisure Group -- AV1	AV1	AV1 SAP HEC-AMM SAP LOB	Incident	P2 - Major	New		Ping Availability CRITICAL - 10.68.213.14: Host unreachable @ 10.143.69.196. rta nan, lost 100%	SQ-SAP-TRIO-C2
CS1762379	Apple Leisure Group -- AV1	AV1	AV1 SAP HEC-AMM SAP LOB	Incident	P2 - Major	New		Ping Availability CRITICAL - 10.68.213.12: Host unreachable @ 10.143.69.196. rta nan, lost 100%	SQ-SAP-TRIO-C2

CS1762650	St. Jude Medical , USA -- JUE	JUE	JUE St. Jude Medical SAP HEC-AMM	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.23 (thresh: 16)	SQ-SAP-TRIO-C1


Summary: EventLog Setup CRITICAL: 1 message(s) [Setup:Microsoft-Windows-WUSA:3:Windows update could not be installed because of error 2149842967 (Command line: wusa C:\Users\IBMLOG1\AppData\Local\Temp\6



CS1763801 St. Jude Medical -- JUDP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.05 (thresh: 16)JUDDTRANS02SQ-SAP-TRIO-C1
CS1763856 St. Jude Medical , USA -- JUEP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 25.69 (thresh: 16)JUEHDMART03SQ-SAP-TRIO-C1	10.211.0.20
CS1763875 Delta Airlines -- DALP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)DLTHSBBSI02SQ-SAP-TRIO-C2	 10.4.5.27
CS1763873 Delta Airlines -- DALP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))DLTHSBBSI02SQ-SAP-TRIO-C2(empty)	10.4.5.27 
CS1763680 Delta Airlines -- DALP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.977MB (200MB), total 199.977MB (200MB)DLTHSBBSI02SQ-SAP-TRIO-C2	10.4.5.27 



CS1764499 Certified IT Consultants - TMG -- CI3P3 - MinorDisk Utilization /sapmnt/data CRITICAL: Free 154811.53MB/19.70% (thresh @10.01:20%)CI3BWHANADEVSQ-SAP-TRIO-C2  SAP
CS1765035 Tata Steel Limited -- TTAP3 - MinorDisk Utilization /usr/sap CRITICAL: Free 181.76MB/20.00% (thresh @10.01:20%)TSCMLDEVSQ-SAP-TRIO-C1
CS1765106 Dilip Buildcon Limited -- DLBP3 - MinorDisk Utilization /sapmnt/PEC CRITICAL: Free 3802.22MB/20.00% (thresh @10.01:20%)DLBPECAP01SQ-SAP-TRIO-C2
CS1765113 PT Anugerah Pharmindo Lestari -- PTPP3 - MinorDisk Utilization /usr/sap/APP CRITICAL: Free 8628.14MB/20.00% (thresh @10.01:20%)PTPKOMODOSQ-SAP-TRIO-C2(empty)
CS1764590 Manitoba Telecom Services -- MTSP3 - MinorBQ1MTS (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory ConsumptionMTSBODSQAS01SQ-SAP-TRIO-C1
CS1765207 Arnoldo Mondadori Editore SpA -- ARMP3 - MinorBODARM (ATC)|TOMCAT_ALERT_PERF_MEMORY_CONSUME|High Memory ConsumptionARMFKSAP006SQ-SAP-TRIO-C2
CS1764788 AGEAS -- AGEP3 - MinorDrive-Space F critical(OK: Drive F: has 7.427GB of 49.53GB)SVTQ1SRV1SQ-SAP-TRIO-C1

------------------------------------------------------------------------------------------------------------------------

28 Jan

mount -t cifs //10.102.96.38/Interface /Interface username=SAPServicePOD,password=Sug@erM!nt4,uid=20100,gid=3050,sec=ntlm

\\10.102.96.38\Interface /Interface cifs credentials=/etc/credentials,uid=20100,gid=3050 0 0



CS1776193 Computer Systems Integration Ltd -- CSYP2 - MajorPing Availability CRITICAL - 10.197.2.10: rta nan, lost 100%PSDEVDBSQ-SAP-TRIO-C2
CS1776187 Bombardier Recreational Products Inc -- BR3P2 - MajorPing Availability CRITICAL - 10.138.10.33: rta nan, lost 100%BR3QSAPAS31SQ-SAP-TRIO-C1
CS1776186 CMA CGM -- CMAP2 - MajorPing Availability CRITICAL - 10.78.24.43: rta nan, lost 100%SMGRCQUAQG1SQ-SAP-TRIO-C2
CS1776185 MSC Industrial Supply Co. -- MS3P2 - MajorPing Availability CRITICAL - 10.12.7.34: rta nan, lost 100%MS3VERTEXPRD1SQ-SAP-TRIO-C1
CS1776184 IAG - British Airways -- IA2P2 - MajorPing Availability CRITICAL - ia1bodssbxapp: rta nan, lost 100%IA1BODSSBXAPPSQ-SAP-TRIO-C1
CS1776179 Bombardier Recreational Products Inc -- BR3P2 - MajorPing Availability CRITICAL - br3qscmss36: rta nan, lost 100%BR3QSCMSS36SQ-SAP-TRIO-C1
CS1776178 COTY Inc. -- CTUP2 - MajorPing Availability CRITICAL - 10.12.10.147: rta nan, lost 100%CTUBWQB3AP02SQ-SAP-TRIO-C2


[root@dlthqehdb ibmrmalik]$ cat /etc/mtab |grep -i  /backup_hpe
10.250.17.217:/backup_hpe /backup_hpe nfs rw,vers=4,addr=10.250.17.217,clientaddr=10.250.17.32 0 0


CS1775859 Apple Leisure Group -- AV1P2 - MajorITM Agent Offline: AV1WEBDISP001:UAAV1WEBDISP001SQ-SAP-TRIO-C2
------------------------------------------------------------------------------------------------------------------------

29 Jan

ckdbw4dbprd  BES
CKDBW4DBPRD 	10.20.21.69	10.15.21.77


CS1784012 Tata Steel Limited -- TTAP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 37.67 (thresh: 32)TSLEECPRDDBSQ-SAP-TRIO-C1


CS1790453 Tata Steel Limited -- TTAP2 - MajorPing Availability CRITICAL - 10.207.61.47: rta nan, lost 100%SAPAPP27SQ-10.207.61.47 
CS1790416 Tata Steel Limited -- TTAP2 - MajorPing Availability CRITICAL - 10.207.62.20: rta nan, lost 100%ESSMSSDEVSQ-10.207.61.210
CS1790412 Tata Steel Limited -- TTAP2 - MajorPing Availability CRITICAL - 10.207.61.70: rta nan, lost 100%SAPAPP18SQ-10.207.61.70
CS1790302 Tata Steel Limited -- TTAP2 - MajorPing Availability CRITICAL - 10.207.62.17: rta nan, lost 100%TSCMLDEVSQ-SAP-TRIO-C1
CS1790257 Tata Steel BSL Ltd -- BS5P2 - MajorPing Availability CRITICAL - 10.141.133.19: rta nan, lost 100%BS5QASAPPSQ-SAP-TRIO-C1


CS1791246
Authentication failure activities from username "Zabbix" on the below servers,
BUMSAPPOP01P 	10.134.14.9	10.156.1.11	bumsappop02p
BUMSAPPOP02P 	10.134.14.10	10.156.1.12
BUMSAPS4P02P 	10.134.14.8	10.156.1.9
BUMSAPH4Q01T 	10.134.15.23	10.156.3.29 	
BUMSAPTKQ01T 	10.134.15.12	10.156.3.24
 	
 	
 	[root@bumsaph4q01t ibmrmalik]# chage -l root
You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required


CS1792710 AGEAS -- AGEP2 - MajorDrive-Space C critical(OK: Drive C: has 3.111GB of 59.655GB)SVFS1SRV0SQ-SAP-TRIO-C1
CS1792745 Delta Airlines -- DALP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)DLTHSBBSI02SQ-SAP-TRIO-C2
CS1792824 Delta Airlines -- DALP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))DLTHSBBSI02SQ-SAP-TRIO-C2	10.4.5.27
CS1792984 St. Jude Medical , USA -- JUEP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.91 (thresh: 16)JUEHDMART03SQ-SAP-TRIO-C1
CS1793315 MSC Industrial Supply Co. -- MS3P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.27 (thresh: 16)MDCSERVERP1SQ-SAP-TRIO-C1



statfs("/storage",
146.89.141.91:/storage          /storage        nfs     defaults        0      0
DLTHMEHAP
DLTHMEHAP 	10.4.5.49	10.250.17.49 
-------------------------------------------------------------------------------------------------------------------------------

30 Jan

ECCDDB00 10.5.2.13	 	already OK
A1AERPPD2AP01 10.4.10.58	fixed passwd
SNCHEUAPD11-DR 10.73.10.128	already OK
SNCHECAQD11 10.73.12.10		already OK
SPSVBPAAAPP01 10.6.3.20		fixed passwd
mm3fiufd001 10.79.161.16	fixed passwd
S4HANA-DB-PRD 10.71.6.10	already OK
DLTHDLSLT 10.4.5.15		already OK
SNCHLTAPD51 10.73.10.82		already OK
ECCDB0QAS 10.198.2.71		fixed passwd
JGCSMANPRDAPP 10.199.30.23	fixed passwd
SNCHLTAPA12 10.73.10.84		already OK
MGGGBJDGTSY02 10.133.18.205	fixed passwd
PN4US7LEWMP1 10.12.254.20	fixed passwd
BI1CRMDBDEV01 10.135.4.14	already OK
SMEMUATUM3 10.78.26.21		already OK
SNCHCUATD11 10.73.11.68		already OK
bs4sbq042 10.211.8.79 		fixed passwd
conspdfdbapp 10.16.1.104	already OK

 login shell in /etc/passwd from /bin/ksh to /bin/bash . I think it was a provisioning error, or someone changed it by mistake.

Before:

[root@conspdfdbapp timagent]$ grep timagent /etc/passwd
timagent:x:54716:54716:897/F/*AMMIM2/IBM/CMSD IAM ID,CD=04252017,RI=MSD-PCS-0387,#FUNC#:/home/timagent:/bin/ksh

[root@conspdfdbapp ~]$ su - timagent
[e[1;32m][u@h W]$ [e[m]

After:

[timagent@conspdfdbapp ~]$ grep timagent /etc/passwd
timagent:x:54716:54716:897/F/*AMMIM2/IBM/CMSD IAM ID,CD=04252017,RI=MSD-PCS-0387,#FUNC#:/home/timagent:/bin/bash

[root@conspdfdbapp timagent]$ su - timagent
[timagent@conspdfdbapp ~]$





CS1804118 Apple Leisure Group -- AV1P2 - MajorITM Agent Offline: ASP-ussapasp:ussapasp:mySAPUSSAPASPSQ-SAP-TRIO-C2


CS1804490 City Football Group 1 -- CFOP2 - MajorRuuning_out_of_available_memory_on_server_loncfgceq0001.imzcloud.ibmammsap.local[PROBLEM:21715239]LONCFGCEQ0001SQ-SAP-TRIO-C1


CS1805367 PT Anugerah Pharmindo Lestari -- PTPP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.39 (thresh: 16)PTPBROMOSQ-SAP-TRIO-C2


CS1712817, CS1713235, CS1713278, CS1713349, CS1714175, CS1803786 & CS1803787 - Ping Availability CRITICAL

CS0120618
OS engineer to check for A0EASG012JMP001  10.6.1.99 (SL-SINGAPORE-SNG01) & A0EASG014XVM001 10.70.110.11 (SL-SINGAPORE-SNG01) not able to connect



CS1704010	Bumrungrad Hospital Plc -- BUM	BUM	BUM IC4SAP-SL SAP LOB	Incident	P3 - Minor	New		Please check authentication failure error from "zabbix" on servers listed	SQ-SAP-TRIO-C1
Please check authentication failure error from "zabbix" on servers listed

bumsaps4d01t	10.134.15.9	fixed /etc/passwd
[root@bumsaps4d01t ibmrmalik]# chage -l root
You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required

BUMSAPWEBQ01T	10.134.15.25	fixed /etc/passwd

bumsappoq01t	10.134.15.18	fixed /etc/passwd
[root@bumsappoq01t ibmrmalik]# chage -l root
You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required

bumsaph4d01t 	10.134.15.13	fixed /etc/passwd

bumsaph4p02p	10.134.14.16	fixed /etc/passwd
[root@bumsaph4p02p ibmrmalik]# chage -l root
You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required

bumsaptkq01t	10.134.15.12	fixed /etc/passwd

bumsaps4p02p	10.134.14.8	fixed /etc/passwd

bumsappop01p	10.134.14.9	fixed /etc/passwd

bumsaptkd01t	10.134.15.8	fixed /etc/passwd

bumsappop02p	10.134.14.10	fixed /etc/passwd

bumsaph4q01t	10.134.15.23	fixed /etc/passwd

bumsaps4q01t	10.134.15.19	fixed /etc/passwd

bumsaptkp01p	10.134.14.11	fixed /etc/passwd	
[root@bumsaptkp01p ibmrmalik]# chage -l root
You are required to change your password immediately (password aged)
chage: PAM: Authentication token is no longer valid; new one required

BUMSAPWEBP01P	10.134.14.6	fixed /etc/passwd

bumsaps4p01p	10.134.14.7	fixed /etc/passwd

BUMSAPWEBD01T	10.134.15.7	fixed /etc/passwd

---------------------------------------------------------------------------

1 Feb

CS1832609	2	C1-C2	PN8	PN8US7LDBRP0	Disk Utilization /db2/RP0/sapdata4---> Need to add 400GB disk and extend FS's on placemaker clusters, 100GB each:
/dev/mapper/rp0datavg-db2_RP0_sapdata1_lv xfs   220G  215G  5.1G  98% /db2/RP0/sapdata1
/dev/mapper/rp0datavg-db2_RP0_sapdata2_lv xfs   220G  215G  5.1G  98% /db2/RP0/sapdata2
/dev/mapper/rp0datavg-db2_RP0_sapdata3_lv xfs   220G  215G  5.1G  98% /db2/RP0/sapdata3
/dev/mapper/rp0datavg-db2_RP0_sapdata4_lv xfs   220G  215G  5.1G  98% /db2/RP0/sapdata4

Node Attributes:
* Node pn8us7ldbrp0:ammwdc04custesx25	wdc04pool4ds335	new DS WDC04POOL4POD4DSP414 	DAL13 PN8DAL13DR325
    
* Node pn8us7ldbrp0h:ammwdc04custesx17	wdc04pool4ds335
    
Migration Summary:
* Node pn8us7ldbrp0:
   vcenter-fencing-node2: migration-threshold=3 fail-count=1000000 last-failure='Thu Jan 23 09:54:13 2020'
* Node pn8us7ldbrp0h:

Failed Actions:
* vcenter-fencing-node2_start_0 on pn8us7ldbrp0 'unknown error' (1): call=554, status=Error, exitreason='',
    last-rc-change='Thu Jan 23 09:54:06 2020', queued=0ms, exec=5884ms



CS1834248  Panasonic North America -- PN8   Disk Utilization /db2/RP0/log_dir CRITICAL: Free 212.71MB/0.83% (thresh @0:5%)  P1  10.12.255.26



CHG0139992	CTASK0167619
pls take VM snap shot of host -
SPSVEPAJAPP01  	A0EASG014XVM039
10.6.3.13


CS1809103	Service vmtoolsd CRITICAL: vmtoolsd is not running
CS1690866	System NTP Drift CRITICAL: ERROR - chronyc and ntpdate not installed or /etc/ntp.conf does not exist
CS1222545	Service master CRITICAL: 0 master processes running (thresh 1:)

Feb  1 11:01:01 DLBDBIDA00 postfix/sendmail[106334]: fatal: chdir /var/spool/postfix: No such file or directory
Feb  1 12:01:02 DLBDBIDA00 postfix/sendmail[103809]: fatal: chdir /var/spool/postfix: No such file or directory
Feb  1 13:01:01 DLBDBIDA00 postfix/sendmail[111780]: fatal: chdir /var/spool/postfix: No such file or directory
Feb  1 14:01:02 DLBDBIDA00 postfix/sendmail[10127]: fatal: chdir /var/spool/postfix: No such file or directory
Feb  1 15:01:01 DLBDBIDA00 postfix/sendmail[8861]: fatal: chdir /var/spool/postfix: No such file or directory
--------------------------------------------------------------------------------------------------------------------------------
4 Feb

CS1878008
SAP-HEC-Swivel:HEC: Increase FS space in I: - 10.70.111
10.6.3.35 	A0EASG012XVM042



CS1871904	Panasonic North America -- PN8	PN8	PN8 IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-02-03-10-34-54 for details.	SQ-SAP-TRIO-C2

CS1872182	Panasonic North America -- PN4	PN4	PN4 IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-02-03-13-58-09 for details.	SQ-SAP-TRIO-C2

CS1871973	Panasonic North America -- PN4	PN4	PN4 IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-02-03-13-39-57 for details.	SQ-SAP-TRIO-C2


stat("/sapmnt/data/source_NFS"
[root@juehdmart01 ibmrmalik]# cat /etc/mtab |grep -i /sapmnt/data/source_NFS
10.193.0.12:/sapmnt/data/NFS /sapmnt/data/source_NFS nfs4 rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.193.3.11,local_lock=none,addr=10.193.0.12 0 0



spsvopitsql01(A0EASG012XVM041)

-------------------------------------------------------------------------------------------------------------------------------------------

5th Feb

10.6.3.37  C paging <50%	CS1889455

 10.6.3.45  C paging


10.6.3.36 	paging C CS1830154



Please assist to mount below OT SBX server to ES1/RS1 server  SVES1SRV0 	10.6.1.139	10.92.99.139

SBX OpenText Directory
svts1srv1
10.92.99.149
F:\OpenText\StreamServe\Data\STRS_Spool
/usr/sap/OpenText/STRS_Spool in AL11


SVTS1SRV1 	10.6.1.149	10.92.99.149	windows

//10.92.99.149/STRS_Spool  /usr/sap/OpenText/STRS_Spool  cifs   credentials=/root/usercred.txt,iocharset=utf8,file_mode=0777,dir_mode=0777 0    0


[root@SVES1SRV0 ibmrmalik]$ cat /root/usercred.txt
username=admes1
password=Welcome@123


CS1894877
10.6.1.52   paging 		30%

 
 
 CS1757047	10.6.3.45 
 
 
 10.6.1.52 
 
 -------------------------------------------------------------------------------------------------------------------
 
 6 Feb
 
 
 CS1869807	Ping Availability CRITICAL - 10.204.2.190: rta nan, lost 100%
CS1869808	10.204.2.190	Ping availability
 
 
 
 SVTD1SRV1 	10.6.1.28 	10.92.99.127	A0EASG012XVM005
 
 
 
 CS1908043	Delta Airlines -- DAL	DAL	DAL SAP HEC-AMM SAP LOB	Incident	P2 - Major	New		Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	SQ-SAP-TRIO-C2	10.4.5.27
 
 CS1908046	Delta Airlines -- DAL	DAL	DAL SAP HEC-AMM SAP LOB	Incident	P2 - Major	New		Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))	SQ-SAP-TRIO-C2  
 
 
 CS1911105 - RCA for 10.92.99.127 - drives unmounted[000085557/2020]

CS1895692 -  Mount OT SBX directory in ES1/RS1 s[00086764/2020]
 
 
 
 
 
 
 
 
 
 
 
 
---------------------------------------------------------------------------------------------

7 Feb

 
 CHG0139343-IAG - British Airways -- IA2-06-Feb-2020 05:00:00 PM(Pacific Time)
 Update from CTask: CTASK0165958 02-06-2020 20:30:59 - IBM Ozone (Work notes)
Work Item began at Fri Feb 7 01:29:56 2020. Work was completed at Fri Feb 7 01:30:59 2020. General status for salt: sap_dynamic_task is False.

All work has failed.

Failed CIs: IA2WDDEVAPP, IA2PODEVDBAPP, IA2PODQASWD
 
 ia2wddevapp, ia2podevdbapp, ia2podqaswd	7th Feb 0630-1230	automation
 IA2WDDEVAPP 	10.133.16.59	66.248.245.59
 [root@IA2WDDEVAPP tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux IA2WDDEVAPP 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Feb  6 07:40:56 UTC 2020
ZONE="America/New_York"
OK: No read-only file systems found
[root@IA2WDDEVAPP tmp]$ df -hT |grep -i nfs
                     nfs    5.1T  2.9T  1.9T  61% /storage
                     nfs    6.6T  2.9T  3.4T  47% /sds
                     
[root@IA2WDDEVAPP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux IA2WDDEVAPP 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 01:47:42 UTC 2020
ZONE="America/New_York"
OK: No read-only file systems found


 IA2PODEVDBAPP 	10.133.16.45	66.248.245.45
 [root@IA2PODEVDBAPP tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux IA2PODEVDBAPP 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Feb  6 07:40:55 UTC 2020
ZONE="America/New_York"
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
66.248.245.42:/datamigration/temp       /datamigration/temp     nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/temporary/ /datamigration/temporary/       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/upload/    /datamigration/upload/          nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.42:/INT_ENH/                 /INT_ENH/                       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
66.248.245.42:/datamigration/temp       /datamigration/temp     nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/temporary/ /datamigration/temporary/       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/upload/    /datamigration/upload/          nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.42:/INT_ENH/                 /INT_ENH/                       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
OK: No read-only file systems found
[root@IA2PODEVDBAPP tmp]$ df -hT |grep -i nfs
                     nfs    6.6T  2.9T  3.4T  47% /storage/library
                     nfs     15G   86M   14G   1% /datamigration/temp
                     nfs    2.0G   61M  1.8G   4% /datamigration/temporary
                     nfs    2.0G   61M  1.8G   4% /datamigration/upload
                     nfs     16G  606M   15G   4% /INT_ENH
                     nfs    6.6T  2.9T  3.4T  47% /sds

[root@IA2PODEVDBAPP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux IA2PODEVDBAPP 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 01:47:43 UTC 2020
ZONE="America/New_York"
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
66.248.245.42:/datamigration/temp       /datamigration/temp     nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/temporary/ /datamigration/temporary/       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/upload/    /datamigration/upload/          nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.42:/INT_ENH/                 /INT_ENH/                       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
66.248.245.42:/datamigration/temp       /datamigration/temp     nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/temporary/ /datamigration/temporary/       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.64:/datamigration/upload/    /datamigration/upload/          nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
66.248.245.42:/INT_ENH/                 /INT_ENH/                       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
OK: No read-only file systems found
[root@IA2PODEVDBAPP ibmrmalik]$ df -hT |grep -i nfs
                     nfs    6.6T  2.9T  3.4T  47% /storage/library
                     nfs     15G   86M   14G   1% /datamigration/temp
                     nfs    2.0G   61M  1.8G   4% /datamigration/temporary
                     nfs    2.0G   61M  1.8G   4% /datamigration/upload
                     nfs     16G  606M   15G   4% /INT_ENH
 
 
 IA2PODQASWD 	10.133.16.46	66.248.245.46
 [root@IA2PODQASWD tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux IA2PODQASWD 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Feb  6 07:40:55 UTC 2020
ZONE="America/New_York"
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found
[root@IA2PODQASWD tmp]$ df -hT |grep -i nfs
                     nfs    6.6T  2.9T  3.4T  47% /storage/library
                     nfs    6.6T  2.9T  3.4T  47% /sds

[root@IA2PODQASWD ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux IA2PODQASWD 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 01:47:43 UTC 2020
ZONE="America/New_York"
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found
[root@IA2PODQASWD ibmrmalik]$ df -hT |grep -i nfs
                     nfs    6.6T  2.9T  3.4T  47% /storage/library

 
 
 CHG0139344-IAG - British Airways -- IA2-06-Feb-2020 05:00:00 PM(Pacific Time)	Cancelled
 
 
CHG0140386	Meggit	07-02-2020 11:30:00  to 1430	London02	RazvanSegneanu 	Kuganeswaran KisnianKrishnan

MGGGBJSECCX01	 10.133.18.163	Sandbox
[root@MGGGBJSECCX01 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJSECCX01 2.6.32-754.24.3.el6.x86_64 #1 SMP Tue Nov 12 06:01:24 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 03:16:31 GMT 2020
ZONE="America/New_York"
OK: No read-only file systems found
                     nfs    6.6T  2.9T  3.4T  47% /sds
                     
[root@MGGGBJSECCX01 ibmrmalik]$  cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJSECCX01 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 07:30:27 GMT 2020
ZONE="America/New_York"
OK: No read-only file systems found


MGGGBJSECCX02	10.133.18.164	Sandbox	HANA db	10.164.30.166	lonhana-1024-31.xsportal.local	pHANA	root pw Fl4KBygP
[root@MGGGBJSECCX02 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux MGGGBJSECCX02 2.6.32-573.el6.x86_64 #1 SMP Wed Jul 1 18:23:37 EDT 2015 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 03:16:31 GMT 2020
ZONE="UTC"
UTC=true
10.5.255.163:/backup2   /backup2 nfs    rw,hard,rsize=8192,wsize=8192,timeo=14,intr     0 0
10.5.255.163:/mnt/EES_SYSTEM_REFRESH /mnt/EES_SYSTEM_REFRESH nfs rw,hard,rsize=8192,wsize=8192,timeo=14,intr    0 0
10.5.255.163:/backup2   /backup2 nfs    rw,hard,rsize=8192,wsize=8192,timeo=14,intr     0 0
10.5.255.163:/mnt/EES_SYSTEM_REFRESH /mnt/EES_SYSTEM_REFRESH nfs rw,hard,rsize=8192,wsize=8192,timeo=14,intr    0 0
OK: No read-only file systems found
                     nfs    3.0T  200M  2.9T   1% /backup2
                     nfs    3.0T  200M  2.9T   1% /mnt/EES_SYSTEM_REFRESH
                     
[root@MGGGBJSECCX02 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux MGGGBJSECCX02 2.6.32-573.26.1.el6.x86_64 #1 SMP Tue Apr 12 01:47:01 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 07:42:29 GMT 2020
ZONE="UTC"
UTC=true
10.5.255.163:/backup2   /backup2 nfs    rw,hard,rsize=8192,wsize=8192,timeo=14,intr     0 0
10.5.255.163:/mnt/EES_SYSTEM_REFRESH /mnt/EES_SYSTEM_REFRESH nfs rw,hard,rsize=8192,wsize=8192,timeo=14,intr    0 0
10.5.255.163:/backup2   /backup2 nfs    rw,hard,rsize=8192,wsize=8192,timeo=14,intr     0 0
10.5.255.163:/mnt/EES_SYSTEM_REFRESH /mnt/EES_SYSTEM_REFRESH nfs rw,hard,rsize=8192,wsize=8192,timeo=14,intr    0 0
OK: No read-only file systems found
                     nfs    3.0T  200M  2.9T   1% /backup2
                     nfs    2.0T  1.3T  614G  68% /mnt/EES_SYSTEM_REFRESH
                     

MGGGBJSGTSX01	10.133.18.183	Sandbox
[root@MGGGBJSGTSX01 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJSGTSX01 2.6.32-754.24.3.el6.x86_64 #1 SMP Tue Nov 12 06:01:24 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 03:16:31 GMT 2020
ZONE="America/New_York"
OK: No read-only file systems found
                     nfs    6.6T  2.9T  3.4T  47% /sds
                     
[root@MGGGBJSGTSX01 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux MGGGBJSGTSX01 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 07:29:09 GMT 2020
ZONE="America/New_York"
OK: No read-only file systems found
                     
                     

MGGGBJSGTSX02	10.133.18.184	Sandbox Hana DB	10.164.238.139	lonhana-1024-34.xsportal.local	root pw YABwCKx3
[root@mgggbjsgtsx02 tmp]# cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.5 (Santiago)
Linux mgggbjsgtsx02 2.6.32-431.el6.x86_64 #1 SMP Sun Nov 10 22:19:54 EST 2013 x86_64 x86_64 x86_64 GNU/Linux
Fri Feb  7 03:16:31 GMT 2020
ZONE="UTC"
UTC=true
OK: No read-only file systems found
10.5.255.163:/mnt/EES_SYSTEM_REFRESH        nfs    2.0T  1.3T  614G  68% /mnt/EES_SYSTEM_REFRESH
lon02ammsol01.imzcloud.ibmammsap.local:/sds nfs    6.6T  2.9T  3.4T  47% /sds

 
 IA2WDDEVAPP 	10.133.16.59	66.248.245.59
 IA2PODEVDBAPP 	10.133.16.45	66.248.245.45
 IA2PODQASWD 	10.133.16.46	66.248.245.46
 
 
 A0EASG014XVM003 snapshot
 
 
CS1926507	Tata Steel Limited -- TTA	P3 - Minor	Disk Utilization /home CRITICAL: Free 108.34MB/19.51% (thresh @10.01:20%)	SAPAPP18


CS1926660	A.P. Moller Maersk -- APM	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 29.06 (thresh: 16)
----------------------------------------------------------------------------------------------------------
8 Feb

CS1942198 A.P. Moller Maersk -- APMP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 30.47 (thresh: 16)
CS1942949 St. Jude Medical , USA -- JUEP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 26.35 (thresh: 16)

CS1942172 LSPI -- LSPP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB)), \??\X:\pagefile.sys 3.605GB (4.75GB), total 3.8GB (4.945GB)	10.4.2.12 
CS1942171 LSPI -- LSPP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), \??\X:\pagefile.sys 3.605GB (4.75GB), total 3.8GB (4.945GB)	10.4.2.12 



CHG0137344
spsvopitsql01 10.6.3.34 10.70.111.34	A0EASG012XVM041	32GB RAM Paging 48GB

Add 6gb to Hard disk 0 and add new disk of 60GB to all the servers listed above.

Right click on each VM, click on Edit settings.
Select Hard disk 0 and increase by 6gb.
Click Add and select Hard disk and Click next.
Select "Create a New Virtual Disk" and click next.
Type the Disk capacity - 60GB, Click next twice and click finish.

1. Right click on Start, and then click System.
2. Click on "Advanced System settings".
3. In the System Properties window that pops up, click on Settings for Performance under Advanced tab.
4. Click on Advanced tab again and click on change button.
	5. Now under "Paging file for each drive" select C drive.
	6. Under custom size change both initial and Maximum size to 6144 MB and click on set.
7. Now under "Paging file for each drive" select X drive.
8. Under custom size change both initial and Maximum size to 43008 MB and click on set.
9. Click OK until all the dialog boxes are closed.
10. You will see a pop-up asking to restart, click on restart.
11. Once all the servers is back online, validate OS.

spsvopltapp01    10.6.3.35    10.70.111.35-- A0EASG012XVM042
spsvcpivsql01	10.6.3.36	A0EASG012XVM047	10.70.111.36	OpenText Content: Primary DNS
spsvopivapp01	10.6.3.37	A0EASG012XVM046	10.70.111.37	OpenText Content: Secondary DNS and SMTP Relay
spsvtplnapp01	10.6.3.44	A0EASG012XVM057	10.70.111.44	Tomatosx Runtime
spsvmplmase01	10.6.3.45	A0EASG012XVM055 10.70.111.45




CS1945383 Manchester Airport Group -- MNGP3 - MinorFree_disk_space_is_less_than_20%_on_OS_volume_/va


CS1945416 Panasonic North America -- PN4P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 22.07 (thresh: 16)

-------------------------------------------------------------------------------------------------------------------------

11 Feb

CS1980697CMA CGM -- CMAP3 - MinorDisk Utilization /home CRITICAL: Free 463.31MB/18.51% (thresh @10.01:20%)

-------------------------------------------------------------------------------------------------------------------

12 Feb


sjmdepaa01 / 10.198.11.10 (A0FGSG014XVM001) and sjmdepdb01/10.198.11.11	CHG0141445	CTASK0171389
10.116.35.150	snghana-1024-6.xsportal.local	root/GfsGim%D9voUCc@



ECC           ptpbromo	                192.168.166.12	10.70.31.16	ptpbromo	{U2gJI*E                192.168.166.12	10.70.31.16
					
GRC          ptpborobudur	        192.168.166.18	10.70.31.33	ptpborobudur cstsap(PTP - PT Anugerah Pharmindo Lestari (PTP) - BGC0001E5B
)	         192.168.166.18	10.70.31.33

PO             ptprajaampat	         192.168.166.35	10.70.31.22        ptprajaampat             192.168.166.35	10.70.31.22 

----------------------------------------------------------------------------------------------------

13 Feb

CHG0141647	
DPQ
sjmdpqja01	A0FGSG014XVM011	10.198.11.19		10.198.11.19 	10.195.2.19
sapdpqdb01	A0FGSG014XVM012	10.198.11.20 sybase	10.198.11.20 	10.195.2.20
DRP:
sjmdcpaa01	A0FGSG014XVM003	10.198.11.13 DRP CI	10.198.11.13 	10.195.2.13
sjmdcpdb01	10.198.11.14 hana DB	10.198.11.14 	10.195.2.14	10.116.35.150	snghana-1024-6.xsportal.local	root  GfsGim%D9voUCc@

will be down for CHG0141647

-------------------------------------------------------------------------------------------------------------------

14 feb

CS2016227 AGEAS -- AGEP1 - SevereSAP-HEC-SWIVEL-HEC: Increase 1TB FS space for E:\ drive
SPSVCPIVSQL01 	10.6.3.43 	10.70.111.36	A0EASG012XVM047



a) tftp/ftp service are deactivated at operating system level. Pls share evidence with query executed to corroborate this.

b) Only the minimum number of services required to support the business are activated. Pls share evidence with query executed to corroborate this.

c) All user accounts are password protected and such passwords are encrypted/stored securely. Pls share evidence with query executed to corroborate this.

d) What are the settings of the following password parameters. Pls share evidence with query executed to corroborate this. 
Â·       MAXAGE (number of weeks a password is valid)
Â·       MAXEXPIRED (number of weeks that the password can be changed by the user even after "maxage" weeks went by),
Â·       MINLEN (minimum length of a password)
Â·       HISTEXPIRE (Number of weeks before password can be reused)
Â·       HISTSIZE (Defines the number of previous passwords a user cannot reuse)
Â·       LOGINRETRIES (number of unsuccessful login attempts allowed).

e) Auditing is enabled at operating system level. Pls share evidence with query executed to corroborate this.


No.	Server Name
1	10.170.61.121 - sapapp15 
2	10.170.61.116 - sapapp18 
3	10.170.61.74 - sapapp19 
4	10.170.61.48 - sapapp20 
5	10.170.61.131 - sapapp21 
6	10.170.61.231 - sapapp22
7	10.170.61.226 - sapapp23 
8	10.170.61.176 - sapapp26 
9	10.170.61.166 - sapapp27 
10	10.170.61.211 - sapapp28
11	10.170.61.141 - sapapp29 
12	10.170.61.161 - sapapp30 
13	10.170.61.27 - sapcrmapp1
14	10.170.61.96 - sapcrmapp3
15	10.170.61.22 - r3dev
16	10.170.61.241 - ewmapp2


service --status-all |grep -i active


CS2017751	AGEAS -- AGE	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS2017022	Tecnologia De Materiales S.A. -- TDM	P2 - Major	Memory Swap CRITICAL: Swap free 49.22% (thresh 50:%)



che01ammsol01.imzcloud.ibmammsap.local:/sds  nfs4      3.6T  2.9T  540G  85% /sds


CS2019671	AGEAS -- AGE	P2 - Major	Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)
CS2020067	AGEAS -- AGE	P3 - Minor	Disk Utilization / CRITICAL: Free 4885.00MB/19.94% (thresh @10.01:20%)
CS2020203	A.P. Moller Maersk -- APM	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 69.17 (thresh: 60)
------------------------------------------------------------------------------------------------------------

15 Feb

CS2018904
VM snap shot - sapcrmdi - host - Tomorrow - 9:00 AM !!!	TSTS steel chennai


CHG0141842	CTASK0172522	SPSVEPAJAPP01 (10.6.3.13)	A0EASG014XVM039


DB:
PN8US7LDBCP4	10.12.255.36
PN8US7LDBCP4H	10.12.255.37
APP:
PN8US7LECCP4	10.12.255.38
PN8US7LECCP4H	10.12.255.39 (edited) 



PN8US7LBCP0	10.12.255.43  patching in prog




 vcenter-fencing-node1  (stonith:fence_vmware_soap):    Started pn8us7ldbcp4h (unmanaged)
 vcenter-fencing-node2  (stonith:fence_vmware_soap):    Started pn8us7ldbcp4 (unmanaged)


Masters: [ pn8us7ldbcp4h ]
     Slaves: [ pn8us7ldbcp4 ]

------------------------------------------------------------------------------------------------------------

18 Feb 8173000150


SPSVCPIVSQL01 	10.6.3.43 	10.70.111.36 	A0EASG012XVM047	
E drive to 1 TB



Gwye7Y%KMhCHhJ@



CS2056109 & CS2056367


CS2056238	Tata Steel Limited -- TTA	P2 - Major	SQ-SAP-TRIO-C1	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 61.98 (thresh: 60)


~ # vim-cmd vmsvc/getallvms
Vmid       Name                           File                         Guest OS      Version     Annotation
4      IA1S4HSBXDB     [hanadata1] IA1S4HSBXDB/IA1S4HSBXDB.vmx       rhel6_64Guest   vmx-10
5      IA1S4HQASDB     [hanadata1] IA1S4HQASDB/IA1S4HQASDB.vmx       rhel6_64Guest   vmx-10
6      MGGGBJDECCX02   [hanadata1] MGGGBJDECCX02/MGGGBJDECCX02.vmx   rhel6_64Guest   vmx-10    Meggitt;DEV;DB

---------------------------------------------------------------------------------------------------------------------------

19 Feb

rexqpaweb1n	10.134.2.9	10.135.2.16	
rexqpaeng1n	10.134.2.13	10.135.2.11 	
rexppaweb1n	10.134.1.12	10.135.1.12
rexppaeng1n	10.134.1.13	10.135.1.8
mtsprdbodsapp01	unknown	not found must be deactivated
mtsprdbods01	unknown not found must be deactivated
mtsiaasdev1	10.60.6.65	Manitoba Telecom Services -- MTS 	MTSIAASDEV1 	10.74.6.65 	10.60.6.65 	Development 	Pending Deactivation
mtsprdepdb1	unknown not found must be deactivated


CS2065602
While performing change CHG0142176, HANA DB is not starting. Some processes are not killed. Please reboot the VM:
IA2MDGPRDDB - 10.133.15.35
10.164.30.233	lonhana-1024-48.xsportal.local	root  PorYup%WD6ofTZ@	



CS2067345	Bombardier Recreational Products Inc -- BR3	P2 - Major	SQ-SAP-TRIO-C1	Log PaceMaker-log Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-02-18-23-42-58 for details.


 CS2067573	IAG - British Airways -- IA2	P2 - Major	SQ-SAP-TRIO-C1	(Received during suppression) Ping Availability CRITICAL - 10.133.15.35: rta nan, lost 100%
 
 CS2067574	IAG - British Airways -- IA2	P2 - Major	SQ-SAP-TRIO-C1	(Received during suppression) Ping Availability CRITICAL - 10.133.15.35: rta nan, lost 100%

Sjmcnadm	sjmdfpaa01
sjmpiadm' & 'sjmcnadm'  

Server sjmdfpaa01  / 10.198.11.17



DLBPECAP02 & DLBPECAP01    for P1  CS2068920

------------------------------------------------------------------------------------------------------

20 Feb

CS2069239 - check filesystem /sapmnt/data for I/O errors ---> Need to restore DB please join the #scx-sapc1-ia2
IAG - British Airways -- IA2 	IA2MDGPRDDB 	10.133.15.35 	66.248.244.35	lonhana-1024-48.xsportal.local		root	 PorYup%WD6ofTZ@

[root@ia2mdgprddb ibmrmalik]$ pvs |grep -i sdb
  /dev/sdb1  vghanadata lvm2 a--  539.00g 2.00g
  
  sdb                                    8:16   0  539G  0 disk
â””â”€sdb1                                 8:17   0  539G  0 part
  â”œâ”€vghanadata-lv_hana_data (dm-0)   253:0    0  768G  0 lvm  /sapmnt/data
  â”œâ”€vghanadata-lv_usr_sap (dm-1)     253:1    0   50G  0 lvm  /usr/sap
  â””â”€vghanadata-lv_hana_shared (dm-2) 253:2    0  256G  0 lvm  /sapmnt/shared

CS1690495 sl ticket
https://cloud.ibm.com/unifiedsupport/cases?number=CS1690495


Standard SSH Protocol / Verify LDAP protocol
a0easg014xvm001 - 10.70.110.11 - AGEAS -- AGE [ibmrmalik@sveq1srv0 ~]$ hostname -i
10.70.110.11  10.6.2.11		

agehvcpmhsrv0 - 10.8.3.15 - AGEAS -- AGE	HK
sphvepaeapp02-dr - 10.6.3.12 - AGEAS -- AGE	HK
spsvbpdbhdb01 - 10.6.3.17 - AGEAS -- AGE 	HANA
svbq1hdbsrv0 - 10.6.2.13 - AGEAS -- AGE




CS2078202	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	SQ-SAP-TRIO-C2	CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%


10.166.156.221	root	ftAJVS%ELzVBOJ@

10.166.156.223	root	P2d3Ys%ImwwtdL@



lonhana-2048-1.xsportal.local	A0D8UK014XVM036	Feb 16th	02/16/18 02:31 PM	10.113.60.218 root/ tkkX95%uzEJaCF@	
lonhana-2048-1.xsportal.local	A0D8UK014XVM037	1-333960033	02/01/18 02:24 AM	Pankajesh	Not able to access
lonhana-2048-3.xsportal.local	A0D8UK014XVM034	Feb 16th_2	02/16/18 10:27 AM	10.113.60.220 root/ E4eBQK%vZn00Ye@
lonhana-2048-3.xsportal.local	A0D8UK014XVM035	1-331294972	11/09/17 11:28 PM	Pankajesh	Not able to access




MGGGBJDECCX02 - getting the outage repeated - similar issue on Feb 18, 2020
MGGGBJDECCX01 - got to check now


10.164.30.187    lonhana-1024-6.xsportal.local 	root	Gwye7Y%KMhCHhJ@

EED / EDJ - HANA DB MGGGBJDECCX02 10.133.18.166  

-------------------------------------------------------------------------------------------------------------
21 Feb



zffpoth002	100.126.67.7	100.126.67.7
zffpoth001	100.126.67.10	100.126.67.10 	
armfksap305a1	10.7.102.71	fixed




CS2097481 Rexel -- HGMP2 - MajorVM backup failures for 2 VMs 
 	REXQPAWEB1N 	10.135.2.16 	10.134.2.9
 	REXBFCWEB02 	10.135.1.75 	10.134.1.75 	


CS2098595 Tata Steel Limited -- TTAP2 - MajorCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%


CS2097481-




BS5PIDEV 	10.141.133.22 	132.133.0.22

BS5DEVAPP 	10.141.133.14 	132.133.0.13


FS which will be mounted on Bs5pidev, that should be sharable with the host BS5DEVAPP-132.133.0.13.

Mountpoint will be created as /usr/sap/interface/bank  with the size of 10GB



CS1595384 - LZASOLDEV0
LZASOLDEV0 	10.4.3.29 	10.4.1.29

-----------------------------------------------------------------------------------------------------------------------

22 Feb

CS2111399  Tata Steel Limited -- TTAP2 - Major(Received during suppression) ITM Agent Offline: CQB-sapcrmapp3_CPA_00:Ins



pn8 patching

PN8US7LDBCP5	10.12.255.15	PN8US7LDBCP5 	10.12.255.15 	10.129.32.15
[root@pn8us7ldbcp5 tmp]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux pn8us7ldbcp5 4.4.121-92.104-default #1 SMP Thu Mar 21 11:56:07 UTC 2019 (3f04f94) x86_64 x86_64 x86_64 GNU/Linux
Sat Feb 22 00:40:14 PST 2020
DEFAULT_TIMEZONE="US/Eastern"
TIMEZONE="America/New_York"
10.129.32.80:/CQ5mig    /CP5MockMig     nfs     defaults,nfsvers=3 0 0
ssapp-pn8-cp5:/export/sapmnt/CP5        /sapmnt/CP5     nfs     defaults,nfsvers=3 0 0
10.129.32.18:/interfaces        /interfaces     nfs     defaults 0 0
#10.136.33.25:/CQ5CMSmig                /CP5export      nfs     defaults 0 0
OK

[root@pn8us7ldbcp5 ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux pn8us7ldbcp5 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Feb 22 04:51:55 EST 2020
DEFAULT_TIMEZONE="US/Eastern"
TIMEZONE="America/New_York"
10.129.32.80:/CQ5mig    /CP5MockMig     nfs     defaults,nfsvers=3 0 0
#ssapp-pn8-cp5:/export/sapmnt/CP5       /sapmnt/CP5     nfs     defaults,nfsvers=3 0 0
10.129.32.18:/interfaces        /interfaces     nfs     defaults 0 0
#10.136.33.25:/CQ5CMSmig                /CP5export      nfs     defaults 0 0
OK


PN8US7LDBCP5H	10.12.255.16  	PN8US7LDBCP5H 	10.12.255.16 	10.129.32.16
[root@pn8us7ldbcp5h tmp]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux pn8us7ldbcp5h 4.4.121-92.104-default #1 SMP Thu Mar 21 11:56:07 UTC 2019 (3f04f94) x86_64 x86_64 x86_64 GNU/Linux
Sat Feb 22 00:40:03 PST 2020
DEFAULT_TIMEZONE="US/Eastern"
TIMEZONE="America/New_York"
10.129.32.80:/CQ5mig    /CP5MockMig     nfs     defaults,nfsvers=3 0 0
ssapp-pn8-cp5:/export/sapmnt/CP5        /sapmnt/CP5     nfs     defaults,nfsvers=3 0 0
10.129.32.18:/interfaces        /interfaces     nfs     defaults 0 0
#10.136.33.25:/CQ5CMSmig         /CP5export      nfs     defaults 0 0
OK

[root@pn8us7ldbcp5h ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux pn8us7ldbcp5h 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Feb 22 05:22:57 EST 2020
DEFAULT_TIMEZONE="US/Eastern"
TIMEZONE="America/New_York"
10.129.32.80:/CQ5mig    /CP5MockMig     nfs     defaults,nfsvers=3 0 0
#ssapp-pn8-cp5:/export/sapmnt/CP5       /sapmnt/CP5     nfs     defaults,nfsvers=3 0 0
10.129.32.18:/interfaces        /interfaces     nfs     defaults 0 0
#10.136.33.25:/CQ5CMSmig         /CP5export      nfs     defaults 0 0
OK



"/sapmnt/CP5
[root@pn8us7ldbcp5 tmp]$ cat /etc/fstab |grep -i /sapmnt/CP5
ssapp-pn8-cp5:/export/sapmnt/CP5        /sapmnt/CP5     nfs     defaults,nfsvers=3 0 0

[root@pn8us7ldbcp5h tmp]$ cat /etc/fstab |grep -i /sapmnt/CP5
ssapp-pn8-cp5:/export/sapmnt/CP5        /sapmnt/CP5     nfs     defaults,nfsvers=3 0 0




Node pn8us7ldbcp5: UNCLEAN (online)
Online: [ pn8us7ldbcp5h ]


Online: [ pn8us7ldbcp5h ]
OFFLINE: [ pn8us7ldbcp5 ]



snghana-1024-18.xsportal.local	ADNAELQADB	before67	03/04/18 06:39 AM	10.116.145.8	5WRuIG%jHd1XPy@
snghana-1024-19.xsportal.local	ADNMP1QADB	before67	03/04/18 06:40 AM	10.116.145.62	tzeVQ9%tdJdNXM@

PN8US7LECCP5H 	10.12.255.17 	10.129.32.17 	
PN8US7LECCP5 	10.12.255.18 	10.129.32.18

PN8US7LECCP5
PN8US7LECCP5H
	PN8US7LDBCP5
	PN8US7LDBCP5H 



role:Primary
  disk:UpToDate
  pn8us7leccp5 connection:StandAlone
  
  
  
  .15
  stat("/interfaces",
  
  .16
  
stat("/interfaces",


CS2113303	Dilip Buildcon Limited -- DLB	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 21.04 (thresh: 16)
CS2113204	Apple Leisure Group -- AV1	P2 - Major	Ping Availability CRITICAL - 10.68.213.12: Host unreachable @ 10.143.69.196. rta nan, lost 100%


CS2113543	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Ping Availability CRITICAL - 10.12.255.19: rta nan, lost 100%
CS2113550	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Ping Availability CRITICAL - 10.12.255.20: rta nan, lost 100%

CS2113575	Panasonic North America -- PN8	P2 - Major	(Received during suppression) LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.05 (thresh: 16)
CS2113588	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)
CS2113571	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Log PaceMaker-stonith-ng Found 6 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-


CS2113573	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)
CS2113579	Panasonic North America -- PN8	P2 - Major	Log PaceMaker-stonith-ng Found 6 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-02-22-03-05-37 for details.

CS2113574	Panasonic North America -- PN8	P2 - Major	Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-02-21-23-08-14 for details.
CS2113587	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Service Pacemaker stonithd CRITICAL: 0 /usr/lib64/pacemaker/stonithd processes running (thresh 1:)


CS2113585	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Resources DRBD CRITICAL: Role value Unknown found for resource r0 on host pn8us7leccp5
CS2113578	Panasonic North America -- PN8	P2 - Major	(Received during suppression) Service Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)


CS2113577	Panasonic North America -- PN8	P2 - Major	Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-02-22-04-44-34 for details. - 

CS2113798 Tata Steel Limited -- TTAP2 - MajorCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%

----------------------------------------------------------------------------------------------

24 Feb

snghana-1024-6.xsportal.local
	10.116.35.150	GfsGim%D9voUCc@
	ipmi PRruh5Pmj8
	
	
----------------------------------------------------------------------------------------------------------------------------------
25 Feb


ESOBPCDDB.imzcloud.ibmammsap.local  -root password expired,
AM3S4DEVDB.imzcloud.ibmammsap.local -> . CHEF run is failing , root password expired,
sirs4qashana.imzcloud.ibmammsap.local -> CHEF run failing because of root password expired.



10.143.69.172	delta-dal09-phana-4096-01.imzcloud.ibmammsap.local   ipmi LdMD6pDueW	dlthbehdb	SL ticket CS1696696


Snapshot for host - SVJD1SRV0	A0EASG014XVM003
2:14 PM
CSR# CHG0142893




26 Feb

CHG0140001	

SMGWDEVDQ2 10.78.22.24 
[root@smgwdevdq2 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux smgwdevdq2 2.6.32-754.25.1.el6.x86_64 #1 SMP Wed Nov 20 15:07:26 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Tue Feb 25 06:56:21 UTC 2020
UTC=true
10.5.22.12:/migrations          /migrations              nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
146.89.141.91:/storage          /storage                 nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
####par01ammsol01.imzcloud.ibmammsap.local:/sds /sds     nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
146.89.140.93:/storage/library/sap/MSD_Software/        /storage/library         nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
10.5.26.11:/usr/sap/trans       /usr/sap/trans           nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
10.5.22.12:/migrations          /migrations              nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
146.89.141.91:/storage          /storage                 nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
####par01ammsol01.imzcloud.ibmammsap.local:/sds /sds     nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
146.89.140.93:/storage/library/sap/MSD_Software/        /storage/library         nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
10.5.26.11:/usr/sap/trans       /usr/sap/trans           nfs4 rw,hard,intr,rsize=32768,wsize=32768 0 0
OK: No read-only file systems found


SMBWDEVDW1 10.78.22.59
SMDBDEVDW1 10.78.22.47
SMECCDEVDE1 10.78.22.18
SMDBDEVDE1 10.78.22.17
SMGRCDEVDG1 10.78.22.48





BES client
conspphanaq	10.151.21.160
conspphamdc2	10.151.21.161
br3psolss40	10.138.13.49
br3psolss41	10.3.113.130, 10.3.113.42
br3psolss43	10.138.13.51
br3psolss42	10.3.113.37, 10.3.113.52


SVJQ1SRV0	A0EASG014XVM004
CSR # CHG0143062


CS2152193   Tata Steel Limited -- TTA   Server : TRACEROUTE from source IP (10.170.63.25)  to any of the following destination range is not giving the desired results   SQ-SAP-TRIO-C1   P3
-----------------------------------------------------------------------------------

27 Feb

#scx-sapc2-dal
Reference dlthpehp4	10.4.5.56	10.250.17.56

Copy same NFS parameters to
DLTHPEHAP9	10.4.5.202	10.250.17.209
DLTHPEHAP10	10.4.5.206	10.250.17.214
DLTHPEHAP11	10.4.5.205	10.250.17.215
DLTHPEHAP12	10.4.5.204	10.250.17.212
DLTHPEHAP13	10.4.5.203	10.250.17.211


NFS source DLTHPEHP1


CS2162345   St. Jude Medical -- JU1   SAP-HEC-SWIVEL-Pls set sjmcnadm to password un-expired[00148672/2020]   SQ-SAP-TRIO-C2   P1

CS2102621  CS2158462, CS2158463 & CS2158497 

---------------------------------------------------------------------------------------------------------------

28 Feb


conspphamdc2	10.151.21.161
conspphanaq	10.151.21.160
dysadsapdsp10	10.6.11.59
LONCFGCHP0003	
LONCFGCHP0004	
MGGDRDGTSX04	10.5.254.21




CS2173889
TNGPRODEAPP01 	10.134.2.12 	172.24.2.12
Please help to unlock/reset password of local account cuongbt on the server (172.24.2.12).



10.162.24.252	che01-pod1-4tb-host02.imzcloud.ibmammsap.local	q0YCIE%z1ErDTK@


CS2175539 Tata Steel BSL Ltd -- BS5More mountpoint has to be added at BS5PIPRD-132.132.0.25

BS5PIPRD 	10.141.132.23 	132.132.0.25 	

Kindly map the below mountpoint at 132.132.0.25 server. Mountpoint name and its size is given below : 

/oracle/ABP       20G		oracle_vg   abp_lv
/oracle                10G		oracle_lv
/oracle/client    2G
/oracle/stage    15G
/oracle/ABP/oraarch     10G
/oracle/ABP/sapdata1   10G
/oracle/ABP/sapdata2   10G
/oracle/ABP/mirrlogB    2G
/oracle/ASD/mirrlogA    2G
/oracle/ASD/origlogA    2G
/oracle/ASD/origlogB    2G

[root@bs5piprd ibmrmalik]# df -hT |grep -i oracle
/dev/mapper/pipdatavg-oracle_lv             ext4      9.8G   23M  9.2G   1% /oracle
/dev/mapper/pipdatavg-client_lv             ext4      2.0G  188M  1.7G  11% /oracle/client
/dev/mapper/pipdatavg-stage_lv              ext4       15G  8.1G  5.8G  59% /oracle/stage
/dev/mapper/pipdatavg-oraarch_lv            ext4      9.8G   23M  9.2G   1% /oracle/ABP/oraarch
/dev/mapper/pipdatavg-sapdata1_lv           ext4      9.8G   23M  9.2G   1% /oracle/ABP/sapdata1
/dev/mapper/pipdatavg-sapdata2_lv           ext4      9.8G   23M  9.2G   1% /oracle/ABP/sapdata2
/dev/mapper/pipdatavg-mirrlogB_lv           ext4      2.0G  3.0M  1.8G   1% /oracle/ABP/mirrlogB
/dev/mapper/pipdatavg-mirrlogA_lv           ext4      2.0G  3.0M  1.8G   1% /oracle/ASD/mirrlogA
/dev/mapper/pipdatavg-origlogA_lv           ext4      2.0G  3.0M  1.8G   1% /oracle/ASD/origlogA
/dev/mapper/pipdatavg-origlogB_lv           ext4      2.0G  3.0M  1.8G   1% /oracle/ASD/origlogB

[root@bs5piprd ibmrmalik]# df -hT |grep -i /Oracle
/dev/mapper/pipdatavg-abp_lv                ext4       20G   44M   19G   1% /oracle/ABP
/dev/mapper/pipdatavg-oracle_lv             ext4      9.8G   23M  9.2G   1% /oracle
/dev/mapper/pipdatavg-client_lv             ext4      2.0G  188M  1.7G  11% /oracle/client
/dev/mapper/pipdatavg-stage_lv              ext4       15G  8.1G  5.8G  59% /oracle/stage
/dev/mapper/pipdatavg-mirrlogA_lv           ext4      2.0G  3.0M  1.8G   1% /oracle/ASD/mirrlogA
/dev/mapper/pipdatavg-origlogA_lv           ext4      2.0G  3.0M  1.8G   1% /oracle/ASD/origlogA
/dev/mapper/pipdatavg-origlogB_lv           ext4      2.0G  3.0M  1.8G   1% /oracle/ASD/origlogB


/dev/pipdatavg/abp_lv           /oracle/ABP     ext4     defaults       0 0
/dev/pipdatavg/oracle_lv        /oracle         ext4     defaults       0 0
/dev/pipdatavg/client_lv        /oracle/client  ext4     defaults       0 0
/dev/pipdatavg/stage_lv         /oracle/stage   ext4     defaults       0 0
/dev/pipdatavg/oraarch_lv       /oracle/ABP/oraarch     ext4     defaults      0 0
/dev/pipdatavg/sapdata1_lv      /oracle/ABP/sapdata1    ext4    defaults       0 0
/dev/pipdatavg/sapdata2_lv      /oracle/ABP/sapdata2    ext4    defaults       0 0
/dev/pipdatavg/mirrlogB_lv      /oracle/ABP/mirrlogB    ext4     defaults      0 0
/dev/pipdatavg/mirrlogA_lv      /oracle/ASD/mirrlogA    ext4     defaults      0 0
/dev/pipdatavg/origlogA_lv      /oracle/ASD/origlogA    ext4     defaults      0 0
/dev/pipdatavg/origlogB_lv      /oracle/ASD/origlogB    ext4     defaults      0 0



CS2175357 Tata Steel BSL Ltd -- BS5P2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 20.39 (thresh: 16) - 



SVJD1SRV0	A0EASG014XVM003	, SVWD1SRV0	A0EASG014XVM013
CHG0143374


10.6.1.26 (SVSD1SRV0) -CS2176568

/usr/sap/SD1 >> 20GB

[root@svsd1srv0 ibmrmalik]$ df -h /usr/sap/SD1
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                       40G   30G  8.2G  79% /usr/sap
                       
/usr/sap/trans >> 40GB

[root@svsd1srv0 ibmrmalik]$ df -hT /usr/sap/trans
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                     ext4   40G   30G  8.2G  79% /usr/sap



/usr/sap/ccms >> 5GB

[root@svsd1srv0 ibmrmalik]$ df -hT /usr/sap/ccms
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                     ext4   40G   30G  8.2G  79% /usr/sap

/usr/sap/DAA >> 4 GB

[root@svsd1srv0 ibmrmalik]$ df -hT /usr/sap/DAA
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                     ext4   40G   30G  8.2G  79% /usr/sap

/usr/sap/DAB >> 4GB

[root@svsd1srv0 ibmrmalik]$ df -hT /usr/sap/DAB
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                     ext4   40G   30G  8.2G  79% /usr/sap

/sapmnt/SD1 >> 20GB
[root@svsd1srv0 ibmrmalik]$ df -hT /sapmnt/SD1
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_sapmnt
                     ext4  9.8G  3.6G  5.7G  39% /sapmnt

[root@svsd1srv0 ibmrmalik]$ df -hT /sapmnt
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_sapmnt
                     ext4   30G  3.6G   25G  13% /sapmnt


[root@svsd1srv0 ibmrmalik]$ df -hT df -hT /usr/sap/DAB
df: `df': No such file or directory
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                     ext4  114G   30G   79G  28% /usr/sap


------------------------------------------------------------------------------------------------------------------------

29 Feb

CS2178394


CS2187491  Aceros Chilca - MEPSA -- AC5    Service rpcbind CRITICAL: 0 rpcbind processes running (thresh 1:) 


CS2187434	A.P. Moller Maersk -- APM	02-29-2020 09:10:55	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 93.85 (thresh: 16)	SQ-SAP-TRIO-C1
CS2187426	Panasonic North America -- PN4	02-29-2020 09:09:56	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 16.92 (thresh: 16)	SQ-SAP-TRIO-C2

----------------------------------------------------------------------------------------------------------------------------------------

4 March

CS2235728 BRENNTAG PTE LTD -- BAPP2 - MajorAdd Disk(empty)
CS2177456 - FS Disk Utilization /usr/sap/V33 
hostname: BAPV330900 	10.134.3.7 	10.8.217.13
Add 10gb disk to VG of fs /usr/sap/V33


Creating "VMware Tools" snapshot for virtual machine 'asddev'
ANS9365E VMware vStorage API error for virtual machine 'asddev'.
IBM Spectrum Protect function name : CreateSnapshot_USCORETask
IBM Spectrum Protect file          : ..\..\common\vm\vmvisdk.cpp (6766)
API return code   : 2249
API error message : An error occurred while saving the snapshot: Failed to quiesce the virtual machine.
ANS4067E Snapshot operation attempt 2 of 2 for the guest virtual machine 'asddev' failed using "VMware Tools" snapshot.
Backup failed.
ANS1228E Sending of object 'asddev' failed.
ANS5226E The virtual machine backup operation failed.


CS2237701 Egyptian Refining Company -- EGRP1 - SevereDisk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh 



CHG0143850 CTASK0177924	VM snap shot of host - SVJQ1SRV0	A0EASG014XVM004


sm9l182172003	10.139.224.130	10.135.224.63
4:07 PM
sm9l182172005	10.139.224.85	10.135.224.51
4:07 PM
sm9p185173114	10.139.224.152	10.135.224.28





-rw-------.  1 root   root            83299 Jan 29 03:44 messages.37.gz
-rw-------.  1 root   root            82763 Jan 30 03:50 messages.36.gz
-rw-------.  1 root   root            72892 Jan 31 03:28 messages.35.gz

----------------------------------------------------------------------------------------

5 March

 CS2251479 Tata Steel Limited -- TTAP3 - MinorDisk Utilization /var CRITICAL: Free 1166.20MB/17.77% (thresh @10.01:20%)SAPAPP26SQ-SAP-TRIO-C1
CS2250941 Tata Steel Limited -- TTAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPCRMAPP1- KB0010973SAPCRMAPP1SQ-SAP-TRIO-C1


 CS2251531 IAG GBS Limited -- IA1P2 - MajorSAP HEC SWIVEL - amm.ibmcloud.com expires on 2020/03/08 
 
 
 We need to shut down bs5piprd & bring up bs5piprd_Restore
 
 Cannot open the disk '/vmfs/volumes/4e3f8113-ca8bc3b7/bs5piprd_Restore/bs5piprd_Restore_11-000001.vmdk
9:00 PM
Cannot open the disk '/vmfs/volumes/4e3f8113-ca8bc3b7/bs5piprd_Restore/bs5piprd_Restore_9-000001.vmdk' or one of the snapshot disks it depends on.
9:00 PM
Cannot open the disk '/vmfs/volumes/4e3f8113-ca8bc3b7/bs5piprd_Restore/bs5piprd_Restore_10-000001.vmdk' or one of the snapshot disks it depends on.
 
 
 
 
 
 TQABWPRDH 	10.7.1.40 	10.200.0.40 	
 10.135.58.242	frahana-1024-10.xsportal.local	root	D!ng@reChintam1

 --------------------------------------------------------------------------------------------------
6 March

CS2020750
IFN: 10.146.2.10
DC: LON06
Summary: EventLog Setup CRITICAL: 1 message(s) [Setup:Microsoft-Windows-Servicing:7:Initiating changes to turn on update IIS-HttpErrors of package IIS-WebServer-Core-Pac



CS2263384	Inter Pipeline Fund -- IPL	P2 - Major	ITM Agent Offline: iplsawdat01:INTERNET00


CS2263496 Tata Steel Limited -- TTAP3 - MinorLinux server : Latency while uploading some invoices the status got stuck for more than an hour.




wkfqp1ap03      10.139.100.229


[root@qlaqd1s4haap ibmrmalik]# date
Fri Mar  6 10:39:07 UTC 2020
1h
Ravi Malik (TRIO C - OS Support)  [root@qlaqd1s4hadb ibmrmalik]# date
Fri Mar  6 10:42:30 UTC 2020




CHG0143900
DEV
Hostname: S4HDEV
IP address: 10.207.62.16

QAS
Hostname: ECCTEST
IP address: 10.207.63.19
-------------------------------------------------------------------------------------------------------
 7 March



CS2273993	Manitoba Telecom Services -- MTS	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PRDEPDB1- KB0010973 


CHG0143761	Dal09
acerosprdhana	 	10.4.11.30  HANA 	10.155.223.106	dalhana-1024-11.xsportal.local
[root@acerosprdhana tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux acerosprdhana 2.6.32-573.el6.x86_64 #1 SMP Wed Jul 1 18:23:37 EDT 2015 x86_64 x86_64 x86_64 GNU/Linux
Sat Mar  7 03:24:52 PET 2020
ZONE="UTC"
UTC=true
OK: No read-only file systems found
                     nfs    6.6T  3.2T  3.1T  51% /sds
                     
[root@acerosprdhana etc]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux acerosprdhana 2.6.32-573.26.1.el6.x86_64 #1 SMP Tue Apr 12 01:47:01 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux
Sat Mar  7 04:31:49 PET 2020
ZONE="UTC"
UTC=true
OK: No read-only file systems found
                     


[root@acerosprdhana tmp]$ yum check-update |grep kernel
kernel.x86_64                       2.6.32-573.26.1.el6       rhel-6-server-rpms
kernel-devel.x86_64                 2.6.32-573.26.1.el6       rhel-6-server-rpms
kernel-firmware.noarch              2.6.32-573.26.1.el6       rhel-6-server-rpms
kernel-headers.x86_64               2.6.32-573.26.1.el6       rhel-6-server-rpms
libreport-plugin-kerneloops.x86_64  2.0.9-25.el6_7            rhel-6-server-rpms

	
acerosprdecc		10.4.11.31	app	A0FAUS014XVM004
[root@acerosprdecc tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux acerosprdecc 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Sat Mar  7 03:24:50 -05 2020
# The time zone of the system is defined by the contents of /etc/localtime.
# This file is only for evaluation by system-config-date, do not rely on its
# contents elsewhere.
ZONE="UTC"
UTC=true
acerosdevecc:/usr/sap/trans /usr/sap/trans nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found
                     nfs    5.1T  3.0T  1.8T  63% /storage
                     nfs    6.6T  3.2T  3.1T  51% /sds
                     nfs    136G   68G   61G  53% /usr/sap/trans
                     
[root@acerosprdecc ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux acerosprdecc 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat Mar  7 03:49:28 -05 2020
# The time zone of the system is defined by the contents of /etc/localtime.
# This file is only for evaluation by system-config-date, do not rely on its
# contents elsewhere.
ZONE="UTC"
UTC=true
acerosdevecc:/usr/sap/trans /usr/sap/trans nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found
                     nfs    136G   68G   61G  53% /usr/sap/trans


[root@sapapp23 ibmrmalik]$ sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
CRITICAL:  /usr /run/user/113666/gvfs filesystems are read-only
/usr/local/ncpa/etc/cmas_ksh_functions.sh: line 342: /usr/local/ncpa/var/log/cmas_checks.log: Read-only file system


CS2275796

/root
/boot
swap file system

except above comment all other FS in fstab

welcome123


sev1 for TATA  CS2275796  duplicate CS2275984 and tsm ticket was CS2274604
#scx-sapc1-tta
SUSE case TS003451512	
PRB0052026 and assigned RCA0002124

------------------------------------------------------------------------------------------------------------------------

9 March

CS2292974 St. Jude Medical , USA -- JUEP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 50.49 (thresh: 16)


iag-ba-customer-dr-test

DR INFO: (DR xls attached with DR server list)

DR VLAN:
VLAN 1125       66.248.245.192/26             IAG HANA DR              
VLAN 1126       10.199.15.192/26               IAG IMZ HANA DR  
           
VLAN 1127       66.248.244.0/24               IAG Non-HANA DR              
VLAN 1128       10.133.15.0/24                 IAG IMZ Non-HANA DR




Jannet david:white_check_mark:  4 hours ago
Still server prdepdb1 is not reporting to nagios ,Please work with network team if any network issue. or torubleshoot using the linux trouble shooting steps.
Jannet david:white_check_mark:  4 hours ago
Kindly troubleshoot using steps mentioned on below wiki page.
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/MHAS%20Nagios/page/Linux%20Troubleshooting
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/MHAS%20Nagios/page/Windows%20Troubleshooting
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/MHAS%20Nagios/page/Solaris%2010%20Troubleshooting




Prod Hostname	Prod CFN IP	Prod IFN IP
sm9l182172003	10.139.224.130	10.135.224.63
[2:48 PM]
sm9l182172005	10.139.224.85	10.135.224.51
[2:49 PM]
prod site: Frnakfurt, Dr site: Paris




IA1S4HPRDDBDR	66.248.245.200	10.199.15.200
access issue
Mar  9 10:28:14 IA1S4HPRDDBDR nfsidmap[54295]: nss_getpwnam: name 'root@ibmammsap.local' does not map into domain 'iag.amm.ibmcloud.com'
Mar  9 10:29:02 IA1S4HPRDDBDR sssd: SSSD couldn't load the configuration database [5]: Input/output error.


change  the  IA1 servers  vlan to  1127


filter_users = abrt, adm, bin, chrony, cinstall, custsap, da1adm, daaadm, daemon, dbus, ftp, games, gopher, haldaemon, halt, iuxnes, lp, mail, nfsnobody, nobody, ntp, operator, postfix, puppet, qemu, radvd, root, rpc, rpcuser, sapadm, saslauth, shutdown, sp1adm, sshd, sync, tcpdump, timagent, uucp, vcsa, zabbix


filter_users = abrt, adm, bin, chrony, cinstall, custsap, daaadm, daemon, dbus, ftp, games, gopher, haldaemon, halt, ibmdraalfaro, ibmdraamuru, ibmdraandreianu, ibmdraarias, ibmdraarjunan, ibmdraarroyo, ibmdrabagga, ibmdrabanerjee, ibmdraboertschoek, ibmdrabucur, ibmdrachacon, ibmdrachadaga, ibmdrachandnani, ibmdrachawla, ibmdrachivu, ibmdracordoba, ibmdradalcaran, ibmdradepasquale, ibmdradobra, ibmdraemmerich, ibmdrafernandez, ibmdraflorea, ibmdrafofirca-iacob, ibmdrafrunteanu, ibmdragahlawat, ibmdragiuroiu, ibmdragopal, ibmdragupta, ibmdrahareendran, ibmdraiacob, ibmdrailea, ibmdrajayaram, ibmdrajuturi, ibmdrak, ibmdrakhan, ibmdrakrishnappa, ibmdrakuchekar, ibmdrakumar, ibmdrakumar1, ibmdrakumar2, ibmdrakumar3, ibmdrakumari, ibmdralberto, ibmdramajumder, ibmdramandloi, ibmdramodeam, ibmdramote, ibmdran, ibmdranechifor, ibmdrapereira, ibmdraperez, ibmdrapestritu, ibmdrapires, ibmdrapirvulescu, ibmdrapopescu, ibmdrar, ibmdraraducan, ibmdraraileanu, ibmdraroy, ibmdrasen, ibmdrashanmuganathan, ibmdrashevni, ibmdrasilva, ibmdrasingh, ibmdrasoto, ibmdrasvoboda, ibmdratanasescu, ibmdratone, ibmdratrufin, ibmdravadgave, ibmdravalerin, ibmdraweiner, ibmdrazboril, ibmdrbalamita, ibmdrbarakerimath, ibmdrbbabuji, ibmdrbbacila, ibmdrbbagchi, ibmdrbboagiu, ibmdrbbuckland, ibmdrbbuddensab, ibmdrbcampbell, ibmdrbchaudhari, ibmdrbciorca, ibmdrbconejo, ibmdrbdediu, ibmdrbghosh, ibmdrbhoang, ibmdrbkovilpillai, ibmdrbmahapatra, ibmdrbmailman, ibmdrbmartis, ibmdrbmosher, ibmdrbpaingottoor, ibmdrbpanait, ibmdrbpetrusek, ibmdrbpisini, ibmdrbpoojari, ibmdrbreddappa, ibmdrbs, ibmdrbsukarso, ibmdrbtruskowski, ibmdrbwade, ibmdrcaguilera, ibmdrcanghel, ibmdrcanton, ibmdrcavula, ibmdrcbarboza, ibmdrccalin, ibmdrcchilapambatta, ibmdrcchirian, ibmdrccorduneanu, ibmdrccsaba, ibmdrcdavidson, ibmdrcdingare, ibmdrcdowless, ibmdrcfleseriu, ibmdrcgelu, ibmdrcgheorghita, ibmdrcgodinho, ibmdrcgracia, ibmdrchaidau, ibmdrcjurubita, ibmdrckaravadi, ibmdrcmatei, ibmdrcn, ibmdrcnavarro, ibmdrcneagoe, ibmdrcneculae, ibmdrcopra, ibmdrcpanaitescu, ibmdrcpopa1, ibmdrcporter, ibmdrcsandoval, ibmdrcsandu, ibmdrcshepard-hernandez, ibmdrcstan, ibmdrctudorache, ibmdrcvasudevan, ibmdrcvlad, ibmdrcvlad1, ibmdrcxirinachs, ibmdrdandries, ibmdrdapostol, ibmdrdarias, ibmdrdbalagula, ibmdrdbarganski, ibmdrdbarrantes, ibmdrdbavirisetty, ibmdrdbolduc, ibmdrdcasey, ibmdrdchiriches, ibmdrdciurgauan, ibmdrddooley, ibmdrdeslinger, ibmdrdgonzalez, ibmdrdhebert, ibmdrdhedge, ibmdrdherrera, ibmdrdilie, ibmdrdkober, ibmdrdkundu, ibmdrdlazar, ibmdrdlesovici, ibmdrdluca, ibmdrdmarin, ibmdrdmishra, ibmdrdnair, ibmdrdnunez, ibmdrdpandit, ibmdrdpelaez, ibmdrdramirez, ibmdrdross, ibmdrdrottigawad, ibmdrdsalles, ibmdrdtilea, ibmdrdv, ibmdrdveeranna, ibmdrdzinni, ibmdrebalogh, ibmdrecastro, ibmdrecoffman, ibmdreduran, ibmdregarita, ibmdrehurjui, ibmdremarin, ibmdremazilu, ibmdremedrano, ibmdremonge, ibmdreortiz, ibmdrepicado, ibmdrespataru, ibmdretautul, ibmdrevolz, ibmdrewaggoner, ibmdrfangelino, ibmdrfcalvo, ibmdrfdragomir, ibmdrffernandez, ibmdrfferoze, ibmdrffonseca, ibmdrfgroezinger, ibmdrfkhan, ibmdrfmunoz, ibmdrfwarnke, ibmdrgadam, ibmdrgaloysius, ibmdrgbarnes, ibmdrgeduru, ibmdrgfeodorov, ibmdrggrandison, ibmdrgguliman, ibmdrghale, ibmdrgindira, ibmdrgmontero, ibmdrgmurugesh, ibmdrgparkes, ibmdrgr, ibmdrgsaripalli, ibmdrgthinnakkakath, ibmdrgvanbout, ibmdrhbandaru, ibmdrhbiancardi, ibmdrhhaidaoui, ibmdrhjayadevappa, ibmdrhjayanthilal, ibmdrhjensen, ibmdrhkannan, ibmdrhkheria, ibmdrhmuppalla, ibmdrhreddy, ibmdrhschonz, ibmdrhshetty, ibmdrhtruong, ibmdriavasilichioaie, ibmdribumbar, ibmdriceausu, ibmdricomyns, ibmdridanaila, ibmdrigershovitz, ibmdrikarthikeyan, ibmdrikhan, ibmdrisoponariu, ibmdrivargas, ibmdrjaleman, ibmdrjalonso, ibmdrjalpizar, ibmdrjanand, ibmdrjarias, ibmdrjbillakanti, ibmdrjbrenes, ibmdrjc, ibmdrjcabreros, ibmdrjcastillo, ibmdrjcerdas, ibmdrjchavarria, ibmdrjchmal, ibmdrjcoutinho, ibmdrjdevaraj, ibmdrjgaber, ibmdrjgarita, ibmdrjholmes, ibmdrjjena, ibmdrjjimenez, ibmdrjjoseph, ibmdrjkraenzler, ibmdrjkuchi, ibmdrjlamicq, ibmdrjledezma, ibmdrjleon, ibmdrjmadrigal, ibmdrjmaier, ibmdrjmedina, ibmdrjmora, ibmdrjpasupuleti, ibmdrjporras, ibmdrjrodriguez, ibmdrjrodriguez1, ibmdrjsanchez, ibmdrjsherry, ibmdrjsiu, ibmdrjsloan, ibmdrjstark, ibmdrjvalasek, ibmdrjvega, ibmdrjvelado, ibmdrjvilla, ibmdrjviquez, ibmdrjyadav, ibmdrkananthu, ibmdrkbharathan, ibmdrkblair, ibmdrkchamarti, ibmdrkekbal, ibmdrkguettler, ibmdrkhoelzle, ibmdrkivanov, ibmdrkkhanra, ibmdrkkilpatrick, ibmdrkkumar, ibmdrklin, ibmdrkmishra, ibmdrkmudide, ibmdrknekkanti, ibmdrkpallapothu, ibmdrkqueen, ibmdrkraghuram, ibmdrkruiz, ibmdrks, ibmdrks1, ibmdrks2, ibmdrksanchez, ibmdrksankar, ibmdrkteja, ibmdrkvenkat, ibmdrkzhishev, ibmdrlandrei, ibmdrlayson, ibmdrlbalanescu, ibmdrlbuzea, ibmdrlcanciu, ibmdrllavers, ibmdrlmora, ibmdrlpapierz, ibmdrlpotha, ibmdrlrodgers, ibmdrlvargas, ibmdrlwaller, ibmdrlyu, ibmdrmabalaru, ibmdrmabdelkhalek, ibmdrmahmad, ibmdrmalcazar, ibmdrmandrei, ibmdrmansari, ibmdrmbabu, ibmdrmblenn, ibmdrmbrenes, ibmdrmbrown, ibmdrmbrown1, ibmdrmbuliga, ibmdrmcassidy, ibmdrmdongre, ibmdrmdoraswamy, ibmdrmgnanavelu, ibmdrmgodavari, ibmdrmgrandjean, ibmdrmhabib, ibmdrmholzinger, ibmdrmjain, ibmdrmkar, ibmdrmkaruppasamy, ibmdrmkayal, ibmdrmkeimig, ibmdrmkeller, ibmdrmkelm, ibmdrmkhan, ibmdrmkhrystoliubov, ibmdrmklacko, ibmdrmkumar, ibmdrmleon, ibmdrmm, ibmdrmmalhotra, ibmdrmmehra, ibmdrmmontero, ibmdrmmontero1, ibmdrmmurillo, ibmdrmnaidu, ibmdrmnakkina, ibmdrmpaszenda, ibmdrmpatel, ibmdrmpatel1, ibmdrmpoole, ibmdrmpopa, ibmdrmramirez, ibmdrmromero, ibmdrms, ibmdrmsharma, ibmdrmslate, ibmdrmsoni, ibmdrmsudhan, ibmdrmsyed, ibmdrmsylos, ibmdrmtanase, ibmdrmturner, ibmdrmuddin, ibmdrmuddin1, ibmdrmvargas, ibmdrmvargas1, ibmdrnadil, ibmdrnagarwal, ibmdrnalomar, ibmdrnbellary, ibmdrncastro, ibmdrndwivedi, ibmdrngranados, ibmdrngregorio, ibmdrnhegouaburu, ibmdrnjagtap, ibmdrnlangford, ibmdrnmacdougall, ibmdrnmahesh, ibmdrnmejias, ibmdrnmorales, ibmdrnradulet, ibmdrnrangarajan, ibmdrnschambureck, ibmdrnserbanescu, ibmdrnsutar, ibmdrnupendram, ibmdrobotnari, ibmdromohammed, ibmdropreotescu, ibmdrpabajo, ibmdrpadusumilli, ibmdrpallegaert, ibmdrpantonijevic, ibmdrpb, ibmdrpbodke, ibmdrpcioana, ibmdrpdas, ibmdrpdeb, ibmdrpdeb1, ibmdrpdumlao, ibmdrpgurjar, ibmdrpiannucci, ibmdrpionescu, ibmdrpivan, ibmdrpkakarla, ibmdrpkannaiyan, ibmdrpkoshti, ibmdrpkrishnaswamy, ibmdrpmacarie, ibmdrpmp, ibmdrpmuthusamy, ibmdrpnunnari, ibmdrppankaj, ibmdrppatel, ibmdrppayne, ibmdrpperam, ibmdrpperez, ibmdrprao, ibmdrprao1, ibmdrpravva, ibmdrpsaini, ibmdrpshaw, ibmdrpsingha, ibmdrpslavinskyi, ibmdrpsrivastava, ibmdrpthomas, ibmdrpthorat, ibmdrptudor, ibmdrpugalde, ibmdrpvarnum, ibmdrpvedpathak, ibmdrpvelu, ibmdrrachim, ibmdrrarguedas, ibmdrrarpasanu, ibmdrrbireddy, ibmdrrbufu, ibmdrrcaragea, ibmdrrchukkapalli, ibmdrrchulaki, ibmdrrdolor, ibmdrrgadewar, ibmdrrganguly, ibmdrrgheorghis, ibmdrrghosh, ibmdrrgolley, ibmdrrgopalan, ibmdrrgregg, ibmdrrhalankar, ibmdrrharitharan, ibmdrrinjamuri, ibmdrrjohnson, ibmdrrkamat, ibmdrrkartha, ibmdrrkathirchelvan, ibmdrrkommineni, ibmdrrkonduru, ibmdrrkorrapati, ibmdrrkukketi, ibmdrrkumar, ibmdrrleme, ibmdrrmalik, ibmdrrmatei, ibmdrrmitra, ibmdrrmohapatra, ibmdrrnanjundappa, ibmdrrnewhard, ibmdrrnichols, ibmdrrp, ibmdrrparampalli, ibmdrrpintalhao, ibmdrrpotluri, ibmdrrprabhakar, ibmdrrpursel, ibmdrrr, ibmdrrroba, ibmdrrromosan, ibmdrrsaenz, ibmdrrsarkar, ibmdrrsegneanu, ibmdrrsethurajan, ibmdrrsonea, ibmdrrvargas, ibmdrrvenkataramani, ibmdrrvetter, ibmdrrvillegas, ibmdrrwagner, ibmdrrweklar, ibmdrsaguilar, ibmdrsahmed, ibmdrsbalani, ibmdrsbasha, ibmdrsbehera, ibmdrsbhosale, ibmdrsbhure, ibmdrsbocharova, ibmdrsboppana, ibmdrsbueno, ibmdrscampos, ibmdrschalikondra, ibmdrschand, ibmdrschatterjee, ibmdrscherupally, ibmdrschivu, ibmdrschuenchoosap, ibmdrsciprian, ibmdrsdedu, ibmdrsdelgado, ibmdrsdinu, ibmdrsdraghici, ibmdrsduttaluri, ibmdrsfairley, ibmdrsflorea, ibmdrsgadugoyyala, ibmdrsgaripally, ibmdrsgaur, ibmdrsgutierrez, ibmdrshaidery, ibmdrshansoty, ibmdrshegde, ibmdrshorst, ibmdrshutanu, ibmdrsion, ibmdrsjain, ibmdrsjaishankar, ibmdrskancharlapullaiahgari, ibmdrskandala, ibmdrskareem, ibmdrskarka, ibmdrskhan, ibmdrskhare, ibmdrskoppala, ibmdrskoribilli, ibmdrskumar, ibmdrskuntrapakam, ibmdrskurapati, ibmdrskusay, ibmdrslakshmanan, ibmdrsm, ibmdrsmahapatra, ibmdrsmuzavor, ibmdrsn, ibmdrsn1, ibmdrsnair, ibmdrsnalla, ibmdrsnelapatla, ibmdrsnitu, ibmdrspal, ibmdrspandey, ibmdrspandiri, ibmdrspandita, ibmdrsparikh, ibmdrspaun, ibmdrspeddapalli, ibmdrspopa, ibmdrspr, ibmdrspulare, ibmdrsraita, ibmdrsramalingam, ibmdrsramirez, ibmdrsrao, ibmdrsrusu, ibmdrssafron, ibmdrssageli, ibmdrssbirnau, ibmdrssergiu-catalin, ibmdrsshaik, ibmdrsshrivastava, ibmdrsshrivastava2, ibmdrssubhani, ibmdrssyed, ibmdrsu, ibmdrsweger, ibmdrsyerramilli, ibmdrtgarcia, ibmdrtgoanta, ibmdrtgonzalez, ibmdrtharrington, ibmdrthastings, ibmdrtkrojzl, ibmdrtlee, ibmdrtmailadiyil, ibmdrtpathak, ibmdruputhuraya, ibmdrvbhamidipati, ibmdrvbheemarasetti, ibmdrvboosipally, ibmdrvbotas, ibmdrvchakkaravarthy, ibmdrvchandregowda, ibmdrvcristea, ibmdrvdama, ibmdrvgovindaraj, ibmdrvindireddy, ibmdrvjimenez, ibmdrvk, ibmdrvkosgi, ibmdrvkovarik, ibmdrvmaheshwari, ibmdrvmc, ibmdrvmunteanu, ibmdrvnovoa, ibmdrvprasad, ibmdrvpunna, ibmdrvr, ibmdrvreddy, ibmdrvruchandani, ibmdrvsaju, ibmdrvvadlapally, ibmdrvvaduva, ibmdrvvanaparla, ibmdrvvelasquez, ibmdrvvijay, ibmdrvvinodan, ibmdrwahmed, ibmdrwalawadhi, ibmdrwmohammed, ibmdrwmonzel, ibmdrwvalverde, ibmdrxlin, ibmdrybehki, ibmdryespinoza, ibmdrymian, ibmdrysoni, ibmdrytang, ibmdrythirunavukkarasu, ibmdrzhaider, ibmdrzlapkov, ibmdrzu, iuxnes, lp, mail, nfsnobody, nobody, ntp, operator, postfix, puppet, qemu, radvd, root, rpc, rpcuser, sapadm, saslauth, shutdown, smdadm, sp1adm, sshd, sync, tcpdump, timagent, uucp, vcsa, zabbix



wkfqp1ap03 10.139.100.229 , Error on root FS is causing backup failure for almost a week. Request immediate OS assistance - CS2262667
03/06/20 02:30:22 ANS1999E Incremental processing of '/' stopped.
03/06/20 02:30:23 ANS1028S An internal program error occurred.



Could you please help to mount â€œ/sapmnt/SP5â€ from app ia2s4hprdapp1 to app ia2s4hprdapp2, app ia2s4hprdapp3 and app ia2s4hprdapp4.

ia2s4hprdapp1	/sapmnt/SP5	XuXOhHjG4Ut%uXJ
ia2s4hprdapp2	BTyGH7ebg-,qnd7
ia2s4hprdapp3	Ue/HVZR;
ia2s4hprdapp4	g0|_0fR!

-----------------------------------------------------------------------------------------------

11 March



CHG0143390


CS2317547	Tata Steel Limited -- TTA	P2 - Major	SQ-SAP-TRIO-C1	Memory Swap	

CS2305433
SPSVMPLMASE01 	10.6.3.45 	10.70.111.45	Win





FRA to Paris SRM config access missing

Data is not available:

Permission to perform this operation was denied.

You do not hold privilege "HmsRemote.com.vmware.vcHms.Hbr.View".





CS2318240

The below 2 FS can be removed:
 
/dev/mapper/backupvg-backup_lv               4.5T   64M  4.3T   1% /backup
--> on sapapp26
[root@sapapp26 ibmrmalik]$ lvdisplay /dev/mapper/backupvg-backup_lv
  --- Logical volume ---
  LV Path                /dev/backupvg/backup_lv
  LV Name                backup_lv
  VG Name                backupvg
  LV UUID                CYnTJ7-8gfh-C5cv-ElkZ-m8eB-Ao4T-Fe3M7M
  LV Write Access        read/write
  LV Creation host, time sapapp26, 2019-03-29 14:03:13 +0530
  LV Status              available
  # open                 1
  LV Size                4.50 TiB
  Current LE             1179647
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     1024
  Block device           254:9
 
  /dev/sdc   backupvg    lvm2 a--    4.50t       0

sdc                          8:32   0  4.5T  0 disk
â””â”€backupvg-backup_lv       254:9    0  4.5T  0 lvm  /backup

[root@sapapp26 backup]$ lvremove /dev/backupvg/backup_lv
  Logical volume backupvg/backup_lv contains a filesystem in use.
[root@sapapp26 backup]$ dmsetup info -c | grep backup_lv
backupvg-backup_lv       254   9 L--w    1    1      0 LVM-3lT3zndmBjoR59mtMUay3m1NK4Tbf6MDCYnTJ78gfhC5cvElkZm8eBAo4TFe3M7M

[root@sapapp26 backup]$ lsof |grep "254,9"
bash       2709             root  cwd       DIR              254,9       4096          2 /
lsof      22141             root  cwd       DIR              254,9       4096          2 /
grep      22142             root  cwd       DIR              254,9       4096          2 /
lsof      22143             root  cwd       DIR              254,9       4096          2 /

sdc - SCSI 0:0:2:0

 
/dev/mapper/tempvg-import_lv                 3.0T   72M  2.9T   1% /Import
--> on sapapp19

[root@sapapp19 ibmrmalik]$ lvdisplay /dev/mapper/tempvg-import_lv
  --- Logical volume ---
  LV Path                /dev/tempvg/import_lv
  LV Name                import_lv
  VG Name                tempvg
  LV UUID                FAbBuj-GBl6-OCrE-LQom-ZHUo-HEkc-eiEcmy
  LV Write Access        read/write
  LV Creation host, time sapapp19, 2019-05-01 17:14:19 +0530
  LV Status              available
  # open                 1
  LV Size                3.00 TiB
  Current LE             785818
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     1024
  Block device           254:19
  
/dev/sdc   tempvg   lvm2 a--    3.00t    2.39g

sdc                          8:32   0    3T  0 disk
â””â”€tempvg-import_lv         254:19   0    3T  0 lvm  /Import

sdc - SCSI 0:0:2:0

[root@sapapp19 Import]$ dmsetup info -c | grep import_lv
tempvg-import_lv         254  19 L--w    1    1      0 LVM-O5GB7ZICXya43PGxLaFwudyd1kYIPCyIFAbBujGBl6OCrELQomZHUoHEkceiEcmy

[root@sapapp19 Import]$ lsof |grep "254,19"
bash       31597              root  cwd       DIR             254,19       4096          2 /
lsof      107728              root  cwd       DIR             254,19       4096          2 /
grep      107729              root  cwd       DIR             254,19       4096          2 /
lsof      107730              root  cwd       DIR             254,19       4096          2 /

 
Remove FS, VG, LV and disk. Please take care of nfs dependencies if any before removing.

---------------------------------------------------------------------------------------------------------------
12 March

**RCA DUE 13th MAR** CS2275796 > PRB0052026 > RCA0002124 - IN-Chennai 01 [3.x] - Tata Steel Limited (TTA) - IC4SAP-SL - SAPC1 || SAPAPP23 is in RO mode

afrccpprod	10.146.2.7	fixed
afrqhdbh2	10.72.59.33
afrphdbh2	10.72.59.33	fixed
br3dscmdb57	10.140.211.161
br3tscmdb27	10.140.48.150
br3qscmdb38	10.140.48.150



CHG0143857	12-03-2020 06:30:00	12-03-2020 11:00:00	FRA
ARMFKSAP002	              10.7.103.26	      QA
[root@armfksap002 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
cat: /etc/redhat-release: No such file or directory
Linux armfksap002 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 02:33:52 CET 2020
TIMEZONE="CET"
DEFAULT_TIMEZONE="US/Eastern"
HWCLOCK="-u"
OK: No read-only file systems found
[root@armfksap002 tmp]$ cat /etc/os-release
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"

[root@armfksap002 ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap002 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 03:36:59 CET 2020
TIMEZONE="CET"
DEFAULT_TIMEZONE="US/Eastern"
HWCLOCK="-u"
OK



ARMFKSAP101	              10.7.103.21	      QA
[root@armfksap101 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap101 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 02:33:52 CET 2020
TIMEZONE="CET"
DEFAULT_TIMEZONE="US/Eastern"
HWCLOCK="-u"
#10.144.102.14:/usr/sap/trans   /usr/sap/trans  nfs     defaults        0       0
#10.244.103.30:/usr/sap/trans    /usr/sap/trans  nfs     defaults        0       0
10.244.103.30:/usr/sap/trans    /usr/sap/trans  nfs     defaults        0       0
#10.144.102.14:/usr/sap/trans   /usr/sap/trans  nfs     defaults        0       0
#10.244.103.30:/usr/sap/trans    /usr/sap/trans  nfs     defaults        0       0
10.244.103.30:/usr/sap/trans    /usr/sap/trans  nfs     defaults        0       0
OK: No read-only file systems found


[root@armfksap101 ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap101 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 03:37:02 CET 2020
TIMEZONE="CET"
DEFAULT_TIMEZONE="US/Eastern"
HWCLOCK="-u"
#10.144.102.14:/usr/sap/trans   /usr/sap/trans  nfs     defaults        0       0
#10.244.103.30:/usr/sap/trans    /usr/sap/trans  nfs     defaults        0       0
10.244.103.30:/usr/sap/trans    /usr/sap/trans  nfs     defaults        0       0
OK



ARMFKSAP103	              10.7.103.20	      QA
[root@armfksap103 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
cat: /etc/redhat-release: No such file or directory
Linux armfksap103 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 02:33:52 CET 2020
TIMEZONE="CET"
DEFAULT_TIMEZONE="US/Eastern"
HWCLOCK="-u"
10.7.103.30:/usr/sap/trans      /usr/sap/trans  nfs     defaults        0       0
10.7.103.30:/usr/sap/trans      /usr/sap/trans  nfs     defaults        0       0
OK: No read-only file systems found
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"

NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap103 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 03:44:05 CET 2020
TIMEZONE="CET"
DEFAULT_TIMEZONE="US/Eastern"
HWCLOCK="-u"
10.7.103.30:/usr/sap/trans      /usr/sap/trans  nfs     defaults        0       0
OK



ARMFKSAP104	               10.7.103.35	      QA	10.85.0.183	fra02-pod2-4tb-host01.imzcloud.ibmammsap.local
[root@armfksap104 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i nfs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap104 4.4.121-92.80-default #1 SMP Mon May 21 14:40:10 UTC 2018 (2afdd00) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 02:33:52 CET 2020
TIMEZONE="Etc/GMT"
DEFAULT_TIMEZONE="US/Eastern"
OK: No read-only file systems found

   
[root@armfksap104 ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap104 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 02:37:06 GMT 2020
TIMEZONE="Etc/GMT"
DEFAULT_TIMEZONE="US/Eastern"
OK


dlthbehdb       10.4.5.154   , Server not reachable. Request OS assistance -  CS2328751
10.143.69.172	delta-dal09-phana-4096-01.imzcloud.ibmammsap.local	root / UbKpalr8
Powered on
Disconnected
ipmi LdMD6pDueW

CS1716825	
Server is in disconnected state. Not accessible

Mar 12 02:51:58 dlthbehdb kernel: [   20.728935] ixgbe 0000:41:00.1: Intel(R) 10 Gigabit Network Connection
Mar 12 02:51:58 dlthbehdb kernel: [   20.849355] dsa_filter: loading out-of-tree module taints kernel.
Mar 12 02:51:58 dlthbehdb kernel: [   20.849364] dsa_filter: module license 'Proprietary' taints kernel.
Mar 12 02:51:58 dlthbehdb kernel: [   20.849365] Disabling lock debugging due to kernel taint

Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/1 [megaraid_disk_12], type changed from 'megaraid,12' to 'sat+megaraid,12'
Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/1 [megaraid_disk_12] [SAT], opened
Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/1 [megaraid_disk_12] [SAT], Micron_5100_MTFDDAK3T8TCB, S/N:18151BF52A9F, WWN:5-00a075-11bf52a9f, FW:D0MU417, 3.84 TB
Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/1 [megaraid_disk_12] [SAT], found in smartd database: Crucial/Micron MX1/2/300, M5/600, 1100 Client SSDs
Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/1 [megaraid_disk_12] [SAT], not capable of SMART Health Status check
Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/1 [megaraid_disk_12] [SAT], is SMART capable. Adding to "monitor" list.
Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/1 [megaraid_disk_12] [SAT], state read from /var/lib/smartmontools/smartd.Micron_5100_MTFDDAK3T8TCB-18151BF52A9F.ata.state
Mar 12 02:51:58 dlthbehdb smartd[5561]: Monitoring 8 ATA/SATA, 0 SCSI/SAS and 0 NVMe devices
Mar 12 02:51:58 dlthbehdb smartd[5561]: Device: /dev/bus/0 [megaraid_disk_11] [SAT], 1 Offline uncorrectable sectors

[root@dlthbehdb ibmrmalik]$ tail -3000 /var/log/messages  |grep -i "taint*"     Mar 12 02:51:58 dlthbehdb kernel: [   20.849355] dsa_filter: loading out-of-tree module taints kernel.
Mar 12 02:51:58 dlthbehdb kernel: [   20.849364] dsa_filter: module license 'Proprietary' taints kernel.
Mar 12 02:51:58 dlthbehdb kernel: [   20.849365] Disabling lock debugging due to kernel taint
Mar 12 02:51:58 dlthbehdb kernel: [   20.849977] dsa_filter: module verification failed: signature and/or required key missing - tainting kernel













---------------------------------------------------------------------------------------------------

13 Mar

CHG0143873	13-03-2020 06:30:00 13-03-2020 12:30:00	Lon02
Host Name	                IFN IP			Asset Purpose
LONMAGGRC0001	10.69.0.39	Production
[root@LONMAGGRC0001 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux LONMAGGRC0001 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 04:54:34 UTC 2020
# The time zone of the system is defined by the contents of /etc/localtime.
# This file is only for evaluation by system-config-date, do not rely on its
# contents elsewhere.
ZONE="Asia/Singapore"
#146.89.140.30:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found


LONMAGSPO0001	10.69.0.35	Production
[root@LONMAGSPO0001 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux LONMAGSPO0001 2.6.32-754.24.3.el6.x86_64 #1 SMP Tue Nov 12 06:01:24 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 04:54:34 UTC 2020
# The time zone of the system is defined by the contents of /etc/localtime.
# This file is only for evaluation by system-config-date, do not rely on its
# contents elsewhere.
ZONE="Asia/Singapore"
#172.22.0.12:/usr/sap/AribaMasterdata    /usr/sap/AribaMasterdata nfs    defaults  0 0
172.22.0.12:/interfaces/EP1 /interfaces/EP1 nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
#146.89.140.30:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr 0       0
172.22.0.12:/usr/sap/EP1/share  /usr/sap/EP1/share  nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.24:/sapmnt/OP1/data/frsinput /sapmnt/OP1/data/frsinput nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/interfaces /usr/sap/interfaces  nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/AribaMasterdata/   /usr/sap/AribaMasterdata/       nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/tmp/interfaces/    /usr/sap/tmp/interfaces/        nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/customerdata/LnG           /usr/sap/customerdata/LnG       nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/primavera/inbound          /usr/sap/primavera/inbound      nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/primavera/outbound /usr/sap/primavera/outbound     nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/interface/filetransfer/mcaffe/role_changes_EP1 /usr/sap/interface/filetransfer/mcaffe/role_changes_EP1    nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.12:/usr/sap/interface/filetransfer/mcaffe/user_changes_EP1 /usr/sap/interface/filetransfer/mcaffe/user_changes_EP1    nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.18:/usr/sap/interface/filetransfer/mcaffe/role_changes_BP1 /usr/sap/interface/filetransfer/mcaffe/role_changes_BP1    nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.18:/usr/sap/interface/filetransfer/mcaffe/user_changes_BP1 /usr/sap/interface/filetransfer/mcaffe/user_changes_BP1    nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.39:/usr/sap/interface/filetransfer/mcaffe/role_changes_GP1 /usr/sap/interface/filetransfer/mcaffe/role_changes_GP1    nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
172.22.0.39:/usr/sap/interface/filetransfer/mcaffe/user_changes_GP1 /usr/sap/interface/filetransfer/mcaffe/user_changes_GP1    nfs rw,hard,intr,rsize=32768,wsize=32768    0       0
OK: No read-only file systems found
                     nfs     26G   14G   11G  57% /interfaces/EP1
                     nfs     40G   29G  9.2G  76% /usr/sap/EP1/share
                     nfs     25G  5.5G   18G  24% /sapmnt/OP1/data/frsinput
                     nfs    9.8G   23M  9.2G   1% /usr/sap/interfaces
                     nfs4    40G   29G  9.2G  76% /usr/sap/tmp/interfaces
                     nfs     40G   29G  9.2G  76% /usr/sap/customerdata/LnG
                     nfs     40G   29G  9.2G  76% /usr/sap/primavera/inbound
                     nfs     40G   29G  9.2G  76% /usr/sap/primavera/outbound
                     nfs     30G   44M   28G   1% /usr/sap/interface/filetransfer/mcaffe/role_changes_EP1
                     nfs     30G   44M   28G   1% /usr/sap/interface/filetransfer/mcaffe/user_changes_EP1
                     nfs     30G   44M   28G   1% /usr/sap/interface/filetransfer/mcaffe/user_changes_BP1
                     nfs     30G   44M   28G   1% /usr/sap/interface/filetransfer/mcaffe/role_changes_BP1
                     nfs     30G   44M   28G   1% /usr/sap/interface/filetransfer/mcaffe/user_changes_GP1
                     nfs     30G   44M   28G   1% /usr/sap/interface/filetransfer/mcaffe/role_changes_GP1
                     nfs    8.8G  6.1G  2.3G  73% /usr/sap/AribaMasterdata




CHG0143878	13-03-2020 06:30:00	13-03-2020 12:30:00	Lon02
Host Name	                IFN IP			Asset Purpose
LONMAGSLM0007	10.69.0.74	Production
[root@LONMAGSLM0007 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux LONMAGSLM0007 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 05:18:29 UTC 2020
ZONE="America/New_York"
OK: No read-only file systems found

LONMAGSLM0008	10.69.0.75	Production
[root@LONMAGSLM0008 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux LONMAGSLM0008 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 05:18:29 UTC 2020
ZONE="America/New_York"
OK: No read-only file systems found

LONMAGSLM0009	10.69.0.76	Production
[root@LONMAGSLM0009 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux LONMAGSLM0009 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 05:18:29 GMT 2020
ZONE="America/New_York"
OK: No read-only file systems found

LONMAGSWD0001	10.69.3.10	Production
[root@LONMAGSWD0001 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux LONMAGSWD0001 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 05:18:29 UTC 2020
# The time zone of the system is defined by the contents of /etc/localtime.
# This file is only for evaluation by system-config-date, do not rely on its
# contents elsewhere.
ZONE="Asia/Singapore"
#146.89.140.30:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
146.89.140.93:/storage/library /storage/library nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found

MNGLON02WEB01	10.69.0.101 Production
[root@mnglon02web01 tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux mnglon02web01 2.6.32-754.23.1.el6.x86_64 #1 SMP Tue Sep 17 09:46:55 EDT 2019 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 12 01:18:29 EDT 2020
ZONE="America/New_York"
OK: No read-only file systems found



CS2342518 Bombardier Recreational Products Inc -- BR3P1 - SevereLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-03-12-20-41-51 for details. 

CS2342532 Bombardier Recreational Products Inc -- BR3P1 - SevereLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-03-12-20-26-50 for details.


CHG0143095



SJMPCPDB01 	10.198.10.15 	10.195.1.15	10.116.103.231	sng01ammhana003.xsportal.local	SNG

SJMPCPDB01DR 	10.204.1.11 	10.195.4.11	10.110.7.121	honhana-1024-8.xsportal.local	HK
 	


CS2342436	Bombardier Recreational Products Inc -- BR3	P2 - Major	Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)
CS2342493	Bombardier Recreational Products Inc -- BR3	P2 - Major	Service corosync.service CRITICAL: corosync.service is inactive (dead) since Thu 2020-03-12 20:24:01 EDT: 31s ago


su - s4padm -c "hdbnsutil -sr_register --remoteHost=bumsaph4p01p --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=SITEA"

---------------------------------------------------------------------------------------------------------------------------------
14 March

BR3QSAPSS30 	10.138.10.80
BR3QSAPSS31 	10.138.10.105
BR3QSAPAS30 	10.138.10.100 	
BR3QSAPAS31 	10.138.10.33

-------------------------------------------------------------------------

17 March

10.127.235.150	parhana-1024-22.xsportal.local	disconnected state	root/CQpN8f3s	IPMI pw QuUas2t24D
10.127.235.227	parhana-1024-23.xsportal.local	root/Cl25zNe8	IPMI BnKDBx9VGz



CS2377666   Tata Steel BSL Ltd -- BS5   Perfdata ThreadCount CRITICAL: \2\250 = 1002   SQ-SAP-TRIO-C1  P2

CS2377771	Perfdata ThreadCount CRITICAL: \2\250 = 1212

--------------------------------------------------------------------------------------------

18 March

CS2135266
fmsprdrtem005 and fmsprdrtem006 



bapv120400
stat("/usr/sap/trans",



stat("/tmp/backups
[root@pn4us7leccp1 ibmrmalik]$ cat /etc/fstab |grep -i /tmp/backups
10.142.41.94:/tmp/backups       /tmp/backups    nfs     rw,hard,intr,rsize=32768,wsize=32768 0 0



Development - V59	Linux	BAPV590800 	10.134.4.13
Quality  - V32	Linux	BAPV321100 	10.134.4.15
Prodcution  - V33	Linux	BAPV330900 	10.134.3.7

stat("/usr/sap/trans",
bapv590800:/usr/sap/trans       /usr/sap/trans  nfs4    defaults 0 0


Server role/SAPSID	OS Type	Hostname	IFN	CFN
ECC				
Development - V59	Linux	BAPV590800 	10.134.4.13	10.8.216.14
Quality  - V32	Linux	BAPV321100 	10.134.4.15	10.8.216.17
Prodcution  - V33	Linux	BAPV330900 	10.134.3.7	10.8.217.13

BW				
Development - V52/J52	Linux	BAPV520500 	10.134.4.11	10.8.216.11
Quality  - V72/J72	Linux	BAPV721300 	10.134.4.14	10.8.216.16
Prodcution  - V12/J12	Linux	BAPV120400 	10.134.3.6	10.8.217.8



/usr/sap/trans from  bapv520500  to    >>  bapv120400 and BAPV721300
1:20 PM
Aruna S Chadaga:grin: Development - V52/J52	Linux	BAPV520500 	10.134.4.11
Quality  - V72/J72	Linux	BAPV721300 	10.134.4.14
Prodcution  - V12/J12	Linux	BAPV120400 	10.134.3.6






stat("/tmp/backups", ^C^X
[root@pn4us7lewmq1 ibmrmalik]$ cat /etc/fstab |grep -i /tmp/backups
10.142.41.99:/tmp/backups     /tmp/backups   nfs  rw,hard,intr,rsize=32768,wsize=32768       0       0

-----------------------------------------------------------------------------------------------------
19 March

CS2394947

1]ECC servers:

Development - V59	Linux	BAPV590800 	10.134.4.13
Quality  -      V32	Linux	BAPV321100 	10.134.4.15
Prodcution  - V33	Linux	BAPV330900 	10.134.3.7

create the v59adm on BAPV321100  and BAPV330900
create the v32adm on BAPV590800 andBAPV330900
create the v33adm  on BAPV590800 and BAPV321100
Note:
v59adm  uid=20080(v59adm) gid=3050(sapsys)
v32adm  uid=20110(v32adm) gid=3050(sapsys)
v33adm  uid=20090(v33adm) gid=3050(sapsys)


CS2394455	St. Jude Medical , USA -- JUE	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 78.98 (thresh: 16)


ptpbromodr.imzcloud.ibmammsap.local
 10.70.31.32
ptprajaampatd.imzcloud.ibmammsap.local
 10.70.31.24







-----------------------------------------------------------------------------------------------------
20 March


CHG0144447	ECT-LON02-/NONPROD- Apply Latest Q120 Patches on <<LIN>> Servers	20-03-2020 06:30:00	20-03-2020 10:30:00
We will ONLY patch the LATEST SECURITY patches on the SAME LEVEL...
ECTS4HQASDB	10.5.8.11	QA  -  hana server - hana version 1.00.122.16
[root@ECTS4HQASDB tmp]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/fstab |grep -i sds
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux ECTS4HQASDB 2.6.32-573.el6.x86_64 #1 SMP Wed Jul 1 18:23:37 EDT 2015 x86_64 x86_64 x86_64 GNU/Linux
Thu Mar 19 03:20:35 EET 2020
ZONE="EET"
#UTC=true
OK: No read-only file systems found
                     nfs    6.6T  3.1T  3.2T  49% /sds
                     
                     
[root@ECTS4HQASDB ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/fstab |grep -i sds
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux ECTS4HQASDB 2.6.32-573.26.1.el6.x86_64 #1 SMP Tue Apr 12 01:47:01 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux
Fri Mar 20 03:51:22 EET 2020
ZONE="EET"
#UTC=true
OK: No read-only file systems found
                     
                     
10.164.238.176	lonhana-1024-42.xsportal.local
                     


svjq1srv0	A0EASG014XVM004
CSR # CHG0145764
                     
                     
                     
rename sapstagetemp to sapstagetemp_SDJ in 10.6.1.189                     

                     
DLBSECDB00	10.162.24.196	chehana-1024-01.xsportal.local	Ivybridge

DLBQECDB01	10.162.24.211	che01-pod1-4tb-host01.imzcloud.ibmammsap.local	Broadwell

DLBPECDB01	10.162.186.195	che01-pod1-4tb-host03.imzcloud.ibmammsap.local	Broadwell

DLBQBWDB01	10.162.24.211	che01-pod1-4tb-host01.imzcloud.ibmammsap.local	Broadwell

DLBPBWDB01  	10.162.24.211	che01-pod1-4tb-host01.imzcloud.ibmammsap.local	Broadwell
          
                     
                     
sm9p118217v21	10.139.228.11	10.135.228.14	Welcome@123
sm9p118217v23	10.139.228.16	10.135.228.16

working vm
sm9p118217v24	10.139.224.212	10.135.224.60       
                     
                     

ADNABPDB	Ivybridge

ADNAELDB	Ivybridge

ADNAELDEVDB	Ivybridge

ADNAELQADB	Ivybridge

ADNBIDEVDB	Ivybridge

ADNMP1DB	Ivybridge

ADNMP1DEVDB	Ivybridge

ADNMP1QADB   	Ivybridge
    
   
   
CHG0145100	CTASK0181425                  
OS Engineer:
2.1 Take a full snapshot VM backup for host MGGGBJPGTSX01
Note 2: Set the CSR number in the snapshot backup description.

2.2 Restart host MGGGBJPGTSX01
Note 3: Once above step is completed, notify the SAP engineer to proceed with their tasks..       

--------------------------------------------------------------------------------------------------------------

21 Mar


CS2423029	LSPI -- LSP	P2 - Major	Memory Pagefile CRITICAL: \??\C:\pagefile.sys 198.949MB (200MB), \??\X:\pagefile.sys 3.431GB (4.75GB), total 3.625GB (4.945GB)
CS2423030	LSPI -- LSP	P2 - Major	Perfdata Virtual critical(\??\C:\pagefile.sys 198.949MB (200MB)), \??\X:\pagefile.sys 3.431GB (4.75GB), total 3.625GB (4.945GB)


CS2423930	BRENNTAG PTE LTD -- BAP	P2 - Major	(Received during suppression) Ping Availability CRITICAL - 10.134.4.15: rta nan, lost 100%


CS2424588	Tata Steel Limited -- TTA	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 44.26 (thresh: 40)
:heavy_check_mark:
1


CS2424853 Dilip Buildcon Limited -- DLBMoving mount point /Client_Export from SANDBOX to QEC  
DLBQECAP01	DLBQECAP01 	10.13.2.12 	172.16.22.12 	
SEC	ABAP - S4HANA	Application	RedHat Linux	DLBSECAP01	10.13.2.16

[root@dlbsecap01 ibmrmalik]# df -hT /Client_Export
Filesystem                         Type  Size  Used Avail Use% Mounted on
/dev/mapper/ClntExptvg-ClntExpt_lv ext4  493G  285G  183G  61% /Client_Export

/Client_Export *(rw,async,no_subtree_check,insecure,no_root_squash)



Raghuramaiah Chowdar Korrapati 	EDWARD RAJASEKARAN

-----------------------------------------------------------------------------------------------------------

24 March

Besclient
afrs4hqasapp2	10.214.2.10	fixed
bs4pb0078-ha	10.211.4.67	Fixed
pn8us7leccq3	10.12.255.142	Fixed
SK3CSDEV01	10.5.241.40	Retired
judhdmart01	10.196.4.10	cant connect server not found on Vcenter seems decommissioned, confirm with DPE/PDL



5GB to FS /sybase/SDJ/sapdiag@ 10.6.1.189 



https://146.89.140.160/vsphere-client/


CS2446715	IAG GBS Limited -- IA1	Disk Utilization / CRITICAL: Free 1100.42MB/10.58% (thresh @10.01:20%)	 IA1POPRDDB


CS2454544
Please mount FS /usr/sap/DAA on IA1POPRDDB
Please mount FS /usr/sap/DAA on IA1POPRDDB
Write permissions required on the  filesystem, for user daaadm 
Size: 4GB 

lvcreate -L 4G -n DAA_lv pp1logvg
mkfs.ext4 path of lvdisplay

/dev/pp1logvg/DAA_lv	/usr/sap/DAA
mkdir /sybase
mount
vi /etc/fstab




CS2452767 Controladora De Negocios -- CNGP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)	 10.68.210.27
CS2452765 Controladora De Negocios -- CNGP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))


CS2454551	BRENNTAG PTE LTD -- BAP	P2 - Major	(Received during suppression) ITM Agent Offline: V51-bapv510300_V51_03:Ins -


CS2454904	A.P. Moller Maersk -- APM	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 56.27 (thresh: 16) 


snap shot of host - SVWD1SRV0	A0EASG014XVM013

CSR # CHG0146084




CS2455489	COTY Inc. -- CTU	P2 - Major	Ping Availability CRITICAL - 10.12.10.121: rta nan, lost 100%
ctubwqb4db01 NodeAlias: 10.12.10.121	10.65.162.193	coty-wdc04-phana-4096-12.imzcloud.ibmammsap.local
 
CTU	IPMI HHpmNzmhs8		root RKqELyk5

https://gts-cmas.slack.com/archives/CC9ECQJ3A
number:CS1731401


 CS2457661	COTY Inc. -- CTUP1 - SevereHost Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)CTUBWQB4DB01
 
 -------------------------------------------------------------------------------------------------------------------------
 
 25 March
 
Master Ticket for MCO: CS2468750 
 
CS2468468 Dilip Buildcon Limited -- DLBP1 - SevereDisk Utilization /usr/sap/ccms mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system DLBSECAP01 SQ-SAP-TRIO-C2
CS2468454 Dilip Buildcon Limited -- DLBP1 - SevereInodes Utilization /var/log mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system DLBSECAP01 SQ-SAP-TRIO-C2
CS2468448 Dilip Buildcon Limited -- DLBP1 - SevereInodes Utilization /usr/sap/DAA mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system DLBSECAP01 SQ-SAP-TRIO-C2
CS2468359 Dilip Buildcon Limited -- DLBP1 - SevereInodes Utilization /home/daaadm mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system DLBSECAP01 SQ-SAP-TRIO-C2

CS2468268 Dilip Buildcon Limited -- DLBP1 - SevereInodes Utilization /usr mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file systemDLBSECAP01SQ-SAP-TRIO-C2
CS2468359 Dilip Buildcon Limited -- DLBP1 - SevereInodes Utilization /home/daaadm mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file systemDLBSECAP01SQ-SAP-TRIO-C2
CS2468378 Dilip Buildcon Limited -- DLBP1 - SevereDisk Utilization /boot mktemp: failed to create file via template Ã¢/tmp/XXXXXXXXÃ¢: Read-only file system DLBPBIDA00 SQ-SAP-TRIO-C2
CS2468384 Dilip Buildcon Limited -- DLBP1 - SevereDisk Utilization /sybase/PBI/sybtemp mktemp: failed to create file via template Ã¢/tmp/XXXXXXXXÃ¢: Read-only file system DLBPBIDA00 SQ-SAP-TRIO-C2
CS2468468 Dilip Buildcon Limited -- DLBP1 - SevereDisk Utilization /usr/sap/ccms mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file systemDLBSECAP01SQ-SAP-TRIO-C2
CS2468454 Dilip Buildcon Limited -- DLBP1 - SevereInodes Utilization /var/log mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file systemDLBSECAP01SQ-SAP-TRIO-C2
CS2468448 Dilip Buildcon Limited -- DLBP1 - SevereInodes Utilization /usr/sap/DAA mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file systemDLBSECAP01SQ-SAP-TRIO-C2

CS2468521	Dilip Buildcon Limited -- DLB	P1 - Severe	Inodes Utilization /home/secadm mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	DLBSECAP01	SQ-SAP-TRIO-C2



BS5DEVAPP	fixed
BS5DEVDB	HANA DB server not pingable	10.162.24.252	che01-pod1-4tb-host02.imzcloud.ibmammsap.local
BS5FIORIPRD	cant login  MAY NEED A REBOOT
BS5JMPSRVR	Windows server accessible
BS5PIDEV	cannot login	root pw not accessible in PIM
BS5PIPRD	cannot login	MAY NEED A REBOOT
BS5PRDAPP1	cannot login 
BS5PRDAPP2	cannot login
BS5PRDAPP3	cant login
BS5PRDAPP4	can login found bs5prdapp1:/sapmnt nfs    80G   38G   39G  50% /sapmnt is RO and the NFS server bs5prdapp1  cant login
BS5PRDAPP5	can login foun bs5prdapp1:/sapmnt nfs    80G   38G   39G  50% /sapmnt	is RO and the NFS server bs5prdapp1  cant login
BS5QASAPP	cant login
BS5QASDB	HANA db not pingable
BS5SBXAPP	cant login
BS5SOLMAN	can get in	looks gud
BS5PRDDB	10.162.186.195	che01-pod1-4tb-host03.imzcloud.ibmammsap.local  root/MsFpW9%iTW7clU@


sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh

T@n@yAnj@li@411041

BS5PRDDB	fixed	all gud

BS5PRDAPP1	all gud
BS5PRDAPP2	all gud
BS5PRDAPP3	emergency mode need to boot with iso
BS5PRDAPP4	all gud
BS5PRDAPP5	all gud
BS5PIPRD	all gud
BS5FIORIPRD	all gud
BS5SOLMAN	fixed

bs5prdapp1:/sapmnt nfs    80G   38G   39G  50% /sapmnt is RO and the NFS server bs5prdapp1  cant login



BS5SOLMAN	can get in	looks gud
BS5PRDAPP4	can login found bs5prdapp1:/sapmnt nfs    80G   38G   39G  50% /sapmnt is RO and the NFS server bs5prdapp1  cant login
BS5PRDAPP5	can login foun bs5prdapp1:/sapmnt nfs    80G   38G   39G  50% /sapmnt	is RO and the NFS server bs5prdapp1  cant login
BS5JMPSRVR	Windows server accessible



TSLBWPRDDB	10.162.24.252	che01-pod1-4tb-host02.imzcloud.ibmammsap.local


SAPPOQAC 	10.207.63.51 	10.170.63.130 

BIPRDAPP1	Pending
BIPRDAPP2	Pending
BIPRDAPP3	Pending
	



ESSMSSDEV	Production	EPD	1	Enterprise Portal
TTAR3DEV 	10.207.61.72 	10.170.61.22 	Production	RQA	1	GR
------------------------------------------------------------------------------------------------------------

26 March

bigfix

DLTHMEHAP_restore20Nov2019	unknown
DLTHMEHDB	10.143.69.226	cannot connect
dlthpehdbs	10.143.69.212	cannot connect	
dlthpehdbdr	10.148.74.162	not found/cannot connect
dlthpehdb	10.120.28.78	cannot connect
DLTHSEHDB	10.143.69.165	cannot connect


CS2482780   PT Anugerah Pharmindo Lestari -- PTP   Drive-Space C critical(OK: Drive C: has 5.951GB of 59.655GB)


CS2454544	Please mount FS /usr/sap/DAA on IA1POPRDDB
 /dev/pp1logvg/DAA_lv



 bs5devapp = 10.141.133.14
  #/backup
  #/usr/sap
  #/usr/sap/trans


bs5qasapp = 10.141.133.19


bs5devdb =  10.141.133.12
bs5devapp = 10.141.133.14
bs5qasapp = 10.141.133.19
bs5qasdb=10.141.133.21


vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab


Current Action Plan
Need downtime of 2 hours to perform the below action plan:
1. Create two separate LVs for mounting /usr/sap and /usr/sap/trans -OS
2. Ask customer to stop the apps - Customer
3. Map the /usr/sap/trans and /usr/sap to separate LVs created in previous step -OS
4(a) Copy the Existing data from /usr  to /usr/sap/ and /usr/sap/trans to the newly mapped FS - OS
or
4(b) Take 24th March backup of /usr and copy this to the /usr/sap/ and /usr/sap/trans to the newly mapped FS - OS  (add another hour for TSM task)
5. HO to the customer to start apps and validate (edited)



[root@bs5qasapp ibmrmalik]# df -h /usr/sap
Filesystem                       Size  Used Avail Use% Mounted on
/dev/mapper/s4qappvg-usr_sap_lv   24G  5.1G   18G  23% /usr/sap
[root@bs5qasapp ibmrmalik]# df -h /usr/sap/trans
Filesystem                             Size  Used Avail Use% Mounted on
/dev/mapper/s4qappvg-usr_sap_trans_lv   25G   21G  2.6G  90% /usr/sap/trans


[root@bs5qasapp ibmrmalik]# cat /etc/fstab |grep -i /usr/sap
/dev/s4qappvg/usr_sap_lv   /usr/sap        ext4       defaults        1 2
/dev/s4qappvg/usr_sap_trans_lv   /usr/sap/trans        ext4       defaults 


Filesystem                      Type  Size  Used Avail Use% Mounted on
/dev/mapper/s4dappvg-usr_sap_lv ext4   25G   44M   24G   1% /usr/sap1
[root@bs5devapp ibmrmalik]# df -hT /usr/sap/trans1
Filesystem                            Type  Size  Used Avail Use% Mounted on
/dev/mapper/s4dappvg-usr_sap_trans_lv ext4   30G   44M   28G   1% /usr/sap/trans1

--------------------------------------------------------------------------------------------------

27 March

CS2497324	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBDEVDT1- KB0010973
 SMDBDEVDT1 NodeAlias: 10.78.22.40 


CS2497480 Controladora De Negocios -- CNGP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB) 
 10.68.210.27
 
 

templv           tempvg   -wi-ao---- 63.50g  
[root@bs5devapp usrbackup]# ls -ltr
total 24
drwx------ 2 root root 16384 Mar 26 18:38 lost+found
drwx------ 2 root root  4096 Mar 26 18:39 usrof18
drwx------ 2 root root  4096 Mar 26 18:39 usrof24
[root@bs5devapp usrbackup]# pwd
/usrbackup
[root@bs5devapp usrbackup]# df -hT /usrbackup
Filesystem                Type  Size  Used Avail Use% Mounted on
/dev/mapper/tempvg-templv ext4   63G   52M   60G   1% /usrbackup


CS2497999	A.P. Moller Maersk -- APM	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 38.89 (thresh: 16)


CS2495079 COTY Inc. -- CTU P2 - Major Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWSB3DB01- KB0010973
CS2495089 COTY Inc. -- CTU P2 - Major Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBODR1DB01- KB0010973

CS2498507 Controladora De Negocios -- CNGP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS2498506 Controladora De Negocios -- CNGP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))



100.126.67.40 - VM IP
3:25 PM
re50	140.171.123.234  - Q and remote IP


CS2498851	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBDEVDT1- KB0010973	SMDBDEVDT1	SQ-SAP-TRIO-C2	
CS2498850	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBUATUT3- KB0010973	SMDBUATUT3	SQ-SAP-TRIO-C2	
CS2498849	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMTMDEVDT1- KB0010973	SMTMDEVDT1	SQ-SAP-TRIO-C2



CHG0146765	
To change the the local time zone as /usr/share/zoneinfo/Asia/Jakarta on APD and APQ system 
ptplorentz01	10.70.30.139
PTPBATUR	10.70.31.75



CS2499882	PT Anugerah Pharmindo Lestari -- PTP	P2 - Major	Drive-Space C critical(OK: Drive C: has 5.929GB of 59.655GB)	PTPDIENG	SQ-SAP-TRIO-C2 - Assign this ticket to windows OS team
----------------------------------------------------------------------------------------------------------------

28 Mar

CS2507219	Bombardier Recreational Products Inc -- BR3	P1 - Severe	(Received during suppression) Log PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-SQ-SAP-TRIO-C1



CS2508997   Panasonic North America -- PN4   Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-03-27-22-52-56 for details


 CS2510198	A.P. Moller Maersk -- APM	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 27.08 (thresh: 16)	SQ-SAP-TRIO-C1
 
 
 CS2510541   Ping Availability CRITICAL - 10.12.10.121: rta nan, lost 100%
 10.65.162.193	coty-wdc04-phana-4096-12.imzcloud.ibmammsap.local	root / RKqELyk5   IPMI	HHpmNzmhs8
CTUBWQB4DB01 	10.12.10.121 	172.22.64.121
[root@WDC04AMMCHEF01 ~]# ping CTUBWQB4DB01
PING CTUBWQB4DB01.imzcloud.ibmammsap.local (10.12.10.121) 56(84) bytes of data.
From 10.65.11.53 icmp_seq=1 Destination Host Unreachable
From 10.65.11.53 icmp_seq=2 Destination Host Unreachable
From 10.65.11.53 icmp_seq=3 Destination Host Unreachable
^C
--- CTUBWQB4DB01.imzcloud.ibmammsap.local ping statistics ---
6 packets transmitted, 0 received, +3 errors, 100% packet loss, time 5330ms
pipe 4

SL ticket CS1737591


CS2511493COTY Inc. -- CTUP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB4DB01- KB0010973

--------------------------------------------------------------------------------------------------------------------

31 March

CS2546077	Panasonic North America -- PN8	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN8US7LDBRP0H- KB0010973



TNGPRODEAPP00
TNGPRODEAPP01


CS2543113	IAG GBS Limited -- IA1	Disk Utilization /var CRITICAL: Free 927.34MB/19.90% (thresh @10.01:20%)	
CS2536304	IAG GBS Limited -- IA1	Disk Utilization /var CRITICAL: Free 932.02MB/20.00% (thresh @10.01:20%)


162901000060496 ifsc IOBA0001629

-----------------------------------------------------------------------------------------------
1 April


10.195.2.10 Server: SJMDEPAA01 (DEP) = Username: sjmdepaa01
ibmgkonduru@10.195.2.10's password:
Permission denied, please try again.

[root@sjmdepaa01 ibmrmalik]$ id ibmgkonduru
uid=95795(ibmgkonduru) gid=1513 groups=1513,19711(lxprdadm_ww),8216(linuxprodadmins_ww),8592(prodadmins_in_fda),11442(amm - oswin support (global) - hipaa),8250(linuxprodadmins_in_fda),8591(prodadmins_in),7624(amm - users ou management),11440(amm - oswin support (global)),11531(amm - oslinux support (india) - fda),8593(prodadmins_in_hipaa),19745(lxprdadm_in_fda),19746(lxprdadm_in_hipaa),7604(amm - computer account managment),7606(amm - group management),7607(amm - group policy management),7615(amm - modify group password resetter),11474(amm - oswin support (india) - fda),11530(amm - oslinux support (india)),11499(amm - oslinux support (global) - hipaa),11497(amm - oslinux support (global)),19744(lxprdadm_in),19713(lxprdadm_ww_hipaa),7611(amm - join computer to domain),2508(vpn access),8560(prodadmins_ww_hipaa),7618(amm - remove organization unit),7621(amm - sites and services read-only),11475(amm - oswin support (india) - hipaa),11498(amm - oslinux support (global) - fda),8559(prodadmins_ww_fda),19712(lxprdadm_ww_fda),7626(ibm amm support master access group (global) - fda),11441(amm - oswin support (global) - fda),8218(linuxprodadmins_ww_hipaa),8217(linuxprodadmins_ww_fda),8558(prodadmins_ww),7613(amm - management organizational unit),7617(amm - remove computer from domain),7625(ibm amm support master access group (global)),7627(ibm amm support master access group (global) - hipaa),11473(amm - oswin support (india)),11532(amm - oslinux support (india) - hipaa),8249(linuxprodadmins_in),8251(linuxprodadmins_in_hipaa)


10.195.3.13 Server: SJMQEPAA01 (QEP) = Username: sjmqxpadm
[root@oc1235387571 ~]# ssh ibmgkonduru@10.195.3.13
ssh: connect to host 10.195.3.13 port 22: Connection timed out

[root@sjmqepaa01 ibmrmalik]$ id ibmgkonduru
uid=95795(ibmgkonduru) gid=1513(domain_users) groups=1513(domain_users),19711(lxprdadm_ww),8216(linuxprodadmins_ww),8592(prodadmins_in_fda),11442(amm - oswin support (global) - hipaa),8250(linuxprodadmins_in_fda),8591(prodadmins_in),7624(amm - users ou management),11440(amm - oswin support (global)),11531(amm - oslinux support (india) - fda),8593(prodadmins_in_hipaa),19745(lxprdadm_in_fda),19746(lxprdadm_in_hipaa),7604(amm - computer account managment),7606(amm - group management),7607(amm - group policy management),7615(amm - modify group password resetter),11474(amm - oswin support (india) - fda),11530(amm - oslinux support (india)),11499(amm - oslinux support (global) - hipaa),11497(amm - oslinux support (global)),19744(lxprdadm_in),19713(lxprdadm_ww_hipaa),7611(amm - join computer to domain),2508(vpn access),8560(prodadmins_ww_hipaa),7618(amm - remove organization unit),7621(amm - sites and services read-only),11475(amm - oswin support (india) - hipaa),11498(amm - oslinux support (global) - fda),8559(prodadmins_ww_fda),19712(lxprdadm_ww_fda),7626(ibm amm support master access group (global) - fda),11441(amm - oswin support (global) - fda),8218(linuxprodadmins_ww_hipaa),8217(linuxprodadmins_ww_fda),8558(prodadmins_ww),7613(amm - management organizational unit),7617(amm - remove computer from domain),7625(ibm amm support master access group (global)),7627(ibm amm support master access group (global) - hipaa),11473(amm - oswin support (india)),11532(amm - oslinux support (india) - hipaa),8249(linuxprodadmins_in),8251(linuxprodadmins_in_hipaa)


10.195.1.4 Server: SJMPEPAA01 (PEP) = Username: sjmpxpadm01
ibmgkonduru@10.195.1.4's password:
Permission denied, please try again.

[root@sjmpepaa01 ibmrmalik]$ id ibmgkonduru
uid=95795(ibmgkonduru) gid=1513(domain_users) groups=1513(domain_users),19711(lxprdadm_ww),8216(linuxprodadmins_ww),8592(prodadmins_in_fda),11442(amm - oswin support (global) - hipaa),8250(linuxprodadmins_in_fda),8591(prodadmins_in),7624(amm - users ou management),11440(amm - oswin support (global)),11531(amm - oslinux support (india) - fda),8593(prodadmins_in_hipaa),19745(lxprdadm_in_fda),19746(lxprdadm_in_hipaa),7604(amm - computer account managment),7606(amm - group management),7607(amm - group policy management),7615(amm - modify group password resetter),11474(amm - oswin support (india) - fda),11530(amm - oslinux support (india)),11499(amm - oslinux support (global) - hipaa),11497(amm - oslinux support (global)),19744(lxprdadm_in),19713(lxprdadm_ww_hipaa),7611(amm - join computer to domain),2508(vpn access),8560(prodadmins_ww_hipaa),7618(amm - remove organization unit),7621(amm - sites and services read-only),11475(amm - oswin support (india) - hipaa),11498(amm - oslinux support (global) - fda),8559(prodadmins_ww_fda),19712(lxprdadm_ww_fda),7626(ibm amm support master access group (global) - fda),11441(amm - oswin support (global) - fda),8218(linuxprodadmins_ww_hipaa),8217(linuxprodadmins_ww_fda),8558(prodadmins_ww),7613(amm - management organizational unit),7617(amm - remove computer from domain),7625(ibm amm support master access group (global)),7627(ibm amm support master access group (global) - hipaa),11473(amm - oswin support (india)),11532(amm - oslinux support (india) - hipaa),8249(linuxprodadmins_in),8251(linuxprodadmins_in_hipaa)


10.195.1.5 Server: SJMPEPAA02 (PEP) = Username: sjmpxpadm02
[root@oc1235387571 ~]# ssh ibmgkonduru@10.195.1.5
ssh: connect to host 10.195.1.5 port 22: Connection timed out

[root@sjmpepaa02 ibmrmalik]$ id ibmgkonduru
uid=95795(ibmgkonduru) gid=1513(domain_users) groups=1513(domain_users),19711(lxprdadm_ww),8216(linuxprodadmins_ww),8592(prodadmins_in_fda),11442(amm - oswin support (global) - hipaa),8250(linuxprodadmins_in_fda),8591(prodadmins_in),7624(amm - users ou management),11440(amm - oswin support (global)),11531(amm - oslinux support (india) - fda),8593(prodadmins_in_hipaa),19745(lxprdadm_in_fda),19746(lxprdadm_in_hipaa),7604(amm - computer account managment),7606(amm - group management),7607(amm - group policy management),7615(amm - modify group password resetter),11474(amm - oswin support (india) - fda),11530(amm - oslinux support (india)),11499(amm - oslinux support (global) - hipaa),11497(amm - oslinux support (global)),19744(lxprdadm_in),19713(lxprdadm_ww_hipaa),7611(amm - join computer to domain),2508(vpn access),8560(prodadmins_ww_hipaa),7618(amm - remove organization unit),7621(amm - sites and services read-only),11475(amm - oswin support (india) - hipaa),11498(amm - oslinux support (global) - fda),8559(prodadmins_ww_fda),19712(lxprdadm_ww_fda),7626(ibm amm support master access group (global) - fda),11441(amm - oswin support (global) - fda),8218(linuxprodadmins_ww_hipaa),8217(linuxprodadmins_ww_fda),8558(prodadmins_ww),7613(amm - management organizational unit),7617(amm - remove computer from domain),7625(ibm amm support master access group (global)),7627(ibm amm support master access group (global) - hipaa),11473(amm - oswin support (india)),11532(amm - oslinux support (india) - hipaa),8249(linuxprodadmins_in),8251(linuxprodadmins_in_hipaa)


CS2560591 PT Anugerah Pharmindo Lestari -- PTP P1 - Severe SQ-SAP-TRIO-C2 Disk Utilization /opt CRITICAL: Free 1386.42MB/4.17% (thresh @0:5%)
9:54 AM
CS2560590 PT Anugerah Pharmindo Lestari -- PTP P1 - Severe SQ-SAP-TRIO-C2 Disk Utilization /var/lib/pgsql CRITICAL: Free 1383.84MB/4.16% (thresh @0:5%)
9:54 AM
CS2560588 PT Anugerah Pharmindo Lestari -- PTP P1 - Severe SQ-SAP-TRIO-C2 Disk Utilization /var/opt/BESClient CRITICAL: Free 1380.66MB/4.15% (thresh @0:5%)

CS2560602 PT Anugerah Pharmindo Lestari -- PTP P1 - Severe SQ-SAP-TRIO-C2 Disk Utilization /var/lib/libvirt/images CRITICAL: Free 1380.66MB/4.15%


CS2560714
xtend FS on host SPSVSPASAPP01 & spsvspdsase01 as below

SPSVSPDSASE01 	10.6.3.32 	10.70.111.32
SPSVSPASAPP01 	10.6.3.33 	10.70.111.33

n addition to that please mount the  /sapstagetemp FS  in  SPP  (10.6.3.33 & 10.6.3.32 ) and SPJ system(10.6.3.62) from Dev system (SD1-10.6.1.189   CFN IP: 10.92.99.185).

[ibmspeddapalli@svsd1srv0 sapstagetemp]$ df -h /sapstagetemp
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/tempss-sapstage_lv
                      493G  286G  182G  62% /sapstagetemp
[ibmspeddapalli@svsd1srv0 sapstagetemp]$ date
Wed Apr  1 12:37:29 +08 2020
[ibmspeddapalli@svsd1srv0 sapstagetemp]$


IP address (10.6.3.32) +120GB	SPSVSPDSASE01	A0EASG014XVM035

/sybase 1GB			/dev/mapper/spplogvg-sybase_lv
/sybase/SPP 10GB		/dev/mapper/sppdatavg-sppsybase_lv
/sybase/SPP/sapdiag 10GB	/dev/mapper/spparchvg-sppsybdiag_lv	need to add	
/sybase/SPP/saplog1 7GB		/dev/mapper/spplogvg-sppsyblog1_lv	
/sybase/SPP/sapdata1 20GB	/dev/mapper/sppdatavg-sppsapdata1_lv
/sybase/SPP/sapdata2 20GB	/dev/mapper/sppdatavg-sppsapdata2_lv
/sybase/SPP/sapdata3 20GB	/dev/mapper/sppdatavg-sppsapdata3_lv
/sybase/SPP/sapdata4 20GB	/dev/mapper/sppdatavg-sppsapdata4_lv
/sybase/SPP/saptemp 10GB	/dev/mapper/sppdatavg-sppsaptemp_lv


File system Request: ( IP address :10.6.3.33)+84GB	SPSVSPASAPP01

/home/sppadm 1GB	/dev/mapper/sppappvg-sppadm_lv
/home/daaadm 1GB	/dev/mapper/sppappvg-daaadm_lv
/home/sapadm 1GB	/dev/mapper/sppappvg-sapadm_lv
/usr/sap 4GB		/dev/mapper/sppappvg-usrsap_lv
/usr/sap/SPP 20GB	/dev/mapper/sppappvg-sppusrSPP_lv
/usr/sap/DAA 4GB	/dev/mapper/sppappvg-usrsapdaa_lv
/usr/sap/ccms 4GB	/dev/mapper/sppappvg-usrsapccms_lv
/usr/sap/trans 20GB	10.92.99.125:/usr/sap/trans   NFS	SVSD1SRV0 	10.6.1.26 	10.92.99.125	A0EASG014XVM014
/sapmnt/SPP 15GB	/dev/mapper/sppappvg-sppsapmnt_lv
/sapstage 10GB		/dev/mapper/sppappvg-sapstage_lv

----------------------------------------------------------------------------------------------------------

2 April


CS2573813
<>/dev/mapper/sppappvg-sapstage_lv	A0EASG014XVM030
15G 3.1G 11G 23% /sapstage
[root@spsvspasapp01 /]# hostname
spsvspasapp01.eastwestageaslife.com
[root@spsvspasapp01 /]#
8:03 AM
need to add another 300 GB to /sapstage in SPP

[root@spsvspasapp01 ibmrmalik]# df -hT /sapstage
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/sppappvg-sapstage_lv
                     ext3   15G  3.1G   11G  23% /sapstage



<>Filesystem Size Used Avail Use% Mounted on
/dev/mapper/spjappvg-sapstage_lv
4.8G 1.2G 3.5G 25% /sapstage
[ibmspeddapalli@agespsvspsrv2 ~]$ hostname
agespsvspsrv2
[ibmspeddapalli@agespsvspsrv2 ~]$
8:13 AM
SPJ another 60 GB

[root@agespsvspsrv2 /]# df -hT /sapstage
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/spjappvg-sapstage_lv
                     ext4  4.8G  1.2G  3.5G  25% /sapstage


CS2572351 COTY Inc. -- CTU P2 - Major SQ-SAP-TRIO-C2 LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.06 (thresh: 16) @Ravi Malik (TRIO C - OS Support)

CS2571014 COTY Inc. -- CTU P2 - Major SQ-SAP-TRIO-C2 LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 61.78 (thresh: 16) @Ravi Malik (TRIO C - OS Support)



CS2575884 IAG GBS Limited -- IA1P1 - SevereSAP-HEC-SWIVEL C drive in ICC production server is full(empty)



CS2576286
Add disk space -20G on smbosbxsb1      10.78.20.11 in sb1logvg- Needed for DB2 upgrade 11.1.FP5


ADNMP1DB	HANA we cant
ADNMP1DEVDB	HANA we cant
ADNMP1QADB	HANA we cant
dradnabpdb	HANA we cant
dradnaeldb	HANA we cant
dradnmp1db	HANA we cant
--------------------------------------------------------------------------------------------------------

3 April

CHG0145499	IA1-LON02-NONPROD- Apply Latest Q2 20 Patches on <<LINUX>> Servers	03-04-2020 13:30:00	03-04-2020 19:30:00
Iulia Bumbar	ADRIANA DANIELA MEROLLO
Host Name     CFNIP           Asset Purpose
ia1pisbxdb  10.133.16.16   NONPROD
ia1pisbxapp 10.133.16.17 NONPROD
ia1fiosbxapp 10.133.16.14 NONPROD
ia1webdspsbx1 10.133.16.15 NONPROD
ia1fiosbxdb 10.133.16.13 NONPROD




CS2588233 Manchester Airport Group -- MNGP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS2588305 Manchester Airport Group -- MNGP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)


CS2588559 Manchester Airport Group -- MNGP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS2588616 Manchester Airport Group -- MNGP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)


CS2588783 Manchester Airport Group -- MNGP2 - MajorPerfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS2588726 Manchester Airport Group -- MNGP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS2588884 Manchester Airport Group -- MNGP2 - MajorMemory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB) (edited) 


reboot
SAPAPP23 10.207.61.130


CS2589982 St. Jude Medical , USA -- JUE LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 68.54 (thresh: 16) P2
CS2590028 Tata Steel Limited -- TTA Service cron CRITICAL: 0 cron processes running (thresh 1:) P2

CS2590590 Controladora De Negocios -- CNG Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB) P2

CS2590981 Controladora De Negocios -- CNG P2 - Major Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)) SQ-SAP-TRIO-C1
CS2590929 Controladora De Negocios -- CNG P2 - Major Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB) SQ-SAP-TRIO-C1 (edited) 
3:07 PM
CS2591022 A.P. Moller Maersk -- APM LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 35.81 (thresh: 16) SQ-SAP-TRIO-C2 P2



CS2589482
Please check routes and if Nagios is installed on Rexel Servers
Please check if the following routes exist on the below servers, add them if they are not present:
158.87.44.0 
158.87.46.0 
169.62.212.64 

Hostname:                           IFN:
	REXBFCAPP1N                 10.135.1.101	waiting for subnet and gateway, routes missing
	REXBFCAPP2N                 10.135.1.102	waiting for subnet and gateway, routes missing
REXBFCHANA1-DR         10.133.1.71
	REXBFCWEB01N              10.135.1.103		waiting for subnet and gateway, routes missing
	REXBFCWEB02                 10.135.1.75		admlocal/May55	waiting for subnet and gateway, routes missing
	REXQBFCAPP1                 10.135.2.200	admlocal/May55	waiting for subnet and gateway, routes missing
	REXQBFCWEB1                10.135.2.201		waiting for subnet and gateway, routes missing

On the same vein, please check on the above servers whether the Nagios agent is installed.
You can compare if required with the below server for which nagios monitoring is working fine.
REXQBFCHANA1          10.135.2.199


CS2591433 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)


CS2591374 Manchester Airport Group -- MNG P2 - Major Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS2589050 Manchester Airport Group -- MNG P2 - Major Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS2591536 Manchester Airport Group -- MNG P2 - Major Memory Pagefile CRITICAL: \??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB)
CS2591533 Manchester Airport Group -- MNG P2 - Major Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))
CS2589251 Manchester Airport Group -- MNG P2 - Major Perfdata Virtual critical(\??\C:\pagefile.sys 199.992MB (200MB), total 199.992MB (200MB))



CS2592194 Arnoldo Mondadori Editore SpA -- ARMP3 - Minoriftop process at 100% CPU on the armfksap404d1 server - @Ravi Malik (TRIO C - OS Support) pls check it


CS2592359 IAG - British Airways -- IA2P1 - SevereHost Reboot CRITICAL: Uptime 11 minutes (thresh 60 min)
ia1s4hsbxdb   10.133.16.11       NONPROD
ia1s4hsbxapp  10.133.16.12      NON PROD

ia1bodssbxdb



DLTWTS01 10.4.5.153 , Login to this windows server not working. Request OS assistance - CS2590605
DLTWTS01 	10.4.5.153 	10.250.17.153




CS2592614 Tata Steel Limited -- TTAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on S4HDEV- KB0010973 
-------------------------------------------------------------------------------------------------------------------------------

4 April

CS2604514 CMA CGM -- CMA P2 - Major Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMTMQUAQT3- KB0010973


CS2605101 CMA CGM -- CMA P2 - Major Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBQUAQT3- KB0010973
Server decommissioned tickets needs to be cancelled
CMA_3xDecom3 - https://cmas-sam.rchland.ibm.com/models/CMA_3xDecom3 - smtmquaqt3 & smdbquaqt3


CS2605620 CMA CGM -- CMAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBQUAQT3- KB0010973

------------------------------------------------------------------------------------------------------------------------------

7 April

Frankfurt ==>	https://146.89.140.222/vsphere-client/		works		ammfra02vcs001.imzcloud.ibmammsap.local
Hong Kong  ==> 	https://146.89.141.40/vsphere-client/
Montreal	https://146.89.141.160/vsphere-client/
Paris		https://146.89.142.147/vsphere-client/



SVJQ1SRV0
CSR # CHG0148387


CS2636043 Delta Airlines -- DAL P3 - Minor ANE4174E Full VM backup of VMware Virtual Machine 'dltqeahap1' failed with RC=65535 mode=Incremental Forever - Incremental, target node name='AMM_A0B4US01_DC',
CS2635989 Delta Airlines -- DAL P3 - Minor ANE4174E Full VM backup of VMware Virtual Machine 'A0DBUS014XVM026' failed with RC=65535 mode=Incremental Forever - Incremental, target node name='AMM_A0B4US01_
CS2636293 Delta Airlines -- DAL P3 - Minor ANE4174E Full VM backup of VMware Virtual Machine 'dlthpehap13' failed with RC=65535 mode=Incremental Forever - Incremental, target node name='AMM_A0B4US01_DC',
CS2636257 Delta Airlines -- DAL P3 - Minor ANE4174E Full VM backup of VMware Virtual Machine 'dlthmehap4' failed with RC=65535 mode=Incremental Forever - Incremental, target node name='AMM_A0B4US01_DC',



CS2635334 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1IDMPRDAPP- KB0010973IA1IDMPRDAPP




CS2638716
Dear Team Kindly do SFTP,PING & TRACERT to IDBI server from Web Dispatcher production...
Webdispatcher = DLBPWDAP00 10.13.1.20(IFN) 172.16.20.20 (CFN)

IDBI IP is 103.93.44.97



SVJS1SRV0 - CSR # CHG0148407
2:03 PM
SVJD1SRV0  A0EASG014XVM003 , SVFD1SRV0  A0EASG012XVM003- CSR # CHG0148400

-------------------------------------------------------------------------------------------------------------------------------

8 April

From the password-aged shee
Ravi----------------------->164 - 204


AD1 - Development BOBJ svad1srv0 10.6.1.18
[root@svad1srv0 April7th]$ ./sapinst SAPINST_HTTPS_PORT=8089 SAPINST_HTTP_PORT=8090 SAPINST_REMOTE_ACCESS_USER=boadm SAPINST_REMOTE_ACCESS_USER_IS_TRUSTED=true
The C++ runtime installed on this machine is too old to run SAPinst.
In order to update the runtime to a current version, see SAP Note 2195019



CS2652536

AD1 - Development BOBJ			svad1srv0	10.6.1.18
BD1 - Development BW Application	svbd1srv0	10.6.1.14
EDM - MDC Development HANA DB		agesvedmhsrv1	10.6.1.179 
LD1 - Development POL (ABAP)		svld1srv0	10.6.1.20 



AD1 - Development BOBJ svad1srv0 10.6.1.18
BD1 - Development BW Application svbd1srv0 10.6.1.14
EDM - MDC Development HANA DB agesvedmhsrv1 10.6.1.179

BD1 svbd1srv0	10.6.1.14	A0EASG014XVM005




10.65.162.193	coty-wdc04-phana-4096-12.imzcloud.ibmammsap.local

----------------------------------------------------------------------------------------------------------------

9 April

CS2664452	
stat("/backup_new",
[root@iplsas4dd03 ibmrmalik]$ cat /etc/fstab |grep -i /backup_new
10.11.1.13:/backup_new         /backup_new             nfs      defaults               1       2

IPLSAS4AP01 	10.138.1.13 	10.11.1.13	Mon


Reg: Not able to run the OS commands like "df-Ph" or ls on iplsas4dd03	10.138.2.47

iplsas4dd03	10.138.2.47 
iplsapoad01	10.138.2.18 - 

[root@iplsas4ap01 ibmrmalik]$ cat /var/log/messages |grep -i tainted
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1
Apr  8 18:16:24 iplsas4ap01 kernel:      Tainted: P           -- ------------    2.6.32-754.24.3.el6.x86_64 #1

[root@iplsas4ap01 ibmrmalik]$ cat /var/log/messages |grep -i hung
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  8 18:16:24 iplsas4ap01 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.




CS2665035
add 400GB disk on iplsas4ad01 10.138.2.12
map NFS to iplsas4dd03 10.138.2.47- 400GB

vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab
LV Path                /dev/tempvg/templv


CS2665242
Reg: Adding 200GB - 300 GB disks
Manual backups need to be taken and so the need for Temporary FS's.

Servers:
PDA: iplsapoad01	10.138.2.18 -      300GB	migrated
SDA: iplsasmad01	10.138.2.24         200GB
SDJ : iplsasmad02	10.138.2.25         200GB




A0EASG014XVM004  SVJQ1SRV0 (now)
P1-CS2665519




EQ1 - Quality ERP Application		sveq1srv0	10.6.2.11	done	
RQ1 - Quality ERP Application		sveq1srv0	10.6.2.11	done
JQ1 - Quality Java (FS-QUO)		svjq1srv0	10.6.2.12	done	fine
BQ1 - Qaulity BW Aplication		svbq1srv0	10.6.2.14	done	fine
CQ1 - Quality CRM Application (ABAP)	svcq1srv0	10.6.2.16	done
XQ1 - Quality CRM Application (JAVA)	svcq1srv0	10.6.2.16	done
AQ1 - Quality BOBI			svaq1srv0	10.6.2.18	done
LQ1 - Quality POL (ABAP)		svlq1srv0	10.6.2.19	done
PQ1 - Enterprise Portal			svpq1srv0	10.6.2.22	done

SR CS2665420

-------------------------------------------------------------------------------------------

10 April

CS2669321
update C++ on listed Prod servers /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.15
Please update /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.15 on below listed servers

EPM - MDC Production HANA DB	agesvepmhsrv1	10.6.3.58	10.70.111.59	SUSE  libstdc libstdc++33-3.3.3-12.15.x86_64 glibc-2.22-62.22.5.x86_64
EPP - Production ERP Application	spsvepaeapp01	10.6.3.12	10.70.111.12	Done
RPP - Production ERP Application	spsvepaeapp01	10.6.3.12	10.70.111.12	DOne
JPP - Production ERP Application Java	spsvepajapp01	10.6.3.13	10.70.111.13	DOne
CPM - MDC Production HANA DB	agesvcpmhsrv1	10.6.3.59	10.70.111.60	SUSE pending any linking, updated libstdc
CPP - Production CRM ABAP	spsvcpacapp01	10.6.3.15	10.70.111.15	done
XPP - Production CRM Java	spsvcpacapp01	10.6.3.15	10.70.111.15	DOne
BPP - BW HANA DB-New	agesvbpphsrv1	10.6.3.60	10.70.111.61	SUSE pending any linking, updated libstdc
BPP - BW Application	spsvbpabapp01	10.6.3.18	10.70.111.18	Done
APP - BOBI (Sybase DB)	spsvbpdaase01	10.6.3.19	10.70.111.19	DOne
APP - BOBI Application	spsvbpaaapp01	10.6.3.20	10.70.111.20	Done
LPP - SAP POL (ABAP)	spsvppalase01	10.6.3.22	10.70.111.22	Done
PPP - Enterprose Portal	spsvepdpase01	10.6.3.27	10.70.111.27	DOne
PPP - Enterprose Portal	spsvepapapp01	10.6.3.28	10.70.111.28	Done
WPP - SAP WebDispatcher	spsvwpawapp11	10.6.3.30	10.70.111.30	Done
WPP - SAP WebDispatcher	spsvwpawapp12	10.6.3.31	10.70.111.31	Done
SPP - Solman	spslspdsase01	10.6.3.32	10.70.111.32		Done
SPP - Solman	spsvspasapp01	10.6.3.33	10.70.111.33		DOne
SCC - Cloud Connector (Master)	svcc2srv0	10.6.3.101	10.70.111.101	SUSE pending any linking, updated libstdc
SCC - Cloud Connector (Slave)	svcc2srv1	10.6.3.102	10.70.111.102	SUSE pending any linking, updated libstdc


CS2681945	Delta Airlines -- DAL	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DLTHSEHDB2- KB0010973
10.143.69.228	delta-dal09-phana-2048-03.imzcloud.ibmammsap.local	root Le9uzpMS	IPMI Upl9Mekhz5
SL case number:CS1756863


CS2682598 Delta Airlines -- DALP1 - SevereHost Reboot CRITICAL: Uptime 1 minutes (thresh 60 min) 


handvh4psrv02
handvwd1srv01
handvlb7srv01


CS2678205	Bombardier Recreational Products Inc -- BR3	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 33.20 (thresh: 16)	10.138.10.76 
CS2678218	Bombardier Recreational Products Inc -- BR3	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 33.41 (thresh: 16)	10.138.10.107
CS2678413	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3QGTSSS35- KB0010973	 10.138.10.38
[root@br3qgtsss35 ibmrmalik]$ cat /etc/fstab |grep -i /usr/sap/trans
10.3.112.22:/usr/sap/trans /usr/sap/trans      nfs defaults 0 0

CS2678361	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3QGTSAS36- KB0010973	10.138.10.109 
CS2678405	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3QGTSAS35- KB0010973	10.138.10.119
CS2678407	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSCMSS47- KB0010973	 10.138.13.12
CS2678421	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSCMSS46- KB0010973	10.138.13.10
CS2678403	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSCMAS47- KB0010973	10.138.13.8 
CS2678338	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSCMAS46- KB0010973	10.138.13.11
CS2678411	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSAPSS41- KB0010973	10.138.13.42
CS2678393	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSAPSS40- KB0010973	10.138.13.37
CS2678331	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSAPAS41- KB0010973	10.138.13.35
CS2678415	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PSAPAS40- KB0010973	 10.138.13.33
CS2678377	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PGTSSS46- KB0010973	10.138.13.40
CS2678432	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PGTSSS45- KB0010973	10.138.13.22
CS2678381	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PGTSAS46- KB0010973	10.138.13.25
CS2678344	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3PGTSAS45- KB0010973	 10.138.13.24 
CS2678341	Bombardier Recreational Products Inc -- BR3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BR3FSCMAS60- KB0010973

CS2679209	Controladora De Negocios -- CNG	P2 - Major	Ping Availability CRITICAL - 10.68.210.28: rta nan, lost 100%


CS2679535	Apple Leisure Group -- AV1	P2 - Major	Ping Availability CRITICAL - 10.68.214.12: rta nan, lost 100%
CS2679485	Apple Leisure Group -- AV1	P2 - Major	Ping Availability CRITICAL - 10.68.214.12: rta nan, lost 100%


CS2679551	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.15: rta nan, lost 100%	YANBALBOPRD
CS2679549	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.16: rta nan, lost 100%	UNQSAPBPCPRD
CS2679513	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.18: rta nan, lost 100%	UNQSAPBPCDEV
CS2679478	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.16: rta nan, lost 100%	UNQSAPBPCPRD
CS2679471	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.14: rta nan, lost 100%	YANBALBOQAS
CS2679425	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.15: rta nan, lost 100%	YANBALBOPRD
CS2679405	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.14: rta nan, lost 100%	YANBALBOQAS
CS2679383	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.17: rta nan, lost 100%	UNQSAPBPCQAS
CS2679275	Unique S.A. -- UNQ	P2 - Major	Ping Availability CRITICAL - 10.4.7.18: rta nan, lost 100%	UNQSAPBPCDEV


#inf-na-tech1

CS2679444	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.159: rta nan, lost 100%	DLTHBGGAT3
CS2679442	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.9: rta nan, lost 100%	DLTDSPAP1
CS2679433	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.153: rta nan, lost 100%	DLTWTS01 windows issue
CS2679429	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.164: rta nan, lost 100%	DLTHBEHAP5
 Server Type: Sandbox                                                     *
*       Hostname: dlthbehap5                                                  *
*         CFN IP: 10.250.17.164                                               *
*         IFN IP: 10.4.5.164                                                  *
*        SAP SID: HBE                                                         *
*******************************************************************************
[ibmrmalik@dlthbehap5 ~]$ uptime
 01:23am  up 94 days 11:06,  2 users,  load average: 0.10, 0.10, 0.08
[ibmrmalik@dlthbehap5 ~]$ date
Fri Apr 10 01:23:53 EDT 2020

CS2679423	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.6: rta nan, lost 100%	DLTDSDDB1
*******************************************************************************
[ibmrmalik@dltdsddb1 ~]$ uptime
 00:24:38 up 94 days, 11:15,  1 user,  load average: 0.02, 0.01, 0.00
[ibmrmalik@dltdsddb1 ~]$ date
Fri Apr 10 00:24:40 EST 2020

CS2679418	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.166: rta nan, lost 100%	DLTHBGGAT
[ibmrmalik@dlthbggat ~]$ uptime
 01:25am  up 94 days 11:06,  2 users,  load average: 0.06, 0.07, 0.08
[ibmrmalik@dlthbggat ~]$ date
Fri Apr 10 01:25:15 EDT 2020

CS2679413	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.5: rta nan, lost 100%	DLTDSQAP1
[ibmrmalik@dltdsqap1 ~]$ uptime
 00:30:33 up 94 days, 11:20,  2 users,  load average: 1.66, 1.20, 1.06
[ibmrmalik@dltdsqap1 ~]$ date
Fri Apr 10 00:30:34 EST 2020

CS2679411	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.10: rta nan, lost 100%	DLTDSSDB1
[ibmrmalik@dltdssdb1 ~]$ uptime
 05:31:30 up 94 days, 11:23,  1 user,  load average: 0.08, 0.03, 0.00
[ibmrmalik@dltdssdb1 ~]$ date
Fri Apr 10 05:31:31 UTC 2020

CS2679409	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.7: rta nan, lost 100%	DLTDSDAP1
[ibmrmalik@dltdsdap1 ~]$ uptime
 00:33:40 up 94 days, 11:25,  1 user,  load average: 0.03, 0.03, 0.00
[ibmrmalik@dltdsdap1 ~]$ date
Fri Apr 10 00:33:41 EST 2020

CS2679407	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.161: rta nan, lost 100%	DLTHBEHAP1
[ibmrmalik@dlthbehap1 ~]$ uptime
 01:34am  up 94 days 11:11,  2 users,  load average: 0.20, 0.11, 0.07
[ibmrmalik@dlthbehap1 ~]$ date
Fri Apr 10 01:34:37 EDT 2020

CS2679404	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.28: rta nan, lost 100%	DLTHDBBSI02	ok

CS2679402	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.8: rta nan, lost 100%	DLTDSPDB1
[ibmrmalik@dltdspdb1 ~]$ uptime
 00:35:54 up 94 days, 11:27,  1 user,  load average: 0.00, 0.02, 0.00
[ibmrmalik@dltdspdb1 ~]$ date
Fri Apr 10 00:35:54 EST 2020

CS2679397	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.18: rta nan, lost 100%	DLTDSSAP1
[ibmrmalik@dltdssap1 ~]$ uptime
 05:41:31 up 94 days, 11:33,  1 user,  load average: 0.13, 0.05, 0.01
[ibmrmalik@dltdssap1 ~]$ date
Fri Apr 10 05:41:32 UTC 2020

CS2679395	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.165: rta nan, lost 100%	DLTHBEHAP2
[ibmrmalik@dlthbehap2 ~]$ uptime
 01:44am  up 94 days 11:26,  1 user,  load average: 0.06, 0.02, 0.00
[ibmrmalik@dlthbehap2 ~]$ date
Fri Apr 10 01:44:26 EDT 2020

CS2679392	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.12: rta nan, lost 100%	DLTHDEHAP
[ibmrmalik@dlthdehap ~]$ uptime
 01:45:06 up 91 days,  5:30,  1 user,  load average: 1.02, 0.59, 0.39
[ibmrmalik@dlthdehap ~]$ date
Fri Apr 10 01:45:07 EDT 2020

CS2679380	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.224: rta nan, lost 100%	DLTOTADB01
[ibmrmalik@dltotadb01 /]$ uptime
 01:49:16 up 139 days, 21:14,  1 user,  load average: 0.00, 0.02, 0.00
[ibmrmalik@dltotadb01 /]$ date
Fri Apr 10 01:49:17 EDT 2020

CS2679367	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.158: rta nan, lost 100%	DLTHBGGAT2
[ibmrmalik@dlthbggat2 ~]$ uptie
If 'uptie' is not a typo you can use command-not-found to lookup the package that contains it, like this:
    cnf uptie
[ibmrmalik@dlthbggat2 ~]$ date
Fri Apr 10 01:50:02 EDT 2020

CS2679366	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.223: rta nan, lost 100%	DLTOTAAP01
[ibmrmalik@dltotaap01 /]$ uptime
 01:50:45 up 139 days, 21:16,  1 user,  load average: 0.08, 0.05, 0.01
[ibmrmalik@dltotaap01 /]$ date
Fri Apr 10 01:50:46 EDT 2020

CS2679340	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.155: rta nan, lost 100%	DLTWB2HWD
[ibmrmalik@dltwb2hwd ~]$ uptime
 01:51am  up 94 days 11:33,  2 users,  load average: 0.16, 0.12, 0.09
[ibmrmalik@dltwb2hwd ~]$ date
Fri Apr 10 01:51:30 EDT 2020

CS2679272	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.163: rta nan, lost 100%	DLTHBEHAP3
[ibmrmalik@dlthbehap3 ~]$ uptime
 01:52am  up 94 days 11:35,  2 users,  load average: 0.07, 0.09, 0.08
[ibmrmalik@dlthbehap3 ~]$ date
Fri Apr 10 01:52:47 EDT 2020

CS2679263	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.162: rta nan, lost 100%	DLTHBEHAP4
[ibmrmalik@dlthbehap4 ~]$ uptime
 01:53am  up 94 days 11:36,  2 users,  load average: 0.10, 0.17, 0.11
[ibmrmalik@dlthbehap4 ~]$ date
Fri Apr 10 01:53:34 EDT 2020

CS2679255	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.156: rta nan, lost 100%	DLTWB1HWD
ibmrmalik@dltwb1hwd:~> uptime
 01:57am  up 94 days 11:39,  2 users,  load average: 0.13, 0.12, 0.10
ibmrmalik@dltwb1hwd:~> date
Fri Apr 10 01:57:16 EDT 2020


CS2681560 Unique S.A. -- UNQP1 - SevereHost Reboot CRITICAL: Uptime 5 minutes (thresh 60 min) -



Delta pHANA rest CS1716825

-------------------------------------------------------------------------------

11 April

CS2692200   A.P. Moller Maersk -- APM  LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 36.71 (thresh: 16)  P2


CS2693320   Meggitt PLC -- MGG  Memory Virtual CRITICAL: Free Memory 1.99% (thresh 2:%) 


CS2695875 A.P. Moller Maersk -- APMP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 46.21 (thresh: 16)



REXBFCHANA1	10.135.1.71	10.134.17.116	rexbfchana1.rxlfra.hec.sap.biz	root  V4YTK3zt   IPMI K7Jmtk6xsZ
REXBFCHANA1-DR	10.133.1.71

-----------------------------------------------------------------------------------------------------------------------

14 April

CHG0146536-Hanon Systems -- HAN-13-Apr-2020 12:30:00 AM(Pacific Time)


CS2731979	COTY Inc. -- CTU	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWSB3DB01- KB0010973



CONSPPHANAQ	10.16.1.25
10.151.21.167
root => Rbqw2CqZ2c
 SL hostname - sao01-mdc-1024-4.imzcloud.ibmammsap.local
 CS1761358 is the SL ticket I raised
  #scx-sapc1-con
  CS2730376 Concessionaria Aeroporto Rio de Jan -- CON P2 - Major Ping Availability CRITICAL - 10.16.1.25: rta nan, lost 100%
  
  
  
  CS2734644 Panasonic North America -- PN8P2 - MajorMemory Swap CRITICAL: Swap free 49.97% (thresh 50:%)PN8US7LAP1P3
  
  
  
  CHG0149435
  Change the Timezone to Jakarta and restart the systems SOA, SOj , APD and APQ
   Solman	PTPSEMERU 	10.70.30.142	done

APD â€“ SAP ECC EHP8 Netweaver 7.50	ptplorentz01	10.70.30.139
APD â€“ SAP HANA Database	ptppangandara	10.70.30.151

APQ APP server	PTPBATUR	10.70.31.75
APQ HANA server	ptpdreamland	10.70.31.86






CS2726405	Mon
Please configure a Temporary FS for taking backups ( locally). Below are the details :

1. iplsafidt01	10.138.3.14 - 200GB  ( locally)	IPLSAFIDT01 	10.138.3.14 	10.11.3.14
sdc                                    8:32   0  128G  0 disk
/dev/tempvg/templv	
[root@iplsafidt01 ibmrmalik]$ df -hT /dev/tempvg/templv
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/tempvg-templv
                     ext3  126G  188M  119G   1% /backup_temp

vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab
 	
2. iplsapodt01	10.138.3.19  - 200GB ( Locally)	IPLSAPODT01 	10.138.3.19 	10.11.3.19
sdc                                    8:32   0  128G  0 disk
sde                                    8:64   0   64G  0 disk
 LV Path                /dev/tempvg/templv
 
[root@iplsapodt01 ibmrmalik]$ df -hT /backup_temp
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/tempvg-templv
                     ext3  189G  188M  179G   1% /backup_temp


3. iplsafidp01	10.138.1.15 - 250 GB  (locally)	IPLSAFIDP01 	10.138.1.15 	10.11.1.15  no disk to create vg need to add a new one after ds migration	
/dev/tempvg/templv	/backup_temp

[root@iplsafidp01 ibmrmalik]$ df -hT /backup_temp
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/tempvg-templv
                     ext3  247G  188M  234G   1% /backup_temp



4. iplsapodp01	10.138.1.20  - 250 GB (locally)	IPLSAPODP01 	10.138.1.20 	10.11.1.20  no disk to create vg need to add a new one after ds migration	
/dev/tempvg/templv	/backup_temp

[root@iplsapodp01 ibmrmalik]$ df -hT /backup_temp/
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/tempvg-templv
                     ext3  247G  188M  234G   1% /backup_temp

5.  iplsas4dt03	10.138.3.23  - 450 GB. This is a HANA DB,so  local FS extension is NOT possible. So mount an FS from somewhere ( this has to be a non-prod system though).	 	IPLSAS4DT03 	10.138.3.23 	10.11.3.24

[root@iplsas4dt03 ibmrmalik]$ df -hT /backup_temp
Filesystem               Type  Size  Used Avail Use% Mounted on
iplsas4ad01:/backup_temp nfs4  456G  198M  433G   1% /backup_temp


6. iplsas4dp03	10.138.1.73 - Also same as above. This is PRODUCTION HANA DB. -  Size 500GB.	IPLSAS4DP03 	10.138.1.73 	10.11.1.74
  /dev/tempvg/templv	
  
  iplsas4at01	10.138.3.12 
  iplsas4dt03	10.138.3.23 
  iplsafiat01	10.138.3.15
  sdc                                8:32   0  128G  0 disk
sdd                                8:48   0   64G  0 disk
sde                                8:64   0   64G  0 disk
sdf                                8:80   0   32G  0 disk

  
  
iplsafidt01	10.138.3.14

	iplsas4ad01	10.138.2.12
iplsafiax01	10.138.2.33
iplsafidx01	10.138.2.32
iplsafiad01	10.138.2.14
iplsafiad02	10.138.2.21

  

[ibmrmalik@iplsas4ad01 backup_temp]$ df -hT /backup_temp/
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/tempvg-templv
                     ext3  456G  199M  433G   1% /backup_temp
------------------------------------------------------------------------------------------
15 April


CS2749175 Manchester Airport Group -- MNGP2 - MajorMemory Pagefile total 199.992MB (200MB)FRAMAGSSP0002SQ-SAP-TRIO-C1
CS2749174 Manchester Airport Group -- MNGP2 - MajorPerfdata Virtual total 199.992MB (200MB)FRAMAGSSP0002SQ-SAP-TRIO-C1


 CS2749839 Manchester Airport Group -- MNGP2 - MajorPerfdata Virtual total 199.992MB (200MB)FRAMAGSSP0002SQ-SAP-TRIO-C1



 CS2749780 Tata Steel Limited -- TTAP3 - MinorServer : OSS: 89187, Regarding performance issue of TSGC SAP PO for Tata Steel Long Products(empty)
 
 
 CS2759932 St. Jude Medical -- JU1P2 - MajorPing Availability CRITICAL - 10.198.13.11: rta nan, lost 100%SJMQWDAA01SQ-SAP-TRIO-C2
CS2759931 St. Jude Medical -- JU1P2 - MajorPing Availability CRITICAL - 10.198.13.12: rta nan, lost 100%SJMPWDAA01SQ-SAP-TRIO-C2
CS2759928 St. Jude Medical -- JU1P2 - MajorPing Availability CRITICAL - 10.198.13.10: rta nan, lost 100%SJMDWDWD01SQ-SAP-TRIO-C2
 
 
 #abbott_ju1_daily_ops
 DEV system:
sjmdfpaa01 | 10.198.11.17
users : sjmpiadm & sjmcnadm
QA FTP
sjmqfpaa01 | 10.198.12.14 | 10.195.3.14
users : sjmpiadm , sjmdwadm , sjmcnadm
Prod FTP server
Host name / IP : sjmpfpaa01 | 10.198.10.7 | 10.195.1.7
Users : sjmcnadm ,sjmdwadm ,sjmpiadm


export CHEF_ORG=
knife node show sjmdfpaa01.imzcloud.ibmammsap.local -a policy_linux_pass_max_age



CS2760791 Panasonic North America -- PN8P2 - MajorMemory Swap CRITICAL: Swap free 47.72% (thresh 50:%)PN8US7LECCQ3SQ-SAP-TRIO-C2


CHG0149415

DR server
BUMSAPH4PDR    10.136.5.13

Primary and HA DB server details as below
SAP HANA DB node1 (Cluster)	bumsaph4p01p	10.134.14.15
SAP HaNA DB node2 (Cluster)	bumsaph4p02p	10.134.14.16

APP server
Hostname	                                IMZ IP address
bumsaps4p01p(Cluster)	10.134.14.7
bumsaps4p02p(Cluster)	10.134.14.8
bumsappop01p (Cluster)	10.134.14.9
bumsappop02p (Cluster)	10.134.14.10
bumsaptkp01p	        10.134.14.11


Hostname	                                IMZ IP address
S4P
bumsaps4p01p Node1 (Cluster)	10.134.14.7
bumsaps4p02p Node2(Cluster)	10.134.14.8
POP
bumsappop01p Node1 (Cluster)	10.134.14.9
bumsappop02p Node2 (Cluster)	10.134.14.10
DB servers
SAP HANA DB node1 (Cluster)	bumsaph4p01p	10.134.14.15
SAP HaNA DB node2 (Cluster)	bumsaph4p02p	10.134.14.16


commands to put cluster in managed and unmanaged state
crm configure property maintenance-mode=true
crm configure property maintenance-mode=false




route -p add 158.87.44.0 mask 255.255.254.0 10.134.2.200
route -p add 158.87.46.0 mask 255.255.254.0 10.134.2.200


svcc2srv0 & svcc2srv1
CHG0149609

--------------------------------------------------------------------------------------------------------------------
17 April

LON02AMMADC001	localhost	unknown		Domain controller WIndows box no access
LON02AMMADC002	localhost	unknown		Domain controller WIndows box no access
A0ETUS018VHAN11	A0ETUS018VHAN11	10.120.28.102	server not found nor pingable
A0ETUS018VHAN01	A0ETUS018VHAN01	10.143.69.239	server not found nor pingable
A0ETUS018VHAN02	A0ETUS018VHAN02	10.143.69.239	server not found nor pingable
br3tsapdb20	br3tsapdb20			Fixed 
fbtprdhandb_new	fbtprdhandb_new	10.121.75.11	server not found nor pingable
mtsdmartdev01	mtsdmartdev01	10.140.211.139	server not found nor pingable
mtsdmartqas01	mtsdmartqas01	10.140.48.168	server not found nor pingable
ptpkelimutudr	ptpkelimutudr	10.174.73.178	not accessible Linux HANA
ptpkelimutu	ptpkelimutu	10.174.73.189	not accessible Linux HANA
SJMPEPDB01DR	SJMPEPDB01DR	10.110.214.194	Fixed


CS2773550	St. Jude Medical -- JUD	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on JUDHDMART03-OLD- KB0010973
CS2773541	St. Jude Medical -- JUD	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on JUDHDMART02- KB0010973
CS2773544	MSC Industrial Supply Co. -- MS3	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MDCSERVERP2- KB0010973


My HO  -->   OS  performer  need  to  join channel   to  provide RAID  rebuild /copy   details  every  1  hr.
Server  - che01ammtsm001 -  146.89.142.114
Command   -  /opt/MegaRAID/storcli/storcli64 /c0/eall/sall show copyback
Provide  output  in tta channel (edited) 
[3:39 PM] 2>  CS2769209  -- Take followup  of  SUSE  ticket  - #00195417
https://scc.suse.com/support/cases/00195417#02s1i00000D1rrKAAR


CS2775772 LSPI -- LSPP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAVTXPRD0- KB0010973LZAVTXPRD0



approved to go ahead and remove obsolete deactivated VMs.

1) A0EASG012XVM041C-clone-keep off
2) svms1srv0-old
3) svth1srv0_old
4) svms1srv0_corrupted
5) svmh1srv0-old



CHG0149428
reboot OS servers for 10.6.3.32 and 10.6.3.33
spsvspasapp01	spsvspdsase01



 CS2776424  Manitoba Telecom Services -- MTSP2 - MajorMemory Swap CRITICAL: Swap free 49.93% (thresh 50:%)SOLNMGRDEV
[root@solnmgrdev ibmrmalik]$ free -gh
             total       used       free     shared    buffers     cached
Mem:           31G        17G        13G       4.4G       946M       7.2G
-/+ buffers/cache:       9.3G        22G
Swap:         8.0G       2.8G       5.2G



 CS2776529 Panasonic North America -- PN8P2 - MajorMemory Swap CRITICAL: Swap free 49.88% (thresh 50:%)PN8US7LECCQ3
 
 
 CS2776178 Concessionaria Aeroporto Rio de Jan -- CONP1 - SevereDisk Utilization /tmp CRITICAL: Free 16.23MB/0.43% (thresh @0:5%)CONSPDFDBAPPMHAS-AUTO TICKET DEFAULT DISPATCH
 

---------------------------------------------------------------------------------------

18 April

CHG0147727-IAG GBS Limited -- IA1-18-Apr-2020 12:00:00 AM(Pacific Time)	SP1 SAP Kernel upgrade	18-04-2020 12:30:00	16:30
SID : SP1
SP1	IA1S4HPRDAPP	10.133.15.13 	 	 
SP1	IA1S4HPRDDB	        10.133.15.11
SP1	IA1S4HPRDDBHA	10.133.15.12
SP1	IA1S4HPRDDBDR	10.199.15.200



CHG0147729-IAG GBS Limited -- IA1-18-Apr-2020 12:00:00 AM(Pacific Time)	BP1 SAP Kernel upgrade
Host / IP = IA1BPCPRDAPP / 10.133.15.22



CS2785280 Meggitt PLC -- MGGP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 23.82 (thresh: 16)

CS2785664 Panasonic North America -- PN8P2 - MajorMemory Swap CRITICAL: Swap free 45.63% (thresh 50:%)


CS2787161 A.P. Moller Maersk -- APMP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 43.45 (thresh: 16)

CS2787571    DFJ Trung Nguyen Group Corporation -- TNGP3 - Minor(Received during suppression) Disk Utilization /opt/monitor/IBM CRITICAL: Free 657.12MB/12.77% (thresh @10.01:20%)

CS2788722 A.P. Moller Maersk -- APMP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 44.69 (thresh: 16)






[root@asddev ibmrmalik]$ df -hT /dev/mapper/adsappvg-usr_sap_ccms_lv
Filesystem                           Type  Size  Used Avail Use% Mounted on
/dev/mapper/adsappvg-usr_sap_ccms_lv ext4   12G  9.0G  2.2G  81% /usr/sap/ccms
/dev/mapper/adsappvg-usr_sap_ccms_lv  /usr/sap/ccm

[root@asddev ibmrmalik]$ dumpe2fs  /dev/mapper/adsappvg-usr_sap_ccms_lv | grep -i superblock
dumpe2fs 1.42.11 (09-Jul-2014)
  Primary superblock at 0, Group descriptors at 1-1
  Backup superblock at 32768, Group descriptors at 32769-32769
  Backup superblock at 98304, Group descriptors at 98305-98305
  Backup superblock at 163840, Group descriptors at 163841-163841
  Backup superblock at 229376, Group descriptors at 229377-229377
  Backup superblock at 294912, Group descriptors at 294913-294913
  Backup superblock at 819200, Group descriptors at 819201-819201
  Backup superblock at 884736, Group descriptors at 884737-884737
  Backup superblock at 1605632, Group descriptors at 1605633-1605633
  Backup superblock at 2654208, Group descriptors at 2654209-2654209
----------------------------------------------------------------------------------------------------
21 April


MGGGBJVECCX05	MGGGBJVECCX05	10.133.18.175	Fixed
mgggbjveccx09	mgggbjveccx09	10.133.18.155	Fixed
juddtrans02	10.216.15.28			Fixed
juddtrans02	10.196.4.13			duplicate of above server, noting found with ip adress
ms3wdclapp02	172.17.154.14, fe80::250:56ff:feb1:65ae	server noot found, cant connect 
pn8us7leccd5  	Fixed 10.129.32.80                                                                                                                                                                                                                     A0DTUS012XVM021	crosflsua01	10.68.200.30	server not found




sybase/SPJ  >>30 GB
/sybase/SPJ/sybsystem  > 3 GB
[root@agespsvspsrv2 /]# df -hT /sybase/SPJ/sybsystem
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/spjlogvg-spjsybsystm_lv
                     ext4  4.8G 1011M  3.6G  22% /sybase/SPJ/sybsystem
                     
[root@agespsvspsrv2 /]# vgs spjlogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  spjlogvg   1   4   0 wz--n- 32.00g 1020.00m



 /sybase/SPJ/sybtemp > 5GB
 [root@agespsvspsrv2 /]# df -hT /sybase/SPJ/sybtemp
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/spjdatavg-spjsybtemp_lv
                     ext4  4.8G  3.1G  1.6G  67% /sybase/SPJ/sybtemp
[root@agespsvspsrv2 /]# vgs spjdatavg
  VG        #PV #LV #SN Attr   VSize   VFree
  spjdatavg   2   7   0 wz--n- 191.99g 4.99g
 
 
 /sybase/SPJ/sapdiag >5 GB
 [root@agespsvspsrv2 /]# df -hT /sybase/SPJ/sapdiag
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/spjlogvg-spjsybdiag_lv
                     ext4  4.8G  4.1G  550M  89% /sybase/SPJ/sapdiag
[root@agespsvspsrv2 /]# vgs spjlogvg
  VG       #PV #LV #SN Attr   VSize  VFree
  spjlogvg   1   4   0 wz--n- 32.00g 1020.00m
 
 
[7:51 AM] Hostname :agespsvspsrv2, IP address 10.6.3.62


[root@asddev ibmrmalik]$ strace -ffxvto resize2fs-beforefsck.strace resize2fs /dev/mapper/adsappvg-usr_sap_ccms_lv
resize2fs 1.42.11 (09-Jul-2014)
Filesystem at /dev/mapper/adsappvg-usr_sap_ccms_lv is mounted on /usr/sap/ccms; on-line resizing required
old_desc_blocks = 1, new_desc_blocks = 2
resize2fs: Permission denied to resize filesystem


CS2819061	AGEAS -- AGE	AGE	AGE SAP HEC-AMM SAP LOB	Incident	P1 - Severe	New		Host Reboot CRITICAL: Uptime 1 minutes 



SUSE Case 00195580 - RCA to know why after an OS update the file /usr/share/zoneinfo/America/New_York got corrupted
Issue has been handle in channel #pn4-19apr20-rcas-mp1-cp1

-------------------------------------------------------------------------------------------------------
22 April

Aq12wsde34rfgt56



CS2828854		number:CS1770558
10.143.69.228	delta-dal09-phana-2048-03.imzcloud.ibmammsap.local
dlthsehdb2	10.4.5.168		IPMI Upl9Mekhz5


CS2831560	Delta Airlines -- DAL	DAL	DAL SAP HEC-AMM SAP LOB	Incident	P1 - Severe	New		Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)
9:39 AM
CS2831556	Delta Airlines -- DAL	DAL	DAL SAP HEC-AMM SAP LOB	Incident	P1 - Severe	New		Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)	dltqeahap3

CS2831582	Delta Airlines -- DAL	DAL	DAL SAP HEC-AMM SAP LOB	Incident	P1 - Severe	New		Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)	dlthpehap12
9:44 AM



CS2625267
Still below servers are reporting with current time. Kindly remove nagios software from all the below mentioned servers and let us know, So that we can remove from nagios monitoring
Host Nagios Server Status/Last Update
====================================================
dlthpghap3 passive3east 2020-04-13 05:12:09
dltdsdap1 passive3east 2020-04-13 05:12:50
dltdsddb1 passive3east 2020-04-13 05:12:59
dltdspap1 passive3east 2020-04-13 05:12:50
dltdspdb1 passive3east 2020-04-13 05:13:05
dltdsqap1 passive3east 2020-04-13 05:11:35
dltdsqdb1 passive3east 2020-04-13 05:11:42
dltdssap1 passive3east 2020-04-13 05:12:14
dltdssdb1 passive3east 2020-04-13 05:13:24
dlthbehap1 passive3east 2020-04-13 05:13:41
dlthbehap2 passive3east 2020-04-13 05:09:51
dlthbehap3 passive3east 2020-04-13 05:12:34
dlthbehap4 passive3east 2020-04-13 05:12:59
dlthbehap5 passive3east 2020-04-13 05:12:38
dlthbggat passive3east 2020-04-13 05:10:32
dlthbggat1 passive3east 2020-04-13 05:13:49
dlthbggat2 passive3east 2020-04-13 05:11:12
dlthbggat3 passive3east 2020-04-13 05:13:08
dltwb1hwd passive3east 2020-04-13 05:13:47
dltwb2hwd passive3east 2020-04-13 05:12:49
dlthmggat2 passive3east 2020-04-13 05:12:58


CHG0149428	CS2831809
spsvspasapp01	A0EASG014XVM030	10.6.3.33
spslspdsase01	A0EASG014XVM035
agespsvspsrv2

VG name sppdatavg


/sybase			 2 GB	sybase_lv	lvcreate -L 2G -n sybase_lv sppdatavg		 /dev/sppdatavg/sybase_lv	
/sybase/SPP		 18 GB	sppsybase_lv	lvcreate -L 18G -n sppsybase_lv sppdatavg	 /dev/sppdatavg/sppsybase_lv
/sybase/SPP/sybtemp	 5 GB	sppsybtemp_lv	lvcreate -L 5G -n sppsybtemp_lv sppdatavg	 /dev/sppdatavg/sppsybtemp_lv
/sybase/SPP/log_archive	 56 GB  sppsyblog1_lv	lvcreate -L 56G -n sppsyblog1_lv sppdatavg	 /dev/sppdatavg/sppsyblog1_lv
/sybase/SPP/sapdiag	 18 GB	sppsybdiag_lv	lvcreate -L 18G -n sppsybdiag_lv sppdatavg	 /dev/sppdatavg/sppsybdiag_lv
/sybase/SPP/sapdata1	100 GB	sppsapdata1_lv	lvcreate -L 100G -n sppsapdata1_lv sppdatavg	 /dev/sppdatavg/sppsapdata1_lv
/sybase/SPP/sapdata2	100 GB	sppsapdata2_lv	lvcreate -L 100G -n sppsapdata2_lv sppdatavg	 /dev/sppdatavg/sppsapdata2_lv
/sybase/SPP/sapdata3	100 GB	sppsapdata3_lv	lvcreate -L 100G -n sppsapdata3_lv sppdatavg	 /dev/sppdatavg/sppsapdata3_lv
/sybase/SPP/sapdata4	100 GB	sppsapdata4_lv	lvcreate -L 100G -n sppsapdata4_lv sppdatavg	 /dev/sppdatavg/sppsapdata4_lv
/sybase/SPP/saptemp	 48 GB	sppsaptemp_lv	lvcreate -L 48G -n sppsaptemp_lv sppdatavg	 /dev/sppdatavg/sppsaptemp_lv
					
/sybase/SPP/saplog1		sppsaplog1_lv	lvcreate -L 60G -n sppsaplog1_lv sppdatavg	/dev/sppdatavg/sppsaplog1_lv
/sybase/SPP/sybsystem		sppsybsystm_lv	lvcreate -L 5G -n sppsybsystm_lv sppdatavg	/dev/sppdatavg/sppsybsystm_lv

				sppsapbkp_lv	lvcreate -L 5G -n sppsapbkp_lv sppdatavg	/dev/sppdatavg/sppsapbkp_lv

mkfs.ext4  /dev/sppdatavg/sppsaplog1_lv 

mkfs.ext4 /dev/sppdatavg/sppsybsystm_lv 	

<>/sybase/SPP/saplog1 >> 60GB

<>/sybase/SPP/sybsystem >> 5GB

Above FS need to be created on (10.6.3.33)	
Pls keep some additional disk in reserver (to mount if required)


spplogvg-sybase_lv
sppdatavg-sppsybase_lv
spplogarch_lv  spparchvg -wi-ao----  54.00g                                   
  sppsybdiag_lv  spparchvg -wi-ao----  16.00g                                   
  sppsybsystm_lv spparchvg -wi-ao----   3.00g                                   
  sppsybtemp_lv  spparchvg -wi-ao----   5.00g                                   
  sppsapdata1_lv sppdatavg -wi-ao---- 137.00g                                   
  sppsapdata2_lv sppdatavg -wi-ao----  85.00g                                   
  sppsapdata3_lv sppdatavg -wi-ao----  85.00g                                   
  sppsapdata4_lv sppdatavg -wi-ao----  85.00g                                   
  sppsaptemp_lv  sppdatavg -wi-ao----  47.00g                                   
  sppsybase_lv   sppdatavg -wi-ao----  17.00g                                   
  sppsyblog1_lv  spplogvg  -wi-ao----  45.00g 
  
--------------------------------------------------------------------------------------------------------

23 April


afrfirprd2	10.146.2.13	FIXED
afrs4hprdapp2	10.67.1.37	Tried all possible steps, check if showing up now
zffpoth002	149.223.100.11	no access to my id in predeployment contact project team
zffpoth001	149.223.100.16 	no access to my id in predeployment contact project team                                                       
ERP-PRD2	10.7.1.13   	fixed



logged in the "sybspp" user need to execute this env file source /sybase/SPP/SYBASE.csh

LC_ALL=en_US.UTF-8
SAP_JRE7_32=/sybase/SPP/shared/SAPJRE-7_1_064_32BIT
SAP_JRE7=/sybase/SPP/shared/SAPJRE-7_1_064_64BIT
SAP_JRE7_64=/sybase/SPP/shared/SAPJRE-7_1_064_64BIT
SYBASE_OCS=OCS-16_0
INCLUDE=/sybase/SPP/OCS-16_0/include:
LIB=/sybase/SPP/OCS-16_0/lib:
LD_LIBRARY_PATH=/sybase/SPP/ASE-16_0/lib:/sybase/SPP/OCS-16_0/lib:/sybase/SPP/OCS-16_0/lib3p64:/sybase/SPP/OCS-16_0/lib3p:
SYBASE=/sybase/SPP
SYBASE_ASE=ASE-16_0
SYBROOT=/sybase/SPP
SYBASE_JRE_RTDS=/sybase/SPP/shared/SAPJRE-7_1_064_64BIT
SYBASE_WS=WS-16_0

[sybspp@spsvspdsase01 ~]$ printenv PATH
/sybase/SPP/ASE-16_0/jobscheduler/bin:/sybase/SPP/ASE-16_0/bin:/sybase/SPP/ASE-16_0/install:/sybase/SPP/WLA/bin::/sybase/SPP/OCS-16_0/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin


[sybspp@spsvspasapp01 ~]$ printenv PATH
/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin
-------------------------------------------------------------------------------------------------

24 April


CHG0146810	0630-1030	Manual change	"DPEJazril NaaimMohd Jaffar <jazril@my.ibm.com>
PDLBogdanDediu <RO69131@ro.ibm.com> Bharat kumar peram"

smdbuatuu3	10.78.26.24
smediuatuu3	10.78.26.25
smdbuatum3	10.78.26.20
smgwuatuq3	10.78.26.11
smemuatum3	10.78.26.21
smpouatux8	10.78.26.19



CS2852908


CS2856006  St. Jude Medical , USA -- JUE   LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 58.53 (thresh: 16)  P2


CS2856360  Panariagroup Industrie Ceramiche SP -- PNC   Mount down in ECP - pncapeccp   P1
//10.3.1.1/sapexchange /mnt/sapexchangeIT cifs credentials=/etc/sapexchangeIT_credential,uid=20000,gid=3050
[root@pncapeccp mnt]$ ls -ltr
ls: cannot access 'sapexchangeIT': Invalid argument
total 8
d????????? ? ?      ?         ?            ? sapexchangeIT


CS2855650 A.P. Moller Maersk -- APMP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 62.71 (thresh: 16)

CS2857267 A.P. Moller Maersk -- APMP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 33.41 (thresh: 16)


 CHG0151140
SVJD1SRV0	A0EASG014XVM003
SVFD1SRV0	A0EASG012XVM003

--------------------------------------------------------------------------------------------------------------------------

25 April


[root@spsvspasapp01 ibmrmalik]# df -hT /usr/sap/trans
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/sppappvg-usrtrans_lv
                     ext3   84G  2.0G   78G   3% /usr/sap/trans
                     



10.6.2.23
unmount
10.92.99.125:/usr/sap/trans
                      133G   67G   60G  53% /usr/sap/trans
Once done
re-name
/usr/sap/trans_old as /usr/sap/trans





[root@agespsvspsrv2 ibmrmalik]# cat /etc/fstab |grep -i /sapstage
/dev/spjappvg/sapstage_lv       /sapstage       ext4    _netdev,defaults       12
10.92.99.125:/sapstagetemp      /sapstagetemp nfs defaults  1  2
10.6.3.33:/sapstage     /sapstage       nfs     defaults        1 2



CS2870065   St. Jude Medical , USA -- JUE   LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 76.97 (thresh: 16)  P2                     
                     

----------------------------------------------------------------------------------------------------------------

28 April

CS2907149	Bumrungrad Hospital Plc -- BUM	P1 - Severe	S4P00003 (HANADB)|HDB_DATABASE_AVAILABILITY|Database Unavailable
CS2907132	Bumrungrad Hospital Plc -- BUM	P1 - Severe	POP00001 (HANADB)|HDB_DATABASE_AVAILABILITY|Database Unavailable


CS2907875 Bumrungrad Hospital Plc -- BUMP2 - MajorLog PaceMaker-log Found 6 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-04-28-10-18-26 for details. 


CS2907990	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-log Found 6 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-04-28-10-28-27 for details.
CS2908184	Bumrungrad Hospital Plc -- BUM	P2 - Major	Log PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-04-28-10-48-27 for details.
CS2908198	Bumrungrad Hospital Plc -- BUM	P2 - Major	Resource Pacemaker Active Nodes CRITICAL: CLUSTER OK: 1 node online, 1 standby node, 6 resources configured (thresh 2:2)
CS2908187	Bumrungrad Hospital Plc -- BUM	P2 - Major	Resource Pacemaker Colocation CRITICAL: Colocation Failure - Master/Slave Set: msl_SAPHana_S4P_HDB00 [rsc_SAPHana_S4P_HDB00] - rsc_ip on bumsaph4p02p, rsc_tsmtd

CS2908415	Bumrungrad Hospital Plc -- BUM	P1 - Severe	Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)

-------------------------------------------------------------------------------------------------------------------------------

29 April

A0DIML012XVM013	SAPCRMDNS1	10.70.2.74

false alert crond is gud  https://github.ibm.com/cms-infra-cookbooks/besclient/issues/56

false alert crond is gud  https://github.ibm.com/cms-infra-cookbooks/besclient/issues/56

cp4clusterissue

CS2923077   Tata Steel Limited -- TTA    LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 47.44 (thresh: 40)

CS2922329	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2922269	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2922255	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2922217	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2921666	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2921582	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2921542	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2921533	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2921531	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2921205	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2920987	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)
CS2920405	AGEAS -- AGE	P2 - Major	SQ-SAP-TRIO-C1	Service crond CRITICAL: 0 crond processes running (thresh 1:)

------------------------------------------------------------------------------------------------------------------------------

30 April


CS2932057	COTY Inc. -- CTU	P2 - Major	SQ-SAP-TRIO-C2	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.63 (thresh: 16) 
7:24 AM
CS2932388	St. Jude Medical , USA -- JUE	P2 - Major	SQ-SAP-TRIO-C1	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 33.79 (thresh: 16) 


CS2925628
Quality  - V72	Linux	BAPV721300 	10.134.4.14

remove the FS created in V32 /oracle/V32/sapdata5 350 GB
and
create the temporary File system /oracle/V72/sapdata5 350 GB

[root@bapv721300 V72]# df -hT /oracle/V32/sapdata5/
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/oraclevg-sapdata5_lv ext4  246G   60M  234G   1% /oracle/V32/sapdata5


 CS2956059 Meggitt PLC -- MGGP2 - MajorMemory Virtual CRITICAL: Free Memory 0.95% (thresh 2:%)MGGGBJQGTSX03
CS2955167  Panasonic North America -- PN8    CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=89.41% system=10.59% iowait=0.00% idle=0.00%


 CS2956059 Meggitt PLC -- MGGP2 - MajorMemory Virtual CRITICAL: Free Memory 0.95% (thresh 2:%)MGGGBJQGTSX03


ATLCRPDB 	10.15.32.20 	10.38.32.142		CEZ
Dal13
10.208.79.244	celanese-dal13-pod1-phana-4096-02.imzcloud.ibmammsap.local
root / Eu6nh9C9
IPMI pw   root  HcKG8gG8vk


172.22.64.23:/usr/sap/QB1/interfaces   /usr/sap/QB1/interfaces


CS2969003 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)

CS2969046 Tata Steel Limited -- TTAP2 - MajorDisk Utilization /var CRITICAL: Free 1379.49MB/8.02% (thresh @5.01:10%)


CS2969203 Tata Steel Limited -- TTAP2 - MajorDisk Utilization /var CRITICAL: Free 1517.14MB/8.82% (thresh @5.01:10%) 


CS2969463 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)

Log file tar ball: /var/log/nts_sapapp23_200502_1820.tbz
  Log file size:     5.7M
  Log file md5sum:   bea3ce7ad0ee60296121a16797af4fa5


--------------------------------------------
6 May

CS3018687


1. Source system (10.134.15.9 & bumsaps4d01t ) BUMSAPS4D01T 	10.134.15.9 	10.156.3.11	-  Mount Point  /usr/sap/trans
					       BUMSAPPOP01P 	10.134.14.9 	10.156.1.11
2. Destination Systems - 

-  Please move exisitng mount point  /usr/sap/trans  to /usr/sap/trans.old

 - And mount trasn directory from Source system (10.134.15.9 & bumsaps4d01t ))

Host names -  
 <> 10.134.15.15 (bumsappod01t)
<.> 10.134.15.18 (bumsappoq01t)
<>10.134.14.9 (bumsappop01p)
<>10.134.14.10 (bumsappop02p)



CS3014849	AGEAS -- AGE	AGE	AGE SAP HEC-AMM SAP LOB	Incident	P2 - Major	New		Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP3SRV0-DR- KB0010973
2:08 PM
CS3014845	AGEAS -- AGE	AGE	AGE SAP HEC-AMM SAP LOB	Incident	P2 - Major	New		Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP3SRV0- KB0010973


stat("/sapmnt/POP


CHG0151457
tscmldev	10.207.62.17	Development -- Linux tscmldev 4.4.121-92.125-default #1 --
[root@tscmldev ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tscmldev 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Wed May  6 07:11:57 EST 2020

[root@tscmldev ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tscmldev 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Wed May  6 08:29:37 EST 2020
      Local time: Wed 2020-05-06 08:29:37 EST
  Universal time: Wed 2020-05-06 13:29:37 UTC
        RTC time: Wed 2020-05-06 13:29:36
       Time zone: Etc/GMT (EST, -0500)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found

jbdaix4	        10.207.62.22	Development -- Linux jbdaix4 4.4.121-92.125-default #1 --
[root@jbdaix4 ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux jbdaix4 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Wed May  6 17:42:02 IST 2020

[root@jbdaix4 ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux jbdaix4 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Wed May  6 19:04:05 IST 2020
      Local time: Wed 2020-05-06 19:04:05 IST
  Universal time: Wed 2020-05-06 13:34:05 UTC
        RTC time: Wed 2020-05-06 13:34:05
       Time zone: Etc/GMT (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found


Sev4-Important Patches
SUSE-SLE-SAP-12-SP2-2020-68
SUSE-SLE-SAP-12-SP2-2020-159
SUSE-SLE-SAP-12-SP2-2020-318
SUSE-SLE-SAP-12-SP2-2020-331
SUSE-SLE-SAP-12-SP2-2020-334
SUSE-SLE-SAP-12-SP2-2020-384
SUSE-SLE-SAP-12-SP2-2020-410
SUSE-SLE-SAP-12-SP2-2019-3347
SUSE-SLE-SAP-12-SP2-2020-717
SUSE-SLE-SAP-12-SP2-2020-928
SUSE-SLE-SAP-12-SP2-2020-978
SUSE-SLE-SAP-12-SP2-2019-3347
Sev3 -Moderate Patches
SUSE-SLE-SAP-12-SP2-2019-3180
SUSE-SLE-SAP-12-SP2-2020-88
SUSE-SLE-SAP-12-SP2-2020-394
SUSE-SLE-SAP-12-SP2-2020-457
SUSE-SLE-SAP-12-SP2-2020-474
SUSE-SLE-SAP-12-SP2-2020-497
SUSE-SLE-SAP-12-SP2-2020-512
SUSE-SLE-SAP-12-SP2-2020-545
SUSE-SLE-SAP-12-SP2-2020-569
SUSE-SLE-SAP-12-SP2-2020-792
SUSE-SLE-SAP-12-SP2-2020-854



########## POST CHECK ###############
cd /tmp
./prechecks_script.sh >> postcheck.log
################################

zypper ref
zypper --non-interactive up
Reboot
POST CHECK
umount -l path
fsck -y lv-path
tune2fs -l lv_path

-------------------------------------------------------------------------------------------------

7 May


bs5devdb	10.162.24.252	FIXED
ttatslmdgqadb	10.162.186.176	Retired
tsleecprhadb	10.162.186.170	mostly retired
pidev		10.207.62.23	cant connect server in predeployment
sappoqa		10.207.63.29	cant connect server in predeployment
sapcrmapp2	unknown		Pending deactivation
prdrep		10.207.61.220	cant connect
sapapp27	10.207.61.47	FIXED
sapapp20	10.207.61.195	FIXED
ap4dmg0022	unknown		pending deactivation
ap4bwp0015	100.126.144.16	FIXED
ap4s4p0011	10.141.0.22	FIXED
bumsappop02p	10.134.14.10	FIXED


TATA change	CHG0151460
crmdevapp    10.207.62.19  CDA apps only
crmdevapp /home/ibmrmalik# cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux crmdevapp 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu May  7 17:26:55 IST 2020
      Local time: Thu 2020-05-07 17:26:55 IST
  Universal time: Thu 2020-05-07 11:56:55 UTC
        RTC time: Thu 2020-05-07 11:56:55
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found

[root@crmdevapp ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux crmdevapp 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu May  7 18:54:20 IST 2020
      Local time: Thu 2020-05-07 18:54:20 IST
  Universal time: Thu 2020-05-07 13:24:20 UTC
        RTC time: Thu 2020-05-07 13:24:20
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found

tsgpdev      10.207.62.27   SGD apps+oraDB   --- Has FSCK Errors
[root@tsgpdev ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tsgpdev 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu May  7 19:57:03 +08 2020
      Local time: Thu 2020-05-07 19:57:03 +08
  Universal time: Thu 2020-05-07 11:57:03 UTC
        RTC time: Thu 2020-05-07 11:57:03
       Time zone: Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found

[root@tsgpdev ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tsgpdev 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Thu May  7 21:10:03 +08 2020
      Local time: Thu 2020-05-07 21:10:03 +08
  Universal time: Thu 2020-05-07 13:10:03 UTC
        RTC time: Thu 2020-05-07 13:10:02
       Time zone: Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found



One liner to check for FS wih errors
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done




CS3027530 AGEAS -- AGEP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP3SRV0-DR- KB0010973CCCP3SRV0-DR



CS3031786 AGEAS -- AGEP2 - MajorService gpsvc critical(gpsvc=stopped (auto))SVMQ1SRV0SQ-SAP-TRIO-C1



CS3033330 AGEAS -- AGEP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP3SRV0- KB0010973CCCP3SRV0SQ-SAP-TRIO-C1
CS3033348 AGEAS -- AGEP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP3SRV0-DR- KB0010973CCCP3SRV0-DRSQ-SAP-TRIO-C1


----------------------------------------------------------


8 May

158.87.44.0     10.74.6.1       255.255.254.0   UG    0      0        0 bond0.1328
158.87.46.0     10.74.6.1       255.255.254.0   UG    0      0        0 bond0.1328


route del -net 158.87.46.0 gw 10.74.6.1 netmask 255.255.254.0 dev bond0.1328


CS3043395  Panasonic North America -- PN4   Memory Swap CRITICAL: Swap free 30.97% (thresh 50:%) 



CS3034863	TSLBWDEVDB NodeAlias: 10.207.62.14
Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TSLBWDEVDB- KB0010973


CS3034867 -


 CS3043048 Bumrungrad Hospital Plc -- BUMP2 - MajorResource Pacemaker Colocation CRITICAL: Colocation Failure - Master/Slave Set: msl_SAPHana_S4P_HDB00 [rsc_SAPHana_S4P_HDB00] - rsc_ip on bumsaph4p01p, rsc_tsmtdBUMSAPH4P01PSQ-SAP-TRIO-C1
 
 10.116.145.56	sng01-pod2-4tb-host03.imzcloud.ibmammsap.local	root 8U6bie%Rddpzy2@	bumsaph4p01p
 10.116.145.59	sng01-pod2-4tb-host04.imzcloud.ibmammsap.local  root K2oExi%mFnZKXB@	bumsaph4p02p

 
 
CS3043108 Bumrungrad Hospital Plc -- BUMP2 - MajorLog PaceMaker-log Found 20 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-05-08-12-32-46 for details.BUMSAPH4P01PSQ-SAP-TRIO-C1 (edited) 



CS3044513 Panasonic North America -- PN4P2 - MajorMemory Swap CRITICAL: Swap free 40.66% (thresh 50:%)PN4US7LSMGD



CS3044441


 CS3045770 CMA CGM -- CMAP3 - MinorDisk add -needed due to db2 upgrade project(empty)S
Please add disks and assign to vg on below hosts :
smsltquaqk1     10.78.24.39 20G space in qk1logvg
smdsquaqo1q71   10.78.24.27 20G space in qo1logvg
smboquaqb3      10.78.24.15 20G space in qb3logvg
smbouatub3      10.78.26.12 20G space in ub3logvg


CHG0151464
 
One liner to check for FS wih errors
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done

asddev	    10.207.62.25	   Development 

 cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux asddev 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Fri May  8 17:06:42 IST 2020
      Local time: Fri 2020-05-08 17:06:43 IST
  Universal time: Fri 2020-05-08 11:36:43 UTC
        RTC time: Fri 2020-05-08 11:36:43
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found

[root@asddev ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux asddev 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Fri May  8 18:27:03 IST 2020
      Local time: Fri 2020-05-08 18:27:04 IST
  Universal time: Fri 2020-05-08 12:57:04 UTC
        RTC time: Fri 2020-05-08 12:57:03
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found


journalctl -xb  |grep -i error
vgchange -ay rootvg
lvsscan
tune2fs -l /dev/rootvg/rootlv |grep state
Filesystem state:         clean
check each fs  like this
if you see clean with error  run fsck
e2fsck -f -y and path rite
or
fsck.xfs /dev/roovg/lvname

comment a section put /* and */

[root@essmssdev-dr ibmrmalik]$ df -hT |grep -i eddappvg-usr_sap_lv
/dev/mapper/eddappvg-usr_sap_lv               ext4      976M  583M  327M  65% /usr/sap







----------------------------------------------------------------------------------

9 May
Kernel upgrade patch level to 753/501 on PRD (S/4 HANA PROD) systems + FSCK error fixing

One liner to check for FS wih errors
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done


CHG0153071	09-05-2020 06:00:00	09-05-2020 08:30:00

SAPAPP22	10.207.61.63	10.170.61.231
SAPAPP15	10.207.61.37	10.170.61.121
SAPAPP18	10.207.61.70	10.170.61.116
SAPAPP19	10.207.61.215	10.170.61.74
SAPAPP20	10.207.61.195	10.170.61.48
SAPAPP21	10.207.61.80	10.170.61.131
SAPAPP23	10.207.61.130	10.170.61.226
SAPAPP26	10.207.61.48	10.170.61.176
SAPAPP27	10.207.61.47	10.170.61.166
SAPAPP28	10.207.61.58	10.170.61.211
SAPAPP29	10.207.61.85	10.170.61.141
SAPAPP30	10.207.61.95	10.170.61.161

+ 

FSCK errors are found in below servers which needs to be fixed for which we need OS reboot:
SAPAPP21	10.207.61.80	10.170.61.131
/dev/mapper/prdappvg-sapmnt_lv
Filesystem state:         clean with errors
/dev/mapper/prdappvg-INTERFACE_lv
Filesystem state:         clean with errors
/dev/mapper/prdappvg-tran1s_lv
Filesystem state:         clean with errors
/dev/mapper/prdappvg-usr_sap_lv
Filesystem state:         clean with errors
/dev/mapper/prdappvg-usr_sap_PRD_lv
Filesystem state:         clean with errors
/dev/mapper/prdappvg-usr_sap_DAA_lv
Filesystem state:         clean with errors



SAPAPP26	10.207.61.48	10.170.61.176
/dev/mapper/prdappvg-usr_sap_lv
Filesystem state:         clean with errors

[root@sapapp26 ibmrmalik]$ tune2fs -l //dev/mapper/prdappvg-usr_sap_lv |grep -i state
Filesystem state:         clean




sapapp29	sandeep
/dev/mapper/rootvg-tmplv
Filesystem state:         clean with errors


TSLEECPRDDB 	10.207.61.78 	10.170.61.59
/dev/sda1
Filesystem state:         not clean



BIPRDAPP3 	10.207.61.31 	10.170.61.17
/dev/mapper/rootvg-tmplv
Filesystem state:         clean with errors

/dev/mapper/rootvg-varlv
Filesystem state:         clean with errors
/dev/mapper/rootvg-vloglv
Filesystem state:         clean with errors


BIPRDAPP1 	10.207.61.28 	10.170.61.91



CHG0153071
 sapapp21, sapapp22, sapapp26, sapapp29

--------------------------------------------------------------------------------------------------

12 May



CHG0150959	FBS-FRA02-NONPROD- Apply Latest Q220 Patches on Linux Servers			
FRA02	Bogdan Dediu	MAHESH NAIK P	12-05-2020 06:30:00	12-05-2020 13:00:00
				
fbsdbd01fgcl	10.199.98.20			
fbsdbd02fgcl	10.199.98.21	10.85.0.180	fra02-pod2-4tb-host02.imzcloud.ibmammsap.local root  NftWo6%5HyBhBZ@
fbsapd02fgcl	10.199.98.13			
fbsapd01fgcl	10.199.98.11			


CHG0146893
CHG0147500
CHG0146233
CHG0151161
CHG0150794

--------------------------------------------------------------------------------------------------
13 May


CS3087211 and let me know if there is a possibility to have a new FS on this server: iplsas4dt03	10.138.3.23


[root@jbdaix4 ibmrmalik]$ rpm -qa |grep -i openssh
openssh-askpass-1.2.4.1-7.5.x86_64
openssh-helpers-7.2p2-74.54.1.x86_64
openssh-7.2p2-74.54.1.x86_64


[root@jbdaix4 ibmrmalik]$ zypper list-updates |grep -i openssh
[root@jbdaix4 ibmrmalik]$


No update candidate for 'openssh-askpass-1.2.4.1-7.5.x86_64'. The highest available version is already installed.
No update candidate for 'openssh-helpers-7.2p2-74.54.1.x86_64'. The highest available version is already installed.
No update candidate for 'openssh-7.2p2-74.54.1.x86_64'. The highest available version is already installed.



CS3091176	Bumrungrad Hospital Plc -- BUM	BUM	BUM IC4SAP-SL SAP LOB	Incident	P1 - Severe	New		Mountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :

CS3088529	ZF Friedrichshafen AG -- ZFF	ZFF	ZFF IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-05-13-00-18-44 for details


--------------------------------------------------------------------------------------------------------

14 May


CHG0153801	OS update from SLES 12 SP2 to SP4

SVES1SRV0	10.6.1.139	10.92.99.139
SVJS1SRV0	10.6.1.140	10.92.99.140
SVCS1SRV0	10.6.1.142	10.92.99.142

SVES1HDBSRV01	10.6.1.138	10.92.99.138	OS update 10.116.205.203	ageas-phana-1024-4.imzcloud.ibmammsap.local
SVES1HDBSRV01:/tmp # cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux SVES1HDBSRV01 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Wed May 13 15:59:12 +08 2020
      Local time: Wed 2020-05-13 15:59:12 +08
  Universal time: Wed 2020-05-13 07:59:12 UTC
        RTC time: Wed 2020-05-13 07:59:12
       Time zone: Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found

SVES1HDBSRV01:/home/ibmrmalik # cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux SVES1HDBSRV01 4.12.14-95.51-default #1 SMP Fri Apr 17 08:14:12 UTC 2020 (c6bab98) x86_64 x86_64 x86_64 GNU/Linux
Thu May 14 10:19:31 +08 2020
      Local time: Thu 2020-05-14 10:19:31 +08
  Universal time: Thu 2020-05-14 02:19:31 UTC
        RTC time: Thu 2020-05-14 02:19:31
       Time zone: Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found



SVCS1HDBSRV01	10.6.1.141	10.92.99.141	OS update 10.116.205.198	ageas-phana-1024-2.imzcloud.ibmammsap.local
[root@SVCS1HDBSRV01 tmp]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux SVCS1HDBSRV01 4.4.121-92.117-default #1 SMP Tue Jul 9 10:25:00 UTC 2019 (c78052b) x86_64 x86_64 x86_64 GNU/Linux
Wed May 13 15:59:12 +08 2020
      Local time: Wed 2020-05-13 15:59:12 +08
  Universal time: Wed 2020-05-13 07:59:12 UTC
        RTC time: Wed 2020-05-13 15:59:12
       Time zone: Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: yes

Warning: The system is configured to read the RTC time in the local time zone.
         This mode can not be fully supported. It will create various problems
         with time zone changes and daylight saving time adjustments. The RTC
         time is never updated, it relies on external facilities to maintain it.
         If at all possible, use RTC in UTC by calling
         'timedatectl set-local-rtc 0'.
OK: No read-only file systems found


root@SVCS1HDBSRV01 etc]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux SVCS1HDBSRV01 4.12.14-95.51-default #1 SMP Fri Apr 17 08:14:12 UTC 2020 (c6bab98) x86_64 x86_64 x86_64 GNU/Linux
Thu May 14 15:42:59 +08 2020
      Local time: Thu 2020-05-14 15:42:59 +08
  Universal time: Thu 2020-05-14 07:42:59 UTC
        RTC time: Thu 2020-05-14 02:42:59
       Time zone: Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: yes

Warning: The system is configured to read the RTC time in the local time zone.
         This mode can not be fully supported. It will create various problems
         with time zone changes and daylight saving time adjustments. The RTC
         time is never updated, it relies on external facilities to maintain it.
         If at all possible, use RTC in UTC by calling
         'timedatectl set-local-rtc 0'.
OK: No read-only file systems found


root@SVCS1HDBSRV01
Can't get available migrations from server: SUSE::Connect::CannotBuildBasicAuth: 
Cannot read username and password from /etc/zypp/credentials.d/SCCcredentials.
'/usr/lib/zypper/commands/zypper-migration' exited with status 1

https://www.suse.com/support/kb/doc/?id=000018907

[root@SVCS1HDBSRV01 credentials.d]$ zypper ls
#  | Alias                                                                                       | Name                                        | Enabled | GPG Check | Refresh | Type    
---+---------------------------------------------------------------------------------------------+---------------------------------------------+---------+-----------+---------+---------
1  | SLE-12-SAP-DVD1                                                                             | SLE-12-SAP-DVD1                             | Yes     | (r ) Yes  | Yes     | yast2   
2  | SLE-12-SAP-DVD2                                                                             | SLE-12-SAP-DVD2                             | Yes     | (r ) Yes  | Yes     | yast2   
3  | SLE-MOD-SYSMGMNT                                                                            | SLE-MOD-SYSMGMNT                            | Yes     | ( p) Yes  | Yes     | plaindir
4  | SMT-http_che01ammsmt01_imzcloud_ibmammsap_local:SLE-Module-Adv-Systems-Management12-Pool    | SLE-Module-Adv-Systems-Management12-Pool    | Yes     | (r ) Yes  | No      | rpm-md  
5  | SMT-http_che01ammsmt01_imzcloud_ibmammsap_local:SLE-Module-Adv-Systems-Management12-Updates | SLE-Module-Adv-Systems-Management12-Updates | Yes     | (r ) Yes  | No      | rpm-md  
6  | SMT-http_che01ammsmt01_imzcloud_ibmammsap_local:SLE-SDK12-SP2-Updates                       | SLE-SDK12-SP2-Updates                       | Yes     | (r ) Yes  | No      | rpm-md  
7  | Updates-SLE-HA                                                                              | Updates-SLE-HA                              | Yes     | ( p) Yes  | Yes     | plaindir
8  | Updates-SLE-SAP                                                                             | Updates-SLE-SAP                             | Yes     | ( p) Yes  | Yes     | plaindir
9  | Updates-SLE-SDK                                                                             | Updates-SLE-SDK                             | Yes     | ( p) Yes  | Yes     | plaindir
10 | Updates-SLE-SERVER                                                                          | Updates-SLE-SERVER                          | Yes     | ( p) Yes  | Yes     | plaindir

Adding service SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local: SUSE::Connect::ZypperError: Unexpected exception.
[SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local:SLES12-SP4-Updates|http://che01ammsmt01.imzcloud.ibmammsap.local/repo/SUSE/Updates/SLE-SERVER/12-SP4/x86_64/update?credentials=SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local] Repository already exists.


Performing repository rollback...
Starting to sync system product activations to the server. This can take some time...
command 'zypper --non-interactive removeservice 'SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local'' failed
Rollback failed: SUSE::Connect::ZypperError: System management is locked by the application with pid 27574 (zypper)


Florin Iordan we had 2 issues in the past
12:19 PM
servers registered to a wrong SMT server during provisioning because of some wrong images
12:20 PM
Ravi Malik (TRIO C - OS Support):grin: hmm i could see wrong url in suseconnect
12:20 PM
so manually edited it to chennai one
12:20 PM
but that also didnt help
12:20 PM
and credentials.d was empty
12:20 PM
now i see 2 files with cred
12:20 PM
Florin Iordan 2. a problem with /root/cert_fingerprint that we had to remove on all the VMs and rerun chef-client
12:20 PM
Ravi Malik (TRIO C - OS Support):grin: oh
12:20 PM
Florin Iordan so in this case you had the issue 1
12:21 PM
in that case you only need to remove /etc/SUSEConnect file and rerun chef-client
12:21 PM
you should not edit it manually
12:22 PM
Ravi Malik (TRIO C - OS Support):grin: oh
12:23 PM
so this is something we can try too
12:23 PM
wil make a note of this

SVES1HDBSRV01
completed and restarted






25 May to 28th june
50 hrs furlough


CS3103201  Bumrungrad Hospital Plc -- BUM    Mountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :   P1


-------------------------------------------------------------------------------

15 May


CHG0151143	15-05-2020 06:30:00	15-05-2020 11:00:00
Gratiela Novac 	VIKNESH PALAYAM	
ECT-LON02-NONPROD- Apply Latest Q220 Patches on Linux Servers
Host Name	                IFN IP			Asset Purpose

ECTS4HQASDB 	10.5.8.11 	10.30.10.139 		       QA  -  hana server - hana version 1.00.122.16 (RLES HANA DB - 3.x only - We will ONLY patch the LATEST SECURITY patches on the SAME LEVEL...)
[root@ECTS4HQASDB ibmrmalik]$ cat /etc/redhat-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/fstab |grep -i sds
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux ECTS4HQASDB 2.6.32-573.26.1.el6.x86_64 #1 SMP Tue Apr 12 01:47:01 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux
Thu May 14 12:03:34 EET 2020
bash: timedatectl: command not found
OK: No read-only file systems found
                     nfs    6.6T  3.1T  3.2T  49% /sds
[root@ECTS4HQASDB tmp]$ subscription-manager release --show
Release: 6.7

Limiting packages to security relevant ones
No packages needed for security; 90 packages available
[root@ECTS4HQASDB ibmrmalik]$

[root@ECTS4HQASDB ibmrmalik]$ cat /etc/redhat-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/fstab |grep -i sds
Red Hat Enterprise Linux Server release 6.7 (Santiago)
Linux ECTS4HQASDB 2.6.32-573.26.1.el6.x86_64 #1 SMP Tue Apr 12 01:47:01 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux
Fri May 15 03:47:33 EET 2020
bash: timedatectl: command not found
OK: No read-only file systems found
                     nfs    6.6T  3.1T  3.2T  49% /sds



ECTS4HQASAP 	10.5.8.12 	10.30.10.140	       QA - application servers
[root@ECTS4HQASAP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/fstab |grep -i sds
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ECTS4HQASAP 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Thu May 14 12:03:15 EET 2020
bash: timedatectl: command not found
10.30.10.142:/usr/sap/trans /usr/sap/trans nfs defaults 0 0
OK: No read-only file systems found
                     nfs    103G   26G   72G  27% /usr/sap/trans
                     nfs    6.6T  3.1T  3.2T  49% /sds

[root@ECTS4HQASAP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/fstab |grep -i sds
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ECTS4HQASAP 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri May 15 03:50:30 EET 2020
bash: timedatectl: command not found
10.30.10.142:/usr/sap/trans /usr/sap/trans nfs defaults 0 0
OK: No read-only file systems found
                     nfs    103G   26G   72G  27% /usr/sap/trans
                     nfs    6.6T  3.1T  3.2T  49% /sds


FBTPRDHANDB_new with this info? Network information: CFN & IFN gateway & VLAN details  192.168.167.252(CFN) ( 
10.121.75.11	dalhana-1024-57.xsportal.local




CS3109728
For pre-prod V31 - NFS mount 

1> Rename existing mount /usr/sap/trans to /usr/sap/trans_V31
2> NFS mount /usr/sap/trans from V59 system to V31 (reference V32 and V33)

server Details:
V59 bapv590800 - 10.134.4.13
Server Type: Development                                                 *
*       Hostname: bapv590800                                                  *
*         CFN IP: 10.8.216.14                                                 *
*         IFN IP: 10.134.4.13                                                 *
*        SAP SID: V59      
 
V31 bapv311300   - 10.134.4.16
 Server Type: Pre-Production                                              *
*       Hostname: bapv311300                                                  *
*         CFN IP: 10.8.216.20                                                 *
*         IFN IP: 10.134.4.16                                                 *
*        SAP SID: V31                                                         *
************************



CS3109682
CPU Utilization
Memory Utilization

 using "sar -u -f" for CPU and "sar -r -f" for memory

sappoprdc	CPU	Mem	
	        CPU     %user     %nice   %system   %iowait    %steal     %idle
Average:        all      3.17      0.01      1.24      0.33      0.00     95.25
Average:        all      3.25      0.01      1.25      0.34      0.00     95.15

	    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
Average:     38261159 141238057     78.68   4322126 107072838  80404779     34.98  90445162  41847970       568
Average:     38244138 141255078     78.69   4322601 107092163  80414889     34.99  90514094  41801015       570




sapapp26
	        CPU     %user     %nice   %system   %iowait    %steal     %idle
Average:        all     10.46      0.02      1.32      0.08      0.00     88.12
Average:        all     11.21      0.02      1.32      0.08      0.00     87.37

	    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
Average:      3386022  63623086     94.95    784342  44573255  71316258     60.78  52964981   7050523      1659
Average:      3368405  63640703     94.97    769689  44387040  71506745     60.94  52934634   7081256      1549


---------------------------------------------------------------------------------------------------------------------------------------------

16 May


CHG0147500
IA1-LON02-AUTOMATION-PROD- Apply Latest Q220 Patches on <<Linux>> Servers	IAG GBS Limited -- IA1
16-05-2020 13:30:00	16-05-2020 19:30:00

Perform the patching automation via the following link: https://sapops.containers.ciocloudservices.ibm.com
SOP: 3.x Patching process: https://github.ibm.com/CMS/sap-ops-automation-docs/wiki/3.x-Patching-Process

Host Name	                IFN IP			Asset Purpose
ia1hccprdwd	10.133.15.28	Production
[root@IA1HCCPRDWD ibmrmalik]# uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Linux IA1HCCPRDWD 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat May 16 12:09:13 CEST 2020
OK: No read-only file systems found

ia1webdspprd1	10.133.15.16	Production	done
[root@IA1WEBDSPPRD1 ibmrmalik]$ uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Linux IA1WEBDSPPRD1 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat May 16 12:09:13 CEST 2020
OK: No read-only file systems found

ia1webdspprd2	10.133.15.17	Production
[root@IA1WEBDSPPRD2 ibmrmalik]$ uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Linux IA1WEBDSPPRD2 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat May 16 12:09:13 CEST 2020
OK: No read-only file systems found


ia1hcidevapp	10.133.17.150	Production
[root@IA1HCIDEVAPP ibmrmalik]$ uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Linux IA1HCIDEVAPP 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat May 16 12:09:13 CEST 2020
OK: No read-only file systems found


ia1ftsprdapp	10.133.15.24	Production	Done
[root@IA1FTSPRDAPP ibmrmalik]$ uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Linux IA1FTSPRDAPP 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat May 16 12:09:13 CEST 2020
OK: No read-only file systems found

ia1webdslbdr	10.133.15.31	Production	Done
[root@IA1WEBDSLBDR ibmrmalik]$ uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Linux IA1WEBDSLBDR 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat May 16 12:09:13 CEST 2020
OK: No read-only file systems found


ia1nfsprdapp	10.133.15.25	Production
[root@IA1NFSPRDAPP ibmrmalik]$ uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
Linux IA1NFSPRDAPP 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat May 16 12:09:18 CEST 2020
OK: No read-only file systems found

ia1fioprdapp	10.133.15.15	Production	done


ia1fioprddb	10.133.15.14	Production	done
ia1otasprdapp	10.133.17.147	Production
ia1otasprddb	10.133.17.146	Production
ia1webdslbha	10.133.15.33	Production
ia1webdslb	10.133.15.32	Production	Done
ia1hciprdapp	10.133.15.23	Production	done

CS3118910-pre checks SNOW number
patching change CHG0154748


uname -a;date;sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh



CS3119708 Arnoldo Mondadori Editore SpA -- ARMP3 - MinorDisk Utilization /var/log CRITICAL: Free 758.22MB/19.90% (thresh @10.01:20%)


CS3120240 COTY Inc. -- CTUP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBODR1DB01- KB0010973

-------------------------------------------------------------------------------------------------------


19 May


FBTPRDHANDB_new with this info? Network information: CFN & IFN gateway & VLAN details  192.168.167.252(CFN)
Hostname: FBTPRDHANDB                                                 *
*         CFN IP: 192.168.167.10                                              *
*         IFN IP: 10.4.27.10

CS3140960                                                                                                
smdbuatut3	smdbuatut3	Retired
SMDBDEVDT1	SMDBDEVDT1	Retired
smdbsbxst1	smdbsbxst1	Retired


DLBPBIDA00	172.16.20.16, 	10.13.1.16




CS3087022
Validate current SRM replication - Louis Dreyfus Company(LDC) before DR internal DR test schedule on 26th May - CSR - CHG0153726
1- Account Name Louis Dreyfus Company(LDC)
2- Production site-Frankfurt 02
3- DR site-Paris 01
4- Production VLANs-CFN VLAN ID-2996/IMZ VLAN -1885
5- DR VLANs -CFN VLAN ID-2996/IMZ VLAN -1885
6- RPO -15 Minutes
7- list of vms that are requested to test


	PHO:cdi2pbldapp11(CFN 10.253.240.101/IMZ 100.126.68.128)
	PBO:cdi2pbldsql21(CFN 10.253.240.71/IMZ 100.126.68.179)
	PSO:cdi2pbldapp33(CFN 10.253.240.94/IMZ 
	PWD:cdi2pbldapp35(CFN 10.253.240.11/IMZ 100.126.68.175)
	PBO:cdi2pbldapp22(CFN 10.253.240.34/IMZ 100.126.68.153)
	PBO:cdi2pbldweb21(CFN 10.253.240.106/IMZ 100.126.68.94)
	PS1:cdi2pbldweb33(CFN 10.253.240.106/IMZ 100.126.68.36)
	AD :cdi2padsapp11(CFN 10.253.240.6/IMZ 100.126.68.6)
	AD :cdi2padsapp12(CFN 10.253.240.9/IMZ 100.126.68.9)



CS3143582 St. Jude Medical -- JU1P2 - MajorMemory Swap CRITICAL: Swap free 49.86% (thresh 50:%)

----------------------------------------------------------------------------------------------------------------------------------

21 May

CHG0153420
CHG0153420	
LIN ENG : Ravi Malik & Sandeep Gaur	
SAP ENG : Sudha Kumari & Anupama Vasantham
Host Name	IFN IP		Asset Purpose

	smdbsbxss0	10.78.20.24	Sandbox
	smifasbxsf1	10.78.20.32	Sandbox
	smposbxsx8	10.78.20.20	Sandbox
	smdbsbxsm1	10.78.20.21	Sandbox
	smgwsbxsq1	10.78.20.31	Sandbox
smbosbxsb1	10.78.20.11	Sandbox
	smgrcsbxsg1	10.78.20.30	Sandbox
	smemsbxsm1	10.78.20.22	Sandbox
	smsmsbxss0	10.78.20.25	Sandbox
	
	
----------------------------------------------
	
	CHG0152529_CHG0152201
22 May

CHG0152529	22-05-2020 06:30:00	22-05-2020 13:00:00
Affected Servers:
==============
Host Name	                IFN IP		        Asset Purpose    
ECTSOLPRD                     10.5.7.13	        Production     - application and sybase ASE database server  independent disk
ECTS4HPRDAP	              10.5.7.12	        Production    -  application server
ECTS4HPRDDB	      10.5.7.11	        Production    -  hana server - hana version 1.00.122.16 (RLES HANA DB - 3.x only ->We will ONLY patch the LATEST SECURITY patches on the SAME LEVEL...)




CHG0152201	22-05-2020 06:30:00	22-05-2020 12:30:00
Host Name	                IFN IP			Asset Purpose
ercnwq01	                        10.5.1.105	        Production
ercerpp1	                        10.5.1.103	        Production
ercsolprd1	                        10.5.1.106	         Production


CS3177947 IAG GBS Limited -- IA1P2 - MajorMemory Swap CRITICAL: Swap free 49.92% (thresh 50:%)


Soure :10.134.15.9 /stapstage/S4D_FioriFrontendServer3.0_ 	BUMSAPS4D01T 	10.134.15.9 	10.156.3.11
to destination (10.134.14.7) /sapstage/S4D_FioriFrontendServer3.0	BUMSAPS4P01P 	10.134.14.7 	10.156.1.7


CS3178367 IAG - British Airways -- IA2P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA2ICCDEV2- KB0010973


CHG0147502	Done	OS SME approves the change to be executed as scheduled.
CHG0152209
CHG0152156
CHG0151488



CS3179042 Dilip Buildcon Limited -- DLBAdding entry in hosts file fo QEC
CS3178979 Dilip Buildcon Limited -- DLBAdding entry in hosts file fo DEC

CS3179013 Dilip Buildcon Limited -- DLBP3 - MinorInodes Utilization /tmp CRITICAL: Free 19664/131072 15.00% (thresh @10.01:15%)

CS3179172 Dilip Buildcon Limited -- DLBAdding entry in hosts file fo QEC


CHG0151970
CHG0152205



CS3179246 Panasonic North America -- PN4P2 - MajorLog PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-05-22-03-09-18 for details.

----------------------------------------------------------------------------------------------------

23 May


A0DIML012XVM013	SAPCRMDNS1	10.70.2.74   no info found with any name or ip
ctuwdprdap03, dlthbehdb	10.143.69.172    dlthbehdb is in decomm list
 
CTUWDPRDAP03 10.12.12.15 	172.22.68.15 whereas when connected with ip it connects to CTUWDPNPAP03 fixed 


CS3187616  CMA CGM -- CMA   Disk Utilization /var CRITICAL: Free 127.02MB/2.47% (thresh @0:5%)  P1


CS3188225  Bumrungrad Hospital Plc -- BUM    Mountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :   P1


note in wich datastore is currently that vm DS1 DS2
then
right click the vm ,
selec : change both compute resource and storage
select compute resource first
select host dal13-pod1-4tb-host30.imzcloud.ibmammsap.local ( under amm_vhana_ca )
select datastore previously noted.
select networks ,   destination should be the same as source.
select vmotion priority  high priority .
finish it . (edited) 
10:10 AM
those are the steps
10:10 AM
source esxi dal13-pod1-4tb-host16.imzcloud.ibmammsap.local


Pepsi    PEPQASEPDB=======================Validated-looks good
Mitsubishi Motors    MM3FIUFP001======================Validated-looks good
Briggs & Stratton Corporation    Bs4pb0077--======================Validated-looks good
St. Jude Medical , USA    Juehdmart03--=========Validated-looks good
Lindt and Spring    Lnasv224br--======================Validated-looks good


10.208.79.59	dal13-pod1-4tb-host16.imzcloud.ibmammsap.local
root XB3NbMdQ


DAL13POOL16DS1	used 6.91   cap 6.98

------------------------------------------------------------------------------------------------------------------

26 May


CS3183896, CS2862504, CS2907554, CS2117119, CS0120618, CS1349186, CS1597453, CS1716019




CS3216806 Tata Steel Limited -- TTAP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 41.57 (thresh: 32)

CS3217031 ZF Friedrichshafen AG -- ZFFP2 - MajorMemory Swap CRITICAL: Swap free 49.99% (thresh 50:%)


/usr/local/bin/dr_enable.py

CS3218111 Panasonic North America -- PN4P2 - MajorLog PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-05-26-06-18-11 for details.PN4USHLEWMP1CSQ-SAP-TRIO-C2	pn4ushlewmp1c pn4us7lewmp1c
CS3218046 Panasonic North America -- PN4P2 - MajorLog PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-05-26-06-11-02 for details.PN4US7LEWMP1SQ-SAP-TRIO-C2	PN4US7LEWMP1
CS3218032 Panasonic North America -- PN4P2 - MajorLog PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-05-26-06-09-26 for details.PN4US7LEWMP1C SQ-SAP-TRIO-C2	PN4US7LEWMP1C
CS3218031 Panasonic North America -- PN4P2 - MajorLog PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-05-26-06-10-39 for details.PN4USHLECCP1C SQ-SAP-TRIO-C2	PN4USHLECCP1C


CS3218775 - Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ARMFKDR305A1- KB0010973
[root@armfkdr305a1 ibmrmalik]$ cat /etc/fstab |grep -i /usr/sap/trans
/dev/popappvg/usrtrans_lv       /usr/sap/trans  ext3    _netdev,defaults       12
10.244.103.22:/usr/sap/trans /usr/sap/trans nfs rw,soft,vers=3,intr 0 0


 CS3219537 IAG GBS Limited -- IA1P2 - MajorMemory Swap CRITICAL: Swap free 49.76% (thresh 50:%)IA1NFSPRDAPP


CS3219795 Bumrungrad Hospital Plc -- BUMP1 - SevereMountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :BUMSAPPOD01TSQ-SAP-TRIO-C1
CS3219669 Bumrungrad Hospital Plc -- BUMP1 - SevereMountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :BUMSAPPOD01TSQ-SAP-TRIO-C1

--------------------------------------------------------------------------------------------------

27 May


CS3227412	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMEDIQUAQU3- KB0010973	SMEDIQUAQU3	SQ-SAP-TRIO-C2
CS3227396	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBTRNTR1- KB0010973	SMDBTRNTR1	SQ-SAP-TRIO-C2
CS3227379	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDIDEVDD1- KB0010973	SMDIDEVDD1	SQ-SAP-TRIO-C2
CS3227370	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMGWDEVDQ1- KB0010973	SMGWDEVDQ1	SQ-SAP-TRIO-C2
CS3227367	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMEMQUAQM3- KB0010973	SMEMQUAQM3	SQ-SAP-TRIO-C2
CS3227365	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMGWDEVDQ1- KB0010973	SMGWDEVDQ1	SQ-SAP-TRIO-C2
CS3227360	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMEMQUAQM3- KB0010973	SMEMQUAQM3	SQ-SAP-TRIO-C2
CS3227353	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMECCDEVDE1- KB0010973	SMECCDEVDE1	SQ-SAP-TRIO-C2
CS3227340	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBUATUU3- KB0010973	SMDBUATUU3	SQ-SAP-TRIO-C2
CS3227321	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDSQUAQO1Q71- KB0010973	SMDSQUAQO1Q71	SQ-SAP-TRIO-C2
CS3227313	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMCRMDEVDR3- KB0010973	SMCRMDEVDR3	SQ-SAP-TRIO-C2
CS3227293	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDSQUAQO1Q71- KB0010973	SMDSQUAQO1Q71	SQ-SAP-TRIO-C2

CS3227274	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBQUAQR3- KB0010973	SMDBQUAQR3	SQ-SAP-TRIO-C2
CS3227261	CMA CGM -- CMA	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMIFADEVDF1- KB0010973	SMIFADEVDF1	SQ-SAP-TRIO-C2




 CS3226511 Panasonic North America -- PN8P2 - MajorCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.26% system=15.50% iowait=0.00% idle=0.00%PN8US7LDBCP3
 
 
cat /proc/sys/net/ipv4/tcp_keepalive_time 
 SAPSSL_CIPHERSUITES=135:PFS:HIGH::EC_P256:EC_HIGH
SAPSSL_CLIENT_CIPHERSUITES=150:PFS:HIGH::EC_P256:EC_HIGH
SAPSSL_CLIENT_SNI_ENABLED=TRUE
 
 
 
 CS3097048
 
 
 CHG0155926
 tbos4prdd1	100.126.48.27
tbos4prdd2	100.126.48.25


CHG0156178
time zone change to WIB
ptpumang	 10.70.31.78	QA
ptpbatur	 10.70.31.75	QA

---------------------------------------------------------------------------------------------------------------

CS3238552 Inter Pipeline Fund -- IPLP2 - MajorMemory Swap CRITICAL: Swap free 49.44% (thresh 50:%)IPLSAS4DD03


CS3237994 Controladora De Negocios -- CNGP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CROSFLSUA01- KB0010973CROSFLSUA01
 
 
CS3011885


CS3239808 Bumrungrad Hospital Plc -- BUMP1 - SevereMountpoint Interface CRITICAL: /Interface_local2 is not mounted :BUMSAPPOP02P


CS3240641 Meggitt PLC -- MGGP2 - MajorMemory Virtual CRITICAL: Free Memory 1.95% (thresh 2:%)MGGGBJQGTSY01SQ-SAP-TRIO-C2
CS3240161 AGEAS -- AGEP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP2SRV0- KB0010973CCCP2SRV0SQ-SAP-TRIO-C1
 CCCP2SRV0
 
 
netsh interface ipv4 show subinterface

C:\Windows\system32>netsh interface ipv4 show subinterface

   MTU  MediaSenseState   Bytes In  Bytes Out  Interface
------  ---------------  ---------  ---------  -------------
4294967295                1          0          0  Loopback Pseudo-Interface 1
  1500                1  3293125523  20582142513  Private
  1500                1  976622342  25231862233  Public

netsh interface ipv4 set subinterface Private mtu=1518 store=persistent
netsh interface ipv4 set subinterface â€œPureVPNâ€ mtu=1498 store=persistent



/dev/temp_vg/backup_lv
 
 
 10.116.145.8	snghana-1024-18.xsportal.local
 root	
5WRuIG%jHd1XPy@

IPMI A4wGteRjdm


CS3242348 Bumrungrad Hospital Plc -- BUMP1 - SevereMountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :BUMSAPPOQ01TSQ-SAP-TRIO-C1


-----------------------------------------------------------------------------------------

29 May


CS3249061 Home Control Singapore -- HCSP4 - MinimalPlease unmount and release this temporary FS /temp_sar
Please unmount and release  this temporary FS  /temp_sar

/dev/mapper/temp_VG-temp_sar_lv       39G   48M   37G   1% /temp_sar
server details:
ECD CI	eccci0dev	10.198.2.10

[root@eccci0dev temp_sar]$ df -hT /temp_sar
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/temp_VG-temp_sar_lv
                     ext4   39G   48M   37G   1% /temp_sar
                     
/dev/temp_VG/temp_sar_lv                     



EGRS4HPRDAPP 	10.135.5.13 	10.20.0.13

journalctl -xb  |grep -i error
vgchange -ay rootvg
lvsscan
[root@sapapp19 ~]$ tune2fs -l /dev/rootvg/rootlv |grep state
Filesystem state:         clean
check each fs  like this
if you see clean with error  run fsck
e2fsck -f -y and path rite
or
fsck.xfs /dev/roovg/lvname

comment a section put /* and */


CS3249396 AGEAS -- AGEP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVVD1SRV0- KB0010973

CS3249819 CMA CGM -- CMAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMECCQUAQE1- KB0010973
CS3249816 CMA CGM -- CMAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMSLTQUAQK1- KB0010973
CS3249815 CMA CGM -- CMAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SMDBSBXSM1- KB0010973
CS3249876 CMA CGM -- CMAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MMGRAS- KB0010973

CS3250174 Concessionaria Aeroporto Rio de Jan -- CONP2 - MajorMemory Swap CRITICAL: Swap free 49.95% (thresh 50:%)


CS3250399 Meggitt PLC -- MGGP2 - MajorMemory Virtual CRITICAL: Free Memory 1.51% (thresh 2:%)


CS3239716
As of now the interfaces path is :
/interfaces/in/1022/1022actr
/interfaces/in/1078/1078actr 
/interfaces/in/1083/1083actr 
/interfaces/in/1081/1081actr 
/interfaces/in/1080/1080act 

Pls change it to :

/interfaces/in/1022
/interfaces/in/1078
/interfaces/in/1083
/interfaces/in/1081
/interfaces/in/1080

Note  : pls do it on priority , required for month end processes


CS3250506 - P3 ZF Friedrichshafen AG -- ZFF  System NTP Drift CRITICAL: ERROR - chronyc and ntpdate not installed or /etc/ntp.conf does not exist

CS3251031 Meggitt PLC -- MGGP2 - MajorMemory Virtual CRITICAL: Free Memory 1.99% (thresh 2:%)MGGGBJDGTSY02SQ-SAP-TRIO-C2


CS3251051
filesystem  /mxm-server12 currently not mounted on XEP
filesystem  /mxm-server12 was mounted to XEP 

//10.201.0.30/Data/MFG/PrdOrd_Data /mxm-server12

but currently it is not mounted. Can you please get this mounted.
XEP host name - MGGGBJPECCX07; IP Address - 10.133.18.24 / 10.5.255.24


CS3251818
tslgldev   10.207.62.28   10.170.62.100
Please add 16 GB of memory on Green light Dev server(IP : 10.170.62.100 ) as it is having memory bottleneck.

CS3251907 Egyptian Refining Company -- EGRP2 - MajorDetails for OS patching change -> for some servers backout plan was appliedEGRS4HPRDAPP

---------------------------------------------------------------------------------------------------------------------

30 May


CS3260113	COTY Inc. -- CTU	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBODR0AP01- KB0010973
CS3260217	COTY Inc. -- CTU	P2 - Major	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBODR0AP02- KB0010973


-------------------------------------------------------------------------------------------

2 June

HC1-DAL13-AUTOMATION-PROD- Apply Latest Q220 Patches on <<Linux>> Servers
CHG0153881	Perform the patching automation via the following link: https://sapops.containers.ciocloudservices.ibm.com

SJP	hc1hosmjavap	10.211.80.12	Production - App+DB
[root@HC1HOSMJAVAP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux HC1HOSMJAVAP 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun  2 12:44:50 -03 2020
OK: No read-only file systems found
                     nfs    3.6T  2.9T  514G  86% /sds
dal13ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.142.203,clientaddr=10.211.80.12 0 0

[root@HC1HOSMJAVAP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux HC1HOSMJAVAP 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun  2 23:35:54 -03 2020
OK: No read-only file systems found
                     nfs    3.6T  2.9T  513G  86% /sds
dal13ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.142.203,clientaddr=10.211.80.12 0 0



SMP	hc1hosmabapp	10.211.80.11	Production - App+DB
[root@HC1HOSMABAPP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux HC1HOSMABAPP 2.6.32-754.27.1.el6.x86_64 #1 SMP Wed Jan 8 05:56:42 EST 2020 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun  2 12:44:50 -03 2020
OK: No read-only file systems found
                     nfs    3.6T  2.9T  514G  86% /sds
dal13ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.142.203,clientaddr=10.211.80.11 0 0

[root@HC1HOSMABAPP ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux HC1HOSMABAPP 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Tue Jun  2 23:35:54 -03 2020
OK: No read-only file systems found
                     nfs    3.6T  2.9T  513G  86% /sds
dal13ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.142.203,clientaddr=10.211.80.11 0 0

prechecks  CS3299004

patching with reboot  CHG0157204
Update from CTask: CTASK0217865 06-02-2020 22:23:05 - IBM Ozone (Work notes)
Work Item began at Wed Jun 3 02:01:22 2020. Work was completed at Wed Jun 3 02:23:05 2020. General status for Install Patches w/ Reboot is Success.

All work was successful.

Successful CIs: HC1HOSMJAVAP, HC1HOSMABAPP





CS3298638


CS3299141



sources :-TSCMLDEV	
Target  grcdevnew



pn4us7lewmp1 : 10.142.41.19/26  Network:   10.142.41.0/26  HostMin:   10.142.41.1	eth1	
wdc04ammtsm002: 10.148.74.184/26  Network:   10.148.74.128/26  HostMin:   10.148.74.129

In pn4us7lewmp1 - eth1 , 10.148.74.128/26 via 10.142.41.1
In wdc04ammtsm002 - bondo , 10.142.41.0/26 via 10.148.74.129



route add -net 10.148.74.184/26 gw 10.148.74.128/26 netmask 255.255.255.192 dev eth1 

EG
route add -net 192.168.3.0 gw 192.168.1.1 netmask 255.255.255.0 dev eth0 
--------------------------------------------------------------------------------------------------------

4 June


[root@PBBs4hpap00 ibmrmalik]$ cat /etc/fstab |grep -i /usr/CIMB02
172.16.0.30:/var/nfs/cimbbiz     /usr/CIMB02   nfs    vers=3  0      0

CS3314466

----------------------------------------------------------------------------------
5th June

CS3319598
Crontab job  and NFS mounting verification	PBBS4HPAP00

We got issue when transferred file from /usr/CIMB02 to nfs mounting of /usr/CIMB.

Please assist us to  verify as following

1. verify whether nfs mounting of /usr/CIMB already set up properly  :
#df -h /usr/CIMB
if not configured properly  , please execute following command under root
#mount 172.16.0.30:/var/nfs/cimbbiz  /usr/CIMB

2. verify whether crontab job of fileperm.sh already configured under s4padm user:
s4padm>crontab -l
if not please configure crontab under s4padm as below :
*/5 * * * *  /home/s4padm/fileperm.sh



[root@PBBs4hpap00 ibmrmalik]$ showmount -e 172.16.0.30
Export list for 172.16.0.30:
/var/nfs/cimbbizdev 172.25.1.16,10.0.19.61,192.168.0.104
/var/nfs/cimbbiz    172.25.1.16,10.0.19.61,192.168.0.104,192.168.0.108,192.168.0.5
/var/nfs/general    10.0.19.61,192.168.0.5


in the /etc/exports file on the NFS server 172.16.0.30 at the cust end, ask them to edit the ip 172.25.1.16 with 10.6.7.16 or alternatively, allow all by removing ips and putting a *



CS3326400	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-06-04-23-48-55 for details.	SQ-SAP-TRIO-C2
CS3326137	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-06-04-23-36-36 for details.	SQ-SAP-TRIO-C2


CS3327508  Panasonic North America -- PN8   System Read Only File Systems /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh: fork: retry: No child processes   P3


CS3327221	Delta Airlines -- DAL	P2 - Major	Ping Availability CRITICAL - 10.4.5.185: rta nan, lost 100%	SQ-SAP-TRIO-C2
CS3326907	Panasonic North America -- PN4	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 60.42 (thresh: 48)	SQ-SAP-TRIO-C2
CS3326850	AGEAS -- AGE	P2 - Major	Memory Swap CRITICAL: Swap free 33.81% (thresh 50:%)	SQ-SAP-TRIO-C1


10.143.69.186	delta-dal09-phana-1024-01.imzcloud.ibmammsap.local




top - 14:05:58 up 30 days, 13:33,  5 users,  load average: 1.79, 2.11, 1.82
Tasks: 450 total,   1 running, 449 sleeping,   0 stopped,   0 zombie
%Cpu(s):  3.7 us,  1.7 sy,  0.0 ni, 94.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  25176908+total, 24993168+used,  1837400 free,     6556 buffers
KiB Swap:  2097148 total,  1894720 used,   202428 free. 28923648 cached Mem

  PID USER      PR  NI    VIRT    RES    SHR S   %CPU  %MEM     TIME+   SWAP COMMAND
19847 edmadm    20   0  0.110t 0.109t 0.014t S  5.941 46.29   4526:21  85892 hdbindexserver
 3393 root      20   0  291336    616    140 S  0.000 0.000   0:00.00  50844 salt-minion
 2705 root      20   0  195996    752    344 S  0.000 0.000   0:00.43  46812 salt-minion
 2932 root      20   0 1189628  91340   8936 S  0.000 0.036  31:53.71  26748 ds_agent


CS3326850 P2 - MajorAGEAS -- AGEMemory Swap CRITICAL: Swap free 33.81% (thresh 50:%)
CS3327691 P2 - MajorLSPI -- LSPDrive-Space F critical(OK: Drive F: has 6.308GB of 63.998GB)
CS3328134 P2 - MajorAGEAS -- AGENagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP3SRV0- KB0010973
CS3328135 P2 - MajorAGEAS -- AGENagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP3SRV0-DR- KB0010973


--------------------------------------------------------------------------------------------------------


6 June


CHG0157263	06-06-2020 12:00:00	06-06-2020 20:00:00
update OS from SLES 12 SP2 to SP4 on below hosts

AGESVBD1HSRV1 	10.6.1.184 	10.92.99.192		10.116.205.226	sng01-pod2-4tb-host02.imzcloud.ibmammsap.local    PZm2zc%1g6PPlQ@  root
[root@agesvbd1hsrv1 ibmrmalik]$ SUSEConnect -s
[{"identifier":"SLES_SAP","version":"12.2","arch":"x86_64","status":"Registered"}]
[root@agesvbd1hsrv1 tmp]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux agesvbd1hsrv1 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun  6 09:41:07 +08 2020
DEFAULT_TIMEZONE="US/Eastern"
TIMEZONE="Asia/Singapore"
OK

[root@agesvbd1hsrv1 tmp]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds; df -hT |grep -i nfs
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux agesvbd1hsrv1 4.12.14-95.51-default #1 SMP Fri Apr 17 08:14:12 UTC 2020 (c6bab98) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun  6 16:07:43 +08 2020
      Local time: Sat 2020-06-06 16:07:43 +08
  Universal time: Sat 2020-06-06 08:07:43 UTC
        RTC time: Sat 2020-06-06 08:07:43
       Time zone: Asia/Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
sng01ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  3.0T  3.3T  47% /sds


AGESVCDMHSRV1 	10.6.1.180 	10.92.99.187		10.116.205.226	sng01-pod2-4tb-host02.imzcloud.ibmammsap.local
[root@agesvcdmhsrv1 ibmrmalik]$ SUSEConnect -s
[{"identifier":"SLES_SAP","version":"12.2","arch":"x86_64","status":"Registered"}]
[root@agesvcdmhsrv1 tmp]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux agesvcdmhsrv1 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun  6 09:41:07 +08 2020
TIMEZONE="Asia/Singapore"
DEFAULT_TIMEZONE="US/Eastern"
OK

[root@agesvcdmhsrv1 ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh;df -hT |grep -i nfs
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux agesvcdmhsrv1 4.12.14-95.51-default #1 SMP Fri Apr 17 08:14:12 UTC 2020 (c6bab98) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun  6 16:18:38 +08 2020
TIMEZONE="Asia/Singapore"
DEFAULT_TIMEZONE="US/Eastern"
OK
sng01ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  3.0T  3.3T  47% /sds

AGESVEDMHSRV1 	10.6.1.179 	10.92.99.176		10.116.205.226	sng01-pod2-4tb-host02.imzcloud.ibmammsap.local
[root@agesvedmhsrv1 ibmrmalik]$ SUSEConnect -s
[{"identifier":"SLES_SAP","version":"12.2","arch":"x86_64","status":"Registered"}]
[root@agesvedmhsrv1 tmp]$ cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux agesvedmhsrv1 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun  6 09:41:07 +08 2020
TIMEZONE="Asia/Singapore"
DEFAULT_TIMEZONE="US/Eastern"
OK
sng01ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  3.0T  3.3T  47% /sds

[root@agesvedmhsrv1 tmp]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds; df -hT |grep -i nfs
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux agesvedmhsrv1 4.12.14-95.51-default #1 SMP Fri Apr 17 08:14:12 UTC 2020 (c6bab98) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun  6 15:59:44 +08 2020
      Local time: Sat 2020-06-06 15:59:44 +08
  Universal time: Sat 2020-06-06 07:59:44 UTC
        RTC time: Sat 2020-06-06 07:59:44
       Time zone: Asia/Singapore (+08, +0800)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
[root@agesvedmhsrv1 tmp]$ df -hT |grep -i nfs
sng01ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  3.0T  3.3T  47% /sds


Post update, the ssh login is slow and switching the id is also slow.
To fix it
After applying patch process for upgrading from SuSE 12 SP2 to SP4 the authentication process via SSH takes so long.
-This issue we already fix executing the follow commands:
service sssd stop;rm -rf /var/lib/sss/db/* ;rm -rf /etc/krb5.keytab ; kdestroy;chef-client; rm -rf /tmp/krb*


CHG0157600	CTASK0219008	
snapshot request at 830 AM today
Please take VM snapshot for below server
BUMSAPPOD01T 	10.134.15.15 	10.156.3.16	SNG



CS3341385   Egyptian Refining Company -- EGR   Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)   P2


 
CS3343035 P1 - SevereBumrungrad Hospital Plc -- BUMMountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :


---------------------------------------------------------------------------

11 June


[root@PBBs4hpap00 ibmrmalik]$ cat /etc/fstab |grep -i nfs
172.25.1.12:/usr/sap/trans /usr/sap/trans    nfs   defaults        1   2
#r3devsap:/usr/IDOC     /usr/IDOC nfs   vers=3  0       0
#r3devsap:/usr/CIMB     /usr/CIMB nfs   vers=3  0       0
#r3devsap:/DEVSAP04/TEMP    /DEVSAP04/TEMP nfs   ver3=3  0      0
#172.25.1.12:/usr/sap/trans /usr/sap/trans nfs   defaults        1   2
172.16.0.30:/var/nfs/cimbbiz     /usr/CIMB02   nfs    vers=3  0      0
172.16.0.30:/var/nfs/cimbbiz     /usr/CIMB  nfs   defaults        1   2
crmdb:/usr/IDOC /usr/IDOC nfs    vers=3 0 0


CS3399941 cronjob for restart of goferd service to clear the memory on Applications hosts

DEV - TNGDEVEAPP40	10.134.2.14
QAS - TNGQASEAPP20	10.134.2.13
PRD - TNGPRODEAPP00	10.134.2.11
PRD - TNGPRODEAPP01	10.134.2.12
pls restart goferd service today and set cronjob to run daily 04:30 AM System Time


*/30   *   *   *  *    /path/to/script
 0,30 *   *   *  *  /path/to/script
 
# * * * * * <command to execute>
 
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ minute (0 - 59)
# â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hour (0 - 23)
# â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of the month (1 - 31)
# â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ month (1 - 12)
# â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of the week (0 - 6) (Sunday to Saturday;
# â”‚ â”‚ â”‚ â”‚ â”‚                                   7 is also Sunday on some systems)
# â”‚ â”‚ â”‚ â”‚ â”‚
# â”‚ â”‚ â”‚ â”‚ â”‚
# 30 4 * * * /etc/init.d/goferd restart

Use crontab -l to list the crontab for current user.

Use crontab -e to edit (VI) the crontab for current user.




CS3399852	Egyptian Cement -- ECT	ECT	ECT IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Memory Swap CRITICAL: Swap free 49.71% (thresh 50:%) 

CS3400314 P2 - MajorTata Steel Limited -- TTALoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 66.89 (thresh: 40)



CS3400404	IAG GBS Limited -- IA1	IA1	IA1 SAPHEC-IC4SAP-SL SAP LOB	Incident	P1 - Severe	New		SAP-HEC-SWIVEL----- Not able to connect SFTP productio[0383969 /2020]

Incident#: Ensure the incident is elevated to P1 Case
Client Name:IAG GBS Limited -- IA1
CDIR:	IA1 SAPHEC-IC4SAP-SL SAP LOB
Issue Description: Not able to connect SFTP productio[0383969 	/2020]
Data Center:London 02
Asset Name:IaaS Enhanced IA1HCCPRDWD
Reported/Validated by: IBM Engineer, Monitoring, Client	Ravi Malik, recd cust ticket
Note: All monitoring alerts must be validated before TRM is engaged. Server is not accessible via putty but it is accessible via console, CPU and memory seems high

What is the impact to client business?:
Request for Engineers:




PRB0052745/RCA0002646
 	IA1HCCPRDWD 	10.133.15.28 	66.248.244.28 	
 	
[root@IA1HCCPRDWD ibmrmalik]# netstat -antp | grep sshd | grep -i ESTABLISHED | wc -l
1029
[root@IA1HCCPRDWD ibmrmalik]# date
Thu Jun 11 09:53:34 CEST 2020

-------------------------------------------------------------------------------------------------------------------

12 June

CS3407773	ZF Friedrichshafen AG -- ZFF	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 24.08 (thresh: 16)	SQ-SAP-TRIO-C1


CS3407061	ZF Friedrichshafen AG -- ZFF	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 17.26 (thresh: 16)	SQ-SAP-TRIO-C1



CS3410929 P1 - SevereBumrungrad Hospital Plc -- BUMMountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :


CHG0158081	12-06-2020 12:00:00

AFRS4HQADB
AFRS4HPRDDB
ia2bpcqasdb (shutoff)



 CS3411360 P1 - SevereBombardier Recreational Products Inc -- BR3Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)
 
 
 
 CS3411506 IAG - British Airways -- IA2P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA2ICCPRD- KB0010973
CS3411186 Apple Leisure Group -- AV1P2 - MajorPing Availability CRITICAL - 10.68.213.11: Host unreachable @ 10.143.69.196. rta nan, lost 100%
 Dal09	A0ETUS014XVM006
 
 
 CS3411974 P2 - MajorBombardier Recreational Products Inc -- BR3Log PaceMaker-log Found 23 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-06-12-02-32-38 for details.
 
 
 
 CHG0157234	Computer Systems Integration Ltd -- CSY	06-17-2020 18:00:00
CHG0157296	Dilip Buildcon Limited -- DLB	06-19-2020 08:00:00

------------------------------------------------------------------------------------------------------

13 June


DLBDBWAP01:/usr/sap/trans /usr/sap/trans        nfs    rw,hard,intr,rsize=32768,wsize=32768    0  0


CS3421359 Tata Steel Limited -- TTAP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 139.80 (thresh: 32)


CS3417543
We are facing issue with minting service in HSE system to fix this issue we need to correct the sequence of the below entries as given below in /etc/hosts file of host dlthsesap.
 
Current Sequence of Entries -
 
147.118.249.50#servicemii-dvl.delta.com servicemiidvl.delta.com
147.118.249.49#servicemii-int.delta.com servicemiiint.delta.com
147.118.248.234#servicemii-int.delta.com servicemiiint.delta.com
10.185.88.71#servicemii-lab.delta.com servicemiilab.delta.com
147.118.31.20#servicemii.delta.com
147.118.31.16#servicemii.delta.com
 
Corrected Sequence of Entries -
 
147.118.249.50#servicemii-dvl.delta.com servicemiidvl.delta.com
147.118.248.234#servicemii-int.delta.com servicemiiint.delta.com
147.118.249.49#servicemii-int.delta.com servicemiiint.delta.com
10.185.88.71#servicemii-lab.delta.com servicemiilab.delta.com
147.118.31.20#servicemii.delta.com
147.118.31.16#servicemii.delta.com
 
Regards,
Sachin Sable




CS3425714 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var CRITICAL: Free 0.00MB/0.00% (thresh @0:5%)

-------------------------------------------------------------------------------------------------------------

14 June

CHG0156217	Tata Steel Limited (TTA) 06/14/2020  6:30 AM  9:30 AM

[root@sapcrmdi sds]$ df -hT .
Filesystem                                  Type  Size  Used Avail Use% Mounted on
che01ammsol01.imzcloud.ibmammsap.local:/sds nfs4  3.6T  3.0T  494G  86% /sds


[root@sapcrmdi sds]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux sapcrmdi 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun 13 18:32:19 IST 2020
CRITICAL:  /home/dipadm/.gvfs /oracle/DIP/.gvfs filesystems are read-only
che01ammsol01.imzcloud.ibmammsap.local:/sds   nfs4      3.6T  3.0T  494G  86% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3230,timeout=600,minproto=5,maxproto=5,direct 0 0
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.207.61.83,local_lock=none,addr=146.89.142.94 0 0

[root@sapcrmdi ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux sapcrmdi 4.4.121-92.135-default #1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528) x86_64 x86_64 x86_64 GNU/Linux
Sun Jun 14 07:14:20 IST 2020
OK: No read-only file systems found
che01ammsol01.imzcloud.ibmammsap.local:/sds   nfs4      3.6T  3.0T  494G  86% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3124,timeout=600,minproto=5,maxproto=5,direct 0 0
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.207.61.83,local_lock=none,addr=146.89.142.94 0 0
----------------------------------------

[root@tscmlprd tmp]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tscmlprd 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun 13 18:32:19 IST 2020
OK: No read-only file systems found
che01ammsol01.imzcloud.ibmammsap.local:/sds   nfs4      3.6T  3.0T  494G  86% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3016,timeout=600,minproto=5,maxproto=5,direct 0 0
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.207.61.36,local_lock=none,addr=146.89.142.94 0 0

[root@tscmlprd tmp]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tscmlprd 4.4.121-92.135-default #1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun 13 22:29:11 EDT 2020
OK: No read-only file systems found
che01ammsol01.imzcloud.ibmammsap.local:/sds   nfs4      3.6T  3.0T  494G  86% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3390,timeout=600,minproto=5,maxproto=5,direct 0 0
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.207.61.36,local_lock=none,addr=146.89.142.94 0 0

----------------------------------------------

[root@tsgpprd tmp]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tsgpprd 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Jun 13 18:32:19 IST 2020
OK: No read-only file systems found
che01ammsol01.imzcloud.ibmammsap.local:/sds   nfs4      3.6T  3.0T  494G  86% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3489,timeout=600,minproto=5,maxproto=5,direct 0 0
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.207.61.41,local_lock=none,addr=146.89.142.94 0 0
You have mail in /var/mail/root

[root@tsgpprd ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tsgpprd 4.4.121-92.135-default #1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528) x86_64 x86_64 x86_64 GNU/Linux
Sun Jun 14 07:14:23 IST 2020
OK: No read-only file systems found
che01ammsol01.imzcloud.ibmammsap.local:/sds   nfs4      3.6T  3.0T  494G  86% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3373,timeout=600,minproto=5,maxproto=5,direct 0 0
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.207.61.41,local_lock=none,addr=146.89.142.94 0 0

--------------------------------------------------------------------------------

19 June


[root@PBBs4hpap00 ibmrmalik]$ showmount -e 172.16.0.30
Export list for 172.16.0.30:
/var/nfs/cimbbizdev 172.25.1.16,10.0.19.61,192.168.0.104
/var/nfs/cimbbiz    172.25.1.16,10.0.19.61,192.168.0.104,192.168.0.108,192.168.0.5
/var/nfs/general    10.0.19.61,192.168.0.5

CS3319598
Crontab job  and NFS mounting verification	PBBS4HPAP00

We got issue when transferred file from /usr/CIMB02 to nfs mounting of /usr/CIMB.

Please assist us to  verify as following

1. verify whether nfs mounting of /usr/CIMB already set up properly  :
#df -h /usr/CIMB
if not configured properly  , please execute following command under root
#mount 172.16.0.30:/var/nfs/cimbbiz  /usr/CIMB

2. verify whether crontab job of fileperm.sh already configured under s4padm user:
s4padm>crontab -l
if not please configure crontab under s4padm as below :
*/5 * * * *  /home/s4padm/fileperm.sh


mount -t nfs 172.16.0.30:/var/nfs/cimbbiz 

mount -t nfs 172.16.0.30:/var/nfs/cimbbiz /cimbbiz



CS3488418 St. Jude Medical -- JU1P2 - MajorMemory Swap CRITICAL: Swap free 49.84% (thresh 50:%)



CS3488556 Tecnologia De Materiales S.A. -- TDMP2 - MajorMemory Swap CRITICAL: Swap free 49.98% (thresh 50:%)


CS3488999 Tata Steel Limited -- TTAP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 68.02 (thresh: 50)


 IA1OTASPRDAPP.iag.amm.ibmcloud.com
 IA1OTASDEVDB.iag.amm.ibmcloud.com
 IA1OTASDEVAPP.iag.amm.ibmcloud.com
 IA1HCCPRDWD.iag.amm.ibmcloud.com
 IA1FTSPRDAPP.iag.amm.ibmcloud.com
 IA1NFSPRDAPP.iag.amm.ibmcloud.com
 IA1HCIPRDAPP.iag.amm.ibmcloud.com
 IA1HCIDEVAPP.iag.amm.ibmcloud.com
 
 
 
 
 [root@IA1HCCPRDWD log]# netstat -antp | grep sshd | grep -i ESTABLISHED | wc -l
98
[root@IA1HCCPRDWD log]# ps -eo user,pid,etime,cmd --sort=start_time|grep PIUSER|grep sshd|wc -l
192

-----------------------------------------------------------------------------------------------------------------------

20 June

 CS3496503  Meggitt PLC -- MGG   pingcheck pingcheck CRITICAL: Unable to ping MGGGBJQGTSX01,.   P1
 
 
 CS3493792  MSC Industrial Supply Co. -- MS3   please create snapshots of the following VMs  SQ-SAP-TRIO-C1
 
 CS3496561	IAG GBS Limited -- IA1	P2 - Major	Memory Swap CRITICAL: Swap free 49.95% (thresh 50:%)	SQ-SAP-TRIO-C1
CS3496554	Delta Airlines -- DAL	P3 - Minor	System NTP Drift CRITICAL: Could not determine offset to check NTPDRIFT	SQ-SAP-TRIO-C2
 
CS3497282  Manchester Airport Group -- MNG    Memory Virtual CRITICAL: Free Memory 1.97% (thresh 2:%)  P2


CS3497568	ZF Friedrichshafen AG -- ZFF	P3 - Minor	Disk Utilization /usr CRITICAL: Free 1883.33MB/19.99% (thresh @10.01:20%)	SQ-SAP-TRIO-C1



CS3497940 ZF Friedrichshafen AG -- ZFFP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 44.77 (thresh: 16)
CS3498376 ZF Friedrichshafen AG -- ZFFP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 18.35 (thresh: 16)

------------------------------------------------------------------------------------------------

24 June



mtsprdbods01	server not found mostly decommissioned
mtsprdbodsapp01	server not found mostly decommissioned 	                                                                                                                                                                                                                                                                                                                                                                                                          


CROSFLIEM01 	10.68.210.29 	10.68.200.29	Fixed
CONSPPHANAQ 	10.16.1.25 	10.80.1.25	Server in disconnected state on SL portal, mostly decomm or not needed chk with DPE
mtsiaasdev1   Pending Deactivation
DLTWTS01 	10.4.5.153 	10.250.17.153	server not allowing to login, started besclient service remotely chk if it helped, logs suggest the config needs to be corrected with correct relay server. Can do without getting access. 


CS3452485
 why servers below does not report to BFI?
I have attached troubleshooting guide
SAPCRMDNS1 	10.70.2.74 	A0DIML012XVM013
SAPCRMDNS2 	10.70.1.75 A0DIML012XVM014
Thank you in advance




CS3534316
Please add 100 GB each on below mentioned FS on server DLTQBGGAT

/dev/mapper/qbgdatavg-sybase_QBG_sapdata1_lv
                      492G  451G   17G  97% /sybase/QBG/sapdata1
/dev/mapper/qbgdatavg-sybase_QBG_sapdata2_lv
                      492G  451G   17G  97% /sybase/QBG/sapdata2
/dev/mapper/qbgdatavg-sybase_QBG_sapdata3_lv
                      492G  451G   17G  97% /sybase/QBG/sapdata3
/dev/mapper/qbgdatavg-sybase_QBG_sapdata4_lv
                      492G  451G   17G  97% /sybase/QBG/sapdata4
approval has been added for the same



PN8US7LECCP4 	10.12.255.38 	10.129.32.50



CS3533791	St. Jude Medical , USA -- JUE	JUE	JUE St. Jude Medical SAP HEC-AMM	Incident	P2 - Major	New		LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 19.13 (thresh: 16) 

CS3533765	Bombardier Recreational Products Inc -- BR3	BR3	BR3 IC4SAP-SL SAP LOB	Incident	P2 - Major	New		Log PaceMaker-log Found 5 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-06-23-20-07-59 for details


 CS3545697 Bumrungrad Hospital Plc -- BUMP3 - MinorPlease add space to filesystem mentioned(empty


 CS3443230, this was assign to sandeep gaur, and he tried to fix this  linux server, crosfliem01- but he stated that there is issue with synchornization. Do you know how to solve this? could you please check rest of the servers crosflavs01	10.68.210.26
crosflsua01	10.68.200.28
crosfliem02	10.68.200.30


enable the NFS mapped /Bank in DEC (DLBDECAP01) and QEC (DLBQECAP01)

-------------------------------------------------------------------------------------------------------------------

26 June

 CS3443230  this was assign to sandeep gaur, and he tried to fix this  linux server, crosfliem01- but he stated that there is issue with synchornization. Do you know how to solve this? could you please check rest of the servers 
 
 crosfliem01	should be gud now
 crosflavs01	10.68.210.26	A0DTUS012XVM019	server out of domain cant login with imz and localadmin does not work neither is the pw in the PIM tool 
crosflsua01	10.68.200.28	A0DTUS012XVM021	C:\Program Files\BigFix Enterprise\BES Client\__BESData\__Global\Logs	_BESData\__Global\Logs missing tried reinstall also need chef team to check and help reinstall besclient again
crosfliem02	10.68.200.30	server not found with name or ip





Source - 10.70.111.37 (cfn p) Windows E:\OOM\JPP	SPSVOPIVAPP01 	10.6.3.37 	10.70.111.37
need to mount on target as /wts_oom_JPP
Target - 10.6.3.13 (imz ip)/ 10.70.111.13 (cfn ip)

//Spsvopivapp01/oom/JPP /wts_oom_JPP cifs username=msg_jp1,passwd=Brguest#123,_netdev uid=20000,gid=3050 0 0
JPP (file://Spsvopivapp01/oom/JPP)

uid=20000(jq1adm) gid=3050(sapsys)


username=SAPServicePOD
password=Sug@rM!nt4

username=SAPServicePOD,passwd=Sug@rM!nt4

//10.102.96.38/Interface /Interface cifs username=SAPServicePOD,passwd=Sug@rM!nt4,uid=20100,gid=3050 0 0



CS3559123 Delta Airlines -- DALP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DLTWTS01- KB0010973



 CS3559293 Bumrungrad Hospital Plc -- BUMP1 - SevereMountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :BUMSAPPOD01T




 CS3559567 Delta Airlines -- DALP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on DLTWTS01- KB0010973DLTWTS01SQ-SAP-TRIO-C2
 
 
 ----------------------------------------------------------------------------------------------------------------
 
 
 30 June
 
 
 CS3593191 P2 - MajorDilip Buildcon Limited -- DLBMemory Swap CRITICAL: Swap free 49.99% (thresh 50:%)
 
 
 CS3595317 P3 - MinorIAG - British Airways -- IA2System MegaRAID Drive Media Errors CRITICAL: Media Error Count = 2SQ-SAP-TRIO-C1
 10.85.139.141	fra02-p2-hana-2048-01.xsportal.local    root/Wemcl2HT  IPMI UkJ7qqctyh
 
CS3596381 P3 - MinorPanasonic North America -- PN8Disk Utilization /usr/sap/hostctrl CRITICAL: Free 180.84MB/19.90% (thresh @10.01:20%)
----------------------------------------------------------------------------------------------------------------

CS3602058 P2 - MajorCertified IT Consultants - TMG -- CI3Memory Swap CRITICAL: Swap free 49.98% (thresh 50:%)

------------------------------------------------------------------------------------------------------

CS3615344 P1 - SevereTata Steel Limited -- TTAService po-pingcheck CRITICAL: Packet RTA=58.177ms, loss=20.00% (thresh 1000,5)
CS3615334 P1 - SevereTata Steel Limited -- TTAService po-pingcheck CRITICAL: Packet RTA=63.028ms, loss=40.00% (thresh 1000,5)

 CS3615370 P1 - SevereTata Steel Limited -- TTAService po-pingcheck CRITICAL: Packet RTA=54.217ms, loss=40.00% (thresh 1000,5)SQ-SAP-TRIO-C1


CHG0160063
CHG0160270


CS3626430   IAG - British Airways -- IA2    Memory Swap CRITICAL: Swap free 49.79% (thresh 50:%)   P2


CS3628210	Bombardier Recreational Products Inc -- BR3	P2 - Major	Memory Swap CRITICAL: Swap free 49.98% (thresh 50:%)	SQ-SAP-TRIO-C1

CS3586625
bumsaph4p01p	10.134.14.15
bumsaph4p02p	10.134.14.16


CS3638293   Fitbit Inc -- FBT   Zabbix_agent_on_fbtprdfirwd.imzcloud.ibmammsap.local_is_unavailable 



CS3640617	Computer Systems Integration Ltd -- CSY	P2 - Major	Memory Swap CRITICAL: Swap free 48.90% (thresh 50:%)



10.162.24.194	tata-che01-pod1-phana-6114-1.imzcloud.ibmammsap.local

PROD DB host TSLEECPRDDB is not reachable

Support Cases chevron_right 00203743    SL ticket number:CS1877034
IPMI  SCb4wcbNzU
14:40:02    257813312 6083746720     95.93    309264 277128212 5762054444     90.86 5797163104 244505972       520
17:00:04    6335529964   6030068      0.10     48612   2369332    957980      0.02   2641480   1063860      2256

ds agent log
2020-07-04 14:49:47.000000: [Info/5] | SQLITE_INFO[283]: recovered 736 frames from WAL file /var/opt/ds_agent/dsa_core/ds_agent.db-wal | /build/workspace/Sustain/11.0/Build_DSA_11.0_SUSE12x64/src/dsa/core/db/SqliteDb.cpp:582:dsa_sqlite3_logerror | 2EC77:7F00BE7AA700:CScriptThread

[root@tsleecprddb diag]$ cat ds_am.log |grep -i "2020-07-04 14"
2020-07-04 14:49:23.467125: [ds_am-M/2] | [DAEMON] signal:15 doing 26E1/26E1/2E976 time:1 is_running:0 | main.cpp:127:pass_term_signal | 26E1:26E1:15::log
2020-07-04 14:49:23.468472: [ds_am/2] | event is received. exit application | main.cpp:1413:main_runloop | 2701:2701:895::
2020-07-04 14:49:23.468824: [ds_am/4] | rtscan_config_fn() stopping  | dsa_rtscan_hook.c:858:rtscan_config_fn | 2701:27A7:896::
2020-07-04 14:49:23.474272: [ds_am-M/4] | [DAEMON] Waiting for child process interrupted - Try again | main.cpp:881:do_daemon | 26E1:26E1:16::log
2020-07-04 14:49:23.474446: [ds_am/4] | rtscan_hook_fn() stopped  | dsa_rtscan_hook.c:763:rtscan_hook_fn | 2701:2DF8:897::
2020-07-04 14:49:45.260028: [ds_am/4] | rtscan_config_fn() stopped  | dsa_rtscan_hook.c:861:rtscan_config_fn | 2701:27A7:898::
2020-07-04 14:49:45.260188: [ds_am/4] | sapscan module is stopped. | sapscan_module.c:1750:sapscan_stop | 2701:2701:899::
2020-07-04 14:49:46.305951: [ds_am/4] | sapscan module is released. | sapscan_module.c:1719:sapscan_destroy | 2701:2701:900::
2020-07-04 14:49:54.705740: [ds_am-M/2] | [DAEMON] do_daemon is doing ../diag/ds_am.log | main.cpp:767:do_daemon | 2EE4B:2EE4B:1::log
2020-07-04 14:49:54.705983: [ds_am-M/2] | No pidfile found | main.cpp:354:check_pidfile | 2EE4B:2EE4B:2::log
2020-07-04 14:49:54.707170: [ds_am-M/4] | SIGCHLD is BLOCK. | main.cpp:212:daemon_handle_signal | 2EE4D:2EE4D:3::log
2020-07-04 14:49:54.707243: [ds_am-M/4] | SIGTERM is BLOCK. | main.cpp:217:daemon_handle_signal | 2EE4D:2EE4D:4::log
2020-07-04 14:49:54.707259: [ds_am-M/4] | SIGINT is BLOCK. | main.cpp:222:daemon_handle_signal | 2EE4D:2EE4D:5::log
2020-07-04 14:49:54.707271: [ds_am-M/4] | SIGUSR1 is BLOCK. | main.cpp:227:daemon_handle_signal | 2EE4D:2EE4D:6::log
2020-07-04 14:49:54.707283: [ds_am-M/4] | SIGUSR2 is BLOCK. | main.cpp:232:daemon_handle_signal | 2EE4D:2EE4D:7::log
2020-07-04 14:49:54.707422: [ds_am-M/2] | [DAEMON] do restart trashing control 0. | main.cpp:821:do_daemon | 2EE4D:2EE4D:8::log
2020-07-04 14:49:54.723274: [ds_am-M/2] | [DAEMON] Monitor process 2EE4D:1:2EE4D is_running:1 | main.cpp:869:do_daemon | 2EE4D:2EE4D:9::log
2020-07-04 14:49:54.723499: [ds_am-M/2] | [DAEMON] fork child process 2EE5C:2EE4D:2EE4D is_running:1 | main.cpp:864:do_daemon | 2EE5C:2EE5C:9::log
2020-07-04 14:49:54.724199: [ds_am/2] | Pid (192092/192077) using parameter dir = /var/opt/ds_agent/am | main.cpp:1516:main | 2EE5C:2EE5C:10::
2020-07-04 14:49:54.724877: [ds_am/5] | Check log rotate ds_am 0/5 drop:0 10/9/0 | vmpd_log.c:182:vmpd_log_rotate | 2EE5C:2EE5E:11::log
2020-07-04 14:49:54.763661: [ds_am/4] | [ICRC] *** vmpd_icrc_so_loaded() *** | vmpd_icrc.cpp:764:vmpd_icrc_so_loaded | 2EE5C:2EE5C:12::
2020-07-04 14:49:54.763734: [ds_am/4] | [SCAN] *** scanctrl_so_loaded() ***  | scanctrl_vmpd_module.c:1700:scanctrl_so_loaded | 2EE5C:2EE5C:13::
2020-07-04 14:49:54.785857: [ds_am/4] | xslt_init() done  | sapscan_scan.c:5141:sapscan_scan_init | 2EE5C:2EE5C:14::
2020-07-04 14:49:54.788770: [ds_am/2] | [ICRC] iCRC engine: 2.82.0.1055 | vmpd_icrc.cpp:291:vmpd_icrc_init | 2EE5C:2EE5C:15::
2020-07-04 14:49:54.800625: [ds_am/4] | *** vmpd_vsec_rtscan_so_loaded()*** | dsa_rtscan_module.c:684:vmpd_vsec_rtscan_so_loaded | 2EE5C:2EE5C:16::
2020-07-04 14:49:54.801024: [ds_am/4] | *** vmpd_sapscan_so_loaded()*** | sapscan_module.c:1937:vmpd_sapscan_so_loaded | 2EE5C:2EE5C:17::
2020-07-04 14:49:54.804071: [ds_am/3] | Create DOHCThread successfully | hc_engine.cpp:79:InitHCEngine | 2EE5C:2EE79:18::
2020-07-04 14:49:54.804138: [ds_am/2] | sapscan_start() doing  | sapscan_module.c:1756:sapscan_start | 2EE5C:2EE7F:19::
2020-07-04 14:49:54.804270: [ds_am/2] | sapscan_start() done  | sapscan_module.c:1823:sapscan_start | 2EE5C:2EE7F:20::
2020-07-04 14:49:54.831140: [ds_am/2] | wxLogging has been initialized entering main loop | main.cpp:1367:DoLogString | 2EE5C:2EE5C:21::
2020-07-04 14:49:54.831631: [ds_am/4] | [SCAN] working_objs:0 - global conf (0 -> 0) is configuring... | scanctrl_vmpd_module.c:1244:scanctrl_vmpd_module_handle_global_config_event | 2EE5C:2EE61:22::
2020-07-04 14:49:54.832028: [ds_am/2] | [SCAN] VSAPI engine: 11.000.1006 | scanctrl_am_engine.c:1120:am_engine_manager_new | 2EE5C:2EE61:23::

Memory during the issue time
14:00:01    280312680 6061247352     95.58    309264 277115436 5745620900     90.60 5774706320 244509240       520
14:10:02    278399200 6063160832     95.61    309264 277120776 5745045792     90.59 5776610656 244513340       296
14:20:04    277724740 6063835292     95.62    309264 277122636 5745371004     90.60 5777288288 244513908       420
14:30:01    259313436 6082246596     95.91    309264 277136232 5760075412     90.83 5795628284 244515028       492
14:40:02    257813312 6083746720     95.93    309264 277128212 5762054444     90.86 5797163104 244505972       520
17:00:04    6335529964   6030068      0.10     48612   2369332    957980      0.02   2641480   1063860      2256
17:10:01    6093573472 247986560      3.91     55936  35917400 314884104      4.97 210609764  34511336      1560
17:20:01    5922769836 418790196      6.60     62880  36028128 503669604      7.94 380940224  34558240       616


CPU
11:00:01        CPU     %user     %nice   %system   %iowait    %steal     %idle
14:00:01        all     28.63      0.00      0.70      0.04      0.00     70.62
14:10:02        all     35.74      0.00      0.73      0.05      0.00     63.48
14:20:04        all     16.81      0.00      0.64      0.06      0.00     82.49
14:30:01        all     20.67      0.00      0.88      0.05      0.00     78.40
14:40:02        all     28.09      0.00      0.93      0.17      0.00     70.80
17:00:04        all    100.00      0.00      0.00      0.00      0.00      0.00
17:10:01        all      2.78      0.00      0.88      0.69      0.00     95.64
17:20:01        all      2.91      0.00      0.70      1.34      0.00     95.05



[root@tsleecprddb ibmrmalik]$ df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done
Filesystem
tune2fs: No such file or directory while trying to open Filesystem
Couldn't find valid filesystem superblock.
/dev/sda2
Filesystem state:         clean
/dev/sdb1
tune2fs: Bad magic number in super-block while trying to open /dev/sdb1
Couldn't find valid filesystem superblock.
/dev/sdb2
tune2fs: Bad magic number in super-block while trying to open /dev/sdb2
Couldn't find valid filesystem superblock.
/dev/sda1
Filesystem state:         not clean
/dev/sda5
tune2fs: Bad magic number in super-block while trying to open /dev/sda5
Couldn't find valid filesystem superblock.
/dev/sda6
tune2fs: Bad magic number in super-block while trying to open /dev/sda6
Couldn't find valid filesystem superblock.
che01ammsol01.imzcloud.ibmammsap.local:/sds
tune2fs: No such file or directory while trying to open che01ammsol01.imzcloud.ibmammsap.local:/sds
Couldn't find valid filesystem superblock.
[root@tsleecprddb ibmrmalik]$ ^C
[root@tsleecprddb ibmrmalik]$ lsblk
NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda      8:0    0 893.8G  0 disk
â”œâ”€sda1   8:1    0     1G  0 part /boot
â”œâ”€sda2   8:2    0   150G  0 part /
â”œâ”€sda3   8:3    0     1K  0 part
â”œâ”€sda5   8:5    0   150G  0 part /usr/sap
â””â”€sda6   8:6    0 592.8G  0 part /sapmnt/log
sdb      8:16   0  10.5T  0 disk
â”œâ”€sdb1   8:17   0     1T  0 part /sapmnt/shared
â””â”€sdb2   8:18   0   9.5T  0 part /sapmnt/data




IA1S4HQASDB 	IMZ IP - 10.133.17.139 - HANA server
IA1S4HQASDB	10.164.30.187	lonhana-1024-6.xsportal.local (edited) 

root WdFV3d%2aXDYTO@




IA1BPCQASDB
10.164.30.221	lonhana-1024-7.xsportal.local
root uVuQmg%lqY8LLF@



 	DAL09AMMSRTR2 	146.89.140.28 	146.89.140.28
 	
 	
 	
 	
RCA0002797  TATA RCA



CS3682197  IAG GBS Limited -- IA1P2 - MajorSAP HEC SWIVEL - file system size increase in Prod OTAS A
lease increase   /opt/opentext/volume_storage file system size by 400 GB in below servers.
 
IA2OTAPPRDAPP
66.248.244.210
ia2otappdapdr
66.248.242.20

[root@ia2otappdapdr ibmrmalik]$ df -hT /opt/opentext/volume_storage
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/opentext_vg-volume_storage_lv
                     ext4  433G  174G  238G  43% /opt/opentext/volume_storage
[root@ia2otappdapdr ibmrmalik]$ vgs opentext_vg
  VG          #PV #LV #SN Attr   VSize   VFree
  opentext_vg   3   9   0 wz--n- 734.99g 1020.00m

[root@ia2otappdapdr ibmrmalik]$ df -hT /opt/opentext/volume_storage
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/opentext_vg-volume_storage_lv
                     ext4  827G  174G  612G  23% /opt/opentext/volume_storage


IA2OTAPPRDAPP 	10.133.15.107 	66.248.244.210
[root@ia2otapprdapp ibmrmalik]$ df -hT /opt/opentext/volume_storage
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/opentext_vg-volume_storage_lv
                     ext4  465G  377G   88G  82% /opt/opentext/volume_storage
[root@ia2otapprdapp ibmrmalik]$ vgs opentext_vg
  VG          #PV #LV #SN Attr   VSize   VFree
  opentext_vg   2  10   0 wz--n- 766.99g    0


[root@ia2otapprdapp ibmrmalik]$ df -hT /opt/opentext/volume_storage
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/opentext_vg-volume_storage_lv
                     ext4  859G  377G  482G  44% /opt/opentext/volume_storage



CI3	CS3682272
CI3S4HANAPRDA 	10.210.1.12 	10.201.0.12

10:50:01 AM   7309144 257202084     97.24     24268 143962312 288464536    102.55
Average:     12170092 252341136     95.40    498375 146222855 280799425     99.83

12:03:52 PM       LINUX RESTART

[root@CI3S4HANAPRDA log]$ free -gh
             total       used       free     shared    buffers     cached
Mem:          252G        23G       228G        13G        65M        14G
-/+ buffers/cache:       9.1G       243G
Swap:          15G         0B        15G
[root@CI3S4HANAPRDA log]$ cat /etc/fstab |grep -i swap
/dev/mapper/VolGroup-lv_swap swap                    swap    defaults        0 0





Jul  8 10:43:31 CI3S4HANAPRDA goferd: [ERROR][worker-0] gofer.messaging.adapter.proton.connection:106 - connect: proton+amqps://par01ammcaps01.imzcloud.ibmammsap.local:5647, failed: Connection amqps://par01ammcaps01.imzcloud.ibmammsap.local:5647 disconnected



10.164.30.221	lonhana-1024-7.xsportal.local

-----------------------------------------------------------------------------------

CHG0160530
Non Prod /SAP/ LON02 / MANUAL - Apply Latest Q320 Patches on LINUX Servers

IA2S4HDEVDB	10.133.16.41	66.248.245.41
IA2MDGDEVAPP	10.133.16.73	66.248.245.64
IA2S4HDEVAPP	10.133.16.42	66.248.245.42
IA2MDGDEVDB	10.133.16.68	66.248.245.67





DAL09AMMSRT1 : 146.89.140.28
DAL09AMMSRTR2 	146.89.140.28 	146.89.140.28


HC   [EXTERNAL] Case CS3489938 Home Control : Request to mount eccci0prd & eccap1prd to customer's remote folder
ECP CI	eccci0prd	10.198.2.140
ECP App	eccap1prd	10.198.2.141


approval on CHG0148730


CS3692872
TSGPPRD 	10.207.61.41 	10.170.61.20
----------------------------------------------------------

CS3692984
System Name : SAP S4H  PRD

    OS user creation, modification, deletion data with evidence

        This is required for period â€“ 1st July â€“ 31st Dec 2019

Hostname	IFN IP	CFN IP
TSLEECPRDDB	10.207.61.78	10.170.61.59
SAPAPP22	10.207.61.63	10.170.61.231
SAPAPP15	10.207.61.37	10.170.61.121
SAPAPP18	10.207.61.70	10.170.61.116
SAPAPP19	10.207.61.215	10.170.61.74
SAPAPP20	10.207.61.195	10.170.61.48
SAPAPP21	10.207.61.80	10.170.61.131
SAPAPP23	10.207.61.130	10.170.61.226
SAPAPP26	10.207.61.48	10.170.61.176
SAPAPP27	10.207.61.47	10.170.61.166
SAPAPP28	10.207.61.58	10.170.61.211
SAPAPP29	10.207.61.85	10.170.61.141
SAPAPP30	10.207.61.95	10.170.61.161



System Name : SAP CRM PRD

    OS user creation, modification, deletion data with evidence

This is required for period 1st July â€“ 31st Dec 2019

 SAPCRMAPP1	10.207.61.24	10.170.61.27
SAPCRMAPP3	10.207.61.60	10.170.61.96



CS3700863 CMA CGM -- CMAP2 - MajorMemory Swap CRITICAL: Swap free 49.77% (thresh 50:%)


Hostname: ia2mdgqadb
CFN IP: 66.248.245.163
IFN IP: 10.133.17.164
SAP SID: GQ5
============
10.164.30.233	lonhana-1024-48.xsportal.local

10.164.30.233	lonhana-1024-48.xsportal.local



CS3702914 Bumrungrad Hospital Plc -- BUMP1 - SevereMountpoint Interface CRITICAL: /Interface did not respond in 3 sec. Seems to be stale. :BUMSAPPOD01T



dlthsbbsi02
System Boot Time:          7/10/2020, 1:12:23 AM
The process C:\Windows\Explorer.EXE (DLTHSBBSI02) has initiated the restart of computer DLTHSBBSI02 on behalf of user IMZCLOUD\ibmmhussain for the following reason: Other (Unplanned)
 Reason Code: 0x0
 Shutdown Type: restart



Node Attributes:
* Node br3psoldb40:
    + hana_psa_clone_state              : DEMOTED
    + hana_psa_op_mode                  : logreplay
    + hana_psa_remoteHost               : br3psoldb41
    + hana_psa_roles                    : 4:S:master1:master:worker:master
    + hana_psa_site                     : NODEA
    + hana_psa_srmode                   : sync
    + hana_psa_sync_state               : SFAIL
    + hana_psa_version                  : 2.00.037.04.1571818940
    + hana_psa_vhost                    : br3psoldb40
    + lpa_psa_lpt                       : 10
    + master-rsc_SAPHana_PSA_HDB84      : -INFINITY
* Node br3psoldb41:
    + hana_psa_clone_state              : PROMOTED
    + hana_psa_op_mode                  : logreplay
    + hana_psa_remoteHost               : br3psoldb40
    + hana_psa_roles                    : 4:P:master1:master:worker:master
    + hana_psa_site                     : SITEB
    + hana_psa_srmode                   : sync
    + hana_psa_sync_state               : PRIM
    + hana_psa_version                  : 2.00.037.04.1571818940
    + hana_psa_vhost                    : br3psoldb41
    + lpa_psa_lpt                       : 1594701736
    + master-rsc_SAPHana_PSA_HDB84      : 150
    
    
    Issue found on n/w end where the servers were unable to connect to the Nagios ip. Fixed by n/w ref ticket to n/w CS3739072




TNGDEVERPDB	10.134.1.13 / 172.24.1.13	vHANA	10.116.145.43	snghana-1024-17.xsportal.local	RJxw57%wOLmJaJ@
TNGDEVEAPP40	10.134.2.14 / 172.24.2.14	given
TNGQASERPDB	10.134.1.12 / 172.24.1.12	vHANA   10.116.145.37	snghana-1024-22.xsportal.local	DBIjIh%hdPTRB4@
TNGQASEAPP20	10.134.2.13 / 172.24.2.13	given
TNGPRODERPDB	10.134.1.11 / 172.24.1.11	vHANA   10.116.145.43	snghana-1024-17.xsportal.local	RJxw57%wOLmJaJ@
TNGPRODEAPP00	10.134.2.11 / 172.24.2.11	given
TNGPRODEAPP01	10.134.2.12 / 172.24.2.12






[root@mm3pouxp003 ibmrmalik]# cat /etc/fstab |grep -i /export
mm3s4uep002:/export     /export         nfs    defaults,nfsvers=4,intr 0 0
Mitsubishi Motors North America Inc -- MM3 	MM3S4UEP002 	10.15.131.42 	10.15.0.102 	Production 	Pending Deactivation
M3S4UEP002 	10.15.131.42 	10.15.0.102 	Production 	Pending Deactivation


bigfix

BR3PMIGA01 	10.138.10.34 	10.3.112.55    fixed
BR3TSAPAS20 	10.138.10.65 	10.3.112.58    fixed	
BR3QSCMSS37 	10.138.10.76 	10.3.112.140   fixed
BAPV120400 	10.134.3.6 	10.8.217.8     fixed	
SAPAPP23 	10.207.61.130 	10.170.61.226  fixed
BS5DEVAPP 	10.141.133.14 	132.133.0.13   fixed    


[root@jbdaix4 ibmrmalik]$ df -hT /sapmnt/DIS
Filesystem                         Type  Size  Used Avail Use% Mounted on
/dev/mapper/disappvg-sapmnt_DIS_lv ext4  112G   66G   41G  62% /sapmnt/DIS


stat("/usr/sap/trans", ^C^Z
[1]+  Stopped                 strace df -hT
[root@br3qscmas37 ibmrmalik]#
[root@br3qscmas37 ibmrmalik]# cat /etc/fstab |grep -i /usr/sap/trans
/dev/qcmappvg/usrtrans_lv       /usr/sap/trans_old      xfs     _netdev,defaults        1       2
10.3.112.111:/usr/sap/trans /usr/sap/trans  nfs nfsvers=3   0 0


[root@br3qsapss30 ibmrmalik]$ cat /etc/fstab |grep -i /usr/sap/trans
10.3.112.23:/usr/sap/trans /usr/sap/trans nfs rw,soft,intr 0 0

----------------------------------------------------------------------------

CHG0161040	17-07-2020 07:00:00
<Non Prod>/SAP/<PAR01>/<MANUAL>- Apply Latest Q320 Patches on <<LINUX>> Servers
		smdbsbxss0	10.78.20.24	   Development	10.127.235.210	parhana-512-1.xsportal.local
		smbosbxsb1	10.78.20.11	   Development
		smdbsbxsm1	10.78.20.21	   Development	10.127.155.79	parhana-1024-3.xsportal.local
		smemsbxsm1	10.78.20.22	   Development
		smifasbxsf1	10.78.20.32	   Development
		smposbxsx8	10.78.20.20	   Development
		smsmsbxss0	10.78.20.25	   Development
		smgrcsbxsg1	10.78.20.30	   Development
		smgwsbxsq1	10.78.20.31	   Development



each time a server moves from one node to another there is a minimum wait time when all the processes are kept on hold â€“ that would affect the system performance
-------------------------------------------------------------------------------

CS3760090	DLBQECAP01
[root@DLBQECAP01 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux DLBQECAP01 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 06:49:48 IST 2020
146.89.140.30:/storage/library /storage/library nfs rw,vers=4,addr=146.89.140.30,clientaddr=10.13.2.12 0 0
172.16.22.24:/Bank      /Bank    nfs4    rw,auto,hard,intr,retrans=3             0      0
172.16.22.105:/Client_Export /Client_Export nfs defaults 0 0
CRITICAL:  /Bank filesystems are read-only
                     nfs    6.6T  3.2T  3.1T  51% /storage/library
                     nfs    493G  286G  182G  62% /Client_Export
                     nfs    3.6T  3.0T  440G  88% /sds
172.16.22.24:/Bank   nfs4    15G  571M   14G   5% /Bank
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.142.94,clientaddr=10.13.2.12 0 0

[root@DLBQECAP01 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux DLBQECAP01 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 07:02:00 IST 2020
146.89.140.30:/storage/library /storage/library nfs rw,vers=4,addr=146.89.140.30,clientaddr=10.13.2.12 0 0
172.16.22.24:/Bank      /Bank    nfs4    rw,auto,hard,intr,retrans=3             0      0
172.16.22.105:/Client_Export /Client_Export nfs defaults 0 0
CRITICAL:  /Bank filesystems are read-only
                     nfs    6.6T  3.2T  3.1T  51% /storage/library
172.16.22.24:/Bank   nfs4    15G  571M   14G   5% /Bank
                     nfs    493G  286G  182G  62% /Client_Export
                     nfs    3.6T  3.0T  440G  88% /sds
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.142.94,clientaddr=10.13.2.12 0 0

CS3760062	DLBDECAP01
[ibmrmalik@DLBDECAP01 ~]$ sudo su
[root@DLBDECAP01 ibmrmalik]# cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux DLBDECAP01 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 06:49:52 IST 2020
#172.16.22.24:/Bank     /Bank    nfs3    rw,auto,hard,intr,retrans=3             0      0
172.16.22.24:/Bank     /Bank    nfs    rw,auto,hard,intr,retrans=3
OK: No read-only file systems found
                     nfs    3.6T  3.0T  440G  88% /sds
172.16.22.24:/Bank   nfs     15G  571M   14G   5% /Bank
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.142.94,clientaddr=10.13.2.14 0 0
#/sapmnt/data_new  *(rw,sync,no_root_squash)
/Bank *(rw,sync,no_root_squash)

[root@DLBDECAP01 ibmrmalik]# cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux DLBDECAP01 2.6.32-754.29.2.el6.x86_64 #1 SMP Thu May 7 06:14:05 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 07:02:08 IST 2020
#172.16.22.24:/Bank     /Bank    nfs3    rw,auto,hard,intr,retrans=3             0      0
172.16.22.24:/Bank     /Bank    nfs    rw,auto,hard,intr,retrans=3
OK: No read-only file systems found
172.16.22.24:/Bank   nfs     15G  571M   14G   5% /Bank
                     nfs    3.6T  3.0T  440G  88% /sds
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.142.94,clientaddr=10.13.2.14 0 0
#/sapmnt/data_new  *(rw,sync,no_root_squash)
/Bank *(rw,sync,no_root_squash)



CS3760045	dlbqecdb01	10.162.24.211	che01-pod1-4tb-host01.imzcloud.ibmammsap.local		
R0n1ke%01bH974@
[root@dlbqecdb01 ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds; cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux dlbqecdb01 4.4.121-92.135-default #1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528) x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 06:58:24 IST 2020
      Local time: Sat 2020-07-18 06:58:24 IST
  Universal time: Sat 2020-07-18 01:28:24 UTC
        RTC time: Sat 2020-07-18 01:28:24
       Time zone: Asia/Calcutta (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective

[root@dlbqecdb01 ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds; cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux dlbqecdb01 4.4.121-92.135-default #1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528) x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 07:15:25 IST 2020
      Local time: Sat 2020-07-18 07:15:26 IST
  Universal time: Sat 2020-07-18 01:45:26 UTC
        RTC time: Sat 2020-07-18 01:45:26
       Time zone: Asia/Calcutta (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

	
Effected hosts:
DEC Application: DLBDECAP01   10.13.2.14
QEC Application: DLBQECAP01   10.13.2.12
HANA DB:          DLBQECDB00   10.13.2.41	
Effected SID: DEC & QEC


CS3771969   Dilip Buildcon Limited -- DLB   Host Reboot CRITICAL: Uptime 2 minutes (thresh 60 min)  p1




BUMSAPH4PDR 	10.136.5.13 	10.156.5.61	10.174.73.130	hkg02-pod2-4tb-host03.imzcloud.ibmammsap.local	tQpRY4%1WDayt8@
CHG0163539	HANA SP upgrade from SP02 to SP04 along with SUSE SP upgrade to SP4 	18-07-2020 08:30:00	18-07-2020 16:30:00
[root@bumsaph4pdr ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds; cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux bumsaph4pdr 4.4.121-92.125-default #1 SMP Wed Nov 13 11:24:27 UTC 2019 (e3b50c1) x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 09:58:27 +07 2020
OK: No read-only file systems found
hkg02ammsol01.imzcloud.ibmammsap.local:/sds nfs4      5.5T  3.0T  2.3T  56% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=4155,timeout=600,minproto=5,maxproto=5,direct 0 0
hkg02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.136.5.13,local_lock=none,addr=146.89.141.28 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

[root@bumsaph4pdr sds]# cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds; cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux bumsaph4pdr 4.12.14-95.54-default #1 SMP Thu Jun 4 12:49:28 UTC 2020 (892ef1f) x86_64 x86_64 x86_64 GNU/Linux
Sat Jul 18 13:08:12 +07 2020
      Local time: Sat 2020-07-18 13:08:12 +07
  Universal time: Sat 2020-07-18 06:08:12 UTC
        RTC time: Sat 2020-07-18 06:08:12
       Time zone: Asia/Bangkok (+07, +0700)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

[2020-07-18T11:33:31+07:00] ERROR: Server returned error 504 for https://HKG02AMMCHEF01.imzcloud.ibmammsap.local/organizations/bum/data-collector, retrying 1/5 in 3s
[2020-07-18T11:33:35+07:00] ERROR: Server returned error 504 for https://HKG02AMMCHEF01.imzcloud.ibmammsap.local/organizations/bum/data-collector, retrying 2/5 in 8s
[2020-07-18T11:33:44+07:00] ERROR: Server returned error 504 for https://HKG02AMMCHEF01.imzcloud.ibmammsap.local/organizations/bum/data-collector, retrying 3/5 in 16s
[2020-07-18T11:34:01+07:00] ERROR: Server returned error 504 for https://HKG02AMMCHEF01.imzcloud.ibmammsap.local/organizations/bum/data-collector, retrying 4/5 in 32s




[root@bumsaph4pdr log]# cat /var/log/sssd/sssd.log |grep -i error
(Sat Jul 18 10:41:18 2020) [sssd] [monitor_cleanup] (0x0010): Error removing pidfile! (2 [No such file or directory])
(Sat Jul 18 10:59:56 2020) [sssd] [monitor_cleanup] (0x0010): Error removing pidfile! (2 [No such file or directory])
(Sat Jul 18 11:31:04 2020) [sssd] [monitor_cleanup] (0x0010): Error removing pidfile! (2 [No such file or directory])
(Sat Jul 18 11:32:39 2020) [sssd] [monitor_cleanup] (0x0010): Error removing pidfile! (2 [No such file or directory])
(Sat Jul 18 11:37:02 2020) [sssd] [monitor_cleanup] (0x0010): Error removing pidfile! (2 [No such file or directory])
(Sat Jul 18 11:48:14 2020) [sssd] [monitor_cleanup] (0x0010): Error removing pidfile! (2 [No such file or directory])



 BUMSAPH4PDR 10.136.5.13 10.156.5.61 chef-client failed cannot connect to chef regional server #4908 


/root/clientSetup4SMT.sh https://hkg02ammsmt01.imzcloud.ibmammsap.local/center/regsvc --yes --fingerprint 

 /root/clientSetup4SMT.sh https://hkg02ammsmt01.imzcloud.ibmammsap.local/center/regsvc --yes --fingerprint $(cat /root/cert_fingerprint)
 
 /usr/bin/SUSEConnect --write-config --url https://hkg02ammsmt01.imzcloud.ibmammsap.local/center/regsvc



https://ibm.ent.box.com/folder/116499076400

---------------------------------------------------------------------------------------

CS3795149 - can you pls take VM snap shot for below hosts
svfs1srv0
svjs1srv0
svcs1srv0




case # CS3801711
sftp dev/qas (SVMQ1SRV1 	10.6.2.42 	10.70.110.42) is already mounted on 10.6.1.11.
But we need your assistance to permit rd1adm to access the /sftp/dev/ mountpoint




[root@MGGGBJDSOLX02 ibmrmalik]$ /etc/init.d/besclient status
BESClient dead but subsys locked



	CS3801809	P3 - Minor	Fitbit Inc -- FBT	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801694	P3 - Minor	Hortus Comercio de Alimentos SA -- HC1	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801674	P3 - Minor	ETRO SPA -- ETO	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801646	P3 - Minor	Fitbit Inc -- FBT	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801619	P3 - Minor	Egyptian Refining Company -- EGR	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801562	P3 - Minor	Fitbit Inc -- FBT	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801531	P3 - Minor	Hortus Comercio de Alimentos SA -- HC1	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801483	P3 - Minor	Egyptian Refining Company -- EGR	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801482	P3 - Minor	ETRO SPA -- ETO	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801479	P3 - Minor	Hortus Comercio de Alimentos SA -- HC1	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801478	P3 - Minor	Egyptian Cement -- ECT	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801458	P3 - Minor	Hortus Comercio de Alimentos SA -- HC1	Service vmtoolsd CRITICAL: vmtoolsd is not running
	CS3801453	P3 - Minor	Egyptian Cement -- ECT	Service vmtoolsd CRITICAL: vmtoolsd is not running
CS3801443	P3 - Minor	ETRO SPA -- ETO	Service vmtoolsd CRITICAL: vmtoolsd is not running



CS3811612: 
Reboot request for below hosts. 6:30AM
Customer: Dilip Buildcon Limited -- DLB
Below VMs are involved for VM snapshot + Reboot
DLBPBWAP01    10.13.1.15 Application of PBW
[root@DLBPBWAP01 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux DLBPBWAP01 2.6.32-754.30.2.el6.x86_64 #1 SMP Fri May 29 04:45:43 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Thu Jul 23 06:45:00 IST 2020
DLBDBWAP01:/usr/sap/trans /usr/sap/trans        nfs    rw,hard,intr,rsize=32768,wsize=32768    0  0
OK: No read-only file systems found
                     nfs    3.6T  3.0T  440G  88% /sds
                     nfs     50G   38G  8.9G  81% /usr/sap/trans
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.142.94,clientaddr=10.13.1.15 0 0

[root@DLBPBWAP01 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux DLBPBWAP01 2.6.32-754.30.2.el6.x86_64 #1 SMP Fri May 29 04:45:43 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Thu Jul 23 07:19:17 IST 2020
DLBDBWAP01:/usr/sap/trans /usr/sap/trans        nfs    rw,hard,intr,rsize=32768,wsize=32768    0  0
OK: No read-only file systems found
                     nfs     50G   38G  8.9G  81% /usr/sap/trans
                     nfs    3.6T  3.0T  440G  88% /sds
che01ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.142.94,clientaddr=10.13.1.15 0 0


DLBPBWDB01    10.13.1.22 HANA DB of PBW	HANA	10.162.24.211	che01-pod1-4tb-host01.imzcloud.ibmammsap.local
[root@dlbpbwdb01 ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;cat /etc/fstab |grep -i sds; cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux dlbpbwdb01 4.4.121-92.135-default #1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528) x86_64 x86_64 x86_64 GNU/Linux
Thu Jul 23 06:46:02 IST 2020
      Local time: Thu 2020-07-23 06:46:02 IST
  Universal time: Thu 2020-07-23 01:16:02 UTC
        RTC time: Thu 2020-07-23 01:16:02
       Time zone: Asia/Calcutta (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.





export PS1="\[\e[1;36m\][\u@\h \W]\$ \[\e[m\]"
if [ ! -z "$SSH_CONNECTION" ]; then
echo "*******************************************************************************"
        printf '*    Server Type: \e[1;36m%-60s\e[m*\n' 'QA'
        printf '*       Hostname: \e[1;36m%-60s\e[m*\n' 'agesvbq1hsrv1'
        printf '*         CFN IP: \e[1;36m%-60s\e[m*\n' '10.70.110.72'
        printf '*         IFN IP: \e[1;36m%-60s\e[m*\n' '10.6.2.70'
        printf '*        SAP SID: \e[1;36m%-60s\e[m*\n' 'BQ1'
echo "*******************************************************************************"





[root@DLBDECAP01 ibmrmalik]# sudo update-alternatives --config java
Sorry, user root is not allowed to execute '/usr/sbin/update-alternatives --config java' as root on DLBDECAP01.
[root@DLBDECAP01 ibmrmalik]#  update-alternatives --config java

There are 6 programs which provide 'java'.

  Selection    Command
-----------------------------------------------
   1           /usr/lib/jvm/jre-1.6.0-openjdk.x86_64/bin/java
   2           /usr/lib/jvm/jre-1.5.0-gcj/bin/java
   3           /usr/lib/jvm/jre-1.8.0-openjdk.x86_64-debug/bin/java
*+ 4           /usr/lib/jvm/jre-1.8.0-openjdk.x86_64/bin/java
   5           /usr/lib/jvm/jre-1.4.2-ibm-sap.x86_64/bin/java
   6           /usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java

Enter to keep the current selection[+], or type selection number:




CHG0161468 -Egyptian Refining Company -- EGR- 24-07-2020 07:00:00-24-07-2020 14:30:00	SAP Bharat Peram
Customer:mhaddad@ERCEGYPT.COM,wsalousa@eg.ibm.com,rharfoush@ERCEGYPT.COM
DPE: yadhukarb@in.ibm.com
PDL: gratiela.novac@ibm.com

egrs4hdevapp	 10.135.6.11	Development
egrs4hqasdb	 10.135.6.12	Development - - hana server - hana version 2.00.037.04 (Please patch SLES12 SP2 to latest versions in SP2 in order to avoid any issues with customer 3rd parties interfaces)
egrs4hqasapp	 10.135.6.16	QA
egrwd-dev	         10.135.6.17	Development
egrwd-qas	         10.135.6.13	QA



Change Number # CHG0161468
Start time & End Time: 7:00 AM IST till 2:30 PM IST
OS Engineer / SAP Engineer - Bharat Peram and Ravi Malik
Effected Server : egrs4hdevapp, egrs4hqasdb, egrs4hqasapp,egrwd-dev, egrwd-qas 
Status : Started / Completed / Extended  - started


EGRWD-DEV	10.135.6.17	10.21.0.23
		
EGRS4HQASDB	10.135.6.12	10.21.0.13
		
EGRS4HDEVAPP	10.135.6.11	10.21.0.18
		
EGRWD-QAS	10.135.6.13	10.21.0.28
		
EGRS4HQASAPP	10.135.6.16	10.21.0.33






Change Number # CHG0161472
Start time & End Time: 7:00 AM IST till 11:30 AM IST
OS Engineer / SAP Engineer - Anupama and Sandeep gaur
Effected Server : ercnwd01 10.5.1.104 Non-Production , ercerpd1 10.5.1.101         Non-Production , ercerpq1 10.5.1.102 Non-Production
Status : Started / Completed / Extended  - started

ERCERPD1 	10.5.1.101 	10.10.0.101	A0DDUK014XVM001
[root@ercerpd1 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ercerpd1 2.6.32-754.29.1.el6.x86_64 #1 SMP Thu Mar 12 19:09:58 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jul 24 04:06:23 EET 2020
OK: No read-only file systems found
                     nfs    6.6T  3.0T  3.3T  48% /sds
lon02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.140.93,clientaddr=10.5.1.101 0 0
/usr/sap/trans          *(rw,sync,no_root_squash)

[root@ercerpd1 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ercerpd1 2.6.32-754.30.2.el6.x86_64 #1 SMP Fri May 29 04:45:43 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jul 24 05:51:20 EET 2020
OK: No read-only file systems found
                     nfs    6.6T  3.0T  3.3T  48% /sds
lon02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.140.93,clientaddr=10.5.1.101 0 0
/usr/sap/trans          *(rw,sync,no_root_squash)


ERCERPQ1 	10.5.1.102 	10.10.0.102	A0DDUK014XVM002
[root@ercerpq1 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ercerpq1 2.6.32-754.29.1.el6.x86_64 #1 SMP Thu Mar 12 19:09:58 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jul 24 04:07:09 EET 2020
10.10.0.101:/usr/sap/trans      /usr/sap/trans      nfs    nfsvers=3   0 0
OK: No read-only file systems found
                     nfs    138G   75G   57G  57% /usr/sap/trans
                     nfs    6.6T  3.0T  3.3T  48% /sds
lon02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.140.93,clientaddr=10.5.1.102 0 0

[root@ercerpq1 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ercerpq1 2.6.32-754.30.2.el6.x86_64 #1 SMP Fri May 29 04:45:43 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jul 24 05:51:24 EET 2020
10.10.0.101:/usr/sap/trans      /usr/sap/trans      nfs    nfsvers=3   0 0
OK: No read-only file systems found
                     nfs    138G   75G   57G  57% /usr/sap/trans
                     nfs    6.6T  3.0T  3.3T  48% /sds
lon02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.140.93,clientaddr=10.5.1.102 0 0

ERCNWD01 	10.5.1.104 	10.10.0.103	A0DDUK014XVM004
[root@ercnwd01 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ercnwd01 2.6.32-754.29.1.el6.x86_64 #1 SMP Thu Mar 12 19:09:58 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jul 24 04:07:16 EET 2020
OK: No read-only file systems found
                     nfs    6.6T  3.0T  3.3T  48% /sds
lon02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs ro,soft,nolock,vers=4,sloppy,addr=146.89.140.93,clientaddr=10.5.1.104 0 0
/usr/sap/trans          *(rw,sync,no_root_squash)

[root@ercnwd01 ibmrmalik]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux ercnwd01 2.6.32-754.30.2.el6.x86_64 #1 SMP Fri May 29 04:45:43 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jul 24 05:51:28 EET 2020
OK: No read-only file systems found
                     nfs    6.6T  3.0T  3.3T  48% /sds
lon02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs rw,vers=4,addr=146.89.140.93,clientaddr=10.5.1.104 0 0
/usr/sap/trans          *(rw,sync,no_root_squash)


CHG0164207	snapshot
Svjs1srv0 â€“ JS1
Svfs1srv0 â€“ FS1
Svcs1srv0 â€“ XS1

SVFSSRV0


10.85.0.180	fra02-pod2-4tb-host02.imzcloud.ibmammsap.local	JQbFQc%HkAWmef@



BAPV110100 	10.134.3.11
BAPCCP0100 	10.134.5.8
BAPV330900 	10.134.3.7
BAPV120400 	10.134.3.6
BAPV721300 	10.134.4.14
BAPCCD0100 	10.134.5.9
BAPV510300 	10.134.4.12
BAPV520500 	10.134.4.11
BAPV590800 	10.134.4.13
BAPV321100 	10.134.4.15




Hi Ravi, when you have some time could you please check my last comment here https://github.ibm.com/CMS/cms-chef/issues/4921, it seems chef team is not able to connect server apfs4ppdb, as we discuss last time together, thank you




Ravi when you will be working there is one more thing in github https://github.ibm.com/CMS/cms-chef/issues/4750                       sdmiamhdb | sdmiamhdb_**
The BigFix agent is up and running for above 2 nodes and i have verified the Relay Server Values as well .Also log dir is getting created and Logs are populated in the directory ..
 â— besclient.service - Besclient Daemon
 Loaded: loaded (/usr/lib/systemd/system/besclient.service; enabled; vendor preset: disabled)
 Active: active (exited) since Wed 2019-03-20 12:03:44 GMT; 1 years 3 months ago
 Main PID: 116521 (code=exited, status=0/SUCCESS)
 Tasks: 8 (limit: 512)
 CGroup: /system.slice/besclient.service
 â””â”€116525 /opt/BESClient/bin/BESClient
 Although Chef Convergence is failing with below error and need to get it checked with Client Trio...
 [2020-07-02T09:36:48+00:00] ERROR: hana_connection[check_connectivity_INWAUTOMATION] (sap_hana::sap_hana_install line 310) had an error: RuntimeError: HANA Database connectivity check failed. Check database is started. Details: Please see https://github.ibm.com/CMS/cms-sq-sap-hana-pe-automation_hana/wiki/Operations:-check-create-adjust-hana-users., SID=INW, INSTANCE NUM=00, TENANT=SYSTEMDB, ADMIN_KEY=INWAUTOMATION, error_code=-10709, error_message=Connection failed (RTE, error_details=System call 'send' failed, rc=104:Connection reset by peer {127.0.0.1:30013})
 [2020-07-02T09:36:48+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
1:33 PM
this is devtest server but per info from github this should be checked with client trio


br3psoldb40
br3psoldb41


su - psaadm -c "hdbnsutil -sr_register --remoteHost=br3psoldb41 --remoteInstance=84 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEA"

su - psaadm -c "hdbnsutil -sr_register --remoteHost=br3psoldb41 --remoteInstance=84 --replicationMode=sync --operationMode=logreplay --name=NODEA"

Node Attributes:
* Node br3psoldb40:
    + hana_psa_clone_state              : UNDEFINED
    + hana_psa_op_mode                  : logreplay
    + hana_psa_remoteHost               : br3psoldb41
    + hana_psa_roles                    : 1:P:master1::worker:
    + hana_psa_site                     : NODEA
    + hana_psa_srmode                   : sync
    + hana_psa_sync_state               : SFAIL
    + hana_psa_version                  : 2.00.037.04.1571818940
    + hana_psa_vhost                    : br3psoldb40
    + lpa_psa_lpt                       : 10
    + master-rsc_SAPHana_PSA_HDB84      : -9000




Can you pls help to mount FS temporarily in 10.4.5.185
10.250.17.217:/backup_hpe
                      4.4T 6.1G 4.4T  1% /backup_hpe
 can we get someone from OS and network team to help
CS3799058
DLTQEBHAP1 	10.4.5.208 	10.250.17.217



CS3885215	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4ushlewmp1c(stonith:fence_vmware_soap):Stopped
CS3885204	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-05-13-31 for details.
CS3885203	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-05-13-32 for details.
CS3885202	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lapsp1c(stonith:fence_vmware_soap):Stopped vcenter-fencing-pn4ushlapsp1c(stonit
CS3885197	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-05-12-40 for details.
CS3885195	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lapsp1(stonith:fence_vmware_soap):Stopped
CS3885194	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lmiip1(stonith:fence_vmware_soap):Stopped vcenter-fencing-pn4ushlmiip1(stonith:
CS3885190	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lmiip1(stonith:fence_vmware_soap):Stopped vcenter-fencing-pn4ushlmiip1(stonith:
CS3885189	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-05-11-58 for details.
CS3885187	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4ushlewmp1c(stonith:fence_vmware_soap):Stopped
CS3885186	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-05-11-19 for details.
CS3885185	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lapsp1c(stonith:fence_vmware_soap):Stopped vcenter-fencing-pn4ushlapsp1c(stonit
CS3885184	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lmiip1c(stonith:fence_vmware_soap):Stopped
CS3885182	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lapsp1(stonith:fence_vmware_soap):Stopped
CS3885181	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-05-10-21 for details.
CS3885176	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-05-09-34 for details.
CS3885174	Panasonic North America -- PN4	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-pn4us7lmiip1c(stonith:fence_vmware_soap):Stopped





CS2190235
[2:57 PM] ptpborobudur /sybase/GRP% cd /sybase/GRP/saplog1
ptpborobudur GRP/saplog1% ls -ltr
total 36226092
drwxr-x--- 2 sybgrp sapsys       16384 Apr 20  2019 lost+found
-rw-r----- 1 sybgrp sapsys 37059416064 Jul 28 16:25 GRP_log_001.dat
ptpborobudur GRP/saplog1%
[3:03 PM] we want to add 30Gb ...  Do we have the space in VG ?
3:07 PM
Ip Of the server is 10.70.31.33




CHG0162053	<Non Prod>/SAP/<PAR01>/<MANUAL>- Apply Latest Q320 Patches on <<LINUX>> Servers	
29-07-2020 16:30:00	29-07-2020 20:30:00		Ravi/Vinod
DPE	Jazril NaaimMohd Jaffar <jazril@my.ibm.com>	
PDL	BogdanDediu <RO69131@ro.ibm.com>	
smarcdevd41	10.78.22.27	   Development
smcrmdevdr3	10.78.22.20	    Development
smdbdevdr3	10.78.22.19	     Development
smdbdevd41	10.78.22.26	     Development
smdsdevdo1d71	10.78.22.30	    Development



Length: 11157897216 (10G)
Saving to: â€˜LI-EL8.2.0-20200722-1.imgâ€™


statfs("/sapmnt/AP2", ^X^C^Z
[1]+  Stopped                 strace df -hT
[root@aprlcprd ibmrmalik]#
[root@aprlcprd ibmrmalik]# cat /etc/fstab |grep -i /sapmnt/AP2
10.10.21.36:/sapmnt/AP2 /sapmnt/AP2 nfs defaults 0 0




stat("/Tdisk", ^C
^X
^Z
[1]+  Stopped                 strace df -hT
[root@ldcs4hdbsbx ibmrmalik]#
[root@ldcs4hdbsbx ibmrmalik]# cat /etc/fstab |grep -i /Tdisk
cdi1ds4happ01:/Tdisk    /Tdisk  nfs    defaults,nfsvers=3,intr 0 0



CS3888934	Nidec ASI spa -- ASD	SQ-SAP-TRIO-B1		ASDPRDDB	Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-18-57-12 for details.
CS3890539	Nidec ASI spa -- ASD	SQ-SAP-TRIO-B1		ASDPRDDB	Log PaceMaker-log Found 53 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-07-28-20-37-33 for details.



[root@pn8us7leccd5 log]$ df -ih .
Filesystem                Inodes IUsed IFree IUse% Mounted on
/dev/mapper/rootvg-vloglv   160K  137K   24K   86% /var/log




CS3920638
Ping Node: juehdmart03 NodeAlias: 10.211.0.20 
10.208.79.59	dal13-pod1-4tb-host16.imzcloud.ibmammsap.local
root/ LuZSnU%RfNcB8X@
IPMI LKULbhXh36



CS3930764  Tata Steel Limited -- TTA   Disk Utilization /var CRITICAL: Free 269.14MB/4.18% (thresh @0:5%)  P1



[root@eccci0qas ibmrmalik]$ tune2fs -l /dev/mapper/vg_app-lv_usrsap |grep -i state
Filesystem state:         clean with errors
[root@eccci0qas ibmrmalik]$ tune2fs -l /dev/mapper/vg_app-lv_sapmnt |grep -i state
Filesystem state:         clean with errors

[root@eccci0qas ibmrmalik]$ df -hT /dev/mapper/vg_app-lv_usrsap
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_usrsap
                     ext4  100G   49G   46G  52% /usr/sap
[root@eccci0qas ibmrmalik]$ df -hT /dev/mapper/vg_app-lv_sapmnt
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_app-lv_sapmnt
                     ext4  9.8G  3.7G  5.6G  40% /sapmnt



epdappvg-usr_sap_EPD_lv
essmssdev	10.170.61.63	10.207.61.210


CS3964029 - resetting the root password to deafult
DR Host Name	CFN IP	IFN IP
May55now#	
		
sapapp18	10.170.61.116	10.207.61.70	Done
sapapp19	10.170.61.74	10.207.61.215	Done
sapapp20	10.170.61.48	10.207.61.195	Done
sapapp21	10.170.61.131	10.207.61.80	Done
sapapp22	10.170.61.231	10.207.61.63	DOne
sapapp26	10.170.61.176	10.207.61.48	Done
sapapp27	10.170.61.166	10.207.61.47	Done
sapapp28	10.170.61.211	10.207.61.58	Done
sapapp29	10.170.61.141	10.207.61.85	Done
sapapp30	10.170.61.161	10.207.61.95	Done
sapapp15	10.170.61.121	10.207.61.37	Done
sapapp23	10.170.61.226	10.207.61.130	Done
sapcrmapp3	10.170.61.96	10.207.61.60	Done
sapcrmapp1	10.170.61.27	10.207.61.24	Done
ewmapp2		10.170.61.241	10.207.61.140	Done
ewmapp1		10.170.61.68	10.207.61.77	Done
tsgpprd		10.170.61.20	10.207.61.41	Done
tscmlprd	10.170.61.15	10.207.61.36	Done
biprdapp3 	10.170.61.17	10.207.61.31	Done
biprdapp1	10.170.61.91	10.207.61.28	Done
adsprds		10.170.61.25	10.207.61.29	Done
sapborepo	10.170.61.56	10.207.61.40	Done
sapboprd	10.170.61.58	10.207.61.205	Done
sapcrmdi	10.170.61.69	10.207.61.83	Done
	essmssdev	10.170.61.63	10.207.61.210	Done
ttar3dev	10.170.61.22	10.207.61.72	Done
sappoprdc	10.170.61.30	10.207.61.89	Done



Login           Failures Latest failure     From
root                5    07/25/20 00:34:18  10.136.139.21
root                2    07/25/20 00:11:17  10.136.139.21
root                8    07/25/20 00:54:43  10.136.139.21


sapboprd
 Timed out waiting for VMware Tools after 300 seconds


essmssdev
 Timed out waiting for VMware Tools after 300 seconds
 
 
 
 /dev/mapper/epdappvg-usr_sap_EPD_lv
Filesystem state:         clean with errors



A0EASG014XVM003	CHG0166727

----------------------------------


CHG0163380

ms3wdcappsd1    
ms3wdcladb12
ms3wdclapp01
ms3wdcadbsd1   
mdcserverd1
ms3wdclapp06
ms3wdcladb14
ms3wdcladb03b
ms3wdcladb03
mscvertex01
ms3wdcwapp10




ms3wdcladb12	    10.12.6.28	Development - Non HANA
ms3wdclapp01	    10.12.6.12	Development  -  Non HANA
mdcserverd1	   10.12.6.75	Development - SUSE SP4 - HANA VM




Development - V59	Linux	BAPV590800 	10.134.4.13	total 1.23 TB  			Used storage 652.68 GB
Quality  - V32	Linux	BAPV321100 	10.134.4.15		total 1.94 TB			Used storage 1.01 TB
Prodcution  - V33	Linux	BAPV330900 	10.134.3.7	total 1.53 TB			Used storage 1.32 TB
Development - V51	Linux	BAPV510300 	10.134.4.12	total 1.15 TB			Used storage 571.27 GB
Prodcution  - V11	Linux	BAPV110100 	10.134.3.11	total 1.17 TB			Used storage 762.71 GB
Development - V52/J52	Linux	BAPV520500 	10.134.4.11	total 1.67 TB 			Used storage 817.28 GB
Prodcution  - V12/J12	Linux	BAPV120400 	10.134.3.6	total 2.5 TB			Used storage 1.68 TB



CS4035451 AGEAS -- AGEP3 - MinorPlease add additional 10GB space to AGESVSD1SRV01 (SDJ


CS4036334  new raised for enrollment link



CS4042936 Panasonic North America -- PN8P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN8US7LECCQ2- KB0010973
CS4042934 Panasonic North America -- PN8P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN8US7LAP1Q2- KB0010973


CS4045775 Panasonic North America -- PN8P2 - MajorMemory Swap CRITICAL: Swap free 49.99% (thresh 50:%)


CS4057768 P1 - SevereAmerican Airlines -- Z5FUser Reported Issue,VM ISSUE,GENERAL ISSUE




CS4056020 P2 - MajorApple Leisure Group -- AV1Ping Availability CRITICAL - 10.68.213.11: Host unreachable @ 10.143.69.196. rta nan, lost 100%SQ-SAP-TRIO-C2

CS4058183 P2 - MajorApple Leisure Group -- AV1Ping Availability CRITICAL - 10.68.213.12: Host unreachable @ 10.143.69.196. rta nan, lost 100%SQ-SAP-TRIO-C2


Support Cases chevron_right 00243002

PN8US7LDBCP3 / 10.12.255.22
PN8US7LDBCP3H / 10.12.255.23

hb_report -u root -f "2020/08/13 17:00" -t "2020/08/13 19:45" /tmp/hb_report_log

cluster was on maintenance mode
- once cluster was taken out of maintenance mode, the issue happened
- seems there is a miscongiuration/incomplete configuration already presented on the cluster, so after cluster was taken out of maintenance mode it is causing issues (this part needs more investigation)
- right now the team is trying to restore the FS manually to recover the service, and focus on the miscongiuration later on


Aug 13 18:40:58 [3412] pn8us7ldbcp3 stonith-ng:   notice: unpack_config:        On loss of CCM Quorum: Ignore
Aug 13 18:40:58 [3412] pn8us7ldbcp3 stonith-ng:     info: cib_device_update:    Device vcenter-fencing-node1 has been disabled on pn8us7ldbcp3: score=-INFINITY
Filesystem(fs-db2_db2cp3)[51224]:       2020/08/13_18:40:58 INFO: Running start for /dev/cp3logvg/db2_db2cp3_lv on /db2/db2cp3
Filesystem(fs-db2_db2cp3)[51224]:       2020/08/13_18:40:58 ERROR: Couldnâ€™t mount filesystem /dev/cp3logvg/db2_db2cp3_lv on /db2/db2cp3

/db2/CP3 file system wasn't mounted 
5:18 AM
solution
5:18 AM
unmount all sub fs under /db2/CP3
5:18 AM
mount /db2/CP3
5:18 AM
then mount every thing under
5:19 AM
that should do it


Action taken to fix DB2 issue:
-unmount all sub fs under /db2/CP3
-mount /db2/CP3 and then mount every thing under /db2/CP3


[root@pn8us7ldbcp3 ibmrmalik]$ pam_tally2 --reset
Login           Failures Latest failure     From
root               94    07/24/20 12:15:02  10.130.114.85
cmsguest           25    05/24/20 12:16:43  10.130.114.85
aoddba              5    08/13/20 18:00:34
db2cp3              1    08/13/20 19:43:05  pts/16
administrator      21    07/24/20 12:14:40  10.130.114.85
[root@pn8us7ldbcp3 ibmrmalik]$ date
Thu Aug 13 23:42:35 EDT 2020

[root@pn8us7ldbcp3 ibmrmalik]$ chage -l root
Last password change                                    : May 17, 2020
Password expires                                        : Aug 15, 2020
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 1
Maximum number of days between password change          : 90
Number of days of warning before password expires       : -1


[root@pn8us7ldbcp3h ibmrmalik]$ pam_tally2 --reset
Login           Failures Latest failure     From
root               52    07/24/20 12:12:44  10.130.114.85
cmsguest           10    05/24/20 12:14:26  10.130.114.85
aoddba             17    08/13/20 18:00:34
administrator      12    07/24/20 12:12:23  10.130.114.85
ibmdzimmer         15    04/22/20 22:07:24  146.89.142.229
ibmninjam           3    04/11/20 02:48:05  /dev/pts/0
[root@pn8us7ldbcp3h ibmrmalik]$ date
Thu Aug 13 23:43:31 EDT 2020

[root@pn8us7ldbcp3h ibmrmalik]$ chage -l root
Last password change                                    : May 17, 2020
Password expires                                        : Aug 15, 2020
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 1
Maximum number of days between password change          : 90
Number of days of warning before password expires       : -1


 Log file tar ball: /var/log/scc_pn8us7ldbcp3h_200814_0113.txz
 Log file tar ball: /var/log/scc_pn8us7ldbcp3_200814_0113.txz





Pls add 25GB space to each fs...
CS4058294 P2 - MajorPanasonic North America -- PN4Disk Utilization /db2/CQ1/sapdata4 CRITICAL: Free 47656.69MB/9.98% (thresh @5.01:10%)SQ-SAP-TRIO-C2
CS4058295 P2 - MajorPanasonic North America -- PN4Disk Utilization /db2/CQ1/sapdata3 CRITICAL: Free 47656.69MB/9.98% (thresh @5.01:10%)SQ-SAP-TRIO-C2
CS4058318 P2 - MajorPanasonic North America -- PN4Disk Utilization /db2/CQ1/sapdata1 CRITICAL: Free 47608.64MB/9.97% (thresh @5.01:10%)SQ-SAP-TRIO-C2



CHG0164032 15-08-2020 07:00:00	15-08-2020 14:30:00 WDC
	Dominic Arulsamy = Dominic.Arulsamy@mscdirect.com
- Lott Sgueglia = SguegliL@mscdirect.com
- Garrick Hall = Garrick.Hall@mscdirect.com 

ms3iccqa01     	   10.12.6.56	QA
ms3archqa01	   10.12.6.58	QA
msiccqa01	   10.12.6.56	QA


MS3ARCHQA01 10.12.6.58
MS3ICCQA01 10.12.6.56

Automation 
prechecks-CS4071782 An error occurred running the task: Unable to find device MSICCQA01
CHG0168392  full workflow
CHG0168393  patch with reboot



CS4098930 PN5SAPECCT12
CS4099438 PN5SAPECCP12
CS4099800  PENAD15SL
CS4099801  PENAP15SL
CS4100937  PN5SAPECCD12


 CS4123564 Apple Leisure Group -- AV1P2 - MajorPing Availability CRITICAL - 10.68.213.12: rta nan, lost 100%USSAPAWPSQ-SAP-TRIO-C2

 SYSTEM password for SYSTEMDB of INW system
 
 
 
 
 CS4124131 Controladora De Negocios -- CNGP2 - MajorUptime System-Rebooted CRITICAL: uptime: 0:6m, boot: 2020-08-18 10:07:39 (UTC)CROSFLSUA01SQ-SAP-TRIO-C1

 
 Check database is started. Details: Please see https://github.ibm.com/CMS/cms-sq-sap-hana-pe-automation_hana/wiki/Operations:-check-create-adjust-hana-users., SID=INW, INSTANCE NUM=00, TENANT=SYSTEMDB, ADMIN_KEY=INWAUTOMATION, error_code=-10709, error_message=Connection failed (RTE, error_details=System call 'send' failed, rc=104:Connection reset by peer {127.0.0.1:30013})
[2020-08-18T11:23:08+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
sdmiamhdb:/home/ibmrmalik #





CHANGE on 21st Aug at 1130
CHG0167031   21-08-2020 11:30:00   21-08-2020 14:30:00
<Prod>/SAP/<DAL09>/<AUTOMATION>- Apply Latest Q320 Patches on <<WINDOWS>> Servers
grc01	             	10.68.210.15 	10.68.200.15
crosfldcs02		10.68.210.25 	10.68.200.25 	
solman01	        10.68.210.14 	10.68.200.14

MAURICIO MENDEZ MURILLO 	Fabian Perez Chapa



10.211.42.217	wdc04-pod4-4tb-host10.imzcloud.ibmammsap.local
root   / WhkfG3%a1XHsN1@

New enrollment request CS4141132






CS4158095 Tecnologia De Materiales S.A. -- TDMP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TDMPRDHANA- KB0010973TDMPRDHANASQ-SAP-TRIO-C2
CS4158090 Tecnologia De Materiales S.A. -- TDMP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TDMDEVHANA- KB0010973TDMDEVHANASQ-SAP-TRIO-C2
CS4158084 Tecnologia De Materiales S.A. -- TDMP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TDMDEVECC- KB0010973TDMDEVECCSQ-SAP-TRIO-C2
CS4158083 Tecnologia De Materiales S.A. -- TDMP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TDMQASHANA- KB0010973TDMQASHANASQ-SAP-TRIO-C2
CS4158078 Tecnologia De Materiales S.A. -- TDMP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on WEBDISP-         KB0010973WEBDISPSQ-SAP-TRIO-C2
CS4158072 Tecnologia De Materiales S.A. -- TDMP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TDMPRDECC- KB0010973TDMPRDECCSQ-SAP-TRIO-C2
CS4158069 Tecnologia De Materiales S.A. -- TDMP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TDMQASECC- KB0010973TDMQASECCSQ-SAP-TRIO-C2




CHANGE on 21st Aug at 1130
CHG0167031   21-08-2020 11:30:00   21-08-2020 14:30:00
<Prod>/SAP/<DAL09>/<AUTOMATION>- Apply Latest Q320 Patches on <<WINDOWS>> Servers
grc01	             	10.68.210.15 	10.68.200.15	A0DTUS012XVM008_restore1
crosfldcs02		10.68.210.25 	10.68.200.25	A0DTUS012XVM018 	Done
solman01	        10.68.210.14 	10.68.200.14	A0DTUS012XVM007_restore	

MAURICIO MENDEZ MURILLO 	Fabian Perez Chapa





10.143.82.19	dalhana-1024-1.xsportal.local	TDMQASHANA

	
fdXt0n%ximhkmw@




CHG0164775
22-08-2020 14:30:00	22-08-2020 20:30:00
ia2s4hprddb	   10.133.15.36	Production	HANA
ia2s4hprdapp1	   10.133.15.59	Production
ia2s4hprdapp4	   10.133.15.42	Production
ia2s4hprdapp2	   10.133.15.40	Production
ia2s4hprddbh	   10.133.15.37	Production	HANA
ia2s4hprdapp3	   10.133.15.87	Production
ia2s4hprdddr	   10.199.15.207 Production	HANA


CS4187925  Meggitt PLC -- MGG   Memory Swap CRITICAL: Swap free 49.75% (thresh 50:%)   P2


[root@ecctest /]$ lvdisplay |grep -i backuptemp
  LV Path                /dev/backuptempvg/backuptemplv
  LV Name                backuptemplv
  VG Name                backuptempvg

[root@ecctest /]$ df -hT /backupdb
Filesystem                            Type  Size  Used Avail Use% Mounted on
/dev/mapper/backuptempvg-backuptemplv ext4  5.0T   61M  4.8T   1% /backupdb

/dev/mapper/backuptempvg-backuptemplv  /backupdb   ext4




10.162.24.242 - che01ammtsm001
10.162.24.222 - tsleecqa

ECCTEST



CHG0166351
<Non Prod>/SAP/<PAR01>/<MANUAL>- Apply Latest Q320 Patches on <<LINUX>> Servers
25-08-2020 07:00:00	25-08-2020 11:00:00
DPE	Jazril NaaimMohd Jaffar <jazril@my.ibm.com>	
PDL	BogdanDediu <RO69131@ro.ibm.com>		
Mallikarjun V

smdbdevdm1	 10.78.22.38	Development - HANA
smbodevdb3	 10.78.22.14	Development
smemdevdm1	 10.78.22.39	Development
smdbdevds1	 10.78.22.42	Development - HANA
smpodevdx8	 10.78.22.22	Development
smslddevdl0	 10.78.22.21	Development
smhccdevdcc	 10.78.22.51	Development
smsmdevds1	 10.78.22.43	Development
smgwdevdq1	 10.78.22.13	Development
smifadevdf1	 10.78.22.25	Development




CHG0166373
<Non Prod>/SAP/<PAR01>/<MANUAL>- Apply Latest Q320 Patches on <<LINUX>> Servers
28-08-2020 07:00:00	28-08-2020 11:00:00
smdbuatuu3	 10.78.26.24	QA - HANA
smediuatuu3	 10.78.26.25	QA
smdbuatum3	 10.78.26.20	QA - HANA
smgwuatuq3	 10.78.26.11	QA
smemuatum3	 10.78.26.21	QA
smpouatux8	 10.78.26.19	QA



10.116.145.50

Tc5v9VPner		IPMI
	
bb8EHe%ipNJZ67@      root
number:CS1943534  sev1
CS1943400   sev2



CHG0166353	26-08-2020 07:00:00	26-08-2020 11:00:00
smdbdevde1	 10.78.22.17	Development - HANA
smbwdevdw1	 10.78.22.59	Development
smdbdevdw1	 10.78.22.47	Development - HANA
smdidevdd1	 10.78.22.49	Development
smeccdevde1	 10.78.22.18	Development
smgwdevdq2	 10.78.22.24	Development
smsltdevdk1	 10.78.22.44	Development
smgrcdevdg1	 10.78.22.48	Development






BES
sm9d185173005	10.139.224.40, 10.139.224.55	Fixed
sm9h182172003	10.135.224.69		Fixed
sm9h182172004	10.139.224.57, 10.139.224.67, 10.139.224.77   fixed
sm9h182172005	10.139.224.90, 10.139.224.110	Fixed
sm9h182172006	unknown		fixed
sm9l182172016	10.139.224.105	fixed
sm9l182172018	10.139.224.80	fixed
sm9p118217v22	10.135.224.57	fixed
sm9p118217v24	10.139.224.212	fixed


ESOBPCQAP2 	10.139.31.12 	10.254.29.25 	
ESOBPCQAP3 	10.139.31.18   10.254.29.30 no rush, thank you very much in advance




CHG0166364	27-08-2020 07:00:00	27-08-2020 11:00:00

smdbuatuw3	 10.78.26.27	QA -HANA
smeccuatue3	 10.78.26.16	QA
smbouatub3	 10.78.26.12	QA
smcrmuatur3	 10.78.26.18	QA
smdbuatur3	 10.78.26.17	QA -HANA
smbwuatuw3	 10.78.26.28	QA
smdbuatue3	 10.78.26.15	QA -HANA
smgwuatuq2	 10.78.26.23	QA



10.208.79.130	dal13-pod1-4tb-host22.imzcloud.ibmammsap.local


CHG0166373
28-08-2020 07:00:00	28-08-2020 11:00:00
smdbuatuu3	 10.78.26.24	QA - HANA
smediuatuu3	 10.78.26.25	QA
smdbuatum3	 10.78.26.20	QA - HANA
smgwuatuq3	 10.78.26.11	QA
smemuatum3	 10.78.26.21	QA
smpouatux8	 10.78.26.19	QA



10.162.24.222	tata-che01-pod1-phana-6114-2.imzcloud.ibmammsap.local
tsleecqa


/usr/local/bin/enable_dr_3.x.py

SID	Prod Hostname	Prod CFN IP	Prod IFN IP
ECP	sm9l182172003	10.139.224.130	10.135.224.63	present	permission is nobody nobody
ECP	sm9l182172004	10.139.224.52	10.135.224.19	present	permission is nobody nobody	
BWP	sm9l182172005	10.139.224.85	10.135.224.51	present	permission is nobody nobody
BWP	sm9l182172006	10.139.224.197	10.135.224.55	present	permission is nobody nobody

P11	sm9d185173001	10.139.224.187	10.135.224.43	present	permission is nobody nobody
P11	sm9d185173005	10.139.224.40	10.135.224.39	present	permission is nobody nobody

P33	sm9a185173115	10.139.224.97	10.135.224.24	present	permission is nobody nobody
P34	sm9d185173116	10.139.224.15	10.135.224.29	present	permission is nobody nobody
P34	sm9d18517311a	10.139.224.112	10.135.224.26	present and permissions also seems correct saprouter saprouter



# cd /etc/sudoers.d
# ls -ltr
total 4
-r-------- 1 root root 36 Nov 14  2019 jobuser01
# vi jobuser01
# cat jobuser01
jobuser01 ALL=(ALL)   NOPASSWD: ALL


when we login as custapp user in essmssdev , we want this user to be able to
1 - Sudo to "epdadm" and "oraepd"




user_list host_list=effective_user_list tag_list command_list
custapp=(epdadm,oraepd) NOPASSWD


user1    ALL=(user2) NOPASSWD: /bin/bash
custapp ALL=(epdadm) NOPASSWD:ALL
custapp ALL=(oraepd) NOPASSWD:ALL



 TSLEECQA - 10.207.63.14	10.170.63.15
 
 
 
CS4334940 AGEAS -- AGEP2 - MajorMemory Pagefile total 199.992MB (200MB)
CS4334928 AGEAS -- AGEP2 - MajorPerfdata Virtual total 199.992MB (200MB)
CS4333862 AGEAS -- AGEP2 - MajorMemory Pagefile total 199.992MB (200MB)
CS4333846 AGEAS -- AGEP2 - MajorPerfdata Virtual total 199.992MB (200MB)



Thu Sep  3 07:40:13 2020 TLS_ERROR: BIO read tls_read_plaintext error
Thu Sep  3 07:40:13 2020 TLS Error: TLS object -> incoming plaintext read error
Thu Sep  3 07:40:13 2020 TLS Error: TLS handshake failed
Thu Sep  3 07:40:13 2020 SIGUSR1[soft,tls-error] received, process restarting
Thu Sep  3 07:40:13 2020 Restart pause, 5 second(s)


CHG0169972
04-09-2020 07:00:00	04-09-2020 11:00:00
smdsquaqo1q71	 10.78.24.27	QA
smeccquaqe1	 10.78.24.19	QA
smdbquaqe1	 10.78.24.18	QA
smdbquaqr3	 10.78.24.20	QA
smdbquaqw3	 10.78.24.40	QA
smcrmquaqr3	 10.78.24.21	QA
smbwquaqw3	 10.78.24.41	QA
smsltquaqk1	 10.78.24.39	QA



CS4366098- new enrollment link for mobipass


Ticket: CS4373619
Channel: #mcx-na-tech1
Webex: https://ibm.webex.com/meet/salihin
Impacted Host: wdc04-pod4-4tb-host01
Impacted VMs all non prods:
1) Wakefern - WKFDS2DB01 (vHANA)cant connect
2) Wakefern - WKFDR1DB01 (vHANA)cant login
3) Coty - ctubwdb0db01 (vHANA)
4) Coty - ctubwdb3db01 (vHANA)
5) Coty - ctubwsb3db01 (vHANA)



CS4380254	COTY Inc. -- CTU	P1 - Severe	Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)	SQ-SAP-TRIO-C2
CS4380248	COTY Inc. -- CTU	P1 - Severe	Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)	SQ-SAP-TRIO-C2
CS4380229	COTY Inc. -- CTU	P1 - Severe	Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)	SQ-SAP-TRIO-C2



AAAAB3NzaC1yc2EAAAADAQABAAABAQCvtY3KqcuXzZbc5K3LiaH1MXtIHrs0zGnhUt+kRGsrvnzMmhNgPoXItYLZ1nMsxXRvOQBTfmM8w0O6Tww2iFR9JvpNzBT97zFW2C1CWjCZ3pX4MFQKziIU1oPq4qtXcTWU6LUxmJTr4V2UKDMoQte+7gKfedVXQw0GO9jiV48SXb1B5GyyWRI9whI44bV6f6JagyEYqXIBalW89QeQ/VzXbSmexvqe/6Kx+uYdxawkRI+42WASA9ggGpoESQQ2UMEkIy/+MdKksAZ7vQfMO2mPjLyxgRLHVk5ld0HvxJEBwubqeWa70LBFH7+wedcRLCDCruNMe5RoRpPOpXDx1Z+l Ravi Malik;IBMUS5g5726897;IBMUSc-hrrj897;N

ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCvtY3KqcuXzZbc5K3LiaH1MXtIHrs0zGnhUt+kRGsrvnzMmhNgPoXItYLZ1nMsxXRvOQBTfmM8w0O6Tww2iFR9JvpNzBT97zFW2C1CWjCZ3pX4MFQKziIU1oPq4qtXcTWU6LUxmJTr4V2UKDMoQte+7gKfedVXQw0GO9jiV48SXb1B5GyyWRI9whI44bV6f6JagyEYqXIBalW89QeQ/VzXbSmexvqe/6Kx+uYdxawkRI+42WASA9ggGpoESQQ2UMEkIy/+MdKksAZ7vQfMO2mPjLyxgRLHVk5ld0HvxJEBwubqeWa70LBFH7+wedcRLCDCruNMe5RoRpPOpXDx1Z+l root@oc4233460376.ibm.com


top - 09:46:02 up 57 days,  7:07,  3 users,  load average: 2.22, 2.62, 2.45
Tasks: 460 total,   1 running, 459 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1.4 us,  0.5 sy,  0.0 ni, 98.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  25173289+total, 24810131+used,  3631580 free,     6556 buffers
KiB Swap:  2097148 total,  2000168 used,    96980 free. 10968364 cached Mem

   PID USER      PR  NI    VIRT    RES    SHR S   %CPU  %MEM     TIME+   SWAP COMMAND
  2895 gdm       20   0 5301876 3.603g   7392 S  0.987 1.501 749:19.51  99680 gnome-shell --mode=gdm
  2735 root      20   0  288872   7028      0 S  0.000 0.003   0:00.00  46108 /usr/bin/python /usr/bin/salt-minion
  2222 root      20   0  193836   3128     12 S  0.000 0.001   0:00.34  44324 /usr/bin/python /usr/bin/salt-minion
 32860 root      20   0  226648    216    124 S  0.000 0.000   0:05.14  33780 /usr/local/ncpa/ncpa_listener --start
  2204 root      20   0 2212128 1.899g  16420 S  0.000 0.791 118:39.74  33372 /opt/tivoli/tsm/tdp_hana/prole -p tdphana
  2369 root      20   0  974164 218192   6332 S  0.000 0.087  43:56.19  23168 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
  2218 root      20   0  155844  25448   2348 S  0.000 0.010   0:07.15  19492 /opt/chef/embedded/bin/ruby --disable-gems /usr/bin/chef-client -c /etc/chef/client.rb +
 22880 root      35  15 1142304  56216   2092 S  0.000 0.022  41:51.21  18800 /opt/monitor/tivoli/client/../_jvm-client/jre/bin/java -Djava.compiler=NONE -Xmx1024m -+
  2860 qt1adm    20   0  766148   2760      0 S  0.000 0.001  39:47.04  16268 /usr/sap/QT1/HDB22/exe/sapstartsrv pf=/usr/sap/QT1/SYS/profile/QT1_HDB22_qlaqt1s4hadb -+
 55857 qt1adm    20   0 4536224   1500   1196 S  0.000 0.001   7:33.32  14752 hdbrsutil  --start --port 32240 --volume 2 --volumesuffix mnt00001/hdb00002.00003 --ide+
 48971 qt1adm    20   0  669608   1372   1040 S  0.329 0.001   7:24.32  14728 hdbrsutil  --start --port 32201 --volume 1 --volumesuffix mnt00001/hdb00001 --identifie+
  2864 sapadm    20   0 2188256  55072  39728 S  0.329 0.022 121:23.49  14664 /usr/sap/hostctrl/exe/sapstartsrv pf=/usr/sap/hostctrl/exe/host_profile -D
  2432 root      20   0  434636    656      0 S  0.000 0.000   0:28.27  12564 /usr/bin/Xorg :0 -background none -verbose -auth /run/gdm/auth-for-gdm-EblF5o/database +
  3242 root      20   0 5032640 306012      4 S  1.316 0.122   2278:48   8148 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R



Case Number: CS1957982
Description: ETA required to replace Compute Book and upgrade firmware on tsleecprddb (tata-che01-pod1-phana-6114-1.imzcloud.ibmamm

tata-che01-pod1-phana-6114-1.imzcloud.ibmammsap.local


bes
sm9temphdb	
sm9p185173114	unknown
sm9v235532009	10.139.224.25
sm9h185173116	10.135.224.45



CS4423751
Add users/groups to qlaqp1s4haap.
Please ensure that the following groups are present and ensure the users are added and allocated to the correct groups.

Grp name:
scappsupport	

[root@qlaqp1s4haap ibmrmalik]# cat /etc/group |grep -i scappsupport
scappsupport:x:54750:


Priv:
(root) NOPASSWD: 
sudo /bin/su [-] sapdcprd
sudo /bin/su [-] mqm"

Grp name:
p2pappsupport

[root@qlaqp1s4haap ibmrmalik]# cat /etc/group |grep -i p2pappsupport
p2pappsupport:x:54751:

Priv:
(root) NOPASSWD: 
sudo /bin/su [-] sapdcprd

Group: 
cnwme

[root@qlaqp1s4haap ibmrmalik]# cat /etc/group |grep -i cnwme
cnwme:x:54812:


Priv:
(root) NOPASSWD: /bin/su [-] mqm

User ID 	User Group Name
annirose	staff, p2pappsupport
[root@qlaqp1s4haap ibmrmalik]# getent passwd annirose
annirose:x:54726:100:744/I/088734/IBM/ROSE.ANNIE REENA (ANNIE REENA)/:/home/annirose:/bin/bash

[root@qlaqp1s4haap ibmrmalik]# id annirose
uid=54726(annirose) gid=100(users) groups=100(users)

[root@qlaqp1s4haap ibmrmalik]# id annirose
uid=54726(annirose) gid=100(users) groups=100(users),54751(p2pappsupport),54813(staff)


jegadeesh	staff, p2pappsupport	user not present


vbchaudh	staff, p2pappsupport	
[root@qlaqp1s4haap ibmrmalik]# getent passwd vbchaudh
vbchaudh:x:54727:100:744/I/04104Z/IBM/Chaudhari.Vijay B (Vijay)/:/home/vbchaudh:/bin/bash

[root@qlaqp1s4haap ibmrmalik]# id vbchaudh
uid=54727(vbchaudh) gid=100(users) groups=100(users)

[root@qlaqp1s4haap ibmrmalik]# id vbchaudh
uid=54727(vbchaudh) gid=100(users) groups=100(users),54751(p2pappsupport),54813(staff)


shirisp1	staff, scappsupport	user not present


manasbha	staff, scappsupport	 
[root@qlaqp1s4haap ibmrmalik]# id manasbha
uid=54729(manasbha) gid=100(users) groups=100(users)

[root@qlaqp1s4haap ibmrmalik]# id manasbha
uid=54729(manasbha) gid=100(users) groups=100(users),54750(scappsupport)

[root@qlaqp1s4haap ibmrmalik]# getent passwd manasbha
manasbha:x:54729:100:744/I/079718/IBM/Bhat.Manasa/:/home/manasbha:/bin/bash


ruchikmi 	staff, scappsupport	user not present

rkumar81	staff, scappsupport	user not present

grcheeli	staff, scappsupport	user not present


huangchm	staff, cnwme		
root@qlaqp1s4haap ibmrmalik]# id huangchm
uid=54723(huangchm) gid=100(users) groups=100(users)

[root@qlaqp1s4haap ibmrmalik]# getent passwd huangchm
huangchm:x:54723:100:672/I/215899/IBM/Huang.Chun ming/:/home/huangchm:/bin/bash

[root@qlaqp1s4haap ibmrmalik]# id huangchm
uid=54723(huangchm) gid=100(users) groups=100(users),54812(cnwme),54813(staff)


ygqiang	        staff,cnwme		
[root@qlaqp1s4haap ibmrmalik]# id ygqiang
uid=54724(ygqiang) gid=100(users) groups=100(users)

[root@qlaqp1s4haap ibmrmalik]# getent passwd ygqiang
ygqiang:x:54724:100:672/I/215229/IBM/Yang guo Qiang/:/home/ygqiang:/bin/bash

[root@qlaqp1s4haap ibmrmalik]# id ygqiang
uid=54724(ygqiang) gid=100(users) groups=100(users),54812(cnwme),54813(staff)


gaoxuz	        staff,cnwme		 
[root@qlaqp1s4haap ibmrmalik]# id gaoxuz
uid=54725(gaoxuz) gid=100(users) groups=100(users)

[root@qlaqp1s4haap ibmrmalik]# getent passwd gaoxuz
gaoxuz:x:54725:100:672/I/091263/IBM/Xu zhao Gao/:/home/gaoxuz:/bin/bash

[root@qlaqp1s4haap ibmrmalik]# id gaoxuz
uid=54725(gaoxuz) gid=100(users) groups=100(users),54812(cnwme),54813(staff)


wbaw	        staff,cnwme		user not present





CHG017061
victor.sangeorzan@ro.ibm.com;Gratiela.Novac@ibm.com;Harbi.Heer@csiltd.co.uk

psweb	        10.197.2.41	Development
psqasap	10.197.2.21	QA
psqasdb	10.197.2.20	QA  | HANA
psdevap	10.197.2.11	Development
psdevasjava	10.197.2.43	Development
psdevdb	10.197.2.10	Development  | HANA


br3qgtsas35
br3qgtsas36

#/dev/qgtappvg/qgtsapmnt_lv     /sapmnt/QGT     ext3    _netdev,defaults        1       2
#/dev/qgtappvg/usrtrans_lv      /usr/sap/trans  ext3    _netdev,defaults        1       2
/dev/qgtappvg/qgt3rdprty_lv     /3rdPartySoftware/QGT   ext3    _netdev,defaults        1       2
/dev/qgtappvg/qgtIntface_lv     /interface/QGT  ext3    _netdev,defaults        1       2
/dev/qgtappvg/sapstage_lv       /sapstage       ext3    _netdev,defaults        1       2
/dev/qgtappvg/backup_lv /backup ext3    _netdev,defaults        1       2
#mount from cluster
#ssapp-br3-qgt:/export/sapmnt/QGT        /sapmnt/QGT  nfs     soft,vers=3 0 0
##ssapp-br3-qgt:/export/usr/sap/trans     /usr/sap/trans  nfs     soft,vers=3 0 0
#ssapp-br3-qgt:/export/3rdPartySoftware/QGT     /3rdPartySoftware/QGT    nfs     soft,vers=3 0 0
#ssapp-br3-qgt:/export/interface/QGT            /interface/QGT   nfs     soft,vers=3 0 0
#10.3.112.147:/talend-qa/QA /usr/sap/BRPData/QA/ nfs rw 0 0
#10.3.112.22:/usr/sap/trans /usr/sap/trans      nfs defaults 0 0
[root@br3qgtsas36 SYS]$



CHG0170110  <Non Prod>/SAP/<PAR01>/<MANUAL>- Apply Latest Q320 Patches on <<LINUX>> Servers
10-09-2020 07:00:00	10-09-2020 11:00:00
smgwquaqq1	 10.78.24.14	QA
smdbquaqm3	 10.78.24.25	QA
smgwquaqq2	 10.78.24.35	QA
smgrcquaqg1	 10.78.24.43	QA
smifaquaqf1	 10.78.24.44	QA
smediquaqu3	 10.78.24.32	QA
smpoquaqx8	 10.78.24.22	QA
smemquaqm3	 10.78.24.26	QA
smdbquaqu3	 10.78.24.31	QA
smboquaqb3	 10.78.24.15	QA

OS Ravi Malik
SAP Sudha and Surendra

jazril@my.ibm.com;RO69131@ro.ibm.com	

 
https://ibmma.service-now.com/sn_customerservice_case.do?sysparm_tiny=f022d75bdb439c18883d06e2ca961970
CS4449467Concessionaria Aeroporto Rio de Jan -- CONP2 - MajorMemory Swap CRITICAL: Swap free 49.99% (thresh 50:%)


usc-hrrj
Requested as Account/Access: 	rmaliknew on IBM:GSNI-LDAP



roshan.mandal@careinsurance.com



CS4456103 - P2 - User Reported Issue,VM ISSUE,GENERAL ISSUE,CUSTOMER'S VM ISSUE  |linux |da7qasdbapp01 is only reachable via ssh with root, chef gives errors  |OS to follow up with chef team on issue #5289 and also check if anolroy@us.ibm.com can help on this as per recommendation
root pw H?BWyV16Z9]_/EX

Sep 10 19:22:47 da7qasdbapp01 postfix/error[26063]: 57AB36F: to=<usfssa@us.ibm.com>, relay=none, delay=13536, delays=313536/0.01/0/0.01, dsn=4.4.1, status=deferred (delivery temporarily suspended: connect t mx0b-001b2d01.pphosted.com[148.163.158.5]:25: Connection timed out)
Sep 10 19:37:47 da7qasdbapp01 postfix/error[70649]: ADA4765: to=<usfssa@us.ibm.com>, relay=none, delay=15417, delays=315416/0.01/0/0.01, dsn=4.4.1, status=deferred (delivery temporarily suspended: connect t mx0b-001b2d01.pphosted.com[148.163.158.5]:25: Connection timed out)
Sep 10 19:37:47 da7qasdbapp01 postfix/error[70650]: 778FD8B: to=<usfssa@us.ibm.com>, relay=none, delay=11261, delays=311261/0.01/0/0.01, dsn=4.4.1, status=deferred (delivery temporarily suspended: connect t mx0b-001b2d01.pphosted.com[148.163.158.5]:25: Connection timed out)
[root@da7qasdbapp01 etc]# date
Thu Sep 10 19:47:48 MDT 2020



sudo su
curl -O https://packages.microsoft.com/keys/microsoft.asc
rpm --import microsoft.asc

#Download appropriate package for the OS version
#Choose only ONE of the following, corresponding to your OS version

#SUSE Linux Enterprise Server 11 SP4
#Ensure SUSE Linux Enterprise 11 Security Module has been installed 
zypper ar https://packages.microsoft.com/config/sles/11/prod.repo

#SUSE Linux Enterprise Server 12
zypper ar https://packages.microsoft.com/config/sles/12/prod.repo

#SUSE Linux Enterprise Server 15
zypper ar https://packages.microsoft.com/config/sles/15/prod.repo
#(Only for driver 17.3 and below)
SUSEConnect -p sle-module-legacy/15/x86_64

exit
sudo ACCEPT_EULA=Y zypper install msodbcsql17
# optional: for bcp and sqlcmd
sudo ACCEPT_EULA=Y zypper install mssql-tools
echo 'export PATH="$PATH:/opt/mssql-tools/bin"' >> ~/.bash_profile
echo 'export PATH="$PATH:/opt/mssql-tools/bin"' >> ~/.bashrc
source ~/.bashrc
# optional: for unixODBC development headers
sudo zypper install unixODBC-devel


[root@lbuds1db01 tmp]# rpm -ivh /tmp/msodbcsql17-17.6.1.1-1.x86_64.rpm
warning: /tmp/msodbcsql17-17.6.1.1-1.x86_64.rpm: Header V4 RSA/SHA256 Signature, key ID be1229cf: NOKEY
error: Failed dependencies:
       libodbcinst.so.2()(64bit) is needed by msodbcsql17-17.6.1.1-1.x86_64
        unixODBC >= 2.3.1 is needed by msodbcsql17-17.6.1.1-1.x86_64


CHG0167970	11-09-2020 07:00:00	11-09-2020 13:30:00
<Prod>/SAP/<FRA02>/<MANUAL>- Apply Latest Q320 Patches on <<LINUX>> Servers
egrs4hprdapp	10.135.5.13	Production
egrs4hprddb	10.135.5.12	Production - hana server - hana version 2.00.037.04 (Please patch SLES12 SP2 to latest versions in SP2 in order to avoid any issues with customer 3rd parties interfaces)
egrsolmanprd	10.135.5.11	Production	SXSvn9RbyfnpEFA
egrwd-prd	        10.135.5.14	  Production



ACEROSPRDECC	10.4.11.31	
ACEROSPRDHANA	10.4.11.30



PSM /PSJ â€“ SOLMAN / PROD    dcghanasoldb1    10.197.5.12    LINUX
10.164.30.236	lonhana-1024-32.xsportal.local		root cTw1yq%Byyhwd5@	10.164.30.239	J7F9ydNWnX


PSM /PSJ â€“ SOLMAN / PROD    dcghanasoldb2    10.197.5.13    LINUX
10.164.30.199	lonhana-1024-33.xsportal.local		root 4w1og2%LAzJJZA@	10.164.30.225	Cn9dLxdb2z



10.127.235.182	parhana-1024-18.xsportal.local	10.127.235.183
root 38cUIB%IOr8Yow@

IPMI F8c5phk9pQ   10.127.235.183





/dev/mapper/vg00-lv_swap

[root@AHECPSAP01 ibmrmalik]$ lvdisplay |grep -i swap
  LV Path                /dev/vg00/lv_swap
  LV Name                lv_swap
  
  
  [root@AHECPSAP01 /]$ swapon -s
Filename                                Type            Size    Used    Priority
/dev/dm-1                               partition       67911676        14896780        -1


[root@AHECPSAP01 dev]$ ls -lh /dev/dm-1
brw-rw----. 1 root disk 253, 1 Sep 12 07:24 /dev/dm-1


[root@AHECPSAP01 dev]$ swapoff -a -v
swapoff on /dev/mapper/vg00-lv_swap


[root@AHECPSAP01 dev]$ blkid |grep swap
/dev/mapper/vg00-lv_swap: UUID="458b7bb7-d9df-43bf-8c43-aedaae4ae390" TYPE="swap"


bigfix
mrt-qut-test
qut-smp-dbapp
qut-erp-dbapp

npsv059	        165.88.67.73 OR
cordali01	165.88.67.9, i think this might be similar case


Source - CFN IP: 192.168.78.17  and IFN IP: 10.198.3.7
PAth /usr/sap/trans/data/RX00023.PRD
Destination - CFN IP: 192.168.80.12 and IFN IP: 10.198.5.12
PAth /usr/sap/trans/data


/dev/mapper/ebpappvg-daaadm_lv                ext4      976M  1.3M  908M   1% /home/daaadm
/dev/mapper/ebpappvg-sapadm_lv                ext4      976M  1.3M  908M   1% /home/sapadm
/dev/mapper/ebpappvg-usr_sap_lv               ext4      4.8G   10M  4.6G   1% /usr/sap
/dev/mapper/ebpappvg-usr_sap_ccms_lv          ext4      3.9G  8.0M  3.6G   1% /usr/sap/ccms
/dev/mapper/ebpappvg-usr_sap_DAA_lv           ext4      3.9G  8.0M  3.6G   1% /usr/sap/DAA


1006  2020-09-17 10:06:14 mkdir -p /usr/sap/EBP
 1019  2020-09-17 10:08:52 chmod 755 /usr/sap/EBP
 1025  2020-09-17 10:13:29 lvcreate -L 24G ebpappvg -n usr_sap_EBP_lv
 1026  2020-09-17 10:13:48 lvs |grep EBP
 1027  2020-09-17 10:16:41 df -hT /usr/sap/EBP
 1029  2020-09-17 10:17:07 lvextend -L +8G /dev/mapper/ebpappvg-usr_sap_EBP_lv 
 1030  2020-09-17 10:17:13 resize2fs /dev/mapper/ebpappvg-usr_sap_EBP_lv 
 1031  2020-09-17 10:17:17 df -hT /usr/sap/EBP
 1059  2020-09-17 10:38:37 df -hT /usr/sap/EBP
 1060  2020-09-17 10:38:53 df -hT |grep /usr/sap/EBP
 1061  2020-09-17 10:39:06 cd /usr/sap/EBP
 1062  2020-09-17 10:39:44 df -hT /usr/sap/EBP
 1066  2020-09-17 10:40:29 df -hT /dev/mapper/ebpappvg-usr_sap_EBP_lv
 1067  2020-09-17 10:41:27 lvdisplay |grep /dev/mapper/ebpappvg-usr_sap_EBP_lv
 1068  2020-09-17 10:41:59 df -hT /usr/sap/EBP
 1069  2020-09-17 10:42:29 history |grep EBP

[root@zffpappdb015 sap]# lvdisplay /dev/mapper/ebpappvg-usr_sap_EBP_lv
  --- Logical volume ---
  LV Path                /dev/ebpappvg/usr_sap_EBP_lv
  LV Name                usr_sap_EBP_lv
  VG Name                ebpappvg
  

Filesystem                               Type  Size  Used Avail Use% Mounted on
	
/dev/mapper/ebpappvg-home_ebpadm_lv      ext4   /home/ebpadm	ext4       defaults        1 2
	/dev/mapper/ebpappvg-sapadm_lv              /home/sapadm	ext4       defaults        1 2
	/dev/mapper/ebpappvg-usr_sap_DAA_lv         /usr/sap/DAA	ext4       defaults        1 2
	/dev/mapper/ebpappvg-usr_sap_ccms_lv        /usr/sap/ccms	ext4       defaults        1 2
	/dev/mapper/ebpappvg-usr_sap_lv             /usr/sap	ext4       defaults        1 2
	/dev/mapper/ebpappvg-daaadm_lv  	/home/daaadm  ext4       defaults        1 2
	
	/dev/mapper/ebpappvg-usr_sap_EBP_lv          /usr/sap/EBP	ext4       defaults        1 2



[ibmrmalik@zffpappdb015 /]$ df -hT |grep oracle*
/dev/mapper/ebpappvg-oracle_EBP_lv            ext4       28G   12G   15G  47% /oracle/EBP
/dev/mapper/ebpappvg-oracle_stage_EBP_lv      ext4       11G  6.8G  3.4G  67% /oracle/stage_EBP
/dev/mapper/ebplogvg-oracle_EBP_mirrorlogA_lv ext4      953M  1.2M  887M   1% /oracle/EBP/mirrorlogA
/dev/mapper/ebplogvg-oracle_EBP_mirrorlogB_lv ext4      953M  1.2M  887M   1% /oracle/EBP/mirrorlogB
/dev/mapper/ebplogvg-oracle_EBP_origlogA_lv   ext4      973M  422M  485M  47% /oracle/EBP/origlogA
/dev/mapper/ebpdatavg-oracle_EBP_sapdata1_lv  ext4       99G   73G   21G  79% /oracle/EBP/sapdata1
/dev/mapper/ebplogvg-oracle_EBP_origlogB_lv   ext4      945M  422M  459M  48% /oracle/EBP/origlogB
/dev/mapper/ebparchvg-oracle_EBP_sapreorg_lv  ext4      3.9G   88M  3.6G   3% /oracle/EBP/sapreorg
/dev/mapper/ebparchvg-oracle_EBP_oraarch_lv   ext4      9.5G   22M  9.0G   1% /oracle/EBP/oraarch


[root@zffpappdb015 local]# cat /etc/fstab |grep -i oracle
/dev/ebpappvg/oracle_EBP_lv   /oracle/EBP        ext4       defaults        1 2
/dev/ebpdatavg/oracle_EBP_sapdata1_lv   /oracle/EBP/sapdata1        ext4       defaults        1 2
/dev/ebparchvg/oracle_EBP_oraarch_lv   /oracle/EBP/oraarch        ext4       defaults        1 2
/dev/ebplogvg/oracle_EBP_mirrorlogA_lv   /oracle/EBP/mirrorlogA        ext4       defaults        1 2
/dev/ebplogvg/oracle_EBP_mirrorlogB_lv   /oracle/EBP/mirrorlogB        ext4       defaults        1 2
/dev/ebplogvg/oracle_EBP_origlogA_lv   /oracle/EBP/origlogA        ext4       defaults        1 2
/dev/ebplogvg/oracle_EBP_origlogB_lv   /oracle/EBP/origlogB        ext4       defaults        1 2
/dev/ebparchvg/oracle_EBP_sapreorg_lv   /oracle/EBP/sapreorg        ext4       defaults        1 2
/dev/ebpappvg/oracle_stage_EBP_lv   /oracle/stage_EBP        ext4       defaults        1 2


clsdwq01 - 10.9.2.35 - Unable to connect to server , No login prompt - CS4536923
dyss4apsbd41 - 10.6.12.18 , /usr/sap mount is having errors - CS4530554


CHE01POOL1DS321_migration
CHE01POOL1DS349		migrating bs5prdapp1 

ecctest
sappoprdc




we need to create on FS /oracle/BOD/19800 of 30G .. issme catch yeh hai it should be under /oracle/BOD plus mounted as /oracle/BOD/19800 ... u can refer /oracle/BOD/11204 means /oracle/BOD parent child as a seaparate mount /oracle/BOD/19800



ot@sapbodev BOD]$ df -hT /oracle/BOD/11204
Filesystem                               Type  Size  Used Avail Use% Mounted on
/dev/mapper/bodlogvg-oracle_BOD_11204_lv ext4   19G  5.9G   12G  34% /oracle/BOD/11204


[root@sapbodev BOD]$ lvdisplay |grep BOD_19800
  LV Path                /dev/bodlogvg/oracle_BOD_19800_lv
  LV Name                oracle_BOD_19800_lv


[root@sapbodev BOD]$ df -hT /oracle/BOD/*
Filesystem                                    Type  Size  Used Avail Use% Mounted on
/dev/mapper/bodlogvg-oracle_BOD_11204_lv      ext4   19G  5.9G   12G  34% /oracle/BOD/11204

[root@sapbodev BOD]$ df -hT /oracle/BOD*
Filesystem                         Type  Size  Used Avail Use% Mounted on
/dev/mapper/bodlogvg-oracle_BOD_lv ext4  4.4G  914M  3.3G  22% /oracle/BOD



/dev/mapper/bodlogvg-oracle_BOD_19800_lv 	/oracle/BOD/19800	ext4



\\172.22.5.20\CUSTOMER-PO\SAP_DOWNLOAD	/interfaces/SAPReports/3325  cifs username=mplc1\mee-sd-sap,passwd=M3ggitt2020!,_netdev,defaults 0 0

//10.230.10.249/departments/rockVIEW/Data\046Systems/Sap\046Reports/Sap\046Downloads  /interfaces/SAPReports/3110 cifs   credentials=/etc/credentialsDownloads3110,uid=eepadm,gid=sapsys,rw 0 0

//10.230.10.249/departments/rockVIEW/Data\040Systems/SAP\040Reports/SAP\040Downloads  /interfaces/SAPReports/3110 cifs   credentials=/etc/credentialsDownloads3110,uid=eepadm,gid=sapsys,rw 0 0

//172.22.5.20/CUSTOMER-PO/SAP_DOWNLOAD  /interfaces/SAPReports/3325     cifs    credentials=/etc/credentialsDownloads989,uid=eepadm,gid=sapsys,rw 0 0

mount -vvv -t cifs -o username=mee-sd-sap,password=M3ggitt2020!,domain=mplc1 //172.22.5.20/CUSTOMER-PO/SAP_DOWNLOAD  /interfaces/SAPReports/3325

user ID - mplc1\mee-sd-sap
Pass: M3ggitt2020!


username=mplc1\mee-sd-sap
password=M3ggitt2020!


mount -t cifs //172.22.5.20/CUSTOMER-PO/SAP_DOWNLOAD  /interfaces/SAPReports/3325 sec=ntlmv2,domain=MYDOMAIN,username=myusername,password=mypassword


[root@IA1S4HPRDAPP backupravi]$ df -hT /usr/sap/SP1
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/sp1appvg-sp1usrSP1_lv
                     ext3  126G   20G  100G  17% /usr/sap/SP1
[root@IA1S4HPRDAPP backupravi]$  df -hT /sapmnt/SP1
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/sp1appvg-sp1sapmnt_lv
                     ext3  339G   12G  311G   4% /sapmnt/SP1



Tc5v9VPner	10.116.145.50


Node Attributes:
* Node tgyerpprddb1:
    + hana_pe1_clone_state              : DEMOTED
    + hana_pe1_op_mode                  : logreplay
    + hana_pe1_remoteHost               : tgyerpprddb2
    + hana_pe1_roles                    : 4:S:master1:master:worker:master
    + hana_pe1_site                     : NODEA
    + hana_pe1_srmode                   : sync
    + hana_pe1_sync_state               : SOK
    + hana_pe1_version                  : 1.00.122.30.1582793455
    + hana_pe1_vhost                    : tgyerpprddb1
    + lpa_pe1_lpt                       : 30
    + master-rsc_SAPHana_PE1_HDB00      : 100
* Node tgyerpprddb2:
    + hana_pe1_clone_state              : PROMOTED
    + hana_pe1_op_mode                  : logreplay
    + hana_pe1_remoteHost               : tgyerpprddb1
    + hana_pe1_roles                    : 4:P:master1:master:worker:master
    + hana_pe1_site                     : NODEB
    + hana_pe1_srmode                   : sync
    + hana_pe1_sync_state               : PRIM
    + hana_pe1_version                  : 1.00.122.30.1582793455
    + hana_pe1_vhost                    : tgyerpprddb2
    + lpa_pe1_lpt                       : 1600513321
    + master-rsc_SAPHana_PE1_HDB00      : 150


TGYERPPRDDB2 to TGYERPPRDDB1

su - pe1adm -c "hdbnsutil -sr_register --remoteHost=tgyerpprddb1 --remoteInstance=<instance_number> --replicationMode=sync --operationMode=logreplay --name=tgyerpprddb2"

to get the instance no for the above

su - sidadm

To failover db from one to the other node


STop pacemaker on the node that is primary(all resources move to secondary)
chk crm_mon -1Afr and see if the secondary has now become primary
Start pacemaker on the same node where it was stopped(now secondary)
register the new node
su - <SID>adm -c "hdbnsutil -sr_register --remoteHost=<PRIMARY_hostname> --remoteInstance=<instance_number> --replicationMode=sync --operationMode=logreplay --name=<SECONDARY_name>"

sid can be fetched from the banner at the login screen or ask SAP and the instance no can be fetched by logging into the node and su - sidadm
[root@tgyerpprddb1 ~]# su - pe1adm
pe1adm@tgyerpprddb1:/usr/sap/PE1/HDB00>
the number after HDB above is the instance no

check replication status with
python systemReplicationStatus.py

for failback its viceversa

refer 
https://github.ibm.com/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/03a_Planned_Failover.md



CS4582331	P1 - Severe	Tech Data Corporation -- ZEC	zec#ITM Agent Offline: zec_gbwpas4:KUX	SQ-SAP-TRIO-B2	UNIX no access
CS4582326	P1 - Severe	Tech Data Corporation -- ZEC	zec#ITM Agent Offline: zec_gbwpyaci2:KUX	SQ-SAP-TRIO-B2	UNIX no access
CS4582294	P1 - Severe	Tech Data Corporation -- ZEC	zec#ITM Agent Offline: zec_tdasappa2as6:KUX	SQ-SAP-TRIO-B2
CS4582489	P1 - Severe	Tech Data Corporation -- ZEC	zec#ITM Agent Offline: zec_tdesapqrtas0:KUX	SQ-SAP-TRIO-B2



CHE01POOL1POD1DSP437,Normal,NFS,,23.44 TB,12.25 TB,25.16 TB
349 to 493


a0easg014xvm001 - 10.70.110.11 - AGEAS -- AGE
agehvcpmhsrv0 - 10.8.3.15 - AGEAS -- AGE
sphvepaeapp02-dr - 10.6.3.12 - AGEAS -- AGE
spsvbpdbhdb01 - 10.6.3.17 - AGEAS -- AGE 
svbq1hdbsrv0 - 10.6.2.13 - AGEAS -- AGE


1.x
MHAS
SEI
TTA - EWM and CRM Applications HA Migration

Naveen Bellary to Lori Nevaraz

Pooja and Shreya SOW renewal  3112



CS4592757 Panariagroup Industrie Ceramiche SP -- PNCCheck NFS mount on ECP system
As consequence of the planned   change to add 2 new vcpu to CLDSMTP01 (10.134.175.150) will be performed tomorrow morning (Sept 24th) in the time window from 04:00 to 08:00am (CET), because IBM Cloud requires a 4h time window.
After the change (after the 8.00 AM CET) is required to check  all the  NFS mounts on ECP system.
PNCAPECCP	10.126.71.25	10.199.1.25
PNCAPECCP1	10.126.71.36	10.199.1.36

[root@pncapeccp1 ibmrmalik]$ cat /etc/fstab |grep -i "10.134.175.150"
	//10.134.175.150/Kyriba /usr/sap/kyriba cifs credentials=/etc/kyriba_credential,uid=20000,gid=3050
	//10.134.175.150/FTI /usr/sap/FTI cifs credentials=/etc/FTI_credential,uid=20000,gid=3050
	//10.134.175.150/Employees /usr/sap/employees cifs credentials=/etc/employees_credential,uid=20000,gid=3050,sec=ntlm
//10.134.175.150/Elavon/ /usr/sap/elavon cifs rw,file_mode=0444,dir_mode=0444,suid,username=PO,password=Sap!2016 0 0
//10.134.175.150/Concur/ /usr/sap/concur cifs rw,file_mode=0444,dir_mode=0444,suid,username=PO,password=Sap!2016 0 0
//10.134.175.150/Paycor/ /usr/sap/paycor cifs rw,file_mode=0444,dir_mode=0444,suid,username=PO,password=Sap!2016 0 0
	//10.134.175.150/Ebill /usr/sap/ebill cifs username=ebill,password=Wellsfargo!18,uid=20000,gid=3050,sec=ntlm

[root@pncapeccp1 ibmrmalik]$ df -hT |grep -i cifs
//10.134.175.150/Employees                  cifs      100G   79G   22G  79% /usr/sap/employees
//10.134.175.150/Ebill                      cifs      100G   79G   22G  79% /usr/sap/ebill
//10.134.175.150/Kyriba                     cifs      100G   79G   22G  79% /usr/sap/kyriba
//10.134.175.150/FTI                        cifs      100G   79G   22G  79% /usr/sap/FTI




CTASK0270971	VM snapshot for host - BIPRDAPP1 and BIPRDAPP3

CS4599961 for VM snap shot for host - BIPRDAPP1 and BIPRDAPP3



10.164.30.233	lonhana-1024-48.xsportal.local
mgggbjpeccx04 	10.133.18.21
qTSMJT%MU1t5tz@



tscmldev
[root@tscmldev ibmrmalik]$ systemctl status ntpd
â— ntpd.service
   Loaded: not-found (Reason: No such file or directory)
   Active: inactive (dead)
[root@tscmldev ibmrmalik]$ systemctl status chrony
â— chrony.service
   Loaded: not-found (Reason: No such file or directory)
   Active: inactive (dead)
[root@tscmldev ibmrmalik]$ timedatectl
      Local time: Thu 2020-09-24 22:32:30 EST
  Universal time: Fri 2020-09-25 03:32:30 UTC
        RTC time: Fri 2020-09-25 03:32:30
       Time zone: EST (EST, -0500)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
 
its host ammche01custesx02.imzcloud.ibmammsap.local
Need to knwo if they both are in same time zone or different and if NTP is enabled on the host or any other service like chrony or something else is managing the time sync on the host


sng01ammtsm001 (146.89.140.178)
10.116.145.50
Tc5v9VPner

root  bb8EHe%ipNJZ67@




 /interface/DQ1/bartender with sapsys 775 on OS and created the same in SAP AL11
DP1 samba user: bartenderprd
DP1 Folder: /interface/DP1/bartender



celanese-dal13-pod1-phana-4096-01.imzcloud.ibmammsap.local	10.208.79.230	root  XRs2qu6j	atlpr3db
IPMI 10.208.79.234	root   bEEMKbxzK5




10.162.186.195	che01-pod1-4tb-host03.imzcloud.ibmammsap.local
TSLBWQADB 10.207.63.20

 tslbwqadb to che01-pod1-4tb-host04.imzcloud.ibmammsap.local
 che01-pod1-4tb-host03



Monitor of CPU load in MP1 - PN4
uptime must be updated every hour in #scx-sapb1-pn4
SUSE case 00248297 - Pacemaker node hung due to high CPU load (pn4us7lewmp1/pn4ushlewmp1)
IBM Support case TS004256734 - https://www.ibm.com/mysupport/s/case/5000z00001T68xcAAB/cluster-load-average-was-high




snchdmdtd13	10.166.238.239	pHANA powered off suncor-tor01-pod2-phana-2048-3
snchdmdtd12	10.166.238.143  pHANA powered off suncor-tor01-pod2-pHANA-2048-2
snchdmdtd14	10.166.238.130  pHANA powered off suncor-tor01-pod2-phana-2048-4
snchdmdtd15	10.166.238.224  pHANA powered off suncor-tor01-pod2-phana-2048-5




stat("/MII_export",
10.142.41.87:/MII_export        /MII_export 


RTNETLINK answers: File exists
Fri Oct  2 06:55:24 2020 ERROR: Linux route add command failed: external program exited with error status: 2
Fri Oct  2 06:55:24 2020 Initialization Sequence Completed


CHG0173631	03-10-2020 09:30:00	03-10-2020 15:30:00
Storage Reclamation for CP2
Storage Reclamation for CP2  on servers 
PN8US7LDBCP2
PN8US7LECCP2

File System	  New Size (GB)	  Estimated Reduction (GB)

Server:pn8us7ldbcp2
	        	/db2	1	7
			/db2/CP2	2	2
			/db2/CP2/sapdata1	48.75	231.25
			/db2/CP2/sapdata2	48.75	231.25
			/db2/CP2/sapdata3	48.75	231.25
			/db2/CP2/sapdata4	48.75	231.25
			/db2/CP2/sapdata5	48.75	231.25
			/db2/CP2/sapdata6	48.75	231.25
			/db2/CP2/sapdata7	48.75	231.25
			/db2/CP2/sapdata8	48.75	231.25
			/db2/CP2/saptmp1	        10	         20
			/db2/CP2/saptmp2	10	20
			/db2/CP2/saptmp3	10	20
			/db2/CP2/saptmp4	10	20
			/db2/CP2/saptmp5	10	20
			/db2/CP2/saptmp6	10	20
			/db2/CP2/saptmp7	10	20
			/db2/CP2/saptmp8	10	20
			/db2/db2cp2	3	5
			/db2/CP2/log_dir	17	173

pn8us7leccp2	
                        /export/sapmnt/CP2	16	14

SOP 
Capture the server snapshot
Reduce the filesytems requested
FILESYSTEM_VG: VG of FILESYSTEM 
FILESYSTEM_LV: LV of FILESYSTEM 
- verify
# df -hT /FILESYSTEM
# vgs [FILESYSTEM_VG]
- reduce the LV FILESYSTEM
# umount /FILESYSTEM
# e2fsck -f /dev/FILESYSTEM_VG/FILESYSTEM_LV
# lvreduce -r -L [NEW_SIZE]G /dev/[FILESYSTEM_VG/FILESYSTEM_LV
# e2fsck -f /dev/FILESYSTEM_VG/FILESYSTEM_LV 
# mount /FILESYSTEM
- verify
# df -hT /FILESYSTEM
# vgs [FILESYSTEM_VG]
Documentation:
https://access.redhat.com/solutions/32530


CS4684485	Manchester Airport Group -- MNG	P1 - Severe	Disk Utilization / mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1

LONMAGHAN0004
10.113.60.220	lonhana-2048-3.xsportal.local

CS4684442	Manchester Airport Group -- MNG	P1 - Severe	Inodes Utilization /hana/data mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1

LONMAGHAN0004 goferd: [ERROR][worker-0] gofer.messaging.adapter.proton.connection:106 - connect: proton+amqps://lon02ammcaps01.imzcloud.ibmammsap.local:5647, failed: Connection amqps://lon02ammcaps01.imzcloud.ibmammsap.local:5647 disconnected


CS4684598  Manchester Airport Group -- MNG   Ping Availability CRITICAL - 10.69.0.19: rta nan, lost 100%  P2


lease check if this is related to your P1's
CS4684598	Manchester Airport Group -- MNG	P2 - Major	Ping Availability CRITICAL - 10.69.0.19: rta nan, lost 100%	SQ-SAP-TRIO-C1
CS4684497	Manchester Airport Group -- MNG	P2 - Major	Memory Swap CRITICAL: Swap free 49.96% (thresh 50:%)	SQ-SAP-TRIO-C1
CS4684454	Manchester Airport Group -- MNG	P2 - Major	Service sshd mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1
CS4684452	Manchester Airport Group -- MNG	P2 - Major	Service master mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1
CS4684451	Manchester Airport Group -- MNG	P3 - Minor	Disk Utilization / mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1
CS4684449	Manchester Airport Group -- MNG	P2 - Major	Service rsyslogd mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1
CS4684447	Manchester Airport Group -- MNG	P2 - Major	Disk Utilization /hana/shared mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1
CS4684446	Manchester Airport Group -- MNG	P3 - Minor	Inodes Utilization /hana/data mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1
CS4684444	Manchester Airport Group -- MNG	P3 - Minor	Inodes Utilization /usr/sap/DAB mktemp: failed to create file via template /tmp/XXXXXXXX: Read-only file system	SQ-SAP-TRIO-C1



LONMAGHAN0004	A0D8UK014XVM035	10.69.0.19 	172.22.0.19
10.113.60.220	lonhana-2048-3.xsportal.local
CFG-LONCFGCEQ0001-LONCFGCCQ0002.xsportal.local  
root / 	
YvlU76%mvB5gPr@

A0D8UK014XVM034  LONMAGHAN0003

mdadm --examine-badblocks /dev/sda3

ev/sda3

number:CS1997191
start of the vm failed
Connection error while establishing connection (9): Virtual machine config file does not exist..
Cannot open a local pipe to local virtual machine '/vmfs/volumes/561fe29a-98d72b50-988f-002590f9fed8/A0D8UK014XVM035/A0D8UK014XVM035.vmx'.


Bare Metal name:	lonhana-2048-3.xsportal.local
Fully Qualified Domain (Host) Name:
Motherboard Firmware version:
Raid Controller Firmware version:
IBM Cloud Ticket number: CS1997191
Version :
=======
Firmware Package Build = 24.6.0-0023
Firmware Version = 4.260.00-3735
Bios Version = 6.20.04.0_4.16.08.00_0x06090700
Ctrl-R Version = 5.07-0006
Preboot CLI Version = 01.07-05:#%0000
NVDATA Version = 3.1408.00-0007
Boot Block Version = 3.02.00.00-0001
Driver Name = lsi-mr3
Driver Version = 6.606.10.00

Basics :
======
Controller = 0
Model = LSI MegaRAID SAS 9361-8i
Serial Number = SV43306484
Current Controller Date/Time = 10/02/2020, 22:51:13
Current System Date/time = 10/02/2020, 23:26:26
SAS Address = 500605b0093243a0
PCI Address = 00:43:00:00
Mfg Date = 11/09/14
Rework Date = 00/00/00
Revision No = 14B



LV Path                /dev/cp2datavg/temprm_lv




par01ammipa001	146.89.142.155, fe80::250:56ff:feb3:3b9d	
dal13ammipa001	146.89.175.203, fe80::250:56ff:fe9a:6a7c	
wdc04ammipa001	146.89.142.35, fe80::250:56ff:fead:27e0



CHG0175451 - Development : Moving the VMs to Dedicated Cluster
CHG already has an approval for 5 hours extention
CHG channel is #tta_customdr_vmotion
1 VM pending which is GRCDEVNEW , user who started the migration ibmmvargas1
Once the migration is completed please validate from OS side then ask SAP peer to validated
Lately notify channel and then customer according to Notification Task


DWC30CBK

CS4735431 snapshot	
CHG0175898 09-10-2020 06:30:00	09-10-2020 08:30:00
EWA parameters recommendation recycle 
EDM - MDC Development HANA DB		agesvedmhsrv1	10.6.1.179	
ED1 - Development ERP Application	sved1srv0	10.6.1.11
RD1 - Development ERP Application	sved1srv0	10.6.1.11
JD1 - Development JAVA (FS_QUO)		svjd1srv0	10.6.1.12
BD1 - Development BW HANA DB		agesvbd1hsrv1	10.6.1.184
BD1 - Development BW Application	svbd1srv0	10.6.1.14
CDM - MDC Development HANA DB		agesvcdmhsrv1	10.6.1.180
CD1 - Development CRM System (ABAP)	svcd1srv0	10.6.1.16
XD1 - Development CRM System (JAVA)	svcd1srv0	10.6.1.16



Operation Failed
Unable to complete the reconfiguration task at remote site for replication group 'sm9d185173005' (managed object ID: 'GID-3d4ab162-d93f-47f3-8a7c-2dba188abb92'): task 'HTID-11c7a0a5-c5a0-4497-a7d8-623ff337c977'. Details: 'A generic error occurred in the vSphere Replication Management Server. Exception details: 'java.lang.NullPointerException'.'.
Operation ID: b8fc87b8-3f13-4a36-a016-a32f010d608e




10.116.35.150	snghana-1024-6.xsportal.local		
RP2kyp%SXXdZDH@
10.116.35.150	snghana-1024-6.xsportal.local




CS4752403 P2 - MajorPak Suzuki Motor Company Ltd (Psmcl) --Ping Availability (Service check timed out after 30.01 seconds)SQ-SAP-TRIO-B1
CS4752672 P2 - MajorPak Suzuki Motor Company Ltd (Psmcl) --Ping Availability (Service check timed out after 30.01 seconds)SQ-SAP-TRIO-B1
CS4752760 P2 - MajorPak Suzuki Motor Company Ltd (Psmcl) --Ping Availability (Service check timed out after 30.01 seconds)SQ-SAP-TRIO-B1



AGESVBQ1HSRV1
svbq1srv0	A0EASG014XVM018



[root@zffqappdb013 ibmrmalik]# cat /etc/fstab |grep -i "/usr/sap/transEBP"
#149.223.40.67:/usr/sap/transEBP_jfs2   /usr/sap/transEBP       nfs     defaults,nfsvers=3,intr 0 0
149.223.100.19:/usr/sap/transEBP        /usr/sap/transEBP       nfs     defaults 1 2


CHG0176360	CTASK0279147
ASDDEV   Chennai


CHG0176728-COTY Inc -- CTU-15-Oct-2020 05:00:00 AM
Once applications are brought down, please take a VM snapshot of the application servers
CTUBOSR1AP01	10.12.10.16
CTUBOSR1SP02	10.12.10.17


CHG0177115	16-10-2020 18:00:00	16-10-2020 22:30:00
Please deploy latest OS Upgrade( SUSE 12 SP4)  to the following servers.

Hostname         IMZ IP address	       CFN IP
-----------------------------------------------------------
GRCDEVNEW	10.207.62.24	10.170.62.80
Server Type: Development                                                 *
*       Hostname: grcdevnew                                                   *
*         CFN IP: 10.170.62.80                                                *
*         IFN IP: 10.207.62.24                                                *
*        SAP SID: GRD 




[root@grcdevnew ibmrmalik]$ SUSEConnect -s
[{"identifier":"SLES_SAP","version":"12.2","arch":"x86_64","status":"Registered"}]


ISMA OS Engineer
-> Task-1:  OS:: Start-Communication

ISMA SAP Engineer
-> Task-2: SAP::STOP Application

ISMA OS Engineer
Have root password handy
-> 1) Upgrade SuSe 12.2 applying the last patches for the current version.
1.1) Take OS prechecks and take Snap Shot of VM
1.2) zypper refresh; zypper in zypper-migration-plugin
1.3) zypper --no-refresh patch-check --updatestack-only
1.4) zypper --no-refresh patch --updatestack-only
1.5) Check if kernel changes, then reboot if it is necessary
 
2) Execute the zypper migration to do the upgrade from 12.2 to 12.4
2.1) zypper migration
-> Task-3: OS::Upgrade
-> Task-4: OS::Validation

ISMA SAP Engineer
-> Task-5: SAP::START Application


Can't get available migrations from server: SUSE::Connect::ApiError: Invalid combination of products registered. Unable to find base product for id(s) '100668'.


[root@grcdevnew products.d]$ ls -ltr
total 4
-rw-r--r-- 1 root root 3080 Mar 30  2017 SLES_SAP.prod
lrwxrwxrwx 1 root root   13 Dec 21  2018 baseproduct -> SLES_SAP.prod
[root@grcdevnew products.d]$ rm baseproduct
[root@grcdevnew products.d]$ ls -ltr
total 4
-rw-r--r-- 1 root root 3080 Mar 30  2017 SLES_SAP.prod
[root@grcdevnew products.d]$ ln -s /etc/products.d/SLES_SAP.prod /etc/products.d/baseproduct
[root@grcdevnew products.d]$ ls -ltr
total 4
-rw-r--r-- 1 root root 3080 Mar 30  2017 SLES_SAP.prod
lrwxrwxrwx 1 root root   29 Oct 16 19:22 baseproduct -> /etc/products.d/SLES_SAP.prod



[root@grcdevnew ibmrmalik]$ cat /etc/os-release
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"


[root@grcdevnew ibmrmalik]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux grcdevnew 4.12.14-95.60-default #1 SMP Mon Sep 7 12:13:13 UTC 2020 (52adb2e) x86_64 x86_64 x86_64 GNU/Linux
Fri Oct 16 20:18:40 IST 2020
#TSCMLDEV:/home /testnfs     nfs _netdev,defaults 0 0
OK: No read-only file systems found
che01ammyum01.imzcloud.ibmammsap.local:/sds   nfs4      6.0T  2.8T  2.9T  49% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3176,timeout=600,minproto=5,maxproto=5,direct,pipe_ino=35623 0 0
che01ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.207.62.24,local_lock=none,addr=146.89.142.88 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.
/var/log *(rw,async,no_subtree_check,insecure,no_root_squash)


[root@grcdevnew ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux grcdevnew 4.4.121-92.135-default #1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528) x86_64 x86_64 x86_64 GNU/Linux
Fri Oct 16 16:07:49 IST 2020
      Local time: Fri 2020-10-16 16:07:49 IST
  Universal time: Fri 2020-10-16 10:37:49 UTC
        RTC time: Fri 2020-10-16 10:37:49
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
#TSCMLDEV:/home /testnfs     nfs _netdev,defaults 0 0 
CRITICAL:  /run/user/99609/gvfs filesystems are read-only
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to 
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.
/var/log *(rw,async,no_subtree_check,insecure,no_root_squash)

[root@grcdevnew ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux grcdevnew 4.12.14-95.60-default #1 SMP Mon Sep 7 12:13:13 UTC 2020 (52adb2e) x86_64 x86_64 x86_64 GNU/Linux
Fri Oct 16 20:52:47 IST 2020
      Local time: Fri 2020-10-16 20:52:47 IST
  Universal time: Fri 2020-10-16 15:22:47 UTC
        RTC time: Fri 2020-10-16 15:22:47
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
#TSCMLDEV:/home /testnfs     nfs _netdev,defaults 0 0
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.
/var/log *(rw,async,no_subtree_check,insecure,no_root_squash)



Ravi will investigate how to transfer training badges and course completions, and think40 hours from old IDs to new IDs.  Joanie will ask her peer managers as well.



CS4898019  sev 1 for /sds hung in chennai
number:CS2024871  SL ticket for sds server powered off
PRB0054100 / RCA0003623  
reboot   system boot  3.10.0-1160.2.2. Thu Oct 22 21:46 
Ravi Malik (TRIO B - OS Support):speech_balloon: Hi Vithya, when u are in pls help me find the user name and mail id for ibmmpatel2

mitul.patel@ibm.com

che01ammsol01.imzcloud.ibmammsap.local:/sds  3.6T  2.8T  677G  81% /sds

che01ammsol01 was identified by the managed apps security team as an unknown/rogue device. After further investigation it was identified that Jason Sherry's team may own this device. The security team spoke to Jason who did not own the device and no further information could be gathered about the device. Since this device is not in the managed apps CMDB, SNOW, this device was patched and powered off to secure the 3.x business. In order for this device to no longer be considered Rogue and a threat to the environment, it must be added to SNOW as a device with device owners identified.
 

	       kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
04:00:01 PM    660852  32079320     97.98   1214312  20037784   6721636     19.89   7708008  17488348       144
04:10:01 PM    275344  32464828     99.16   1214688  20501724   7077616     20.95  10795520  15260392    116812




CS4897210 P2 - MajorAmerican Airlines Inc. -- A2ALog PaceMaker-log Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-10-22-19-38-37 for details.SQ-SAP-TRIO-B2	A2AHANAPRD2DB
CS4897285 P2 - MajorAmerican Airlines Inc. -- A2ALog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2020-10-22-19-48-40 for details.SQ-SAP-TRIO-B2

CS4897354 P2 - MajorConcessionaria Aeroporto Rio de Jan -- CONNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CONSPENADBAPP- KB0010973
CS4897359 P2 - MajorLSPI -- LSPNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZABWPRD0- KB0010973SQ-SAP-TRIO-C1
CS4897371 P2 - MajorLSPI -- LSPNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZABJPRD0- KB0010973SQ-SAP-TRIO-C1(e
CS4897372 P2 - MajorAGEAS -- AGENagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVFD1SRV0- KB0010973SQ-SAP-TRIO-C1



CS4897713 Suncor Energy Inc. -- SNCP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SNCHBIBPA15- KB0010973SNCHBIBPA15SQ-SAP-TRIO-B2
CS4897712 Suncor Energy Inc. -- SNCP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SNCHBIBPA15-DR- KB0010973SNCHBIBPA15-DRSQ-SAP-TRIO-B2
CS4898696 Suncor Energy Inc. -- SNCP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SNCHBIBTA11- KB0010973SNCHBIBTA11SQ-SAP-TRIO-B2


AABAH1713K
HighBl1$$@Wing


fbtprdhandb_new,  IP 10.4.27.25		10.121.75.11	dalhana-1024-57.xsportal.local




CS4947884	MCO at LON02-SL. ESXi on PSOD state.



n TSCMLDEV
can you help mounting below 2
sde                                   8:64   0  210G  0 disk
â””â”€import_vg-import_lv               254:26   0  209G  0 lvm  /import
[root@tscmldev ibmrmalik]$ lvdisplay |grep -i import_lv
  LV Path                /dev/import_vg/import_lv
  LV Name                import_lv




sdg                                   8:96   0  200G  0 disk
â””â”€swdump_vg-swdump_lv               254:43   0  199G  0 lvm  /swdump (edited) 
[root@tscmldev ibmrmalik]$ lvdisplay |grep -i /swdump
  LV Path                /dev/swdump_vg/swdump_lv


[root@tscmldev ibmrmalik]$ mount -t ext4 /dev/import_vg/import_lv /import

[root@tscmldev ibmrmalik]$ mount -t ext4 /dev/swdump_vg/swdump_lv /swdump


9822849971 sunil mali



Masters: [ pn8us7leccp3 ]
Slaves: [ pn8us7leccp3h ]



	  Node Name 1: ogypxn001                      IP: 10.25.8.206                                                                     |
|         Node Name 2: ogypxn001                      IP: 10.139.8.223                                                                    |
|                                                                                                                                         |
|         Cluster Type                                        : Database                                                                  |
|         Launching Database recovery Script....                                                                                          |
|=========================================================================================================================================|
|         Node Name 1: ogypxn001                      IP: 10.25.8.206                                                                     |
|         Node Name 2: ogypxn001                      IP: 10.139.8.223



varfadinu@oksbi

CS4968189	AM3S4PRDDB	SNG01-SL	SHPAM3 (HANADB)|HDB_LARGE_HEAPAREAS|Large Heap Areas
CS4968844	AM3S4PRDDB	SNG01-SL	SHPAM3 (HANADB)|HDB_AVL_1015_REPLICATION_STATUS_ALERT|SR: Replication Status
CS4968131	AM3S4PRDDB	SNG01-SL	SHPAM3 (HANADB)|HDB_REPLICATION_TIME_LAG_1018|SR: High Replication Time Lag
CS4968178	AM3S4PRDDB-DR	HKG02-SL	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AM3S4PRDDB-DR- KB0010973



AM3S4PRDDB
10.174.73.178	hkg02-pod2-4tb-host02.imzcloud.ibmammsap.local
Management
10.174.73.186
User
root
Password
ThghC54Z9Q

root   	94AoAl%IywQEt5@


am3s4prddb


PAC	10.116.83.108
Destination:
V59	10.8.216.14 (DEV)	BAPV590800 	10.134.4.13 	10.8.216.14 	
V32	10.8.216.17 (QA)	BAPV321100 	10.134.4.15 	10.8.216.17 	
V33	10.8.217.13 (PROD)	BAPV330900 	10.134.3.7 	10.8.217.13



bapibmcpac01
/usr/sap/interfaces/V59/sharedoc *(rw,sync,no_root_squash,no_subtree_check)
/usr/sap/interfaces/V32/sharedoc *(rw,sync,no_root_squash,no_subtree_check)


10.116.83.108 x/srv/interface    x/usr/sap/interfaces/V59/sharedoc xnfs     xdefaults



CS4982810
CS4982912

CS4984694	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/pgsql MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984692	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /srv MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984690	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/crash MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984689	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/spool MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984687	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mariadb MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984685	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /tmp MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984682	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/tmp MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984681	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/machines MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984680	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /usr/local MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS4984679	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/opt MINOR: Free 7617.23MB/18.88% (thresh @10.01:20%)	SQ-SAP-TRIO-C2 (edited) 



DG1ERPQASDG 	10.143.31.12 	10.10.31.12	 add new temporal disk of 650GB size	DAL13 SL
* After add new disk, create a FS /BACKUPTEMP on DG1erpqasdg server * 

Server role/SAPSID	Hostname	IFN IP	CFN IP

App+DB server  PRD	DG1erpprodg	10.143.30.11	10.10.30.11 <-- Source
APP+DB server  QAS	DG1erpqasdg	10.143.31.12	10.10.31.12 <-- Target

[root@DG1erpqasdg ibmrmalik]$ lvdisplay |grep -i backuptemp*
  LV Path                /dev/backuptempvg/backuptemp_lv
  LV Name                backuptemp_lv
  VG Name                backuptempvg


CS5015941
sapboprd (IP: 10.170.61.58)



CS5018109
Please create the FS  permanently /oracle/SGP/19.0.0 on TSGPPRD and /oracle/TSP/19.0.0 on TSCMLPRD servers. 

 FS -  /oracle/SGP/19.0.0   50GB with the permissions orasgp :dba on  TSGPPRD ( 10.207.61.41 ) 
 
 [root@tsgpprd SGP]$ lvdisplay |grep -i Ora19_lv
  LV Path                /dev/sgpappvg/Ora19_lv
  
[root@tsgpprd ibmrmalik]$ df -hT /oracle/SGP/19.0.0
Filesystem                    Type  Size  Used Avail Use% Mounted on
/dev/mapper/sgpappvg-Ora19_lv ext4   25G   44M   24G   1% /oracle/SGP/19.0.0

[root@tsgpprd SGP]$ df -hT /sapstage
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/sgpappvg-sapstage_lv ext4   30G  1.2G   27G   5% /sapstage
  

 FS -  /oracle/TSP/19.0.0   50GB with the permissions oratsp : dba  on TSCMLPRD (10.207.61.36)

And also please add 25GB for the FS - /sapstage on both servers TSGPPRD and TSCMLPRD

[root@tscmlprd TSP]$ df -hT /oracle/TSP/19.0.0/
Filesystem                  Type  Size  Used Avail Use% Mounted on
/dev/mapper/tspdatavg-Ora19 ext4   25G   44M   24G   1% /oracle/TSP/19.0.0


CS5025146
1	SNCHECAQA11
2	SNCHECAQA12
3	SNCHECAQA13
4	SNCHECAQA14
5	SNCHECAQA15
6	SNCHECAQA16
7	SNCHECAQA17
8	SNCHECAQA18
9	SNCHECAQA19
10	SNCHECAQA20
11	SNCHWDWQW11
12	SNCHAPAQA11
13	SNCHAPAQA12
14	SNCHZRAQA11
15	SNCHZRAQA12
16	SNCHLTAQA11
17	SNCHLTAQA12
18	SNCHLTAQA13
19	SNCHLTAQA14
20	SNCHTNAQA11
21	SNCHTNAQA12
22	SNCHCRAQA11
23	SNCHCRAQA12
24	SNCHCRAQA13
25	SNCHMDAQA11
26	SNCHMDAQA12
27	SNCHGRAQA11
28	SNCHGRAQA12
29	SNCHCUAQA11
30	SNCHCUAQA12
31	SNCHEUAQA11
32	SNCHEUAQA12
33	SNCHEUAQA13
34	SNCHBDWQW11
35	SNCHCIIQA11


lbudm1db01

10.211.42.173	wdc04-pod4-4tb-host15.imzcloud.ibmammsap.local


CS5042470	COTY Inc. -- CTU	P3 - Minor	Disk Utilization /var/log MINOR: Free 373.86MB/19.93% (thresh @10.01:20%)	SQ-SAP-TRIO-B1
CS5039225	Bombardier Recreational Products Inc -- BR3	P2 - Major	LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp.	SQ-SAP-TRIO-C1



CS5045168P2 - MajorBombardier Recreational Products Inc -- BR3LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.154/nrdp.SQ-SAP-TRIO-C1
CS5045071P2 - MajorBombardier Recreational Products Inc -- BR3LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.154/nrdp.SQ-SAP-TRIO-C1

CS5044670P2 - MajorBombardier Recreational Products Inc -- BR3LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp.SQ-SAP-TRIO-C1
CS5044339P2 - MajorConcessionaria Aeroporto Rio de Jan -- CONMemory Swap CRITICAL: Swap free 49.91% (thresh 50:%)SQ-SAP-TRIO-B1
CS5044206P2 - MajorLiberty Utilities (Canada) Corp -- LBUNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUQO1AP02- KB0010973SQ-SAP-TRIO-B1



welcometodr
LONMAGBOB0002 172.22.0.24	A0D8UK014XVM011	
LONMAGSPO0001 172.22.0.35	A0D8UK014XVM018	
LONMAGSWD0001 172.22.1.10	A0D8UK014XVM031
LONMAGSLM0010 172.22.0.77	samename
LONMAGSLM0003 172.22.0.70	samename
LONMAGSLM0004 172.22.0.71	samename
LONMAGSLM0007 172.22.0.74	samename
LONMAGSLM0008 172.22.0.75	samename
LONMAGSLM0009 172.22.0.76	samename


/dev/tempvg/templv


10.113.60.218	lonhana-2048-1.xsportal.local	k587oh%hehKRQ7@
10.112.13.132	lon02drhana006.xsportal.local	B8nw0d%KjmuGum@
10.113.60.236	CFG-LONCFGCEQ0001-LONCFGCCQ0002.xsportal.local	Xlc8c7%flaSVMm@
10.113.60.220	lonhana-2048-3.xsportal.local	YvlU76%mvB5gPr@
10.134.53.169	frahana-1024-2.xsportal.local	HK7N46%Bteqkui@
10.134.17.76	MAG-FRAMAGHAN0002.xsportal.local	u3ebws%9zrLXHF@
10.134.53.146	frahana-1024-4.xsportal.local	BSUsPt%TcKNa6w@





CS5081493 COTY Inc. -- CTUP3 - MinorDisk Utilization /boot/grub2/x86_64-efi MINOR: Free 12095.11MB/19.87% (thresh @10.01:20%)
CS5081481 COTY Inc. -- CTUP3 - MinorDisk Utilization /.snapshots MINOR: Free 12094.79MB/19.87% (thresh @10.01:20%)
CS5081477 COTY Inc. -- CTUP3 - MinorDisk Utilization /var/lib/mariadb MINOR: Free 12094.79MB/19.87% (thresh @10.01:20%)
CS5081473 COTY Inc. -- CTUP3 - MinorDisk Utilization /var/lib/named MINOR: Free 12094.79MB/19.87% (thresh @10.01:20%)
CS5081472 COTY Inc. -- CTUP3 - MinorDisk Utilization /opt MINOR: Free 12094.79MB/19.87% (thresh @10.01:20%)
CS5081459 COTY Inc. -- CTUP3 - MinorDisk Utilization /var/lib/mysql MINOR: Free 12094.82MB/19.87% (thresh @10.01:20%)
CS5081452 COTY Inc. -- CTUP3 - MinorDisk Utilization /boot/grub2/i386-pc MINOR: Free 12094.85MB/19.87% (thresh @10.01:20%)
CS5081451 COTY Inc. -- CTUP3 - MinorDisk Utilization /var/lib/pgsql MINOR: Free 12094.85MB/19.87% (thresh @10.01:20%)


CHG0175556   - Dixons Carphone DR Test
PROD 	London
DR	Frankfurt
PROD/LON/CPW - Annual DR Test 2020 - Dixons Carphone Warehouse


SL.No	Application	SID	Purpose	PROD Hostname	CFN IP	IMZ IP	DR Hostname	CFN IP	IMZ IP
1	S/4HANA HANA System	PSF	vHANA DB	dcghanaprddb2	10.197.2.18	10.197.5.18	dcghanaprddb3	10.199.4.14	10.199.7.14
2	S/4HANA App Systems	PSF	App	dcghanaprdap1	10.197.2.14	10.197.5.14	dcghanaprdap1	10.197.2.14	10.197.5.14
3	S/4HANA App Systems	PSF	App	dcghanaprdap2	10.197.2.15	10.197.5.15	dcghanaprdap2	10.197.2.15	10.197.5.15
4	S/4HANA App Systems	PSF	App	dcghanaprdap3	10.197.2.16	10.197.5.16	dcghanaprdap3	10.197.2.16	10.197.5.16

5	Application Server for SAP Fiori 	PFE	App	dcgpfeapp10	10.197.2.19	10.197.5.19	dcgpfeapp10	10.197.2.19	10.197.5.19
6	Application Server for SAP Fiori 	PFE	App	dcgpfeapp11	10.197.2.20	10.197.5.20	dcgpfeapp11	10.197.2.20	10.197.5.20
7	Application Server for SAP Fiori 	PFE	App + DB	dcgpfeapp12	10.197.2.21	10.197.5.21	dcgpfeapp12	10.197.2.21	10.197.5.21


sapmnt/PSF from dcghanaprdap1 to dcghanaprdap2 and dcghanaprdap3

DR Hostname	CFN IP	IMZ IP
dcghanaprddb3	10.199.4.14	10.199.7.14
	dcghanaprdap1	10.197.2.14	10.197.5.14	DR [yvtDEP*2.Pd`r7    PRD 9X,c%*[xuY0I]I0  
	dcghanaprdap2	10.197.2.15	10.197.5.15
	dcghanaprdap3	10.197.2.16	10.197.5.16
dcgpfeapp10	         10.197.2.19	10.197.5.19
dcgpfeapp11	         10.197.2.20	10.197.5.20
dcgpfeapp12	         10.197.2.21	10.197.5.21





CS5087337
[HNO] inquiry about nmon interval

CDIR:HNO

[Request]
Customer is going to do the performance test on HP1 from next week .
They would like to check the system resource during the performance test.

The system utilization can be monitored with nmon on linux servers.
The interval of nmon is set as 600 seconds(5minutes).

Would it possible to change the interval during the performance test?
Or Could you run another nmon with the interval 60 seconds during the performance test?

[Server]
HOSTNAME	OS				IFN IP				CFN IP		SID	Description
--------------		-------------		-----------------		--------------	-----	------------------------
hnosapapp1	Suse Linux 	192.168.16.81		10.20.0.17	HSP	SAP S/4HANA AP
hnosapapp2	Suse Linux		192.168.16.78		10.20.0.12 	HSP	SAP S/4HANA AP
hnosapdbp1	Suse Linux 	192.168.16.87		10.20.0.23	HSP	SAP S/4HANA DB
hnosapdbp2	Suse Linux 	192.168.16.91		10.20.0.26	HSP	SAP S/4HANA DB
hnosapwdp1	Suse Linux 	192.168.16.94		10.20.0.30	HWP	SAP Webdispatcher

[Note]
none

-----
[ibmhwatanabe@hnosapapp1 ~]$ ps -ef | grep nmon
root      11778      1  0 00:02 ?        00:00:04 /usr/bin/nmon -f -t -m /var/log/nmon
ibmhwat+ 128912 119916  0 13:06 pts/0    00:00:00 grep --color=auto nmon
[ibmhwatanabe@hnosapapp1 ~]$ 
[ibmhwatanabe@hnosapapp1 ~]$ ls -l /var/log/nmon | tail
-rwxrwxr-x 1 root root 155961 Nov  3 23:57 hnosapapp1_201103_0002.nmon.gz
-rwxrwxr-x 1 root root 917344 Nov  4 23:57 hnosapapp1_201104_0002.nmon
-rwxrwxr-x 1 root root 919652 Nov  5 23:57 hnosapapp1_201105_0002.nmon
-rwxrwxr-x 1 root root 927739 Nov  6 23:57 hnosapapp1_201106_0002.nmon
-rwxrwxr-x 1 root root 916375 Nov  7 23:57 hnosapapp1_201107_0002.nmon
-rwxrwxr-x 1 root root 915630 Nov  8 23:57 hnosapapp1_201108_0002.nmon
-rwxrwxr-x 1 root root 913735 Nov  9 23:57 hnosapapp1_201109_0002.nmon
-rwxrwxr-x 1 root root 916414 Nov 10 23:57 hnosapapp1_201110_0002.nmon
-rwxrwxr-x 1 root root 903860 Nov 11 23:57 hnosapapp1_201111_0002.nmon
-rwxrwxr-x 1 root root 531596 Nov 12 13:07 hnosapapp1_201112_0002.nmon
[ibmhwatanabe@hnosapapp1 ~]$ 
[ibmhwatanabe@hnosapapp1 ~]$ head /var/log/nmon/hnosapapp1_201112_0002.nmon
AAA,progname,nmon
AAA,command,/usr/bin/nmon -f -t -m /var/log/nmon 
AAA,version,16g
AAA,disks_per_line,150
AAA,max_disks,256,set by -d option
AAA,disks,30,
AAA,host,hnosapapp1
AAA,user,root
AAA,OS,Linux,4.4.121-92.135-default,#1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528),x86_64
AAA,runname,hnosapapp1
[ibmhwatanabe@hnosapapp1 ~]$ head -30 /var/log/nmon/hnosapapp1_201112_0002.nmon
AAA,progname,nmon
AAA,command,/usr/bin/nmon -f -t -m /var/log/nmon 
AAA,version,16g
AAA,disks_per_line,150
AAA,max_disks,256,set by -d option
AAA,disks,30,
AAA,host,hnosapapp1
AAA,user,root
AAA,OS,Linux,4.4.121-92.135-default,#1 SMP Thu Jun 4 10:34:31 UTC 2020 (effc528),x86_64
AAA,runname,hnosapapp1
AAA,time,00:02.02
AAA,date,12-NOV-2020
AAA,interval,300
AAA,snapshots,288
AAA,cpus,7
AAA,x86,VendorId,GenuineIntel
AAA,x86,ModelName,Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz
AAA,x86,MHz,2599.997
AAA,x86,bogomips,5199.99
AAA,x86,ProcessorChips,2
AAA,x86,Cores,1
AAA,x86,hyperthreads,0
AAA,x86,VirtualCPUs,7
AAA,proc_stat_variables,8
AAA,boottime,06:41 PM 16-Oct-2020
AAA,note0, Warning - use the UNIX sort command to order this file before loading into a spreadsheet
AAA,note1, The First Column is simply to get the output sorted in the right order
AAA,note2, The T0001-T9999 column is a snapshot number. To work out the actual time; see the ZZZ section at the end
CPU001,CPU 1 hnosapapp1,User%,Sys%,Wait%,Idle%,Steal%
CPU002,CPU 2 hnosapapp1,User%,Sys%,Wait%,Idle%,Steal%
[ibmhwatanabe@hnosapapp1 ~]$ 



nmon.conf file, I run the command
/opt/splunk/bin/splunk reload deploy-server -class serverclassname -debug

I created the nmon.conf in 'local' directory and edited the file there (deployment server). I have edited too the nmon.conf directly in 'default' directory but it haven't work.

My linux servers received the app correctly, and with the new value in fifo_interval parameter, but performance measures are still being collected each 60 seconds.

restarting the splunkd service on the forwarder(it should do automatically if your serverclass stanza has restartsplunkd = true).




CS5132318
replication status TATA VMs in Chennai


Pacemaker training
https://ec.yourlearning.ibm.com/w3/playback/10130317 
https://ec.yourlearning.ibm.com/w3/playback/10122067


 Placeholder VM for the protected VM 'A0D8UK014XVM007' is missing.
 
/vmfs/volumes/b714923f-9bb87e83/A0D8UK014XVM007/vrTestImage/A0D8UK01



DETAILED DESCRIPTION.............: 
Server/Host name...........................: zffsappdb007	

Please check printer 922_SUNGB_ADB_P002 is available in OS level in print server. please provide the screenshot with printer name,shortname and availability

while trying to print getting error the printer or the class was not found.


Link to the modules:
Compliance Essentials: https://bundles.yourlearning.ibm.com/ibm/security-compliance/#MKPYGXVZPZYW145X
Global Security Processes : https://bundles.yourlearning.ibm.com/ibm/security-compliance/#DNRMWKPENKXQ4MMR
Audit Essentials : https://bundles.yourlearning.ibm.com/ibm/security-compliance/#WWZRWNRVJGDZ128M
ISO 27001: 2013 : https://bundles.yourlearning.ibm.com/ibm/security-compliance/#RKEMXDKXMGNY16W7
Cross Border Process/Data Privacy : https://bundles.yourlearning.ibm.com/ibm/security-compliance/#WWZRQMRWZGRV148A



[root@MGGGBJPGTSX02 ~]$ sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh
CRITICAL:  / / /boot /sapmnt/data /sapmnt/shared /usr/sap filesystems are read-only
/usr/local/ncpa/etc/cmas_ksh_functions.sh: line 342: /usr/local/ncpa/var/log/cmas_checks.log: Read-only file system

CS5147790 is in place and being worked. SL ticket for ref CS2059250


	sapapp18	10.170.61.116	10.207.61.70
	sapapp19	10.170.61.74	10.207.61.215
	sapapp20	10.170.61.48	10.207.61.195
	sapapp21	10.170.61.131	10.207.61.80
	sapapp26	10.170.61.176	10.207.61.48
	sapapp27	10.170.61.166	10.207.61.47
	sapapp28	10.170.61.211	10.207.61.58
	sapapp29	10.170.61.141	10.207.61.85
	sapapp30	10.170.61.161	10.207.61.95
	sapapp15	10.170.61.121	10.207.61.37
	sapapp31	10.170.61.40	10.207.61.84
	sapapp23	10.170.61.226	10.207.61.130
	sapcrmapp3	10.170.61.96	10.207.61.60
	sapcrmapp4	10.170.61.160	10.207.61.187
	ewmapp3	10.170.61.204	10.207.61.114
	ewmapp1	10.170.61.68	10.207.61.77
	biprdapp3 	10.170.61.17	10.207.61.31
	biprdapp1	10.170.61.91	10.207.61.28
	tscmlprd	10.170.61.15	10.207.61.36
	tsgpprd	10.170.61.20	10.207.61.41
	sappoprdc	10.170.61.30	10.207.61.89
	essmssdev	10.170.61.63	10.207.61.210
	adsprds	10.170.61.25	10.207.61.29
	ttar3dev	10.170.61.22	10.207.61.72
	sapborepo	10.170.61.56	10.207.61.40
	sapboprd	10.170.61.58	10.207.61.205
	sapbowapp	10.170.61.33	10.207.61.73
	sapcrmdi	10.170.61.69	10.207.61.83
	tsldrlog	10.170.61.67	10.207.61.133
	ttactrl01	10.170.61.105	10.207.61.169




66.248.241.19 DR server 
10.133.18.27 PRIMARY

backup could not be completed, Backint cannot execute /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint, Permission denied (13)


DR
[root@MGGDRDGTSX02 ibmrmalik]# ls -Z /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
lrwxrwxrwx root root ?                                /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint -> /opt/tivoli/tsm/tdp_hana/hdbbackint


Primary
[root@MGGGBJPGTSX02 ibmrmalik]$ ls -Z /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
lrwxrwxrwx. root root system_u:object_r:default_t:s0   /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint -> /opt/tivoli/tsm/tdp_hana/hdbbackint

chcon -h system_u:object_r:default_t:s0 /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint

ls --lcontext <file path>

To Apply selinux context :
ls --lcontext /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint [ls --lcontext <Filename>]
chcon -h system_u:object_r:default_t:s0 /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
ls --lcontext <Filename>


Primary
[root@MGGGBJPGTSX02 ibmrmalik]$ ls --lcontext /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
lrwxrwxrwx. 1 system_u:object_r:default_t:s0   root root 35 Nov  4  2017 /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint -> /opt/tivoli/tsm/tdp_hana/hdbbackint


DR
[root@MGGDRDGTSX02 ibmrmalik]# ls --lcontext /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
lrwxrwxrwx. 1 system_u:object_r:default_t:s0   root root 35 Nov 20 04:05 /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint -> /opt/tivoli/tsm/tdp_hana/hdbbackint



FRA
10.85.0.180	fra02-pod2-4tb-host02.imzcloud.ibmammsap.local



10.135.58.210	frahana-1024-11.xsportal.local
JpxguR2z






 Placeholder VM for the protected VM 'A0D8UK014XVM007' is missing.
 
 
BW HANA - tslbwprddb	( CFN-10.170.61.53/IFN-10.207.61.200)

S4 HANA - tsls4proddb (CFN-10.170.61.225/IFN-10.207.61.123)

(CFN-10.170.61.67/IFN-10.207.61.133) in CHE
 FS - /DRDrillLogs

 
 
 SAP SID: QCM
 problematic one br3qscmdb37
 NODEB
 su - qcmadm -c "hdbnsutil -sr_register --remoteHost=br3qscmdb36 --remoteInstance=36 --replicationMode=sync --operationMode=logreplay --name=NODEB"
 
 
 
 
-rw------- 1 ibmsgupta    domain_users 1795 Nov 21 04:17 krb5cc_108288
shutdown system down  4.4.121-92.141-d Sat Nov 21 04:23 - 04:25  (00:01)
reboot   system boot  4.4.121-92.141-d Sat Nov 21 04:25 - 04:55  (00:30)




-rw------- 1 ibmsgupta        domain_users 1795 Nov 21 04:32 krb5cc_108288
-rw------- 1 ibmsbaltodano    domain_users 2123 Nov 21 04:27 krb5cc_108523


shutdown system down  4.4.121-92.141-d Sat Nov 21 04:21 - 04:25  (00:03)

reboot   system boot  4.4.121-92.141-d Sat Nov 21 04:25 - 05:03  (00:38)




 Clone Set: cln_SAPHanaTopology_QCM_HDB36 [rsc_SAPHanaTopology_QCM_HDB36]
     Started: [ br3qscmdb36 br3qscmdb37 ]
 Master/Slave Set: msl_SAPHana_QCM_HDB36 [rsc_SAPHana_QCM_HDB36]
     Masters: [ br3qscmdb36 ]
     Slaves: [ br3qscmdb37 ]
 rsc_ip_QCM_HDB36       (ocf::heartbeat:IPaddr2):       Started br3qscmdb36
 TSMTDP_QCM_HDB36       (systemd:dsmcad_hana):  Started br3qscmdb36



CS5200130 HollyFrontier Corporation -- HFCP2 - MajorPing Availability CRITICAL - 10.211.16.84: rta nan, lost 100%
CS5199686 HollyFrontier Corporation -- HFCP2 - MajorPing Availability CRITICAL - 10.211.16.84: rta nan, lost 100%



W3 id migration call

YL trainings migration not working as expected
ibm.com id already cant they get the location updated



CHG0183076	CTASK0302173

NFS mounts

Since it's a cluster environment we need to setup in maintenance mode first: 

#Maintenance/Managed Mode
crm configure property maintenance-mode=true
crm configure property maintenance-mode=false

On lbups1ap01, lbups1ap01ha, lbups1ap02 and lbups1ap03:

1) Unmount the file system /interface/PS1 (ssapp-lbu-ps1:/export/interface/PS1) 

2) NFS mount filesystem /interface from lbupf1ap01 on mounting point /interface  (mount it as a nfs4 type)

3) Mount filesystem ssapp-lbu-ps1:/export/interface/PS1 on /int/PS1

4) Update the /etc/fstab to reflect the changes and make them permanent



	LBUPS1AP01	10.139.10.59	
	LBUPS1AP01HA	10.139.10.88	CFN IP: 10.140.0.100
LBUPS1AP02	10.139.10.38	
LBUPS1AP03	10.139.10.56


LBUPF1AP01 	10.139.10.78 	10.140.0.20

[ibmrmalik@lbups1ap01ha ~]$ cat /etc/fstab |grep -i nfs
10.140.32.28:/usr/sap/trans	/usr/sap/trans	nfs4	defaults,intr 0 0
ssapp-lbu-ps1:/export/interface/PS1 /int/PS1 nfs4    defaults,intr 0 0
10.140.0.20:/interface /interface nfs4 defaults,intr 0 0 


[root@lbups1ap01 ibmrmalik]# df -hT /interface/PS1
Filesystem                          Type  Size  Used Avail Use% Mounted on
ssapp-lbu-ps1:/export/interface/PS1 nfs  1014M   32M  982M   4% /interface/PS1
[root@lbups1ap01 ibmrmalik]# umount /interface/PS1
[root@lbups1ap01 ibmrmalik]# df -hT /interface/PS1

[ibmrmalik@lbups1ap01 int]$ df -hT |grep -i int
10.140.0.20:/interface                      nfs4      1.9T   67M  1.8T   1% /interface
ssapp-lbu-ps1:/export/interface/PS1         nfs4     1014M   32M  982M   4% /int/PS1


On lbups1ap01, lbups1ap01ha, lbups1ap02 and lbups1ap03:

1) Unmount the file system /interface/PS1 (ssapp-lbu-ps1:/export/interface/PS1)
2) Mount filesystem ssapp-lbu-ps1:/export/interface/PS1 on /int/PS1
3) NFS mount filesystem /interface from lbupf1ap01 on mounting point /interface
10.140.0.20:/interface /interface

4) Update the /etc/fstab to reflect the changes and make them permanent (edited) 

[root@lbupg1ap01 ibmrmalik]# df -hT |grep -i nfs
10.140.32.32:/usr/sap/trans         /usr/sap/trans nfs4 
ssapp-lbu-pg1:/export/3rdPartySoftware/PG1  /3rdPartySoftware/PG1 	nfs
ssapp-lbu-pg1:/export/interface/PG1  /int/PG1 nfs4
ssapp-lbu-pg1:/export/sapmnt/PG1  /sapmnt/PG1 nfs
10.140.0.20:/interface  /interface nfs


LBUPP1AP01	10.139.10.23	
LBUPP1AP01HA	10.139.10.40	
LBUPP1AP02	10.139.10.26


1) Unmount the file system /interface/PL1 (ssapp-lbu-ps1:/export/interface/PL1)
2) Mount filesystem ssapp-lbu-ps1:/export/interface/PL1 on /int/PL1
3) NFS mount filesystem /interface from lbupf1ap01 on mounting point /interface
10.140.0.20:/interface /interface


LBUPL1AP01	10.139.10.20	
LBUPL1AP02	10.139.10.73

[root@lbupl1ap01 ibmrmalik]# df -hT |grep -i int
/dev/mapper/pl1appvg-pl1Intface_lv          xfs       2.0G   33M  2.0G   2% /interface/PL1





CS5210298	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /tmp MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210293	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mysql MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210268	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/spool MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210260	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /.snapshots MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210256	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/cache MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210254	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/pgsql MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210248	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/crash MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210203	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /usr/local MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5210190	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /boot/grub2/x86_64-efi MINOR: Free 8209.39MB/18.14% (thresh @10.01:20%)
CS5205933	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/log MINOR: Free 8264.57MB/18.26% (thresh @10.01:20%)
CS5205931	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /home MINOR: Free 8264.56MB/18.26% (thresh @10.01:20%)
CS5205928	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mailman MINOR: Free 8264.56MB/18.26% (thresh @10.01:20%)
CS5205926	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/libvirt/images MINOR: Free 8264.56MB/18.26% (thresh @10.01:20%)
CS5205925	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/named MINOR: Free 8264.56MB/18.26% (thresh @10.01:20%)
CS5205924	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mariadb MINOR: Free 8264.57MB/18.26% (thresh @10.01:20%)
CS5205921	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mysql MINOR: Free 9048.26MB/19.99% (thresh @10.01:20%)
CS5205920	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/opt MINOR: Free 9048.26MB/19.99% (thresh @10.01:20%)
CS5205919	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /tmp MINOR: Free 9048.26MB/19.99% (thresh @10.01:20%)
CS5205918	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /usr/local MINOR: Free 9048.26MB/19.99% (thresh @10.01:20%)




cmastsm01	146.89.142.219	win server no access
testvmcoretr7	146.89.143.44	access denied
testvmcoretr	146.89.143.45	access denied
TESTVMTZSLE12SP2	146.89.143.46	cant access




CS5234899	Alpro Comm. VA -- APR	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 96.66 (thresh: 30)	SQ-SAP-TRIO-B1
CS5234162	CMA CGM -- CMA	P3 - Minor	Disk Utilization /tmp MINOR: Free 751.58MB/19.97% (thresh @10.01:20%)	SQ-SAP-TRIO-C2 




10.65.11.18

X7PGgjWK3f


0000018460609

160265166684



CS5259148 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var FATAL: Free 55.30MB/0.99% (thresh @0:5%)
CS5259144 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var FATAL: Free 125.35MB/2.24% (thresh @0:5%)
CS5259131 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var FATAL: Free 110.57MB/1.98% (thresh @0:5%)

CS5259152 Tata Steel Limited -- TTAP2 - MajorDisk Utilization /var CRITICAL: Free 800.18MB/9.42% (thresh @5.01:10%)
CS5259151 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var FATAL: Free 0.00MB/0.00% (thresh @0:5%)
CS5259149 Tata Steel Limited -- TTAP1 - SevereDisk Utilization /var FATAL: Free 0.00MB/0.00% (thresh @0:5%)



Failed Actions:
* vol_prdersvg_monitor_30000 on sapapp31 'unknown error' (1): call=1445, status=Timed Out, exitreason='',
    last-rc-change='Tue Dec  1 10:00:33 2020', queued=0ms, exec=0ms
* vol_prdglobalvg_monitor_30000 on sapapp31 'unknown error' (1): call=1510, status=Timed Out, exitreason='',
    last-rc-change='Tue Dec  1 10:00:12 2020', queued=0ms, exec=0ms
[root@sapapp31-ha ibmhjayadevappa]#


Dec  1 10:00:13 sapapp31-ha SAPPRD_22[120319]: F6E Spool / Printing: Error synchronizing file /usr/sap/PRD/SYS/global/600JOBLG/0001X09450301X43635. Error 13
Dec  1 10:00:13 sapapp31-ha SAPPRD_22[120319]: AB0 Basis System: Runtime error "UNCAUGHT_EXCEPTION" occurred.
Dec  1 10:00:14 sapapp31-ha SAPPRD_22[120319]: F6E Spool / Printing: Error synchronizing file /usr/sap/PRD/SYS/global/600JOBLG/0001X09450301X43635. Error 13
Dec  1 10:00:14 sapapp31-ha SAPPRD_22[120319]: R38 Basis System: Error at DB commit, return code 001024
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[61955]: F6E Spool / Printing: Error synchronizing file /usr/sap/PRD/SYS/global/600JOBLG/0001X09300700X65046. Error 13
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[61955]: R38 Basis System: Error at DB commit, return code 001024
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[61955]: F6E Spool / Printing: Error synchronizing file /usr/sap/PRD/SYS/global/600JOBLG/0001X09300700X65046. Error 13
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[61955]: R38 Basis System: Error at DB commit, return code 001024
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[81921]: F6E Spool / Printing: Error synchronizing file /usr/sap/PRD/SYS/global/600JOBLG/0001X09500000X98496. Error 13
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[81921]: R38 Basis System: Error at DB commit, return code 001024
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[81921]: F6E Spool / Printing: Error synchronizing file /usr/sap/PRD/SYS/global/600JOBLG/0001X09500000X98496. Error 13
Dec  1 10:00:18 sapapp31-ha SAPPRD_22[81921]: R38 Basis System: Error at DB commit, return code 001024
Dec  1 10:01:00 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X10000100X25845
Dec  1 10:01:01 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X10000200X25730
Dec  1 10:01:01 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X0401000LX61757
Dec  1 10:01:01 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X09590001X65345
Dec  1 10:01:03 sapapp31-ha SAPPRD_22[50025]: F6E Spool / Printing: Error synchronizing file /usr/sap/PRD/SYS/global/600JOBLG/0001X08450000X56319. Error 13
Dec  1 10:01:03 sapapp31-ha SAPPRD_22[50025]: R38 Basis System: Error at DB commit, return code 001024
Dec  1 10:01:20 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X10011900X64804
Dec  1 10:01:20 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X09582002X53936
Dec  1 10:01:20 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X09562200X94140
Dec  1 10:01:22 sapapp31-ha pengine[10436]:  warning: Processing failed op monitor for vol_prdersvg on sapapp31: unknown error (1)
Dec  1 10:01:22 sapapp31-ha pengine[10436]:  warning: Processing failed op monitor for vol_prdglobalvg on sapapp31: unknown error (1)
Dec  1 10:01:25 sapapp31-ha SAPPRD_22[98244]: F3V Spool / Printing: Error 13 for write/read access to a file. File = /usr/sap/PRD/SYS/global/600JOBLG/0001X10012500X70284


Dec  1 10:19:01 sapapp31-ha SAPPRD_11[55847]: Unable to change to Directory /usr/sap/PRD/ERS11/work. (Error 2 No such file or directory) [/bas/753_REL/src/proj/ntserv/ntservsserver.cpp 4527]
Dec  1 10:19:02 sapapp31-ha SAPInstance(rsc_sap_PRD_ERS11)[55487]: ERROR: sapstartsrv for instance PRD-ERS11 could not be started!
Dec  1 10:19:03 sapapp31-ha pengine[10436]:  warning: Processing failed op monitor for vol_prdglobalvg on sapapp31: unknown error (1)


Dec 01 05:18:42 [10436] sapapp31-ha    pengine:    error: unpack_rsc_op:        Preventing rsc_sap_PRD_ERS11 from re-starting anywhere: operation start failed 'not configured' (6)
Dec 01 05:18:42 [10436] sapapp31-ha    pengine:    error: unpack_rsc_op:        Preventing rsc_sap_PRD_ERS11 from re-starting anywhere: operation start failed 'not configured' (6)

Dec 01 10:19:00 [10437] sapapp31-ha       crmd:  warning: status_from_rc:       Action 33 (vol_prdersvg_monitor_0) on sapapp31 failed (target: 7 vs. rc: 0): Error
SAPInstance(rsc_sap_PRD_ERS11)[55487]:  2020/12/01_10:19:02 ERROR: sapstartsrv for instance PRD-ERS11 could not be started!




CS5264706 P2 - MajorFCA Bank S.p.A -- FBSLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 32.68 (thresh: 30)
CS5264299 P2 - MajorETRO SPA -- ETOMemory Swap CRITICAL: Swap free 49.92% (thresh 50:%)
CS5263951 P2 - MajorETRO SPA -- ETOMemory Swap CRITICAL: Swap free 49.99% (thresh 50:%)



pHANA 10.148.24.145	msc-phana-1024-3.imzcloud.ibmammsap.local	MDCSERVERQ1	10.12.6.76	172.17.154.76
10.148.24.187	root Be5v4BlHC5   IPMI    root EBbnAFz4



TSCMLPRD 10.207.61.36
/oracle/TSP/19.0.0  >> 50 GB >> Please check the permissions as well.
/sapstage  >> 20 GB done
/oracle/stage >>20GB


tsparchvg     1   4   0 wz--n- 128.00g   68.00g
tspdatavg     2   6   0 wz--n- 519.99g   24.99g
tsplogvg      2   9   0 wz--n-  61.99g   24.99g


[root@tscmlprd sapstage]$ df -hT .
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/tspappvg-sapstage_lv ext4  4.8G   10M  4.6G   1% /sapstage

 tspappvg      1  16   0 wz--n- 160.00g  424.00m


CS5279522 P2 - MajorControladora De Negocios -- CNGNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GRC01- KB0010973SQ-SAP-TRIO-B1
CS5279524 P2 - MajorLiberty Utilities (Canada) Corp -- LBUNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUPO1AP01- KB0010973SQ-SAP-TRIO-B1




root   ZKCeLx%7DAEG7u@   

IPMI root 



CS5280685 P2 - MajorIAG GBS Limited -- IA1Service master CRITICAL: 0 master processes running (thresh 1:)SQ-SAP-TRIO-A2
CS5282552 P2 - MajorHAVI Logistics -- HAVhav#ITM Agent Offline: KC4-deeh12hav100c:SysSQ-SAP-TRIO-B2


CS5285447 P2 - MajorTecnicas Reunidas S.A. -- TREMemory Swap CRITICAL: Swap free 49.73% (thresh 50:%)SQ-SAP-TRIO-B2
CS5285582 P2 - MajorManchester Airport Group -- MNGMemory Swap CRITICAL: Swap free 49.96% (thresh 50:%)SQ-SAP-TRIO-B2
CS5285939 P2 - MajorAGEAS -- AGEMemory Swap CRITICAL: Swap free 49.81% (thresh 50:%)SQ-SAP-TRIO-B1




SAPBOREPO 10.207.61.40
/oracle/BOP/19.0.0 >> 50 GB >> Please check the permissions as well and please make a entry in fstab as well.
/sapstage >> 20 GB
/oracle/stage >>20GB




ADSPRDS 10.207.61.29
/oracle/ASD/19.0.0 >> 50 GB >> Please check the permissions as well and please make a entry in fstab as well.
/sapstage >> 20 GB
/oracle/stage >>20GB


lvcreate -L 50G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab



MGGGBJPECCX02	lonhana-1024-39.xsportal.local
MGGGBJPECCX04	lonhana-1024-48.xsportal.local
MGGGBJPECCX06	lonhana-1024-18.xsportal.local
MGGGBJPECCX08	lonhana-1024-50.xsportal.local
MGGGBJSECCX02	lonhana-1024-31.xsportal.local
MGGGBJDECCX02	lonhana-1024-6.xsportal.local
MGGGBJQECCX02	lonhana-1024-35.xsportal.local
MGGGBJVECCX02	lonhana-1024-38.xsportal.local
MGGGBJVECCX04	lonhana-1024-24.xsportal.local
MGGGBJVECCX06	lonhana-1024-20.xsportal.local
MGGGBJVECCX08	lonhana-1024-24.xsportal.local
MGGGBJPGTSX02	lonhana-1024-37.xsportal.local
MGGGBJSGTSX02	lonhana-1024-34.xsportal.local
MGGGBJDGTSX02	lonhana-1024-10.xsportal.local
MGGGBJQGTSX02	lonhana-1024-36.xsportal.local
MGGGBJPSOLX02	lonhana-1024-23.xsportal.local
MGGGBJDSOLX02	lonhana-1024-23.xsportal.local
MGGGBJQECCY02	lonhana-1024-49.xsportal.local
MGGGBJQGTSY01	not found in HANA sheet
MGGGBJDECCY02	lonhana-1024-10.xsportal.local
MGGGBJDGTSY02	lonhana-1024-46.xsportal.local
MGGGBJTGTSX02	lonhana-1024-49.xsportal.local



172.18.8.19 qfrxmotk64
172.18.8.23 qfrxk141
172.18.8.21 qfrxmotk14




bgeu4ZTT


biprdapp1
biprdapp3
tsgpprd


 CS5335528	Hino Motors Ltd -- HNO	P1 - Severe	Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)	SQ-SAP-TRIO-B3
CS5335488	Hino Motors Ltd -- HNO	P1 - Severe	Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)	SQ-SAP-TRIO-B3



Sorry, we are unable to open your deposit account right now, as all required details for Online account Opening are currently not available in your account data, available with Bank. Please visit your nearest branch for completing the same and try again.


SP5 DB - IA2S4HPRDDB - 10.133.15.36		LON
SP5 DB HA-DR - IA2S4HPRDDBH - 10.133.15.37	LON
SP5 DB DR - IA2S4HPRDDDR - 10.199.15.207	FRA
GP5 DB - IA2MDGPRDDB - 10.133.15.35	LON
GP5 DB DR - IA2MDGDDB - 10.199.15.203	FRA


After patch and reboot the server. we found network interface card is missing.
Solution :-
Need to edit the below file /etc/modprobe.d/vmxnet3.conf before reboot the server its should not impact to the network card issue.(comment the line #options vmxnet3 disable_lro=1)
vi /etc/modprobe.d/vmxnet3.conf
 #options vmxnet3 disable_lro=1 


IA2S4HPRDDB 
IA2S4HPRDDBH 
IA2S4HPRDDDR 
IA2MDGPRDDB 
IA2MDGDDB

shutdown -rf now "CS5375969" 

ia2s4hprddbh	10.164.238.209	lonhana-2048-6.xsportal.local	
ia2s4hprdddr	10.85.139.141	fra02-p2-hana-2048-01.xsportal.local	



10.164.238.209	lonhana-2048-6.xsportal.local	10.164.238.133	root/SnHM68Mxfa
10.85.139.141	fra02-p2-hana-2048-01.xsportal.local	10.85.139.144	root/UkJ7qqctyh


number:CS2090461



CS5345116 P2 - MajorSuncor Energy Inc. -- SNCCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%
CS5345618 P2 - MajorSuncor Energy Inc. -- SNCCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=0.00% system=0.00% iowait=0.00% idle=0.00%
CS5345251 P2 - MajorTecnicas Reunidas S.A. -- TREMemory Swap CRITICAL: Swap free 49.99% (thresh 50:%)
CS5345455 P2 - MajorEgyptian Refining Company -- EGRDisk Utilization /backup FATAL: Free 53.87MB/0.05% (thresh @0:5%)
CS5345879 P2 - MajorAmerican Airlines -- Z5Fz5f#aaecprha#Error log entry: 4D91E3EA: A split has been detected.
CS5346212 P2 - MajorLiberty Utilities (Canada) Corp -- LBUNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUPW1AP01- KB0010973

CS5344066 P2 - MajorMeggitt PLC -- MGGXVTMGG (HANADB)|HDB_ALERT_METRIC_2001|High Hana service ping timeSQ-SAP-TRIO-B1
CS5346241 P2 - MajorMitsubishi Motors North America, Inc. --...Memory Swap CRITICAL: Swap free 49.86% (thresh 50:%)
CS5346523 P2 - MajorMitsubishi Motors North America, Inc. --...Memory Swap CRITICAL: Swap free 49.98% (thresh 50:%)


SL tickets

Pooja  CS5144069	I BABY PRASHANTHI PUDOTA	18 Nov
Asmita CS5221300	I BABY PRASHANTHI PUDOTA	26 Nov	

Complaint Or Service Request Successfully created. Your Service Number is 8000156539


CS5366430 P2 - MajorDelta Airlines -- DALMemory Swap CRITICAL: Swap free 49.51% (thresh 50:%)
CS5369374 P2 - MajorIAG - British Airways -- IA2Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)
CS5369361 P2 - MajorMitsubishi Motors North America, Inc. --...Memory Swap CRITICAL: Swap free 49.72% (thresh 50:%)



root/ Tc5v9VPner 10.116.145.50		root 	bb8EHe%ipNJZ67@


AT
ALVIN THEW
Work notesâ€¢25-11-2020 14:46:49
after 2 weeks, you may delete the list below


Name State Status Provisioned Space Used Space Host CPU Host Mem
A0EASG012XVM029 Powered Off Normal 264.2 GB 42.3 GB 0 Hz 0 B
A0EASG012XVM030 Powered Off Normal 116.2 GB 43.59 GB 0 Hz 0 B
A0EASG012XVM028 Powered Off Normal 108.18 GB 23.68 GB 0 Hz 0 B
A0EASG012XVM026 Powered Off Normal 108.18 GB 22.64 GB 0 Hz 0 B
A0EASG012XVM023 Powered Off Normal 108.18 GB 30.82 GB 0 Hz 0 B
A0EASG012XVM020 Powered Off Normal 232.19 GB 41.41 GB 0 Hz 0 B
A0EASG012XVM035 Powered Off Normal 116.18 GB 30.61 GB 0 Hz 0 B
A0EASG014XVM043 Powered Off Normal 148.19 GB 16.61 GB 0 Hz 0 B
A0EASG012XVM024 Powered Off Normal 232.19 GB 35.25 GB 0 Hz 0 B



tsls4proddb was rebooted around 18.12.2020 03:31 IST, DB failed over to tsls4proddbh
Dec 17 14:31:32 [34981] tsls4proddb      attrd:     info: attrd_peer_update:    Setting hana_prd_sync_state[tsls4proddbh]: SFAIL -> SOK from tsls4proddb
Dec 18 04:15:40 [112911] tsls4proddb      attrd:   notice: attrd_peer_update:   hana_prd_sync_state[tsls4proddb]: local value '(null)' takes priority over 'SFAIL' from tsls4proddbh

reboot   system boot  4.12.14-95.54-de Fri Dec 18 03:30 - 09:31  (06:01)
[root@tsls4proddb ibmrmalik1]$ df -hT |grep -i sds
che01ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  2.9T  2.8T  51% /sds


che01ammsol01.imzcloud.ibmammsap.local:/sds  3.6T  2.8T  677G  81% /sds

tsls4proddb	10.162.186.206	tta-che01-pod1-phana-h8-12000-001.imzcloud.ibmammsap.local
root / May55now#


[root@tsls4proddb ibmrmalik1]$ cat /var/log/messages |grep -i taint
Dec 18 03:31:23 tsls4proddb kernel: [  100.417954] tmhook: loading out-of-tree module taints kernel.
Dec 18 03:31:23 tsls4proddb kernel: [  100.418016] tmhook: module verification failed: signature and/or required key missing - tainting kernel

[root@tsls4proddb ibmrmalik1]$ sar -r
Linux 4.12.14-95.54-default (tsls4proddb)       12/18/20        _x86_64_        (448 CPU)

00:00:01    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
00:10:01    4269628652 4283213648 8079738220     63.71   1272972 313963348 8468091592     66.77 8070588796 302200944      1008
00:20:01    4267395980 4280984940 8081995636     63.72   1273004 313965872 8463320820     66.73 8072834476 302205304       432
00:30:02    4264325980 4277926748 8085047488     63.75   1273004 313985068 8467157704     66.76 8075892620 302221168       648
00:40:01    4294197368 4307797768 8055173124     63.51   1273004 313984292 8434227956     66.50 8046059596 302219968       772
00:50:01    4289982020 4303581856 8059385836     63.54   1273004 313983492 8438090500     66.53 8050218840 302219664       616
01:00:01    4287904656 4301506236 8061468068     63.56   1273008 313984900 8442592268     66.57 8052336684 302220560       332
01:10:01    4292360180 4305957896 8056995272     63.53   1273008 313988804 8443627572     66.57 8047850040 302224064      1432
01:20:01    4287286732 4300887428 8062079072     63.57   1273008 313992260 8445721028     66.59 8052931388 302227524       892
01:30:01    4281632148 4295241608 8067712796     63.61   1273008 313999900 8455566000     66.67 8058578832 302234068       336
01:40:01    4295820672 4309433992 8053524400     63.50   1273008 314004036 8442168344     66.56 8044408176 302237416       472
01:50:01    4294254524 4307867072 8055083580     63.51   1273008 314010060 8443554884     66.57 8045950312 302245488       556
02:00:01    4287465996 4301080224 8061876148     63.56   1273008 314011376 8464892028     66.74 8052768600 302244280       928
02:10:01    4285578280 4299198540 8063744304     63.58   1273008 314016844 8462533320     66.72 8054592108 302249312      1000
02:20:01    4286040128 4299663936 8063287900     63.58   1273008 314020452 8458665108     66.69 8054161660 302252640       840
02:30:01    4290206920 4303834988 8059103536     63.54   1273008 314031840 8460350072     66.71 8049933024 302279900       624
02:40:01    4285600188 4299228668 8063711244     63.58   1273008 314032116 8467409768     66.76 8054527252 302279188      1428
02:50:01    4284852512 4298483420 8064452052     63.58   1273008 314034112 8466056596     66.75 8055284240 302280900      1492
03:00:01    4295424888 4309048336 8053884408     63.50   1273008 314027808 8453609464     66.65 8044737908 302274492      1156
03:10:01    4309792496 4323422704 8039515912     63.39   1273008 314033356 8443426396     66.57 8030425836 302279460      1128
05:30:00            0         0         0      0.00         0         0         0      0.00         0         0         0
05:30:00            0         0         0      0.00         0         0         0      0.00         0         0         0
05:30:00            0         0         0      0.00 1623497637888 260610025586688         0      0.00         0 64424509440         0
Invalid system activity file: /var/log/sa/sa20201218


[root@tsls4proddb ibmrmalik1]$ sar -u
Linux 4.12.14-95.54-default (tsls4proddb)       12/18/20        _x86_64_        (448 CPU)

00:00:01        CPU     %user     %nice   %system   %iowait    %steal     %idle
00:10:01        all     11.19      0.92      0.73      0.04      0.00     87.12
00:20:01        all      8.40      0.01      0.54      0.05      0.00     91.01
00:30:02        all      9.58      0.00      0.58      0.05      0.00     89.78
00:40:01        all     10.77      0.09      0.69      0.00      0.00     88.44
00:50:01        all      7.09      0.00      0.48      0.04      0.00     92.39
01:00:01        all      6.18      0.00      0.38      0.04      0.00     93.40
01:10:01        all      9.56      0.00      0.47      0.00      0.00     89.96
01:20:01        all      6.01      0.06      0.36      0.03      0.00     93.54
01:30:01        all      5.71      0.00      0.36      0.03      0.00     93.89
01:40:01        all      5.95      0.05      0.37      0.00      0.00     93.62
01:50:01        all      4.95      0.06      0.31      0.03      0.00     94.65
02:00:01        all      6.46      0.00      0.37      0.03      0.00     93.14
02:10:01        all     14.06      0.00      0.64      0.02      0.00     85.27
02:20:01        all     10.45      0.00      0.51      0.03      0.00     89.01
02:30:01        all      5.57      0.06      0.34      0.03      0.00     94.00
02:40:01        all      7.73      0.00      0.43      0.02      0.00     91.82
02:50:01        all      6.80      0.00      0.37      0.03      0.00     92.79
03:00:01        all      5.73      0.00      0.34      0.03      0.00     93.90
03:10:01        all     10.12      0.00      0.48      0.01      0.00     89.39
Invalid system activity file: /var/log/sa/sa20201218




Server got rebooted on its own
Case number
TS004698280
Sev1 raised to SL as well to look for any h/w issues number:CS2098793



CS5381839 P2 - MajorAlpro Comm. VA -- APRLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 89.48 (thresh: 30)
CS5382279 P2 - MajorMethanol Chemicals Company-Chemanol -- CH5Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAHOERECP- KB0010973



CS5382540	Suncor Energy Inc. -- SNC	P2 - Major	Memory Swap CRITICAL: Swap free 49.70% (thresh 50:%)	SQ-SAP-TRIO-B2
CS5382408	American Airlines Inc. -- A2A	P2 - Major	Memory Swap CRITICAL: Swap free 40.01% (thresh 50:%)	SQ-SAP-TRIO-B2
CS5382273	IAG GBS Limited -- IA1	P3 - Minor	Disk Utilization /opentext_backup MINOR: Free 56797.93MB/20.00% (thresh @10.01:20%)	SQ-SAP-TRIO-B1
CS5381839	Alpro Comm. VA -- APR	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 89.48 (thresh: 30)	SQ-SAP-TRIO-B1


CS5387966 P2 - MajorTelstra Melbourne -- QLAMemory Swap CRITICAL: Swap free 47.34% (thresh 50:%)SQ-SAP-TRIO-B1
CS5387318 P2 - MajorCOTY Inc. -- CTUNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB4DB02- KB0010973SQ-SAP-TRIO-B1
CS5386907 P2 - MajorCOTY Inc. -- CTUPing Availability CRITICAL - 10.12.10.122: rta nan, lost 100%SQ-SAP-TRIO-B1

10.65.162.204	coty-wdc04-phana-4096-13.imzcloud.ibmammsap.local
10.65.162.241	root/ MUs6tn4nxD		root EuM5HZM9

number:CS2099827  raised with SL    FNTS9GN raised is the vendor ticket

CTUBWQB4DB02:/var/log # /usr/bin/last -xF | egrep "reboot|shutdown|runlevel|system"
runlevel (to lvl 3)   4.12.14-95.57-de Sat Dec 19 05:39:05 2020 - Sat Dec 19 05:51:57 2020  (00:12)
reboot   system boot  4.12.14-95.57-de Sat Dec 19 05:38:02 2020 - Sat Dec 19 05:51:57 2020  (00:13)

Problem record PRB0054628 created and RCA0004036 assigned to Name
Attention SAP Technical Team: @Ravi Malik (TRIO B - OS Support-AP)

1. Please update the â€œAssignment Groupâ€ and â€œAssigned to Fieldsâ€ in the validated SEV1 ticket.
2. Populate the Impacted Environment tab and Validate â€œSLA Impacted Minutesâ€ Click â€œSubmitâ€.



Download link
https://support.lenovo.com/in/en/solutions/lnvo-tcli

Download linux executable file

Downloading and using OneCLI on Linux

This section describes how to download and use OneCLI on Linux. The procedure is the same for both Red Hat and SUSE platforms.
Procedure
Step 1.
Download the OneCLI zip file from Lenovo XClarity Essentials OneCLI Web siteto the target server or to the system administrator workstation.
Step 2.
Copy the tgz file to the desired directory and decompress it by running the following shell command.
tar -xvf lnvgy_utl_lxce_oneclixxx-xxx.tgz
Step 3.
Run ./OneCli. All options are displayed.

Thank you,
Donnie H.
Compute Service Engineer
IBM Cloud
Is this response helpful?


Succeeded in writing inventory result to /tmp/logs/OneCli-426974-20201219-132625/OneCli-inventory-7X13-J3024NYX-SLES12--20201219-135551.xml
Succeeded in zipping xml to /tmp/logs/OneCli-426974-20201219-132625/OneCli-inventory-7X13-J3024NYX-SLES12--20201219-135551.zip
Succeeded in writing HTML inventory result to /tmp/logs/OneCli-426974-20201219-132625/OneCli-inventory-7X13-J3024NYX-SLES12--20201219-135551
[3m18s]Get FFDC succeeded. [100%][==================================================================================================================================>]
FFDC log has been saved to:/tmp/logs/OneCli-426974-20201219-132625/


TQAADS,	10.7.1.18
TQABOPRD1, 10.7.1.27	
TQACLDCONPRD, 10.7.1.25
TQASOLMAN, 10.7.1.14
TQAERPDEVH, 10.7.1.33
TQAERPPRD1, 10.7.1.17
TQAERPQA, 10.7.1.16



CS5405131 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1HCCDEVWD- KB0010973
CS5405103 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1HCCPRDWD- KB0010973
CS5405101 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1S4HPRDAPP- KB0010973
CS5405076 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1PODEVAPP- KB0010973
CS5405072 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1FIODEVDB- KB0010973
CS5405068 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1FTSPRDAPP- KB0010973
CS5405056 IAG GBS Limited -- IA1P2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on IA1NFSPRDAPP- KB0010973



CS5409180 Tata Steel Limited -- TTAP3 - MinorLinux Server : Create a directory in SAPAPP22


CS5409057	Manitoba Telecom Services -- MTS	P2 - Major	Service master CRITICAL: 0 master processes running (thresh 1:)	MTSBODSQAS01	SQ-SAP-TRIO-B1
CS5409346	Manitoba Telecom Services -- MTS	P2 - Major	Service master CRITICAL: 0 master processes running (thresh 1:)	MTSBODSDEV01	SQ-SAP-TRIO-B1
CS5409298	Manitoba Telecom Services -- MTS	P2 - Major	Memory Swap CRITICAL: Swap free 46.63% (thresh 50:%)	DMARTQAS01	SQ-SAP-TRIO-B1
CS5409170	Manitoba Telecom Services -- MTS	P2 - Major	Service master CRITICAL: 0 master processes running (thresh 1:)	PRDBODS01	SQ-SAP-TRIO-B1


CS5411717 P2 - MajorBRENNTAG PTE LTD -- BAPCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=97.00% system=2.50% iowait=0.00% idle=0.00%SQ-SAP-TRIO-B1	BAPV321100



DLTHPEHDB4-DR	10.4.5.254	10.250.17.254
10.148.24.149	delta-wdc04-phana-4096-01.imzcloud.ibmammsap.local
root  Set44now@

10.148.24.149	Service ping		Notify users	Immediately	
Down



CS5413988 P1 - SevereCMA CGM -- CMALinux team - Unable to login to smdbuatur3SQ-SAP-TRIO-B1
10.127.155.90	parhana-1024-6.xsportal.local	pHANA


CS5414062 Manitoba Telecom Services -- MTSP3 - MinorSystem NTP Drift CRITICAL: Could not determine offset to check NTPDRIFT



cat /etc/mtab |grep -i che01ammsol01;cat /etc/auto.nfs |grep -i che01ammsol01; cat /etc/fstab |grep -i che01ammsol01; df -hT |grep -i che01ammsol01
 
 
 
CS5484416	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mailman MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484407	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/pgsql MINOR: Free 8369.50MB/16.85% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484406	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/pgsql MINOR: Free 8369.50MB/16.85% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484381	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /boot/grub2/i386-pc MINOR: Free 8369.50MB/16.85% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484365	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization / MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484300	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mysql MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484293	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /opt MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484269	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/libvirt/images MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484263	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /home MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484261	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /.snapshots MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484258	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /tmp MINOR: Free 8369.50MB/16.85% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484253	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/lib/mariadb MINOR: Free 8360.91MB/16.83% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484243	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/opt MINOR: Free 8369.50MB/16.85% (thresh @10.01:20%)	SQ-SAP-TRIO-C2
CS5484239	FCA Bank S.p.A -- FBS	P3 - Minor	Disk Utilization /var/spool MINOR: Free 8369.50MB/16.85% (thresh @10.01:20%)	SQ-SAP-TRIO-C2 



CHG0186570 - SP4 Upgrade owned by @Ravi Malik (TRIO B - OS Support-AP)

TSLGLDEV - SP4 Upgrade to be performed by @Ravi Malik (TRIO B - OS Support-AP)

[root@tslgldev ibmrmalik]# cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux tslgldev 4.4.121-92.141-default #1 SMP Fri Sep 4 09:07:50 UTC 2020 (e4172b5) x86_64 x86_64 x86_64 GNU/Linux
Wed Jan  6 19:12:53 IST 2021
      Local time: Wed 2021-01-06 19:12:53 IST
  Universal time: Wed 2021-01-06 13:42:53 UTC
        RTC time: Wed 2021-01-06 13:42:53
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.


[root@tslgldev ibmrmalik]# cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux tslgldev 4.12.14-95.65-default #1 SMP Mon Nov 16 15:42:15 UTC 2020 (0306e79) x86_64 x86_64 x86_64 GNU/Linux
Wed Jan  6 20:12:52 IST 2021
      Local time: Wed 2021-01-06 20:12:52 IST
  Universal time: Wed 2021-01-06 14:42:52 UTC
        RTC time: Wed 2021-01-06 14:42:52
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.


SAPBIDEV - SP4 Upgrade to be performed by @Ravi Malik (TRIO B - OS Support-AP)

sapbidev /home/ibmrmalik# cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux sapbidev 4.4.121-92.141-default #1 SMP Fri Sep 4 09:07:50 UTC 2020 (e4172b5) x86_64 x86_64 x86_64 GNU/Linux
Wed Jan  6 19:18:12 IST 2021
      Local time: Wed 2021-01-06 19:18:12 IST
  Universal time: Wed 2021-01-06 13:48:12 UTC
        RTC time: Wed 2021-01-06 13:48:12
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
/usr/sap/trans  *(rw,sync,no_root_squash,no_subtree_check)
ibmninjam has logged on pts/2 from 146.89.140.60.
ibmninjam has logged on pts/3 from 146.89.140.60.


sapbidev /home/ibmrmalik# cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux sapbidev 4.12.14-95.65-default #1 SMP Mon Nov 16 15:42:15 UTC 2020 (0306e79) x86_64 x86_64 x86_64 GNU/Linux
Wed Jan  6 20:12:52 IST 2021
      Local time: Wed 2021-01-06 20:12:52 IST
  Universal time: Wed 2021-01-06 14:42:52 UTC
        RTC time: Wed 2021-01-06 14:42:52
       Time zone: Asia/Kolkata (IST, +0530)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
/usr/sap/trans  *(rw,sync,no_root_squash,no_subtree_check)




1. snchtnasa12	10.73.11.230
Error: no implicit conversion of nil into String

Rootcause:	[ibmbreddy@snchtnasa12 ~]$ hostname -f
				hostname: Unknown host
				[ibmbreddy@snchtnasa12 ~]$ 

2. snchtriqa13	10.73.12.94  - Node not found in chef-automate, please check if this node is still active.
Unable to access this node, also confirm it this is correct IP.

3. snchbwjta13	10.73.11.142
				- Failed - chef_client_updater[Chef 13.9.4] had an error: uninitialized constant Mixlib::Versioning
Unable to access this node, please check the IP as well.

4. snchldjda11	10.73.11.57	- failed - 'template[/usr/local/ncpa/etc/ncpa.cfg.d/diskfree.cfg]'
				  undefined method `[]' for nil:NilClass
df command is taking too long, because of which the ohai is not getting completed.
Please fix this..


[root@snchtnasa12 ~]$ cat /var/chef/cache/chef-stacktrace.out |grep -i error
TypeError: no implicit conversion of nil into String
Recipe Compile Error in /var/chef/cache/cookbooks/smt/attributes/default.rb


MGG sev1 
Case #02837810 raised to RHEL




CS5560583
Need to fail over TTA Node tsls4proddbh to  Node tsls4proddb:
CS2120207 TTA SL ticket for maintenance



10.65.162.204	coty-wdc04-phana-4096-13.imzcloud.ibmammsap.local


CS5560884 P1 - SevereTata Steel Limited -- TTALog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-01-08-14-58-37 for details.


CS5560583 master ticket for the maintenance by SL activity

CS5560884 P1 - SevereTata Steel Limited -- TTALog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-01-08-14-58-37 for details.
CS5560813 P2 - MajorTata Steel Limited -- TTAResource Pacemaker Active Nodes CRITICAL: CLUSTER OK: 1 node online, 1 standby node, 7 resources configured (thresh 2:2)SQ-SAP-TRIO-B1
CS5560571 P2 - MajorTata Steel Limited -- TTANagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TSLBWPRDDB- KB0010973SQ-SAP-TRIO-B1
CS5562259  Tata Steel Limited -- TTA   Ping Availability CRITICAL - 10.207.61.113: rta nan, lost 100%  P2


 CS5555178 COTY Inc. -- CTUP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB4DB02- KB0010973CTUBWQB4DB02SQ-SAP-TRIO-B2
10.65.162.204	coty-wdc04-phana-4096-13.imzcloud.ibmammsap.local
IPMI 10.65.162.241 root MUs6tn4nxD
SL ticket number:CS2120673


CS5562562   COTY Inc. -- CTU   Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)  P1


 CS5562920 Tata Steel Limited -- TTAP1 - SevereHost Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)TSLS4PRODDBHSQ-SAP-TRIO-B1
 
 
1. Once the activity completed - start the cluster service and move the cluster to manage state -

2. reregister from tsls4proddb to tsls4proddbh

3.change from standby to online
â€œcrm node standby <nodename>â€ command, all resources on that node will moved to the
second node. Use â€œcrm node online <nodename>â€ to bring the node back online. This is the suggested way to do a
failover test

4. Clear the failed count
5. Wait for sync to be complete and check the cluster status
6. Re-enable DR replication from production to DR



 CS5573379 Tata Steel Limited -- TTAP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TSLBWPRDDB- KB0010973TSLBWPRDDBSQ-SAP-TRIO-B1
CS5573373 Liberty Utilities (Canada) Corp -- LBUP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUPS1DB01- KB0010973LBUPS1DB01SQ-SAP-TRIO-B1



1- When did the crash occur?
sapapp31-ha rebooted - Jan 10 05:36 IST
sapapp31 rebooted - Jan 10 05:41 IST

2- Please provide the exact time and date. What timezone are the times in?
sapapp31-ha rebooted - Jan 10 05:36 IST
sapapp31 rebooted - Jan 10 05:41 IST





CS5598817	Panasonic North America -- PN4	P2 - Major	LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 21.35 (thresh: 20)	SQ-SAP-TRIO-B1
CS5598795	Alpro Comm. VA -- APR	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 104.75 (thresh: 30)	SQ-SAP-TRIO-B1



Printer config	SAP-HEC-SWIVEL:New Zebra Printer Creation in OS level	CS5593729
IP  		Subnet  		Gateway  		Device  		Model  		Serial Number
10.10.90.22	255.255.255.0      10.10.90.254            USFLDAVPT-05721            Zebra-Z200        52C183905721
10.10.90.23     255.255.255.0      10.10.90.254            USFLDAVPT-05749            Zebra-Z200        52C183905749
10.10.90.24     255.255.255.0      10.10.90.254            USFLDAVPT-02890            Zebra-Z200        52J183702890
10.10.90.25     255.255.255.0      10.10.90.254            USFLDAVPT-02740            Zebra-Z200        52J203702740
10.10.90.26     255.255.255.0      10.10.90.254            USFLDAVPT-02726            Zebra-Z200        52J203702726

Printer setup
if printer down just do cupsenable <printer queue name>
To see if printer is ready lpq -P <printerprinter queue name>

check for any printer with short name
lpstat -t |grep gs15
lpstat -t|grep -i 149.223.90.58   (grep ip from SAP printer page to find the printer) 

[root@zffsappdb007 ibmrmalik]# lpstat -t|grep -i 149.223.90.58
device for gs15: lpd://149.223.90.58
[root@zffsappdb007 ibmrmalik]# lpstat -t |grep -i gs15
device for gs15: lpd://149.223.90.58
gs15 accepting requests since Mon Nov 16 12:26:41 2020
printer gs15 is idle.  enabled since Mon Nov 16 12:26:41 2020

lpadmin -x <queue name>   to delete a queue
# lpadmin -p 922_SUNGB_ADB_P002 -v socket://149.223.90.58 -E    to create a new print queue where -p is the queue name and -v is the ip 
alternatively use
lpadmin -p 922_ -v socket://149.223.90.58:9600 -E     this is with specific port 9600
# cupsaccept  922_SUNGB_ADB_P002    to start accepting the prints to this queue


/var/log/cups/access_log for logs of printer grep with the queue name




Internal Suse Ticket : TS004792314
https://www.ibm.com/mysupport/s/case/5003p00002TWLavAAH/pacemaker-node-fence-rebooted-need-to-know-the-rca-sapapp31-sapapp31ha

External Suse Ticket: 00270602

 https://scc.suse.com/support/cases
 puneravi	rmalik@us.ibm.com
 Aq12wsde34rfgt56


sapapp31-ha / sapapp31


egrep -i 'error|fail|warn|fatal|fence|timeout|time-out'  /var/log/cluster/corosync.log | grep -v "+++ OCF_FAILED_MASTER" | grep -v check_initrd_warning

grep -i "vol_prdersvg"  /var/log/cluster/corosync.log  also grep with Time or Timeout



A0EASG014XVM007		SVCD1SRV0 	10.6.1.16 	10.92.99.115


SID	Hostname	CFN IP	IMZ IP
App cluster
P02	aprerpprdd	10.10.21.40	10.135.197.26	yes
P02	aprerpprd1	10.10.21.47	10.135.197.67	yes 
App servers
P02	aprerpprd2	10.10.21.39	10.135.197.13	yes
P02	aprerpprd3	10.10.21.27	10.135.197.17	yes
DB2 cluster
P02	aprerpprdd	10.10.21.40	10.135.197.26		yes
	       aprerpprdd-ha	10.10.21.65	10.135.197.44	yes



RCA0004154


https://gts-cmas.slack.com/help/requests/3317896?replied=1#reply



CTU
Tuesday Jan 19, 8amET

SL ticket CS2120673	128331834 and 127745992

Lenovo recommend to disable C-States in BIOS/UEFI settings and see if that resolves the issue with the CPU.

Recommended Action for further Problem Determination and a possible resolution :
1) Power down the server gracefully
2) With the server powered off, restart the IMM through the IMM interface.
3) Wait for connectivity to be restored.
4) Power on server and monitor 

Raised  CS2129876 for fixing as per Lenovo recomendation


sng01ammtsm001  146.89.140.178
Tc5v9VPner	root
https://10.116.145.50:443	


params ipaddr=146.89.142.92 login="vsphere.local\crmstnmgr" plug=node1 password_script="/usr/local/sbin/getpass.py -g "crmstnmgr" shell_timeout=60 ssl=1 ssl_insecure=1 login_timeout=60 filter="filter.names=node1"
op stop interval=0 on-fail=ignore timeout=60s
op start interval=0 on-fail=restart timeout=60s
op monitor enabled=false on-fail=restart timeout=60s interval=0


CS5664961	
Server: DLTQEAHDB
CDIR: DAL
delta-dal09-phana-2048-01.imzcloud.ibmammsap.local  /// Private IP: 10.120.28.99
SL ticket number:CS2132420
IPMI 10.120.28.120 root LubrKgXm9b


/oracle/stage - 15GB
/oracle/EDD/19.0.0 - 5OGB

lvcreate -L 15G -n oracle_stage_lv eddappvg
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab


/dev/eddarchvg/oracle_EDD_19.0_lv




	sapdxpdb01	A0FGSG014XVM014	
	sjmqgpdb01	A0FGSG014XVM019	
	sjmqxpdb01	A0FGSG014XVM026
	sjmqpqdb01	A0FGSG014XVM021
	sjmppqdb01	A0FGSG014XVM036	
	sjmpxpdb01	A0FGSG014XVM044	
	sjmpgpdb01	A0FGSG014XVM033
	
	
	
CS5688445 - - - > Tata Stel Hypercare.
Please monitor pacemaker cluster status of the following cluster nodes, every hour and send cluster output to the channel #tta_hypercare_monitoring,
* Node sapapp31:
* Node sapapp31-ha:

* Node sapcrmapp4-ha:
* Node sapcrmapp4:

* Node ewmapp3:
* Node ewmapp3-ha:





PCD - WNXECCAPPD01
PCQ - WNXECCAPPQ01
PCP - WNXECCAPPP01

Printer config	SAP-HEC-SWIVEL:New Zebra Printer Creation in OS level	CS5593729
We have requirement from functional team to create label printers
All these  5 printer are connected to network. 

IP  		Subnet  		Gateway  		Device  		Model  		Serial Number
10.10.90.22	255.255.255.0      10.10.90.254            USFLDAVPT-05721            Zebra-Z200        52C183905721
10.10.90.23     255.255.255.0      10.10.90.254            USFLDAVPT-05749            Zebra-Z200        52C183905749
10.10.90.24     255.255.255.0      10.10.90.254            USFLDAVPT-02890            Zebra-Z200        52J183702890
10.10.90.25     255.255.255.0      10.10.90.254            USFLDAVPT-02740            Zebra-Z200        52J203702740
10.10.90.26     255.255.255.0      10.10.90.254            USFLDAVPT-02726            Zebra-Z200        52J203702726

Printer setup
if printer down just do cupsenable <printer queue name>
To see if printer is ready lpq -P <printer queue name>

check for any printer with short name
lpstat -t |grep gs15
lpstat -t|grep -i 149.223.90.58   (grep ip from SAP printer page to find the printer) 

[root@zffsappdb007 ibmrmalik]# lpstat -t|grep -i 149.223.90.58
device for gs15: lpd://149.223.90.58
[root@zffsappdb007 ibmrmalik]# lpstat -t |grep -i gs15
device for gs15: lpd://149.223.90.58
gs15 accepting requests since Mon Nov 16 12:26:41 2020
printer gs15 is idle.  enabled since Mon Nov 16 12:26:41 2020

lpadmin -x <queue name>   to delete a queue
# lpadmin -p 922_SUNGB_ADB_P002 -v socket://149.223.90.58 -E    to create a new print queue where -p is the queue name and -v is the ip 
alternatively use
lpadmin -p 922_ -v socket://149.223.90.58:9600 -E     this is with specific port 9600
# cupsaccept  922_SUNGB_ADB_P002    to start accepting the prints to this queue


/var/log/cups/access_log for logs of printer grep with the queue name

lpadmin -p 52C183905721 -E -v USFLDAVPT-05721 -m ppd


[root@WNXECCAPPD01 ibmrmalik1]$ lpinfo -m | grep -i Zebra
drv:///sample.drv/zebracpl.ppd Zebra CPCL Label Printer
drv:///sample.drv/zebraep1.ppd Zebra EPL1 Label Printer
drv:///sample.drv/zebraep2.ppd Zebra EPL2 Label Printer
drv:///sample.drv/zebra.ppd Zebra ZPL Label Printer


[root@WNXECCAPPD01 ibmrmalik1]$ lpinfo -v
network lpd
network https
network socket
network beh
direct scsi
network smb
network ipp
network http


USFLDAVPT-05721://10.10.90.22/


lpadmin -p USFLDAVPT-05721 -P drv:///sample.drv/zebra.ppd - v lpd://10.10.90.22/PASSTHRU -E

lpadmin -p USFLDAVPT-05721 -v socket://10.10.90.22/ -E


lpadmin -p USFLDAVPT-02726 -v socket://10.10.90.26:9100

cupsenable USFLDAVPT-02726
cupsaccept USFLDAVPT-02726


lpadmin -p USFLDAVPT-02890 -v socket://10.10.90.24:9100;cupsenable USFLDAVPT-02890;cupsaccept USFLDAVPT-02890

lpadmin -p USFLDAVPT-02740 -v socket://10.10.90.25:9100;cupsenable USFLDAVPT-02740;cupsaccept USFLDAVPT-02740

lpadmin -p USFLDAVPT-02726 -v socket://10.10.90.26:9100;cupsenable USFLDAVPT-02726;cupsaccept USFLDAVPT-02726




CS5695004 P2 - MajorFitbit Inc -- FBTMemory Swap CRITICAL: Swap free 48.52% (thresh 50:%)
CS5696663 P2 - MajorFitbit Inc -- FBTMemory Swap CRITICAL: Swap free 48.52% (thresh 50:%)
CS5697181 P2 - MajorFitbit Inc -- FBTMemory Swap CRITICAL: Swap free 49.91% (thresh 50:%)
CS5697734 P2 - MajorFitbit Inc -- FBTMemory Swap CRITICAL: Swap free 49.91% (thresh 50:%)
CS5695418 P2 - MajorFitbit Inc -- FBTMemory Swap CRITICAL: Swap free 49.91% (thresh 50:%)
CS5697944 P2 - MajorAlpro Comm. VA -- APRLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 107.67 (thresh: 30)
CS5698406 P2 - MajorAlpro Comm. VA -- APRLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 107.67 (thresh: 30)





MGGGBJSECCX02	10.133.18.164
10.164.30.166	lonhana-1024-31.xsportal.local



* Node br3psoldb40:
* Node br3psoldb41:


Server Type: Production                                                  *
*       Hostname: br3psoldb40                                                 *
*         CFN IP: 10.3.113.120                                                *
*         IFN IP: 10.138.13.48                                                *
*         SBR IP: 10.141.24.24                                                *
*        SAP SID: PSA                                                         *
*   HANA Tenants: PSA


su - psaadm -c "hdbnsutil -sr_register --remoteHost=br3psoldb40 --remoteInstance=84 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEB" 


Node Attributes:
* Node br3psoldb40:
    + hana_psa_clone_state              : PROMOTED
    + hana_psa_op_mode                  : logreplay
    + hana_psa_remoteHost               : br3psoldb41
    + hana_psa_roles                    : 4:S:master1:master:worker:master
    + hana_psa_site                     : NODEA
    + hana_psa_srmode                   : sync
    + hana_psa_sync_state               : PRIM
    + hana_psa_version                  : 2.00.048.01.1596718894
    + hana_psa_vhost                    : br3psoldb40
    + lpa_psa_lpt                       : 30
    + master-rsc_SAPHana_PSA_HDB84      : 100
* Node br3psoldb41:
    + hana_psa_clone_state              : UNDEFINED
    + hana_psa_op_mode                  : logreplay
    + hana_psa_remoteHost               : br3psoldb40
    + hana_psa_roles                    : 4:P:master1:master:worker:master
    + hana_psa_site                     : NODEB
    + hana_psa_srmode                   : sync
    + hana_psa_sync_state               : SFAIL
    + hana_psa_version                  : 2.00.048.01.1596718894
    + hana_psa_vhost                    : br3psoldb41
    + lpa_psa_lpt                       : 10
    + master-rsc_SAPHana_PSA_HDB84      : -9000
    
    
CS5751107 HollyFrontier Corporation -- HFCP2 - Majorunmount old and mount new /usr/sap/trans


CS5752793 - SUNCOR || Installation of compat-sap-c++-6 on OS (edited) 


CS5752873 - SUNCOR || Request for VM snapshot



CS5688445 - - - > Tata Stel Hypercare
sapapp31
sapcrmapp4
ewmapp3
tsls4proddb



CS5783537 P2 - MajorPanasonic North America -- PN4LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 24.77 (thresh: 20)
CS5783627 P2 - MajorPanasonic North America -- PN4LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 24.77 (thresh: 20)
CS5783974 P2 - MajorBRENNTAG PTE LTD -- BAPCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=81.59% system=18.41% iowait=0.00% idle=0.00%S


10.116.145.50
root   Tc5v9VPner

Your sosreport has been generated and saved in:
  /tmp/sosreport-rmalik.dummy-20210202161427.tar.xz


Feb  2 08:01:41 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:02:13 sng01ammtsm001 kernel: connection3:0: detected conn error (1011)
Feb  2 08:02:13 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:04:42 sng01ammtsm001 kernel: connection7:0: detected conn error (1011)
Feb  2 08:04:43 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 7:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:05:31 sng01ammtsm001 kernel: connection7:0: detected conn error (1011)
Feb  2 08:05:31 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 7:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:06:26 sng01ammtsm001 kernel: connection3:0: detected conn error (1011)
Feb  2 08:06:27 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:06:41 sng01ammtsm001 kernel: connection3:0: detected conn error (1011)
Feb  2 08:06:41 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:07:32 sng01ammtsm001 kernel: connection6:0: detected conn error (1011)
Feb  2 08:07:33 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 6:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:07:45 sng01ammtsm001 kernel: connection6:0: detected conn error (1011)
Feb  2 08:07:46 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 6:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:10:17 sng01ammtsm001 kernel: connection10:0: detected conn error (1011)
Feb  2 08:10:18 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 10:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:11:42 sng01ammtsm001 kernel: connection10:0: detected conn error (1011)
Feb  2 08:11:43 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 10:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:11:57 sng01ammtsm001 kernel: connection7:0: detected conn error (1011)
Feb  2 08:11:58 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 7:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:12:42 sng01ammtsm001 kernel: connection5:0: detected conn error (1011)
Feb  2 08:12:42 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 5:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:12:48 sng01ammtsm001 kernel: connection3:0: detected conn error (1011)
Feb  2 08:12:48 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:13:01 sng01ammtsm001 kernel: connection7:0: detected conn error (1011)
Feb  2 08:13:02 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 7:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:13:15 sng01ammtsm001 kernel: connection7:0: detected conn error (1011)
Feb  2 08:13:15 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 7:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:13:31 sng01ammtsm001 kernel: connection7:0: detected conn error (1011)
Feb  2 08:13:31 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 7:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:13:47 sng01ammtsm001 kernel: connection7:0: detected conn error (1011)
Feb  2 08:13:47 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 7:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:15:06 sng01ammtsm001 kernel: connection3:0: detected conn error (1011)
Feb  2 08:15:07 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:15:30 sng01ammtsm001 kernel: connection3:0: detected conn error (1011)
Feb  2 08:15:30 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:15:35 sng01ammtsm001 kernel: connection5:0: detected conn error (1011)
Feb  2 08:15:35 sng01ammtsm001 iscsid: Kernel reported iSCSI connection 5:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)
Feb  2 08:56:06 sng01ammtsm001 smbd[10643]:   nt_printing_init: error checking published printers: WERR_ACCESS_DENIED
Feb  2 10:00:55 sng01ammtsm001 smbd[25911]:   nt_printing_init: error checking published printers: WERR_ACCESS_DENIED
Feb  2 11:04:25 sng01ammtsm001 smbd[39682]:   nt_printing_init: error checking published printers: WERR_ACCESS_DENIED
Feb  2 12:11:09 sng01ammtsm001 smbd[7156]:   nt_printing_init: error checking published printers: WERR_ACCESS_DENIED
Feb  2 16:08:09 sng01ammtsm001 kernel: HEST: Enabling Firmware First mode for corrected errors.
Feb  2 16:08:09 sng01ammtsm001 kernel: ERST: Error Record Serialization Table (ERST) support is initialized.
Feb  2 16:08:09 sng01ammtsm001 kernel: device-mapper: table: 253:7: multipath: error getting device
Feb  2 16:08:09 sng01ammtsm001 kernel: device-mapper: ioctl: error adding target to table
Feb  2 16:08:09 sng01ammtsm001 kernel: device-mapper: table: 253:34: multipath: error getting device
Feb  2 16:08:09 sng01ammtsm001 kernel: device-mapper: ioctl: error adding target to table
Feb  2 16:08:14 sng01ammtsm001 kernel: device-mapper: table: 253:48: multipath: error getting device
Feb  2 16:08:14 sng01ammtsm001 kernel: device-mapper: ioctl: error adding target to table




SuSE external for kdump TATA  Support Cases keyboard_arrow_right 00273155
SuSE IBM Internal for kdump TATA TS004936430

Need to know if chef team can help incorporate kdump configuration on all TATA Steel servers #6070

https://www.suse.com/support/kb/doc/?id=000016171
https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-tuning-kexec.html

Hello Ravi,

Thank you for contacting IBM Support. This is Mohammed Sabry with the Global Linux Team and I will be working with you on this case.
Basically there are 3 main steps to get kdump working on your servers:

1- Calculating crashkernel Allocation Size 
https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-tuning-kexec.html#sec-tuning-kexec-crashkernel

2- Basic Kdump Configuration
https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-tuning-kexec.html#cha-tuning-kdump-basic

3- Test local kernel core dump capture
https://www.suse.com/support/kb/doc/?id=000016171

The steps would be the same for different servers running SLES 12. 
Please let me know if you need further assistance with the steps mentioned above.

Regards,

Sabry



CDIR: hfcqh4hadb001	
10.208.79.143	dal13-pod1-4tb-host25.imzcloud.ibmammsap.local




smdbquaqm3      10.78.24.25
smdbdevde1      10.78.22.17
I/O Error on root FS causing trouble. Request OS Linux assistance - CS5855471


CHG0189595
SAPCRMDI	10.207.61.83	10.170.61.69

  4. Change the PCache path-/sapmnt/DIP/dataservices/log/PCache (which is a directory now) to a FS (from the logical volume created in Step 1) (Note: We are not making any configuration change as such)

  5. Copy the contents from existing PCACHE location from the backup taken in Step 3 to the newly create PCACHE FS.

  6. Make sure ownership/permission for this FS and its contents are with dipadm:sapsys

  7. Add the necessary entry under /etc/fstab



 dipappvg      5  17   0 wz--n- 315.98g    2.02g


[root@sapcrmdi PCache]$ lvdisplay |grep -i dataservices_log_PCache_lv
  LV Path                /dev/dipappvg/dataservices_log_PCache_lv
  LV Name                dataservices_log_PCache_lv

[root@sapcrmdi PCache]$ lvs |grep -i dataservices_log_PCache_lv
  dataservices_log_PCache_lv dipappvg    -wi-a-----   30.00g


/pcacheFS

mount -t ext4 /dev/dipappvg/dataservices_log_PCache_lv /pcacheFS

rsync -avz PCache /swdump/








CS5876935 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)PS2-S4P-CISQ-SAP-TRIO-B1
CS5876701 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)PS2-S4P-CI-HASQ-SAP-TRIO-B1
CS5876909 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)PS2-S4P-DBSQ-SAP-TRIO-B1
CS5876852 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)PS2-S4P-CISQ-SAP-TRIO-B1




CS5877141	Pak Suzuki Motor Company Ltd (Psmcl) -- 	P2 - Major	Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)	PS2-S4P-CI-HA	SQ-SAP-TRIO-B1	
CS5877454	Pak Suzuki Motor Company Ltd (Psmcl) -- 	P2 - Major	Disk Utilization /mnt/resource CRITICAL: Free 4098.96MB/7.69% (thresh @5.01:10%)	PS2-POX-CI	SQ-SAP-TRIO-B1	

CS5876852	Pak Suzuki Motor Company Ltd (Psmcl) -- 	P2 - Major	Service Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)	PS2-S4P-CI	SQ-SAP-TRIO-B1	


CS5878446 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker stonithd CRITICAL: 0 /usr/lib64/pacemaker/stonithd processes running (thresh 1:)PS2-S4P-CI-HASQ-SAP-TRIO-B1
CS5878443 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)PS2-S4P-CISQ-SAP-TRIO-B1
CS5878442 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)PS2-S4P-CISQ-SAP-TRIO-B1
CS5878440 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)PS2-S4P-CISQ-SAP-TRIO-B1(
CS5878412 Pak Suzuki Motor Company Ltd (Psmcl) -- P2 - MajorService Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)PS2-S4P-DB-HASQ-SAP-TRIO-B1



		n(open files)	u(max user processes)	d(data seg size)
tsls4proddb	65536		unlimited		unlimited	
tsls4proddbh	1024		49540214		unlimited
tslbwprddb	1024		24769368		unlimited





fsf-wdc0401a1-fz.service.softlayer.com:/IBM02SEV393684_63/data01 /sapmnt/log/mnt00001 nfs rw,vers=4,minorversion=1,hard,timeo=300,retrans=3,rsize=1048576,wsize=1048576,intr,noatime,lock 0 0

fsf-wdc0401h1-fz.service.softlayer.com:/IBM02SEV393684_64/data01 /sapmnt/log/mnt00002 nfs 

fsf-wdc0401a1-fz.service.softlayer.com
fsf-wdc0401h1-fz.service.softlayer.com



RCA0004320
Servers:
CS5808710==>BR3PSOLDB40-BR3PSOLDB41
BR3PSOLDB40 (10.138.13.48)
BR3PSOLDB41 (10.138.13.50) 


note: other server that reported similar pacemaker problem -> CS5768537==>BR3PSCMSS46


CS5900091 Panasonic North America -- PN4 PN4US7LECCP1 P2 LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 20.94 (thresh: 20)


â”€prdglobalvg-ixos_archive_lv 254:22   0  200G  0 lvm  /export/ixos/archive

[root@sapapp31-ha ibmrmalik1]# df -hT /export/ixos/archive
Filesystem                              Type  Size  Used Avail Use% Mounted on
/dev/mapper/prdglobalvg-ixos_archive_lv xfs   200G  180G   21G  90% /export/ixos/archive
[root@sapapp31-ha ibmrmalik1]# df -hT /ixos/archive
Filesystem                          Type  Size  Used Avail Use% Mounted on
ssapp-tta-prd2:/export/ixos/archive nfs   200G  180G   21G  90% /ixos/archive


sdc                               8:32   0  512G  0 disk
â””â”€drbd0                         147:0    0  512G  0 disk
  â”œâ”€prdglobalvg-interface_lv    254:19   0   20G  0 lvm  /export/INTERFACE
  â”œâ”€prdglobalvg-sapmnt_lv       254:20   0  120G  0 lvm  /export/sapmnt/PRD
  â”œâ”€prdglobalvg-usrsaptrans_lv  254:21   0  172G  0 lvm  /export/usr/sap/trans
  â””â”€prdglobalvg-ixos_archive_lv 254:22   0  200G  0 lvm  /export/ixos/archive
sdd                               8:48   0   32G  0 disk
â””â”€drbd1                         147:1    0   32G  1 disk
sde                               8:64   0   32G  0 disk
â””â”€drbd2                         147:2    0   32G  0 disk
  â””â”€prdersvg-ers_lv             254:23   0   10G  0 lvm  /usr/sap/PRD/ERS11


[root@sapapp31-ha ibmrmalik1]# vgs prdglobalvg
  VG          #PV #LV #SN Attr   VSize   VFree
  prdglobalvg   1   4   0 wz--n- 511.98g    0

[root@sapapp31-ha ibmrmalik1]# lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdb
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[0:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sdd
[0:0:4:0]    disk    VMware   Virtual disk     1.0   /dev/sde
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf
[0:0:6:0]    disk    VMware   Virtual disk     1.0   /dev/sdg



[root@sapapp31-ha ibmrmalik1]# grep -r "drbd0" /etc/drbd.d/r*
/etc/drbd.d/r0.res:    device /dev/drbd0;


/etc/drbd.d/r0.res:    device /dev/drbd0;
[root@sapapp31-ha ibmrmalik1]# cat /etc/drbd.d/r0.res
resource r0 {
  volume 0 {
    device /dev/drbd0;
    disk /dev/sdc;
    meta-disk internal;
  }

  on sapapp31 {
    address  10.170.61.40:7780;
    node-id 0;
  }
  on sapapp31-ha {
    address  10.170.61.123:7780;
    node-id 1;
  }
  disk {
    resync-rate 10M;
  }
  net {
    after-sb-0pri   discard-younger-primary;
    after-sb-1pri   consensus;
    after-sb-2pri   disconnect;
    cram-hmac-alg   sha1;
    shared-secret   "NEMVcf04PNBSpt";
  }
  connection-mesh {
    hosts sapapp31 sapapp31-ha;
  }
}




volume 1 { 
    device /dev/drbd3;  <-- New DRBD name
    disk /dev/sdf;  <-- New Disk name
    meta-disk internal;



ssh ibmrmalik1@10.207.61.123
Feb 09 13:35:55 tsls4proddb systemd-coredump[454144]: Process 454141 (storcli64) of user 0 dumped core.
                                                      
                                                      Stack trace of thread 454141:...
Feb 09 13:40:55 tsls4proddb systemd-coredump[21818]: Process 21815 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 21815:...
Feb 09 13:40:55 tsls4proddb systemd-coredump[21830]: Process 21827 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 21827:...
Feb 09 13:40:55 tsls4proddb systemd-coredump[21842]: Process 21839 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 21839:...
Feb 09 13:45:55 tsls4proddb systemd-coredump[45485]: Process 45482 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 45482:...
Feb 09 13:45:55 tsls4proddb systemd-coredump[45497]: Process 45494 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 45494:...
Feb 09 13:45:55 tsls4proddb systemd-coredump[45509]: Process 45506 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 45506:...
Feb 09 13:50:56 tsls4proddb systemd-coredump[70117]: Process 70114 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 70114:...
Feb 09 13:50:56 tsls4proddb systemd-coredump[70129]: Process 70126 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 70126:...
Feb 09 13:50:56 tsls4proddb systemd-coredump[70141]: Process 70138 (storcli64) of user 0 dumped core.
                                                     
                                                     Stack trace of thread 70138:...


10.162.186.207
root v4RCYvlEDz



tsls4proddb:/tmp #  ulimit -a
core file size          (blocks, -c) 2097151
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 49542083
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 65536
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) unlimited
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

tsls4proddb:/tmp # free -gh
             total       used       free     shared    buffers     cached
Mem:           11T       8.1T       3.7T       267G       1.3G       467G
-/+ buffers/cache:       7.6T       4.2T
Swap:           0B         0B         0B


tsls4proddbh:/opt/MegaRAID/storcli #  ulimit -a
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 49540214
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 49540214
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

tsls4proddbh:/opt/MegaRAID/storcli # free -gh
             total       used       free     shared    buffers     cached
Mem:           11T       8.0T       3.8T       267G       1.2G       331G
-/+ buffers/cache:       7.6T       4.2T
Swap:           0B         0B         0B



ulimit -u 65535
Modify the DefaultTasksMax=65535 parameter in the /etc/systemd/system.conf file
Add the UserTasksMax=65535 parameter in the /etc/systemd/logind.conf file
systemctl daemon-reload
systemctl restart systemd-logind.service



CS5917463 Panasonic North America -- PN8 PN8US7LECCQ2 P2 Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on PN8US7LECCQ2- KB0010973
CS5917500 Panasonic North America -- PN4 PN4US7LECCP1 P2 LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 21.99 (thresh: 20)




CS5923207	Tata Steel Limited -- TTA	P1 - Severe	Host Reboot CRITICAL: Uptime 2 minutes (thresh 60 min)	SQ-SAP-TRIO-B1
CS5923120	Tata Steel Limited -- TTA	P1 - Severe	Host Reboot CRITICAL: Uptime 1 minutes (thresh 60 min)	SQ-SAP-TRIO-B1


sapapp31, sapapp31-ha
sapcrmapp4, sapcrmapp4-ha
ewmapp3, ewmapp3-ha   



CS5924051 Egyptian Refining Company -- EGR ERCSOLPRD1 P2 Memory Swap CRITICAL: Swap free 45.47% (thresh 50:%)
CS5924000 Egyptian Refining Company -- EGR ERCSOLPRD1 P2 Memory Swap CRITICAL: Swap free 45.50% (thresh 50:%)
CS5923934 Egyptian Refining Company -- EGR ERCSOLPRD1 P2 Memory Swap CRITICAL: Swap free 45.51% (thresh 50:%)


CS5924634 Manitoba Telecom Services -- MTS R3QAT P1 System MegaRAID Drive Media Errors CRITICAL: [See KB0015294] Media Error Count = 3
Drive /c0/e27/s7 - Detailed Information :
Shield Counter = 0
Media Error Count = 3
Other Error Count = 0
Drive Temperature =  35C (95.00 F)
Predictive Failure Count = 0
S.M.A.R.T alert flagged by drive = No
SN = 6SL4QF8L0000B3060ST5
Firmware Revision = 0730000B



CS5930945	Hino Motors Ltd -- HNO	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 83.62 (thresh: 30)	SQ-SAP-TRIO-B3
CS5930944	Hino Motors Ltd -- HNO	P2 - Major	CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=71.75% system=28.25% iowait=0.00% idle=0.00%	SQ-SAP-TRIO-B3
CS5930905	Consolidated Metco Inc. -- Z2Y	P2 - Major	CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=94.50% system=5.50% iowait=0.00% idle=0.00%	SQ-SAP-TRIO-B2
CS5930779	Consolidated Metco Inc. -- Z2Y	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 32.62 (thresh: 30)	SQ-SAP-TRIO-B1



CS5955385 CS5955387 CS5955388 CS5955390 CS5955395






CS5971736	Suncor Energy Inc. -- SNC	P3 - Minor	Disk Utilization /home MINOR: Free 191.31MB/10.34% (thresh @10.01:19%)	SQ-SAP-TRIO-B2
CS5971468	Suncor Energy Inc. -- SNC	P3 - Minor	Disk Utilization /home MINOR: Free 190.43MB/10.30% (thresh @10.01:19%)	SQ-SAP-TRIO-B2



CTUBWQB0DB02	10.65.162.185	coty-wdc04-phana-4096-5.imzcloud.ibmammsap.local


CS5982864 GKN Driveline Newton LLC -- GKN P2 Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNECCPRDCIH- KB0010973
CS5982863 GKN Driveline Newton LLC -- GKN GKNECCPRDCI P2 Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNECCPRDCI- KB0010973

CS5978473	AV notification
eccap1prd
eccci0dev
eccci0prd
eccdb0dev
eccdb0qas




Update notice RHBA-2020:1991 (from rhel-sap-for-rhel-7-server-rpms) is broken, or a bad duplicate, skipping.
You should report this problem to the owner of the rhel-sap-for-rhel-7-server-rpms repository.
If you are the owner, consider re-running the same command with --verbose to see the exact data that caused the conflict.
Update notice RHBA-2020:1991 (from rhel-sap-hana-for-rhel-7-server-rpms) is broken, or a bad duplicate, skipping.
You should report this problem to the owner of the rhel-sap-hana-for-rhel-7-server-rpms repository.
If you are the owner, consider re-running the same command with --verbose to see the exact data that caused the conflict.
Uploading Enabled Repositories Report
Loaded plugins: product-id, subscription-manager, versionlock



TSLS4PRODDB
tsls4proddb => tsls4proddbh




Landscape Name	SID	Environment (Singapore)	datavg(GB)
SAP ECC 6.0	       V32	BAPV321100                                           QA	48
SAP ECC 6.0	       V31	BAPV311300	                 Pre-Prod	              100
SAP ECC 6.0	      V33	 BAPV330900                PROD                   	80
SAP BW 7.0	      V52	BAPV520500	                                        DEV	125
SAP BW 7.0             V72	BAPV721300                                  QA	50
SAP ECC Legacy 6.0	V51	BAPV510300                 Non PROD	48



CS5951420	Certified IT Consultants -- CI2	P2 - Major	Ping Availability CRITICAL - 10.5.242.12: rta nan. lost 100% Attention commas replaced by dots.
CS5951380	Certified IT Consultants -- CI2	P2 - Major	Ping Availability CRITICAL - 10.5.242.14: rta nan. lost 100% Attention commas replaced by dots.
CS5951378	Certified IT Consultants -- CI2	P2 - Major	Ping Availability CRITICAL - 10.5.242.15: rta nan. lost 100% Attention commas replaced by dots.
CS5950889	Certified IT Consultants -- CI2	P2 - Major	Ping Availability CRITICAL - 10.5.242.16: rta nan. lost 100% Attention commas replaced by dots.
CS5950718	Certified IT Consultants -- CI2	P2 - Major	Ping Availability CRITICAL - 10.5.242.17: rta nan. lost 100% Attention commas replaced by dots.
CS5950699	Certified IT Consultants -- CI2	P2 - Major	Ping Availability CRITICAL - ci2qadb: rta nan. lost 100% Attention commas replaced by dots.
CS5949819	Certified IT Consultants -- CI2	P2 - Major	Ping Availability CRITICAL - ci2devdb: rta nan. lost 100% Attention commas replaced by dots.




TS005089040 - raised for finding RCA for the server tsls4proddb rebooted unexpectedly
00275672 - external suse case for the unexpected reboot
 rebooted between 4:45 to 5AM
CS2184636 raised to SL to check for any possible hardware failure


HDB info to check service tart/stop status

tsls4proddb	10.207.61.123	10.170.61.225
tsls4proddbh	10.207.61.113	10.170.61.78
tsls4proddbdr	100.64.4.23	10.170.64.50

only tsls4proddb was rebooted  10.162.186.206	tta-che01-pod1-phana-h8-12000-001.imzcloud.ibmammsap.local
tsls4proddb:/home/ibmrmalik1 # last reboot
reboot   system boot  4.12.14-95.54-de Thu Feb 25 05:02 - 07:00  (01:58)

wtmp begins Mon Feb 22 12:32:21 2021
tsls4proddb:/home/ibmrmalik1 # date
Thu Feb 25 07:01:06 IST 2021

Feb 25 05:03:52 [24222] tsls4proddb       crmd:   notice: process_lrm_event:    Result of probe operation for rsc_SAPHana_PRD_HDB00 on tsls4proddb: 1 (unknown error) | call=15 key=rsc_SAPHana_PRD_HDB00_monitor_0 confirmed=true cib-update=16
Feb 25 05:05:43 [24222] tsls4proddb       crmd:   notice: process_lrm_event:    Result of probe operation for rsc_SAPHana_PRD_HDB00 on tsls4proddb: 1 (unknown error) | call=29 key=rsc_SAPHana_PRD_HDB00_monitor_0 confirmed=true cib-update=24
Feb 25 06:31:10 [24219] tsls4proddb       lrmd:   notice: operation_finished:   rsc_SAPHana_PRD_HDB00_monitor_0:287138:stderr [ Error performing operation: No such device or address ]
Feb 25 06:31:10 [24219] tsls4proddb       lrmd:   notice: operation_finished:   rsc_SAPHana_PRD_HDB00_monitor_0:287138:stderr [ Error performing operation: No such device or address ]

tsls4proddb:/var/log/cluster #  dmesg |grep -i fail
[   22.227467] pci 0000:2e:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.227471] pci 0000:2e:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.227599] pci 0000:45:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.227603] pci 0000:45:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.227805] pci 0000:6e:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.227807] pci 0000:6e:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.227810] pci 0000:6e:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.227811] pci 0000:6e:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228095] pci 0000:ae:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228097] pci 0000:ae:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228099] pci 0000:ae:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228101] pci 0000:ae:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228212] pci 0000:c5:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228214] pci 0000:c5:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228216] pci 0000:c5:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228218] pci 0000:c5:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228385] pci 0000:ee:02.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228386] pci 0000:ee:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228389] pci 0000:ee:03.0: BAR 13: failed to assign [io  size 0x1000]
[   22.228390] pci 0000:ee:02.0: BAR 13: failed to assign [io  size 0x1000]
[  101.970713] tmhook: module verification failed: signature and/or required key missing - tainting kernel
You have mail in /var/mail/root

tsls4proddb:/var/log/cluster # cat /var/log/messages |grep -i expired
Feb 25 05:03:28 tsls4proddb systemd[1]: haveged.service: Service RestartSec=100ms expired, scheduling restart.


sapcrmapp4
sapcrmapp4-ha


CTUBWQB0AP01	10.12.10.140
CTUBWQB0AP02	10.12.10.139
CTUBWQB0AP03	10.12.10.153
CTUBWQB0AP04	10.12.10.152
CTUBWQB0DB01	10.12.10.65
CTUBWQB0DB02	10.12.10.81


CHG0193415	02-03-2021 06:30:00	02-03-2021 12:30:00	FRA

Server Role	Hostname	            IFN IP                 SID
Development    armfksap007    10.7.103.27          BWD   (Application server)
[root@armfksap007 ibmrmalik1]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap007 4.4.121-92.138-default #1 SMP Mon Jul 27 12:52:22 UTC 2020 (cfc473a) x86_64 x86_64 x86_64 GNU/Linux
Tue Mar  2 02:44:56 CET 2021
OK: No read-only file systems found
fra02ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  2.9T  3.4T  46% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=2958,timeout=600,minproto=5,maxproto=5,direct 0 0
fra02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.7.103.27,local_lock=none,addr=146.89.140.220 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

/usr/sap/trans  *(rw,sync,no_root_squash)


[root@armfksap007 ibmrmalik1]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux armfksap007 4.12.14-95.68-default #1 SMP Tue Feb 2 20:33:05 UTC 2021 (e91b37e) x86_64 x86_64 x86_64 GNU/Linux
Tue Mar  2 03:25:46 CET 2021
OK: No read-only file systems found
fra02ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  2.9T  3.4T  46% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=2697,timeout=600,minproto=5,maxproto=5,direct,pipe_ino=30624 0 0
fra02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.7.103.27,local_lock=none,addr=146.89.140.220 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

/usr/sap/trans  *(rw,sync,no_root_squash)


[root@armfksap007 ibmrmalik1]$ ip route
default via 10.244.103.1 dev eth1
10.7.103.0/24 dev eth0  proto kernel  scope link  src 10.7.103.27
10.244.103.0/24 dev eth1  proto kernel  scope link  src 10.244.103.27
146.89.140.0/22 via 10.7.103.1 dev eth0
146.89.140.242 via 10.7.103.1 dev eth0
146.89.168.0/21 via 10.7.103.1 dev eth0
158.87.44.0/23 via 10.7.103.1 dev eth0
158.87.46.0/23 via 10.7.103.1 dev eth0
169.55.16.128/28 via 10.7.103.1 dev eth0
169.55.28.32/27 via 10.7.103.1 dev eth0
169.55.28.64/28 via 10.7.103.1 dev eth0
169.55.192.96/27 via 10.7.103.1 dev eth0
169.60.136.0/22 via 10.7.103.1 dev eth0
169.62.212.64/26 via 10.7.103.1 dev eth0

armfksap007
Development    armfksap006	10.7.103.24          BOD   (Application and sybase server)
[root@armfksap006 ibmrmalik1]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux armfksap006 4.4.121-92.138-default #1 SMP Mon Jul 27 12:52:22 UTC 2020 (cfc473a) x86_64 x86_64 x86_64 GNU/Linux
Tue Mar  2 02:44:56 CET 2021
OK: No read-only file systems found
fra02ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  2.9T  3.4T  46% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=3363,timeout=600,minproto=5,maxproto=5,direct 0 0
fra02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.7.103.24,local_lock=none,addr=146.89.140.220 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.


[root@armfksap006 ibmrmalik1]$ cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux armfksap006 4.12.14-95.68-default #1 SMP Tue Feb 2 20:33:05 UTC 2021 (e91b37e) x86_64 x86_64 x86_64 GNU/Linux
Tue Mar  2 04:15:25 CET 2021
OK: No read-only file systems found
fra02ammsol01.imzcloud.ibmammsap.local:/sds nfs4      6.6T  2.9T  3.4T  46% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=2657,timeout=600,minproto=5,maxproto=5,direct,pipe_ino=31432 0 0
fra02ammsol01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.7.103.24,local_lock=none,addr=146.89.140.220 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

[root@armfksap006 ibmrmalik1]$ ip route
default via 10.244.103.1 dev eth1
10.7.103.0/24 dev eth0  proto kernel  scope link  src 10.7.103.24
10.244.103.0/24 dev eth1  proto kernel  scope link  src 10.244.103.23
146.89.140.0/22 via 10.7.103.1 dev eth0
146.89.140.242 via 10.7.103.1 dev eth0
146.89.168.0/21 via 10.7.103.1 dev eth0
158.87.44.0/23 via 10.7.103.1 dev eth0
158.87.46.0/23 via 10.7.103.1 dev eth0
169.55.16.128/28 via 10.7.103.1 dev eth0
169.55.28.32/27 via 10.7.103.1 dev eth0
169.55.28.64/28 via 10.7.103.1 dev eth0
169.55.192.96/27 via 10.7.103.1 dev eth0
169.60.136.0/22 via 10.7.103.1 dev eth0
169.62.212.64/26 via 10.7.103.1 dev eth0



CHG0193432
Upgrade SUSE Linux servers from 12 SP2 to 12 SP4 	FRA02-SL

Current OS version:
SUSE Linux Enterprise Server for SAP Applications 12 SP2
Target version:
SUSE Linux Enterprise Server for SAP Applications 12 SP4

Server details: (list server details below)-
Server Role	Hostname	            IFN IP                 SID
Development    armfksap003	10.7.103.30          ECD  (Application server)
Development    armfksap001	10.7.103.28          GWD   (Application and sybase server)
Development    armfksap005	10.7.103.22          POD   (Application and sybase server)



CS6091928
10.70.111.35 (F:\OpenText\StreamServe\Data\STRS_Output\OfficialReceipt) to 10.70.111.46.

SPSVOPLTAPP01	10.6.3.35	10.70.111.35	source windows

SPSVMPLMAPP01	10.6.3.46	10.70.111.46	

OfficialReceipt (file://SPSVOPLTAPP01/STRS_Output/OfficialReceipt)


username=msgteam
password=Welcome@123

mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/IBP /usr/sap/s4hana/SBD/S4HANA_DC/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev

//SPSVOPLTAPP01/STRS_Output/OfficialReceipt     /OfficialReceipt      cifs    credentials=/etc/credentials,_netdev 0 0



A0EASG014XVM030		ammsng01custesx028
A0EASG012XVM041		ammsng01custesx030
A0EASG012XVM042		ammsng01custesx030
A0EASG012XVM047		ammsng01custesx029


CS6100245	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.25: rta nan. lost 100% Attention commas replaced by dots.
CS6100218	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.165: rta nan. lost 100% Attention commas replaced by dots.
CS6100191	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.195: rta nan. lost 100% Attention commas replaced by dots.
CS6100172	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.182: rta nan. lost 100% Attention commas replaced by dots.
CS6100164	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.205: rta nan. lost 100% Attention commas replaced by dots.
CS6100163	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.187: rta nan. lost 100% Attention commas replaced by dots.
CS6100160	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.181: rta nan. lost 100% Attention commas replaced by dots.
CS6100157	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - mgggbjpeccx10: rta nan. lost 100% Attention commas replaced by dots.
CS6100150	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.31: rta nan. lost 100% Attention commas replaced by dots.
CS6100140	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.18: rta nan. lost 100% Attention commas replaced by dots.



mnhdevapp01  fixed

PSDEVASJAVA	172.31.10.43		LON02-SL	Computer Systems Integration Ltd -- CSY	CSY		A0FTUK014XVM006 
PSPRDASJAVA	10.197.2.42	172.31.10.42		Computer Systems Integration Ltd -- CSY	CSY		A0FTUK014XVM007
PSWEB	10.197.2.41	172.31.10.41	Computer Systems Integration Ltd -- CSY	CSY			A0FTUK014XVM002
PSQASAP	10.197.2.21	172.31.10.21	Computer Systems Integration Ltd -- CSY	CSY			A0FTUK014XVM003
PSWEB2	10.197.2.44	172.31.10.44	Computer Systems Integration Ltd -- CSY	CSY	A0FTUK014XVM008_restore_06062017
PSDEVAP	10.197.2.11	172.31.10.11	Computer Systems Integration Ltd -- CSY	CSY	A0FTUK014XVM001
PSPRDAP1 10.197.2.31	172.31.10.31	Computer Systems Integration Ltd -- CSY	CS	A0FTUK014XVM004		fixed



MGGGBJDCNTX01
MGGGBJDCNTX02
MGGGBJDECCX01
MGGGBJDECCY01
MGGGBJDGTSX01
mgggbjdgtsy01
MGGGBJDSOLX01
MGGGBJPBCCX01
MGGGBJPCNTX01
MGGGBJPCNTX02
MGGGBJPECCX07	Asmita
MGGGBJPGTSX01	Asmita
MGGGBJPSOLX01	Asmita
MGGGBJQECCY01
MGGGBJSECCX01
MGGGBJSGTSX01
MGGGBJVECCX01
MGGGBJVECCX03
MGGGBJVECCX05
MGGGBJVECCX07



rescue mode working https://www.novell.com/documentation/suse91/suselinux-adminguide/html/ch12s05.html
journalctl -xb  |grep -i error |less
vgchange -ay rootvg
lvscan
[root@sapapp19 ~]$ tune2fs -l /dev/rootvg/rootlv |grep state
Filesystem state:         clean
check each fs  like this
if you see clean with error  run fsck
e2fsck -f -y and path rite
or
fsck.xfs /dev/roovg/lvname

fsck -p <path to check for error>


rd.break,  single, or init=/bin/bash



mgggbjpeccx08	Ravi	10.133.18.25	10.5.255.25		gud
Mgggbjpgtsx02	Ravi	10.133.18.27	10.5.255.27		gud	
MGGGBJPSOLX02	Ravi	10.133.18.31	10.5.255.31		gud
MGGGBJPGTSX04	Ravi	10.133.18.29	10.5.255.29		Retired
MGGGBJPECCX02	Ravi	10.133.18.19	10.5.255.19		is gud	
MGGGBJPECCX06	Ravi	10.133.18.23	10.5.255.23		is gud	
mgggbjpeccx04	Ravi	10.133.18.21	10.5.255.21		is gud	


      # it is auto-activated. The auto_activation_volume_list setting
        # Configuration option activation/volume_list.
        #     or VG. See tags/hosttags. If any host tags exist but volume_list
        # volume_list = [ "vg1", "vg2/lvol1", "@tag1", "@*" ]
          volume_list = [ "VolGroup","nvjappvg","nvtappvg","VG_NVT_SYSTEM_REFRESH","VG_NEP_SYSTEM_REFRESH"]
        # Configuration option activation/auto_activation_volume_list.
        # This list works like volume_list, but it is used only by
        # auto-activation, must also be selected by volume_list (if defined)
        #     or VG. See tags/hosttags. If any host tags exist but volume_list
        # auto_activation_volume_list = [ "vg1", "vg2/lvol1", "@tag1", "@*" ]
        # Configuration option activation/read_only_volume_list.
        #     or VG. See tags/hosttags. If any host tags exist but volume_list
        # read_only_volume_list = [ "vg1", "vg2/lvol1", "@tag1", "@*" ]
        # The rules are the same as those for volume_list.
        # The rules are the same as those for auto_activation_volume_list.
[root@MGGGBJVECCX05 ibmrmalik1]$ vgs
  VG                    #PV #LV #SN Attr   VSize   VFree
  VG_NEP_SYSTEM_REFRESH   1   1   0 wz--n- 610.00g     0
  VG_NVT_SYSTEM_REFRESH   2   1   0 wz--n-   1.03t 21.99g
  VolGroup                2   7   0 wz--n-  95.50g  1.49g
  nvjappvg                1   5   0 wz--n- 128.00g 85.00g
  nvtappvg                1  13   0 wz--n- 128.00g 11.00g




10.5.255.32:/sapdb/ECP/Kofax /sapdb/ECP/Kofax nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
10.5.255.33:/sapdb/NCP/Kofax /sapdb/NCP/Kofax nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0


10.5.255.18:/sapmnt/EEP       /sapmnt/EEP               nfs     defaults
10.5.255.18:/sapmnt/EPJ       /sapmnt/EPJ               nfs     defaults
chef-client failed


/sapdb/ECP/Kofax		MGGGBJPCNTX01
/sapdb/NCP/Kofax
both file systems should be mounted to all app servers of EEP
from MANOJ KUMAR (External) to everyone:    10:27 AM
/sapdb/ECP/Kofax
from MANOJ KUMAR (External) to everyone:    10:27 AM
/sapdb/NCP/Kofax



svjd1srv0	10.6.1.12	
svfd1srv0	10.6.1.24



CS6174029 P2 - MajorAlpro Comm. VA -- APRResources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped
CS6174040 P2 - MajorAlpro Comm. VA -- APRResources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped
CS6174042 P2 - MajorAlpro Comm. VA -- APRLog PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-03-10-08-10-29 for details.
CS6174134 P2 - MajorAlpro Comm. VA -- APRLog PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-03-10-08-25-28 for details.

CS6174210 Toyota Boshoku -- TBOP3 - Minor[TBO] Request for increasing disk space by 50GB on Dev&QA machine.(empty)SQ-SAP-TRIO-B2



 TSLS4PRODDB - 10.207.61.123   10.170.61.225
10.162.186.206	tta-che01-pod1-phana-h8-12000-001.imzcloud.ibmammsap.local
https://cloud.ibm.com/unifiedsupport/cases?number=CS2206942&new=true






[2021-03-07T00:49:17+05:30] INFO: Chef Run complete in 165.086034782 seconds
[2021-03-07T01:56:28+05:30] INFO: Chef Run complete in 161.128805953 seconds
[2021-03-07T03:05:39+05:30] INFO: Chef Run complete in 243.667126306 seconds
[2021-03-07T04:13:39+05:30] INFO: Chef Run complete in 146.536857751 seconds
[2021-03-07T05:20:58+05:30] INFO: Chef Run complete in 163.276142984 seconds
[2021-03-07T06:28:40+05:30] INFO: Chef Run complete in 130.946367684 seconds
[2021-03-07T07:35:54+05:30] INFO: Chef Run complete in 170.216433352 seconds
[2021-03-07T08:40:16+05:30] INFO: Chef Run complete in 150.755494779 seconds
[2021-03-07T09:46:18+05:30] INFO: Chef Run complete in 168.356331921 seconds
[2021-03-07T10:54:40+05:30] INFO: Chef Run complete in 146.293177293 seconds
[2021-03-07T11:58:40+05:30] INFO: Chef Run complete in 134.554301594 seconds
[2021-03-10T19:22:53+05:30] INFO: Chef Run complete in 335.863231636 seconds



tslbwprdhdb

CS6197417	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.25: rta nan. lost 100% Attention commas replaced by dots.	MGGGBJPECCX08	SQ-SAP-TRIO-B1	
	CS6197415	LSPI -- LSP	P2 - Major	Ping Availability CRITICAL - 10.4.2.11: rta nan. lost 100% Attention commas replaced by dots.	LZAECCPRD0	Windows
CS6197413	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.33: rta nan. lost 100% Attention commas replaced by dots.	MGGGBJPCNTX02	SQ-SAP-TRIO-B1	
CS6197375	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - mgggbjseccx01: rta nan. lost 100% Attention commas replaced by dots.	MGGGBJSECCX01	SQ-SAP-TRIO-B1	
CS6197290	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 66.248.241.11: rta nan. lost 100% Attention commas replaced by dots.	mggdrdeccx02	SQ-SAP-TRIO-B1	
	CS6197288	LSPI -- LSP	P2 - Major	Ping Availability CRITICAL - 10.4.2.21: rta nan. lost 100% Attention commas replaced by dots.	LZAMOBPRD0	SQ-SAP-TRIO-B2	
CS6197283	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.18: rta nan. lost 100% Attention commas replaced by dots.	MGGGBJPECCX01	SQ-SAP-TRIO-B1	
	CS6197280	LSPI -- LSP	P2 - Major	Ping Availability CRITICAL - 10.4.3.26: rta nan. lost 100% Attention commas replaced by dots.	LZAADSBX0	SQ-SAP-TRIO-B2	
CS6197279	Meggitt PLC -- MGG	P2 - Major	Ping Availability CRITICAL - 10.133.18.179: rta nan. lost 100% Attention commas replaced by dots.	MGGGBJDECCY01	SQ-SAP-TRIO-B1	
	CS6197233	LSPI -- LSP	P2 - Major	Ping Availability CRITICAL - 10.4.3.18: rta nan. lost 100% Attention commas replaced by dots.	LZABWSBX0	SQ-SAP-TRIO-B2	
	CS6197173	LSPI -- LSP	P2 - Major	Ping Availability CRITICAL - 10.4.2.13: rta nan. lost 100% Attention commas replaced by dots.	LZAGRCPRD0	SQ-SAP-TRIO-B2	
	CS6197150	LSPI -- LSP	P2 - Major	Ping Availability CRITICAL - 10.4.2.18: rta nan. lost 100% Attention commas replaced by dots.	LZASOLPRD0	SQ-SAP-TRIO-B2



CS6200205 Meggitt PLC -- MGG MGGGBJPECCX08 P1 LogScanner TSM Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.140/nrdp.


CS6201549



CS6201808
Need CPU n Memory stats 
March 10 - 10:37 PM - 11:41 PM
LBUPS1AP01
LBUPS1AP01HA
LBUPS1AP02
LBUPS1AP03




CHG0195152	
13-03-2021 13:30:00	13-03-2021 17:30:00
PXN landscape 
ogypxn001	10.139.8.223             Database - passive 
ogypxn001-ha	10.139.8.60       Database - active
ogypxn002	10.139.8.59                ASCS /  D00  instance
ogypxn002-ha	10.139.8.184      ERS / D00 instance
ogypxn003	10.139.8.32                PXN app server
ogypxn004	10.139.8.22                PXN app server

Pacemaker Servers - 

1 -  ogypxn001 and ogypxn001-ha
2 - ogypxn002 and ogypxn002-ha

Validation script - /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py
1)  Error : NodeA Pacemaker Tools: pacemaker-tools-1.3-0.noarch    [ FAILED ]
                 NodeB Pacemaker Tools: pacemaker-tools-1.3-0.noarch    [ FAILED ]



Fix:  Install  the latest pacemaker-tools version from the directory   "/sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker" .  Should be executed on issue node. 
        follow below steps.

   # cd /sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker
   # rpm -Uvh pacemaker-tools-1.4-0.noarch.rpm

---------------------------------------------------------------------------------------------------------------------------------------

2)  Error : VMware Tool Update Status           : New version available                               [ FAILED ]

FIX : VMware tools need to be updated.

Follow the SOP: KB0013637 VMware Tools update on Windows and Linux Servers.docx 



Implementation Plan
==================
Task-2: LINUX - Set the pacemaker cluster unmanaged state.
Task-3: SAP: Stop SAP and Oracle
Task-4: Linux - Remediate Pacemaker health check
Task-5 : LINUX - start pacemaker
Task-6 : SAP - start SAP and Oracle


Servers - 

1 - ogypxn001 and ogypxn001-ha
2 - ogypxn002 and ogypxn002-ha

1.Take the Cluster config backup
 
# crm_mon -1Afr  (verify the custer status)
# cp -vp /var/lib/pacemaker/cib/cib.xml /tmp/backup_datae_cib.xml	cp /var/lib/pacemaker/cib/cib.xml /tmp/backup_datae_cib.xml_backup
# crm configure show > /tmp/backup_date_crm.xml
# cp -vp /etc/corosync/corosync.conf /tmp/backup_date_corosync.conf	cp /etc/corosync/corosync.conf /tmp/backup_date_corosync.conf_backup

2.Put the cluster in maintenance mode
# crm configure property maintenance-mode=true
# crm_mon -1Afr  (verify the custer status)



Validation script - /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py

1 - Take the VM snapshot once Apps are stopped.

 ogypxn001 and ogypxn001-ha
 ogypxn002 and ogypxn002-ha


2 - Stop the pacemaker service on the both nodes
# systemctl stop pacemaker

3 - Install  the latest pacemaker-tools version from the directory   "/sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker" .  Should be executed on issue node. 
        follow below steps.

   # cd /sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker
   # rpm -Uvh pacemaker-tools-1.4-0.noarch.rpm

4 - Validate the RPM
 # rpm -qa |grep pacemaker-tools

5 -  Error : VMware Tool Update Status           : New version available                               [ FAILED ]

FIX : VMware tools need to be updated.

Follow the SOP: KB0013637 VMware Tools update on Windows and Linux Servers.docx 




Start pacemaker
1.Start the pacemaker service on both nodes
 # systemctl start pacemaker

2 - Clean the fail-count if any.
 # crm resource cleanup <resource name>

3. Verify the drbd status
 # drbdadm status

In case any issue on pacemaker, engage pacemaker Team 
#cms-suse-cluster

4 - Inform SAP team to start the apps manually.

5 - Once DB are Apps are UP set the cluster to managed state.
 # crm configure property maintenance-mode=false


TTA firmware upgrade CHG0196279  1730 on 13 March 2021

TSLS4PRODDB     Case Number: CS2206942 
https://cloud.ibm.com/unifiedsupport/cases/manage/CS2206942?accountId=2cea01cbf09f43608f00746a01b0cf27
IPMI 10.162.186.207 root	v4RCYvlEDz





CS6212162 Panasonic North America -- PN8P2 - MajorMemory Swap CRITICAL: Swap free 47.10% (thresh 50:%)PN8US7LAP1P3SQ-SAP-TRIO-B1
CS6212155 COTY Inc. -- CTUP2 - MajorNagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CTUBWQB0DB02- KB0010973CTUBWQB0DB02SQ-SAP-TRIO-B1


CS6243314	WDC
1. Add 1TB new disk to lbupm1ap01
2. Create a new VG for the new  FS - /sap_backups with 775 permissions 		backupvg	/dev/backupvg/sap_backups_lv
3. Create NFS mount (permanent) of the above FS in the below systems

vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab

/sap_backups *(rw,sync,no_root_squash,no_subtree_check)

lbupm1ap01:/sap_backups /sap_backups nfs _netdev,defaults 0 0

lbupm1ap01:

LBUDM1DB01	mapped
LBUPM1DB01	mapped

LBUDG1DB01	mapped
LBUDG2DB01	mapped
LBUQG1DB01	mapped
LBUPG1DB01	mapped

LBUSS1DB01	mapped
LBUDS1DB01	mapped
LBUDS2DB01	mapped
LBUQS1DB01	mapped
LBUPS1DB01	mapped

LBUDP1DB01	mapped
LBUDP2DB01	mapped
LBUQP1DB01	mapped
LBUPP1DB01	mapped

LBUDL1DB01	mapped
LBUQL1DB01	mapped
LBUPL1DB01	mapped



10.140.0.10     lbupm1ap01




CHG0193827_IA1_CMS3X_Linux_S-S_OS-7-PROD1 03192021 (Manual Patching)	20-03-2021 09:30:00	20-03-2021 13:30:00

CHG0194773	Restart ECP and GWP SAP cluster (only application)  due  to SAP parameter login/no_automatic_user_sapstar change from value 0 to 1	27-03-2021 06:30:00	27-03-2021 10:30:00

CHG0194586	Upgrade SUSE Linux servers from 12 SP2 to 12 SP4 - cluster PROD servers	20-03-2021 06:30:00	20-03-2021 16:30:00	



su - bp1adm -c "hdbnsutil -sr_register --remoteHost=clsdwp02ha --remoteInstance=05 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEA" 


CS6269723
SAP HEC Swivel P3 : PE1 DB request to add space (0189163/2021)
SNCHEUAPD11
SNCHEUAPD12



Can you do quick check on these 2 HANA servers?
7:26 AM
TSLEECQA01
tTSLBWQADB01



CHG0196803
3.X Prod, MON01 BR3 - Pacemaker Failovers and cluster setting for vHana migrations (ESXi Firmware upgrades)

Friday 19th 2021:
br3qscmdb36 - Primary, QSC, host03   
br3qscmdb36 <= br3qscmdb37
SAP SID: QCM 
/usr/sap/QCM/HDB36/exe/python_support	

Node Attributes:
* Node br3qscmdb36:
    + hana_qcm_clone_state            	: DEMOTED   
    + hana_qcm_op_mode                	: logreplay 
    + hana_qcm_remoteHost             	: br3qscmdb37
    + hana_qcm_roles                  	: 4:S:master1:master:worker:master
    + hana_qcm_site                   	: NODEA     
    + hana_qcm_srmode                 	: sync      
    + hana_qcm_sync_state             	: SOK       
    + hana_qcm_version                	: 2.00.048.01.1596718894
    + hana_qcm_vhost                  	: br3qscmdb36
    + lpa_qcm_lpt                     	: 30        
    + master-rsc_SAPHana_QCM_HDB36    	: 100       
* Node br3qscmdb37:
    + hana_qcm_clone_state            	: PROMOTED  
    + hana_qcm_op_mode                	: logreplay 
    + hana_qcm_remoteHost             	: br3qscmdb36
    + hana_qcm_roles                  	: 4:P:master1:master:worker:master
    + hana_qcm_site                   	: NODEB     
    + hana_qcm_srmode                 	: sync      
    + hana_qcm_sync_state             	: PRIM      
    + hana_qcm_version                	: 2.00.048.01.1596718894
    + hana_qcm_vhost                  	: br3qscmdb37
    + lpa_qcm_lpt                     	: 1616130645
    + master-rsc_SAPHana_QCM_HDB36    	: 150 

OS: set QCM cluster to unmanaged
BHT: vmotion br3qscmdb36 to host08
OS: set PGT cluster to unmanaged
BHT: vmotion br3pgtsdb46 - Secondary, PGT, host04 to host06
OS: once vmotion completed, set PGT cluster back to managed
OS: set P4H cluster unmanaged
BHT vmotion br3psapdb41 - Secondary, P4H, host04 to host06
OS: once vmotion completed, set P4H cluster back to managed
OS: once QCM vmotion completed:  set QCM cluster back to managed



    
br3pgtsdb46 - Secondary, PGT, host04
SAP SID: PGT 
Node Attributes:
* Node br3pgtsdb45:
    + hana_pgt_clone_state              : PROMOTED
    + hana_pgt_op_mode                  : logreplay
    + hana_pgt_remoteHost               : br3pgtsdb46
    + hana_pgt_roles                    : 4:P:master1:master:worker:master
    + hana_pgt_site                     : NODEA
    + hana_pgt_srmode                   : sync
    + hana_pgt_sync_state               : PRIM
    + hana_pgt_version                  : 2.00.048.01.1596718894
    + hana_pgt_vhost                    : br3pgtsdb45
    + lpa_pgt_lpt                       : 1616131777
    + master-rsc_SAPHana_PGT_HDB02      : 150
* Node br3pgtsdb46:
    + hana_pgt_clone_state              : DEMOTED
    + hana_pgt_op_mode                  : logreplay
    + hana_pgt_remoteHost               : br3pgtsdb45
    + hana_pgt_roles                    : 4:S:master1:master:worker:master
    + hana_pgt_site                     : NODEB
    + hana_pgt_srmode                   : sync
    + hana_pgt_sync_state               : SOK
    + hana_pgt_version                  : 2.00.048.01.1596718894
    + hana_pgt_vhost                    : br3pgtsdb46
    + lpa_pgt_lpt                       : 30
    + master-rsc_SAPHana_PGT_HDB02      : 100






br3psapdb41 - Secondary, PSA, host04

Node Attributes:
* Node br3psapdb40:
    + hana_p4h_clone_state            	: DEMOTED
    + hana_p4h_op_mode                	: logreplay
    + hana_p4h_remoteHost             	: br3psapdb41
    + hana_p4h_roles                  	: 4:s:master1:master:worker:master
    + hana_p4h_site                   	: NODEA
    + hana_p4h_srmode                 	: sync
    + hana_p4h_sync_state             	: SOK
    + hana_p4h_version                	: 2.00.048.01.1596718894
    + hana_p4h_vhost                  	: br3psapdb40
    + lpa_p4h_lpt                     	: 30
    + master-rsc_SAPHana_P4H_HDB40    	: 100
* Node br3psapdb41:
    + hana_p4h_clone_state            	: PROMOTED
    + hana_p4h_op_mode                	: logreplay
    + hana_p4h_remoteHost             	: br3psapdb40
    + hana_p4h_roles                  	: 4:p:master1:master:worker:master
    + hana_p4h_site                   	: NODEB
    + hana_p4h_srmode                 	: sync
    + hana_p4h_sync_state             	: PRIM
    + hana_p4h_version                	: 2.00.048.01.1596718894
    + hana_p4h_vhost                  	: br3psapdb41
    + lpa_p4h_lpt                     	: 1616136370
    + master-rsc_SAPHana_P4H_HDB40    	: 150

SAP SID: P4H

su - p4hadm -c "hdbnsutil -sr_register --remoteHost=br3psapdb40 --remoteInstance=40 --replicationMode=sync --operationMode=logreplay --name=br3psapdb41"

su - p4hadm -c "hdbnsutil -sr_register --remoteHost=br3psapdb41 --remoteInstance=40 --replicationMode=sync --operationMode=logreplay --name=br3psapdb40"



su - p4hadm -c "hdbnsutil -sr_state"



Celestica CHG Details:
CHG0189755 - CLC-TOR01-PROD & NON-PROD: Toronto DC Cloud MZR change#1 - starts on Mar 19th, 2021	ashish and kaushik
CHG0190198 - CLC-TOR01-PROD & NON-PROD:  Toronto DC Cloud MZR change#2 - starts on 21-03-2021 04:30:00 IST to 21-03-2021 16:30:00 IST sreejesh and sandeep j  
 
Suncor CHG Dtails:

 
CHG0191659 - CTASK0351934 - Shut All production VMs         => 20-03-2021 08:30:00 to 20-03-2021 14:30:00   - (falls during India working hours and owned by IN engineers)
No.of servers - 96
Schedule -  March 19th - 20:00 to 22:00  MT (2 hrs)
Linux Resource : 3
 
CHG0191659 - CTASK0351950- Start All production VMs          => 20th 1:30 PM IST - 2hrs      - (falls during India working hours and owned by IN engineers)
No.of servers - 96
Schedule -  March 20th -02:00 to 04:00  MT (2 hrs)
Linux Resource : 3
 
 
CHG0191665 - CTASK0352061- Start All production VMs         =>  21st 11:30 AM IST  -  2hrs   -(falls during India working hours and owned by IN engineers)
No.of servers - 96 
Schedule -  March 21st -00:00 to 02:00AM  MT (2 hrs)
Linux Resource : 3


CHG0191677 - CTASK0352675 -Start All non production VMs  => Mar 21st 1:30 PM IST  - 3 hrs  - (falls during India working hours and owned by IN engineers)
No.of Servers:152
Schedule - March 21st - 02:00 to 05:00 AM MT ( 3 hrs)
Linux Resource: 4



CHG0190762	20-03-2021 13:30:00	20-03-2021 17:30:00

ia1webdslb	                10.133.15.32			undefined  
ia1webdslbdr	                10.133.15.31			undefined  
ia1webdspprd2	                10.133.15.17			undefined  
ia1adsprddb	                10.133.15.29			undefined  
ia1poprddb	                10.133.15.18			undefined  
ia1webdslbha	                10.133.15.33			undefined  
ia1adsprdapp	                10.133.15.30			undefined  
ia1fioprddb	                10.133.15.14			undefined  
ia1webdspprd1	                10.133.15.16			undefined  
ia1poprdapp	                10.133.15.19			undefined  
ia1fioprdapp	                10.133.15.15			undefined  


CS6290788	ZF Friedrichshafen AG -- ZFF	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 30.13 (thresh: 30)	SQ-SAP-TRIO-B1



LD5
ia2wdprdlb	                10.133.15.60			undefined
FP5
ia2fioprdapp2	                10.133.15.79			undefined
WP5
ia2fioprdwd	                10.133.15.80			undefined
WP5 HA
ia2fioprdwdha	                10.133.15.81			undefined



	ia2otaprddb	                10.133.15.54			undefined  	fixed
	ia2sftpprd	                        10.133.15.55			undefined  	fixed
	ia2sccprdage	                10.133.15.105			undefined  	fixed
ia2sccprdmas	                10.133.15.62			undefined  	fixed
	ia2sccprdmsl	                10.133.15.106			undefined 	fixed
	ia2otapprdapp	                10.133.15.107			undefined	fixed



CS6334707	Suncor Energy Inc. -- SNC	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SNCMSBXHEC001- KB0010973	P2 - Major	SNCMSBXHEC001	Windows
CS6334706	Suncor Energy Inc. -- SNC	Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SNCMDEVHEC001- KB0010973	P2 - Major	SNCMDEVHEC001	Windows
CS6334045	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHDSBSD11	SAP
	CS6333766	Suncor Energy Inc. -- SNC	Service master CRITICAL: 0 master processes running (thresh 1:)	P2 - Major	SNCHSMADA11
CS6332449	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHECATA14
CS6332448	Suncor Energy Inc. -- SNC	Service master CRITICAL: 0 master processes running (thresh 1:)	P2 - Major	SNCHECATA14
CS6332427	Suncor Energy Inc. -- SNC	Service sshd CRITICAL: 0 sshd processes running (thresh 1:)	P2 - Major	SNCHECATA17
CS6332426	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHECATA17
CS6332344	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHBWJQA13
CS6332331	Suncor Energy Inc. -- SNC	Service master CRITICAL: 0 master processes running (thresh 1:)	P2 - Major	SNCHBWJQA14
CS6332149	Suncor Energy Inc. -- SNC	Service sshd CRITICAL: 0 sshd processes running (thresh 1:)	P2 - Major	SNCHEPJQA11
CS6332116	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHLTAQA11
CS6332114	Suncor Energy Inc. -- SNC	Service master CRITICAL: 0 master processes running (thresh 1:)	P2 - Major	SNCHLTAQA11
CS6332099	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHCRADA11
CS6332092	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHBWJSA11
CS6332076	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHBWJQA13
CS6332074	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHECATA14
CS6332061	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHLTAQA11
CS6332053	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHCRADA11
CS6332052	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHECATA19
CS6332046	Suncor Energy Inc. -- SNC	Ping Availability CRITICAL - 10.73.10.112: rta nan. lost 100% Attention commas replaced by dots.	P2 - Major	SNCHTNAPD51
CS6332042	Suncor Energy Inc. -- SNC	Service sshd CRITICAL: 0 sshd processes running (thresh 1:)	P2 - Major	SNCHEPJQA13
CS6332033	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHGRADA11
CS6332008	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHPIJDA11
CS6332000	Suncor Energy Inc. -- SNC	Service master CRITICAL: 0 master processes running (thresh 1:)	P2 - Major	SNCHEUAQA11
CS6331989	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHECAQA19
CS6331947	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHTNAQD11
CS6331946	Suncor Energy Inc. -- SNC	Service master CRITICAL: 0 master processes running (thresh 1:)	P2 - Major	SNCHTNAQD11
CS6331945	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHTNAQD11
CS6331933	Suncor Energy Inc. -- SNC	Ping Availability CRITICAL - 10.73.11.90: rta nan. lost 100% Attention commas replaced by dots.	P2 - Major	SNCHBIBPD21
CS6331932	Suncor Energy Inc. -- SNC	Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)	P2 - Major	SNCHCRATA12
CS6331931	Suncor Energy Inc. -- SNC	Ping Availability CRITICAL - 10.73.10.112: rta nan. lost 100% Attention commas replaced by dots.	P2 - Major	SNCHTNAPD51
CS6331705	Suncor Energy Inc. -- SNC	Service crond CRITICAL: 0 crond processes running (thresh 1:)	P2 - Major	SNCHBIBPD61



ORD43639400ROMS


For JD1, required read access is from /usr/sap/FSPRO.	svjd1srv0    

For JQ1, required read access is from /usr/sap/FSQUO.	svjq1srv0

read access to all MSG* users


msgkaren
msgbikash
msgsatish
msgsangram


SVJS1SRV0	10.6.1.140	/usr/sap/FSQUO & /usr/sap/JS1/J00/j2ee/cluster
SVJD1SRV0	10.6.1.12	/usr/sap/FSPRO & /usr/sap/JD1/J00/j2ee/cluster
SVJQ1SRV0	10.6.2.12	/usr/sap/FSQUO & /usr/sap/JQ1/J00/j2ee/cluster
SPSVEPAJAPP01	10.6.3.13	/usr/sap/FSQUO & /usr/sap/JPP/J00/j2ee/cluster	

503  2021-03-25 13:56:39 df -hT /usr/sap
  504  2021-03-25 13:57:06 tune2fs -l /dev/mapper/jppappvg-jppusrsap_lv  | grep 'mount option'
  505  2021-03-25 13:57:25 tune2fs -o acl /dev/mapper/jppappvg-jppusrsap_lv
  506  2021-03-25 13:57:28 tune2fs -l /dev/mapper/jppappvg-jppusrsap_lv  | grep 'mount option'
  507  2021-03-25 13:58:38 mount -t ext3 -o remount,acl /dev/mapper/jppappvg-jppusrsap_lv /usr/sap
  509  2021-03-25 14:01:57 setfacl -m u:msgkaren:r-x /usr/sap/FSQUO
  510  2021-03-25 14:02:28 setfacl -m u:msgbikash:r-x /usr/sap/FSQUO
  511  2021-03-25 14:02:40 setfacl -m u:msgsatish:r-x /usr/sap/FSQUO
  512  2021-03-25 14:02:56 setfacl -m u:msgsangram:r-x /usr/sap/FSQUO
  
  524  2021-03-25 14:06:58 tune2fs -l /dev/mapper/jppappvg-jppusrJPP_lv | grep 'mount option'
  525  2021-03-25 14:07:11 tune2fs -o acl /dev/mapper/jppappvg-jppusrJPP_lv
  526  2021-03-25 14:07:14 tune2fs -l /dev/mapper/jppappvg-jppusrJPP_lv | grep 'mount option'
  527  2021-03-25 14:07:40 mount -t ext3 -o remount,acl /dev/mapper/jppappvg-jppusrJPP_lv /usr/sap/JPP
  528  2021-03-25 14:08:11 setfacl -m u:msgkaren:r-x /usr/sap/JPP/J00/j2ee/cluster/
  529  2021-03-25 14:08:30 setfacl -m u:msgbikash:r-x /usr/sap/JPP/J00/j2ee/cluster/
  530  2021-03-25 14:08:45 setfacl -m u:msgsatish:r-x /usr/sap/JPP/J00/j2ee/cluster/
  531  2021-03-25 14:09:01 setfacl -m u:msgsangram:r-x /usr/sap/JPP/J00/j2ee/cluster/




CHE01AMMTSM003	SL ticket CS2227539
10:20 > HDD20
10:21 > HDD21	10:21    27 Onln   4 10.913 TB SATA HDD N   N  512B ST12000NM0007-2A1101                    U
11:6  > HDD30	11:6     32 UBad   -      0 KB SATA HDD N   N  512B      x       x       i`     8        i` U


/opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show rebuild
/opt/MegaRAID/storcli/storcli64 /c0 show all
/opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show all | grep -iE "det|cou|tem|SN|S.M|fir"


fsf-che0101c-fz.service.softlayer.com:/IBM02SEV393684_306/data01		16TB		16TB -- on tsls4proddbh		10.200.30.169

tsls4proddbh:/Temp_backup # df -hT .
Filesystem                                                       Type  Size  Used Avail Use% Mounted on
fsf-che0101c-fz.service.softlayer.com:/IBM02SEV393684_306/data01 nfs4   16T  6.5G   16T   1% /Temp_backup



fsf-che0101f-fz.service.softlayer.com:/IBM02SEV393684_307/data01		6 TB		6TB -- on TSLBWPRDDB	


tslbwprdhdb	tta-che01-pod1-phana-h8-6000-001.imzcloud.ibmammsap.local




tta-che01-pod1-phana-h8-6000-001.imzcloud.ibmammsap.local
10.162.186.155
gateway: 10.162.186.129	


tta-che01-pod1-phana-h8-12000-002.imzcloud.ibmammsap.local
10.162.186.219
gateway : 10.162.186.129



route add -net 10.0.80.12 gw 10.162.186.129 netmask 255.255.255.255 dev bond0


route del -net 10.200.30.190 gw 10.162.186.129 netmask 255.255.255.255 dev bond0


10.200.30.190

10.0.80.12/32 via 10.162.186.129 dev bond0


10.0.0.0/8 via 10.162.186.129 dev bond0



10.200.30.190	fsf-che0101f-fz.service.softlayer.com	

11:6     32 UBad   -      0 KB SATA HDD N   N  512B      x       x       i`     8        i` U



CS5939569	P3 - Minor	TSM: lon02ammtsm001 ANR2578W Schedule 7TW_FIL_INC_0430 in domain D30_SMR_SHORT for node MNG_LONMAGSLM0006_FIL_DLY has missed its scheduled start up window.~	SAPB1	linux
CS6342733	P3 - Minor	TSM: fra02ammtsm001 ANR2579E Schedule DLY_INC_0430_11PM in domain NFL_N_FIL for node CH5_SAHODMSD_FIL failed (return code 12).~	SAPB2	linux
CS6342890	P3 - Minor	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule DLY_INC_2330 in domain NFL_P_FIL for node CH5_SAHODMS_FIL failed (return code 12).~	SAPB2	linux




CHG0194773	27th of March 2021 	0630-1030 IST
Restart ECP and GWP SAP cluster (only application)  due  to SAP parameter login/no_automatic_user_sapstar change from value 0 to 1
Change Implementation Date:  27th of March 2021 at 02:00 AM CET for 4 hours duration

ECP SAP system
armfksap303ap     10.7.102.59    Production   - Cluster application - node 1
armfksap303a1     10.7.102.57    Production   - Cluster application - node 2

GWP SAP system
armfksap301a1     10.7.102.62       Production   - Cluster application - node 1
armfksap301ap    10.7.102.64       Production   - Cluster application - node 2



GESPIRITU
gespiritu	Security#1
/usr/sap/FSQUO/env/AppForm
Access: Read Only access (for download)


CS6407555
EQ1 - Quality ERP Application		sveq1srv0	10.6.2.11
RQ1 - Quality ERP Application		sveq1srv0	10.6.2.11
BQ1 - Qaulity BW Aplication		svbq1srv0	10.6.2.14
CQ1 - Quality CRM Application (ABAP)	svcq1srv0	10.6.2.16
LQ1 - Quality POL (ABAP)		svlq1srv0	10.6.2.19






Name,State,Status,Provisioned Space,Used Space,Host CPU,Host Mem
xpierpsbx,Powered On,Unknown,2.86 TB,800CONSPBOBDAPP
CONSGRCPDAPP
CONSPSMABAP
CONSPECCAPQ.1 GB,0 Hz,0 B		XP Investimentos Corretora SA -- XPI
xpideverpdda,Powered On,Unknown,1.5 TB,1.07 TB,0 Hz,0 B		XP Investimentos Corretora SA -- XPI
cm7pidbapp,Powered On,Unknown,1.23 TB,516.08 GB,0 Hz,0 B	CMOC International Brasil -- CM7
conspsmabap,Powered On,Unknown,1.14 TB,602.33 GB,0 Hz,0 B	Concessionaria Aeroporto Rio de Jan -- CON
cm7pidbapq,Powered On,Unknown,1.08 TB,507.79 GB,0 Hz,0 B	CMOC International Brasil -- CM7
corpodbapjd,Powered On,Unknown,810 GB,285.06 GB,0 Hz,0 B	Copersucar S A -- COR	
conspbobdapp,Powered On,Unknown,776.02 GB,193 GB,0 Hz,0 B	Concessionaria Aeroporto Rio de Jan -- CON
cm7podbapq,Powered On,Unknown,658 GB,276.7 GB,0 Hz,0 B		CMOC International Brasil -- CM7
BRSPSOL041AMM,Powered On,Unknown,614.01 GB,290.86 GB,0 Hz,0 B		IBM Internal -- CCP	
conspeccapq,Powered On,Unknown,557.39 GB,182.86 GB,0 Hz,0 B	Concessionaria Aeroporto Rio de Jan -- CON
consgrcpdapp,Powered On,Unknown,516.02 GB,306.12 GB,0 Hz,0 B	Concessionaria Aeroporto Rio de Jan -- CON
corecpepa1,Powered On,Unknown,274 GB,56.61 GB,0 Hz,0 B		Copersucar S A -- COR	
mvosmaptrex,Powered On,Unknown,242 GB,54.36 GB,0 Hz,0 B		Companhia Brasileira de Distribuica -- MVO
BRSPVRS011AMMW1,Powered On,Unknown,26 GB,5.75 GB,0 Hz,0 B
/vmfs/volumes/880e07ae-0ed7ddcb/zdbaeqdb/zdbaeqdb.vmx,Powered Off,Unknown,32 MB,0 B,0 Hz,0 B
/vmfs/volumes/880e07ae-0ed7ddcb/zdbaeqci/zdbaeqci.vmx,Powered Off,Unknown,32 MB,0 B,0 Hz,0 B






	CONSPBOBDAPP
	CONSGRCPDAPP
	CONSPSMABAP
CONSPECCAPQ


	CONSPSMABAP (SAP/IBM)    CONSPSMABAP (SAP/IBM) is unavailable by ICMP    
			CONSGRCPDAPP (SAP/IBM)    Service and Port TCP 3200 is down    
			CONSGRCPDAPP (SAP/IBM)    Service and Port TCP 8200 is down    
			CONSGRCPDAPP (SAP/IBM)    CONSGRCPDAPP (SAP/IBM) is unavailable by ICMP    
CONSPBOBDAPP (SAP/IBM)    CONSPBOBDAPP (SAP/IBM) is unavailable by ICMP    
CONSPBOBDAPP (SAP/IBM)    Service and Port TCP 8080 is down    
	CONSPSMABAP (SAP/IBM)    Service and Port TCP 3200 is down    
	CONSPSMABAP (SAP/IBM)    Service and Port TCP 8000 is down


echo 1 > /sys/class/scsi_disk/0\:0\:6\:0/device/rescan

old Chennai TSM server ip 146.89.142.96



CHG0198847 
MGGGBJSGTSX01
MGGGBJSGTSX02


CHG0198746
MGGGBJSECCX02
MGGGBJSECCX01


Turn off auto-numa balancing
chkconfig --list|grep numa
Already  numad off
###########################
Disable transparent hugepages:
kernel /vmlinuz-2.6.32-754.35.1.el6.x86_64 ro root=/dev/mapper/VolGroup-lv_root nomodeset rd_NO_LUKS LANG=en_US.UTF-8 rd_NO_MD rd_LVM_LV=VolGroup/lv_swap SYSFONT=latarcyrheb-sun16 crashkernel=auto rd_LVM_LV=VolGroup/lv_root  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet transparent_hugepage=never
###########################
Configure C-States for lower latency in Linux
[root@MGGGBJSECCX01 ~]$ cat /sys/devices/system/cpu/cpuidle/current_driver
acpi_idle
###########################
SELinux:
cat /etc/sysconfig/selinux |grep -i SELINUX
SELINUX=disabled
should be disabled.
####################################





br3qgtsdb37 - Primary, QGT, host01
br3qgtsdb36    - Secondary, QGT, host02


su - qgtadm -c "hdbnsutil -sr_register --remoteHost=br3qgtsdb36 --remoteInstance=35 --replicationMode=sync --operationMode=logreplay --name=br3qgtsdb37"




OS: once QGT vmotion completed:  set QGT cluster back to managed (if needed)
OS: faiback the primary node back to  br3qgtsdb37
SAP: validate QGT cluster




CS6490632 can anyone check on this... Please restart the SAP PI server usbd11uni1031.univar.net as soon as possible. for univar ?


CHG0200009 AG Team + Ravi Malik 	not approved
CHG0200334 - AG Team + Ravi Malik 	not approved
CHG0200342 - AG team + Ravi Malik	not approved




CHG0198408
br3qsapdb31    - Primary, QSA, (will end up as secondary, as initially)
* Node br3qsapdb30:
    + hana_q4h_clone_state              : DEMOTED

* Node br3qsapdb31:
    + hana_q4h_clone_state              : PROMOTED




br3qgtsdb36    - Primary, QGT, (will end up as secondary, as initially)
* Node br3qgtsdb36:
    + hana_qgt_clone_state              : PROMOTED
* Node br3qgtsdb37:
    + hana_qgt_clone_state              : DEMOTED




let's follow this OS: faiback the primary node back to br3qsapdb30
SAP: validate QSA cluster
OS: set QSA cluster to unmanaged
BHT: vmotion br3qsapdb31     -  now-Secondary, QSA, host01 to host03


OS: faiback the primary node back to  br3qgtsdb37
SAP: validate QGT cluster
OS: set QGT cluster to unmanaged
BHT: vmotion br3qgtsdb36     - now-Secondary, QGT, host02 to host13
OS: set the QSA cluster back to managed
OS: set the QGT cluster back to managed


su - qgtadm -c "hdbnsutil -sr_register --remoteHost=br3qgtsdb37 --remoteInstance=35 --replicationMode=sync --operationMode=logreplay --name=br3qgtsdb36


su - q4hadm -c "hdbnsutil -sr_register --remoteHost=br3qsapdb30 --remoteInstance=30 --replicationMode=sync --operationMode=logreplay --name=br3qsapdb31"


<user>  ALL=(ALL) NOPASSWD:ALL,SUROOT,RESTRICTED_CMDS



CS6569037	Hino Motors Ltd -- HNO	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 31.53 (thresh: 30)	SQ-SAP-TRIO-B3
CS6567575	Tecnologia De Materiales S.A. -- TDM	P2 - Major	Memory Swap CRITICAL: Swap free 49.62% (thresh 50:%)	SQ-SAP-TRIO-B1
CS6567567	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-04-15-21-49-45 for details.	SQ-SAP-TRIO-B1
CS6569974	Alpro Comm. VA -- APR	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped	SQ-SAP-TRIO-B1
CS6569948	Alpro Comm. VA -- APR	P2 - Major	Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped	SQ-SAP-TRIO-B1



user:msgsatish:r-x
user:msgkaren:r-x
user:msgbikash:r-x
user:msgsangram:r-x


502  2021-03-24 16:45:54 setfacl -m d:u:msgkaren:rx /usr/sap/FSQUO
  503  2021-03-24 16:47:50 getfacl /usr/sap/FSPRO
  509  2021-03-24 16:54:26 tune2fs -l /dev/mapper/vg_app-lv_usrsap                  |grep 'mount option'
  510  2021-03-24 16:59:27 tune2fs -o acl /dev/mapper/vg_app-lv_usrsap
  511  2021-03-24 16:59:57 tune2fs -l /dev/mapper/vg_app-lv_usrsap                  |grep 'mount option'
  512  2021-03-24 17:00:38 setfacl -m u:msgkaren:rx /usr/sap/FSPRO
  513  2021-03-24 17:01:00 setfacl -m u:msgkaren:rx /usr/sap/
  514  2021-03-24 17:01:42 setfacl -m u:msgkaren:r-x /usr/sap/
  515  2021-03-24 17:03:01 cat /etc/redhat-release
  516  2021-03-24 17:04:47 getfacl /usr/sap/FSPRO
  517  2021-03-24 17:12:37 df -hT /usr/sap/
  518  2021-03-24 17:18:38 cat /etc/fstab
  519  2021-03-24 17:25:37 mount |grep /usr/sap/
  520  2021-03-24 17:26:05 df -hT /usr/sap/
  521  2021-03-24 17:26:33 mount |grep 'usrsap'
  522  2021-03-24 17:27:26 cat /etc/fstab
  523  2021-03-24 17:29:31 mount -t ext4 -o remount,acl /dev/mapper/vg_app-lv_usrsap /usr/sap
  524  2021-03-24 17:30:17 mount |grep 'usrsap'
  525  2021-03-24 17:30:48 setfacl -m u:msgkaren:r-x /usr/sap/FSPRO
  526  2021-03-24 17:31:25 su - msgkaren


setfacl -b /usr/sap/JS1/j00/j2ee/cluster/

setfacl -m d:u:msgkaren:rxX /usr/sap/JS1/j00/j2ee/cluster/


[root@SVJS1SRV0 ibmrmalik1]$ setfacl -m d:u:msgkaren:rxX /usr/sap/FSQUO
[root@SVJS1SRV0 ibmrmalik1]$ setfacl -m d:u:msgsatish:rxX /usr/sap/FSQUO
[root@SVJS1SRV0 ibmrmalik1]$ setfacl -m d:u:msgbikash:rxX /usr/sap/FSQUO
[root@SVJS1SRV0 ibmrmalik1]$ setfacl -m d:u:msgsangram:rxX /usr/sap/FSQUO


[root@SVJS1SRV0 ibmrmalik1]$ setfacl -m d:u:msgkaren:rxX /usr/sap/JS1/J00/j2ee/cluster/
[root@SVJS1SRV0 ibmrmalik1]$  setfacl -m d:u:msgsatish:rxX /usr/sap/JS1/J00/j2ee/cluster/
[root@SVJS1SRV0 ibmrmalik1]$  setfacl -m d:u:msgbikash:rxX /usr/sap/JS1/J00/j2ee/cluster/
[root@SVJS1SRV0 ibmrmalik1]$  setfacl -m d:u:msgsangram:rxX /usr/sap/JS1/J00/j2ee/cluster/



setfacl -Rm u:foo:rwX,d:u:foo:rwX test




Drive /c0/e8/s13 - Detailed Information :
Shield Counter = 0
Media Error Count = 0
Other Error Count = 1
Drive Temperature =  36C (96.80 F)
Predictive Failure Count = 0
S.M.A.R.T alert flagged by drive = No
SN = S7M0M5MJ0000M608ALZ7
Firmware Revision = 000B0003

10.164.238.150	lonhana-1024-39.xsportal.local
CS2272062


CS6630414
Request #4:

Source: 10.70.110.25

Source Directory: F:\OpenText\StreamServe\Data\STRS_Output\SOA_DIVISION			SOA_DIVISION (file://Svtq1srv1/soa_division)

Target: 10.70.110.11 (sveq1srv0)

 Request #5:

Source: 10.70.110.25

Source Directory: F:\OpenText\StreamServe\Data\STRS_Output\SOA_STORE	SOA_STORE (file://Svtq1srv1/soa_store)


Target: 10.70.110.11 (sveq1srv0)




//Svtq1srv1/soa_division    /usr/sap/OpenText/STRS_Output/SOA_DIVISION   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//Svtq1srv1/soa_store    /usr/sap/OpenText/soa_store   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0


[root@sveq1srv0 OpenText]# df -hT soa_division
Filesystem           Type  Size  Used Avail Use% Mounted on
//Svtq1srv1/soa_division
                     cifs   50G   40G   11G  80% /usr/sap/OpenText/soa_division		/usr/sap/OpenText/STRS_Output/SOA_DIVISION		SOA_DIVISION (file://SVTQ1SRV1/STRS_Output/SOA_DIVISION)

[root@sveq1srv0 OpenText]# df -hT soa_store
Filesystem           Type  Size  Used Avail Use% Mounted on
//Svtq1srv1/soa_store
                     cifs   50G   40G   11G  80% /usr/sap/OpenText/soa_store		/usr/sap/OpenText/STRS_Output/SOA_STORE



CS6642798	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.10: rta nan. lost 100% Attention commas replaced by dots.
CS6642791	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.35: rta nan. lost 100% Attention commas replaced by dots.
CS6642790	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.18: rta nan. lost 100% Attention commas replaced by dots.
CS6642751	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.17: rta nan. lost 100% Attention commas replaced by dots.
CS6642748	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.36: rta nan. lost 100% Attention commas replaced by dots.
CS6642745	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.31: rta nan. lost 100% Attention commas replaced by dots.
CS6642741	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.19: rta nan. lost 100% Attention commas replaced by dots.
CS6642725	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.33: rta nan. lost 100% Attention commas replaced by dots.
CS6642708	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.14: rta nan. lost 100% Attention commas replaced by dots.
CS6642705	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.38: rta nan. lost 100% Attention commas replaced by dots.
CS6642696	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.35: rta nan. lost 100% Attention commas replaced by dots.
CS6642690	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.11: rta nan. lost 100% Attention commas replaced by dots.
CS6642689	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.10: rta nan. lost 100% Attention commas replaced by dots.
CS6642688	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.20: rta nan. lost 100% Attention commas replaced by dots.
CS6642687	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.15: rta nan. lost 100% Attention commas replaced by dots.
CS6642668	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.30: rta nan. lost 100% Attention commas replaced by dots.
CS6642661	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.13: rta nan. lost 100% Attention commas replaced by dots.
CS6642648	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.12: rta nan. lost 100% Attention commas replaced by dots.
CS6642617	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.13: rta nan. lost 100% Attention commas replaced by dots.
CS6642616	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.27.14: rta nan. lost 100% Attention commas replaced by dots.
CS6642604	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.15: rta nan. lost 100% Attention commas replaced by dots.
CS6642601	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.37: rta nan. lost 100% Attention commas replaced by dots.
CS6642588	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.32: rta nan. lost 100% Attention commas replaced by dots.
CS6642585	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.16: rta nan. lost 100% Attention commas replaced by dots.
CS6642563	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.34: rta nan. lost 100% Attention commas replaced by dots.
CS6642551	Fitbit Inc -- FBT	P2 - Major	Ping Availability CRITICAL - 10.4.26.12: rta nan. lost 100% Attention commas replaced by dots.



CS6650175 master ticket for n/w issue

A0DTUS014XVM002_restore		26BCA014



APP DB bs4eq1061, App bs4eq1062.
10.211.8.101	App+DB	bs4eq1061	EQ1
10.211.8.135	App	bs4eq1062	EQ1

saptempdb deleted from 1061     /sybase/EQ1
'/sybase/EQ1/saptemp/saptempdb_data_001.dat',




CS6377488
Following servers are out of date and need heartbeat from the servers to get the latest updates from DSM, others are online and up to date.
TSLS4PRODDBDR
tsls4proddbdr:/home/ibmrmalik1 # ps aux | grep ds_agent
root     438777  0.0  0.0  86940  9372 ?        S    07:20   0:00 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
root     438778 27.0  0.0 766036 46884 ?        Sl   07:20   0:01 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
root     438841  0.0  0.0  41652  3112 ?        S    07:20   0:00 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R
root     438856  140  0.0 2656240 257816 ?      Sl   07:20   0:03 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R
root     438999  0.0  0.0   9292  1560 pts/3    S+   07:20   0:00 grep --color=auto ds_agent
ttsls4proddbdr:/home/ibmrmalik1 # /etc/init.d/ds_agent reset
HTTP Status: 200 - OK
tsls4proddbdr:/home/ibmrmalik1 # /opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/
Activation will be re-attempted 30 time(s) in case of failure
HTTP Status: 200 - OK
Response:
Attempting to connect to https://169.55.28.73:4120/
SSL handshake completed successfully - initiating command session.
Connected with (NONE) to peer at 169.55.28.73
Received a 'GetHostInfo' command from the manager.
Received a 'SetDSMCert' command from the manager.
Received a 'SetAgentCredentials' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetInterfaces' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetComponentInfo' command from the manager.
Received a 'GetDockerVersion' command from the manager.
Received a 'SetSecurityConfiguration' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Command session completed.
tsls4proddbdr:/home/ibmrmalik1 # rpm -qa |grep -i ds
gvfs-backends-1.28.3-16.5.x86_64
ds_agent-12.0.0-1373.SuSE_12.x86_64
pciutils-ids-2018.02.08-12.3.1.noarch
libspeexdsp1-1.1.999_1.2rc1-22.64.x86_64



EWMAPP3-HA
[root@ewmapp3-ha ibmrmalik1]# rpm -qa |grep -i ds_agent
ds_agent-12.0.0-1373.SuSE_12.x86_64
[root@ewmapp3-ha ibmrmalik1]# /etc/init.d/ds_agent reset
HTTP Status: 200 - OK
[root@ewmapp3-ha ibmrmalik1]# /opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/
Activation will be re-attempted 30 time(s) in case of failure
HTTP Status: 200 - OK
Response:
Attempting to connect to https://169.55.28.73:4120/
SSL handshake completed successfully - initiating command session.
Connected with (NONE) to peer at 169.55.28.73
Received a 'GetHostInfo' command from the manager.
Received a 'SetDSMCert' command from the manager.
Received a 'SetAgentCredentials' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetInterfaces' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetComponentInfo' command from the manager.
Received a 'GetDockerVersion' command from the manager.
Received a 'SetSecurityConfiguration' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Command session completed.


EWMAPP3
[root@ewmapp3 ~]# rpm -qa |grep -i ds_agent
ds_agent-12.0.0-1373.SuSE_12.x86_64
[root@ewmapp3 ~]# /etc/init.d/ds_agent reset
HTTP Status: 200 - OK
[root@ewmapp3 ~]# /opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/
Activation will be re-attempted 30 time(s) in case of failure
HTTP Status: 200 - OK
Response:
Attempting to connect to https://169.55.28.73:4120/
SSL handshake completed successfully - initiating command session.
Connected with (NONE) to peer at 169.55.28.73
Received a 'GetHostInfo' command from the manager.
Received a 'SetDSMCert' command from the manager.
Received a 'SetAgentCredentials' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetInterfaces' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetComponentInfo' command from the manager.
Received a 'GetDockerVersion' command from the manager.
Received a 'SetSecurityConfiguration' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.





SAPAPP31
[root@sapapp31 ibmrmalik1]# rpm -qa |grep -i ds_agent
ds_agent-12.0.0-1373.SuSE_12.x86_64
[root@sapapp31 ibmrmalik1]# /etc/init.d/ds_agent reset
HTTP Status: 200 - OK
[root@sapapp31 ibmrmalik1]# /opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/
Activation will be re-attempted 30 time(s) in case of failure
HTTP Status: 200 - OK
Response:
Attempting to connect to https://169.55.28.73:4120/
SSL handshake completed successfully - initiating command session.
Connected with (NONE) to peer at 169.55.28.73
Received a 'GetHostInfo' command from the manager.
Received a 'SetDSMCert' command from the manager.
Received a 'SetAgentCredentials' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetInterfaces' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetComponentInfo' command from the manager.
Received a 'GetDockerVersion' command from the manager.
Received a 'SetSecurityConfiguration' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Command session completed.


sapapp31-ha
[root@sapapp31-ha ~]# rpm -qa |grep -i ds_agent
ds_agent-12.0.0-1373.SuSE_12.x86_64
[root@sapapp31-ha ~]# /etc/init.d/ds_agent reset
HTTP Status: 200 - OK
[root@sapapp31-ha ~]# /opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/
Activation will be re-attempted 30 time(s) in case of failure
HTTP Status: 200 - OK
Response:
Attempting to connect to https://169.55.28.73:4120/
SSL handshake completed successfully - initiating command session.
Connected with (NONE) to peer at 169.55.28.73
Received a 'GetHostInfo' command from the manager.
Received a 'SetDSMCert' command from the manager.
Received a 'SetAgentCredentials' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetInterfaces' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetComponentInfo' command from the manager.
Received a 'GetDockerVersion' command from the manager.
Received a 'SetSecurityConfiguration' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Command session completed.

TSLBWPRDDB
[root@tslbwprddb ibmrmalik1]$ rpm -qa |grep -i ds_agent
ds_agent-12.0.0-1373.SuSE_12.x86_64
[root@tslbwprddb ibmrmalik1]$ /etc/init.d/ds_agent reset
HTTP Status: 200 - OK
[root@tslbwprddb ibmrmalik1]$ /opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/
Activation will be re-attempted 30 time(s) in case of failure
HTTP Status: 200 - OK
Response:
Attempting to connect to https://169.55.28.73:4120/
SSL handshake completed successfully - initiating command session.
Connected with (NONE) to peer at 169.55.28.73
Received a 'GetHostInfo' command from the manager.
Received a 'SetDSMCert' command from the manager.
Received a 'SetAgentCredentials' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetInterfaces' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetComponentInfo' command from the manager.
Received a 'GetDockerVersion' command from the manager.
Received a 'SetSecurityConfiguration' command from the manager.
Received a 'GetAgentEvents' command from the manager.
Received a 'GetAgentStatus' command from the manager.
Command session completed.



Insufficient storage space on device for datastore path DAL13POOL2POD1DSP533 #6484




Master ticket  CS6702001
 CS6701671	AGEAS -- AGE	Ping Availability CRITICAL - 10.6.1.138: rta nan. lost 100% Attention commas replaced by dots.	
P2 - Major	SVES1HDBSRV01	SQ-SAP-TRIO-B1	
CS6701668	AGEAS -- AGE	Ping Availability CRITICAL - 10.6.3.46: rta nan. lost 100% Attention commas replaced by dots.	
P2 - Major	SPSVMPLMAPP01	SQ-SAP-TRIO-B1
CS6701667AGEAS -- AGEPing Availability CRITICAL - 10.6.3.44: rta nan. lost 100% Attention commas replaced by dots.P2 - MajorSPSVTPLNAPP01SQ-SAP-TRIO-B1
CS6701664AGEAS -- AGEPing Availability CRITICAL - 10.6.2.24: rta nan. lost 100% Attention commas replaced by dots.P2 - MajorSVTQ1SRV0SQ-SAP-TRIO-B1


CS6704209
Kindly mount from source to target. Thanks!

Source: 10.70.110.25	SVTQ1SRV1	10.6.2.25	10.70.110.25

Source Directory: F:\OpenText\StreamServe\Data\STRS_Output\SOA_DIVISION			SOA_DIVISION (file://SVTQ1SRV1/STRS_Output/SOA_DIVISION)

Target: 10.70.110.42		SVMQ1SRV1	10.6.2.42	10.70.110.42

Target Directory: /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION


//SVTQ1SRV1/STRS_Output/SOA_DIVISION    /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0







CS6703964
Kindly mount from source to target. Thanks!
Source: 10.70.110.25		SVTQ1SRV1	10.6.2.25	10.70.110.25
Source Directory: F:\OpenText\StreamServe\Data\STRS_Output\SOA_DIVISION			//SVTQ1SRV1/STRS_Output/SOA_DIVISION		
Target: 10.70.110.42
Target Directory: /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION




CS6801924 P3 - MinorToyota Boshoku -- TBO[TBO] OS user creaton request on J2Q
CS6801563 P4 - MinimalCelestica International Inc. -- CLCExecuting salt module ibm_inventory.get on CLSDWQ01.C4SAP.CELESTICA.COM/clsdwq01
CS6801556 P4 - MinimalCelestica International Inc. -- CLCExecuting salt module ibm_inventory.get on 5674c666-05fd-44de-8cf2-ae4ed49bb9e3/clsltq01
CS6801554 P4 - MinimalCelestica International Inc. -- CLCExecuting salt module ibm_inventory.get on ae73f710-6aed-41b3-882d-ae91580dbfd3/clsmgq01
CS6801553 P4 - MinimalCelestica International Inc. -- CLCExecuting salt module ibm_inventory.get on d217612a-ed36-4bb8-8a6d-5b27e7b4ee2c/clsmgq02
CS6801552 P4 - MinimalCelestica International Inc. -- CLCExecuting salt module ibm_inventory.get on CLSDWQ02.C4SAP.CELESTICA.COM/clsdwq02


running pkg.upgrade: Problem encountered upgrading packages.\
  \ Additional info follows:\n\nchanges:\n    ----------\nresult:\n    ----------\n\
  \    pid:\n        2516512\n    retcode:\n        3\n    stderr:\n        Running\
  \ scope as unit run-rcc74851686af47b9a710351ceaf1c73a.scope.\n        Repository\
  \ \'SLE-12-SAP-DVD1,SLE-12-SAP-DVD2,SLE-12-SP4-SAP-Updates,SLE-HA12-SP4-Pool,SLE-HA12-SP4-Updates,SLE-Module-Adv-Systems-Management12-Pool,SLE-Module-Adv-Systems-Management12-Updates,SLE-SDK12-SP4-Updates,SLE12-SP4-SAP-Pool,SLES12-SP4-Pool,SLES12-SP4-Updates,SMT-*,Updates-SLE-HA,Updates-SLE-SAP,Updates-SLE-SDK,Updates-SLE-SERVER\'\
  \ not found by its alias, number, or URI.\n    stdout:\n        Use \'zypper repos\'\
  \ to get the list of defined repositories."




CS6814248P2 - MajorMeggitt PLC -- MGGPing Availability CRITICAL - 10.133.18.19: rta nan. lost 100% Attention commas replaced by dots.		PHANA maintenance	135560570	number:CS2298554
CS6814258P2 - MajorMeggitt PLC -- MGGPing Availability CRITICAL - 10.133.18.152: rta nan. lost 100% Attention commas replaced by dots.
CS6814261P2 - MajorMeggitt PLC -- MGGPing Availability CRITICAL - 10.133.18.31: rta nan. lost 100% Attention commas replaced by dots.
CS6814265P2 - MajorMeggitt PLC -- MGGPing Availability CRITICAL - 10.133.18.168: rta nan. lost 100% Attention commas replaced by dots.
CS6814267P2 - MajorMeggitt PLC -- MGGPing Availability CRITICAL - mgggbjsgtsx01: rta nan. lost 100% Attention commas replaced by dots.
CS6814269P2 - MajorMeggitt PLC -- MGGPing Availability CRITICAL - 10.133.18.175: rta nan. lost 100% Attention commas replaced by dots.
CS6814270P2 - MajorMeggitt PLC -- MGGPing Availability CRITICAL - 10.133.18.165: rta nan. lost 100% Attention commas replaced by dots.



CS6857834	
Please perform mountin gof OpenText PRD directories to EPP and sftp PRD. Please see below requirements.
Request #1:
Source: 10.70.111.35 (OpenText PRD)		SPSVOPLTAPP01	10.6.3.35	10.70.111.35	
Source Directory: F:\OpenText\StreamServe\Data\STRS_Output\SOA_DIVISION		\\SPSVOPLTAPP01\STRS_Output\SOA_DIVISION
Target: 10.70.111.12 (spsvepaeapp01)		SPSVEPAEAPP01	10.6.3.12	10.70.111.12	
Source Directory: /usr/sap/OpenText/STRS_Output/SOA_DIVISION

[root@spsvepaeapp01 SOA_DIVISION]# df -hT |grep -i cifs
                     cifs   260G  176G   85G  68% /usr/sap/OpenText/STRS_Spool
                     cifs   260G  176G   85G  68% /usr/sap/OpenText/STRS_output
                     cifs   260G  176G   85G  68% /usr/sap/OpenText/STRS_Output/SOA_DIVISION


Request #2:
Source: 10.70.111.35 (OpenText PRD)		SPSVOPLTAPP01	10.6.3.35	10.70.111.35
Source Directory: F:\OpenText\StreamServe\Data\STRS_Output\SOA_STORE		\\SPSVOPLTAPP01\STRS_Output\SOA_STORE
Target: 10.70.111.12 (spsvepaeapp01)		SPSVEPAEAPP01	10.6.3.12	10.70.111.12	
Source Directory: /usr/sap/OpenText/STRS_Output/SOA_STORE

[root@spsvepaeapp01 SOA_STORE]# df -hT |grep -i cifs
                     cifs   260G  176G   85G  68% /usr/sap/OpenText/STRS_Spool
                     cifs   260G  176G   85G  68% /usr/sap/OpenText/STRS_output
                     cifs   260G  176G   85G  68% /usr/sap/OpenText/STRS_Output/SOA_DIVISION
                     cifs   260G  176G   85G  68% /usr/sap/OpenText/STRS_Output/SOA_STORE


Request #3:
Source: 10.70.111.35 (OpenText PRD)		SPSVOPLTAPP01	

mount -o anon usa-node01:/mapr z:

mount -o anon lbudo1ap02:/interface Z:




OGYSGP036	10.139.9.81   WDC SUSE

FBQFIRAPP	10.4.26.33	Linux	Dal09
Server Type: Non-Production                                              *
*       Hostname: fbqfirapp                                                   *
*         CFN IP: 192.168.166.33                                              *
*         IFN IP: 10.4.26.33                                                  *
*        SAP SID: FIQ 


[root@fbqfirapp ibmrmalik1]$ wget https://158.87.44.143/nrdp
--2021-05-19 18:39:27--  https://158.87.44.143/nrdp
Connecting to 158.87.44.143:443...



Also created a cron entry to move files every 30 mins from /sapdb_backups/CSP/log/ to /CSPLOG/

[root@bapconprd1 ~]# df -h /CSPLOG/
Filesystem Size Used Avail Use% Mounted on
/dev/mapper/tempvg-temp_CSPLOG
1007G 33G 924G 4% /CSPLOG
[root@bapconprd1 ~]# df -h /sapdb_backups/CSP/log/
Filesystem Size Used Avail Use% Mounted on
/dev/mapper/csparchvg-sapdb_backups_lv
99G 8.2G 86G 9% /sapdb_backups



find $sDirectory -type f -maxdepth 1 -name "*.mp4" -exec mv {} $sVideos \;

*/30 * * * * find "/sapdb_backups/CSP/log" -maxdepth 1 -type f -name "*" -mmin +30 -exec mv {} "/CSPLOG" \;



PU1	SNCHCUAPD11	10.73.10.92	
PU1	SNCHCUAPD51	10.73.10.93
PU1	SNCHCUAPA11	10.73.10.94
PU1	SNCHCUAPA12	10.73.10.95


SNCHBDWPW51	23:53:40 up  1:34,  2 users,  load average: 0.05, 0.16, 0.24	rebooted

SNCHSMADD11	 23:54:19 up 34 days, 16:16,  3 users,  load average: 0.87, 0.79, 0.74	not rebooted
SNCHEUAPA13	 23:54:54 up  1:33,  2 users,  load average: 0.01, 0.02, 0.05	rebooted
SNCHBWJPA11	23:55:17 up  1:33,  2 users,  load average: 0.11, 0.08, 0.08	rebooted
SNCHECAPA15	 23:55:40 up  1:33,  1 user,  load average: 0.34, 0.16, 0.11	rebooted
SNCHDIJPA11	23:56:03 up  1:33,  3 users,  load average: 0.09, 0.12, 0.24	rebooted
SNCHECAPA13	23:56:26 up  1:33,  1 user,  load average: 0.06, 0.06, 0.09	rebooted
SNCHSMADD11	 23:56:46 up  1:33,  2 users,  load average: 0.04, 0.06, 0.08	rebooted



QP6	SNCHEPJQD11	10.73.12.49	00:14:43 up 6 days,  5:21,  1 user,  load average: 0.34, 0.34, 0.36	not rebooted
QP6	SNCHEPJQA11	10.73.12.50	00:15:46 up 6 days,  5:16,  1 user,  load average: 0.31, 0.15, 0.10	not rebooted	ammtor01custesx071.imzcloud.ibmammsap.local	62 days uptime
QP6	SNCHEPJQA12	10.73.12.51	00:16:17 up 6 days,  5:16,  1 user,  load average: 0.10, 0.06, 0.07	not rebooted	ammtor01custesx071.imzcloud.ibmammsap.local
QP6	SNCHEPJQA13	10.73.12.52	00:16:41 up 6 days,  5:17,  1 user,  load average: 0.14, 0.28, 0.14	not rebooted	ammtor01custesx070.imzcloud.ibmammsap.local
QP6	SNCHEPJQA14	10.73.12.53	 00:17:05 up  1:56,  1 user,  load average: 0.32, 0.12, 0.03		REBOOTED	ammtor01custesx070.imzcloud.ibmammsap.local	
QP6	SNCHEPJQA15	10.73.12.54	00:17:28 up 6 days,  5:17,  1 user,  load average: 0.00, 0.04, 0.07	not rebooted	ammtor01custesx071.imzcloud.ibmammsap.local
QP6	SNCHEPJQA16	10.73.12.55	00:18:02 up 6 days,  5:18,  1 user,  load average: 0.07, 0.06, 0.03	not rebooted	ammtor01custesx070.imzcloud.ibmammsap.local



SNCHEUAQA12	01:28:47 up  3:11,  1 user,  load average: 0.14, 0.09, 0.01	rebooted
SNCHSMJDA11	01:29:16 up  3:12,  1 user,  load average: 0.07, 0.03, 0.00	rebooted
SNCHZRAQA12	01:29:40 up  3:12,  1 user,  load average: 0.11, 0.05, 0.01	rebooted
SNCHWDWTW11	01:30:37 up  3:13,  1 user,  load average: 0.08, 0.09, 0.08	rebooted
SNCHECAQA15	01:31:05 up  3:14,  1 user,  load average: 0.11, 0.11, 0.08	rebooted
SNCHECADA11	01:31:29 up  3:13,  1 user,  load average: 0.04, 0.04, 0.00	rebooted
SNCHTRIQA13	01:31:50 up  3:13,  1 user,  load average: 0.09, 0.07, 0.02	rebooted
SNCHEPJQA14	01:32:11 up  3:11,  6 users,  load average: 0.00, 0.04, 0.06	rebooted


snchbibqd11	01:36:22 up  3:18,  1 user,  load average: 0.51, 0.59, 0.57	rebooted
sncheuasd11	01:36:48 up  3:19,  1 user,  load average: 0.33, 0.32, 0.12	rebooted
snchbdjta11	01:37:18 up  3:20,  1 user,  load average: 0.32, 0.35, 0.14	rebooted
snchepjta12	01:37:43 up  3:20,  1 user,  load average: 0.04, 0.21, 0.11	rebooted
snchcuata12	01:38:10 up  3:21,  1 user,  load average: 0.59, 0.37, 0.14	rebooted
snchtripa11	01:38:35 up  3:15,  1 user,  load average: 0.45, 0.40, 0.36	rebooted




CHG0195211	Upgrade SUSE Linux servers from 12 SP2 to 12 SP4:

ARMFKSAP305A1	10.7.102.71	Production  -  POP Cluster application - node 1 - application is up on both nodes	The disk space in partition /run/user/20000 is nearly exhausted.
ARMFKSAP305AP	10.7.102.50	Production  -  POP  Cluster application - node 1- application is up on both nodes
ARMFKSAP305D1	10.7.102.70	Production -   POP Cluster sybase - node 1 - database is active on this node
ARMFKSAP305DB	10.7.102.54	Production -   POP  Cluster sybase - node 2						The disk space in partition /run/user/17882
armfksap303ap	 10.7.102.59	Production   - ECP Cluster application - node 1- application is up on both nodes	The disk space in partition /sapmnt/ECP
armfksap303a1	 10.7.102.57	Production   - ECP Cluster application - node 2- application is up on both nodes	The disk space in partition /run/user/17882 


Customer:  Roberto Ciambella  (Roberto Ciambella/Italy/IBM)
DPE: Mahesh K Naik/India/IBM@IBMIN
PDL: Gratiela Novac, Valentin Caradaica

[root@armfksap305a1 tmp]$ ./prechecks.sh >>prechecksb4patch

prechecksb4patch

Cluster in maintenance mode
app stop
prechecks
take snapshot
stop pacemaker cluster service
start patching 
after reboot start pacemaker cluster and run validation script and fix primitives (backup the config file b4 changes)
make it managed
HO to SAP for app start



armfksap305a1 armfksap305ap	JAVA cluster

armfksap305d1 armfksap305db	Sybase cluster
[root@armfksap305db POP]$ /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py |grep -i FAILED
Cluster VM on same ESX host         : True                                                [ FAILED ]
Cluster on same Datastore           : True                                                [ FAILED ]
armfksap305db anti_affinity rule enabled : False                                               [ FAILED ]
armfksap305db anti_affinity rule enabled : False                                               [ FAILED ]
armfksap305db Pacemaker Tools       : pacemaker-tools-1.4-0.noarch                        [ FAILED ]
armfksap305db Pacemaker Tools       : pacemaker-tools-1.4-0.noarch                        [ FAILED ]
armfksap305db Pacemaker Service     : enabled                                             [ FAILED ]
armfksap305db Pacemaker Service     : enabled                                             [ FAILED ]
armfksap305db DefaultTasksMax       : 512                                                 [ FAILED ]
armfksap305db DefaultTasksMax       : 512                                                 [ FAILED ]
armfksap305db eth_offload           : on                                                  [ FAILED ]
armfksap305db eth_offload           : on                                                  [ FAILED ]
armfksap305db Logrotate             : Disabled                                            [ FAILED ]
armfksap305db Logrotate             : Disabled                                            [ FAILED ]
Cluster Token                       : 5000                                                [ FAILED ]
Cluster Consensus                   : 6000                                                [ FAILED ]
Cluster to_syslog                   : no                                                  [ FAILED ]
Vcenter Plug                        : armfksap305d1                                       [ FAILED ]
Vcenter filter.names                : filter.names=armfksap305d1                          [ FAILED ]





armfksap303a1 armfksap303ap	ABAP 	ECP_ERS10		ECP_ASCS01
[root@armfksap303a1 tmp]$ /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py |grep -i FAILED
Cluster on same Datastore           : True                                                [ FAILED ]
cluster order constraint            : No.. of order = 5 (Expected 6)                      [ FAILED ]


Primitive corrections are to be done on any onf the the cluster nodes
fence_vmware_soap:

Link for primitive changes
https://github.ibm.com/CMS/SAP-Base-RR/tree/master/CMAS%203x/Pacemaker/Primitives/SLES%20SP4

cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/fence_vmware_soap /usr/sbin/fence_vmware_soap
chmod 755 /usr/sbin/fence_vmware_soap

validation script 
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py
crm configure show >>/tmp/configure_backup
crm configure edit	and :wq to save	
commit(to save changes)

armfksap305d1 armfksap305db
vCenter Login                       : Failed                                              [ FAILED ]
armfksap305db Pacemaker Service     : enabled                                             [ FAILED ]
armfksap305d1 DefaultTasksMax       : 512                                                 [ FAILED ]
armfksap305db DefaultTasksMax       : 512                                                 [ FAILED ]
armfksap305d1 eth_offload           : on                                                  [ FAILED ]
armfksap305db eth_offload           : on                                                  [ FAILED ]
armfksap305d1 Logrotate             : Disabled                                            [ FAILED ]
armfksap305db Logrotate             : Disabled                                            [ FAILED ]
Corosync Configuration
----------------------
Cluster Token                       : 5000                                                [ FAILED ]
Cluster Consensus                   : 6000                                                [ FAILED ]
Cluster to_syslog                   : no                                                  [ FAILED ]








ref
HPP	hfchppdb1	- 10.191.16.106 - SAP Portal production database server
HPP	hfchppdb1ha	- 10.191.16.29 - SAP Portal production database server HA
HCD	hfchcddb1	- 10.191.16.76 - SAP Environmental Compliance production (yes, it is production even though it's named HCD) database server
HCD	hfchcddb1ha	- 10.191.16.40 - SAP Environmental Compliance production (yes, it is production even though it's named HCD) database server HA

WDP	hfcwdpapp1	- 10.191.16.46 - Web dispatcher production app
WDP	hfcwdpapp1ha - 10.191.16.116 - Web dispatcher production app HA

SJP	hfcsjpapp1  - 10.191.16.91 - Solman Java production app server
SJP     hfcsjpapp1ha - 10.191.16.43 - Solman Java production app server HA

SMP	hfcsmpapp1  - 10.191.16.101 - Solman ABAP production app server
SMP     hfcsmpapp1ha - 10.191.16.32 - Solman ABAP production app server HA



10.162.24.222	tata-che01-pod1-phana-6114-2.imzcloud.ibmammsap.local	TSLEECQA
CS2327843  SL case
https://scc.suse.com/support/cases/00285709	External SuSE vendor case Support Cases 00285709
Internal SuSE TS005761213
https://www.ibm.com/mysupport/s/case/5003p00002XeSJMAA3/phana-server-got-hung-and-had-to-be-rebooted-to-fix?openCase=true



IPMI 10.162.24.254	Hl56jLgs66


[root@tsleecqa ibmrmalik1]$  dmesg |grep -i error
[   15.228073] HEST: Enabling Firmware First mode for corrected errors.
[   18.582593] ERST: Error Record Serialization Table (ERST) support is initialized.
[   18.582689] [Firmware Warn]: GHES: Poll interval is 0 for generic hardware error source: 4, disabled.
[   25.073550] IPMI message handler: This machine has two different BMCs with the same product id and device id.  This is an error in the firmware, but incrementing the device id to work around the problem. Prod ID = 0x419, Dev ID = 0x20



May 28 07:48:50 tsleecqa kernel: [ 25.073550] IPMI message handler: This machine has two different BMCs with the same product id and device id. This is an error in the firmware, but incrementing the device id to work around the problem. Prod ID = 0x419, Dev ID = 0x20 May 28 07:49:00 tsleecqa filebeat[10251]: 2021-05-28T07:49:00.312+0530#011INFO#011beater/filebeat.go:92#011Enabled modules/filesets: nginx (access, error), apache (access, error), postgresql (log), mysql (error, slowlog), system (auth, syslog), elasticsearch (deprecation, gc, server, slowlog, audit), ()



10.132.133.77	tok02-pod1-4tb-host01.imzcloud.ibmammsap.local


CS7066693	HollyFrontier Corporation -- HFC	P2 - Major	Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-05-27-21-43-25 for details.	SQ-SAP-TRIO-B3	
CS7066647	IAG - British Airways -- IA2	P2 - Major	Log PaceMaker-log Found 9 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-05-28-04-39-12 for details.	SQ-SAP-TRIO-B1	
CS7066605	HollyFrontier Corporation -- HFC	P2 - Major	Log PaceMaker-log Found 18 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-05-27-21-38-23 for details.	SQ-SAP-TRIO-B3	
CS7066247	The Ogilvy Group Inc -- OGY	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-05-27-17-15-02 for details.	SQ-SAP-TRIO-B2	n
CS7066231	Panasonic North America -- PN4	P2 - Major	Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-05-27-17-04-25 for details.	SQ-SAP-TRIO-B1	n




CS7066358P2 - MajorBombardier Recreational Products Inc -- BR3Memory Swap CRITICAL: Swap free 49.98% (thresh 50:%)
CS7066409P2 - MajorControladora De Negocios -- CNGMemory Physical CRITICAL: physical = 11.936GB
CS7067232P2 - MajorCOTY Inc. -- CTUPing Availability CRITICAL - 10.12.10.140: rta nan. lost 100% Attention commas replaced by dots.



CS7079150
BAPECCV38

Copy the Export data to HDD

Step I
1) Copy Data from Source /exportfs to HDD1
2) Unmount HDD1 from ISCSI port
3) Mount HDD2 (ISCSI Port)
4) Copy Data from Source /Exportfs to HDD2
5) Unmount HDD2 from ISCSI Port
6) Mount HDD3 (ISCSI Port)
7) Copy Data from Source / Exportfs to HDD3
8) Unmount HDD3 from ISCSI port

To Mount ISCSI port on Source

https://cloud.ibm.com/docs/DataTransferService?topic=DataTransferService-mount-dts-linux

Source IP Source IP 10.134.3.16
Port 3260

Target HDD1 - 10.2.32.71
UserName - IBMDT393684-78
Password - va9qQwdcaV94

[root@bapeccv38 mnt]# df -hT /mnt
Filesystem     Type     Size  Used Avail Use% Mounted on
/dev/sdq1      fuseblk  1.9T  177G  1.7T  10% /mnt



HDD2 - Username - IBMDT393684-76
Password - fLzA2BDLVKEY


mount -t fuseblk /dev/sdq1 /mnt

HDD3 - Username - IBMDT393684-77
Password - kb4gZbJnE7Uz



mount.ntfs-3g /dev/sdq1 /mnt
rsync -avz /exportfs /mnt


139  2021-05-24 19:20:39 iscsiadm -m discovery -t sendtargets -p  10.2.32.71


[root@bapeccv38 ~]# iscsiadm -m discovery -t sendtargets -p  10.2.32.71
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-76
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-78

[root@bapeccv38 ~]# iscsiadm -m discovery -t sendtargets -p  10.2.32.71
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-76
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-77
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-78



iscsiadm -m node -T [output from previous command, starting with IQN.] -p [IP address in StorageLayer] -l
 142  2021-05-24 19:21:40 iscsiadm -m node -T iqn.1994-05.com.redhat:7712241530:IBMDT393684-76 -p 10.2.32.71 -l


[root@bapeccv38 ~]# iscsiadm -m node -T iqn.1994-05.com.redhat:7712241530:IBMDT393684-77 -p 10.2.32.71 -l
Logging in to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-77, portal: 10.2.32.71,3260]
Login to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-76, portal: 10.2.32.71,3260] successful.


[root@bapeccv38 ~]# iscsiadm -m node -T iqn.1994-05.com.redhat:7712241530:IBMDT393684-77 -p 10.2.32.71 -l
Logging in to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-77, portal: 10.2.32.71,3260]
Login to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-77, portal: 10.2.32.71,3260] successful.




[root@gknfioridev sapdata4]$ ls -ltr /dev/nwddatavg
total 0
lrwxrwxrwx 1 root root 8 Jun  1 22:37 db2_NWD_saptmp4_lv -> ../dm-36

root@gknfioridev sapdata4]$ pvs
  WARNING: Device for PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig not found or rejected by a filter.

[root@gknfioridev sapdata4]$ mount -t ext4 /dev/nwddatavg/db2_NWD_sapdata4_lv /db2/NWD/sapdata4
mount: special device /dev/nwddatavg/db2_NWD_sapdata4_lv does not exist


[root@gknfioridev sapdata4]$ blkid /dev/sdc
/dev/sdc: PTUUID="3bde513c" PTTYPE="dos"


32 GB disks
HDD7 0:2 disk7	[DAL13POOL1DS270] gknfioridev_restore/gknfioridev_restore_6-000001.vmdk
HDD3 0:5 disk3	[DAL13POOL1DS270] gknfioridev_restore/gknfioridev_restore_2-000001.vmdk

[root@gknfioridev scsi_disk]$ lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdb
	[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[0:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sdh
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdd
[0:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sde
[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdf
[1:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdg


[root@gknfioridev scsi_disk]$ pvs
  WARNING: Device for PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig not found or rejected by a filter.
  PV             VG        Fmt  Attr PSize   PFree
  	/dev/sda2      rootvg    lvm2 a--   63.49g  5.89g
  	/dev/sdb       rootvg    lvm2 a--   50.00g 14.00g
 	 /dev/sdd       nwdlogvg  lvm2 a--   32.00g 12.00g
  	/dev/sde       nwdarchvg lvm2 a--   64.00g 47.00g
  	/dev/sdf       nwddatavg lvm2 a--  128.00g  1.99g
  	/dev/sdg       nwdappvg  lvm2 a--  200.00g 55.00g
  	/dev/sdh1      nwddatavg lvm2 a--   16.00g 16.00g
  unknown device nwddatavg lvm2 a-m   32.00g     0


[root@gknfioridev archive]$ pvs
  WARNING: Device for PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig not found or rejected by a filter.
  WARNING: Device for PV aH7N04-rvvu-RVno-fPCH-cjt6-OwYs-pHBQpd not found or rejected by a filter.
  PV             VG        Fmt  Attr PSize   PFree
  /dev/sda2      rootvg    lvm2 a--   63.49g  5.89g
  /dev/sdb       rootvg    lvm2 a--   50.00g 14.00g
  /dev/sdd       nwdlogvg  lvm2 a--   32.00g 12.00g
  /dev/sde       nwdarchvg lvm2 a--   64.00g 47.00g
  /dev/sdf       nwddatavg lvm2 a--  128.00g  1.99g
  /dev/sdg       nwdappvg  lvm2 a--  200.00g 55.00g
  /dev/sdh1      nwddatavg lvm2 a--   16.00g 16.00g
  unknown device nwddatavg lvm2 a-m   32.00g     0
  unknown device nwddatavg lvm2 a-m   32.00g 32.00g



db2_NWD_sapdata4_lv        nwddatavg -wi-----p-  42.00g                                                     unknown device(0)

PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig 


pvcreate --uuid "8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig" --restorefile /etc/lvm/archive/VG_00050.vg /dev/sdc



db2_NWD_sapdata4_lv        nwddatavg -wi-a---p-  42.00g                                                     unknown device(0)
  db2_NWD_sapdata4_lv        nwddatavg -wi-a---p-  42.00g                                                     /dev/sdf(29696)


WARNING: Device for PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig not found or rejected by a filter.
  WARNING: Device for PV aH7N04-rvvu-RVno-fPCH-cjt6-OwYs-pHBQpd not found or rejected by a filter.



vcreate --uuid "8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig" --restorefile /etc/lvm/archive/nwddatavg_00008-201606036.vg /dev/sdc

 File:         /etc/lvm/backup/nwddatavg
  Couldn't find device with uuid Guf30L-3DfG-hGby-nErT-rTSJ-gy3p-T9bX0B.
  Couldn't find device with uuid aH7N04-rvvu-RVno-fPCH-cjt6-OwYs-pHBQpd.
  Couldn't find device with uuid efbWPB-nawl-O3LV-a56Q-HebI-UbBy-plZZQe.
  VG name:      nwddatavg
  Description:  Created *after* executing 'vgextend nwddatavg /dev/sdc'
  Backup Time:  Wed Jun  2 11:09:55 2021



[root@gknfioridev archive]$ vgscan -v
    Wiping cache of LVM-capable devices
    Wiping internal VG cache
  Reading all physical volumes.  This may take a while...
    Using volume group(s) on command line.
  WARNING: Device for PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig not found or rejected by a filter.
  WARNING: Device for PV aH7N04-rvvu-RVno-fPCH-cjt6-OwYs-pHBQpd not found or rejected by a filter.
    There are 2 physical volumes missing.
    There are 2 physical volumes missing.
  Found volume group "nwddatavg" using metadata type lvm2
  Found volume group "nwdarchvg" using metadata type lvm2
  Found volume group "rootvg" using metadata type lvm2
  Found volume group "nwdlogvg" using metadata type lvm2
  Found volume group "nwdappvg" using metadata type lvm2


[root@gknfioridev archive]$ pvscan -v
    Wiping cache of LVM-capable devices
    Wiping internal VG cache
  WARNING: Device for PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig not found or rejected by a filter.
  WARNING: Device for PV aH7N04-rvvu-RVno-fPCH-cjt6-OwYs-pHBQpd not found or rejected by a filter.
    There are 2 physical volumes missing.
    Walking through all physical volumes
  WARNING: Device for PV 8mY7Wc-2KQb-v5JQ-zLCd-su2q-sV0a-ucP1ig not found or rejected by a filter.
  WARNING: Device for PV aH7N04-rvvu-RVno-fPCH-cjt6-OwYs-pHBQpd not found or rejected by a filter.
    There are 2 physical volumes missing.
  PV /dev/sdg         VG nwdappvg    lvm2 [200.00 GiB / 55.00 GiB free]
  PV /dev/sdd         VG nwdlogvg    lvm2 [32.00 GiB / 12.00 GiB free]
  PV /dev/sda2        VG rootvg      lvm2 [63.49 GiB / 5.89 GiB free]
  PV /dev/sdb         VG rootvg      lvm2 [50.00 GiB / 14.00 GiB free]
  PV /dev/sde         VG nwdarchvg   lvm2 [64.00 GiB / 47.00 GiB free]
  PV /dev/sdf         VG nwddatavg   lvm2 [128.00 GiB / 1.99 GiB free]
  PV unknown device   VG nwddatavg   lvm2 [32.00 GiB / 0    free]
  PV /dev/sdh1        VG nwddatavg   lvm2 [16.00 GiB / 16.00 GiB free]
  PV unknown device   VG nwddatavg   lvm2 [32.00 GiB / 32.00 GiB free]
  PV /dev/sdc         VG nwddatavg   lvm2 [32.00 GiB / 32.00 GiB free]
  Total: 10 [649.46 GiB] / in use: 10 [649.46 GiB] / in no VG: 0 [0   ]





CHG0206820
zffpappdb015/zffpappdb021/zffpappdb022/zffpappdb023 -Upgrade SUSE Linux servers from 12 SP2 to 12 SP4 (EBP, GWP, JWP, BWP,BJP)

Server Role	                        Hostname	            IFN IP                        SID
zffpappdb015	         100.126.67.55          EBP    (Application server+db)
zffpappdb021		 100.126.67.54            GWP   (Application server+db)
zffpappdb022          	 100.126.67.51         JWP    (Application server+db)
zffpappdb023             100.126.67.170         BJP, BWP    (Application server+db)




CHG0206823
zffpapp002/zffpapp002-ha/zffpdb002/zffpdb002-ha -Upgrade SUSE Linux servers from 12 SP2 to 12 SP4 (KPX)

Server Role	                        Hostname	            IFN IP                        SID
zffpapp002	         100.126.67.129          KPX    (Application server)	java
zffpapp002-ha		 100.126.67.130           KPX   (Application server)
zffpdb002                100.126.67.134                 dbserver		oracle
zffpdb002-ha             100.126.67.135         dbserver



Fixed as part of the patching change 
CHG0206823



N/w side issue CS7209894
3.x Network team post investigation had reset the VPN on device fra02INFRAvyatta001 device, post which the network connectivity got restored



tslbwprdhdbdr




sapcrmdi  TTLMUM01DSC02		ammmum01vrs001


ttar3dev	TTA_PG2


tata VMs:
tsls4proddb.imzcloud.ibmammsap.local (10.207.61.123)
tsls4proddbh.imzcloud.ibmammsap.local (10.207.61.113)
tsleecqa.imzcloud.ibmammsap.local (10.207.63.14)

TSM server :
che01ammtsm005.imzcloud.ibmammsap.local (146.89.142.119)  / 10.162.24.194

tsls4proddbh:/home/ibmrmalik1 # route
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
default         10.170.61.1     0.0.0.0         UG    0      0        0 vlan1
10.0.80.12      10.162.186.129  255.255.255.255 UGH   0      0        0 bond0
10.136.0.0      10.170.61.1     255.255.0.0     UG    0      0        0 vlan1
10.152.0.0      10.170.61.1     255.255.0.0     UG    0      0        0 vlan1
10.162.24.192   10.162.186.129  255.255.255.192 UG    0      0        0 bond0
10.162.88.64    10.170.61.1     255.255.255.192 UG    0      0        0 vlan1
10.162.103.192  10.170.61.1     255.255.255.192 UG    0      0        0 vlan1
10.162.186.128  *               255.255.255.128 U     0      0        0 bond0
10.170.61.0     *               255.255.255.0   U     0      0        0 vlan1
10.170.64.0     10.170.61.1     255.255.255.0   UG    0      0        0 vlan1
10.200.30.0     10.162.186.129  255.255.255.0   UG    0      0        0 bond0
10.207.61.0     *               255.255.255.0   U     0      0        0 vlan0
146.89.140.0    10.207.61.1     255.255.252.0   UG    0      0        0 vlan0
146.89.168.0    10.207.61.1     255.255.248.0   UG    0      0        0 vlan0
158.87.44.0     10.207.61.1     255.255.254.0   UG    0      0        0 vlan0
158.87.46.0     10.207.61.1     255.255.254.0   UG    0      0        0 vlan0
80.10.37a9.ip4. 10.207.61.1     255.255.255.240 UG    0      0        0 vlan0
169.55.28.32    10.207.61.1     255.255.255.224 UG    0      0        0 vlan0
169.55.28.64    10.207.61.1     255.255.255.240 UG    0      0        0 vlan0
169.55.192.96   10.207.61.1     255.255.255.224 UG    0      0        0 vlan0
169.60.136.0    10.207.61.1     255.255.252.0   UG    0      0        0 vlan0




bond0: flags=5187<UP,BROADCAST,RUNNING,MASTER,MULTICAST>  mtu 1500
        inet 10.162.24.194  netmask 255.255.255.192  broadcast 10.162.24.255
        inet6 fe80::ec4:7aff:feeb:acc0  prefixlen 64  scopeid 0x20<link>
        ether 0c:c4:7a:eb:ac:c0  txqueuelen 1000  (Ethernet)
        RX packets 8107285  bytes 10266230161 (9.5 GiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 1091942  bytes 143273310 (136.6 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

bond0.886: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 146.89.142.119  netmask 255.255.255.192  broadcast 146.89.142.127



inet 10.162.24.194  netmask 255.255.255.192  broadcast 10.162.24.255
  inet 146.89.142.119  netmask 255.255.255.192  broadcast 146.89.142.127



route add -net 10.162.24.194 gw 10.162.24.255 netmask 255.255.255.192 dev bond0

route add -net 146.89.142.119 gw 146.89.142.127 dev bond0


ip route add 10.162.24.194 via 10.162.24.255 dev bond0



SNOW ticket CS7237909
SL CS2347837


ewmapp1 TTLMUM01DSC04	replication	15 min	TTA PG1

sapapp18	TTLMUM01DSC07	15 min	TTA PG1



CS7238512P2 - MajorCelestica International Inc. -- CLCResources CRM CRITICAL: Unmanaged resources found: vcenter-fencing-clsdwp01(stonith:fence_vmware_soap):Started clsdwp01ha (unmanaged) vcenter-fencing-clsdwp01ha
CS7238550 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-06-10-19-41-23 for details.
CS7238899 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-06-10-20-11-27 for details.
CS7238987 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 3 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_lo
CS7239082 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-06-10-20-41-22 for details.
CS7239198 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-06-10-20-51-31 for details.
CS7239406 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-06-10-21-11-27 for details.
CS7239468 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cm
CS7239604 P2 - MajorCelestica International Inc. -- CLCLog PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-06-10-21-41-29 for details.


CS7234567	Home Control Singapore -- HCS	HCS	Incident	P2 - Major	New		Ping Availability CRITICAL - 10.204.2.190: rta nan. lost 100% Attention commas replaced by dots.	
CS7219825	Home Control Singapore -- HCS	HCS	Incident	P2 - Major	Awaiting Info	Blocked by customer	Ping Availability CRITICAL - 10.204.2.190: rta nan. lost 100% Attention commas replaced by dots.


 reset the VPN Tunnel between fra02INFRAvyatta001 and eu-seiaggregator-vyatta002


su - bp1adm -c "hdbnsutil -sr_register --remoteHost=clsdwp04 --remoteInstance=05 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEB" 


CHG0194586
ARMFKSAP301A1	10.7.102.62	ABAP                         GWP SAP system (Cluster application - node 1) - application up and running on both nodes
ARMFKSAP301AP	10.7.102.64	ABAP                         GWP SAP system (Cluster application - node 2)- application up and running on both nodes
ARMFKSAP301D1	10.7.102.65	Sybase                         GWP SAP system (Cluster sybase - node 1)
ARMFKSAP301DB	10.7.102.66	Sybase                         GWP SAP system (Cluster sybase - node 2) - currently the database is active on this node
armfksap302a1	 10.7.102.60	Production                         WEP SAP Webdispatcher (Cluster application - node 1 - application is running on this node)
armfksap302ap	 10.7.102.67	Production                         WEP SAP Webdispatcher (Cluster application - node 2)

./prechecks.sh >>prepatch.txt

./prechecks.sh >>postpatch.txt



rsc_
last line   capital   primitive name

group
new nmae capital letter



CS7329868
frahana-1024-11.xsportal.local	mggdrdgtsx02
Media Error Count = 68


Drive /c0/e8/s16 - Detailed Information :
Shield Counter = 0
Media Error Count = 68
Other Error Count = 0
Drive Temperature =  36C (96.80 F)
Predictive Failure Count = 0
S.M.A.R.T alert flagged by drive = No
SN = 6SLA7MNA0000N53922ZY
Firmware Revision = 0730000B

SL ticket number:CS2357710

8:14     13 UBad   -       0 KB SAS  HDD N   N  512B ST3600057SS         U



CHG0207570  TTA change	tsls4proddbdr
rpm -q libgcc_s1 libstdc++6 libatomic1


tslbwprdhdbdr:/home/ibmrmalik1 # zypper repos
Repository priorities are without effect. All enabled repositories share the same priority.

# | Alias                                                                                       | Name                                        | Enabled | GPG Check | Refresh
--+---------------------------------------------------------------------------------------------+---------------------------------------------+---------+-----------+--------
1 | SLES12-SP4-12.4-0                                                                           | SLES12-SP4-12.4-0                           | No      | ----      | ----
2 | SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local:SLES12-SP4-Installer-Updates                | SLES12-SP4-Installer-Updates                | No      | ----      | ----
3 | SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local:SLES12-SP4-Pool                             | SLES12-SP4-Pool                             | Yes     | (r ) Yes  | No
4 | SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local:SLES12-SP4-Updates                          | SLES12-SP4-Updates                          | Yes     | (r ) Yes  | Yes
5 | SMT-http_che01ammsmt01_imzcloud_ibmammsap_local:SLE-Module-Adv-Systems-Management12-Pool    | SLE-Module-Adv-Systems-Management12-Pool    | Yes     | (r ) Yes  | No
6 | SMT-http_che01ammsmt01_imzcloud_ibmammsap_local:SLE-Module-Adv-Systems-Management12-Updates | SLE-Module-Adv-Systems-Management12-Updates | Yes     | (r ) Yes  | No
7 | SMT-http_che01ammsmt01_imzcloud_ibmammsap_local:SLE-SDK12-SP4-Updates                       | SLE-SDK12-SP4-Updates                       | Yes     | (r ) Yes  | No




libgtk-2_0-0-2.24.31-7.11.x86_64
libgtksourceview-3_0-1-3.20.4-5.3.x86_64
libgtkmm-3_0-1-3.20.1-4.3.x86_64


tsls4proddbdr:/tmp # rpm -ivh libgtkmm-3_0-1-3.20.1-4.3.x86_64.rpm
 libatkmm-1.6.so.1()(64bit) is needed by libgtkmm-3_0-1-3.20.1-4.3.x86_64
        libcairomm-1.0.so.1()(64bit) is needed by libgtkmm-3_0-1-3.20.1-4.3.x86_64
        libgiomm-2.4.so.1()(64bit) is needed by libgtkmm-3_0-1-3.20.1-4.3.x86_64
        libglibmm-2.4.so.1()(64bit) is needed by libgtkmm-3_0-1-3.20.1-4.3.x86_64
        libpangomm-1.4.so.1()(64bit) is needed by libgtkmm-3_0-1-3.20.1-4.3.x86_64
        libsigc-2.0.so.0()(64bit) is needed by libgtkmm-3_0-1-3.20.1-4.3.x86_64
tsls4proddbdr:/tmp # rpm -ivh libgtk-2_0-0-2.24.31-9.6.28.x86_64.rpm
error: Failed dependencies:
        gtk2-tools >= 2.24.20 is needed by libgtk-2_0-0-2.24.31-9.6.28.x86_64


libgtk-x11-2.0.so.0()(64bit) is needed by gtk2-tools-2.24.31-9.6.28.x86_64
tsls4proddbdr:/tmp # rpm -ivh libpangomm-1_4-1-2.40.1-7.2.x86_64.rpm
error: Failed dependencies:
        libcairomm-1.0.so.1()(64bit) is needed by libpangomm-1_4-1-2.40.1-7.2.x86_64
        libglibmm-2.4.so.1()(64bit) is needed by libpangomm-1_4-1-2.40.1-7.2.x86_64



CS7349848 P2 - MajorHAVI Logistics -- HAVLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 37.31 (thresh: 30)
CS7349985 P2 - MajorPanasonic North America -- PN4LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 20.31 (thresh: 20)
CS7350625 P2 - MajorPanasonic North America -- PN4LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 20.41 (thresh: 20)
CS7349471 P2 - MajorPanasonic North America -- PN8Memory Swap CRITICAL: Swap free 49.59% (thresh 50:%
CS7348843 P2 - MajorPanasonic North America -- PN8Memory Swap CRITICAL: Swap free 49.88% (thresh 50:%)
CS7350053 P2 - MajorPanasonic North America -- PN4LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 20.38 (thresh: 20)
CS7350092 P2 - MajorPanasonic North America -- PN8Memory Swap CRITICAL: Swap free 49.87% (thresh 50:%)
CS7350578 P2 - MajorTecnologia De Materiales S.A. -- TDMMemory Swap CRITICAL: Swap free 49.93% (thresh 50:%)



//svtd1srv1/AFP /sftp/dev/opentext/ cifs _netdev,username=fileshare,password=Welcome-1,file_mode=0777,uid=otxdev,gid=sftp,dir_mode=0777 0 0
//10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/ /usr/sap/OpenText/STRS_Output/OfficialReceipt cifs username=sftp,passwd=Security#1
#//10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/SOA_DIVISION/ /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
//10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/ /usr/sap/OpenText/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//10.70.110.25/SOA_DIVISION/ /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
//10.70.110.25/STRS_Spool/  /usr/sap/OpenText_QA/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0
//10.70.110.25/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//SVTQ1SRV1/STRS_Output/SOA_DIVISION    /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0


svts1srv1	10.6.1.149	10.92.99.149

Destination SVMQ1SRV1	10.6.2.42	10.70.110.42	

//10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/                                    50G 32G 18G 65% /usr/sap/OpenText/STRS_Output/OfficialReceipt
/10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/SOA DIVISION/       50G 32G 18G 65% /usr/sap/OpenText/STRS_Output/SOA_DIVISION
//10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/                                    50G      	                     


//SVTS1SRV1/STRS_Output		/usr/sap/OpenText/STRS_Output/OfficialReceipt
\\SVTS1SRV1/STRS_Output/SOA_DIVISION	/usr/sap/OpenText/STRS_Output/SOA_DIVISION
\\SVTS1SRV1/STRS_Output		/usr/sap/OpenText/STRS_Output/SOA_STORE

 
\\SVTS1SRV1\STRS_Output 



/usr/sap/OpenText/STRS_Output/OfficialReceipt

/usr/sap/OpenText/STRS_Output/SOA_DIVISION

/usr/sap/OpenText/STRS_Output/SOA_STORE



TSLEECQA - (IFN: 10.207.63.14)



FIRST1021


TATA Change	CTASK0397473	CHG0207583
1 Starting the pacemaker service only on Primary node (tsls4proddbh)

2 Starting the pacemaker service on Secondary node (tsls4proddb).

3 Putting the cluster back to managed mode.






CHG0200424
Update SUSE Linux 12 SP2 to SP4
Scheduled - 06-20-2021 08:30 AM IST - 06-20-2021 16:30 IST
7:27 AM
1- The cluster configuration backup taken to /home/ibmsu/ directory.
2 - Cluster validation script - /home/ibmsu/pacemaker_validation/run_pacemaker_validation.py

PE1	hfcpe1app1	- 10.191.16.16 - Production app server
PE1	hfcpe1app1ha  -	10.191.16.111 - Production app server HA

VP1        hfcvp1app - 10.211.12.20 - Production Vertex server

PR1   hfcpr1app1  - 10.191.16.61 - Production app server
PR1   hfcpr1app1ha - 10.191.16.38 - Production app server HA
PR1   hfcpr1app2  - 10.191.16.56 - Production app server

HEP	hfchepapp1	- 10.191.16.23 - Production app server
HEP	hfchepapp1ha  - 10.191.16.30 - Production app server HA
HEP	hfchepapp2	- 10.191.16.11 - Production app server

HBP	hfchbpapp1	- 10.191.16.12 - Production app server
HBP	hfchbpapp1ha  -	10.191.16.35 - Production app server HA

POP	hfcpopapp1	- 10.191.16.96 - Process Orchesration production app server
POP	hfcpopdb1	- 10.191.16.86 - Process Orchesration production database server
POP	hfcpopdb1ha	- 10.191.16.121 - Process Orchesration production database server HA

BBP	hfcbbpsydb1	- 10.191.16.21 - BillerDirect Production database server
BBP	hfcbbpsydb1ha - 10.191.16.19 - - BillerDirect Production database server
BBP	hfcbbpapp1	- 10.191.16.22 - BillerDirect Production app server
BBP	hfcbbpapp1ha  - 10.191.16.33 - - BillerDirect Production app server HA

BOP	hfcbopsydb1	- 10.191.16.66 - BOBJ Production database server
BOP	hfcbopapp1	- 10.191.16.51 - BOBJ Production app server



PE1+HEP  Deepshree
VP1+BBP  KK
PR1+BOP  Ravi
HBP+POP  Sreejesh


PR1+BOP  Ravi	Dal13

PR1   hfcpr1app1  - 10.191.16.61 - Production app server
PR1   hfcpr1app1ha - 10.191.16.38 - Production app server HA
PR1   hfcpr1app2  - 10.191.16.56 - Production app server

BOP	hfcbopsydb1	- 10.191.16.66 - BOBJ Production database server
BOP	hfcbopapp1	- 10.191.16.51 - BOBJ Production app server



chmod 755 prechecks.sh

primitive rsc_sap_PR1_ERS04 SAPInstance \
        operations $id=rsc_sap_PR1_ERS04-operations \
        op start interval=0 timeout=240 \
        op stop interval=0 timeout=240 \
        op monitor interval=11s timeout=120s \
        params AUTOMATIC_RECOVER=false InstanceName=PR1_ERS04_hfc-pr1-ers START_PROFILE="/usr/sap/PR1/SYS/profile/PR1_ERS04_hfc-pr1-ers" IS_ERS=true \

Downloads 20/6/21  

ers		HA
ascs		app



svts1srv1	10.6.1.149	10.92.99.149

svts1srv1	10.6.1.149	10.92.99.149 - TS1
SVES1SRV0	10.6.1.139	10.92.99.139 - ES1


CS7447686 P2 - MajorAlpro Comm. VA -- APRResources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped
CS7445244 P2 - MajorAlpro Comm. VA -- APRLog PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-06-24-17-56-50 for details.
CS7447687 P2 - MajorAlpro Comm. VA -- APRResources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped
CS7450677 P2 - MajorAlpro Comm. VA -- APRResources DRBD CRITICAL: Role value Unknown found for resource r1 on host aprpiprdd


CS7449592 P2 - MajorTata Steel Limited -- TTAInodes Utilization /sapmnt/log /usr/local/ncpa/plugins/cmas_check_inodesfree.sh: fork: retry: No child processes
CS7450746 P2 - MajorTata Steel Limited -- TTAInodes Utilization /sapmnt/log /usr/local/ncpa/plugins/cmas_check_inodesfree.sh: fork: retry: No child processes
CS7450776 P2 - MajorTata Steel Limited -- TTADisk Utilization /sapmnt/log CRITICAL: /usr/local/ncpa/etc/cmas_ksh_functions.sh: fork: retry: No child processes
CS7450420 P2 - MajorTata Steel Limited -- TTAInodes Utilization /sapmnt/log /usr/local/ncpa/plugins/cmas_check_inodesfree.sh: fork: retry: No child processes


svts1srv1	10.6.1.149	10.92.99.149


svts1srv1	10.6.1.149	10.92.99.149 - TS1
SVES1SRV0	10.6.1.139	10.92.99.139 - ES1


CS7453132


CS7462768 - Issues with hfcxhfhndb1 - cannot log in - Access Denied
https://scc.suse.com/support/cases/00304412
hfcxhfhndb1 - 10.92.9.77

Support Cases keyboard_arrow_right 00304421  https://scc.suse.com/support/cases/00304421



CS7468070 P2 - MajorTecnologia De Materiales S.A. -- TDMMemory Swap CRITICAL: Swap free 49.88% (thresh 50:%)	comments updated move to SAP
CS7466222 P2 - MajorPanasonic North America -- PN8Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)		comments updated move to SAP
CS7468728 P2 - MajorPanasonic North America -- PN8Memory Swap CRITICAL: Swap free 49.99% (thresh 50:%)
CS7469346 P2 - MajorPanasonic North America -- PN8Memory Swap CRITICAL: Swap free 49.92% (thresh 50:%)
CS7468055 P2 - MajorPanasonic North America -- PN8Memory Swap CRITICAL: Swap free 49.82% (thresh 50:%)
CS7468741 P2 - MajorPanasonic North America -- PN4LoadAvgNew 15 Minute Load AvgNew CRITICAL: 15-Minute LoadavgNew 20.96 (thresh: 20)
CS7465796 P2 - MajorCelestica International Inc. -- CLCMemory Swap CRITICAL: Swap free 0.93% (thresh 50:%)
CS7448952 P2 - MajorTokyo Seimitsu Co., Ltd. -- TSMMemory Swap CRITICAL: Swap free 49.93% (thresh 50:%)		comments updated move to SAP	
CS7470964 P2 - MajorIAG GBS Limited -- IA1Disk Utilization /var CRITICAL: Free 418.36MB/8.98% (thresh @5.01:10%

CS7466201 P3 - MinorTAQA Arabia -- TQADisk Utilization /var/log MINOR: Free 340.38MB/18.15% (thresh @10.01:19%)
CS7467568 P3 - MinorConcessionaria Aeroporto Rio de Jan -- CONDisk Utilization /var MINOR: Free 848.23MB/18.21% (thresh @10.01:19%)
CS7467285 P3 - MinorArnoldo Mondadori Editore SpA -- ARMDisk Utilization /var/log MINOR: Free 355.63MB/18.96% (thresh @10.01:19%) (edited) 

CS7471076 P1 - SevereIAG GBS Limited -- IA1Disk Utilization /var FATAL: Free 157.74MB/3.39% (thresh @0:5%)



CHG0209980
sveq1srv0	10.6.2.11	A0EASG014XVM001
sveq1srv0	10.6.2.11	A0EASG014XVM001
svcq1srv0	10.6.2.16	A0EASG014XVM017



asdprddb-dr.asd.imzcloud.ibmammsap.local	done	
bs4pb0077-dr.bs4.imzcloud.ibmammsap.local	
agehvbpphsrv1.age.imzcloud.ibmammsap.local	
agehvepmhsrv1.age.imzcloud.ibmammsap.local	
agehvcpmhsrv1.age.imzcloud.ibmammsap.local	
tdpdcprdhdb.tdp.imzcloud.ibmammsap.local	
tdpdcprdap2.tdp.imzcloud.ibmammsap.local	
tdpdcprdap1.tdp.imzcloud.ibmammsap.local	
armfksap209.arm.imzcloud.ibmammsap.local	




CS7537102 Concessionaria Aeroporto Rio de Jan -- CONInodes Utilization /var MINOR: Free 48672/328000 14.84% (thresh @10.01:15%)P3 - Minor CONSPBW4HAPD SQ-SAP-TRIO-B1
CS7537091 Concessionaria Aeroporto Rio de Jan -- CONInodes Utilization /var MINOR: Free 46595/328000 14.21% (thresh @10.01:15%)P3 - Minor CONSPECCAPQ SQ-SAP-TRIO-B1
CS7537019 Concessionaria Aeroporto Rio de Jan -- CONInodes Utilization /var MINOR: Free 47031/328000 14.34% (thresh @10.01:15%)P3 - Minor CONSPTDFAPD SQ-SAP-TRIO-B1
CS7536796 Concessionaria Aeroporto Rio de Jan -- CONInodes Utilization /var MINOR: Free 47691/328000 14.54% (thresh @10.01:15%)P3 - Minor CONSPGWAPD SQ-SAP-TRIO-B1(e
CS7536685 Concessionaria Aeroporto Rio de Jan -- CONDisk Utilization /var MINOR: Free 881.56MB/18.92% (thresh @10.01:19%)P3 - Minor CONSPTDFAPD SQ-SAP-TRIO-B1





Change mountpoint mount point for IP address 10.70.110.25 (old OpenText QAS server) to 10.92.99.127 (new OpenText QAS server) in EQ1/RQ1 server(10.70.110.11)	sveq1srv0 (10.6.2.11)
SVTQ1SRV1	10.6.2.25	10.70.110.25 to   SVTD1SRV1 	10.6.1.28 	10.92.99.127
Directories /usr/sap/OpenText/STRS_Spool and /usr/sap/OpenText/STRS_Output/* should be mounted to 10.92.99.127 Server

 

2.      Change mountpoint from 10.70.110.25 to 10.92.99.127 in server 10.70.110.42 (sftp dev/qas). 
SVTQ1SRV1	10.6.2.25	10.70.110.25 to   SVTD1SRV1 	10.6.1.28 	10.92.99.127	 in SVMQ1SRV1	10.6.2.42	10.70.110.42

svts1srv1	10.6.1.149	10.92.99.149

Destination SVMQ1SRV1	10.6.2.42	10.70.110.42	

//10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/                                    50G 32G 18G 65% /usr/sap/OpenText/STRS_Output/OfficialReceipt
/10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/SOA DIVISION/       50G 32G 18G 65% /usr/sap/OpenText/STRS_Output/SOA_DIVISION
//10.92.99.127/OPENTEXT/STREAMSERVE/DATA/STRS_OUTPUT/              





\\SVTD1SRV1\STRS_Spool

\\SVTD1SRV1\STRS_Output




//SVTD1SRV1/STRS_Spool    /usr/sap/OpenText/STRS_Spool   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//SVTD1SRV1/STRS_Output    /usr/sap/OpenText/STRS_Output   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0



//10.92.99.127/STRS_Output/ /usr/sap/OpenText/STRS_Output cifs username=msgteam,password=Welcome@123 0 0
//10.92.99.127/STRS_Spool/ /usr/sap/OpenText/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0


10.92.99.127    SVTD1SRV1.eastwestageaslife.com SVTD1SRV1 svtd1srv0.eastwestageaslife.com svtd1srv0


//SVTD1SRV1/STRS_Spool    /usr/sap/OpenText/STRS_Spool   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//SVTD1SRV1/STRS_Output/SOA_DIVISION    /usr/sap/OpenText/STRS_Output/SOA_DIVISION   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//SVTD1SRV1/soa_store    /usr/sap/OpenText/STRS_Output/SOA_STORE   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//SVTD1SRV1/STRS_Output    /usr/sap/OpenText/STRS_Output   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
[root@sveq1srv0 ~]#


-----------------------------------------------------------------------------------------------------
[root@sveq1srv0 SOA_DIVISION]# df -hT |grep -i cifs
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText/STRS_Spool
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText/STRS_Output/SOA_DIVISION
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText/STRS_Output
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText/STRS_Output/SOA_STORE



[root@svmq1srv1 OpenText]# df -hT |grep -i cifs
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION
                     cifs   260G   68G  193G  26% /usr/sap/OpenText/STRS_Output/SOA_STORE
                     cifs   260G   68G  193G  26% /usr/sap/OpenText/STRS_Output/OfficialReceipt
                     cifs   260G   68G  193G  26% /usr/sap/OpenText/STRS_Output/SOA_DIVISION
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText_QA/STRS_Spool
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText_QA/STRS_Output/SOA_STORE
                     cifs    50G  4.9G   45G  10% /usr/sap/OpenText_QA/STRS_Output

--------------------------------------------------------------------------------------------------------





[root@svmq1srv1 OpenText]# cat /etc/fstab |grep -i cifs
//svtd1srv1/AFP /sftp/dev/opentext/ cifs _netdev,username=fileshare,password=Welcome-1,file_mode=0777,uid=otxdev,gid=sftp,dir_mode=0777 0 0
//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/OfficialReceipt cifs username=sftp,passwd=Security#1
//10.92.99.149/STRS_Output/SOA_DIVISION /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/SOA_DIVISION/ /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/STRS_Spool/  /usr/sap/OpenText_QA/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//SVTQ1SRV1/STRS_Output/SOA_DIVISION    /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//10.92.99.127/STRS_Output/ /usr/sap/OpenText/STRS_Output cifs username=msgteam,password=Welcome@123 0 0
//10.92.99.127/STRS_Spool/ /usr/sap/OpenText/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0


//SVTD1SRV1/STRS_Spool    /usr/sap/OpenText/STRS_Spool   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//SVTD1SRV1/STRS_Output/SOA_DIVISION    /usr/sap/OpenText/STRS_Output/SOA_DIVISION   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//SVTD1SRV1/STRS_Output/SOA_STORE    /usr/sap/OpenText/STRS_Output/SOA_STORE   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//SVTD1SRV1/STRS_Output    /usr/sap/OpenText/STRS_Output   cifs  _netdev,username=cd1adm,password=xStream2015!,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0


//SVTD1SRV1/STRS_Output/SOA_DIVISION /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Spool  /usr/sap/OpenText_QA/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output	/usr/sap/OpenText_QA/STRS_Output cifs username=msgteam,password=Welcome@123 0 0


uid=908(rd1adm) gid=504(sapsys)

uid=908,gid=504


CS7537416 Meggitt PLC -- MGGP2 - MajorLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 47.46 (thresh: 30)MGGGBJVECCX01 SQ-SAP-TRIO-B1
CS7537240 Meggitt PLC -- MGGP2 - MajorLoadAverageCustom Custom 15 Min Load Avg CRITICAL: Fail count is 3: 15-Minute Loadavg 82.93 (thresh: 30)MGGGBJVECCX09 SQ-SAP-TRIO-B1 (edited) 



CS7555266	System MegaRAID Offline or degraded CRITICAL: [See KB0015294] 0 - - - - RAID5 Dgrd N 4.362 TB dsbl N N dflt N 0 0 - - - RAID5 Dgrd N 4.362 TB dsbl N N dflt N 0/
10.164.238.144	lonhana-1024-36.xsportal.local
number:CS2377345


ppldcprdccdb	CS7567177	PEPPPL (ABAP)|ABAP_SYSTEM_AVAILABILITY|ABAP System not available
SL case number:CS2379415  and  CS2379485 for DIMM error
internal SuSE TS006072480
External SuSE vendor 0305088 	
 10.162.24.235	ple-che01-pod1-phana-h2-3000-01.imzcloud.ibmammsap.local

ipmi gKgUSAHy28
10.162.24.238
ppldcprdccdb:/home/ibmrmalik1 # cat /var/log/messages |grep -i taint
Jul  2 07:55:40 ppldcprdccdb kernel: [   25.193399] tmhook: loading out-of-tree module taints kernel.
Jul  2 07:55:40 ppldcprdccdb kernel: [   25.193451] tmhook: module verification failed: signature and/or required key missing - tainting kernel

07:55:38 AM  LINUX RESTART




CS7677014 Panasonic North America -- PN8Disk Utilization /var/log MINOR: Free 2505.85MB/18.88% (thresh @10.01:19%)P3 - MinorPN8US7LAP1P4 SQ-SAP-TRIO-B1
CS7677455 Panasonic North America -- PN8Disk Utilization /var/log MINOR: Free 2333.64MB/18.97% (thresh @10.01:19%)P3 - MinorPN8US7LAP2P4 SQ-SAP-TRIO-B1




QE1 hfcqe1app1 - IFN: 10.92.9.48 , CFN: 10.28.25.89 - QA app server


[root@da7bwpapp01 ~]# mount /wmshare ; df -h /wmshare
Filesystem Size Used Avail Use% Mounted on
//dannapsta010lrs.file.core.windows.net/p-webmethods/sapfiletransfer 1.5T 68G 1.5T 5% /wmshare


CS7736958 P3 - MinorTorrent Gas Pvt Limited -- TGPCheck OS level monitoring alert is generating , host : tgps4hdevdb
CS7740169 P3 - MinorDelta Airlines -- DALDelta IP address CFN 10.250.17.7 & 10.250.17.8 not accessible


CS7766827
Request to create new FS  as /oracle/DIP/19.0.0  permanently and allocate 50GB for /oracle/DIP/19.0.0 mount point on the server SAPCRMDI - 10.207.61.83
diparchvg    1   3   0 wz--n- 128.00g 98.94g
oracle_DIP_v19_lv

lvcreate -L 50G -n oracle_DIP_v19_lv diparchvg

[root@sapcrmdi ibmrmalik1]$ lvdisplay |grep -i oracle_DIP_v19_lv
  LV Path                /dev/diparchvg/oracle_DIP_v19_lv
  LV Name                oracle_DIP_v19_lv

[root@sapcrmdi ibmrmalik1]$ df -hT /oracle/DIP/19.0.0
Filesystem                              Type  Size  Used Avail Use% Mounted on
/dev/mapper/diparchvg-oracle_DIP_v19_lv ext4   49G   53M   47G   1% /oracle/DIP/19.0.0


Need to add additional 20GB space for the mount point  for the FS  -  /sapstage
/dev/mapper/dipappvg-sapstage_lv                 4.8G  477M  4.1G  11% /sapstage


Need to add additional 5GB space for the FS  -  /oracle/stage
/dev/mapper/dipappvg-oracle_stage_lv              12G  5.8G  5.4G  52% /oracle/stage







mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab




CS7768856
Can you check the FS of below servers? Customer is not able to access /share FS.
10.73.10.27
10.73.10.28


CS7835584  SNOW
Exteral  =  00306976
Internal  = TS006225078


Upcoming changes
CHG0211337 and CHG0211422



CS7839737 CMA CGM -- CMAFile system creation in DX8 system

CS7840195 P3 - MinorCoca Cola Amatil -- Z3V/archive filesystem for QAR is owned by root:system so InfoSys not able to test archiving on the system.



CS7852656 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-21-08-38-31 for details.
CS7852655 P2 APRERPPRDD Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprerpprdd-ha(stonith:fence_vmware_soap):Stopped
CS7852658 P2 APRERPPRDD-HA Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprerpprdd-ha(stonith:fence_vmware_soap):Stopped
CS7852696 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-21-08-48-03 for details. 



CS7852920 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-21-09-08-05 for details.



CHG0211337	22-07-2021 07:00:00	22-07-2021 13:00:00	TOK02-SL	
Upgrade of SUSE HANA servers from 12SP02 to 12SP03 on the Dev Systems. 
Server impacted
Host Name             IFN IP       Asset Purpose   SID
jp0811zbe2005     10.216.15.34	  Dev            HD1 S4 HANA App QA
jp0811zbe200e	  10.216.15.71	  Dev            HD1 S4 HANA DB		10.129.214.24	tok02-pod1-4tb-host07.imzcloud.ibmammsap.local
tsmwddev01	  10.216.15.75	  Dev            WD1

Amarnath Naik Balya Jayaram




communication post change
To: junpei.t@accretech.jp
CC: E23462@jp.ibm.com, HIDETOW@jp.ibm.com, HidetoWatanabe@b03ledav005.gho.boulder.ibm.com, kamiokata@accretech.jp, Toshikazu__Katoh@b03ledav005.gho.boulder.ibm.com, Amarnath Jayaram <amajayar@in.ibm.com>,msingh93@in.ibm.com




CHG0211626	TOK	22-07-2021 09:00:00	22-07-2021 14:00:00
 Upgrade SUSE Linux servers from 12 SP2 to 12 SP4 for below servers

Current OS version:
SUSE Linux Enterprise Server for SAP Applications 12 SP2
Target version:
SUSE Linux Enterprise Server for SAP Applications 12 SP4

[Server]
HOSTNAME	OS					CFN IP			IFN IP			SID	Description
-------------------	------------------------	------------------	-------------------	--------	------------------------------------
TBOSMABAP	SUSE 12 SP2 12.2	10.69.20.18	100.126.48.17	J1S	SOLMAN + SAP Router
TBOSMJAVA	SUSE 12 SP2 12.2	10.69.20.15	100.126.48.16	J2S	SOLMAN



S02	Oracle 12.1.0.2	zffsappdb001	100.126.67.20

printer queue 
IP                Name:
10.548.9.68   PBREFR_PZ16

lpadmin -p PBREFR_PZ16 -v socket://10.548.9.68 -E


CS7865039 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-22-09-40-41 for details.
CS7865037 P2 APRERPPRDD Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprerpprdd-ha(stonith:fence_vmware_soap):Stopped
CS7865045 P2 APRERPPRDD-HA Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprerpprdd-ha(stonith:fence_vmware_soap):Stopped

CS7865287 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-22-10-05-42 for details.
CS7865289 P2 APRERPPRDD-HA Alpro Comm. VA Log PaceMaker-crmd Found 22 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-22-10-05-58 for details.
CS7865290 P2 APRERPPRDD-HA Alpro Comm. VA Log PaceMaker-stonith-ng Found 91 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-22-10-05-58 for details.

CS7865412 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 6 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-22-10-20-42 for details.
CS7865451 P2 APRERPPRDD-HA Alpro Comm. VA Log PaceMaker-crmd Found 22 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-22-10-26-03 for details.



CHG0211422	TOK	23-07-2021 07:00:00	23-07-2021 15:00:00
Upgrade of SUSE HANA servers from 12SP02 to 12SP03 on the Dev Systems. 
Server impacted
Host Name	  IFN IP	Asset Purpose   SID
jpzetftpq01	10.216.15.36	              No SAP running
tsmwdqas01	10.216.15.16	      Quality        WQ1
jp0811zbe2010	10.216.15.79	Quality        HQ1 S4 HANA App QA 
jp0811zbe2015	10.216.15.8	Quality        HQ1 S4 HANA DB
jp0811zbe2014	10.216.15.6	Quality        HM1 MDC (HM1) Tenant (BD1,BQ1)

To: junpei.t@accretech.jp
CC: E23462@jp.ibm.com, HIDETOW@jp.ibm.com, HidetoWatanabe@b03ledav005.gho.boulder.ibm.com, kamiokata@accretech.jp, Toshikazu__Katoh@b03ledav005.gho.boulder.ibm.com, Amarnath Jayaram <amajayar@in.ibm.com>,msingh93@in.ibm.com,	Inbasekaran Karthikeyan



CS7876777 P1 - SevereMeggitt PLC -- MGGHost Reboot CRITICAL: Uptime 1 minutes (thresh 60 min
[root@MGGGBJVECCX01 ibmrmalik1]$ last reboot
reboot   system boot  2.6.32-754.35.1. Fri Jul 23 05:11 - 05:58  (00:47)

494  2021-07-23 05:00:25 more /etc/fstab
  495  2021-07-23 05:00:29 reboot


[root@MGGGBJVECCX01 log]$ egrep -i '(shut|reboot)' messages
Jul 23 04:51:20 MGGGBJVECCX01 SAPEVT_32[64696]: Q41 Monitoring: Snapshot 4 created; reason: Hard Shutdown
Jul 23 05:00:30 MGGGBJVECCX01 oddjobd: oddjobd shutdown succeeded

[root@MGGGBJVECCX01 log]$ /usr/bin/last -xF | egrep "reboot|shutdown|runlevel|system"
runlevel (to lvl 3)   2.6.32-754.35.1. Fri Jul 23 05:11:03 2021 - Fri Jul 23 06:00:58 2021  (00:49)
reboot   system boot  2.6.32-754.35.1. Fri Jul 23 05:11:03 2021 - Fri Jul 23 06:00:58 2021  (00:49)
shutdown system down  2.6.32-754.35.1. Fri Jul 23 05:07:06 2021 - Fri Jul 23 05:11:03 2021  (00:03)
runlevel (to lvl 6)   2.6.32-754.35.1. Fri Jul 23 05:00:30 2021 - Fri Jul 23 05:07:06 2021  (00:06)




CS7877306 P2 APRPIPRDD Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped (Monitoring)
CS7877308 P2 APRPIPRDD-HA Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprpiprdd-ha(stonith:fence_vmware_soap):Stopped (Monitoring)



CS7889215 P2 - MajorZF Friedrichshafen AG -- ZFFCPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=93.50% system=6.50% iowait=0.00% idle=0.00%
CS7889404 P2 - MajorTecnologia De Materiales S.A. -- TDMMemory Swap CRITICAL: Swap free 49.35% (thresh 50:%)
CS7889455 P3 - MinorCoca Cola Amatil -- Z3VDisk Utilization /audit MINOR: Free 76.76MB/14.99% (thresh @10.01:15%)
CS7889861 P3 - MinorIAG GBS Limited -- IA1Disk Utilization /var MINOR: Free 886.23MB/18.99% (thresh @10.01:19%)


ti3s4qdb02, ti3s4ddb02



CS7969613 COTY Inc. -- CTUP2 - MajorPing Availability CRITICAL - 10.12.10.147: rta nan. lost 100% Attention commas replaced by dots.CTUBWQB3AP02 SQ-SAP-TRIO-B1
CS7969614 COTY Inc. -- CTUP2 - MajorPing Availability CRITICAL - 10.12.10.146: rta nan. lost 100% Attention commas replaced by dots.CTUBWQB3AP04 SQ-SAP-TRIO-B1
CS7969471 COTY Inc. -- CTUP2 - MajorPing Availability CRITICAL - 10.12.10.148: rta nan. lost 100% Attention commas replaced by dots.CTUBWQB3AP03 SQ-SAP-TRIO-B1
CS7969612 COTY Inc. -- CTUP2 - MajorPing Availability CRITICAL - 10.12.10.140: rta nan. lost 100% Attention commas replaced by dots.CTUBWQB0AP01 SQ-SAP-TRIO-B1
CS7969618 COTY Inc. -- CTUP2 - MajorPing Availability CRITICAL - 10.12.10.39: rta nan. lost 100% Attention commas replaced by dots.CTUWTSPRAP01 SQ-SAP-TRIO-B1



CHG0213481	30-07-2021 06:30:00	30-07-2021 14:30:00
Upgrade SUSE LINUX Server to SLES 12 SP4

SID	         Purpose                       HostName		IFN IP		
-----                ------------------------       --------------         ------------
CCD               Cloud connector Dev   grpccdap01     10.6.80.8
 S4P                  S/4 HANA Prod           grps4pap01          10.6.70.6
CCP                 Cloud connector Prod     grpccpap01        10.6.70.45
WDP                Web Dispatcher Prod     grpwdpap01      10.6.70.10




install driver for these printers in ecctest.tatasteel.co.in
Define queue for each of them (same as their hostname) and Maintain host name and IP in host file of ecctest.tatasteel.co.in server (10.170.63.25)

INVOICE PRINTER DETAILS CDC#1
Product Name:                 HP LaserJet E60065
Model Number:                M0P35A
Product Serial Number:  CNM8L8H4SK
Drivers Name:
Host Name:                       NPIB7165F
IP Address:                         133.0.13.21		NPIB7165F


LR PRINTER DETAILS CDC#1
Product Name:                 HP LaserJet P3015
Model Number:                CE528A
Product Serial Number:  VNF3R15432
Drivers Name:
Host Name:                       JSSWLJ1981
IP Address:                         133.0.13.17		JSSWLJ1981


TC PRINTER DETAILS CDC#1
Product Name:                 HP LaserJet P3015
Model Number:                CE528A
Product Serial Number:  VNF3R16117
Drivers Name:                  

Printer Name:                   CDCTC
Host Name:                       JSSWLJ1980
IP Address:                         133.0.13.16		JSSWLJ1980



lpadmin -x <queue name>   to delete a queue
# lpadmin -p JSSWLJ1980 -v socket://133.0.13.16 -E    to create a new print queue where -p is the queue name and -v is the ip 
alternatively use
lpadmin -p 922_ -v socket://149.223.90.58:9600 -E     this is with specific port 9600
# cupsaccept  922_SUNGB_ADB_P002    to start accepting the prints to this queue

lpstat -a  printers installed



CS8028464 P2 APRERPPRDD-HA Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprerpprdd-ha(stonith:fence_vmware_soap):Stopped
CS8028462 P2 APRERPPRDD Alpro Comm. VA Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-aprerpprdd-ha(stonith:fence_vmware_soap):Stopped
CS8028461 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-31-12-41-16 for details.

CS8028592 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-31-12-54-15 for details.

CS8028710 P2 APRERPPRDD Alpro Comm. VA Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-07-31-13-04-16 for details.



PROD- LON02
DR - FRA-02

 No storage is found for datastore path '[IA1FRA02BCB58DR] ia2s4hprdapp3/hbrdisk.RDID-7edd7a4e-e69d-43b5-a2f9-4118707de731.16775720.104178797419979.vmdk'.

	ia2s4hprdapp1	8IVEFpG;Ug+ABNz	
	ia2s4hprdapp2	9xtY[iMIwVF]PVE	
	ia2s4hprdapp3	L!5B%TLIXTXEe7D	
	ia2s4hprdapp4	MtyM|Ula8ltO|ia
	ia2mdgprdapp	
IA1S4HPRDAPP	RP1 Recovery failed because the Virtual Machine is no longer configured for replication.



https://eisweb.persistent.co.in/eis/login.aspx?url=/eis/TMS/WebUI/Reports/UserReports/CoursesAttended.aspx

	

 install driver for printer listed below in ecctest.tatasteel.co.in server.

INVOICE PRINTER  DETAILS CDC#2
Asset ID
JSSWLJ1984
Product Name:
HP LaserJet P3010
Model Number:
CE52BA
Product Serial Number:
VNF3R16132
Drivers Name:

Printer Name:
CDCIN
Host Name:
NP115F246
IP Address:
154.0.16.97
LR PRINTER  DETAILS CDC#2
Asset ID
JSSWLJ1983
Product Name:
HP LaserJet P3010
Model Number:
CE528A
Product Serial Number:
VNF3R16125
Drivers Name:

Printer Name:
CDCLR
Host Name:
NP115F221
IP Address:
154.0.16.98




CS8130585

Source system :
10.207.62.24 /GRCDEVNEW  -  
Mount point : / unicode

[root@grcdevnew unicode]$ df -h /unicode/
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/grdunicodevg-unicode_lv  492G  166G  301G  36% /unicode


Target system:
10.207.62.29/ttagrcdev
Mount point - /unicode


lpadmin -p NPI452EF5 -v socket://135.21.31.175 -E



F:\OpenText\Streamserve\Data\STRS_Output

STRS_Output (file://AGESVTP2SRV1/STRS_Output)

STRS_Spool (file://AGESVTP2SRV1/STRS_Spool)

SOA_STORE (file://AGESVTP2SRV1/STRS_Output/SOA_STORE)

SOA_DIVISION (file://AGESVTP2SRV1/STRS_Output/SOA_DIVISION)

OpenText (file://AGESVTP2SRV1/OpenText)

AFP (file://AGESVTP2SRV1/STRS_Output/AFP)







EPP - Production ERP Application	spsvepaeapp01	10.6.3.12
RPP - Production ERP Application	spsvepaeapp01	10.6.3.12
CPP - Production CRM ABAP		spsvcpacapp01	10.6.3.15

August@2021_Ageas

Welcome-1

//AGESVTP2SRV1/STRS_Output     /usr/sap/OpenText/STRS_output   cifs    username=admtmp,password=August@2021_Ageas,dir_mode=0777,file_mode=0777 0 0

//AGESVTP2SRV1/STRS_Output
                     cifs   259G   52G  208G  20% /usr/sap/OpenText/STRS_output
[root@spsvepaeapp01 ~]# cd /usr/sap/OpenText/STRS_output
[root@spsvepaeapp01 STRS_output]# ls -ltr
total 0
drwxr-xr-x. 2 root root 0 Aug  7 14:21 AFP

[root@spsvcpacapp01 STRS_output]$ df -hT /usr/sap/OpenText/STRS_output
Filesystem           Type  Size  Used Avail Use% Mounted on
//AGESVTP2SRV1/STRS_Output
                     cifs  259G   52G  207G  21% /usr/sap/OpenText/STRS_output




mount.cifs -o username=admtmp,password=August@2021_Ageas //AGESVTP2SRV1/STRS_Output/SOA_DIVISION  /usr/sap/OpenText/STRS_Output/SOA_DIVISION

mount.cifs -o username=admtmp,password=August@2021_Ageas //AGESVTP2SRV1/AFP /sftp/prd/OpenText


//AGESVTP2SRV1/STRS_Output/SOA_DIVISION  /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//AGESVTP2SRV1/STRS_Output/SOA_STORE  /usr/sap/OpenText/STRS_Output/SOA_STORE cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0


//AGESVTP2SRV1/AFP  /usr/sap/OpenText/STRS_Output cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//AGESVTP2SRV1/STRS_Output/OfficialReceipt    /usr/sap/OpenText/STRS_Output/OfficialReceipt      cifs   _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//AGESVTP2SRV1/STRS_Output/SOA_DIVISION  /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0
//AGESVTP2SRV1/STRS_Output/SOA_STORE  /usr/sap/OpenText/STRS_Output/SOA_STORE cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777 0 0




CS8149098 P2 - MajorDelta Airlines -- DALLoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 30.64 (thresh: 30)



sapcrmdi
TTA_PG2


[root@spsvcpacapp01 sap]$ id cppadm
uid=20000,gid=504



uid=20000,gid=504


spsvbpaaapp01
TOR01AMMSOL01


	CS8178110	Alpro Comm. VA -- APR	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0430 in domain D30_SMR_SHORT for node APR_APRSCMPRD_FIL_DLY failed (return code 12).~
	CS8176768	HAVI Logistics -- HAV	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0330 in domain D14_SMR_SHORT for node HAV_HAVKS4_FIL_DLY failed (return code 12).~
	CS8177063	Takasago International Corporation -- TI3	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0330 in domain D14_SMR_SHORT for node TI3_TI3ADNDBAP01_FIL_DLY failed (return code 12).~
	CS8178109	Tecnicas Reunidas S.A. -- TRE	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0530 in domain D60_SMR_SHORT for node TRE_TREBWPRDDBN_FIL_DLY failed (return code 12).~
	CS8176767	ZF Friedrichshafen AG -- ZFF	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0330 in domain D60_SMR_SHORT for node ZFF_ZFFPAPP011-HA_FIL_DLY failed (return code 12).~
CS8188725	Alpro Comm. VA -- APR	TSM: fra02ammtsm003.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2030 in domain D30_SMR_SHORT for node APR_APRLCPRD_MAXDB has missed its scheduled start up win
CS8191064	Controladora De Negocios -- CNG	TSM: dal09ammtsm001.ibmammsap.local ANR2579E Schedule OS_INCR_1800 in domain DAL_D_DOM for node FAM_CIDRH03_FIL failed (return code 12).~


1- Vm was worked today on CHG0213243, now we cannot login via ssh.
2- According to Snow vm is located at SNG Data Center however I did not find it there.
3- The login process uses some keys which are not present on the vm, when Chef runs it generates those keys, currently application chef-client fails.
4- A github to Chef team was created
A0EASG014XVM007		SVCD1SRV0 	10.6.1.16 	10.92.99.115

https://github.kyndryl.net/CMS/cms-chef/issues/6986



[2021-08-11T09:58:51+08:00] INFO: Running queued delayed notifications before re-raising exception

    ================================================================================
    Error executing action `register` on resource 'rhsm_register[svcd1srv0.eastwestageaslife.com]'
    ================================================================================

[root@svcd1srv0 rhsm]$ strace -ttTvf -s 4096 -o /tmp/yum.strace yum -d10 repolist -v
Loading "aliases" plugin
Loading "changelog" plugin
Loading "enabled_repos_upload" plugin
Loading "package_upload" plugin
Loading "presto" plugin
Loading "product-id" plugin
Loading "refresh-packagekit" plugin
Loading "rhui-lb" plugin
Loading "search-disabled-repos" plugin
Loading "security" plugin
Loading "subscription-manager" plugin
Loading "tmprepo" plugin
Loading "verify" plugin
Loading "versionlock" plugin
Updating Subscription Management repositories.
Unable to read consumer identity
This system is not registered with an entitlement server. You can use subscription-manager to register.
Config time: 0.617
Yum Version: 3.2.29
Setting up Package Sacks
Reading version lock configuration
pkgsack time: 1.144
Repo-id      : rhel-source
Repo-name    : Red Hat Enterprise Linux 6Server - x86_64 - Source
Repo-revision: 1606816889
Repo-updated : Tue Dec  1 18:02:00 2020
Repo-pkgs    : 0
Repo-size    : 0
Repo-baseurl : ftp://ftp.redhat.com/pub/redhat/linux/enterprise/6Server/en/os/SRPMS/
Repo-expire  : 21,600 second(s) (last: Wed Aug 11 09:58:32 2021)

Repo-id      : rhel-source-beta
Repo-name    : Red Hat Enterprise Linux 6Server Beta - x86_64 - Source
Repo-revision: 1349976169
Repo-updated : Fri Oct 12 01:22:49 2012
Repo-pkgs    : 0
Repo-size    : 0
Repo-baseurl : ftp://ftp.redhat.com/pub/redhat/linux/beta/6Server/en/os/SRPMS/
Repo-expire  : 21,600 second(s) (last: Wed Aug 11 09:58:45 2021)

Repo-id      : salt-repository
Repo-name    : Saltstack RPMS.latest Repository
Repo-revision: 1593702640
Repo-updated : Thu Jul  2 23:10:41 2020
Repo-pkgs    : 114
Repo-size    : 58 M
Repo-baseurl : http://146.89.140.152/mrepo/salt6server-x86_64/RPMS.latest
Repo-expire  : 21,600 second(s) (last: Wed Aug 11 09:58:47 2021)

repolist: 114
Uploading Enabled Repositories Report
Loaded plugins: presto, product-id, refresh-packagekit, rhui-lb, subscription-
              : manager, versionlock
This system is not registered with an entitlement server. You can use subscription-manager to register.
Cannot upload enabled repos report, is this client registered?

Case 03008102



BAP - Brenntag_Pte_Ltd_PG
bapv120400


OS patching done as part of CHG0213179 somehow left the box unavailable for use.
Soft Layer ticket CS2433677 was created to make sure the server is good at hardware level. They found no issues. 
Suse ticket has been created too: it is 00309778.
We involved Suse external support to help us get the box up and running again.  Suse ticket is 00309778.
Booting from an alternative older kernel was also attempted but gave the same issue.
Boot messages showed "A start job is running for dev-disk" and an UUID which then we saw was the HDD for /
The server was rebooted from an ISO while Suse export was with us on the call.
Suse support found a possible misconfiguration related to swap, not necessarily related to our issue.
We booted again from the local hardware and to see if that helped but it made no difference
The server is being rebooted again from ISO to drive t-shoot efforts forward.
We will have to hand over this ticket to the next shift to continue troubleshooting efforts with Suse support on the line.
Suse support is also getting an engineer at this time to hand over the ticket/webex to.


TSLEECQA - 10.207.63.14


tata-che01-pod1-phana-6114-2.imzcloud.ibmammsap.local

IMM IP 10.162.24.254   root/Hl56jLgs66




DB server SVES1HDBSRV01
application  servers SVES1SRV0 & SVJS1SRV0

SVES1HDBSRV01
10.116.205.203	ageas-phana-1024-4.imzcloud.ibmammsap.local




Product Name:                 HP LaserJet M506
Model Number:                F2A69A
Product Serial Number:   PHCHQ08472
Drivers Name:                  HP universal Printing PCL 6 (v6.2.1)
Printer Name:                   INVOICE
Host Name:                        NPIEAF805
IP Address:                         135.37.32.222


lpadmin -p NPIEAF805 -v socket://135.37.32.222 -E

PPLDCPRECCDBS	10.207.65.9
PPLDCQASCCDBS	10.207.65.17


PPLDCQASCCDBS	10.162.186.244	ple-che01-pod1-phana-h2-3000-02.imzcloud.ibmammsap.local
SL ticket number:CS2435108
CHG0214109: PPLDCQASCCDBS	10.207.65.17 is still rebooting for about an hour now. This is a physical server.
CS8239573 sev1 raised for the issue

root 
u6lB6p8cFj



CS8227175



CHG0213487	SYD04-SL,TOK02-SL	14-08-2021 07:30:00	14-08-2021 15:30:00
Upgrade of SUSE HANA servers from 12SP02 to 12SP03 on the Dev Systems. 

Server impacted
Host Name	  IFN IP	Asset Purpose   SID
JP0811ZBE100A	10.216.14.25	Production     HP1 HANA SAP 	app server clustered ASCS ERS
JP0811ZBE100B	10.216.14.19	Production     HP1 HANA SAP(Stand By)	app server clustered ASCS ERS
JP0811ZBE1009	10.216.14.35	Production     HP1 HANA DB	10.129.214.72	tok02-pod1-4tb-host05.imzcloud.ibmammsap.local	vhana
JP0811ZBE1011	10.216.14.26	Production     HP1 HANA DB (Stand By)	10.129.214.51	tok02-pod1-4tb-host06.imzcloud.ibmammsap.local	vhana
au0411zbe1006   10.215.14.6     Production     HP1 HANA DB (DR Server)	10.63.43.66	syd04-pod1-4tb-host01.imzcloud.ibmammsap.local	vhana



[root@jp0811zbe1009 hanaconfigvalidation]# su - hp1adm
hp1adm@jp0811zbe1009:/usr/sap/HP1/HDB00>

su - hp1adm -c "hdbnsutil -sr_register --remoteHost=jp0811zbe1009 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay --name=jp0811zbe1011"


Node Attributes:
* Node jp0811zbe1009:
    + hana_hp1_clone_state              : PROMOTED
    + hana_hp1_op_mode                  : logreplay
    + hana_hp1_remoteHost               : jp0811zbe1011
    + hana_hp1_roles                    : 4:P:master1:master:worker:master
    + hana_hp1_site                     : NODEA
    + hana_hp1_srmode                   : sync
    + hana_hp1_sync_state               : PRIM
    + hana_hp1_version                  : 1.00.122.16.1520578817
    + hana_hp1_vhost                    : jp0811zbe1009
    + lpa_hp1_lpt                       : 1628921242
    + master-rsc_SAPHana_HP1_HDB00      : 150
* Node jp0811zbe1011:
    + hana_hp1_clone_state              : UNDEFINED
    + hana_hp1_op_mode                  : logreplay
    + hana_hp1_remoteHost               : jp0811zbe1011
    + hana_hp1_roles                    : 4:N:master1:master:worker:master
    + hana_hp1_site                     : NODEB
    + hana_hp1_srmode                   : sync
    + hana_hp1_sync_state               : SFAIL
    + hana_hp1_version                  : 1.00.122.16.1520578817
    + hana_hp1_vhost                    : jp0811zbe1011
    + lpa_hp1_lpt                       : 10
    + master-rsc_SAPHana_HP1_HDB00      : 0


CS2435549 - Node A - 'Received customer approval for including firmware upgrade along with DIMMs replacement. There will be no change in downtime start time and still remains as Aug 14th 18.00 IST'
CS2435629 - TSLBWPRDDB - 'Received customer approval for including firmware upgrade along with DIMMs replacement. There will be no change in downtime start time and still remains as Aug 15th 15.00 pm IST'


7990923750


Master case CS8273155. Pending task to be completed by this weekend. The tickets will be generated until then hence closing all as duplicate keeping on on.



CS8339437 raised for softlayer access to ocean id



/oracle/RQA/sapdata1 = 1475		700
/oracle/RQA/sapdata2 = 1475		700
/oracle/RQA/sapdata3 = 1475		700
/oracle/RQA/sapdata4 = 1475		700
/oracle/RQA/sapdata99 = 275		225
/oracle/RQA/oraarch   = 50		9	
eyes
white_check_mark
heavy_plus_sign

IA1OTASPRDDB	10.133.17.146
IA1OTASPRDAPP	10.133.17.147



IA1NFSPRDAPP
/dev/mapper/vg_nfs-lv_nfsshare_P
Filesystem state:         clean with errors
133G
tune2fs: No such file or directory while trying to open 133G
Couldn't find valid filesystem superblock.
/dev/mapper/VolGroupE-lv_back
Filesystem state:         clean with errors
392G
tune2fs: No such file or directory while trying to open 392G
Couldn't find valid filesystem superblock.
/dev/mapper/vg_nfs-lv_OS_Monitor
Filesystem state:         clean with errors
5.0G
Filesystem state:         clean with errors
4.9G
tune2fs: No such file or directory while trying to open 4.9G
Couldn't find valid filesystem superblock.
/dev/mapper/VolGroup-lv_tmp
Filesystem state:         clean with errors
4.4G




CS8400920
Please see attached file as we need OS performer for this task 

Please  add  200Gb disk on server ttagrcprd and  create  new  vg + lv  and  copy  data  from  old  to  new  Filesystem.
Allocate  same space  which is  currently  having in  old  filesystem.
This need  to  be worked  with  SAP performer  as  application need  to  be stopped  while  copying  data to  new  FS.

Please  contact   Kamalnath Sankar  if  you have  any  query.
After that assign that 1.4TB unallocated disk to rqadatavg ( check with Kamalnath.sankar)

Old  VG & FS details 
==========================
[root@ttagrcprd ~]# df -h | grep rqaappvg
/dev/mapper/rqaappvg-rqaIntface_lv           2.0G   33M  2.0G   2% /interface/RQA
/dev/mapper/rqaappvg-sapadm_lv              1014M   33M  982M   4% /home/sapadm
/dev/mapper/rqaappvg-rqa3rdprty_lv           2.0G   33M  2.0G   2% /3rdPartySoftware/RQA
/dev/mapper/rqaappvg-rqasapmnt_lv             16G  1.3G   15G   8% /sapmnt/RQA
/dev/mapper/rqaappvg-usrsap_lv               5.0G  595M  4.5G  12% /usr/sap
/dev/mapper/rqaappvg-daaadm_lv              1014M   33M  982M   4% /home/daaadm
/dev/mapper/rqaappvg-rqaadm_lv              1014M   33M  982M   4% /home/rqaadm
/dev/mapper/rqaappvg-usrsapccms_lv           4.0G   33M  4.0G   1% /usr/sap/ccms
/dev/mapper/rqaappvg-usrtrans_lv              40G   34G  6.9G  83% /usr/sap/trans
/dev/mapper/rqaappvg-rqausrRQA_lv             24G  2.0G   23G   9% /usr/sap/RQA
/dev/mapper/rqaappvg-usrsapdaa_lv            4.0G  1.3G  2.8G  33% /usr/sap/DAA

New  Vg & FS
==============================

/dev/mapper/rqaappvg_new-rqaIntface_lv           2.0G   33M  2.0G   2% /interface_new/RQA
/dev/mapper/rqaappvg_new-sapadm_lv              1014M   33M  982M   4% /home/sapadm_new
/dev/mapper/rqaappvg_new-rqa3rdprty_lv           2.0G   33M  2.0G   2% /3rdPartySoftware_new/RQA
/dev/mapper/rqaappvg_new-rqasapmnt_lv             16G  1.3G   15G   8% /sapmnt_new/RQA
/dev/mapper/rqaappvg_new-usrsap_lv               5.0G  595M  4.5G  12% /usr/sap_new
/dev/mapper/rqaappvg_new-daaadm_lv              1014M   33M  982M   4% /home/daaadm_new
/dev/mapper/rqaappvg_new-rqaadm_lv              1014M   33M  982M   4% /home/rqaadm_new
/dev/mapper/rqaappvg_new-usrsapccms_lv           4.0G   33M  4.0G   1% /usr/sap_new/ccms
/dev/mapper/rqaappvg_new-usrtrans_lv              40G   34G  6.9G  83% /usr/sap_new/trans
/dev/mapper/rqaappvg_new-rqausrRQA_lv             24G  2.0G   23G   9% /usr/sap_new/RQA
/dev/mapper/rqaappvg_new-usrsapdaa_lv            4.0G  1.3G  2.8G  33% /usr/sap_new/DAA




vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name
mkfs.ext2/3/4 path of lvdisplay
mkdir /sybase
mount
vi /etc/fstab

lvcreate -L 200M/G -n new_logical_vol_name volume_grp_name



[root@ttagrcprd scsi_disk]# df -hT |grep -i rqaappvg
	/dev/mapper/rqaappvg-rqaIntface_lv          xfs       2.0G   33M  2.0G   2% /interface/RQA_new
/dev/mapper/rqaappvg-sapadm_lv              xfs      1014M   33M  982M   4% /home/sapadm_new
	/dev/mapper/rqaappvg-rqa3rdprty_lv          xfs       2.0G   33M  2.0G   2% /3rdPartySoftware/RQA_new
	/dev/mapper/rqaappvg-rqasapmnt_lv           xfs        16G  1.3G   15G   8% /sapmnt/RQA_new
/dev/mapper/rqaappvg-usrsap_lv              xfs       5.0G  614M  4.4G  13% /usr/sap_new
/dev/mapper/rqaappvg-daaadm_lv              xfs      1014M   33M  982M   4% /home/daaadm_new
/dev/mapper/rqaappvg-rqaadm_lv              xfs      1014M   33M  982M   4% /home/rqaadm_new
/dev/mapper/rqaappvg-usrsapccms_lv          xfs       4.0G   33M  4.0G   1% /usr/sap/ccms_new
/dev/mapper/rqaappvg-usrtrans_lv            xfs        40G   34G  6.9G  83% /usr/sap/trans_new
/dev/mapper/rqaappvg-rqausrRQA_lv           xfs        24G  2.0G   23G   9% /usr/sap/RQA_new
/dev/mapper/rqaappvg-usrsapdaa_lv           xfs       4.0G  1.3G  2.8G  33% /usr/sap/DAA_new



CS8443638	printer setup
Made: HP LaserJet Pro 
Model: HP LaserJet Pro M402-M403 n-dne PCL 6
Hostname: FCOF
IP: 10.250.41.231
Port: 9100




gbwqhdb00	Pending Deactivation
gbwqas0		Pending Deactivation
gbwqas2		Pending Deactivation
gbwqas3		Pending Deactivation



 CI2QADB -10.5.242.13
10.164.238.238	lonhana-1024-45.xsportal.local


CS8446289
S02 100.126.67.20
E02 100.126.67.45

Please create new printer queues on E02, S02 :
IP                Name:
149.223.62.38           LAAP09201
149.223.62.39           LAAP09101
149.223.62.40           LAAP09102
149.223.62.41           LAAP18001
149.223.62.112          LAAP06001



lpadmin -p LAAP09201 -v socket://149.223.62.38 -E
lpadmin -p LAAP09101 -v socket://149.223.62.39 -E
lpadmin -p LAAP09102 -v socket://149.223.62.40 -E
lpadmin -p LAAP18001 -v socket://149.223.62.41 -E
lpadmin -p LAAP06001 -v socket://149.223.62.112 -E


HFCPE1HNDB1 is hfc-dal13-pod2-phana-h4-6000-04.imzcloud.ibmammsap.local physical box
 hfcpe1hndb1haresides on hfc-dal13-pod2-phana-h4-6000-06.imzcloud.ibmammsap.local


ps2-s4x-ci	10.238.1.134



LONMAGERP0002.mag.local		10.69.0.12	172.22.0.12	A0D8UK014XVM003
LONMAGGRC0001.mag.local		10.69.0.39	172.22.0.39	A0D8UK014XVM020
LONMAGBWH0002.mag.local		10.69.0.18	172.22.0.18	A0D8UK014XVM007

migrationfs
 root:sapsys
777
[root@LONMAGERP0002 /]$ lvdisplay |grep -i lv_migration
  LV Path                /dev/vg_migration/lv_migration		migrationfs
  LV Name                lv_migration

[root@LONMAGERP0002 /]$ df -hT migrationfs
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg_migration-lv_migration
                     ext4 1007G   72M  956G   1% /migrationfs



GRUB stands for GRand Unified Bootloader. Its function is to take over from BIOS at boot time, load itself, load the Linux kernel into memory, and then turn over execution to the kernel.


delta-dal09-phana-1024-01.imzcloud.ibmammsap.local

10.143.69.188	root HgpYWgEUZ6



TSLBWPRDDB - Hana server
ADSPRDS - non-hana



[root@armfksap007 ibmrmalik]$ lvdisplay |grep -i backuptmp_lv
  LV Path                /dev/backuptmp_vg/backuptmp_lv		BWD_DB_Bkp
  LV Name                backuptmp_lv



10.140.48.156	monhana-1024-4.xsportal.local

Mon


CHG0215913
SNCHSMAPD51	vhana	10.73.10.74
10.166.156.196	torhana-1024-20.xsportal.local



CS8577225
SUSE Case TS006716187


cleanup messages for sbd

 Node Name 1: ps2-s4p-ci-ha                      IP: 10.238.1.71                                                |
|         Node Name 2: ps2-s4p-ci                      IP: 10.238.1.70                                                   |

DRBD Disk Role                                      : Bad  


|                             
                                        


CS8655394
case with  softlayer ticket was created : CS2470185

parhana-1024-10.xsportal.local	

parhana-1024-25.xsportal.local   correct server






tslbwprdhdbdr 
The repository initialization failed. Disable (or remove) â”¬ â”‚ 
                                                                       â”‚ â”‚the offending service or repository in the repository     â”‚ â”‚ 
                                                                       â”‚ â”‚manager.                                                  â”‚ â”‚ 
                                                                       â”‚ â”‚                                                          â”´ â”‚ 
                                                                       â”‚ â”‚Details:                                                  â”‚ â”‚ 
                                                                       â”‚ â”‚                                                          â”‚ â”‚ 
                                                                       â”‚ â”‚Error refreshing service                                  â”‚ â”‚ 
                                                                       â”‚ â”‚SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local 


tsls4proddbdr




Incident#: CS8712896
Client Name: IAG GBS Limited -- IA1
CDIR: n/a
Issue Description: root FS maxed out at 100%. Disk Utilization / FATAL: Free 0.00MB
Data Center: LON02-SL
Asset Name: IA1FTSPRDAPP




CHG0217428 - Group 8 - Prod
sapbowapp	                10.207.61.73			undefined  
sapcrmdi	                10.207.61.83			undefined  
sapborepo	                10.207.61.40			undefined  
adsprds	              		10.207.61.29			undefined  
sapboprd	                10.207.61.205			undefined  




CHG0217429 - Group 9 - Prod
BIPRDAPP1	10.207.61.28
BIPRDAPP3	10.207.61.31
TSCMLPRD	10.207.61.36
TSGPPRD		10.207.61.41
TSLBWPRDDB	10.207.61.200




	CS8760311       TSM: par01ammtsm001.ibmammsap.local ANR2578W Schedule DLY_INC_0030 in domain NFL_N_FIL for node CMA_SMDBQUAQW3_FIL has missed its scheduled start up window.~
	CS8760310       TSM: zps2sea1tsm01.imzcloud.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2230 in domain D30_SMR_SHORT for node PS2_PS2-POP-CI_FIL_DLY has missed its scheduled
	CS8759736       TSM: zps2sea1tsm01.imzcloud.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2030 in domain D30_SMR_SHORT for node PS2_PS2-POP-DB_FIL_DLY has missed its scheduled
	CS8758924       TSM: tok02ammtsm001.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0430 in domain D30_SMR_SHORT for node TBO_TBOS4PRDDB2_FIL_DLY failed (return code 12).~
CS8755865       TSM: dal09ammtsm001.ibmammsap.local ANR2579E Schedule @2412 in domain NFL_N_FIL for node LSP_LZAGWDEV0_FIL failed (return code 12).~
CS8756011       TSM: fra02ammtsm002.ibmammsap.local ANR2579E Schedule MLY_FULL_2WK_SAT in domain DFL_N_FIL for node TRE_TRECSDEVDBAP_FIL failed (return code -99).~


Cust0m$rS@p@123456


10.182.18.114	snchdmdpd65.hec.network.qut

10.182.18.118
root YRYuxrjT9A


crm configure property maintenance-mode=false


	ibmddunb pts/5 169.55.192.116 Sat Sep 18 05:07 - 06:33 (01:26)
	ibmddunb pts/4 169.55.192.116 Sat Sep 18 04:33 - 05:21 (00:48)
	ibmrprad pts/3 146.89.140.60 Sat Sep 18 04:31 - 08:03 (03:31)
ibmddunb pts/1 169.55.192.116 Sat Sep 18 04:15 - 05:24 (01:08)
	ibmrprad pts/0 146.89.140.60 Sat Sep 18 04:14 still logged in
	reboot system boot 3.10.0-1160.31.1 Sat Sep 18 04:14 - 08:55 (04:40)
	ibmrprad pts/8 146.89.140.60 Sat Sep 18 04:10 - 04:10 (00:00)
ibmrprad pts/9 146.89.140.60 Sat Sep 18 03:46 - 04:10 (00:23)


cat /home/aaronkilik/.bash_history




Hana - tsls4proddbh
Oracle - sappoprdc


Hana - tslbwprddb
Oracle - sappoprdc

Hana - grep -i log
Oracle - grep -i oraarch


while printf '%s ' "$(df -hT|grep -i log | awk 'NR==2 { print $(NF-1) }')"; do sleep 1800; done



tsls4proddbh:/home/ibmrmalik # df -hT |grep -i log
/dev/sda5                                   xfs       544G  173G  371G  32% /sapmnt/log


[root@sappoprdc ibmrmalik]# df -hT |grep -i oraarch
/dev/mapper/pcparchvg-oracle_PCP_oraarch_lv   ext4       69G   46G   21G  70% /oracle/PCP/oraarch


watch -n 10 df -hT |grep -i log


i=1
outputs_per_line=10
frequency=30
while true; do
  echo -n "$(df / | awk 'NR==2 {print $5}') "
  if [ $((i%outputs_per_line)) -eq 0 ]; then
    echo
  fi
  ((i++))
  sleep "$frequency"
done


*/30 * * * * /tmp/samplerm.sh >>/tmp/df_output.txt


mail -a /tmp/df_output.txt -s "df -hT output" v7g4q7g2a9j1y5c3@kyndryl.slack.com < /dev/null



Master ticket CS8812496- TSM server che01ammtsm005 down


10.207.62.13
10.207.62.16 
10.207.62.19 
10.207.62.18 
10.207.62.14 
10.207.62.21
10.207.62.27 	TSGPDEV
10.207.62.17 	TSCMLDEV
10.207.62.20	ESSMSSDEV-DR 
10.207.62.25 	ASDDEV
10.207.62.24	GRCDEVNEW 
10.207.62.26 	SAPBODEV
10.207.62.22 	JBDAIX4
10.207.62.28	TSLGLDEV
10.207.62.20


CS8841688,CS8841584


Master ticket CS8845079 closed. Restarted ncpa services and Nagios started giving proper response. 

Master ticket CS8853110
[root@IA1ADSDEVAPP ibmrmalik]$ /etc/init.d/postfix status
master (pid  22251) is running...
You have mail in /var/mail/root

Postfix was down, edited the config and started it.


 

 2. Check for any missing symlink to the libraries

# ln -s /opt/rh/SAP/lib64/compat-sap-c++-6.so /usr/lib/libstdc++.so.6

Change the file/directory ownership of /usr/sap/lib
to "sapadm:sapsys" or "<-sid->adm:sapsys" (replace the SID
appropriately).

 

Package glibc-2.12-1.212.el6_10.3.x86_64 already installed and latest version
Package glibc-2.12-1.212.el6_10.3.i686 already installed and latest version


 Just want to know if you see the package compat-sap-c++-6* using

# rpm -q compat-sap-c++-6

and installing the below didn't help.

# yum install compat-sap-c++-6




temp_vg

su - boadm
7:05
then
7:05
./setup.sh -InstallDir /usr/sap/SBO -pre_requisite_check /usr/sap/BOBJ_43/response.ini /usr/sap/BOBJ_43/failed.txt

/usr/local/lib:/usr/lib:/usr/local/lib64:/usr/lib64:/usr/sap/lib:/usr/sap/lib64



	CS8805624       TSM: a0001p5rapp0012.mgt.mhas.ibm.com ANR2578W Schedule 7TW_FIL_INC_0130 in domain D14_SMR_SHORT for node GLT_GLTB4QASAS01_FIL_DLY has missed its scheduled star
	CS8805711       TSM: a0001p5rapp0012.mgt.mhas.ibm.com ANR2578W Schedule 7TW_FIL_INC_0130 in domain D14_SMR_SHORT for node GLT_GLTMEQASDB01_FIL_DLY has missed its scheduled star
	CS8805726       TSM: a0001p5rapp0012.mgt.mhas.ibm.com ANR2578W Schedule 7TW_FIL_INC_0130 in domain D14_SMR_SHORT for node GLT_GLTB4QASAS01_FIL_DLY has missed its scheduled star
	CS8806003       TSM: a0001p5rapp0012.mgt.mhas.ibm.com ANR2578W Schedule 7TW_FIL_INC_0130 in domain D14_SMR_SHORT for node GLT_GLTB4QASAS01_FIL_DLY has missed its scheduled star
CS8857001       TSM: a0001p5rapp0012.mgt.mhas.ibm.com ANR2578W Schedule 7TW_FIL_INC_2130 in domain D14_SMR_SHORT for node GLT_GLTNWQASAS01_FIL_DLY has missed its scheduled star




10.166.238.138	torhana-2048-1.xsportal.local



Package compat-sap-c++-4.8.2-19.el6.x86_64 already installed and latest version
Package libstdc++-4.4.7-23.el6.i686 already installed and latest version

C10830140053A014


IP:161.202.165.43

userid: gpay

Current  Source IP: 64.69.195.1

New Source IP:       64.27.246.4

GPDT-FT-PROD.GLOBALPAY.COM (64.27.246.171)


 public key in sftp prod (10.70.111.46).



MM3
Node mm3s4uep004n1:	
* Node mm3s4uep004n2

primary is mm3s4uep004n2  NODEB
secondary is mm3s4uep004n1 NODEA

su - uepadm -c "hdbnsutil -sr_register --remoteHost=mm3s4uep004n2 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEA"





CS8933884	
Pls refer to 572251 / 2021 Pls help create these 2 folders on DEP (sjmdepaa01) & QEP (sjmqepaa01).
we need to create /usr/sap/PEP/BOA/STATEMENTS/in/ on  PEP (sjmqepaa01 & sjmqepaa02).



/dev/mapper/vghanadata-lv_hana_data
                     xfs    6.0T  2.5T  3.6T  41% /sapmnt/data
/dev/mapper/vghanadata-lv_hana_shared
                     xfs    2.0T   23G  2.0T   2% /sapmnt/shared
/dev/mapper/vghanadata-lv_usr_sap
                     xfs     50G  6.8G   44G  14% /usr/sap




CS8947900ZF Friedrichshafen AG -- ZFFP3 - MinorE02, S02 - new printers LLG
>Server/Host name................................:e02.zf-world.com (149.223.100.65), s02.zf-world.com (149.223.100.41)
ZFFSAPPDB006	100.126.67.45	149.223.100.65		prod
ZFFSAPPDB001	100.126.67.20	149.223.100.41	


Please create new printer queues on E02, S02 :
IP                Name:
10.216.58.23  412_LLGMX_ADB_4475 
10.216.59.103 412_LLGMX_ADB_4369

lpadmin -p 412_LLGMX_ADB_4475 -v socket://10.216.58.23 -E 
lpadmin -p 412_LLGMX_ADB_4369 -v socket://10.216.59.103 -E 



CS8955067Tata Steel Limited -- TTAP2 - MajorMemory Swap CRITICAL: Swap free 0.00% (thresh 50:%)



[root@svad1srv0 /]$ rpm -V compat-sap-c++-4.8.2-19.el6.x86_64
S.5..UGT.    /opt/rh/SAP/lib64/compat-sap-c++.so


SPSVCPIVSQL01	10.6.3.43	A0EASG012XVM047
SPSVMPLMASE01	10.6.3.45	A0EASG012XVM055
SPSVOPITSQL01	10.6.3.34	A0EASG012XVM041
SPSVOPLTAPP01	10.6.3.35	A0EASG012XVM042
SPSVTPLNAPP01	10.6.3.44	A0EASG012XVM057
SVMD1SRV0	10.6.1.34	A0EASG012XVM011
SVMD1SRV1	10.6.1.35	A0EASG012XVM012
SVMQ1SRV0	10.6.2.41	A0EASG012XVM021
SVFD1SRV0	10.6.1.24	A0EASG012XVM003



TOK04-SL		

[root@inoecd00 ibmrmalik]# df -hT /oracle/P01/sapdata*
Filesystem                            Type  Size  Used Avail Use% Mounted on
/dev/mapper/p01datavg-p01sapdata1_lv  ext4  148G  1.5G  140G   2% /oracle/P01/sapdata1
/dev/mapper/p01datavg-p01sapdata2_lv  ext4  148G  137G  4.5G  97% /oracle/P01/sapdata2
/dev/mapper/p01datavg-p01sapdata3_lv  ext4  148G   60M  142G   1% /oracle/P01/sapdata3
/dev/mapper/p01datavg-p01sapdata4_lv  ext4  148G   60M  142G   1% /oracle/P01/sapdata4


/oracle/P01/sapdata1 : 148GB -> 100GB
/oracle/P01/sapdata2 : 148GB -> 300GB
/oracle/P01/sapdata3 : 148GB -> 100GB
/oracle/P01/sapdata4 : 148GB -> 100GB


BAP : Prod Singapore and DR HK02	protection group BAP - Brenntag_Pte_Ltd_PG
BAPV120400	10.134.3.6	10.8.217.8	J12
BAPCCP0100	10.134.5.8	10.8.219.6	CCP
BAPV330900	10.134.3.7	10.8.217.13	V33


9321705143 


Brenntag - BAPV330900 - 15 days ago, the steady state team extended a disk it seems


sm9l182172012
sm9p118217v22
trecsprddbap


10.70.111.42 and sftp prd 10.70.111.46
sftp -v -oCiphers=aes128-ctr 10.10.10.16


hmac-sha256,hmac-sha2-256,hmac-sha512,hmac-sha2-512



CHG0217257	CTASK0441057
Upgrade SUSE 12 from SP2 to SP4

Impacting hosts:

D11	aprerpdev		10.135.196.54
X51	aprpidev		10.135.196.8
BIW	aprbwdev		10.135.196.12
AD2	aprscmdev	10.135.196.6
GRD,GJD	aprgrcdev		10.135.196.7

2. OS SP upgrade on:
D11	aprerpdev	10.10.20.108	10.135.196.54
X51	aprpidev	10.10.20.50	10.135.196.8
BIW	aprbwdev	10.10.20.45	10.135.196.12
AD2	aprscmdev	10.10.20.35	10.135.196.6
LD2	aprlcdev	10.10.20.40	10.135.196.234
GRD,GJD	aprgrcdev	10.10.20.25	10.135.196.7


10.36.106.189	hfc-dal13-pod2-phana-h4-6000-01.imzcloud.ibmammsap.local	HFCQR3HNDB1



CHG0217921	CTASK0443899		08-10-2021 12:30:00	08-10-2021 20:30:00
Upgrade SUSE 12 from SP2 to SP4

Impacting hosts:
A11	aprerpqas		10.135.196.92
X31	aprpiqas		10.135.196.84




JD1 - Development JAVA (FS_QUO)	svjd1srv0	10.6.1.12

JQ1 - Quality Java (FS-QUO)	svjq1srv0	10.6.2.12

JS1 -  Sand Box Java (FS-QUO)	SVJS1SRV0	10.6.1.140

JPP - Production ERP Application Java	spsvepajapp01	10.6.3.13

Please check ticket 0000717859/202 for request to provide DISPLAY access for folder : /usr/sap/SID/J00/j2ee/cluster/apps/sap.com/FS-QUO-ear/app_libraries_container/lib.

 

Our PQM consultants cannot access the folder using below link which they are able to access before. Please compare /usr/sap/SID/J00/j2ee/cluster/apps/sap.com/FS-QUO-ear/app_libraries_container/lib folder permission to JD1 (DEV)


Environment: Prod

URL:  http://10.70.111.13:50000/csiroot/cservlet/DownloadLog?zip=1&file=//usr/sap/JPP/J00/j2ee/cluster/apps/sap.com/FS-QUO-ear/app_libraries_container/lib


Environment: QA

URL:  http://10.70.110.12:50000/csiroot/cservlet/DownloadLog?zip=1&file=//usr/sap//JQ1/J00/j2ee/cluster/apps/sap.com/FS-QUO-ear/app_libraries_container//lib


Environment: SBX

URL:  http://10.70.110.12:50000/csiroot/cservlet/DownloadLog?zip=1&file=//usr/sap//JQ1/J00/j2ee/cluster/apps/sap.com/FS-QUO-ear/app_libraries_container//lib

 
Please compare to DEV:

http://10.92.99.111:50000/csiroot/cservlet/DownloadLog?zip=1&file=//usr/sap//JD1/J00/j2ee/cluster/apps/sap.com/FS-QUO-ear/app_libraries_container//lib

 

TSLBWPRDDB	10.207.61.200
10.162.24.252	che01-pod1-4tb-host02.imzcloud.ibmammsap.local


tslbwdevdb
10.162.24.252	che01-pod1-4tb-host02.imzcloud.ibmammsap.local
-rw------- 1 ibmjorozco       amm - osaix support (cr) 1718 Oct  9 06:23 krb5cc_193686
-rw------- 1 ibmvloria        domain_users             1579 Oct  9 06:28 krb5cc_193958





CS9136954P2 - MajorSuncor Energy Inc. -- SNCPing Availability CRITICAL - 10.73.10.21: rta nan. lost 100% Attention commas replaced by dots.
CS9136985P2 - MajorSuncor Energy Inc. -- SNCPing Availability CRITICAL - 10.73.11.116: rta
CS9139339P2 - MajorSuncor Energy Inc. -- SNCPing Availability CRITICAL - 10.73.10.50: rta nan. lost 100% Attention commas replaced by dots.
CS9139335P2 - MajorSuncor Energy Inc. -- SNCPing Availability CRITICAL - snchzrapd61: rta nan. lost 100% Attention commas replaced by dots.
CS9139324P2 - MajorAmerican Airlines -- A1APing Availability CRITICAL - 10.4.10.30: rta nan. lost 100% Attention commas replaced by dots.
CS9139331P2 - MajorPerformance in Lighting S.P.A. -- PL2Ping Availability CRITICAL - 10.7.33.14: rta nan. lost 100% Attention commas replaced by dots.
CS9139338P2 - MajorDelta Air Lines -- DALPing Availability CRITICAL - 10.4.5.177: rta nan. lost 100% Attention commas replaced by dots.
CS9139350P2 - MajorManchester Airport Group -- MNGPing Availability CRITICAL - 10.71.0.11: rta nan. lost 100% Attention commas replaced by dots.



/oracle
448805
/proc
1515774
/sapstage
37552



10.162.186.161
root

yTmYHqZ9QU


	CS9208851	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2579E Schedule DLY_INC_2330 in domain NFL_P_FIL for node TTA_SAPCRMDI_FIL failed (return code 12).~
	CS9207017	TSM: sng01ammtsm005.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2230 in domain D30_SMR_SHORT for node BTK_BTKF1PDB01_FIL_DLY has missed its scheduled start up
	CS9207448	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2578W Schedule DLY_INC_2030 in domain NFL_N_FIL for node TTA_SAPEPQA_FIL has missed its scheduled start up windo
	CS9207443	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2578W Schedule DLY_INC_2030 in domain NFL_N_FIL for node TTA_TSGPQA_FIL has missed its scheduled start up window
	CS9207439	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2578W Schedule DLY_INC_2030 in domain NFL_N_FIL for node TTA_S4HDEV_FIL has missed its scheduled start up window
	CS9207440	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2578W Schedule DLY_INC_2030 in domain NFL_N_FIL for node TTA_ESSMSSDEV-DR_FIL has missed its scheduled start up 
	CS9207451	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2030 in domain D30_SMR_SHORT for node TTA_SAPAPP31-HA_FIL_DLY has missed its schedule
	CS9207445	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2030 in domain D30_SMR_SHORT for node TTA_TSLEECQA01_FIL has missed its scheduled sta
	CS9207442	TSM: che01ammtsm005.imzcloud.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2030 in domain D30_SMR_SHORT for node TTA_TTAGRCPRD_FIL_DLY has missed its scheduled 
CS9201252	TSM: a0001p5rapp0013 ANR2579E Schedule @40 in domain D30_SMR_SHORT for node ZEC_USPOKPCHD01_FIL_DLY failed (return code 12).~
CS9198968	TSM: a0001p5rapp0013 ANR2579E Schedule 7TW_FIL_INC_0030 in domain D30_SMR_SHORT for node ZEC_USPOKPMHDB01_FIL_DLY failed (return code 12).~



svtd1srv0 10.92.99.126 to AGESVTQ2SRV0 10.70.110.114	A0EASG012XVM004
svtd1srv1 10.92.99.127 to AGESVTQ2SRV1 10.70.110.116	A0EASG012XVM005


A0D8UK014XVM003		LONMAGERP0002
A0D8UK014XVM005		LONMAGERP0004
A0D8UK014XVM007		LONMAGBWH0002
A0D8UK014XVM009		LONMAGBWH0004
A0D8UK014XVM011		LONMAGBOB0002



CPu/Memory  in average and Peek for the last quarter


gateway 10.116.145.63


route add -net 10.116.145.18 gw 10.116.145.63 dev eth0



CS9222490 Suncor Energy Inc. -- SNC SNC TSM: tor01ammtsm002.ibmammsap.local ANR2578W Schedule DLY_INC_0430 in domain DFL_N_FIL for node SNC_SNCHBIBPD61_FIL has missed its scheduled start up window.~
CS9235631 Alpro Comm. VA -- APR APR TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0230 in domain D30_SMR_SHORT for node APR_APRERPPRDD_FIL_DLY failed (return code 12).~
CS9218870 A.P. Moller Maersk -- APM APM TSM: fra02ammtsm001 ANR2578W Schedule DLY_INC_0530 in domain NFL_P_FIL for node APM_SCRBWPDEFRA30_FIL has missed its scheduled start up window.~


/dev/popappvg/usrtrans_lv       /usr/sap/trans


CS9245033	
havhav100cÂ Â Â Â 10.199.190.24Â Â Â Â KC4	all disks used
havhav1010Â Â Â Â 10.199.190.11Â Â Â Â YC4	all disks used
havhav1013Â Â Â Â 10.199.190.8Â Â Â Â DEV	all disks used
havhav100bÂ Â Â Â 10.199.190.10Â Â Â Â TX4,TJ4	all disks used
havhav1018	10.199.191.7		all disks used
havhav100d	10.199.191.6		all disks used

havhav100eÂ Â Â Â 10.199.190.6Â Â Â Â TC4	
/dev/sdg   tc4datavg lvm2 a--  503.00g 503.00g
/dev/sdh   tc4datavg lvm2 a--  503.00g 503.00g
/dev/sdi   tc4datavg lvm2 a--  503.00g 503.00g
/dev/sdj   tc4datavg lvm2 a--  503.00g 503.00g
/dev/sdk   tc4datavg lvm2 a--  503.00g 503.00g
/dev/sdl   tc4datavg lvm2 a--  503.00g 503.00g
/dev/sdm   tc4datavg lvm2 a--  502.00g 502.00g
/dev/sdn   tc4datavg lvm2 a--  502.00g 502.00g


havhav100aÂ Â Â Â 10.199.190.19Â Â Â Â KX4,KJ4
/dev/sdh   kj4datavg lvm2 a--  128.00g  128.00g
/dev/sdc   kj4logvg  lvm2 a--   64.00g   64.00g
/dev/sdd   kj4archvg lvm2 a--  128.00g  128.00g

havhav100fÂ Â Â Â 10.199.190.14Â Â Â Â YX4,YJ4
/dev/sdg   yx4datavg lvm2 a--  144.00g 144.00g

havks4Â Â Â Â 	10.199.190.9Â Â Â Â KS4,KSJ
/dev/sdm   ksjdatavg lvm2 a--  277.00g  277.00g
/dev/sdn   ksjdatavg lvm2 a--  277.00g  277.00g

havhav1009	10.199.191.11
PV         VG            Fmt  Attr PSize    PFree
[unknown]  migration1    lvm2 a-m   512.00g  512.00g
  /dev/sdaf  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdag  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdah  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdai  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdaj  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdak  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdal  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdam  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdh   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdi   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdj   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdk   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdl   migration1    lvm2 a--   512.00g  512.00g
sdbc                                   67:96   0    4T  0 disk	no uuid attached - free to del		sdbc - SCSI 33:0:2:0

sdh - SCSI 0:0:8:0
sdi - SCSI 0:0:9:0
sdj - SCSI 0:0:10:0
sdk - SCSI 0:0:11:0
sdl - SCSI 0:0:12:0

sdaf - SCSI 32:0:4:0
sdag - SCSI 32:0:5:0
sdah - SCSI 32:0:6:0
sdai - SCSI 32:0:8:0
sdaj - SCSI 32:0:9:0
sdak - SCSI 32:0:10:0
sdal - SCSI 32:0:11:0
sdam - SCSI 32:0:12:0





havhav1008	10.199.191.16
PV         VG        Fmt  Attr PSize   PFree
/dev/sdl   psjdatavg lvm2 a--  136.00g 136.00g
/dev/sdm   psjdatavg lvm2 a--  136.00g 136.00g



1096  2021-08-24 12:57:17 pvmove /dev/sdc /dev/sdo
 1097  2021-08-24 13:09:25 pvs |grep -i rqaappvg
 1098  2021-08-24 13:09:44 lvdisplay |grep -i rqaappvg


 /dev/sdaf  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdag  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdah  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdai  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdaj  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdak  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdal  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdam  migration1    lvm2 a--   512.00g  512.00g
  /dev/sdh   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdi   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdj   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdk   migration1    lvm2 a--   512.00g  512.00g
  /dev/sdl   migration1    lvm2 a--   512.00g  512.00g



CS9262990
Please extend filesystems on inoecp00.

/oracle/P01/sapdata1 25GB -> 1200GB
/oracle/P01/sapdata2 25GB -> 1200GB
/oracle/P01/sapdata3 25GB -> 1200GB
/oracle/P01/sapdata4 25GB -> 1200GB
/oracle/P01/sapdata99 25GB -> 600GB



CS9336521Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.102.57: rta nan. lost 100% Attention commas replaced by dots.
CS9336516Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.102.75: rta nan. lost 100% Attention commas replaced by dots.
CS9336500Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.103.29: rta nan. lost 100% Attention commas replaced by dots.
CS9336486Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.103.21: rta nan. lost 100% Attention commas replaced by dots.
CS9336478Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.102.50: rta nan. lost 100% Attention commas replaced by dots.
CS9336476Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.102.38: rta nan. lost 100% Attention commas replaced by dots.
CS9336473Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.102.67: rta nan. lost 100% Attention commas replaced by dots.
CS9336471Arnoldo Mondadori Editore SpA -- ARMP2 - MajorPing Availability CRITICAL - 10.7.102.66: rta nan. lost 100% Attention commas replaced by dots.



su - pb0adm -c "hdbnsutil -sr_register --remoteHost=bs4pb0077-ha --remoteInstance=53 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEA"



sjmpcpaa01	10.195.1.13	10.198.10.13	A0FGSG014XVM037		ok
sjmpepaa01	10.195.1.4	10.198.10.4	A0FGSG014XVM029		ok
sjmppqdb01	10.195.1.12	10.198.10.12	A0FGSG014XVM036		ok
sjmppqaa01	10.195.1.9	10.198.10.9	A0FGSG014XVM034		ok
sjmpwdaa01	10.195.0.12	10.198.13.12	A0FGSG014XVM042 - DMZ	ok
sjmpxpdb01	10.195.1.20	10.198.10.20	A0FGSG014XVM044		ok
sjmpxpaa01	10.195.1.19	10.198.10.19	A0FGSG014XVM043		ok
sjmpfpaa01	10.195.1.7	10.198.10.7	A0FGSG014XVM032		ok


A0EASG014XVM035


10.162.186.207	root	v4RCYvlEDz


CS9373877 Tata Steel Limited -- TTATTA S4HPRDMOCK TTA IC4SAP-SL SAP LOBIncidentP2 - MajorNewLog Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-10-21-10-16-39 for details.SQ-SAP-TRIO-B1(empty)SAPB1Sathishkumar HarikumarHarsha Jayadevappa10-21-2021 10:16:50
11m ago
ibm_netcool10-21-2021 10:16:50
11m ago
CS9372985 Tata Steel Limited -- TTATTA S4HPRDMOCK TTA IC4SAP-SL SAP LOBIncidentP2 - MajorOpenLog Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-10-21-09-06-33 for details.SQ-SAP-TRIO-B1Yun TangSAPB1Sathishkumar HarikumarHarsha Jayadevappa10-21-2021 09:06:45
about an hour ago
ibm_netcool10-21-2021 09:59:20
28m ago
CS9372564 Tata Steel Limited -- TTATTA S4HPRDMOCK TTA IC4SAP-SL SAP LOBIncidentP2 - MajorOpenLog Syslog-ErrorStates Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-10-21-08-41-32 for details.SQ-SAP-TRIO-B1Yun TangSAPB1Sathishkumar HarikumarHarsha Jayadevappa10-21-2021 08:41:45
2h ago
ibm_netcool10-21-2021 09:59:00
28m ago
	CS9372497 Tata Steel Limited -- TTATTA S4HPRDMOCK TTA IC4SAP-SL SAP LOBIncidentP2 - MajorOpenLog Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-10-21-08-31-31 for details.SQ-SAP-TRIO-B1Yun TangSAPB1Sathishkumar HarikumarHarsha Jayadevappa10-21-2021 08:31:43
2h ago
ibm_netcool10-21-2021 09:58:42
29m ago
CS9373192 Tata Steel Limited -- TTATTA S4HPRDMOCK TTA IC4SAP-SL SAP LOBIncidentP2 - MajorOpenLog Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-10-21-09-26-34 for details.



spsvmplmapp01	
agesvtp2srv1/afp

AFP (file://AGESVTP2SRV1/STRS_Output/AFP)



CS9391585 P2 SNCHZRAQA12\ Suncor Energy Inc. -- SNCSNCSNC SAPHEC-IC4SAP-SL SAP LOBPing Availability CRITICAL - 10.73.12.30: rta nan. lost 100% Attention commas replaced by dots.
CS9391539 P2 SNCHDIJPA12TOR01-SLSuncor Energy Inc. -- SNCSNCSNC SAPHEC-IC4SAP-SL SAP LOBPing Availability (Service check timed out after 15.01 seconds)
CS9391417 P2 SNCHTNAQA12TOR01-SLSuncor Energy Inc. -- SNCSNCSNC SAPHEC-IC4SAP-SL SAP LOBPing Availability CRITICAL - 10.73.12.78: rta nan. lost 100% Attention commas replaced by dots.
CS9391394 P2 BOSMABAPToyota Boshoku -- TBOTBOTBO IC4SAP-SL SAP LOBPing Availability CRITICAL - 100.126.48.17: rta nan. lost 100% Attention commas replaced by dots.


CHG0222335	AGEAS - RHEL 6.10 to  7.9  Upgrade on  svad1srv0    NOTE: systems will be down for 11 hours
AD1 - Development BOBJ	svad1srv0	10.6.1.18

SVAD1SRV0	10.6.1.18	10.92.99.117	A0EASG014XVM009

[root@svad1srv0 /]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux svad1srv0 2.6.32-754.35.1.el6.x86_64 #1 SMP Wed Sep 16 06:48:01 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Tue Oct 26 14:20:37 +08 2021
146.89.140.30:/storage/library  /storage/library        nfs     defaults        0       0
OK: No read-only file systems found
                     nfs    6.6T  3.6T  2.7T  58% /storage/library
                     nfs    6.0T  3.3T  2.4T  58% /sds
bash: timedatectl: command not found
/usr/sap/trans  *(rw,sync,no_root_squash)
You have mail in /var/mail/root

[root@svad1srv0 /]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 7.9 (Maipo)
Linux svad1srv0 3.10.0-1160.el7.x86_64 #1 SMP Tue Aug 18 14:50:17 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Tue Oct 26 23:14:25 +08 2021
146.89.140.30:/storage/library  /storage/library        nfs     defaults        0       0
OK: No read-only file systems found
hkg02ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  58% /sds
Warning: Ignoring the TZ variable. Reading the system's time zone setting only.

      Local time: Tue 2021-10-26 23:14:26 +08
  Universal time: Tue 2021-10-26 15:14:26 UTC
        RTC time: Tue 2021-10-26 15:14:26
       Time zone: Asia/Singapore (+08, +0800)
     NTP enabled: yes
NTP synchronized: yes
 RTC in local TZ: no
      DST active: n/a
/usr/sap/trans  *(rw,sync,no_root_squash)



CS9452215 AGEAS -- AGEP3 - MinorDisk Utilization / MINOR: Free 3986.16MB/13.61% (thresh @10.01:15%)SVAD1SRV0SQ-SAP-TRIO-B1
CS9452214 AGEAS -- AGEP2 - MajorService saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (thresh 1:)SVAD1SRV0SQ-SAP-TRIO-B1



[root@svad1srv0 tmp]$ knife status -c /etc/chef/client.rb | grep svad1srv0
649 hours ago, svad1srv0.imzcloud.ibmammsap.local, redhat 6.10.


[root@svad1srv0 tmp]$ df -hT /var
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                     ext4   31G   20G  9.3G  68% /

shutdown -rf now "CHG0222335"

preupg -u http://10.6.1.18:8099/submit/ -r /root/preupgrade-results/preupg_results-211026160109.tar.gz


redhat-upgrade-tool --iso /rhel-server-7.9-x86_64-dvd.iso --cleanup-post




CHG0222762	AGEAS - RHEL 6.10 to  7.9  Upgrade on  svmq1srv1 27-10-2021 12:30:00	27-10-2021 23:30:00		
A0EASG014XVM044		SVMQ1SRV1	10.6.2.42	10.70.110.42

[root@svmq1srv1 /]# cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux svmq1srv1 2.6.32-754.35.1.el6.x86_64 #1 SMP Wed Sep 16 06:48:01 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Wed Oct 27 15:09:33 +08 2021
//svtd1srv1/AFP /sftp/dev/opentext/ cifs _netdev,username=fileshare,password=Welcome-1,file_mode=0777,uid=otxdev,gid=sftp,dir_mode=0777 0 0
//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/OfficialReceipt cifs username=sftp,passwd=Security#1
//10.92.99.149/STRS_Output/SOA_DIVISION /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/OfficialReceipt cifs username=msgteam,password=Welcome@123 0 0
//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/SOA_DIVISION/ /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/STRS_Spool/  /usr/sap/OpenText_QA/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output/SOA_DIVISION /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Spool  /usr/sap/OpenText_QA/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output /usr/sap/OpenText_QA/STRS_Output cifs username=msgteam,password=Welcome@123 0 0
OK: No read-only file systems found
                     nfs    6.0T  3.3T  2.4T  58% /sds
bash: timedatectl: command not found
/sftp/dev   *(rw,sync,no_acl,no_root_squash)
/sftp/qas   *(rw,sync,no_root_squash)


Post upgrade
[root@svmq1srv1 /]# cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 7.9 (Maipo)
Linux svmq1srv1 3.10.0-1160.45.1.el7.x86_64 #1 SMP Fri Sep 24 10:17:16 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
Wed Oct 27 23:27:37 +08 2021
//svtd1srv1/AFP /sftp/dev/opentext/ cifs _netdev,username=fileshare,password=Welcome-1,file_mode=0777,uid=otxdev,gid=sftp,dir_mode=0777 0 0
##//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/OfficialReceipt cifs username=sftp,passwd=Security#1 0 0
##//10.92.99.149/STRS_Output/SOA_DIVISION /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
##//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/OfficialReceipt cifs username=msgteam,password=Welcome@123 0 0
##//10.92.99.149/STRS_Output /usr/sap/OpenText/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/SOA_DIVISION/ /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/STRS_Spool/  /usr/sap/OpenText_QA/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0
#//10.70.110.25/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output/SOA_DIVISION /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Spool  /usr/sap/OpenText_QA/STRS_Spool cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE cifs username=msgteam,password=Welcome@123 0 0
//SVTD1SRV1/STRS_Output /usr/sap/OpenText_QA/STRS_Output cifs username=msgteam,password=Welcome@123 0 0
OK: No read-only file systems found
      Local time: Wed 2021-10-27 23:27:37 +08
  Universal time: Wed 2021-10-27 15:27:37 UTC
        RTC time: Wed 2021-10-27 15:27:37
       Time zone: Asia/Singapore (+08, +0800)
     NTP enabled: yes
NTP synchronized: yes
 RTC in local TZ: no
      DST active: n/a
/sftp/dev   *(rw,sync,no_acl,no_root_squash)
/sftp/qas   *(rw,sync,no_root_squash)


-bash-4.1$ sudo knife status -c /etc/chef/client.rb | grep svmq1srv1
39 minutes ago, svmq1srv1.imzcloud.ibmammsap.local, redhat 6.10.


preupg_results-211027164427/result.html
The tarball with results is stored in '/root/preupgrade-results/preupg_results-211027164427.tar.gz' .
The latest assessment is stored in the '/root/preupgrade' directory.
Summary information:
We have found some critical issues. In-place upgrade or migration is not advised.
Read the file /root/preupgrade/result.html for more details.
Please ensure you have backed up your system and/or data
before doing a system upgrade to prevent loss of data in
case the upgrade fails and full re-install of the system
from installation media is needed.
Upload results to UI by the command:
e.g. preupg -u http://example.com:8099/submit/ -r /root/preupgrade-results/preupg_results-211027164427.tar.gz .

preupg -u http://10.6.2.42:8099/submit/ -r /root/preupgrade-results/preupg_results-211027164427.tar.gz


[root@svmq1srv1 /]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.9 (Maipo)
[root@svmq1srv1 /]# uname -a
Linux svmq1srv1 3.10.0-1160.el7.x86_64 #1 SMP Tue Aug 18 14:50:17 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux



/dev/sda1                   ext4      477M  174M  274M  39% /boot

grub2-install /dev/sda

cat >/etc/default/grub <<EOF
GRUB_TIMEOUT=5
GRUB_DISTRIBUTOR="\$(sed 's, release .*$,,g' /etc/system-release)"
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT="console"
GRUB_CMDLINE_LINUX="$(grep '^\s*kernel /vmlinuz-3' /boot/grub/grub.conf | head -1 | sed -r -e 's,^\s*kernel /vmlinuz\S+ ,,' -e 's,\<root=\S+ ,,' -e 's,\<ro ,,')"
GRUB_DISABLE_RECOVERY="true"
EOF


CS9490520	

Please create 2.2 TB NFS mount point on following server

ppldrqadmss01	10.207.65.24	192.168.50.39

create FS as "Backup_Refresh"  it should be NFS mount point which can be mounted in PEP & PES Database Host

PES - 

ppldcsbeccdb	10.207.65.43	192.168.50.226

PEP

ppldcprdccdb	10.207.64.16	192.168.40.25

This NFS required only for 5 days. 


backuprefvg
backup_ref_lv

 /dev/backuprefvg/backup_ref_lv




CS9492560
IA2ICCPRD  66.248.244.220
IA2ICCPRD2  66.248.244.222

PROD - LON02 (edited) 
DR - FRA 02



spsvmplmapp01	10.6.3.46
eyes
white_check_mark
raised_hands





spsvmplmapp01	10.6.3.46

[root@spsvmplmapp01 /]# sshd -T | grep "\(ciphers\|macs\|kexalgorithms\)"
gssapikexalgorithms gss-gex-sha1-,gss-group1-sha1-,gss-group14-sha1-
ciphers aes128-ctr,aes192-ctr,aes256-ctr
macs hmac-md5,hmac-sha1,umac-64@openssh.com,hmac-ripemd160,hmac-sha1-96,hmac-md5-96,hmac-sha2-256,hmac-sha2-512,hmac-ripemd160@openssh.com
kexalgorithms diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1

[root@spsvmplmapp01 /]# ssh-keygen -lf /etc/ssh/ssh_host_rsa_key.pub
2048 8a:cb:9c:80:4b:05:54:57:f1:93:38:47:0e:d2:ee:c4 /etc/ssh/ssh_host_rsa_key.pub (RSA)

[root@spsvmplmapp01 /]# nmap --script ssh-hostkey localhost

Starting Nmap 5.51 ( http://nmap.org ) at 2021-11-02 11:19 +08
Nmap scan report for localhost (127.0.0.1)
Host is up (0.0000050s latency).
Other addresses for localhost (not scanned): 127.0.0.1
Not shown: 994 closed ports
PORT     STATE SERVICE
22/tcp   open  ssh
| ssh-hostkey: 1024 d0:79:c5:88:06:35:e3:1b:fc:90:03:57:60:fc:ea:8b (DSA)
|_2048 8a:cb:9c:80:4b:05:54:57:f1:93:38:47:0e:d2:ee:c4 (RSA)
25/tcp   open  smtp
53/tcp   open  domain
111/tcp  open  rpcbind
631/tcp  open  ipp
2049/tcp open  nfs

Nmap done: 1 IP address (1 host up) scanned in 0.17 seconds

[gpay@spsvmplmapp01 ~]$ cat ~/.ssh/id_rsa.pub
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAsyg5u+XKGiKxeOdeqJtrP8kJUWFruyltNaTWlk8lQ8IZ4zIdpDOkyYMha/335ngAmc5EleEzoaQ8V8dFrJ47nbyzvSWuMD6RFb3PqH9GWjAnWwKO1TmkKTzeL+zsYTLa/lp1pz/MALobGEayJuVRnN+w7ZFjuAcS1Ely4dp+D0M8QSGQ+Svr5tPD7TUyenVcmrmMCofixRH2iGjSea/PX7IvhRLJMpgzrp+4X4ObzEh4gVyAZB3s7wZTrhxcr0G1wUMlzuA6GCzeEFxjCzN9Q6FIPbI4fQulN3k7f6mWZFWZDKOkek0SGQYVy6Dhm2DQPhQRbXzhkHoTCGa4x0VqfQ== gpay@spsvmplmapp01.eastwestageaslife.com

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


svmq1srv1	10.6.2.42 - non-prod
[root@svmq1srv1 /]# sshd -T | grep "\(ciphers\|macs\|kexalgorithms\)"

gssapikexalgorithms gss-gex-sha1-,gss-group1-sha1-,gss-group14-sha1-
ciphers aes128-ctr,aes192-ctr,aes256-ctr
macs hmac-sha1
kexalgorithms curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha256,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1

[root@svmq1srv1 /]# ssh-keygen -lf /etc/ssh/ssh_host_rsa_key.pub
2048 SHA256:E3BUwwYzqHmhDqcoGSWYzi8ERw8NTn4/pj+On4dnAfg no comment (RSA)
You have new mail in /var/mail/root

[root@svmq1srv1 /]# nmap --script ssh-hostkey localhost

Starting Nmap 6.40 ( http://nmap.org ) at 2021-11-02 11:20 +08
Nmap scan report for localhost (127.0.0.1)
Host is up (0.0000030s latency).
Other addresses for localhost (not scanned): 127.0.0.1
Not shown: 995 closed ports
PORT     STATE SERVICE
22/tcp   open  ssh
| ssh-hostkey: 1024 d0:79:c5:88:06:35:e3:1b:fc:90:03:57:60:fc:ea:8b (DSA)
| 2048 8a:cb:9c:80:4b:05:54:57:f1:93:38:47:0e:d2:ee:c4 (RSA)
|_256 e9:d0:bf:18:75:02:35:72:68:fb:d0:0c:c1:b9:7f:60 (ECDSA)
25/tcp   open  smtp
53/tcp   open  domain
111/tcp  open  rpcbind
2049/tcp open  nfs

Nmap done: 1 IP address (1 host up) scanned in 1.69 seconds

[gpay@svmq1srv1 ~]$ cat ~/.ssh/id_rsa.pub
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA3ET323HM2BMGxPjTl35dsoMJ/+JuENAGtB7TA31srTuJno3UDeOY2XTRrBpyOGXfcbKl2NPehMh1Ai2/YaJx/JkeEYrqPO4sB1xqROCziRXInZ2xE+2bSpp79/ivX/DN3fSXuFd9rygaDzcsQY0GlPb7k3bHtmM3VLvpofKuE5p3mY1kSPxVzWZf8tmE1L++QDeR5LokUsceUKzXcw0Hb6nM+2iH5k42kyShDWbup6eI3UBiHMRKsjV0gjNDaqnR1wU5ZY6jqfvnt6Ju5FMTXZ9GsTrQdQ+cwjwyoXmuJN7H9fw0fU4gwZXmz19j+vLHnfQd0Obj5WVZwZRXAxcM/Q== gpay@svmq1srv1


CS9545371	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.41: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP207
CS9545105	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.71: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP305A1
CS9545327	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.103.20: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP103
CS9545369	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.103.35: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP104
CS9544982	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.50: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP305AP
CS9545000	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.57: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP303A1
CS9545466	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.103.27: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP007
CS9545008	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.60: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP302A1
CS9545015	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.103.26: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP002
CS9544980	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.62: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP301A1
CS9544981	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.103.36: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP004
CS9545375	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.66: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP301DB
CS9545036	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.103.30: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP003
CS9545467	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.102.64: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP301AP
CS9545403	Arnoldo Mondadori Editore SpA -- ARM	P2 - Major	Ping Availability CRITICAL - 10.7.103.28: rta nan. lost 100% Attention commas replaced by dots.	ARMFKSAP001


IA2ICCPRD	66.248.244.220
IA2ICCPRD2	66.248.244.222
drtest ProKabbadi@123


CS9546303Amos Group Limited -- AM3P2 - MajorDisk Utilization / mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS9546208Amos Group Limited -- AM3P2 - MajorDisk Utilization /3rdPartySoftware/WDQ mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS9546201Amos Group Limited -- AM3P2 - MajorService saphostexec mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS9546198Amos Group Limited -- AM3P2 - MajorDisk Utilization /usr/sap/ccms mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS9546197Amos Group Limited -- AM3P2 - MajorInodes Utilization /boot mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system



CS9557713	Ping Availability CRITICAL - 10.134.10.76: rta nan. lost 100% Attention commas replaced by dots.
btk_btkf1qdb01 on  	ammsng01custesx065 to 
btk_btkf1qdb01
ammsng01custesx067.imzcloud.ibmammsap.local
No guest OS heartbeats are being received. Either the guest OS is not responding or VMware Tools is not configured correctly.

SL case :CS2553570

btkf1qdb01 , btks1qdb01



CS9567882
PROD Site - LON 02
DR Site - FRA 02

Validate connectivity to DR VMs from Jump Server

IA2ICCPRD  66.248.244.220
IA2ICCPRD2  66.248.244.222


ia2jumpserver	66.248.245.239	10.199.15.215	158.177.73.103



CS9581155	Celestica International Inc. -- CLC	P1 - Severe	Host Reboot CRITICAL: Uptime 2 minutes (thresh 30 min)	CLSDWQ01
CS9581154	Celestica International Inc. -- CLC	P1 - Severe	Host Reboot CRITICAL: Uptime 0 minutes (thresh 30 min)	CLSMGQ02
CS9581174	Celestica International Inc. -- CLC	P1 - Severe	Host Reboot CRITICAL: Uptime 4 minutes (thresh 30 min)	CLSMGQ01
CS9581404	Celestica International Inc. -- CLC	P1 - Severe	Host Reboot CRITICAL: Uptime 1 minutes (thresh 30 min)	CLSDWQ02


CHG0222700 Liberty Utilities (Canada) Corp -- LBUNON-PROD / LBU - (QA1 Part 1) SUSE Linux SP Update from 12 SP2 to SP4

LBUQW1AP01	10.139.16.6	10.140.16.8
LBUQL1AP01	10.139.32.68	10.140.32.52
LBUQL1DB01	10.139.32.63	10.140.32.31

CHG0222700 Patching in prog. Monitoring suppression not working


there is a n/w change for Bombardier CHG0218140

License renewal and JUNOS upgrade to version 19.4R3-S2 for firewall mon01-br3-brp-dl10g-vsrx	169.54.64.27

[root@br3psapdb40 ibmrmalik]# cat /etc/sysconfig/sbd|grep -i sbd_device
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
SBD_DEVICE="/dev/mapper/sbddisk1"
 
Due to the n/w fluctuation, fencing happened.


sbd -d /dev/mapper/sbddisk1 message br3psapdb40 clear

reboot   system boot  4.12.14-95.80-de Thu Nov  4 21:23 - 00:16  (02:52)

ibmrmali pts/0 146.89.142.229 Thu Nov 4 21:40 - 21:59 (00:19)
(unknown :0 :0 Thu Nov 4 21:24 still logged in
reboot system boot 4.12.14-95.80-de Thu Nov 4 21:23 - 00:29 (03:05)

Oct 30 19:46:39 br3psapdb40 systemd[122986]: Reached target Basic System.
Oct 30 19:46:39 br3psapdb40 systemd[122986]: Reached target Default.
Oct 30 19:46:39 br3psapdb40 systemd[122986]: Startup finished in 25ms.
Oct 30 19:46:39 br3psapdb40 systemd[1]: Started User Manager for UID 1001.
Nov  4 21:24:01 br3psapdb40 systemd[1]: systemd 228 running in system mode. (+PAM -AUDIT +SELINUX -IMA +APPARMOR -SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT -GNUTLS +ACL +XZ -LZ4 +SECCOMP +BLKID +ELFUTILS +KMOD -IDN)
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] Linux version 4.12.14-95.80-default (geeko@buildhost) (gcc version 4.8.5 (SUSE Linux) ) #1 SMP Thu Jul 15 18:19:59 UTC 2021 (db4c18a)
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-4.12.14-95.80-default root=/dev/mapper/system-root resume=/dev/system/swap splash=silent quiet showopts numa_balancing=disable intel_idle.max_cstate=1 processor.max_cstate=1 elevator=noop vmw_pvscsi.cmd_per_lun=254 vmw_pvscsi.ring_pages=32 transparent_hugepage=never
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] Disabled fast string operations
Nov  4 21:24:01 br3psapdb40 systemd[1]: Detected virtualization vmware.
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
Nov  4 21:24:01 br3psapdb40 systemd[1]: Detected architecture x86-64.
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'standard' format.
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] e820: BIOS-provided physical RAM map:
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009ebff] usable
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x000000000009ec00-0x000000000009ffff] reserved
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000000dc000-0x00000000000fffff] reserved
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfecffff] usable
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000bfed0000-0x00000000bfefefff] ACPI data
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000bfeff000-0x00000000bfefffff] ACPI NVS
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000bff00000-0x00000000bfffffff] usable
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000f0000000-0x00000000f7ffffff] reserved
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000fec00000-0x00000000fec0ffff] reserved
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000fee00000-0x00000000fee00fff] reserved
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x00000000fffe0000-0x00000000ffffffff] reserved
Nov  4 21:24:01 br3psapdb40 systemd[1]: Set hostname to <br3psapdb40>.
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000fcffffffff] usable
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] BIOS-e820: [mem 0x0000010000000000-0x000001013fffffff] usable
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] NX (Execute Disable) protection: active
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] SMBIOS 2.4 present.
Nov  4 21:24:01 br3psapdb40 systemd[1]: Configuration file /etc/systemd/system/sapinit.service.d/type.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] DMI: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 12/12/2018
Nov  4 21:24:01 br3psapdb40 kernel: [    0.000000] Hypervisor detected: VMware


Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [MAIN  ] Corosync Cluster Engine ('2.3.6'): started and ready to provide service.
Nov 04 21:24:13 [3722] br3psapdb40 corosync info    [MAIN  ] Corosync built-in features: debug testagents augeas systemd pie relro bindnow
Nov 04 21:24:13 [3722] br3psapdb40 corosync warning [MAIN  ] interface section bindnetaddr is used together with nodelist. Nodelist one is going to be used.
Nov 04 21:24:13 [3722] br3psapdb40 corosync warning [MAIN  ] Please migrate config file to nodelist.
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] Initializing transport (UDP/IP Unicast).
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] Initializing transmit/receive security (NSS) crypto: aes256 hash: sha1
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] The network interface [10.138.13.16] is now up.
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [SERV  ] Service engine loaded: corosync configuration map access [0]
Nov 04 21:24:13 [3722] br3psapdb40 corosync info    [QB    ] server name: cmap
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [SERV  ] Service engine loaded: corosync configuration service [1]
Nov 04 21:24:13 [3722] br3psapdb40 corosync info    [QB    ] server name: cfg
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [SERV  ] Service engine loaded: corosync cluster closed process group service v1.01 [2]
Nov 04 21:24:13 [3722] br3psapdb40 corosync info    [QB    ] server name: cpg
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [SERV  ] Service engine loaded: corosync profile loading service [4]
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [QUORUM] Using quorum provider corosync_votequorum
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [VOTEQ ] Waiting for all cluster members. Current votes: 1 expected_votes: 2
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [SERV  ] Service engine loaded: corosync vote quorum service v1.0 [5]
Nov 04 21:24:13 [3722] br3psapdb40 corosync info    [QB    ] server name: votequorum
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [SERV  ] Service engine loaded: corosync cluster quorum service v0.1 [3]
Nov 04 21:24:13 [3722] br3psapdb40 corosync info    [QB    ] server name: quorum
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] adding new UDPU member {10.138.13.16}
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] adding new UDPU member {10.138.13.23}
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] A new membership (10.138.13.16:260) was formed. Members joined: 176819472
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] A new membership (10.138.13.16:264) was formed. Members joined: 176819479
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [VOTEQ ] Waiting for all cluster members. Current votes: 1 expected_votes: 2
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [VOTEQ ] Waiting for all cluster members. Current votes: 1 expected_votes: 2
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [QUORUM] This node is within the primary component and will provide service.
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [QUORUM] Members[2]: 176819472 176819479
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [MAIN  ] Completed service synchronization, ready to provide service.

[root@br3psapdb41 cluster]#
Nov 04 21:23:25 [3908] br3psapdb41 corosync notice  [TOTEM ] A processor failed, forming new configuration.
Nov 04 21:23:39 [3908] br3psapdb41 corosync notice  [TOTEM ] Failed to receive the leave message. failed: 176819472
Nov 04 21:23:44 [4834] br3psapdb41      attrd:     info: attrd_peer_update:     Setting hana_p4h_sync_state[br3psapdb40]: (null) -> SFAIL from br3psapdb41
SAPHana(rsc_SAPHana_P4H_HDB40)[32966]:  2021/11/04_21:23:44 INFO: ACT site=br3psapdb41, setting SFAIL for secondary (2) - srRc=124
Nov 04 21:23:46 [4834] br3psapdb41      attrd:   notice: write_attribute:       Cannot update hana_p4h_sync_state[br3psapdb40]=SFAIL because peer UUID not known (will retry if learned)
SAPHana(rsc_SAPHana_P4H_HDB40)[39737]:  2021/11/04_21:24:49 INFO: ACT site=br3psapdb41, setting SFAIL for secondary (5) - srRc=11 lss=4
SAPHana(rsc_SAPHana_P4H_HDB40)[45005]:  2021/11/04_21:25:54 INFO: ACT site=br3psapdb41, setting SFAIL for secondary (5) - srRc=11 lss=4
SAPHana(rsc_SAPHana_P4H_HDB40)[54800]:  2021/11/04_21:26:59 INFO: ACT site=br3psapdb41, setting SFAIL for secondary (5) - srRc=11 lss=4
SAPHana(rsc_SAPHana_P4H_HDB40)[65517]:  2021/11/04_21:28:04 INFO: ACT site=br3psapdb41, setting SFAIL for secondary (5) - srRc=11 lss=4


[root@br3psapdb40 cluster]# zcat corosync.log-20211104.gz |zgrep -i membership
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] A new membership (10.138.13.16:260) was formed. Members joined: 176819472
Nov 04 21:24:13 [3722] br3psapdb40 corosync notice  [TOTEM ] A new membership (10.138.13.16:264) was formed. Members joined: 176819479
You have new mail in /var/mail/root

Post a network fluctuation, SLES cluster lost communication between the nodes.
ref https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/A_Linux_node_in_HA_Cluster_was_fenced_after_%22A_processor_failed%2C_forming_new_configuration%22_event 
exact match of the situation
RCA RCA0006286


FRA
TQAERPPRD1	10.7.1.17
TQABOPRD1	10.7.1.27


CHG0222701	NON-PROD / LBU - (QA1 Part 2) SUSE Linux SP Update from 12 SP2 to SP4	06-11-2021 06:00:00	06-11-2021 14:00:00
Host Name	 IFN  IP               	CFN IP
======================================
LBUQZ1AP01	10.139.32.76	10.140.32.22	Sandeep
LBUQZ1AP02	10.139.32.55	10.140.32.65	Sandeep
LBUQZ1AP03	10.139.32.32	10.140.32.24	Sandeep

LBUQA1AP01	10.139.32.61	10.140.32.69	Ravi
LBUQA1DB01	10.139.32.34	10.140.32.58	Ravi
LBUQF1AP01	10.139.32.70	10.140.32.56	Ravi



Please check the Port 3300 is allowed to accept traffic from below source IPs. 

Source - 10.250.17.42/10.250.17.34/10.250.17.180
Destination - 10.250.17.24
Port â€“ 3300

Source
DLTHQGGA1	10.4.5.42	10.250.17.42
DLTHQGGAT	10.4.5.34	10.250.17.34	
DLTQEGGAT	10.4.5.176	10.250.17.180

Destination
DLTHSGGAT	10.4.5.24	10.250.17.24



[ibmrmalik@s4hprdmock protocolfiles]$ cat cmas_logscanner_checklog_filters.protocol-2021-11-11-08-11-30
CRITICAL Errors in messages (tag 6:CRITICAL_Syslog-Authentication)
Nov 11 07:51:10 s4hprdmock systemd[1]: systemd-hibernate-resume@dev-rootvg-paging00.service: Job systemd-hibernate-resume@dev-rootvg-paging00.service/start failed with result 'dependency'.

Nov 11 09:10:47 s4hprdmock sshd[119152]: /home/timagent/.ssh/authorized_keys:2: Authentication tried for timagent with correct key but not from a permitted host (host=169.55.28.70, ip=169.55.28.70, required=169.47.206.52,169.47.206.53,169.47.206.54).


10.207.61.123 10.207.61.113 10.207.61.187 10.207.61.202 10.207.61.60 100.64.4.2313:31
10.207.61.114 10.207.61.203 10.207.61.77


svtd1srv0 & svtd1srv1 - to be cloned and should be up and running until the newly cloned VMs is ready.
10:29
AGESVTQ2SRV0 & AGESVTQ2SRV1 - newly built VM's - with different IP's.

ProKabbadi@123

administrator
svtd1srv1

May55now#123456



Host Name	                 PG Name
co3pueccpdb1	co3 - City of Toledo - PG1
co3fieccpdb1	        co3 - City of Toledo - PG1
co3puucespdb1	co3 - City of Toledo - PG1
co3fibwapdb1	co3 - City of Toledo - PG1
	
co3fibwjpdb1	co3 - City of Toledo - PG2
co3shsmapdb1	co3 - City of Toledo - PG2
co3shsmjpdb1	co3 - City of Toledo - PG2
	co3pusccpap1	co3 - City of Toledo - PG2



1- Account Name - Wakefern Food Corporation -- WKF
2- Production site - Washington 04 (3.x)
3- DR site - Dallas 13 (3.x)
4-  RPO - 30 Minutes
5- List of VMs that are requested to test. - Server List Enclosed


wkfpr1ap02
WKF - Wakefern Food - PG2
WKFDAL13DR425


wkf_wkfpr1ap05
WKF - Wakefern Food - PG4
WKFDAL13DR425



 wkfpp1db01
 WKFDAL13DR425
WKF - Wakefern Food - PG2


 wkfpf1db01
WKFDAL13DR425
WKF - Wakefern Food - PG1


wkfpf1db01

wkfpr1ap01 didnt start in DR

RP1 
wkfpf1db01  Placeholder VM for the protected VM 'wkfpf1db01' is missing.

cleanup error RP1
Placeholder VM for the protected VM 'wkfpf1db01' is missing.

RP2
wkfpr1ap02	 Placeholder VM for the protected VM 'wkfpr1ap02' is missing.
wkfpp1db01	 Placeholder VM for the protected VM 'wkfpp1db01' is missing.	WKFDAL13DR425	PG2

Cleanup of RP2 
Placeholder VM for the protected VM 'wkfpr1ap02' is missing.
 Placeholder VM for the protected VM 'wkfpp1db01' is missing.

RP3
wkfpr1ap01	 Recovery failed because the Virtual Machine is no longer configured for replication.	

Cleanup of RP3
Cleanup failed because the Virtual Machine is no longer configured for replication.

RP4
wkf_wkfpr1ap05	 Placeholder VM for the protected VM 'wkf_wkfpr1ap05' is missing.	

cleanup RP4
wkf_wkfpe1ap07  wkf_wkfpe1ap07 replication error: No storage is found for datastore path '[] wkf_wkfpe1ap07/wkf_wkfpe1ap07_2.vmdk'.


wkf_wkfpe1ap07
WKFDAL13DR425
WKF - Wakefern Food - PG4
 The storage for datastore path '[WKFDAL13DR425] wkf_wkfpe1ap07/hbrdisk.RDID-693dd062-995c-49b1-b076-316d26f99acc.44291624.209877085946264.vmdk' is locked.

Issue with  
wkfpf1db01	WKF - Wakefern Food - PG1
wkfpp1db01	WKF - Wakefern Food - PG2
wkfpr1ap01	PG3	
wkfpr1ap02	PG2  Placeholder Create Error: Unable to protect VM 'wkfpr1ap02' due to inventory conflicts. The resource pool and folder belong to separate datacenters.
wkf_wkfpe1ap07	PG4  Placeholder Create Error: Unable to protect VM 'wkf_wkfpe1ap07' due to inventory conflicts. The resource pool and folder belong to separate datacenters.
wkf_wkfpr1ap05	PG4  Placeholder Create Error: Unable to protect VM 'wkf_wkfpr1ap05' due to inventory conflicts. The resource pool and folder belong to separate datacenters.





CS9692530
pn8us7leccp3 pn8us7leccp3h
Incident#: CS9692530
Client Name:  Panasonic NA
CDIR:  PN8
Issue Description: Host Reboot CRITICAL: Uptime 1 minutes (thresh 30 min)
Data Center:  WDC04
Asset Name:PN8US7LECCP3

RCA Ticket - PRB0057444

[root@pn8us7ldbcp3 ibmrmalik]$ last reboot
reboot   system boot  4.12.14-95.80-de Fri Nov 12 19:23 - 22:07  (02:44)

[root@pn8us7ldbcp3 log]$ cat messages |grep -i Pingack
Nov 12 15:07:54 pn8us7ldbcp3 kernel: [7131842.606671] drbd r1 pn8us7ldbcp3h: PingAck did not arrive in time.
Nov 12 15:07:57 pn8us7ldbcp3 kernel: [7131845.934667] drbd r0 pn8us7ldbcp3h: PingAck did not arrive in time.
Nov 12 15:07:58 pn8us7ldbcp3 kernel: [7131846.958678] drbd r2 pn8us7ldbcp3h: PingAck did not arrive in time.

[root@pn8us7ldbcp3 log]$ zcat messages.9.gz |zgrep -i "Nov 12 15:*" |zgrep -i fail
Nov 12 15:07:54 pn8us7ldbcp3 kernel: [7131842.606958] drbd r1 pn8us7ldbcp3h: conn( Connected -> NetworkFailure ) peer( Secondary -> Unknown )
Nov 12 15:07:54 pn8us7ldbcp3 kernel: [7131842.641189] drbd r1 pn8us7ldbcp3h: conn( NetworkFailure -> Unconnected )
Nov 12 15:07:57 pn8us7ldbcp3 kernel: [7131845.934943] drbd r0 pn8us7ldbcp3h: conn( Connected -> NetworkFailure ) peer( Secondary -> Unknown )
Nov 12 15:07:57 pn8us7ldbcp3 kernel: [7131845.970206] drbd r0 pn8us7ldbcp3h: conn( NetworkFailure -> Unconnected )
Nov 12 15:07:58 pn8us7ldbcp3 kernel: [7131846.958970] drbd r2 pn8us7ldbcp3h: conn( Connected -> NetworkFailure ) peer( Secondary -> Unknown )
Nov 12 15:07:58 pn8us7ldbcp3 kernel: [7131847.014014] drbd r2 pn8us7ldbcp3h: conn( NetworkFailure -> Unconnected )



pn8us7ldbcp3 10.129.32.26
pn8us7ldbcp3h 10.129.32.27

Nov 12 19:18:28 [105188] pn8us7ldbcp3       crmd:    error: process_lrm_event:  Result of monitor operation for rsc_db2 on pn8us7ldbcp3: Timed Out | call=239 key=rsc_db2_monitor_20000 timeout=300000ms
Nov 12 19:18:28 [105188] pn8us7ldbcp3       crmd:     info: process_graph_event:        Detected action (9.99) rsc_db2_monitor_20000.239=unknown error: failed
Nov 12 19:18:28 [105187] pn8us7ldbcp3    pengine:  warning: unpack_rsc_op_failure:      Processing failed monitor of rsc_db2 on pn8us7ldbcp3: unknown error | rc=1
Nov 12 19:18:28 [105187] pn8us7ldbcp3    pengine:  warning: unpack_rsc_op_failure:      Processing failed monitor of rsc_db2 on pn8us7ldbcp3: unknown error | rc=1
DB2(rsc_db2)[66513]:    2021/11/12_20:20:59 ERROR: DB2 database db2cp3(0)/cp3 didn't start: SQL1273N  An operation reading the logs on database "CP3" cannot continue
Nov 12 20:20:59 [60280] pn8us7ldbcp3       crmd:   notice: process_lrm_event:   Result of start operation for rsc_db2 on pn8us7ldbcp3: 1 (unknown error) | call=237 key=rsc_db2_start_0 confirmed=true cib-update=222
DB2(rsc_db2)[123703]:   2021/11/12_20:27:25 ERROR: DB2 database db2cp3(0)/cp3 didn't start: SQL1273N  An operation reading the logs on database "CP3" cannot continue
Nov 12 20:27:25 [60280] pn8us7ldbcp3       crmd:   notice: process_lrm_event:   Result of start operation for rsc_db2 on pn8us7ldbcp3: 1 (unknown error) | call=281 key=rsc_db2_start_0 confirmed=true cib-update=279
DB2(rsc_db2)[1352]:     2021/11/12_20:27:52 ERROR: DB2 database db2cp3(0)/cp3 didn't start: SQL1273N  An operation reading the logs on database "CP3" cannot continue
Nov 12 20:27:52 [60280] pn8us7ldbcp3       crmd:   notice: process_lrm_event:   Result of start operation for rsc_db2 on pn8us7ldbcp3: 1 (unknown error) | call=450 key=rsc_db2_start_0 confirmed=true cib-update=512
DB2(rsc_db2)[32838]:    2021/11/12_20:31:00 ERROR: DB2 database db2cp3(0)/cp3 didn't start: SQL1273N  An operation reading the logs on database "CP3" cannot continue
Nov 12 20:31:00 [60280] pn8us7ldbcp3       crmd:   notice: process_lrm_event:   Result of start operation for rsc_db2 on pn8us7ldbcp3: 1 (unknown error) | call=619 key=rsc_db2_start_0 confirmed=true cib-update=745
Filesystem(fs-db2cp3_db2_software)[35546]:      2021/11/12_20:31:04 ERROR: Couldn't unmount /db2/db2cp3/db2_software; trying cleanup with TERM
DB2(rsc_db2)[40615]:    2021/11/12_20:31:51 ERROR: DB2 database db2cp3(0)/cp3 didn't start: SQL1273N  An operation reading the logs on database "CP3" cannot continue
Nov 12 20:31:51 [60280] pn8us7ldbcp3       crmd:   notice: process_lrm_event:   Result of start operation for rsc_db2 on pn8us7ldbcp3: 1 (unknown error) | call=788 key=rsc_db2_start_0 confirmed=true cib-update=978
DB2(rsc_db2)[59182]:    2021/11/12_20:34:56 ERROR: DB2 database db2cp3(0)/cp3 didn't start: SQL1273N  An operation reading the logs on database "CP3" cannot continue
Nov 12 20:34:56 [60280] pn8us7ldbcp3       crmd:   notice: process_lrm_event:   Result of start operation for rsc_db2 on pn8us7ldbcp3: 1 (unknown error) | call=1097 key=rsc_db2_start_0 confirmed=true cib-update=0
[root@pn8us7ldbcp3 cluster]$



CS9693482 ping availability critical
SL ticket CS2567809	
ALL Hosts are in not responding state in DAL09-SL

CHG0224582 Nw change + 3.x network team failed over the VPN services from primary aggregator to secondary aggregator after which the VPN process were responding
Then 3.x network team corrected tunnel Ip address.

CS9694329	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.12: rta nan. lost 100% Attention commas replaced by dots.	SAPCRMQA
CS9694798	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - ttajcaphdb: rta nan. lost 100% Attention commas replaced by dots.	TTAJCAPHDB
CS9694261	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.62.14: rta nan. lost 100% Attention commas replaced by dots.	TSLBWDEVDB
CS9694460	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.46: rta nan. lost 100% Attention commas replaced by dots.	SAPAPP32
CS9694245	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.85: rta nan. lost 100% Attention commas replaced by dots.	SAPAPP29
CS9695083	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.235: rta nan. lost 100% Attention commas replaced by dots.	SAPAPP33
CS9694880	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.62.25: rta nan. lost 100% Attention commas replaced by dots.	ASDDEV
CS9694929	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.62.14: rta nan. lost 100% Attention commas replaced by dots.	TSLBWDEVDB
CS9694355	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.62.13: rta nan. lost 100% Attention commas replaced by dots.	TSLEECDEVDB
CS9694466	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.185: rta nan. lost 100% Attention commas replaced by dots.	TSLEECQA01
CS9694527	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.70: rta nan. lost 100% Attention commas replaced by dots.	SAPAPP18
CS9694287	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.77: rta nan. lost 100% Attention commas replaced by dots.	EWMAPP1
CS9694419	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.215: rta nan. lost 100% Attention commas replaced by dots.	SAPAPP19
CS9694537	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.11: rta nan. lost 100% Attention commas replaced by dots.	EWMQA
CS9694273	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.185: rta nan. lost 100% Attention commas replaced by dots.	TSLEECQA01
CS9694990	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.202: rta nan. lost 100% Attention commas replaced by dots.	SAPCRMAPP4-HA
CS9694248	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.31: rta nan. lost 100% Attention commas replaced by dots.	BIPRDAPP3
CS9695068	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.36: rta nan. lost 100% Attention commas replaced by dots.	TSCMLPRD
CS9694948	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.173: rta nan. lost 100% Attention commas replaced by dots.	ECCTEST01
CS9694240	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.19: rta nan. lost 100% Attention commas replaced by dots.	ECCTEST
CS9695060	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.64: rta nan. lost 100% Attention commas replaced by dots.	S4HPRDMOCKDB
CS9694760	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.72: rta nan. lost 100% Attention commas replaced by dots.	TTAR3DEV
CS9694996	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.95: rta nan. lost 100% Attention commas replaced by dots.	SAPAPP30
CS9694510	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.235: rta nan. lost 100% Attention commas replaced by dots.	SAPAPP33
CS9694757	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.31: rta nan. lost 100% Attention commas replaced by dots.	BIPRDAPP3
CS9694852	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.29: rta nan. lost 100% Attention commas replaced by dots.	ADSPRDS
CS9694969	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.62.21: rta nan. lost 100% Attention commas replaced by dots.	SAPBIDEV
CS9694403	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.61.28: rta nan. lost 100% Attention commas replaced by dots.	BIPRDAPP1
CS9694253	Tata Steel Limited -- TTA	P2 - Major	Ping Availability CRITICAL - 10.207.63.14: rta nan. lost 100% Attention commas replaced by dots.	TSLEECQA

problem seems to be with na-seiaggregator-vyatta001, VPN process is not responding and it affects Nagios


So team, we found two issues after change# CHG0224582
On aggregator device na-seiaggregator-vyatta001 the VPN process was probably some time after we had validated it was up and running and it was not coming back up, in order to solve it we had to fail over to na-seiaggregator-vyatta002.
As part of the same change, failover happened between dal09INFRApod4vyatta001 and dal09INFRApod4vyatta002, after that, communication issues were reported for everything in DAL09 POD4, so after taking a better look we found out that the IP the tunnel between POD1 and POD4 in DAL09 had been incorrectly set up using the physical IP of dal09INFRApod4vyatta002 instead of the virtual one both devices share, which caused the tunnel to go down when traffic was moved to dal09INFRApod4vyatta001. IP configuration was corrected in vSRX and vyatta and teams confirmed communication was back up.

CS9730750
169.60.136.228  FRDAL13ASCS01.prdcloud.fms.ibmcloud.com FRDAL13ASCS01

/dev/mapper/sapkpdvg-kpdhomeadm             xfs      1014M   33M  982M   4% /home/kpdadm
/dev/mapper/sapkpdvg-hostctrl               xfs       2.5G  676M  1.8G  28% /usr/sap/hostctrl
/dev/mapper/sapkpdvg-kpdsap                 xfs        64G   11G   54G  17% /usr/sap/KPD
/dev/mapper/sapkpdvg-kpdcron                xfs      1014M   33M  982M   4% /var/spool/cron/crontabs
/dev/mapper/sapkpdvg-kpdhomesapadm          xfs      1014M   33M  982M   4% /home/sapadm
/dev/mapper/mpath1-part2                    xfs        20G   16G  4.1G  80% /usr/sap/trans



FRDAL13ASCS01:/etc/iscsi/send_targets # cat /etc/sysconfig/sbd | grep DEVICE
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
SBD_DEVICE="/dev/mapper/mpath1-part3"


AGEAS upgrade from RHEL 6 to 7

spsvmplmapp01	10.6.3.46	10.70.111.46 		SFTP prod	A0EASG014XVM045
Summary information:
We have found some critical issues. In-place upgrade or migration is not advised.
Read the file /root/preupgrade/result.html for more details.
Please ensure you have backed up your system and/or data
before doing a system upgrade to prevent loss of data in
case the upgrade fails and full re-install of the system
from installation media is needed.
Upload results to UI by the command:
e.g. preupg -u http://example.com:8099/submit/ -r /root/preupgrade-results/preupg_results-211117165614.tar.gz .
You have mail in /var/spool/mail/root
[root@spsvmplmapp01 ~]#

preupg -u http://10.6.3.46:8099/submit/ -r /root/preupgrade-results/preupg_results-211118120834.tar.gz

The following packages from the 'Desktop' yum group, which provides the GNOME desktop environment, were detected to be installed on your system: control-center gdm gdm-user-switch-applet gnome-panel gnome-power-manager gnome-screensaver gnome-session gnome-terminal gvfs-archive gvfs-fuse gvfs-smb metacity nautilus notification-daemon polkit-gnome xdg-user-dirs-gtk yelp control-center-extra eog gnome-applets gnome-media gnome-packagekit gnome-vfs2-smb gok orca vino

The following packages from the 'KDE Desktop' yum group, which provides the KDE desktop environment, were detected to be installed on your system: ibus-qt

Removed:
  control-center.x86_64 1:2.28.1-41.el6         control-center-extra.x86_64 1:2.28.1-41.el6      eog.x86_64 0:2.28.2-4.el6                    gdm.x86_64 1:2.30.4-69.el6                gdm-user-switch-applet.x86_64 1:2.30.4-69.el6
  gnome-applets.x86_64 1:2.28.0-7.el6           gnome-media.x86_64 0:2.29.91-6.el6               gnome-packagekit.x86_64 0:2.28.3-10.el6      gnome-panel.x86_64 0:2.30.2-16.el6        gnome-power-manager.x86_64 0:2.28.3-7.el6_4
  gnome-screensaver.x86_64 0:2.28.3-28.el6      gnome-session.x86_64 0:2.28.0-24.el6             gnome-terminal.x86_64 0:2.31.3-11.el6_6      gnome-vfs2-smb.x86_64 0:2.24.2-8.el6      gok.x86_64 0:2.28.1-5.el6
  gvfs-archive.x86_64 0:1.4.3-27.el6            gvfs-fuse.x86_64 0:1.4.3-27.el6                  gvfs-smb.x86_64 0:1.4.3-27.el6               metacity.x86_64 0:2.28.0-23.el6           nautilus.x86_64 0:2.28.4-26.el6
  notification-daemon.x86_64 0:0.5.0-1.el6      orca.x86_64 0:2.28.2-1.el6                       polkit-gnome.x86_64 0:0.96-4.el6             vino.x86_64 0:2.28.1-10.el6               xdg-user-dirs-gtk.x86_64 0:0.8-7.el6
  yelp.x86_64 0:2.28.1-17.el6_3

Dependency Removed:
  abrt-desktop.x86_64 0:2.0.8-44.el6                     abrt-gui.x86_64 0:2.0.8-44.el6                               bluez.x86_64 0:4.66-2.el6_9                              brasero-nautilus.x86_64 0:2.30.3-3.el6
  compiz-gnome.x86_64 0:0.8.2-24.el6                     desktop-effects.x86_64 0:0.8.4-7.el6                         evince.x86_64 0:2.28.2-20.el6                            file-roller.x86_64 0:2.28.2-7.el6
  gedit.x86_64 1:2.28.4-4.el6                            gnome-bluetooth.x86_64 0:2.28.6-8.el6                        gnome-disk-utility.x86_64 0:2.30.1-3.el6                 gnome-media-libs.x86_64 0:2.29.91-6.el6
  gnome-session-xsession.x86_64 0:2.28.0-24.el6          gnome-settings-daemon.x86_64 0:2.28.2-39.el6                 gnome-user-share.x86_64 0:2.28.2-3.el6                   ibus.x86_64 0:1.3.4-10.el6
  ibus-anthy.x86_64 0:1.2.1-3.el6                        ibus-chewing.x86_64 0:1.3.5.20100714-4.el6                   ibus-gtk.x86_64 0:1.3.4-10.el6                           ibus-hangul.x86_64 0:1.3.0.20100329-6.el6
  ibus-m17n.x86_64 0:1.3.0-2.el6                         ibus-pinyin.x86_64 0:1.3.8-1.el6                             ibus-rawcode.x86_64 0:1.3.0.20100421-2.el6               ibus-sayura.x86_64 0:1.2.99.20100209-3.el6
  ibus-table.noarch 0:1.2.0.20100111-5.el6               ibus-table-additional.noarch 0:1.2.0.20100111-5.el6          im-chooser.x86_64 0:1.3.1-3.el6                          imsettings.x86_64 0:0.108.0-3.6.el6
  libnotify.x86_64 0:0.5.0-1.el6                         nautilus-extensions.x86_64 0:2.28.4-26.el6                   nautilus-open-terminal.x86_64 0:0.17-4.el6               nautilus-sendto.x86_64 0:2.28.2-4.el6
  notify-python.x86_64 0:0.1.1-10.el6                    plymouth-gdm-hooks.x86_64 0:0.8.3-29.el6                     pulseaudio-gdm-hooks.x86_64 0:0.9.21-26.el6              pulseaudio-module-bluetooth.x86_64 0:0.9.21-26.el6
  rhythmbox.x86_64 0:0.12.8-1.el6                        seahorse.x86_64 0:2.28.1-4.el6                               sound-juicer.x86_64 0:2.28.1-6.el6                       subscription-manager-gui.x86_64 0:1.20.10-8.el6
  system-config-kdump.noarch 0:2.0.5-19.el6              system-config-printer.x86_64 0:1.1.16-26.el6                 system-config-services.noarch 0:0.99.45-1.el6.3          system-config-services-docs.noarch 0:1.1.8-1.el6
  system-config-users.noarch 0:1.2.106-9.el6             system-config-users-docs.noarch 0:1.0.8-2.el6                totem.x86_64 0:2.28.6-4.el6                              totem-nautilus.x86_64 0:2.28.6-4.el6
  zenity.x86_64 0:2.28.0-1.el6


preupg -u http://10.6.3.46:8099/submit/ -r /root/preupgrade-results/preupg_results-211117165614.tar.gz

AQ1 - Quality BOBI	svaq1srv0	10.6.2.18	BOBJ QA system	A0EASG014XVM021
Removed:
  control-center.x86_64 1:2.28.1-41.el6         control-center-extra.x86_64 1:2.28.1-41.el6      eog.x86_64 0:2.28.2-4.el6                    gdm.x86_64 1:2.30.4-69.el6                gdm-user-switch-applet.x86_64 1:2.30.4-69.el6
  gnome-applets.x86_64 1:2.28.0-7.el6           gnome-media.x86_64 0:2.29.91-6.el6               gnome-packagekit.x86_64 0:2.28.3-10.el6      gnome-panel.x86_64 0:2.30.2-16.el6        gnome-power-manager.x86_64 0:2.28.3-7.el6_4
  gnome-screensaver.x86_64 0:2.28.3-28.el6      gnome-session.x86_64 0:2.28.0-24.el6             gnome-terminal.x86_64 0:2.31.3-11.el6_6      gnome-vfs2-smb.x86_64 0:2.24.2-8.el6      gok.x86_64 0:2.28.1-5.el6
  gvfs-archive.x86_64 0:1.4.3-27.el6            gvfs-fuse.x86_64 0:1.4.3-27.el6                  gvfs-smb.x86_64 0:1.4.3-27.el6               metacity.x86_64 0:2.28.0-23.el6           nautilus.x86_64 0:2.28.4-26.el6
  notification-daemon.x86_64 0:0.5.0-1.el6      orca.x86_64 0:2.28.2-1.el6                       polkit-gnome.x86_64 0:0.96-4.el6             vino.x86_64 0:2.28.1-10.el6               xdg-user-dirs-gtk.x86_64 0:0.8-7.el6
  yelp.x86_64 0:2.28.1-17.el6_3

Dependency Removed:
  abrt-desktop.x86_64 0:2.0.8-44.el6                          abrt-gui.x86_64 0:2.0.8-44.el6                        bluez.x86_64 0:4.66-2.el6_9                                  brasero-nautilus.x86_64 0:2.30.3-3.el6
  compiz-gnome.x86_64 0:0.8.2-24.el6                          desktop-effects.x86_64 0:0.8.4-7.el6                  evince.x86_64 0:2.28.2-20.el6                                file-roller.x86_64 0:2.28.2-7.el6
  gedit.x86_64 1:2.28.4-4.el6                                 gnome-bluetooth.x86_64 0:2.28.6-8.el6                 gnome-disk-utility.x86_64 0:2.30.1-3.el6                     gnome-media-libs.x86_64 0:2.29.91-6.el6
  gnome-session-xsession.x86_64 0:2.28.0-24.el6               gnome-settings-daemon.x86_64 0:2.28.2-39.el6          gnome-user-share.x86_64 0:2.28.2-3.el6                       ibus.x86_64 0:1.3.4-10.el6
  ibus-anthy.x86_64 0:1.2.1-3.el6                             ibus-chewing.x86_64 0:1.3.5.20100714-4.el6            ibus-gtk.x86_64 0:1.3.4-10.el6                               ibus-hangul.x86_64 0:1.3.0.20100329-6.el6
  ibus-m17n.x86_64 0:1.3.0-2.el6                              ibus-pinyin.x86_64 0:1.3.8-1.el6                      ibus-qt.x86_64 0:1.3.0-2.el6                                 ibus-rawcode.x86_64 0:1.3.0.20100421-2.el6
  ibus-sayura.x86_64 0:1.2.99.20100209-3.el6                  ibus-table.noarch 0:1.2.0.20100111-5.el6              ibus-table-additional.noarch 0:1.2.0.20100111-5.el6          im-chooser.x86_64 0:1.3.1-3.el6
  imsettings.x86_64 0:0.108.0-3.6.el6                         libnotify.x86_64 0:0.5.0-1.el6                        nautilus-extensions.x86_64 0:2.28.4-26.el6                   nautilus-open-terminal.x86_64 0:0.17-4.el6
  nautilus-sendto.x86_64 0:2.28.2-4.el6                       notify-python.x86_64 0:0.1.1-10.el6                   plymouth-gdm-hooks.x86_64 0:0.8.3-29.el6                     pulseaudio-gdm-hooks.x86_64 0:0.9.21-26.el6
  pulseaudio-module-bluetooth.x86_64 0:0.9.21-26.el6          rhythmbox.x86_64 0:0.12.8-1.el6                       seahorse.x86_64 0:2.28.1-4.el6                               sound-juicer.x86_64 0:2.28.1-6.el6
  subscription-manager-gui.x86_64 0:1.20.10-8.el6             system-config-kdump.noarch 0:2.0.5-19.el6             system-config-printer.x86_64 0:1.1.16-26.el6                 system-config-services.noarch 0:0.99.45-1.el6.3
  system-config-services-docs.noarch 0:1.1.8-1.el6            system-config-users.noarch 0:1.2.106-9.el6            system-config-users-docs.noarch 0:1.0.8-2.el6                totem.x86_64 0:2.28.6-4.el6
  totem-nautilus.x86_64 0:2.28.6-4.el6                        zenity.x86_64 0:2.28.0-1.el6






CS9656700       TSM: sng01ammtsm003.ibmammsap.local ANR0530W Transaction failed for session 8544783 for node AGE_SPSVPPALASE01_FIL (Sybase-TSM API) - internal server error dete

CS9580451      TSM: dal09ammtsm001.ibmammsap.local ANR2578W Schedule OS_INCR_1800 in domain DAL_D_DOM for node LSP_LZABJPRD0_FIL has missed its scheduled start up window.~
CS9580449      TSM: dal09ammtsm001.ibmammsap.local ANR2578W Schedule OS_INCR_1800 in domain DAL_D_DOM for node LSP_LZABJDEV0_FIL has missed its scheduled start up window.~
CS9580448      TSM: dal09ammtsm001.ibmammsap.local ANR2578W Schedule OS_INCR_1800 in domain DAL_D_DOM for node LSP_LZABJSBX0_FIL has missed its scheduled start up window.~	
CS9505611       TSM: AGESVTQ2SRV1 TSM: sng01ammtsm005.ibmammsap.local ANE4007E Error processing '\\agesvtq2srv1\c$\Windows\System32\LogFiles\WMI\NtfsLog.etl': access to the obj
CS9496792       TSM: AGESVTQ2SRV0 TSM: sng01ammtsm005.ibmammsap.local ANE4007E Error processing '\\agesvtq2srv0\c$\Windows\System32\LogFiles\WMI\NtfsLog.etl': access to the obj
CS9490298       TSM: LBUPA1IH01 TSM: wdc04ammtsm002.ibmammsap.local ANE4007E Error processing '\\lbupa1ih01\c$\Windows\ServiceProfiles\LocalService\AppData\Local\FontCache\~Fon



CS9737729


OLD- //Spsvopivapp01/oom/JPP 250G  185G   66G  74% /wts_oom_JPP
NEW- //swtssrv01/oom/JPP 250G  185G   66G  74% /wts_oom_JPP

Old spsvcpivsql01 10.6.3.37 10.70.111.37 (CFN)
New swtssrv01 10.6.1.36 10.92.99.135 (CFN)

[root@spsvepajapp01 /]$ cat /etc/fstab |grep -i cifs
//Spsvopivapp01/oom/JPP /wts_oom_JPP cifs username=msg_jp1,passwd=Brguest#123,_netdev,uid=20000,gid=3050 0 0
//Swtssrv01/oom/JPP /wts_oom_JPP cifs username=msg_jp1,passwd=Brguest#1234567,_netdev,uid=20000,gid=3050 0 0

mount -t cifs //Spsvopivapp01/oom/JPP /wts_oom_JPP -o username=msg_jp1,passwd=Brguest#1234567,_netdev,uid=20000,gid=3050




Datastore monitoring 
Ref SNOW ticket CS9663594, need to check the feasibility for adding all datastores across the VCs in 3.x into Nagios monitoring #3877

CDtPA4%THtXn6N@	



Hostname	IFN		CFN		SID
	LBUPG1AP01	10.139.10.22	10.140.0.52	PG1	rebooted post patching
LBUPG1AP01HA	10.139.10.12	10.140.0.70	PG1	completed post reboot
	LBUPG1AP02	10.139.10.66	10.140.0.31	PG1     completed post reboot
LBUPL1AP01	10.139.10.20	10.140.0.13	PL1	completed post reboot
	LBUPL1AP02	10.139.10.73	10.140.0.126	PL1	completed post reboot
	LBUPL1DB01	10.139.10.55	10.140.0.21	PL1	completed post reboot


LBUPA1AP01	10.139.10.54	10.140.0.24   completed post reboot	
	LBUPA1DB01	10.139.10.107	10.140.0.87		completed post reboot	


pg1_ers02

PG1_ERS02

[root@lbupg1ap01 ibmrmalik]# crm configure edit
INFO: constraint order:rsc_fs_then_export_then_mount updated
INFO: hanging location:loc_sap_failover_to_ers deleted
INFO: constraint order:rsc_fs_then_export_then_mount updated
You have mail in /var/mail/root


rsc_sap_PG1_ERS02
SAP Primitive Name                  : Standard                                            [ PASSED ]
Auto recover                        : false                                               [ PASSED ]
Start timeout                       : 240s                                                [ PASSED ]
Stop timeout                        : 240                                                 [ PASSED ]
Monitor interval                    : 11s                                                 [ PASSED ]
Monitor timeout                     : 60s                                                 	[ FAILED ]
Is ERS                              : true                                                [ PASSED ]
Meta priority                       : 1000                                                [ PASSED ]

rsc_sap_PG1_ASCS01
SAP Primitive Name                  : Standard                                            [ PASSED ]
Auto recover                        : false                                               [ PASSED ]
Start timeout                       : 240                                                 [ PASSED ]
Stop timeout                        : 240                                                 [ PASSED ]
Monitor interval                    : 11s                                                 [ PASSED ]
Monitor timeout                     : 60s                                                 [ PASSED ]
Monitor on-fail                     : restart                                             [ PASSED ]
Meta priority                       : 10                                                  [ PASSED ]
Meta migration-threshold            : 1                                                   [ PASSED ]
Meta stickiness                     : 5000                                                [ PASSED ]
Meta failure-timeout                : 60                                                  [ PASSED ]


[root@lbupl1ap02 ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux lbupl1ap02 4.4.121-92.152-default #1 SMP Wed Feb 24 12:29:01 UTC 2021 (be05a4f) x86_64 x86_64 x86_64 GNU/Linux
Sat Nov 20 03:57:56 EST 2021
lbupl1ap01:/sapmnt/PL1         /sapmnt/PL1    nfs     defaults     0 0
10.140.32.30:/usr/sap/trans /usr/sap/trans nfs defaults 0 0
10.140.0.20:/interface /interface  nfs defaults 0 0
CRITICAL:  /run/user/0/gvfs filesystems are read-only
10.140.0.20:/interface                      nfs4      1.9T   29G  1.8T   2% /interface
10.140.32.30:/usr/sap/trans                 nfs4       40G   25G   13G  66% /usr/sap/trans
wdc04ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  59% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=13139,timeout=600,minproto=5,maxproto=5,direct 0 0
wdc04ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.139.10.73,local_lock=none,addr=146.89.142.24 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

[root@lbupl1ap02 ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux lbupl1ap02 4.4.121-92.152-default #1 SMP Wed Feb 24 12:29:01 UTC 2021 (be05a4f) x86_64 x86_64 x86_64 GNU/Linux
Sat Nov 20 05:17:07 EST 2021
lbupl1ap01:/sapmnt/PL1         /sapmnt/PL1    nfs     defaults     0 0
10.140.32.30:/usr/sap/trans /usr/sap/trans nfs defaults 0 0
10.140.0.20:/interface /interface  nfs defaults 0 0
OK: No read-only file systems found
10.140.0.20:/interface                      nfs4      1.9T   29G  1.8T   2% /interface
10.140.32.30:/usr/sap/trans                 nfs4       40G   25G   13G  66% /usr/sap/trans
lbupl1ap01:/sapmnt/PL1                      nfs4       16G  2.3G   14G  14% /sapmnt/PL1
wdc04ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  59% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=2394,timeout=600,minproto=5,maxproto=5,direct 0 0
wdc04ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.139.10.73,local_lock=none,addr=146.89.142.24 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.





[root@lbupl1ap01 ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux lbupl1ap01 4.4.121-92.152-default #1 SMP Wed Feb 24 12:29:01 UTC 2021 (be05a4f) x86_64 x86_64 x86_64 GNU/Linux
Sat Nov 20 05:10:17 EST 2021
10.140.32.30:/usr/sap/trans /usr/sap/trans nfs defaults 0 0
10.140.0.20:/interface /interface  nfs defaults 0 0
CRITICAL:  /run/user/0/gvfs filesystems are read-only
10.140.32.30:/usr/sap/trans                 nfs4       40G   25G   13G  66% /usr/sap/trans
10.140.0.20:/interface                      nfs4      1.9T   29G  1.8T   2% /interface
wdc04ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  59% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=18392,timeout=600,minproto=5,maxproto=5,direct 0 0
wdc04ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.139.10.20,local_lock=none,addr=146.89.142.24 0 0
/sapmnt/PL1     lbupl1ap02(rw,sync,no_root_squash,no_subtree_check) lbupl1db01(rw,sync,no_root_squash,no_subtree_check)
/3rdPartySoftware/PL1   lbupl1db01(rw,sync,no_root_squash,no_subtree_check)


[root@lbupl1ap01 ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux lbupl1ap01 4.4.121-92.152-default #1 SMP Wed Feb 24 12:29:01 UTC 2021 (be05a4f) x86_64 x86_64 x86_64 GNU/Linux
Sat Nov 20 05:33:14 EST 2021
10.140.32.30:/usr/sap/trans /usr/sap/trans nfs defaults 0 0
10.140.0.20:/interface /interface  nfs defaults 0 0
OK: No read-only file systems found
10.140.32.30:/usr/sap/trans                 nfs4       40G   25G   13G  66% /usr/sap/trans
10.140.0.20:/interface                      nfs4      1.9T   29G  1.8T   2% /interface
wdc04ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  59% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=2750,timeout=600,minproto=5,maxproto=5,direct 0 0
wdc04ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.139.10.20,local_lock=none,addr=146.89.142.24 0 0
/sapmnt/PL1     lbupl1ap02(rw,sync,no_root_squash,no_subtree_check) lbupl1db01(rw,sync,no_root_squash,no_subtree_check)
/3rdPartySoftware/PL1   lbupl1db01(rw,sync,no_root_squash,no_subtree_check)



LBUPL1APO2	LBUPL1AP02	10.139.10.73	10.140.0.126	PL1

lbupl1ap01 done 

LBUPA1AP01	10.139.10.54	10.140.0.24

LBUPA1DB01	10.139.10.107	10.140.0.87





[root@lbupa1ap01 ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES_SAP"
VERSION="12-SP2"
VERSION_ID="12.2"
PRETTY_NAME="SUSE Linux Enterprise Server for SAP Applications 12 SP2"
ID="sles_sap"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp2"
Linux lbupa1ap01 4.4.121-92.152-default #1 SMP Wed Feb 24 12:29:01 UTC 2021 (be05a4f) x86_64 x86_64 x86_64 GNU/Linux
Sat Nov 20 06:03:43 EST 2021
CRITICAL:  /run/user/0/gvfs filesystems are read-only
wdc04ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  59% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=16550,timeout=600,minproto=5,maxproto=5,direct 0 0
wdc04ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.139.10.54,local_lock=none,addr=146.89.142.24 0 0
/hana/backup    lbupa1db01.libertywe.com(rw,sync,no_subtree_check)


[root@lbupa1ap01 ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux lbupa1ap01 4.4.121-92.152-default #1 SMP Wed Feb 24 12:29:01 UTC 2021 (be05a4f) x86_64 x86_64 x86_64 GNU/Linux
Sat Nov 20 06:32:40 EST 2021
OK: No read-only file systems found
wdc04ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  59% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=1967,timeout=600,minproto=5,maxproto=5,direct 0 0
wdc04ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.139.10.54,local_lock=none,addr=146.89.142.24 0 0
/hana/backup    lbupa1db01.libertywe.com(rw,sync,no_subtree_check)






[root@lbupa1db01 ibmrmalik]# cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports
NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux lbupa1db01 4.12.14-95.6-default #1 SMP Thu Jan 17 06:04:39 UTC 2019 (6af4ef8) x86_64 x86_64 x86_64 GNU/Linux
Sat Nov 20 08:00:18 EST 2021
lbupf1ap01.libertywe.com:/interface     /interface      nfs4    defaults 0 0
lbupa1ap01.libertywe.com:/hana/backup   /hana/backup    nfs     nfsvers=3 0 0
CRITICAL:  /hana/backup filesystems are read-only
lbupf1ap01.libertywe.com:/interface         nfs4      1.9T   29G  1.8T   2% /interface
lbupa1ap01.libertywe.com:/hana/backup       nfs       867G  101G  722G  13% /hana/backup
wdc04ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.3T  2.4T  59% /sds
/etc/auto.nfs /sds autofs rw,relatime,fd=6,pgrp=2487,timeout=600,minproto=5,maxproto=5,direct,pipe_ino=29384 0 0
wdc04ammyum01.imzcloud.ibmammsap.local:/sds /sds nfs4 ro,relatime,vers=4.0,rsize=262144,wsize=262144,namlen=255,soft,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.139.10.107,local_lock=none,addr=146.89.142.24 0 0
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.



LBUPG1AP01	10.139.10.22	10.140.0.52	PG1	Dileep
LBUPG1AP01HA	10.139.10.12	10.140.0.70	PG1	Dileep
Installing: systemd-228-150.98.1.x86_64 ...................................................................................................................................................................................[error]
Installation of systemd-228-150.98.1.x86_64 failed:
Error: Subprocess failed. Error: RPM failed: warning: /etc/systemd/system.conf created as /etc/systemd/system.conf.rpmnew
warning: %post(systemd-228-150.98.1.x86_64) scriptlet failed, signal 2



LBUPG1AP02	10.139.10.66	10.140.0.31	PG1	




group cross-mnt-fs mountfs-3rdPartySoftware_lv mountfs-interface_lv mountfs-sapmnt_lv mountfs-int_lv
group g-ers ip-ers vol_pg1ersvg fs-ers_lv rsc_sap_PG1_ERS02
group g-global ip-nfs vol_pg1globalvg fs-3rdPartySoftware_lv fs-interface_lv fs-sapmnt_lv export-3rdPartySoftware_lv export-interface_lv export-sapmnt_lv \
        meta target-role=Started
group g-scs ip-ascs vol_pg1ascsvg fs-ascs_lv rsc_sap_PG1_ASCS01
ms ms-drbd-ers DRBD2-res \
        meta master-node-max=1 clone-max=2 clone-node-max=1 globally-unique=false notify=true target-role=Started
ms ms-drbd-global DRBD0-res \
        meta master-node-max=1 clone-max=2 clone-node-max=1 globally-unique=false notify=true target-role=Started
ms ms-drbd-scs DRBD1-res \
        meta master-node-max=1 clone-max=2 clone-node-max=1 globally-unique=false notify=true target-role=Started
clone clone-crossmnt cross-mnt-fs \
        meta clone-max=2 target-role=Started
order all_order_crossmnt Mandatory: g-global:start clone-crossmnt symmetrical=false
order all_order_drbd Optional: ms-drbd-scs:promote ms-drbd-ers:promote symmetrical=false
order all_order_drbd_ascs Mandatory: ms-drbd-scs:promote g-scs:start symmetrical=true
order all_order_drbd_ers Mandatory: ms-drbd-ers:promote g-ers:start symmetrical=true
order all_order_nfs Mandatory: ms-drbd-global:promote g-global:start symmetrical=true
colocation ascs-deps 100: ms-drbd-scs:Master g-scs
colocation col_sap_no_both -5000: g-ers g-scs
colocation ers-deps 50: ms-drbd-ers:Master g-ers
colocation global-deps inf: g-global ms-drbd-global:Master
location loc-vcenter-fencing-lbupg1ap01 vcenter-fencing-lbupg1ap01 -inf: lbupg1ap01
location loc-vcenter-fencing-lbupg1ap01ha vcenter-fencing-lbupg1ap01ha -inf: lbupg1ap01ha
order rsc_fs_then_export_then_mount Optional: g-global clone-crossmnt rsc_sap_PG1_ASCS01:start rsc_sap_PG1_ERS02:stop symmetrical=false


WKF
WDC-Dal13
RPO 30 min


CHG0222113

LBUPA1AP01	10.139.10.54	10.140.0.24
[root@lbupa1ap01 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)
	
LBUPA1DB01	10.139.10.107	10.140.0.87
[root@lbupa1db01 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)	

**Managed SAP Full**
Hostname	IFN		CFN		SID
LBUPG1AP01	10.139.10.22	10.140.0.52	PG1
[root@lbupg1ap01 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)

LBUPG1AP01HA	10.139.10.12	10.140.0.70	PG1
[root@lbupg1ap01ha ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)

LBUPG1AP02	10.139.10.66	10.140.0.31	PG1
[root@lbupg1ap02 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)


LBUPL1AP01	10.139.10.20	10.140.0.13	PL1
[root@lbupl1ap01 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)


LBUPL1AP02	10.139.10.73	10.140.0.126	PL1
[root@lbupl1ap02 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)


LBUPL1DB01	10.139.10.55	10.140.0.21	PL1
[root@lbupl1db01 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | kernel*          | package | (any)
5 | libvmtools0      | package | (any)
6 | mpt-firmware     | package | (any)
7 | open-vm-tools    | package | (any)

LBUPM1AP01	10.139.10.10	10.140.0.10	PM1
[root@lbupm1ap01 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | mpt-firmware     | package | (any)

LBUPQ1AP01	10.139.10.8	10.140.0.14	PQ1
[root@lbupq1ap01 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | mpt-firmware     | package | (any)

LBUPQ1AP02	10.139.10.9	10.140.0.7	PQ1
[root@lbupq1ap02 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | mpt-firmware     | package | (any)



Ref on TTA server
[root@sapapp31 ibmrmalik]# zypper locks

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | libvmtools0      | package | (any)
5 | mpt-firmware     | package | (any)
6 | open-vm-tools    | package | (any)


CHG0223550

Meggitt (MGG) Annual DR Test 2020 | PROD - LON02 | DR - FRA02

PROD	         CFN IP	        IFN IP	        DR	        CFN IP 	        IFN IP
MGGGBJPSOLX02	10.5.255.31	10.133.18.31	MGGDRDSOLX02	10.5.254.23	66.248.241.23
	MGGGBJPSOLX01	10.5.255.30	10.133.18.30	MGGGBJPSOLX01	10.5.255.30	10.133.18.30
MGGGBJPECCX08	10.5.255.25	10.133.18.25	MGGDRDECCX08	10.5.254.17	66.248.241.17
	MGGGBJPECCX07	10.5.255.24	10.133.18.24	MGGGBJPECCX07	10.5.255.24	10.133.18.24
MGGGBJPECCX02	10.5.255.19	10.133.18.19	MGGDRDECCX02	10.5.254.11	66.248.241.11
	MGGGBJPECCX01	10.5.255.18	10.133.18.18	MGGGBJPECCX01	10.5.255.18	10.133.18.18
	MGGGBJPECCX09	10.5.255.36	10.133.18.36	MGGGBJPECCX09	10.5.255.36	10.133.18.36
	MGGGBJPECCX10	10.5.255.37	10.133.18.37	MGGGBJPECCX10	10.5.255.37	10.133.18.37
MGGGBJPECCX06	10.5.255.23	10.133.18.23	MGGDRDECCX06	10.5.254.15	66.248.241.15
	MGGGBJPECCX05	10.5.255.22	10.133.18.22	MGGGBJPECCX05	10.5.255.22	10.133.18.22
MGGGBJPGTSX02	10.5.255.27	10.133.18.27	MGGDRDGTSX02	 10.5.254.19	66.248.241.19
	MGGGBJPGTSX01	10.5.255.26	10.133.18.26	MGGGBJPGTSX01	10.5.255.26	10.133.18.26
	MGGGBJPCNTX01	10.5.255.32	10.133.18.32	MGGGBJPCNTX01	10.5.255.32	10.133.18.32
	MGGGBJPCNTX02	10.5.255.33	10.133.18.33	MGGGBJPCNTX02	10.5.255.33	10.133.18.33
MGGGBJPGTSX03	10.33.18.28	10.5.255.28	MGGGBJPGTSX03	10.33.18.28	10.5.255.28	


ss 7030890871  1154 1210  Nishant Adhav

 MGGDE018VL1727M,MGGDE018VL1726	Netweaver_2021*#


/dev/epjappvg/interfaces_celonis_lv


/var/log/scc_agesvepmhsrv1_211124_1851.txz


svlq1srv0	10.6.2.19

[root@armfksap305ap cluster]$ cat /var/log/messages |grep -i pingack
Nov 24 13:24:04 armfksap305ap kernel: [16102096.884502] drbd r0 armfksap305a1: PingAck did not arrive in time.
Nov 24 13:24:07 armfksap305ap kernel: [16102099.700478] drbd r2 armfksap305a1: PingAck did not arrive in time.
Nov 24 13:24:12 armfksap305ap kernel: [16102104.820466] drbd r1 armfksap305a1: PingAck did not arrive in time.


Nov 24 13:33:07 armfksap305a1 systemd[1]: Starting Restore /run/initramfs on shutdown...
Nov 24 13:33:07 armfksap305a1 systemd[1]: Started Restore /run/initramfs on shutdown.
Nov 24 13:33:07 armfksap305a1 systemd[1]: Starting Update UTMP about System Boot/Shutdown...
Nov 24 13:33:07 armfksap305a1 systemd[1]: Started Update UTMP about System Boot/Shutdown.

[root@armfksap305a1 ibmrmalik]$ last reboot
reboot   system boot  4.12.14-95.74-de Wed Nov 24 13:32 - 14:43  (01:10)

[root@aprpiqas ibmrmalik]# last
ibmrmali pts/7        146.89.142.228   Wed Nov 24 14:55   still logged in
ibmtovca pts/5        146.89.142.60    Wed Nov 24 14:24   still logged in
ibmkdodd pts/3        146.89.140.60    Wed Nov 24 14:15   still logged in
ibmtovca pts/0        146.89.142.60    Wed Nov 24 14:12   still logged in
(unknown :0           :0               Wed Nov 24 13:28   still logged in
reboot   system boot  4.12.14-95.80-de Wed Nov 24 13:28 - 14:55  (01:27)


armfksap305a1
armfksap305ap
armfksap305d1
armfksap305db


scrbwrdefra60	Linux Server	A.P. Moller Maersk -- APM
[root@scrbwrdefra60 ibmrmalik]$ uptime
 14:42pm  up   2:16,  5 users,  load average: 0.03, 0.14, 0.26
Check for app start

armfksap305a1	Linux Server	Arnoldo Mondadori Editore SpA -- ARM
[root@armfksap305a1 ibmrmalik]$ uptime
 15:43pm  up   2:12,  6 users,  load average: 0.03, 0.15, 0.08

server is up but cluster is unmanaged and resourecs down sev1 already for apps down in place

FBSAPD01FGCL	Linux Server	FCA Bank S.p.A -- FBS
[root@FBSAPD01FGCL ibmrmalik]$ uptime
 15:44pm  up   2:13,  3 users,  load average: 0.19, 0.19, 0.16


sm9a182172008	Linux Server	Smiths Group plc -- SM9
[root@sm9a182172008 ibmrmalik]$ uptime
 14:45pm  up   2:18,  8 users,  load average: 0.22, 0.34, 0.42


CS9795490 P2 HFCPE1HNDB1HA HollyFrontier Corporation Resource Pacemaker sbd WARNING: This command show is deprecated. please use status Attention commas replaced by dots.
CS9795491 P2 HFCPE1HNDB1 HollyFrontier Corporation Resource Pacemaker sbd WARNING: This command show is deprecated. please use status Attention commas replaced by dots.
CS9795449 P2 HFCPE1HNDB1HA HollyFrontier Corporation Log PaceMaker-log Found 12 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-11-25-03-13-03 for details.



CS9739096
Mount Name: ZEH_SDS_IMPORT
\\172.31.24.143\Output\PDF

Mount Name: TIS_Interface
\\172.26.1.35\SAP          

S4D App ti3s4dap02 10.7.115.22
S4Q - APP ti3s4qap02 10.7.115.14



MGGGBJPECCX01  MGGGBJPECCX01 configuration error: A new disk was added to a replicated virtual machine. Replication will be paused until the new disk is configured for replication.
MGGDE016BCB96DR  out of space
https://github.kyndryl.net/CMS/cms-opaas-api/issues/19774



https://github.kyndryl.net/CMS/cms-opaas-api/issues/19775
XPIWDC04SD377DR  extensions so 1 non replicated disk of xpiprderppd  can be added to replication 



CS9805063	Toyota Boshoku -- TBO	P2 - Major	Ping Availability CRITICAL - 100.126.48.35: rta nan. lost 100% Attention commas replaced by dots.	TBOS4PRDDB2
CS9805030	Toyota Boshoku -- TBO	P2 - Major	Ping Availability CRITICAL - 100.126.48.32: rta nan. lost 100% Attention commas replaced by dots.	TBOS4PRDDB1
CS9804990	Toyota Boshoku -- TBO	P2 - Major	Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)	TBOS4PRDDB2
CS9804975	Toyota Boshoku -- TBO	P2 - Major	Service postfix CRITICAL: 0 postfix processes running (thresh 1:)	TBOS4PRDDB1

xpipippipd
 Recovery failed because the Virtual Machine is no longer configured for replication.
XPIWDC04SDE156DR
PG1
cd/sds/sap/MSD_Software/SAP_Automation/Non-HANA/3.x-Cluster-dr/


CS9813172  PAK suzuki sbd issue sev1
PS2-S4P-CI	172.29.20.72
PS2-S4P-CI-HA172.29.20.73
PS2-S4P-DB-HA	172.29.20.74
PS2-S4P-DB172.29.20.70



CS9826890	ZF Friedrichshafen AG -- ZFF	TSM: fra02ammtsm004.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0330 in domain D60_SMR_SHORT for node ZFF_ZFFPDB005_FIL_DLY failed (return code 12).~	SQ-SAP-TRIO-B1	SQ-SAP-TRIO-B1
CS9709289	Wawa, Inc. -- WA2	TSM: a0001p5rapp0012.mgt.mhas.ibm.com ANR2578W Schedule 7TW_FIL_INC_0530 in domain D14_SMR_SHORT for node WA2_WA2BWQDB01_FIL has missed its scheduled start up w	SQ-SAP-TRIO-B1	SQ-SAP-TRIO-B1
CS9826883	IAG - British Airways -- IA2	TSM: fra02ammtsm004.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0330 in domain D60_SMR_SHORT for node IA2_IA2SP5DB-DR_FIL_DLY failed (return code 12).~	SQ-SAP-TRIO-B1	SQ-SAP-TRIO-B1



CS9828232	SVBD1SRV0  not accessible
CS9828169	resolved
CS9828119	resolved
CS9830662	resolved


CS9121761	closed
CS9325251	vulnerability ticket not in my name and is on hold as it is still being difcussed
CS9390278	closed
CS9463827	closed
CS9466506	vulnerability ticket not in my name and is on hold as it is still being difcussed
CS9466937	vulnerability ticket not in my name and is on hold as it is still being difcussed
CS9469545	closed


CS9852708Suncor Energy Inc. -- SNCP2 - MajorCheckFS DFhanging df command hanging. please check the file system on device Attention commas replaced by dots.SNCHECATA11
CS9852715Suncor Energy Inc. -- SNCP2 - MajorCheckFS DFhanging df command hanging. please check the file system on device Attention commas replaced by dots.
CS9852714Suncor Energy Inc. -- SNCP2 - MajorCheckFS DFhanging df command hanging. please check the file system on device Attention commas replaced by dots.
CS9852709Suncor Energy Inc. -- SNCP2 - MajorCheckFS DFhanging df command hanging. please check the file system on device Attention commas replaced by dots.


CHG0226280 PROD / LBU - SUSE Linux SP Update from 12 SP2 to SP4 (PG1)	03-12-2021 06:30:00	03-12-2021 16:30:00
Hostname	IFN		CFN		SID
LBUPG1AP01	10.139.10.22	10.140.0.52	PG1
LBUPG1AP01HA	10.139.10.12	10.140.0.70	PG1
LBUPG1AP02	10.139.10.66	10.140.0.31	PG1


PS2-S4P-CI	172.29.20.72
PS2-S4P-CI-HA	172.29.20.73
PS2-S4P-DB-HA	172.29.20.74
PS2-S4P-DB	172.29.20.70


Dec  4 01:32:58 ps2-s4p-db chef-client[6835]:   * file[/var/tsm/dsmerror_hana.log] action create[2021-12-04T01:32:58+00:00] INFO: Processing file[/var/tsm/dsmerror_hana.log] action create (fms_tsm_hana::tdp_hana_client line 114)
Dec  4 01:42:24 ps2-s4p-db sbd[39631]: /dev/disk/by-id/scsi-360014054b5958b4db3b4acc914dbb499:    error: sector_io: Short IO (rw=0, res=18446744073709551611, sector_size=512)
Dec  4 01:42:24 ps2-s4p-db sbd[39631]: /dev/disk/by-id/scsi-360014054b5958b4db3b4acc914dbb499:    error: header_get: Unable to read header from device 5
Dec  4 01:42:24 ps2-s4p-db sbd[39631]: /dev/disk/by-id/scsi-360014054b5958b4db3b4acc914dbb499:    error: servant_md: No longer found a valid header on /dev/disk/by-id/scsi-360014054b5958b4db3b4acc914dbb499
Dec  4 01:42:24 ps2-s4p-db sbd[31947]: /dev/disk/by-id/scsi-36001405eb62726ea5f54a3eb6b4ab0b4:    error: sector_io: Short IO (rw=0, res=18446744073709551611, sector_size=512)
Dec  4 01:42:24 ps2-s4p-db sbd[31947]: /dev/disk/by-id/scsi-36001405eb62726ea5f54a3eb6b4ab0b4:    error: header_get: Unable to read header from device 6
Dec  4 01:42:24 ps2-s4p-db sbd[31947]: /dev/disk/by-id/scsi-36001405eb62726ea5f54a3eb6b4ab0b4:    error: servant_md: No longer found a valid header on /dev/disk/by-id/scsi-36001405eb62726ea5f54a3eb6b4ab0b4
Dec  4 01:42:24 ps2-s4p-db sbd[39633]: /dev/disk/by-id/scsi-36001405b80858e9c1f34f239b617a0e5:    error: sector_io: Short IO (rw=0, res=18446744073709551611, sector_size=512)
Dec  4 01:42:24 ps2-s4p-db sbd[39633]: /dev/disk/by-id/scsi-36001405b80858e9c1f34f239b617a0e5:    error: header_get: Unable to read header from device 5
Dec  4 01:42:24 ps2-s4p-db sbd[39633]: /dev/disk/by-id/scsi-36001405b80858e9c1f34f239b617a0e5:    error: servant_md: No longer found a valid header on /dev/disk/by-id/scsi-36001405b80858e9c1f34f239b617a0e5


Dec  4 01:50:17 ps2-s4p-db sbd[2850]: /dev/disk/by-id/scsi-36001405b80858e9c1f34f239b617a0e5:  warning: open_device: Opening device /dev/disk/by-id/scsi-36001405b80858e9c1f34f239b617a0e5 failed.
Dec  4 01:50:17 ps2-s4p-db sbd[2848]: /dev/disk/by-id/scsi-360014054b5958b4db3b4acc914dbb499:  warning: open_device: Opening device /dev/disk/by-id/scsi-360014054b5958b4db3b4acc914dbb499 failed.
Dec  4 01:50:17 ps2-s4p-db sbd[2849]: /dev/disk/by-id/scsi-36001405eb62726ea5f54a3eb6b4ab0b4:  warning: open_device: Opening device /dev/disk/by-id/scsi-36001405eb62726ea5f54a3eb6b4ab0b4 failed.

[root@ps2-s4p-db iscsi]# cat /var/log/messages |grep -i connect
Dec  4 01:32:42 ps2-s4p-db chef-client[6835]:   * hana_connection[check_connectivity_S4PAUTOMATION] action check[2021-12-04T01:32:42+00:00] INFO: Processing hana_connection[check_connectivity_S4PAUTOMATION] action check (sap_hana::sap_hana_install line 345)
Dec  4 01:42:23 ps2-s4p-db iscsid[15752]: iscsid: Connection31:0 to [target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.233,3260] through [iface: default] is shutdown.
Dec  4 01:42:23 ps2-s4p-db iscsid[15752]: iscsid: Connection32:0 to [target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.232,3260] through [iface: default] is shutdown.
Dec  4 01:42:23 ps2-s4p-db iscsid[15752]: iscsid: Connection30:0 to [target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.234,3260] through [iface: default] is shutdown.


[root@ps2-s4p-db send_targets]# ls
172.29.20.232,3260  172.29.20.233,3260  172.29.20.234,3260

[root@ps2-s4p-db send_targets]# iscsiadm -m discovery --type=st --portal=172.29.20.232:3260
172.29.20.232:3260,1 iqn.2006-04.nhps2-s4p-ci.local:nhps2-s4p-ci
172.29.20.232:3260,1 iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db

[root@ps2-s4p-db send_targets]# iscsiadm -m discovery --type=st --portal=172.29.20.233:3260
172.29.20.233:3260,1 iqn.2006-04.nhps2-s4p-ci.local:nhps2-s4p-ci
172.29.20.233:3260,1 iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db

[root@ps2-s4p-db send_targets]# iscsiadm -m discovery --type=st --portal=172.29.20.234:3260
172.29.20.234:3260,1 iqn.2006-04.nhps2-s4p-ci.local:nhps2-s4p-ci
172.29.20.234:3260,1 iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db

[root@ps2-s4p-db send_targets]# iscsiadm -m node -T iqn.2006-04.nhps2-s4p-ci.local:nhps2-s4p-ci --login --portal=172.29.20.232:3260
Logging in to [iface: default, target: iqn.2006-04.nhps2-s4p-ci.local:nhps2-s4p-ci, portal: 172.29.20.232,3260]
iscsiadm: Could not login to [iface: default, target: iqn.2006-04.nhps2-s4p-ci.local:nhps2-s4p-ci, portal: 172.29.20.232,3260].
iscsiadm: initiator reported error (24 - iSCSI login failed due to authorization failure)

[root@ps2-s4p-db send_targets]# iscsiadm -m node -T iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db --login --portal=172.29.20.232:3260
Logging in to [iface: default, target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.232,3260]
Login to [iface: default, target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.232,3260] successful.

[root@ps2-s4p-db send_targets]# iscsiadm -m node -T iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db --login --portal=172.29.20.233:3260
Logging in to [iface: default, target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.233,3260]
Login to [iface: default, target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.233,3260] successful.

[root@ps2-s4p-db send_targets]# iscsiadm -m node -T iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db --login --portal=172.29.20.234:3260
Logging in to [iface: default, target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.234,3260]
Login to [iface: default, target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.234,3260] successful.

[root@ps2-s4p-db iscsi]# systemctl status iscsid.service
â— iscsid.service - Open-iSCSI
   Loaded: loaded (/usr/lib/systemd/system/iscsid.service; disabled; vendor preset: disabled)
   Active: active (running) since Sat 2021-12-04 01:42:38 UTC; 1h 16min ago
     Docs: man:iscsid(8)
           man:iscsiuio(8)
           man:iscsiadm(8)
 Main PID: 55485 (iscsid)
   Status: "Ready to process requests"
    Tasks: 1
   CGroup: /system.slice/iscsid.service
           â””â”€55485 /sbin/iscsid -f

Dec 04 01:42:38 ps2-s4p-db systemd[1]: Starting Open-iSCSI...
Dec 04 01:42:38 ps2-s4p-db systemd[1]: Started Open-iSCSI.
Dec 04 02:41:29 ps2-s4p-db iscsid[55485]: iscsid: conn 0 login rejected: initiator failed authorization with target
Dec 04 02:41:29 ps2-s4p-db iscsid[55485]: iscsid: Connection33:0 to [target: iqn.2006-04.nhps2-s4p-ci.local:nhps2-s4p-ci, portal: 172.29.20.232,3260] through [iface: default] is shutdown.
Dec 04 02:42:35 ps2-s4p-db iscsid[55485]: iscsid: Connection34:0 to [target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.232,3260] through [iface: default] is operational now
Dec 04 02:42:49 ps2-s4p-db iscsid[55485]: iscsid: Connection35:0 to [target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.233,3260] through [iface: default] is operational now
Dec 04 02:42:56 ps2-s4p-db iscsid[55485]: iscsid: Connection36:0 to [target: iqn.2006-04.hdbps2-s4p-db.local:hdbps2-s4p-db, portal: 172.29.20.234,3260] through [iface: default] is operational now




TDMprdhana	CS9866826 sev1
10.143.82.19	dalhana-1024-1.xsportal.local	CDtPA4%THtXn6N@
ipmi root UQ96xzlvRw	10.143.82.31
number:CS2600137 raised to SL to reset the root pw for esxi host

sdb                                    8:16   0  539G  0 disk
â””â”€sdb1                                 8:17   0  539G  0 part
  â”œâ”€vghanadata-lv_hana_data (dm-0)   253:0    0  768G  0 lvm
  â”œâ”€vghanadata-lv_usr_sap (dm-1)     253:1    0   50G  0 lvm
  â””â”€vghanadata-lv_hana_shared (dm-2) 253:2    0  256G  0 lvm
sda                                    8:0    0  100G  0 disk
â”œâ”€sda1                                 8:1    0  200M  0 part /boot
â”œâ”€sda2                                 8:2    0   50G  0 part [SWAP]
â””â”€sda3                                 8:3    0 49.8G  0 part /
sdd                                    8:48   0  258G  0 disk
â””â”€sdd1                                 8:49   0  258G  0 part /hana/log
sdc                                    8:32   0  540G  0 disk
â””â”€sdc1                                 8:33   0  540G  0 part
  â”œâ”€vghanadata-lv_hana_data (dm-0)   253:0    0  768G  0 lvm
  â”œâ”€vghanadata-lv_usr_sap (dm-1)     253:1    0   50G  0 lvm
  â””â”€vghanadata-lv_hana_shared (dm-2) 253:2    0  256G  0 lvm


root passwords for esxi ss

FAN replacement SL ticket number:CS2600154
SL - CS2600137 disk replacement


root CDtPA4%THtXn6N@ root qYF4KD%IYImUtV@ root VKrfRj%8b9llfl@ root 0JOTnz%X4EwslL@ root fdXt0n%ximhkmw@ root QiFX00%yYf12xl@ ibmvmadmin AEdfwd65Lvjf SoftLayer Virtualization Management User root U52NxJ%n4z8aL8@ root yXbny6FqLsz6fI@ root kUzf96eAIpa7hE@ root M43kTYoevKYHre@ root qEqmw92gsA@ root RGX0ouK8Ft@ root PUvjhkenf4@ root Ctamxz9Rg2@ root Y2GzZ369


SL = CS2603220
CS9887437	HANA DB PSPRDDB  unavailable	Sev1
lonhana-1024-16.xsportal.local
PSPRDDB	


PS2-S4P-CI	172.29.20.72
PS2-S4P-CI-HA	172.29.20.73
PS2-S4P-DB-HA	172.29.20.74
PS2-S4P-DB	172.29.20.70

iscsiadm -m node --portal=172.29.20.234:3260 --op=update --name=node.startup --value=automatic
iscsiadm -m node --portal=172.29.20.233:3260 --op=update --name=node.startup --value=automatic
iscsiadm -m node --portal=172.29.20.232:3260 --op=update --name=node.startup --value=automatic




Parle
Prod Chen
DR SNG



mmtbwjavadev	100.126.50.58	ammtok02custesx011.imzcloud.ibmammsap.local
mmtbwjavaqas	100.126.50.39	ammtok02custesx011.imzcloud.ibmammsap.local
mmtbwjavaprd	100.126.50.21	ammtok02custesx009.imzcloud.ibmammsap.local
mmtbwabapdev	100.126.50.60	ammtok02custesx009.imzcloud.ibmammsap.local
mmtbwabapqas	100.126.50.40	ammtok02custesx010.imzcloud.ibmammsap.local
mmtbwabapprd	100.126.50.27	ammtok02custesx011.imzcloud.ibmammsap.local
mmtbobidev	100.126.50.61	ammtok02custesx011.imzcloud.ibmammsap.local
mmtbobiqas	100.126.50.42	ammtok02custesx011.imzcloud.ibmammsap.local
mmtbobiprd	100.126.50.6	ammtok02custesx011.imzcloud.ibmammsap.local
mmtbodsdev	100.126.50.59	ammtok02custesx010.imzcloud.ibmammsap.local
mmtbodsqas	100.126.50.38	ammtok02custesx009.imzcloud.ibmammsap.local
mmtbodsprd	100.126.50.7	ammtok02custesx010.imzcloud.ibmammsap.local
mmtcdqas	100.126.50.45	ammtok02custesx010.imzcloud.ibmammsap.local
mmtcdprd	100.126.50.12	ammtok02custesx009.imzcloud.ibmammsap.local
mmtglobaldc1	100.126.50.8	ammtok02custesx010.imzcloud.ibmammsap.local
mmtglobaldc2	100.126.50.10	ammtok02custesx009.imzcloud.ibmammsap.local



Source -
DLTHQGGA1	10.4.5.42	10.250.17.42
DLTHQGGAT	10.4.5.34	10.250.17.34	
DLTQEGGAT	10.4.5.176	10.250.17.180

Destination - DLTHSGGAT	10.4.5.24	10.250.17.24
Port â€“ 3300


CS9893035
CS9893015
CS9893025
CS9893010
CS9892994


1. From OS/Apps/DB Teams - Need to validate / RDP or SSH / Apps & DB are up and working fine or not
 2. If Pacemaker VM's are there in the above VM's list, please move the cluster services to another node, and validate and confirm the same ( There will not be any outages to the customer)
 3. BHT will migrate the VM's to Other ESXI Hosts within the same cluster and set the host to maintenance mode
 4. After the VM's migration - Need Post validation checks from OS/Apps/DB Teams
 5. BHT Team will work with SL for Faulty hardware parts replacement
 6. Post validation from SL - After the Parts replacement - All looks good, then BHT team will release the host into production.

ammmon01custesx008.imzcloud.ibmammsap.local is presenting Memory issues	

SAP B1:
bmtmon1lapp03	Linux Server	Bombardier Aerospace -- BMT	SAP HEC-AMM	SAPB1	powered off hosted on 	ammmon01custesx008
	
br3psolss42	Linux Server	Bombardier Recreational Products Inc -- BR3  SAPB1	ammmon01custesx008  resources moved to br3psolss43 and this node is set to standby
br3psolss43		ammmon01custesx005


br3qgtsss36	Linux Server	Bombardier Recreational Products Inc -- BR3  SAPB1	ammmon01custesx008	resources moved to br3qgtsss35 and this node is set to standby
br3qgtsss35	ammmon01custesx001

iplsasmad02	Linux Server	Inter Pipeline Fund -- IPL	SAP HEC-AMM	SAPB1    pending deactivation


Unable to pull the details for the below vms
agsybs01d	powered off
AMMMON01PSC01	Retired
pgtstoras04p	powered off
ratstrhel15	powered off
USRD0P0MSDas1	powered off

cd4ewpscs 	ammmon01custesx003
cd4ewscsha 	ammmon01custesx008 

-----------------------------------------

SAP B1:
bmtmon1lapp03	Linux Server	Bombardier Aerospace -- BMT	SAP HEC-AMM	SAPB1	powered off hosted on 	ammmon01custesx005.imzcloud.ibmammsap.local
	
br3psolss42	Linux Server	Bombardier Recreational Products Inc -- BR3  SAPB1	ammmon01custesx007  cluster is healthy. Resources running on both nodes.
br3psolss43		ammmon01custesx005


br3qgtsss36	Linux Server	Bombardier Recreational Products Inc -- BR3  SAPB1	ammmon01custesx004	cluster is healthy. Resources running on both nodes.
br3qgtsss35	ammmon01custesx001

iplsasmad02	Linux Server	Inter Pipeline Fund -- IPL	SAP HEC-AMM	SAPB1    pending deactivation


Unable to pull the details for the below vms
agsybs01d	powered off	ammmon01custesx005
AMMMON01PSC01	Retired
pgtstoras04p	powered off	ammmon01custesx005
ratstrhel15	powered off	ammmon01custesx005
USRD0P0MSDas1	powered off	ammmon01custesx005

cd4ewpscs 	ammmon01custesx003
cd4ewscsha 	ammmon01custesx008 



CS9908344	sev1
HFCHBPHNDB1HA
10.36.106.246	hfc-dal13-pod2-phana-h4-6000-08.imzcloud.ibmammsap.local


hfchbphndb1ha:/opt/MegaRAID/storcli # ./storcli64 /call show all | grep -iE "Sata|SAS" | grep -iE "Bad|Failed"
134:6     3 UBad   -   3.492 TB SATA SSD Y   N  512B Micron_5200_MTFD          U  -


hfchbphndb1ha:/opt/MegaRAID/storcli # ./storcli64 /call show all | grep -iE "OfLn|Pdgd|Dgrd" | grep -v "="
 1 -   -   -        -   RAID10 Dgrd  N    6.984 TB dflt N  N   dflt N      N
 1 0   -   -        -   RAID1  Dgrd  N    3.492 TB dflt N  N   dflt N      N
 1 1   -   -        -   RAID1  Dgrd  N    3.492 TB dflt N  N   dflt N      N
1/1   RAID10 Dgrd  RW     Yes     NRWBD -   ON    6.984 TB RAID10-B



su - uepadm -c "hdbnsutil -sr_register --remoteHost=mm3s4uep004n2 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --online --name=NODEA"


CHG0227134
AGEAS - RHEL 6.10 to  7.9  Upgrade on  svmq1srv1 NOTE: systems will be down for 11 hours
AGEAS - RHEL 6.10 to  7.9  Upgrade on  svaq1srv0 NOTE: systems will be down for 11 hours

svaq1srv0	10.6.2.18


Current version in this host : RHEL Linux Server release 6.10 (Santiago)
Target version in this host: Target RHEL 7.9 (Maipo)



CS9919517
Please NFS mount interface Filesystem onto the 2 S4P app servers
Please export and mount glts4prdas01:/interface/S4P as /interface/S4P       ======> Please reference glts4qasas01 10.92.3.134 for export options
Please export and mount glts4prdas01:/usr/sap/trans as /usr/sap/trans       ======> Please reference glts4qasas01 10.92.3.134 for export options
Source: GLTS4PRDAS01 10.25.199.163

Target: GLTS4PRDAS02 10.25.199.141
Target: GLTS4PRDAS03 10.25.199.147

The NFS mounts should be permanent so please set it up to be automatically added after reboot
***PLEASE USE HOSTNAMES NOT IP ADDRESSES


CS9921785 P2 BR3PSOLDB42 Bombardier Recreational Products Inc Service Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)
CS9921784 P2 BR3PSOLDB42 Bombardier Recreational Products Inc Service Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)
CS9921783 P2 BR3PSOLDB42 Bombardier Recreational Products Inc Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)
CS9921782 P2 BR3PSOLDB42 Bombardier Recreational Products Inc -- BR3BR3BR3 IC4SAP-SL SAP LOBService Pacemaker stonithd CRITICAL: 0 /usr/lib64/pacemaker/stonithd processes running (thresh 1:)




BS4DIP089 win
BS4SERVER030 win
BS4DIQ046   win


LONMAGBOB0002	10.69.0.24	A0D8UK014XVM011
LONMAGBWH0002	10.69.0.18	A0D8UK014XVM007
LONMAGERP0002	10.69.0.12	A0D8UK014XVM003
LONMAGGRC0001	10.69.0.39	A0D8UK014XVM020
LONMAGHAN0001	10.69.0.11	vhana on 10.113.60.236	CFG-LONCFGCEQ0001-LONCFGCCQ0002.xsportal.local
LONMAGHAN0003	10.69.0.17	vhana on 10.113.60.220	lonhana-2048-3.xsportal.local
LONMAGHAN0005	10.69.0.23	server not found in HANA tracker
LONMAGSLM0003	10.69.0.70	LONMAGSLM0003	
LONMAGSLM0004	10.69.0.71	LONMAGSLM0004




A0D8UK014XVM003		LONMAGERP0002
A0D8UK014XVM005		LONMAGERP0004
A0D8UK014XVM007		LONMAGBWH0002
A0D8UK014XVM009		LONMAGBWH0004
A0D8UK014XVM011		LONMAGBOB0002


CS9757913
LBUPG1AP01	10.139.10.22	10.140.0.52	PG1	 snapshot name VM Snapshot 11/18/2021, 2:59:29 PM created on 11/20/2021, 7:37:37 AM                                    
 LBUPG1AP01HA	10.139.10.12	10.140.0.70	PG1   snapshot name VM Snapshot 11/18/2021, 2:59:53 PM created on 11/20/2021, 7:38:02 AM
LBUPG1AP02	10.139.10.66	10.140.0.31	PG1      snapshot name VM Snapshot 11/18/2021, 3:00:16 PM created on 11/20/2021, 7:38:25 AM



146.89.140.50  dal09ammtsm001 -- Source
   146.89.140.114 lon02ammtsm001 -- target -- df is hung here and cannot ping the source

ERROR: rhsm_register[lon02ammtsm001.imzcloud.ibmammsap.local] (satellite-client::default line 50) had an error: Mixlib::ShellOut::ShellCommandFailed: yum_package[subscription-manager] (/var/chef/cache/cookbooks/redhat_subscription_manager/libraries/rhsm_register.rb line 35) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '1'
---- Begin output of /usr/bin/python /opt/chef/embedded/lib/ruby/gems/2.4.0/gems/chef-13.9.4/lib/chef/provider/package/yum/yum-dump.py --options --installed-provides --yum-lock-timeout 30 ----
STDOUT: [option installonlypkgs] kernel kernel-bigmem installonlypkg(kernel) installonlypkg(kernel-module) installonlypkg(vm) kernel-enterprise kernel-smp kernel-debug kernel-unsupported kernel-source kernel-devel kernel-PAE kernel-PAE-debug


SVAQ1SRV0
Resolution
symlink between this directory /etc/systemd/system/getty.target.wants is missing or it has been deleted accidentally
Raw
   # mkdir /etc/systemd/system/getty.target.wants
   # cd /etc/systemd/system/getty.target.wants
   # ln -s /usr/lib/systemd/system/getty@.service getty@tty1.service
Reboot the server and check if you are able to get the login on console prompt.


Error: Package: zeromq-4.3.1-4.el8.x86_64 (IBM_Managed_Applications_Saltstack_for_RHEL_RHEL8_Salt)
           Requires: libstdc++.so.6(GLIBCXX_3.4.20)(64bit)
Error: Package: zeromq-4.3.1-4.el8.x86_64 (IBM_Managed_Applications_Saltstack_for_RHEL_RHEL8_Salt)
           Requires: libstdc++.so.6(CXXABI_1.3.9)(64bit)
Error: Package: zeromq-4.3.1-4.el8.x86_64 (IBM_Managed_Applications_Saltstack_for_RHEL_RHEL8_Salt)
           Requires: libstdc++.so.6(GLIBCXX_3.4.21)(64bit)
 You could try using --skip-broken to work around the problem
 You could try running: rpm -Va --nofiles --nodigest




02:43:17          LINUX RESTART

dlthpehdb4s:/home/ibmrmalik # date
Thu Dec 16 02:50:21 EST 2021


su - hpeadm -c "hdbnsutil -sr_register --remoteHost=dlthpehdb4 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --online --name=NODEB"




AGEAS prod upgrade planned
spsvbpabapp01	10.6.3.19
spsvbpaaapp01	10.6.3.20




CS9965005	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.6.13: rta nan. lost 100% Attention commas replaced by dots.	EGRWD-QAS
CS9964994	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.6.11: rta nan. lost 100% Attention commas replaced by dots.	EGRS4HDEVAPP
CS9965004	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.5.11: rta nan. lost 100% Attention commas replaced by dots.	EGRSOLMANPRD
CS9965007	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.5.14: rta nan. lost 100% Attention commas replaced by dots.	EGRWD-PRD
	CS9964998	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.5.12: rta nan. lost 100% Attention commas replaced by dots.	EGRS4HPRDDB
CS9965003	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.6.12: rta nan. lost 100% Attention commas replaced by dots.	EGRS4HQASDB
CS9964995	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.6.16: rta nan. lost 100% Attention commas replaced by dots.	EGRS4HQASAPP
	CS9965001	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.6.17: rta nan. lost 100% Attention commas replaced by dots.	EGRWD-DEV
	CS9964996	Egyptian Refining Company -- EGR	P2 - Major	Ping Availability CRITICAL - 10.135.5.13: rta nan. lost 100% Attention commas replaced by dots.	EGRS4HPRDAPP


You need to install glibc alongside your current installation of glibc as you cannot update to glibc 2.14 directly in centos 6.x safely. Follow the steps below to install glibc 2.14:

mkdir ~/glibc214
cd ~/glibc214
wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz
tar zxvf glibc-2.14.tar.gz
cd glibc-2.14
mkdir build
cd build
../configure --prefix=/opt/glibc-2.14
make -j4
sudo make install
export LD_LIBRARY_PATH=/opt/glibc-2.14/lib (for current login session) OR add LD_LIBRARY_PATH=/opt/glibc-2.14/lib in the /etc/environment and perform source /etc/environment(to add env variable permanently)


To fix: glibc-2.14/build/elf/ldconfig: Can't open configuration file glibc-2.14/etc/ld.so.conf: No such file or directory I did: cd glibc-2.14/etc/, sh -c "echo 'glibc-2.14/lib' >> ld.so.conf" 

../configure --prefix=/opt/glibc-2.14  libc_cv_forced_unwind=yes libc_cv_c_cleanup=yes



APPRH60
APPRH65
CIARH02
CIDRH03

Path for log4j scanner
https://kyndryl.ent.box.com/s/jcn4h0cfrmmwlup7pwi8fr2k0g4fbjj5
./log4j2-scan: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by ./log4j2-scan)
525  mkdir ~/glibc214
  526  cd ~/glibc214
  527  wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz
  528  cd /tmp
  529  ls -ltr
  530  tar zxvf glibc-2.14.tar.gz
  531  cd glibc-2.14
  532  mkdir build
  533  cd build
  534  ../configure --prefix=/opt/glibc-2.14
  535  make -j4
  537  make install
  538  export LD_LIBRARY_PATH=/opt/glibc-2.14/lib
  539  cd /tmp
  540  ./log4j2-scan --exclude /sds /



CS9972808	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker stonithd CRITICAL: 0 /usr/lib64/pacemaker/stonithd processes running (thresh 1:)	MM3S4UEP005N2
CS9972816	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)	MM3S4UEP005N2
CS9972803	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)	MM3S4UEP005N2
CS9972811	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)	MM3S4UEP005N2
CS9972812	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)	MM3S4UEP005N2
CS9972814	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)	MM3S4UEP005N2

CS9972769	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2021-12-18-01-13-03 for details.	MM3S4UEP005N1
CS9972777	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Resources CRM CRITICAL: Unmanaged resources found: vcenter-fencing-mm3s4uep005n1(stonith:fence_vmware_soap):Started mm3s4uep005n2 (unmanaged) vcenter-fencing-mm	MM3S4UEP005N1
CS9972786	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)	MM3S4UEP005N1
CS9972800	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker stonithd CRITICAL: 0 /usr/lib64/pacemaker/stonithd processes running (thresh 1:)	MM3S4UEP005N1
CS9972832	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)	MM3S4UEP005N1
CS9972790	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker stonithd CRITICAL: 0 /usr/lib64/pacemaker/stonithd processes running (thresh 1:)	MM3S4UEP005N1
CS9972765	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)	MM3S4UEP005N1
CS9972827	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)	MM3S4UEP005N1
CS9972799	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)	MM3S4UEP005N1
CS9972823	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)	MM3S4UEP005N1
CS9972794	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)	MM3S4UEP005N1
CS9972830	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)	MM3S4UEP004N2
CS9972768	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker stonithd CRITICAL: 0 /usr/lib64/pacemaker/stonithd processes running (thresh 1:)	MM3S4UEP004N2
CS9972824	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)	MM3S4UEP004N2
CS9972831	Mitsubishi Motors North America, Inc. -- MM3	P2 - Major	Service Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)	MM3S4UEP004N2





[root@adzpx0ci sapmnt]# systemctl status smb.service
â— smb.service - Samba SMB Daemon
   Loaded: loaded (/usr/lib/systemd/system/smb.service; enabled; vendor preset: disabled)
   Active: active (running) since Mon 2021-12-13 01:56:53 CET; 1 weeks 1 days ago
  Process: 2693761 ExecStartPre=/usr/share/samba/update-apparmor-samba-profile (code=exited, status=0/SUCCESS)
 Main PID: 2693764 (smbd)
   Status: "smbd: ready to serve connections..."
    Tasks: 15
   CGroup: /system.slice/smb.service
           â”œâ”€  82685 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€1594500 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€1601587 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€1904755 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€1993554 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2029930 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2038016 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2693764 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2693765 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2693766 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2693768 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2960933 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2960936 /usr/sbin/smbd --foreground --no-process-group
           â”œâ”€2968376 /usr/sbin/smbd --foreground --no-process-group
           â””â”€3746963 /usr/sbin/smbd --foreground --no-process-group

Dec 13 01:56:53 adzpx0ci smbd[2693764]: [2021/12/13 01:56:53.231330,  0] ../lib/util/become_daemon.c:124(daemon_ready)
Dec 13 01:56:53 adzpx0ci systemd[1]: Started Samba SMB Daemon.
Dec 13 01:56:53 adzpx0ci smbd[2693764]:   STATUS=daemon 'smbd' finished starting up and ready to serve connections
Dec 13 02:50:43 adzpx0ci smbd[2772921]: [2021/12/13 02:50:43.550601,  0] ../auth/gensec/gensec.c:241(gensec_verify_features)
Dec 13 02:50:43 adzpx0ci smbd[2772921]:   Did not manage to negotiate mandatory feature SIGN
Dec 13 02:51:51 adzpx0ci smbd[2772921]: [2021/12/13 02:51:51.472968,  0] ../source3/rpc_server/svcctl/srv_svcctl_nt.c:326(_svcctl_OpenServiceW)
Dec 13 10:33:56 adzpx0ci smbd[3521099]: [2021/12/13 10:33:56.440265,  0] ../source3/rpc_server/srv_pipe.c:725(api_pipe_bind_req)
Dec 13 10:33:56 adzpx0ci smbd[3521099]:   unknown interface
Dec 16 17:05:36 adzpx0ci smbd[2984971]: [2021/12/16 17:05:36.594071,  0] ../auth/gensec/gensec.c:241(gensec_verify_features)
Dec 16 17:05:36 adzpx0ci smbd[2984971]:   Did not manage to negotiate mandatory feature SIGN

RCA ref https://access.redhat.com/solutions/5875681



It is a known fact that GNOME is more "resource hungry" than desktop environments like Xfce
Running for long
32262 gdm       20   0 10.675g 9.376g  10684 S  0.000 7.448   1836:01 gnome-shell --mode=gdm
Memory leak for gnome-shell for gdm user [all driver versions]



A0FGSG014XVM029  vm name  for  SJMPEPAA01
ibmsmatt pts/5        146.89.140.60    Fri Dec 24 08:41   still logged in   
ibmrmali pts/4        146.89.140.60    Fri Dec 24 08:38   still logged in   
ibmgbira pts/1        146.89.140.60    Fri Dec 24 08:07   still logged in   
ibmcjaya pts/0        146.89.142.60    Fri Dec 24 08:06   still logged in

ahecdhdb01
146.89.141.91:/storage /storage/


[root@AHECQHDB01 ibmrmalik]$ cat /etc/fstab |grep -i /Staging/sapsft
146.89.140.30:/storage/library/ /Staging/sapsft nfs     defaults,nfsvers=4      0       0


[root@AHECQHDB01 ibmrmalik]$ cat /etc/fstab |grep -i "/storage"
146.89.140.30:/storage/library/ /Staging/sapsft nfs     defaults,nfsvers=4      0       0
146.89.141.91:/storage  /storage        nfs     defaults,nfsvers=4      0       0			

DAL09AMMSOL01	146.89.140.30	146.89.140.30
TOR01AMMSOL01	146.89.141.91	146.89.141.91



HO: CHG0228493: Reboot of esxi host "parhana-1024-10.xsportal.local" to fix raid issue.
Shutdown of below listed vhana servers hosted on esxi server "parhana-1024-10.xsportal.local" required to fix raid issue.
CI3S4HANAQA
CI3S4HANADEV
SL part is completed.
CI3S4HANADEV is up and running and also validated from OS side. APP/DB is also up on this VM.
CI3S4HANAQA: Booting is in-progress.
Relabeling is in-progress which will take time.
Please update about progress to Dineshkumar D. 

parhana-1024-10.xsportal.local
10.127.155.114
root
zDJ3La%F9xW5hG@

to 146.89.142.160


 /var/chef/cache/chef-stacktrace.out




TSLEECQA	10.207.63.14	10.170.63.15
10.162.24.222	tata-che01-pod1-phana-6114-2.imzcloud.ibmammsap.local


	CS9906515	Cascades Canada Ulc -- CD4	TSM: mon01ammtsm001.ibmammsap.local ANR2579E Schedule @1102 in domain D30_SMR_SHORT for node CD4_CD4ECPAS1_FIL_DLY failed (return code -99).~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
	CS10021884	Liberty Utilities (Canada) Corp -- LBU	TSM: wdc04ammtsm002.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2130 in domain D14_SMR_SHORT for node LBU_LBUQA2AP01_FIL_DLY has missed its scheduled start up	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS10034692	Entegris -- ENT	TSM: a0001p5rapp0013 ANR2578W Schedule 1TY_FIL_INC_1800_SUN in domain Y07_SMR_LONG for node ENT_ETGRWS09HANAH_FIL_YLY has missed its scheduled start up window.~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS10032518	PT Anugerah Pharmindo Lestari -- PTP	TSM: sng01ammtsm003.ibmammsap.local ANR2578W Schedule 7TW_FIL_INC_2130 in domain D60_SMR_SHORT for node PTP_PTPRINJANI_FIL has missed its scheduled start up win	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
CS10040153	Viewnext, S.A. -- VXT	TSM: a0001p5rapp7001 ANR2578W Schedule 7TW_FIL_INC_2230 in domain D30_SMR_SHORT for node VXT_VXTEC-P_FIL_DLY has missed its scheduled start up window.~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
	
	CS10039578	Smiths Group plc -- SM9	TSM: fra02ammtsm002.ibmammsap.local ANR2579E Schedule DLY_INC_2130 in domain DO_MONTH_NORM for node SM9_SM9L182172004_FIL failed (return code 12).~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
	CS9949588	American Airlines -- A1A	TSM: dal09ammtsm001.ibmammsap.local ANR2578W Schedule DLY_INC_1830 in domain HEC_N_FIL for node A1A_AHECQHDB01_FIL has missed its scheduled start up window.~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
	CS10022030	Vaisala -- VAI	TSM: a0001p5rapp6003 ANR2578W Schedule WLY_INC_0300 in domain BU3-AG-WEEKLY for node VL1_VL1LONNIND102_FIL_WLY has missed its scheduled start up window.~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS10014934	Entegris -- ENT	TSM: a0001p5rapp0010 ANR2578W Schedule 7TW_FIL_INC_0230 in domain D30_SMR_SHORT for node ENT_ETGRWS50_FIL_DLY has missed its scheduled start up window.~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS10040069	Saputo, Inc -- SAU	TSM: tor01ammtsm002.ibmammsap.local ANR2579E Schedule 1MO_FULL_4WK_SAT in domain D60_SMR_SHORT for node SAU_SAUDM1APP01D_FIL_DLY failed (return code -99).~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		Windows CS10030899	Controladora De Negocios -- CNG	TSM: dal09ammtsm001.ibmammsap.local ANR2578W Schedule DLY_INC_2200 in domain DAL_P_BOX for node FAM_GRC01_FIL has missed its scheduled start up window.~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS10023661	Panasonic Europe Ltd -- PEU	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 1MO_FULL_4WK_SAT in domain D60_SMR_SHORT for node PEU_PEU-A4P-CI_FIL_DLY failed (return code -99).~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS10025835	Dilip Buildcon Limited -- DLB	TSM: che01ammtsm001.ibmammsap.local ANR2578W Schedule DLY_INC_0030 in domain NFL_N_FIL for node DLB_DLBPCSDA00_FIL has missed its scheduled start up window.~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS10031384	Panasonic Europe Ltd -- PEU	TSM: fra02ammtsm003.ibmammsap.local ANR2579E Schedule 1MO_FULL_4WK_SUN in domain D60_SMR_SHORT for node PEU_PEU-A4P-DB-HA_FIL_DLY failed (return code 12).~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B2
		CS9943602	IBM Internal -- CCP	TSM: fmsprdtsm001.fms.ibmcloud.com ANR2579E Schedule DLY_INC_0000 in domain NFL_N_FIL for node AMM_FRIBMCLDCCS01_FIL failed (return code 12).~	SQ-SAP-TRIO-B2	SQ-SAP-TRIO-B2
		CS10014391	Entegris -- ENT	TSM: a0001p5rapp0010 ANR2578W Schedule 7TW_FIL_INC_0030 in domain D30_SMR_SHORT for node ENT_ETGRWS90_FIL_DLY has missed its scheduled start up window.~	SQ-SAP-TRIO-B1	SQ-SAP-TRIO-B1
		CS10031725	Bumrungrad Hospital Plc -- BUM	TSM: sng01ammtsm003.ibmammsap.local ANR2578W Schedule 1TY_FIL_INC_1800_SUN in domain Y02_SMR_LONG for node BUM_BUMSAPCSP01P_FIL_YLY has missed its scheduled sta	SQ-SAP-TRIO-B1	SQ-SAP-TRIO-B1
		CS9830502	PT Anugerah Pharmindo Lestari -- PTP	TSM: sng01ammtsm003.ibmammsap.local ANR2579E Schedule MLY_FULL_4WK_SUN in domain DFL_P_FIL for node PTP_PTPDERAWAN_FIL failed (return code -99).~	MA-ASGN-SAP-BUR	SQ-SAP-TRIO-B1
		CS10040407	SR Technics Switzerland Ltd. -- SRT	TSM: fra02ammtsm004.ibmammsap.local ANR2579E Schedule 7TW_FIL_INC_0030 in domain D30_SMR_SHORT for node SRT_SRTMDDASCS_FIL failed (return code 12).~	SQ-SAP-TRIO-B1	SQ-SAP-TRIO-B1




SPSVEPAEAPP01	A0EASG014XVM024




dlthpehdb4	10.143.69.160	delta-dal09-phana-4096-03.imzcloud.ibmammsap.local

dlthpehdb4s	10.143.69.254	delta-dal09-phana-4096-04.imzcloud.ibmammsap.local

Node Attributes:
* Node dlthpehdb4:
    + hana_hpe_remoteHost               : dlthpehdb4s
    + hana_hpe_roles                    : 127:-:
    + hana_hpe_site                     : NODEA
    + hana_hpe_srmode                   : sync
    + hana_hpe_vhost                    : dlthpehdb4
    + lpa_hpe_lpt                       : 1561986296
* Node dlthpehdb4s:
    + hana_hpe_op_mode                  : logreplay
    + hana_hpe_remoteHost               : dlthpehdb4
    + hana_hpe_site                     : NODEB
    + hana_hpe_srmode                   : sync
    + hana_hpe_vhost                    : dlthpehdb4s
    + lpa_hpe_lpt                       : 30


su - hpeadm -c "hdbnsutil -sr_register --remoteHost=dlthpehdb4 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay --name=NODEB"

dlthpehdb4  to dlthpehdb4s	sync

dlthpehdb4s	dlthpehdb4-dr  async


dlthpehdb4-dr	10.148.24.149	delta-wdc04-phana-4096-01.imzcloud.ibmammsap.local


dlthpehdb4s:/home/ibmrmalik # last reboot
reboot   system boot  4.4.121-92.117-d Wed Dec 29 22:16


CS2618560 SL ticket 12 days back

Severity 1: Server not accessible and moniroing shows ping down. Status disconnected. Possible hung
New | CS2634201 | 39 seconds ago


TSLEECQA
10.162.24.222	tata-che01-pod1-phana-6114-2.imzcloud.ibmammsap.local

IPMI 10.162.24.254	root / Hl56jLgs66
834-939




Source
DLTHQGGA1 10.4.5.42 	10.250.17.42
DLTHQGGAT 10.4.5.34 	10.250.17.34
DLTQEGGAT 10.4.5.176 	10.250.17.180
Destination
DLTHSGGAT 10.4.5.24 	10.250.17.24


Telnet is not working from Source - 10.250.17.42/10.250.17.34 to destination 10.250.17.24 port 3300

[root@dlthqgga1 ibmmhussain]$ telnet 10.250.17.24 3300
Trying 10.250.17.24...
telnet: connect to address 10.250.17.24: Connection timed out

But it is working from 10.250.17.180


Please check the Port 3300 is allowed to accept traffic from below source IPs. 

Source - 10.250.17.42/10.250.17.34/10.250.17.180
Destination - 10.250.17.24
Port â€“ 3300



SVLS1SRV0 - Linux Server - Development - AGEAS -- AGE - SAPB1
TNGDEVEAPP40 - Linux Server - Development - TNG	DFJ Trung Nguyen Group Corporation -- TNG - SAPB1
	agesvtp2srv1 - Windows Server - Production - AGEAS -- AGE - SAPB1
	hgyjumpserver - Windows Server - Development - Hengyuan Refining Company Berhad -- HGY - SAPB1
	svms1srv0 - Windows Server - Development - AGEAS -- AGE - SAPB1
SAP B2:
	ppldcprbisr01 - Windows Server - Production - Parle Biscuits Pvt. Ltd -- PPL - SAPB2
	am3jumpserver - Windows Server - Production - Amos Group Limited -- AM3 - SAPB2
btks4qcs01 - Linux Server - Development - Breadtalk Group Pte Ltd -- BTK - SAPB2
Internal:
frsngprxy01 - Linux Server - Production - IBM Internal -- CCP - INTERNAL-SL


A0EASG012XVM066		cccp1srv0	Windows
A0EASG014XVM009		SVAD1SRV0	RHEL		validated
A0EASG014XVM019			svhq1srv0	RHEL	RETIRED
A0EASG012XVM055		SPSVMPLMASE01	WIndows
A0EASG012XVM057		SPSVTPLNAPP01	Windows
A0EASG012XVM003		SVFD1SRV0	Windows
A0EASG014XVM037		SPSVWPAWAPP11	RHEL		validated
A0EASG014XVM010		svld1srv0	RHEL		validated
A0EASG012XVM013		swtssrv01	WIndows
A0EASG012XVM027		svnq1srv0	Windows
A0EASG014XVM020		svpq1srv0	RHEL		validated
A0EASG014XVM016		svsq1srv0	RHEL		Pending deactivation
A0EASG014XVM007		SVCD1SRV0	RHEL  		validated
A0EASG014XVM012		svpd1srv0	RHEL		validated



SVLS1SRV0 - Linux Server - Development - AGEAS -- AGE - SAPB1
TNGDEVEAPP40 - Linux Server - Development - TNG	DFJ Trung Nguyen Group Corporation -- TNG - SAPB1
btks4qcs01 - Linux Server - Development - Breadtalk Group Pte Ltd -- BTK - SAPB2
frsngprxy01 - Linux Server - Production - IBM Internal -- CCP - INTERNAL-SL
A0EASG014XVM009		SVAD1SRV0	RHEL		validated
A0EASG014XVM037		SPSVWPAWAPP11	RHEL		validated
A0EASG014XVM010		svld1srv0	RHEL		validated
A0EASG014XVM020		svpq1srv0	RHEL		validated
A0EASG014XVM007		SVCD1SRV0	RHEL  		validated
A0EASG014XVM012		svpd1srv0	RHEL		validated




CS10082147	Tech Data Corporation -- ZEC	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 31.14 (thresh: 30)	GBWPAS3
CS10082053	Tech Data Corporation -- ZEC	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 35.17 (thresh: 30)	GBWPAS4
CS10081925	Tech Data Corporation -- ZEC	P2 - Major	LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 38.77 (thresh: 30)	GBWPAS5



SPSVBPDAASE01	10.6.3.19	A0EASG014XVM027
spsvbpaaapp01	10.6.3.20	A0EASG014XVM042
CHG0229240	04-01-2022 22:00:00	05-01-2022 04:00:00



2022-01-05 10:27:17 reboot
reboot   system boot  5.3.18-24.96-def Wed Jan  5 10:31   still running


[root@szudvij02 protocolfiles]# kdumptool calibrate
Total: 380926
Low: 72
High: 228
MinLow: 72
MaxLow: 2848
MinHigh: 0
MaxHigh: 377856


SIZE_HIGH = RECOMMENDATION + (LUNs / 2)
228+


[root@szudvij02 protocolfiles]# cat /proc/cmdline
BOOT_IMAGE=/boot/vmlinuz-5.3.18-24.96-default root=/dev/mapper/rootvg-rootlv apparmor=1 security=apparmor audit_backlog_limit=8192 audit=1 numa_balancing=disable intel_idle.max_cstate=1 processor.max_cstate=1 elevator=noop vmw_pvscsi.cmd_per_lun=254 vmw_pvscsi.ring_pages=32 transparent_hugepage=never resume=/dev/system/swap splash=silent quiet showopts numa_balancing=disable intel_idle.max_cstate=1 processor.max_cstate=1 elevator=noop vmw_pvscsi.cmd_per_lun=254 vmw_pvscsi.ring_pages=32 transparent_hugepage=never


create "sapautodr" ID in these 2 servers - sapapp36 (CFN-10.170.61.115/IFN-10.207.61.197) and sapapp37 (CFN-10.170.61.107/IFN-10.207.61.156)with the following permissions/groups.


uid=99491(sapauto) gid=1513(domain_users) groups=1513(domain_users),2508(vpn access),7625(ibm amm support master access group (global)),7628(ibm amm support master access group (us only)),8501(preprodadmins_ww),8555(preprodadmins_usonly),8989(amm - build - sap (global)),9043(amm - build - sap (us only)),11041(amm - sap projects (global)),11095(amm - sap projects (us only)),18426(sapsys_ww),18480(sapsys_usonly) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023



*************************************************************************************
AGEAS upgrade RHEL 6.10-7.9

BOBJ DB server - spsvbpdaase01 (10.6.3.19)	A0EASG014XVM027
BOBJ Application server - spsvbpaaapp01	(10.6.3.20)	A0EASG014XVM042

The tarball with results is stored in '/root/preupgrade-results/preupg_results-220106123603.tar.gz' .
The latest assessment is stored in the '/root/preupgrade' directory.
Summary information:
We have found some critical issues. In-place upgrade or migration is not advised.
Read the file /root/preupgrade/result.html for more details.
Please ensure you have backed up your system and/or data
before doing a system upgrade to prevent loss of data in
case the upgrade fails and full re-install of the system
from installation media is needed.
Upload results to UI by the command:
e.g. preupg -u http://example.com:8099/submit/ -r /root/preupgrade-results/preupg_results-220106123603.tar.gz .
[root@spsvbpdaase01 tmp]$

preupg -u http://10.6.3.19:8099/submit/ -r /root/preupgrade-results/preupg_results-220106123603.tar.gz

The following packages from the 'Desktop' yum group, which provides the GNOME desktop environment, were detected to be installed on your system: control-center gdm gdm-user-switch-applet gnome-panel gnome-power-manager gnome-screensaver gnome-session gnome-terminal gvfs-archive gvfs-fuse gvfs-smb metacity nautilus notification-daemon polkit-gnome xdg-user-dirs-gtk yelp control-center-extra eog gnome-applets gnome-media gnome-packagekit gnome-vfs2-smb gok orca vino

The following packages from the 'KDE Desktop' yum group, which provides the KDE desktop environment, were detected to be installed on your system: ibus-qt



2022-01-06 14:37:54 yum remove gnome-bluetooth
  506  2022-01-06 14:38:41 yum remove gnome-disk-utility
  507  2022-01-06 14:39:00 yum remove gnome-media-libs
  508  2022-01-06 14:39:26 yum clean all
  509  2022-01-06 14:42:55 yum remove gnome-session-xsession
  510  2022-01-06 14:52:00 yum remove gnome-settings-daemon gnome-user-share

*************************************************************************************


ibmsapprd.conmet.dom    10.68.11.47




CHG0228269 TTA snapshot	08-01-2022 07:00:00	08-01-2022 08:00:00



To access this RDTS-based course material, you must be on-boarded to the RDTS tool through a supported account - For account on-boarding contacts, please see this link https://ibm.biz/BdFzJu

---------------------------------------------------------------------------------------------

  my OS access not working on below servers , ID-ibmkparihar error message - access denied . Please check on urgent basis

HANA PROD DB -
100.126.64.144	SCRBWPDEFRA11
100.126.64.176	SCRBWPDEFRA12	
100.126.64.150	SCRBWPDEFRA13
100.126.64.147	SCRBWPDEFRA19	
HANA Pre-PROD DB
100.126.64.80	SCRBWRDEFRA41	no issues found
100.126.64.78	SCRBWRDEFRA42	
100.126.64.108	SCRBWRDEFRA43	


Sai Ramya Anapindi  11:55 PM
Please let us know why this change is marked as failed- CHG0229786


CHG0227109  
CS10171291		https://10.170.32.132/ui/



enable the SRM Replication for BOP:
Hostname	CFN IP	         IFN IP
SAPBOREPO	10.170.61.56	10.207.61.40
SAPBOPRD	10.170.61.58	10.207.61.205
SAPBOWAPP	10.170.61.33	10.207.61.73

CIFS VFS: Unexpected lookup error -112
CIFS VFS: Unexpected lookup error -112
CIFS VFS: Unexpected lookup error -112
CIFS VFS: Unexpected lookup error -112
RPC: fragment too large: 369295616
RPC: fragment too large: 369295360
RPC: fragment too large: 352518400
RPC: fragment too large: 369295616
RPC: fragment too large: 369295618
RPC: fragment too large: 369295616
RPC: fragment too large: 369295618
RPC: fragment too large: 369295362
RPC: fragment too large: 4194560
RPC: fragment too large: 1195725856
RPC: fragment too large: 1212501072
RPC: fragment too large: 50331667
CIFS VFS: Server 10.21.0.19 has not responded in 120 seconds. Reconnecting...
CIFS VFS: Unexpected lookup error -112
CIFS VFS: Unexpected lookup error -112
CIFS VFS: Unexpected lookup error -112
CIFS VFS: Unexpected lookup error -112
SELinux: initialized (dev cifs, type cifs), uses genfs_contexts
SELinux: initialized (dev cifs, type cifs), uses genfs_contexts
You have mail in /var/mail/root
[root@MGGGBJQECCX01 SAP_LT]$



/10.220.4.160/SAP_LT           /SAP_LT         cifs guest,_netdev,uid=eeqadm,gid=sapsys,rw 0 0


Error executing action `run` on resource 'execute[join_ads_domain]'


export CHEF_ORG=<customer code>;rake bootstrap:cms3x[root,<ifn IP>,cms3x_cfg,production,<hostname>.imzcloud.ibmammsap.local,<SITECODE>

export CHEF_ORG=zec;rake bootstrap:cms3x[root,10.25.213.61,cms3x_cfg,production,gbwqhdb00.imzcloud.ibmammsap.local]

export CHEF_ORG=zec;rake bootstrap:cms3x[root,10.25.213.61,cms3x_cfg,production,gbwqhdb00.imzcloud.ibmammsap.local]



10.194.67.18	fra02-pod2-4tb-host20.imzcloud.ibmammsap.local

VM name A0D8DE014XVM006 hostname is FRAMAGSPO0003


/system.slice/ds_agent.service
           â”œâ”€2018652 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
           â”œâ”€2018653 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
           â”œâ”€2018710 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R
           â””â”€2018725 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R



cd /usr/local/ncpa/etc/ncpa.cfg.d/
update file suse-pacemaker.cfg to remove the below 2 lines->
%HOSTNAME%|__SUSE__Service__CRITICAL__iscsid.service__ = /plugins/cmas_check_svc.sh/iscsid.service
%HOSTNAME%|__SUSE__Service__CRITICAL__sbd.service__ = /plugins/cmas_check_svc.sh/sbd.service
execute the command-> systemctl restart ncpa_passive

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

CHG0231123	AGEAS - RHEL 6.10 to  7.9  Upgrade on  APP NOTE: systems will be down for 11 hours	22-01-2022 06:30:00	22-01-2022 17:30:00

BOBJ DB server - spsvbpdaase01 (10.6.3.19)	A0EASG014XVM027
[root@spsvbpdaase01 tmp]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
cat: /etc/os-release: No such file or directory
Linux spsvbpdaase01 2.6.32-754.35.1.el6.x86_64 #1 SMP Wed Sep 16 06:48:01 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jan 21 21:30:58 +08 2022
bash: timedatectl: command not found
#146.89.141.91:/storage /storage nfs _netdev,defaults    1 2
OK: No read-only file systems found

[root@spsvbpdaase01 /]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="Red Hat Enterprise Linux Server"
VERSION="7.9 (Maipo)"
ID="rhel"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="7.9"
PRETTY_NAME="Red Hat Enterprise Linux Server 7.9 (Maipo)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:redhat:enterprise_linux:7.9:GA:server"
HOME_URL="https://www.redhat.com/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"

REDHAT_BUGZILLA_PRODUCT="Red Hat Enterprise Linux 7"
REDHAT_BUGZILLA_PRODUCT_VERSION=7.9
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="7.9"
Linux spsvbpdaase01 3.10.0-1160.53.1.el7.x86_64 #1 SMP Thu Dec 16 10:19:28 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
Sat Jan 22 11:50:57 +08 2022
      Local time: Sat 2022-01-22 11:50:57 +08
  Universal time: Sat 2022-01-22 03:50:57 UTC
        RTC time: Sat 2022-01-22 03:50:57
       Time zone: Asia/Singapore (+08, +0800)
     NTP enabled: yes
NTP synchronized: no
 RTC in local TZ: no
      DST active: n/a
#146.89.141.91:/storage /storage nfs _netdev,defaults    1 2
OK: No read-only file systems found

preupg -u http://10.6.3.19:8099/submit/ -r /root/preupgrade-results/preupg_results-220121215725.tar.gz .
[root@spsvbpdaase01 tmp]$

Chef Client finished, 193/880 resources updated in 11 minutes 03 seconds
You have mail in /var/mail/root
[root@spsvbpdaase01 getty.target.wants]$

Skipped (dependency problems):
  libsodium.x86_64 0:1.0.18-1.el7            libunwind.x86_64 2:1.2-2.el7                 openpgm.x86_64 0:5.2.122-17.el8             python3-distro.noarch 0:1.2.0-4.el8           python3-m2crypto.x86_64 0:0.33.0-1.el8
  python3-msgpack.x86_64 0:0.6.1-3.el8       python3-psutil.x86_64 0:5.4.3-8.el8          python3-typing.noarch 0:3.5.2.2-4.el8       python3-zmq.x86_64 0:17.0.0-5.el8             python36-chardet.noarch 0:3.0.4-12.el7
  python36-idna.noarch 0:2.7-5.el7           python36-pycurl.x86_64 0:7.43.0-8.el7        python36-pysocks.noarch 0:1.6.8-6.el7       python36-requests.noarch 0:2.12.5-4.el7       python36-rpm.x86_64 0:4.11.3-8.el7
  python36-six.noarch 0:1.11.0-4.el7         python36-urllib3.noarch 0:1.19.1-6.el7       salt.noarch 0:3002.7-1.el8                  salt-minion.noarch 0:3002.7-1.el8             zeromq.x86_64 0:4.3.1-4.el8

Transaction check error:
  file /usr/lib/python2.7/site-packages/packagekit/__init__.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/__init__.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/backend.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/backend.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/enums.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/enums.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/filter.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/filter.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/misc.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/misc.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/package.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/package.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/progress.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/progress.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64

Error Summary
-------------

Error: Packages have not been installed
You have mail in /var/mail/root
[root@spsvbpdaase01 preupgrade]$ 


BOBJ Application server - spsvbpaaapp01	(10.6.3.20)	A0EASG014XVM042
[root@spsvbpaaapp01 tmp]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
cat: /etc/os-release: No such file or directory
Linux spsvbpaaapp01 2.6.32-754.35.1.el6.x86_64 #1 SMP Wed Sep 16 06:48:01 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Fri Jan 21 21:30:58 +08 2022
bash: timedatectl: command not found
#tor01ammsol01:/storage /storage nfs _netdev,defaults    0 0
OK: No read-only file systems found
/sapwin *(ro,sync)

[root@spsvbpaaapp01 ibmrmalik]$ cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports
NAME="Red Hat Enterprise Linux Server"
VERSION="7.9 (Maipo)"
ID="rhel"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="7.9"
PRETTY_NAME="Red Hat Enterprise Linux Server 7.9 (Maipo)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:redhat:enterprise_linux:7.9:GA:server"
HOME_URL="https://www.redhat.com/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"

REDHAT_BUGZILLA_PRODUCT="Red Hat Enterprise Linux 7"
REDHAT_BUGZILLA_PRODUCT_VERSION=7.9
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="7.9"
Linux spsvbpaaapp01 3.10.0-1160.53.1.el7.x86_64 #1 SMP Thu Dec 16 10:19:28 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
Sat Jan 22 11:52:27 +08 2022
      Local time: Sat 2022-01-22 11:52:27 +08
  Universal time: Sat 2022-01-22 03:52:27 UTC
        RTC time: Sat 2022-01-22 03:52:27
       Time zone: Asia/Singapore (+08, +0800)
     NTP enabled: yes
NTP synchronized: no
 RTC in local TZ: no
      DST active: n/a
#tor01ammsol01:/storage /storage nfs _netdev,defaults    0 0
OK: No read-only file systems found
/sapwin *(ro,sync)


Chef Client finished, 193/887 resources updated in 10 minutes 57 seconds
You have mail in /var/mail/root
[root@spsvbpaaapp01 getty.target.wants]$

Transaction check error:
  file /usr/lib/python2.7/site-packages/packagekit/__init__.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/__init__.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/backend.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/backend.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/enums.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/enums.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/filter.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/filter.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/misc.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/misc.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/package.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/package.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/progress.pyc from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64
  file /usr/lib/python2.7/site-packages/packagekit/progress.pyo from install of PackageKit-1.1.10-2.el7.i686 conflicts with file from package PackageKit-1.1.10-2.el7.x86_64

Error Summary
-------------

Error: Packages have not been installed
[root@spsvbpaaapp01 preupgrade]$
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

208.91.197.39


[2022-01-25T04:37:31+01:00] INFO: Starting Chef Run for par01ammtsm001.imzcloud.ibmammsap.local
[2022-01-25T04:37:31+01:00] INFO: Running start handlers
[2022-01-25T04:37:31+01:00] INFO: Start handlers complete.
[2022-01-25T04:37:32+01:00] ERROR: Server returned error 504 for https://PAR01AMMCHEF01.IMZCLOUD.IBMAMMSAP.LOCAL/organizations/fmsprodinfra/data-collector, retrying 1/5 in 3s
[2022-01-25T04:37:36+01:00] ERROR: Server returned error 504 for https://PAR01AMMCHEF01.IMZCLOUD.IBMAMMSAP.LOCAL/organizations/fmsprodinfra/data-collector, retrying 2/5 in 8s
[2022-01-25T04:37:45+01:00] ERROR: Server returned error 504 for https://PAR01AMMCHEF01.IMZCLOUD.IBMAMMSAP.LOCAL/organizations/fmsprodinfra/data-collector, retrying 3/5 in 12s
[2022-01-25T04:37:58+01:00] ERROR: Server returned error 504 for https://PAR01AMMCHEF01.IMZCLOUD.IBMAMMSAP.LOCAL/organizations/fmsprodinfra/data-collector, retrying 4/5 in 22s
[2022-01-25T04:38:21+01:00] ERROR: Server returned error 504 for https://PAR01AMMCHEF01.IMZCLOUD.IBMAMMSAP.LOCAL/organizations/fmsprodinfra/data-collector, retrying 5/5 in 49s


 ================================================================================
  Recipe Compile Error in /var/chef/cache/cookbooks/cms3x_cfg/recipes/default.rb
  ================================================================================

  Resolv::ResolvError
  -------------------
  DNS result has no information for par01ammadc001.imzcloud.ibmammsap.local

  Cookbook Trace:
  ---------------
    /var/chef/cache/cookbooks/cms3x_cfg/libraries/cms3x_cfg_dns_forwarder.rb:74:in `getaddress'
    /var/chef/cache/cookbooks/cms3x_cfg/libraries/cms3x_cfg_node.rb:96:in `name2ip'
    /var/chef/cache/cookbooks/cms3x_cfg/libraries/cms3x_cfg_command_helper.rb:38:in `ip4route2'
    /var/chef/cache/cookbooks/cms3x_cfg/libraries/cms3x_cfg_node.rb:227:in `linuxad_auth_ip'
    /var/chef/cache/cookbooks/cms3x_cfg/recipes/linuxad_auth.rb:9:in `from_file'
    /var/chef/cache/cookbooks/cms3x_cfg/libraries/cms3x_cfg.rb:34:in `cms3x_include_recipe'
    /var/chef/cache/cookbooks/cms3x_cfg/recipes/default.rb:56:in `from_file'

  Relevant File Content:
  ----------------------
  /var/chef/cache/cookbooks/cms3x_cfg/libraries/cms3x_cfg_dns_forwarder.rb:

   67:          end
   68:
   69:          r4 ? r4[:dns] : @default_resolver[:dns]
   70:        end
   71:
   72:        # Find the address for name using the appropirate @domain_resolver
   73:        def getaddress(name)
   74>>         resolver4(name).getaddress(name)
   75:        end
   76:      end
   77:    end
   78:  end
   79:

  System Info:
  ------------
  chef_version=13.9.4
  platform=redhat
  platform_version=7.9
  ruby=ruby 2.4.4p296 (2018-03-28 revision 63013) [x86_64-linux]
  program_name=chef-client worker: ppid=23377;start=04:37:16;
  executable=/opt/chef/bin/chef-client

[root@par01ammtsm001 ~]# ping par01ammadc001.imzcloud.ibmammsap.local
PING PAR01AMMADC001 (146.89.142.137) 56(84) bytes of data.
64 bytes from PAR01AMMADC001 (146.89.142.137): icmp_seq=1 ttl=128 time=0.187 ms
64 bytes from PAR01AMMADC001 (146.89.142.137): icmp_seq=2 ttl=128 time=0.341 ms
64 bytes from PAR01AMMADC001 (146.89.142.137): icmp_seq=3 ttl=128 time=0.290 ms
64 bytes from PAR01AMMADC001 (146.89.142.137): icmp_seq=4 ttl=128 time=0.121 ms
64 bytes from PAR01AMMADC001 (146.89.142.137): icmp_seq=5 ttl=128 time=0.157 ms
^C
--- PAR01AMMADC001 ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 3999ms
rtt min/avg/max/mdev = 0.121/0.219/0.341/0.083 ms


10.143.69.254	delta-dal09-phana-4096-04.imzcloud.ibmammsap.local


CS10324649	snc#snchmdaqd11#System MegaRAID Drive Media Errors CRITICAL: [See KB0015294] Media Error Count = 2
10.166.238.164	torhana-1024-35.xsportal.local

Drive /c0/e8/s13 - Detailed Information :
Shield Counter = 0
Media Error Count = 3
Other Error Count = 0
Drive Temperature =  33C (91.40 F)
Predictive Failure Count = 0
S.M.A.R.T alert flagged by drive = No
SN = 6SLAF7A70000N54501QJ
Firmware Revision = 0730000B

ccp3app ibmabald pts/10       146.89.140.60    Tue Jan 25 17:54 - 17:56  (00:01)ANA LIDIA FALCON BALDERAS	994  2022-01-25 17:56:07 passwd cp3adm


//AGESVTQ2SRV1/STRS_Spool  /usr/sap/OpenText_QA/STRS_Spool cifs vers=1.0,username=msgteam,password=Welcome@123 0 0

//AGESVTQ2SRV1/STRS_Output   /usr/sap/OpenText_QA/STRS_Output cifs vers=2.0,username=msgteam,password=Welcome@123 0 0


//AGESVTQ2SRV1/STRS_Output/SOA_DIVISION

//AGESVTQ2SRV1/STRS_Output/SOA_STORE


SOA_DIVISION (file://AGESVTQ2SRV1/STRS_Output/SOA_DIVISION)


//AGESVTQ2SRV1/STRS_Output/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_STORE	cifs vers=1.0,username=msgteam,password=Welcome@123 0 0


//AGESVTQ2SRV1/STRS_Output/SOA_DIVISION	/usr/sap/OpenText_QA/STRS_Output/SOA_STORE	cifs vers=1.0,domain=AGESVTQ2SRV1,username=msgteam,password=Welcome@123 0 0

//AGESVTQ2SRV1/STRS_Output/SOA_STORE /usr/sap/OpenText_QA/STRS_Output/SOA_DIVISION	cifs vers=1.0,domain=AGESVTQ2SRV1,username=msgteam,password=Welcome@123 0 0




//AGESVTQ2SRV1/STRS_Spool                                       /usr/sap/OpenText/STRS_Spool

//AGESVTQ2SRV1/STRS_Output                                     /usr/sap/OpenText/STRS_Output

//AGESVTQ2SRV1/STRS_Output/SOA_DIVISION              /usr/sap/OpenText/STRS_Output/SOA_DIVISION

//AGESVTQ2SRV1/STRS_Output/SOA_STORE                  /usr/sap/OpenText/STRS_Output/SOA_STORE




SM9DCNLCSLX01
10.127.235.193	smiths-par01-pod1-phana-1024-01.imzcloud.ibmammsap.local
ipmi  root 10.127.235.194     SztHlCBR7F



CS10330802

CS10333784	PN8



CS10395367	Bombardier Recreational Products Inc -- BR3	P3 - Minor	File system increase (/usr/sap/T4H)	BR3TSAPAS20
CS10395916      Bombardier Recreational Products Inc -- BR3SJL: Required files for ADS



gltbwdb01-dr - GLT
hfcsmphndb1dr - HFC



CS10403168 this was handed over this morning to me. Update RH case and https://kyndryl.slack.com/team/U028Y5Q0J3T accordingly
-----------
CS10431243 PDL needs to know why server rebooted. I could not get to it due to heavy workload
10.134.17.122	rexqbfchana1.rxlfra.hec.sap.biz

10.134.17.123	root HBq4eHnq7M

su - root
May55now#
exit
su - sapautodr
Security#1
exit
sudo su
pam_tally2 --reset;chage -l root;chage -l sapautodr
touch /tmp/testfilerm




CHG0232766	Task2: [OS]: OS reboot - MGGGBJPECCX10

[root@MGGGBJPECCX10 ibmrmalik]$ df -hT |grep -i cifs
                     cifs   100G   18G   83G  18% /SAPUpload
                     cifs   400G  362G   39G  91% /edsrep
                     cifs   400G  362G   39G  91% /SAP_LT
                     cifs    17G  1.6G   15G  10% /Archamps/sap_ii
                     cifs    17G  1.6G   15G  10% /Archamps/sap_io
                     cifs   100G   13G   88G  13% /WMfileTransfer
                     cifs   1.5T  205G  1.3T  14% /sapupload_nh
                     cifs   150G   18G  132G  12% /interfaces/Azure
                     cifs   2.0T  1.7T  303G  86% /interfaces/bartender
                     cifs   3.0T  2.2T  841G  73% /interfaces/SAPReports/1110
                     cifs   1.8T  1.6T  206G  89% /interfaces/SAPReports/3325
//10.10.7.160/sap    cifs   9.9G  1.3G  8.7G  13% /Fribourg
                     cifs   3.7T  3.6T  120G  97% /interfaces/SAPReports/3110
                     cifs   2.0T  837G  1.2T  41% /mfg_share
[root@MGGGBJPECCX10 ibmrmalik]$ df -hT |grep -i nfs
                     nfs     25G   14G   11G  57% /interface/EEP
                     nfs     25G   18G  6.0G  75% /sapmnt/EEP
                     nfs     60G   42G   16G  74% /usr/sap/trans
                     nfs    153G   51G   95G  35% /sapdb/ECP/Kofax
                     nfs     55G   17G   35G  34% /sapdb/NCP/Kofax
                     nfs    2.7T  1.9T  673G  74% /mnt/EES_SYSTEM_REFRESH
                     nfs    296G  190M  281G   1% /interfaces/celonis
                     nfs     16G  8.5G  6.6G  57% /sapmnt/EPJ
[root@MGGGBJPECCX10 ibmrmalik]$ date
Sat Feb  5 01:52:31 GMT 2022
[root@MGGGBJPECCX10 ibmrmalik]$ mount -a



tbos4prddb3	Retired as per SNOW
tbos4prddb1	Installed
tbos4prddb2	Installed
TBOS4QA2DB	Pending deactivation


CS10492250	a1a#ahecqhdb01#System MegaRAID Offline or degraded CRITICAL: [See KB0015294] 0 - - - - RAID5 Dgrd N 4.362 TB enbl N N dflt N 0 0 - - - RAID5 Dgrd N 4.362 TB enb
AHECQHDB01	
10.155.223.10	dalhana-1024-15.xsportal.local




Sever		  CFN-IP		IFN-IP
------------------------------------------------
SAPAPP31	  10.170.61.40	10.207.61.84		

[root@sapapp31 ibmrmalik]# crm config show |grep -i "no-quorum-policy"
        no-quorum-policy=ignore \

SAPAPP31-HA	  10.170.61.123	10.207.61.222

SAPCRMAPP4	  10.170.61.160	10.207.61.187

[root@sapcrmapp4 ibmrmalik]# crm config show |grep -i "no-quorum-policy"
        no-quorum-policy=ignore \

SAPCRMAPP4-HA	 10.170.61.180	10.207.61.202

EWMAPP3		  10.170.61.204	10.207.61.114

[root@ewmapp3 ibmrmalik]# crm config show |grep -i "no-quorum-policy"
        no-quorum-policy=ignore \

EWMAPP3-HA	  10.170.61.213	10.207.61.203

tsls4proddb	  10.170.61.225	10.207.61.123

tsls4proddb:/home/ibmrmalik # crm config show |grep -i "no-quorum-policy"
        no-quorum-policy=ignore \

tsls4proddbh  10.170.61.78	10.207.61.113



10.183.44.177	zec-wdc04-pod3-phanaso-h2-1500-001.imzcloud.ibmammsap.local



10.129.214.56	tok02-pod1-4tb-host08.imzcloud.ibmammsap.local
[root@hnosapdbq1 ibmrmalik]# uname -a
Linux hnosapdbq1 4.12.14-95.80-default #1 SMP Thu Jul 15 18:19:59 UTC 2021 (db4c18a) x86_64 x86_64 x86_64 GNU/Linux


agesvepmhsrv2
spsvepaeapp01
OS logs in /var/log/messages and history of the memory utilization in EPP specifically for February 9-10


CHG0233273
AGEAS RHEL 6 to 7 upgrade on 13th Feb2022
SPSVMPLMAPP01	10.6.3.46	10.70.111.46

The tarball with results is stored in '/root/preupgrade-results/preupg_results-220210123636.tar.gz' .
The latest assessment is stored in the '/root/preupgrade' directory.
Summary information:
We have found some potential risks.
Read the full report file '/root/preupgrade/result.html' for more details.
Please ensure you have backed up your system and/or data
before doing a system upgrade to prevent loss of data in
case the upgrade fails and full re-install of the system
from installation media is needed.
Upload results to UI by the command:
e.g. preupg -u http://example.com:8099/submit/ -r /root/preupgrade-results/preupg_results-220210123636.tar.gz 

spsvmplmapp01.eastwestageaslife.com



lpadmin -p PRTENGF -v socket://10.250.43.39:9100 -E
lpadmin -p PRTENGON -v socket://10.250.43.38:9100 -E
lpadmin -p ENGLCVTRF -v socket://10.250.43.42:9100 -E
lpadmin -p PRTENGTM -v socket://10.250.43.40:9100 -E
lpadmin -p PRTEGOK -v socket://10.250.43.41:9100 -E
lpadmin -p PRTINSPANL  -v socket://10.250.41.220:9100 -E
lpadmin -p PRTDBPENAL  -v socket://10.250.43.46:9100 -E
lpadmin -p PRTIC  -v socket://10.250.41.217:9100 -E
lpadmin -p PRTTC -v socket://10.250.41.216:9100 -E
lpadmin -p PRTCABSG -v socket://192.168.13.25:9100 -E
lpadmin -p PRTCABSG1 -v socket://10.250.41.225:9100 -E
lpadmin -p PRTAXLE -v socket://10.250.41.222:9100 -E
lpadmin -p PRTDISC -v socket://10.250.41.228:9100 -E
lpadmin -p PRTFUEL -v socket://10.250.41.221:9100 -E
lpadmin -p PRTFUELT -v socket://10.250.41.224:9100 -E
lpadmin -p PRTRADITOR -v socket://10.250.41.223:9100 -E
lpadmin -p PRTSEAT -v socket://10.250.41.229:9100 -E
lpadmin -p PRTSTERING -v socket://10.250.41.230:9100 -E
lpadmin -p PRTTYRE -v socket://10.250.41.236:9100 -E
lpadmin -p PRTSABOF -v socket://10.250.41.231:9100 -E



RBI retail direct
Application No: CRR/SA/2022/007442


CS10525937NewGulf States Toyota -- GLTGLTS4UATAS02glt#glts4uatas02#CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=92.00% system=8.00% iowait=0.00% idle=0.00%
CS10526301 NewGulf States Toyota -- GLTGLTS4UATAS03glt#glts4uatas03#CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=92.52% system=7.48% iowait=0.00% idle=0.00%"
CS10526889 NewGulf States Toyota -- GLTGLTS4UATAS01glt#glts4uatas01#CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 98%) user=94.12% system=5.88% iowait=0.00% idle=0.00%
CS10526988NewGulf States Toyota -- GLTGLTS4UATAS02glt#glts4uatas02#LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 57.64 (thresh: 30)
CS10527143NewGulf States Toyota -- GLTGLTS4UATAS01glt#glts4uatas01#LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 47.72 (thresh: 30)"
CS10527147NewGulf States Toyota -- GLTGLTS4UATAS03 glt#glts4uatas03#LoadAverage 15 Minute Load Average CRITICAL: 15-Minute Loadavg 60.58 (thresh: 30)



CS10039583
CS10087644
CS10088409
CS10089143
CS10129980



CHG0233273	12-02-2022 06:30:00	12-02-2022 17:30:00	A0EASG014XVM045
AGEAS RHEL 6 to 7 upgrade on 12th Feb2022	
SPSVMPLMAPP01	10.6.3.46	10.70.111.46	created a clone for troubleshooting SPSVMPLMAPP01_clone_7.9

Case to RHEL Case #03148501

The tarball with results is stored in '/root/preupgrade-results/preupg_results-220210123636.tar.gz' .
The latest assessment is stored in the '/root/preupgrade' directory.
Summary information:
We have found some potential risks.
Read the full report file '/root/preupgrade/result.html' for more details.
Please ensure you have backed up your system and/or data
before doing a system upgrade to prevent loss of data in
case the upgrade fails and full re-install of the system
from installation media is needed.
Upload results to UI by the command:
e.g. preupg -u http://example.com:8099/submit/ -r /root/preupgrade-results/preupg_results-220210123636.tar.gz 

spsvmplmapp01.eastwestageaslife.com


[root@spsvmplmapp01 ~]# cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux spsvmplmapp01.eastwestageaslife.com 2.6.32-754.35.1.el6.x86_64 #1 SMP Wed Sep 16 06:48:01 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
Sat Feb 12 09:26:20 +08 2022
//AGESVTP2SRV1/STRS_Output  /usr/sap/OpenText/STRS_Output/ cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/OfficialReceipt    /usr/sap/OpenText/STRS_Output/OfficialReceipt      cifs   _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/SOA_DIVISION  /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/SOA_STORE  /usr/sap/OpenText/STRS_Output/SOA_STORE cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/AFP /sftp/prd/OpenText cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
OK: No read-only file systems found
                     nfs    6.0T  3.5T  2.2T  62% /sds
-bash: timedatectl: command not found
/sftp/prd *(rw,sync,fsid=0,no_root_squash)
/sftp/prd/WC/Logs *(rw,sync,no_root_squash)


[root@spsvmplmapp01 tmp]# cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 7.9 (Maipo)
Linux spsvmplmapp01.eastwestageaslife.com 3.10.0-1160.53.1.el7.x86_64 #1 SMP Thu Dec 16 10:19:28 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
Sat Feb 12 13:44:19 +08 2022
//AGESVTP2SRV1/STRS_Output  /usr/sap/OpenText/STRS_Output/ cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/OfficialReceipt    /usr/sap/OpenText/STRS_Output/OfficialReceipt      cifs   _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/SOA_DIVISION  /usr/sap/OpenText/STRS_Output/SOA_DIVISION cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/SOA_STORE  /usr/sap/OpenText/STRS_Output/SOA_STORE cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
//AGESVTP2SRV1/STRS_Output/AFP /sftp/prd/OpenText cifs _netdev,username=admtmp,password=August@2021_Ageas,iocharset=utf8,dir_mode=0777,file_mode=0777,uid=20000,gid=504 0 0
OK: No read-only file systems found
sng01ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.5T  2.2T  62% /sds
      Local time: Sat 2022-02-12 13:44:20 +08
  Universal time: Sat 2022-02-12 05:44:20 UTC
        RTC time: Sat 2022-02-12 05:44:20
       Time zone: Singapore (+08, +0800)
     NTP enabled: yes
NTP synchronized: yes
 RTC in local TZ: no
      DST active: n/a
/sftp/prd *(rw,sync,fsid=0,no_root_squash)
/sftp/prd/WC/Logs *(rw,sync,no_root_squash)

/var/chef/cache/cookbooks/redhat_subscription_manager/libraries/rhsm_register.rb

[root@spsvmplmapp01 ibmrmalik]# rpm -qa |grep -i el6
RHEL6-RHUI-NA-XSTREAM_091913-2.0-1.noarch
openpgm-5.1.118-3.el6.x86_64
zeromq-4.0.5-4.el6.x86_64
zeromq3-3.2.5-1.el6.x86_64
salt-minion-2019.2.5-1.el6.noarch
rootsh-1.5.3-11.el6.x86_64
nmon-14g-1.el6.rf.x86_64
ds_agent-12.0.0-1436.el6.x86_64




TTA_RP3
TTA_RP1 and TTA_RP4
TTA_RP2

PCP - sappoprdc(CFN-10.170.61.30/IFN-10.207.61.89)
ASD - adsprds   (CFN-10.170.61.25/IFN-10.207.61.29)
EPD - essmssdev(CFN-10.170.61.63/IFN-10.207.61.210)
RQA - ttar3dev (CFN-10.170.61.22/IFN-10.207.61.72)

BOP - sapborepo(CFN-10.170.61.56/IFN-10.207.61.40)
          sapboprd (CFN-10.170.61.58/IFN-10.207.61.205)
         sapbowapp(CFN-10.170.61.33/IFN-10.207.61.73)
DIP - sapcrmdi  (CFN-10.170.61.69/IFN-10.207.61.83)



ttactrl01   shutdown on Chennai

========================= MOUNTED FILE SYSTEM =========================
Filesystem           Type   Size  Used Avail Use% Mounted on
/dev/mapper/vg00-lv_root
                     ext4    26G   11G   14G  44% /
tmpfs                tmpfs  7.8G   88K  7.8G   1% /dev/shm
/dev/sda1            ext4   477M  108M  345M  24% /boot
/dev/mapper/sftp_vg-sftp_lv
                     ext4    59G  3.6G   53G   7% /sftp
sng01ammyum01.imzcloud.ibmammsap.local:/sds
                     nfs    6.0T  3.5T  2.2T  62% /sds
//AGESVTP2SRV1/AFP   cifs   259G   76G  183G  30% /sftp/prd/OpenText
//AGESVTP2SRV1/STRS_Output
                     cifs   259G   76G  183G  30% /usr/sap/OpenText/STRS_Output
//AGESVTP2SRV1/STRS_Output/OfficialReceipt
                     cifs   259G   76G  183G  30% /usr/sap/OpenText/STRS_Output/OfficialReceipt
//AGESVTP2SRV1/STRS_Output/SOA_DIVISION
                     cifs   259G   76G  183G  30% /usr/sap/OpenText/STRS_Output/SOA_DIVISION
//AGESVTP2SRV1/STRS_Output/SOA_STORE
                     cifs   259G   76G  183G  30% /usr/sap/OpenText/STRS_Output/SOA_STORE
//AGESVTP2SRV1/STRS_Output/AFP
                     cifs   259G   76G  183G  30% /sftp/prd/OpenText





========================= MOUNTED FILE SYSTEM =========================
Filesystem                                  Type      Size  Used Avail Use% Mounted on
devtmpfs                                    devtmpfs  7.8G     0  7.8G   0% /dev
tmpfs                                       tmpfs     7.8G   68K  7.8G   1% /dev/shm
tmpfs                                       tmpfs     7.8G   12M  7.8G   1% /run
tmpfs                                       tmpfs     7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/vg00-lv_root                    ext4       26G   17G  7.6G  69% /
/dev/sda1                                   ext4      477M  224M  225M  50% /boot
/dev/mapper/sftp_vg-sftp_lv                 ext4       59G  3.6G   53G   7% /sftp
tmpfs                                       tmpfs     1.6G     0  1.6G   0% /run/user/193933
sng01ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.5T  2.2T  62% /sds



best part of a DR change is people appreciate the efforts after successful completion which otherwise does not happen even if u take extra efforts to complete something critical also.



Dec@@newdelhi@@45


/dev/sdw   ampappvg  lvm2 a--     1.60t       0
/dev/sdx   ampappvg  lvm2 a--  1024.00g    8.77g

 Logical extents 1888558 to 2146918:
    Type                linear
    Physical volume     /dev/sdx
    Physical extents    0 to 258360

Logical extents 1465344 to 1884773:
    Type                linear
    Physical volume     /dev/sdw
    Physical extents    0 to 419429

[root@kstampsrcs ibmrmalik]# lvdisplay /dev/ampappvg/migration_lv
  --- Logical volume ---
  LV Path                /dev/ampappvg/migration_lv
  LV Name                migration_lv
  VG Name                ampappvg
  LV UUID                Dll0n5-JoM0-fWKn-otOF-XMmn-GVyd-l0GfGx
  LV Write Access        read/write
  LV Creation host, time kstampsrcs, 2020-11-06 16:12:41 +0300
  LV Status              available
  # open                 1
  LV Size                8.19 TiB
  Current LE             2146919
  Segments               11
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     1024
  Block device           254:37


those 2 disks 1TB and 1.6 T are being consumed by the migration lv and this seems to be temporary



syd04powertsm001	#scx-sapb2-z3v	Raise a RHEL ticket
Kaushik.ghosh@kyndryl.com
savita.peter.peter@kyndryl.com
kiran.mudide@kyndryl.com
roopesh.injamuri@kyndryl.com

Your sosreport has been generated and saved in:
  /var/tmp/sosreport-syd04powertsm001-Case03153771-2022-02-18-yowgshh.tar.xz


Name for the server in VC is in bracket alongside
apprh65 10.68.210.13 Production (VMName A0DTUS014XVM004)
ciprh01_node2 10.68.210.31 Production (VMname A0DTUS014XVM002_restore)
apprh60 10.68.210.12 Production (VMName A0DTUS014XVM003)



- Login to the vmÂ  as rootÂ 
- Output of lsblk to make sure that the os is now fully able to see the full sizes of the disk.
echo 1 > /sys/block/sdc/device/rescan
echo 1 > /sys/block/sdd/device/rescan
echo 1 > /sys/block/sde/device/rescan
- pvresize /dev/sdc  
***Note: This should correspond to disk that was extended"
- pvresize /dev/sdd
- pvresize /dev/sdeÂ Â Â 
- run lsblk to make sure that the new disk changes are visible
- lvextend -l +100%free /dev/mapper/sapdata-data -r
- lvextend -l +100%free /dev/mapper/sapshared-shared -r
- lvextend -l +100%free /dev/mapper/saplog-log -r
- vgs
- Output of lsblk to make sure that the os is now fully able to see the full sizes of the disk.
- OS reboot and validation


ps --no-header aux | awk '$8~/D/ {printf "\n%s\n", $0; system("cat /proc/" $2 "/stack")}' &gt;&gt; /tmp/pidstack$(date +%F).out ; date &gt;&gt; /tmp/pidstack$(date +%F).out



delta-dal09-phana-4096-02
dlthemhdb4

IPMI root gowngfwfpwoai	10.143.69.184



CHG0233400	19-02-2022 17:30:00	20-02-2022 00:30:00
This 02/19/2022 - 06:00 - NIX  remediation is for the following CIs:
bapccp0100	10.134.5.8	10.8.219.6
bapv110100	10.134.3.11	10.8.217.18	   
bapv120400	10.134.3.6	10.8.217.8
bapv330900	10.134.3.7	10.8.217.13
bapconprd1	10.134.3.8	10.8.217.7	



tbos4prddb1 Installed
tbos4prddb2 Installed

tdpdcprdap1
tdpdcprdap2
tdpdcprdhdb


	CS10625535 P2 ARMFKSAP303A1FRA02-SLArnoldo Mondadori Editore SpA -- ARMARMARM IC4SAP-SL SAP LOBarm#armfksap303a1#Ping Availability CRITICAL - 10.7.102.57: rta nan. lost 100% Attention commas replaced by dots.
	CS10625419 P2 IA2OTAPPDAPDRFRA02-SLIAG - British Airways -- IA2IA2IA2 SAPHEC-IC4SAP-SL SAP LOBia2#ia2otappdapdr#Ping Availability CRITICAL - 10.199.142.15: rta nan. lost 100% Attention commas replaced by dots.
	CS10625381 P2 MNGLON02WEB01LON02-SLManchester Airport Group -- MNGMNGMNG SAP HEC-AMM SAP LOBmng#mnglon02web01#Ping Availability CRITICAL - 10.69.0.101: rta nan. lost 100% Attention commas replaced by dots.
	CS10625287 P2 IA2OTAPRDDBDRFRA02-SLIAG - British Airways -- IA2IA2IA2 SAPHEC-IC4SAP-SL SAP LOBia2#ia2otaprddbdr#Ping Availability CRITICAL - 10.199.142.14: rta nan. lost 100% Attention commas replaced by dots.
	CS10625253 P2 REXBFCHANA1-DRLON02-SLRexel -- HGMHGMHGM SAP HEC-AMM SAP LOBhgm#rexbfchana1-dr#Ping Availability CRITICAL - 10.133.1.71: rta nan. lost 100% Attention commas replaced by dots.
CS10625226 P2 LONMAGBOB0002LON02-SLManchester Airport Group -- MNGMNGMNG SAP HEC-AMM SAP LOBmng#lonmagbob0002#Ping Availability CRITICAL - 10.69.0.24: rta nan. lost 100% Attention commas replaced by dots.
	CS10625215 P2 MNGLON02WEB01LON02-SLManchester Airport Group -- MNGMNGMNG SAP HEC-AMM SAP LOBmng#mnglon02web01#Ping Availability CRITICAL - 10.69.0.101: rta nan. lost 100% Attention commas replaced by dots.
CS10625162 P2 TQANERPPRDAPPFRA02-SLTAQA Arabia -- TQATQATQA AMM-SAP Infrastructure Srvcstqa#tqanerpprdapp#Ping Availability CRITICAL - 10.7.1.147: rta nan. lost 100% Attention commas replaced by dots.




AGEAS SFTP issue
prod spsvmplmapp01
QA svmq1srv1


on QA in authorised
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDAdO7NwyjKdYJxvkL68EG9evsZ6zgt6LQRCuBvrOOxWLkqXGVIoMr9PD4iG6RyhgVvUa4W+u98Cj716yOCHSsUXvmQYxL6a3ELc+k5fmy81YmRc0LsxkcC+axmVao/bJsV7BlMmhv+ObsIXsZOwqNVyHGdjacJpZt99Cgh0Dicobl5/Q6407YqKspZ9QqsWK68tXp+uLFSsio+XzvZjDKgXaP5P9XP9/zeeB0itSFYguGGxhgGmOsklSxMoOave/Zi9+g61JCOUC5qNqSWvwBeHfMoZW0yZCZUuWR1ZmCW0P61i1YIc0xzNvPqnuk4MuvrUfdMXT5jGV+Uz+XdsIn9 GPIPRODDXOP2021_EXT


in prod 
sh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCfxKvgtWUZnlk2glKC3D+HnXhf+yfuuGPB5niFBFKWHtzOpGjm6PqWCL/mhBG9BRBvLT2Wo7rmOHH9K0D7NxVzSLZJvBYWeZwkInCCBhemaziiz3VMKnKnKWa8L31irq6qS+L0/lW3x+1d0zqxGtAlJXUhFiPZBov72yi/G7lTT2QbYbDyh7JPbhCYlwtQ6CxRMTQ0DIZTO7MDspLFHQNkm9PKjSIisM0jNy5Qsgt7com/WcA3mV/2KzXQKKQeQmp5X1RhXyqNMa+yHNI+xc90iTC85Z1UUKA3Q1Fc/ypL/Rc6906KwasNL/K2GTCGB6XH7SDXJCx317KMnfdAkklJ datatrans2016_EXT

ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA4MZ9ypxAVbYcWPL5RclYJiEjNpP7n4gAuEGbzTineWoT0rlB7Dq9lq4XxlwkBALW0si4IAzqE4p86yPl+MyDTXxiBgqaUzOMe6S8YJ6TakolmVs9HO7BF4msAzIIH4POMLEIqPwsc4TFftg0/oIYRDLxUHHHDubKa3D3WL72GzbyJVsq04w1gLWJL0yaaMOkWAiMpyXSCKuzdolsMMMpxOMu84TcqHmt+Nkpn3ztY7qr0+JKmPJAOz7Y9tai+khJ0AHt2GzBwpuOfHH7ED6v2vSpt16/e3ipRRFdnTAlcmzckoPWs90zzPNbkmtNOvg23kJq9aYnN4T2fTZ54bylqQ== eppadm@spsvepaeapp01.eastwestageaslife.com

ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCfxKvgtWUZnlk2glKC3D+HnXhf+yfuuGPB5niFBFKWHtzOpGjm6PqWCL/mhBG9BRBvLT2Wo7rmOHH9K0D7NxVzSLZJvBYWeZwkInCCBhemaziiz3VMKnKnKWa8L31irq6qS+L0/lW3x+1d0zqxGtAlJXUhFiPZBov72yi/G7lTT2QbYbDyh7JPbhCYlwtQ6CxRMTQ0DIZTO7MDspLFHQNkm9PKjSIisM0jNy5Qsgt7com/WcA3mV/2KzXQKKQeQmp5X1RhXyqNMa+yHNI+xc90iTC85Z1UUKA3Q1Fc/ypL/Rc6906KwasNL/K2GTCGB6XH7SDXJCx317KMnfdAkklJ datatrans2016_EXT

ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDAdO7NwyjKdYJxvkL68EG9evsZ6zgt6LQRCuBvrOOxWLkqXGVIoMr9PD4iG6RyhgVvUa4W+u98Cj716yOCHSsUXvmQYxL6a3ELc+k5fmy81YmRc0LsxkcC+axmVao/bJsV7BlMmhv+ObsIXsZOwqNVyHGdjacJpZt99Cgh0Dicobl5/Q6407YqKspZ9QqsWK68tXp+uLFSsio+XzvZjDKgXaP5P9XP9/zeeB0itSFYguGGxhgGmOsklSxMoOave/Zi9+g61JCOUC5qNqSWvwBeHfMoZW0yZCZUuWR1ZmCW0P61i1YIc0xzNvPqnuk4MuvrUfdMXT5jGV+Uz+XdsIn9 GPIPRODDXOP2021_EXT

ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCHKv4dylRV3JUfmtbbzRW/OmRBFoTUpXNmRYqHGkEDEI3V6IBfo3Fx8QVT1m+2o1dwN2xXcbeSyQHPsR89EBnsL+iesy+6LrdvB/dyP8bqRCDAgIjt+pmRAIr/NpsKNHZO7wCrZeNSpEckMFFlzLWgGqj09PFn0dAqD1RuZn58n3VYiOBJBBZDH3A8idktZl0RmRJ584wDhB6NJT0drMZeXjDUzRqnbgqB35bBGZ8zUlstsx5tUclYV4OaWIoHViL/BRHsUBB1GFX2UM6WwpYEQoyrdgcVNkOKEETIvbDA8bvFMDejd9y/DukvlJfs09OWkkhECsEKPOPweWBKNuXp




AAAAB3NzaC1yc2EAAAADAQABAAABAQCHKv4dylRV3JUfmtbbzRW/OmRBFoTUpXNmRYqHGkEDEI3V6IBfo3Fx8QVT1m+2o1dwN2xXcbeSyQHPsR89EBnsL+iesy+6LrdvB/dyP8bqRCDAgIjt+pmRAIr/NpsKNHZO7wCrZeNSpEckMFFlzLWgGqj09PFn0dAqD1RuZn58n3VYiOBJBBZDH3A8idktZl0RmRJ584wDhB6NJT0drMZeXjDUzRqnbgqB35bBGZ8zUlstsx5tUclYV4OaWIoHViL/BRHsUBB1GFX2UM6WwpYEQoyrdgcVNkOKEETIvbDA8bvFMDejd9y/DukvlJfs09OWkkhECsEKPOPweWBKNuXp



[gpay@svmq1srv1 .ssh]$ cat known_hosts
[ft.test.globalpay.com]:10022,[64.69.195.210]:10022 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCfbnu3E987Nf1/BGXeI7+rf0CpYPulIB4H5x7PcGHyKCOgkyb/zLb1a5D+ri4HECHC3xbHp9nepRzs33rXPFNfJ/N7VVTsQ4n9f3BnQTmS9URzTIY6sV10I4IQDnvLpCFvr298242OcZ9JJBSTM3j/tqZAalYRl7ayUPoMZ18B7v5ziVJi4CsT+fns+zNcC7L/nPKcLCX1hvDmOTveo1+pKlvLJwIURVDc9nLHR00fu2IXxZA2Cj4g90IjZvmE3lTlpc4viO27qP7SVuczsgJZYI9+lqwq2ZdNDwX2GufT+fn3msuAuH6PRCLs9lJlSX2cg9x4LcKQAC3PsEkA5yyP
161.202.165.39 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDCLYj0XSc/9LYI5mmiHqMLc1AnaSBFTI2Jm/ovTRqRxqOkRqg9UzZFZv+XdqqqFgcYyQ08l5+oQoKJd9dUVgUNaS/5RGkc13WzuPthjXgtjaQ/i5nrPbc10LWwYeQzU0nYrNAnROwN4sivlT30gMHMel5BoU6qeUfefCgOMvsscEixZ6HfkUVpvK/TugY1Q1lagXgPJGQTPT4mFN3TCG5RicKEd3ETGHF5Uw/P29GHK76rot5pdRPiyiuQLV83y++bRq+qDTGLdmxXrpwjiQkDtwyEkifB0mt/BKyjmNYt+NlIGbOlGDsGIcnyU2ynwoix8pVrmx96I3ywtt4bVkZ7
svmq1srv1,10.6.2.42 ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAu02s+1VmC+e7Aklx3O2adBoKwRB40OcztSdOw9QYj8hL/6I8niZckfYjHLycjl7GkLA5E504w04gRgTZqOr1XrD8IRxAaQrTrkveUlX3UQSbf0KM7JkPbre5PL3ZQqtpS4rCs1LA2jbVngDBGa/XMceT1Gdv/YPrdvbodbJMnGco27zMNXxAIf1a22VWOi9IRYd2WH86L0Y4vfQuPqAhkMM493ju7rEIZFeouE2yhL2oTEhodtTSp1Ebk1Uh/m1FmaAiHMlOfGIZ/6XoIh2/UowXAQfxfBLUZ71W9BaGnSnJzu2HJpzSrk5Z/UUBZuvHElDlw2mGBUI2PLPzoUzq/Q==
#gpaykey added by Ravi 5th Nov21
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDAdO7NwyjKdYJxvkL68EG9evsZ6zgt6LQRCuBvrOOxWLkqXGVIoMr9PD4iG6RyhgVvUa4W+u98Cj716yOCHSsUXvmQYxL6a3ELc+k5fmy81YmRc0LsxkcC+axmVao/bJsV7BlMmhv+ObsIXsZOwqNVyHGdjacJpZt99Cgh0Dicobl5/Q6407YqKspZ9QqsWK68tXp+uLFSsio+XzvZjDKgXaP5P9XP9/zeeB0itSFYguGGxhgGmOsklSxMoOave/Zi9+g61JCOUC5qNqSWvwBeHfMoZW0yZCZUuWR1ZmCW0P61i1YIc0xzNvPqnuk4MuvrUfdMXT5jGV+Uz+XdsIn9 GPIPRODDXOP2021_EXT

[64.27.246.171]:10022 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCHKv4dylRV3JUfmtbbzRW/OmRBFoTUpXNmRYqHGkEDEI3V6IBfo3Fx8QVT1m+2o1dwN2xXcbeSyQHPsR89EBnsL+iesy+6LrdvB/dyP8bqRCDAgIjt+pmRAIr/NpsKNHZO7wCrZeNSpEckMFFlzLWgGqj09PFn0dAqD1RuZn58n3VYiOBJBBZDH3A8idktZl0RmRJ584wDhB6NJT0drMZeXjDUzRqnbgqB35bBGZ8zUlstsx5tUclYV4OaWIoHViL/BRHsUBB1GFX2UM6WwpYEQoyrdgcVNkOKEETIvbDA8bvFMDejd9y/DukvlJfs09OWkkhECsEKPOPweWBKNuXp





[gpay@spsvmplmapp01 .ssh]$ cat known_hosts
10.6.3.46 ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAu02s+1VmC+e7Aklx3O2adBoKwRB40OcztSdOw9QYj8hL/6I8niZckfYjHLycjl7GkLA5E504w04gRgTZqOr1XrD8IRxAaQrTrkveUlX3UQSbf0KM7JkPbre5PL3ZQqtpS4rCs1LA2jbVngDBGa/XMceT1Gdv/YPrdvbodbJMnGco27zMNXxAIf1a22VWOi9IRYd2WH86L0Y4vfQuPqAhkMM493ju7rEIZFeouE2yhL2oTEhodtTSp1Ebk1Uh/m1FmaAiHMlOfGIZ/6XoIh2/UowXAQfxfBLUZ71W9BaGnSnJzu2HJpzSrk5Z/UUBZuvHElDlw2mGBUI2PLPzoUzq/Q==
[64.69.195.171]:10022 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCg7spN0/aJw5ukc1dAFKRuLRzjY1CDkyc69sPg9HXS2cDrUEdJhmiyjpZpF7PFv4WzuYKd2FfISGLkGofAjCzuaPVRmGnL1YCCssHdqXjotLhvK6+JIINAD2czxCuWKIWth8nGOM58pJKk4apkfA5tDZ0BvTfcPbg8H6ak55YjmyVDhBWb/OGexeQZdOlpsdM5bqjR5PRlxRKgN7+c5HSSW9PkBISRGHO/O9bSahF5BYkHvk5txUpIz7GhGCNzEKDIzfCfZie/HJre8h7sXyQ7jWa6wvsewz5hsH/2AMgpTdUnGN1KN/tpSU3WfOW+QKZt2tm0aNIfYjtyl8dmgbmf
spsvmplmapp01,10.70.111.46 ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAu02s+1VmC+e7Aklx3O2adBoKwRB40OcztSdOw9QYj8hL/6I8niZckfYjHLycjl7GkLA5E504w04gRgTZqOr1XrD8IRxAaQrTrkveUlX3UQSbf0KM7JkPbre5PL3ZQqtpS4rCs1LA2jbVngDBGa/XMceT1Gdv/YPrdvbodbJMnGco27zMNXxAIf1a22VWOi9IRYd2WH86L0Y4vfQuPqAhkMM493ju7rEIZFeouE2yhL2oTEhodtTSp1Ebk1Uh/m1FmaAiHMlOfGIZ/6XoIh2/UowXAQfxfBLUZ71W9BaGnSnJzu2HJpzSrk5Z/UUBZuvHElDlw2mGBUI2PLPzoUzq/Q==
localhost ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAu02s+1VmC+e7Aklx3O2adBoKwRB40OcztSdOw9QYj8hL/6I8niZckfYjHLycjl7GkLA5E504w04gRgTZqOr1XrD8IRxAaQrTrkveUlX3UQSbf0KM7JkPbre5PL3ZQqtpS4rCs1LA2jbVngDBGa/XMceT1Gdv/YPrdvbodbJMnGco27zMNXxAIf1a22VWOi9IRYd2WH86L0Y4vfQuPqAhkMM493ju7rEIZFeouE2yhL2oTEhodtTSp1Ebk1Uh/m1FmaAiHMlOfGIZ/6XoIh2/UowXAQfxfBLUZ71W9BaGnSnJzu2HJpzSrk5Z/UUBZuvHElDlw2mGBUI2PLPzoUzq/Q==
10.70.110.42 ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAu02s+1VmC+e7Aklx3O2adBoKwRB40OcztSdOw9QYj8hL/6I8niZckfYjHLycjl7GkLA5E504w04gRgTZqOr1XrD8IRxAaQrTrkveUlX3UQSbf0KM7JkPbre5PL3ZQqtpS4rCs1LA2jbVngDBGa/XMceT1Gdv/YPrdvbodbJMnGco27zMNXxAIf1a22VWOi9IRYd2WH86L0Y4vfQuPqAhkMM493ju7rEIZFeouE2yhL2oTEhodtTSp1Ebk1Uh/m1FmaAiHMlOfGIZ/6XoIh2/UowXAQfxfBLUZ71W9BaGnSnJzu2HJpzSrk5Z/UUBZuvHElDlw2mGBUI2PLPzoUzq/Q==
svmq1srv1.imzcloud.ibmammsap.local ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAu02s+1VmC+e7Aklx3O2adBoKwRB40OcztSdOw9QYj8hL/6I8niZckfYjHLycjl7GkLA5E504w04gRgTZqOr1XrD8IRxAaQrTrkveUlX3UQSbf0KM7JkPbre5PL3ZQqtpS4rCs1LA2jbVngDBGa/XMceT1Gdv/YPrdvbodbJMnGco27zMNXxAIf1a22VWOi9IRYd2WH86L0Y4vfQuPqAhkMM493ju7rEIZFeouE2yhL2oTEhodtTSp1Ebk1Uh/m1FmaAiHMlOfGIZ/6XoIh2/UowXAQfxfBLUZ71W9BaGnSnJzu2HJpzSrk5Z/UUBZuvHElDlw2mGBUI2PLPzoUzq/Q==



Linux
pledcprtmsdbs
pledcqatms01
ppldcpreccdbs
ppldcprposr02
ppldcsbeccdb
ppldrdvposr01
ppldrqaposr01
pplprecmdb01

[ibmrmalik@pledcprtmsdbs ~]$ uptime
 12:08pm  up 10 days  8:10,  2 users,  load average: 0.51, 0.63, 0.66

[ibmrmalik@pledcqatms01 ~]$ uptime
 12:08pm  up 14 days  8:27,  2 users,  load average: 0.04, 0.04, 0.00

[ibmrmalik@ppldcpreccdbs ~]$ uptime
 12:08pm  up 15 days  8:51,  2 users,  load average: 2.57, 3.66, 4.22

[ibmrmalik@ppldcprposr02 ~]$ uptime
 12:08pm  up 10 days  8:32,  2 users,  load average: 0.02, 0.05, 0.07

[ibmrmalik@ppldcsbeccdb ~]$ uptime
 12:08pm  up 138 days 22:08,  3 users,  load average: 16.34, 7.72, 5.94

[ibmrmalik@ppldrdvposr01 ~]$ uptime
 12:08pm  up 15 days  9:03,  2 users,  load average: 0.56, 0.62, 0.38

[ibmrmalik@ppldrqaposr01 ~]$ uptime
 12:08pm  up 13 days  8:28,  2 users,  load average: 0.10, 0.17, 0.17

[ibmrmalik@pplprecmdb01 ~]$ uptime
 12:08pm  up 11 days  8:15,  2 users,  load average: 0.31, 0.30, 0.33


CS10640632	Chennai Data center  ESXI host ammche01custesx001 has memory issue
SAPB1:
tdpdcprdap2
ap4wdprd
------------------------------------
SAPB2:
	
nl1s4prdapp	
tgppodev
tgpwdprd
tgpwddevprd


Action Plan
1. From OS/Apps/DB Teams - Need to validate / RDP or SSH / Apps & DB are up and working fine or not
2. If Pacemaker VM's are there in the above VM's list, please move the cluster services to another node or Unmanaged State, and validate and confirm the same (Move to Unmanaged State - There will not be any outages to the customer)
3. BHT will migrate the VM's to Other ESXI Hosts within the same cluster and set the host to maintenance mode
4. After the VM's migration - Need Post validation checks  from OS/Apps/DB Teams (Bring back the Pacemaker VM's to Cluster services Managed state / cluster services to available state  - There will not be any outages to the customer)
5. BHT Team will work with SL for Faulty hardware parts replacement and BIOS checks
6. Post validation from SL - After the Parts replacement - All looks good, then BHT team will release the host into production



CHG0226160

br3tsapdb20	                10.138.10.84			TEST  
br3tscmas26	                10.138.10.71			TEST
br3tsapas20	                10.138.10.65			TEST  
br3thcias20	                10.138.10.69			TEST 
br3tgtsdb26	                10.138.10.70			TEST 
br3tscmdb26	                10.138.10.83			TEST  
br3tgtsas25	                10.138.10.79			TEST
BR3COCKPIT                     10.138.13.54
BR3FSAPDB60                  10.138.10.127
BR3FSAPAS60                   10.138.10.170




 Error executing action `run` on resource 'execute[adcli join IMZCLOUD.IBMAMMSAP.LOCAL -H snchbibpd61.imzcloud.ibmammsap.local -O 'OU=Servers - Linux,OU=Suncor (11189),OU=IBM AMM Customers,DC=IMZCLOUD,DC=IBMAMMSAP,DC=LOCAL' -U linuxjoin --domain-controller=tor01ammadc001.imzcloud.ibmammsap.local]'



	CS10648501 GKN Driveline Newton LLC -- GKNP2 - Majorgkn#gknadsprddb#Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-02-24-23-52-59 for dGKNADSPRDDBNewSQ-SAP-TRIO-B2(empty)02-25-2022 10:30:10 - Kyndryl Netcool Au
	CS10648703 GKN Driveline Newton LLC -- GKNP2 - Majorgkn#gknadsprddbh#Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-02-25-00-44-43 forGKNADSPRDDBHNewSQ-SAP-TRIO-B2(empty)02-25-2022 11:24:26 - Kyndryl Netcool Au
	CS10648667 GKN Driveline Newton LLC -- GKNP2 - Majorgkn#Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-gknpeccprddb(stonith:fence_vmware_soap):Stopped vcenter-fencing-gknpeccprddbh(stoGKNPECCPRDDBNewSQ-SAP-TRIO-B2(empty)02-25-2022 11:16:12 - Kyndryl Netcool Au
	CS10648665 GKN Driveline Newton LLC -- GKNP2 - Majorgkn#gknpeccprddb#Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-02-25-00-39-12 forGKNPECCPRDDBNewSQ-SAP-TRIO-B2(empty)02-25-2022 11:16:14 - Kyndryl Netcool Au
CS10648656 GKN Driveline Newton LLC -- GKNP2 - Majorgkn#gknpeccprddbh#Log PaceMaker-crmd Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-02-25-00-37-27 forGKNPECCPRDDBHNewSQ-SAP-TRIO-B2

CS10577378

CS10649059Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap301ap#Service sbd.service CRITICAL: sbd.service is inactive (dead)ARMFKSAP301APNewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:37 - Kyndryl Netcool Au
CS10649060Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap301ap#Service iscsid.service CRITICAL: iscsid.service is inactive (dead)ARMFKSAP301APNewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:39 - Kyndryl Netcool Au
CS10649048Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap305a1#Service sbd.service CRITICAL: sbd.service is inactive (dead)ARMFKSAP305A1NewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:33 - Kyndryl Netcool Au
CS10649061Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap301a1#Service sbd.service CRITICAL: sbd.service is inactive (dead)ARMFKSAP301A1NewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:41 - Kyndryl Netcool Au
CS10649069Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap302ap#Service iscsid.service CRITICAL: iscsid.service is inactive (dead)ARMFKSAP302APNewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:50 - Kyndryl Netcool Au
CS10649068Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap302ap#Service sbd.service CRITICAL: sbd.service is inactive (dead)ARMFKSAP302APNewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:48 - Kyndryl Netcool Au
CS10649047Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap305a1#Service iscsid.service CRITICAL: iscsid.service is inactive (dead)ARMFKSAP305A1NewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:35 - Kyndryl Netcool Au
CS10649067Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap303a1#Resources DRBD CRITICAL: Role value Unknown found for resource r1 on host armfksap303apARMFKSAP303A1NewSQ-SAP-TRIO-C2(empty)02-25-2022 12:25:46 - Kyndryl Netcool Au
CS10649073Arnoldo Mondadori Editore SpA -- ARMP2 - Majorarm#armfksap303ap#Resources DRBD CRITICAL: Role value Unknown found for resource r1 on host armfksap303a1ARMFKSAP303APNewSQ-SAP-TRIO-C2



Node Attributes:
* Node armfksap404d1:
    + hana_ehp_clone_state              : PROMOTED
    + hana_ehp_op_mode                  : logreplay
    + hana_ehp_remoteHost               : armfksap404db
    + hana_ehp_roles                    : 4:P:master1:master:worker:master
    + hana_ehp_site                     : NODEA
    + hana_ehp_srmode                   : sync
    + hana_ehp_sync_state               : PRIM
    + hana_ehp_version                  : 2.00.045.00.1575639312
    + hana_ehp_vhost                    : armfksap404d1
    + lpa_ehp_lpt                       : 1645773705
    + master-rsc_SAPHana_EHP_HDB00      : 150
* Node armfksap404db:
    + hana_ehp_clone_state              : DEMOTED
    + hana_ehp_op_mode                  : logreplay
    + hana_ehp_remoteHost               : armfksap404d1
    + hana_ehp_roles                    : 4:S:master1:master:worker:master
    + hana_ehp_site                     : NODEB
    + hana_ehp_srmode                   : sync
    + hana_ehp_sync_state               : SOK
    + hana_ehp_version                  : 2.00.045.00.1575639312
    + hana_ehp_vhost                    : armfksap404db
    + lpa_ehp_lpt                       : 30
    + master-rsc_SAPHana_EHP_HDB00      : -INFINITY



lpadmin -p FOCF -v socket://10.250.20.242:9600 -E

Saturday 26 February 2022 

CHG0226160 02/25/2022 - 20:00 - NIX - BR3 - PATCH	26-02-2022 06:30:00 - 12:30:00
	br3tsapdb20	                10.138.10.84			HDB 	rebooted after patching 
br3tscmas26	                10.138.10.71			TEST	rebooted after patching
br3tsapas20	                10.138.10.65			TEST 	rebooted after patching 
br3thcias20	                10.138.10.69			TEST 	rebooted after patching
	br3tgtsdb26	                10.138.10.70			HDB 	rebooted after patching
	br3tscmdb26	                10.138.10.83			HDB  	rebooted after patching
br3tgtsas25	                10.138.10.79			TEST	rebooted after patching
BR3COCKPIT                     10.138.13.54				rebooted after patching
	BR3FSAPDB60                  10.138.10.127			HDB	rebooted after patching
BR3FSAPAS60                   10.138.10.170				rebooted after patching


10.3.112.23:/usr/sap/trans                  nfs4      171G  129G   35G  79% /usr/sap/trans
10.138.10.30:/usr/sap/trans                 nfs4      171G  129G   35G  79% /usr/sap/trans_nfs


BR3DSAPA50	10.138.10.30	10.3.112.23


PS2-S4P-DB , PS2-S4P-CI

CS10653345 NewIncidentP2 - MajorPS2-S4P-DBsoutheastasia-AZPak Suzuki Motor Company Ltd (Psmcl) --PS2Pak Suzuki Motor Company Ltd (Psmcl) --ps2#ps2-s4p-db#Service Pacemaker stonithd CRITICAL: 0 /usr/lib/pacemaker/stonithd processes running (thresh 1:)

CS10653339 NewIncidentP2 - MajorPS2-S4P-DBsoutheastasia-AZPak Suzuki Motor Company Ltd (Psmcl) --PS2Pak Suzuki Motor Company Ltd (Psmcl) --ps2#ps2-s4p-db#Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)

CS10653311 NewIncidentP2 - MajorPS2-S4P-DB-HAsoutheastasia-AZPak Suzuki Motor Company Ltd (Psmcl) --PS2Pak Suzuki Motor Company Ltd (Psmcl) --ps2#ps2-s4p-db-ha#Log PaceMaker-log Found 7 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-02-25-19-33-24 for

CS10653301 NewIncidentP2 - MajorPS2-S4P-DBsoutheastasia-AZPak Suzuki Motor Company Ltd (Psmcl) --PS2Pak Suzuki Motor Company Ltd (Psmcl) --ps2#ps2-s4p-db#Service Pacemaker attrd CRITICAL: 0 /usr/lib/pacemaker/attrd processes running (thresh 1:)

CS10653269 NewIncidentP2 - MajorPS2-S4P-CIsoutheastasia-AZPak Suzuki Motor Company Ltd (Psmcl) --PS2Pak Suzuki Motor Company Ltd (Psmcl) --ps2#ps2-s4p-ci#Service Pacemaker lrmd CRITICAL: 0 /usr/lib/pacemaker/lrmd processes running (thresh 1:)

CS10653270 NewIncidentP2 - MajorPS2-S4P-DBsoutheastasia-AZPak Suzuki Motor Company Ltd (Psmcl) --PS2Pak Suzuki Motor Company Ltd (Psmcl) --ps2#ps2-s4p-db#Service Pacemaker pengine CRITICAL: 0 /usr/lib/pacemaker/pengine processes running (thresh 1:)

CS10653267NewIncidentP2 - MajorPS2-S4P-CIsoutheastasia-AZPak Suzuki Motor Company Ltd (Psmcl) --PS2Pak Suzuki Motor Company Ltd (Psmcl) --ps2#ps2-s4p-ci#Resources CRM CRITICAL: Unmanaged resources found: stonith-sbd(stonith:external/sbd):Stopped (unmanaged) ip-s4p-nfs(ocf:IPaddr2):Stopp (edited


CHG0233877



Source
DLTHQGGA1 10.4.5.42 10.250.17.42	A0DBUS014XVM033	1858  2067M
DLTHQGGAT 10.4.5.34 10.250.17.34	A0DBUS014XVM013	1858  2067M
DLTQEGGAT 10.4.5.176 10.250.17.180	samename 1858  2067M

Destination
DLTHSGGAT 10.4.5.24 10.250.17.24	A0DBUS014XVM008	1858  2067M




device for EGOF_SATO_SERV: lpd://10.250.43.43
EGOF_SATO_SERV accepting requests since Tue Feb 22 12:56:08 2022
printer EGOF_SATO_SERV is idle. enabled since Tue Feb 22 12:56:08 2022


Support Cases > 00338049  Mustaq ahmed issue nfs umounted



CHG0235161 & CHG0235162  change approval




[root@spsvmplmapp01 sftp]# ls -ltr
total 24
drwx------.  2 root   root   16384 Mar 30  2016 lost+found
drwxrwxr-x.  2 eppadm sftp    4096 Mar  1 18:30 Backup
drwxrwxrwx. 19 rppadm sapsys  4096 Mar  2 13:50 prd



CS10668941      TSM: wdc04ammtsm002.ibmammsap.local  ANR2579E Schedule @1060 in domain D30_SMR_SHORT for node OGY_OGYPXN001_FIL_DLY failed (return code 12).~
CS10655909      TSM: wdc04ammtsm002.ibmammsap.local  ANR2578W Schedule 7TW_FIL_INC_0230 in domain D30_SMR_SHORT for node OGY_OGYPXN001_FIL_DLY has missed its scheduled start up
CS10654632      TSM: a0001p5rapp0012.mgt.mhas.ibm.com  ANR2578W Schedule 7TW_FIL_INC_2130 in domain D14_SMR_SHORT for node GLT_GLTS4DEVDB01_FIL_DLY has missed its scheduled sta
CS10650288      TSM: wdc04ammtsm002.ibmammsap.local  ANR2579E Schedule 7TW_FIL_INC_0230 in domain D30_SMR_SHORT for node OGY_OGYPXN001_FIL_DLY failed (return code 12).~



CHG0226164
CHG0235341



CHG0235223 change approval


CS10713280 P2 ASDPRDDB Nidec ASI spa -- ASDasd#asdprddb#Log PaceMaker-log Found 6 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-08-08-22-23 for detai
CS10713230 P2 ASDPRDDB Nidec ASI spa -- ASDasd#asdprddb#Log PaceMaker-log Found 6 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-08-08-12-22 for detai



[root@gknsoldev ~]$ df -hT /usr/sap/ccms
Filesystem                         Type  Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrsapccms_lv ext3  4.8G  4.7G     0 100% /usr/sap/ccms

[root@gknsoldev ~]$ df -hT /usr/sap/trans
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrtrans_lv ext3   66G   29G   35G  45% /usr/sap/trans


/dev/mapper/smjarchvg-smjdb2arch_lv         ext3       50G   15G   33G  31% /db2/SMJ/log_archive


/db2/SMJ/log_archive/trans_backup/


copy stuff inside trans to trans_local
rsync -avz trans/* trans_local/


sent 26,733,278,406 bytes  received 459,700 bytes  23,585,124.05 bytes/sec
total size is 30,010,042,450  speedup is 1.12
You have new mail in /var/spool/mail/root



[root@gknsoldev log_archive]$ df -hT /usr/sap/trans/
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrtrans_lv ext3   66G   29G   35G  45% /usr/sap/trans


[root@gknsoldev log_archive]$ df -hT /usr/sap/trans
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrtrans_lv ext3   61G   29G   30G  49% /usr/sap/trans


sent 717,959 bytes  received 79,940 bytes  227,971.14 bytes/sec
total size is 30,010,042,450  speedup is 37,611.33


[root@gknsoldev trans_backup]$ df -hT /usr/sap/ccms
Filesystem                         Type  Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrsapccms_lv ext3  9.7G  4.7G  4.6G  51% /usr/sap/ccms
[root@gknsoldev trans_backup]$ df -hT /usr/sap/trans
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/smaappvg-usrtrans_lv ext3   61G   29G   30G  49% /usr/sap/trans



CHG0235346 & CHG0229823   approvals



AGEAS SFTP RHEL case  https://access.redhat.com/support/cases/#/case/03163558


CS10726703      TSM: tok02ammtsm001.ibmammsap.local  ANR2578W Schedule 7TW_FIL_INC_0530 in domain D14_SMR_SHORT for node MMT_MMTBOBIDEV_FIL_DLY has missed its scheduled start u	Windows
CS10726701      TSM: syd04ammpowertsm02.imzcloud.ibmammsap.local  ANR2578W Schedule 7TW_FIL_INC_2030 in domain D30_SMR_SHORT for node Z3V_PAJAPU01-HA_FIL_DLY has missed its sch
CS10726702      TSM: syd04ammpowertsm02.imzcloud.ibmammsap.local  ANR2578W Schedule 7TW_FIL_INC_2030 in domain D30_SMR_SHORT for node Z3V_PAYAPU01-HA_FIL_DLY has missed its sch



/etc/squid/squid.conf

systemctl status squid

Proxy virtual IP should be	: 146.89.141.152 
Port # 3128


P1 CS10734139HBQ server restarting.
hfchbqhndb1 10.92.9.94


CHG0235987  change approval


Change on Saturday 1030
CHG0235228  Pooja dixit		12-03-2022 10:30:00	12-03-2022 19:30:00
Pooja
IA1WEBDSLB	10.133.15.32
IA1WEBDSLBDR	10.133.15.31
IA1WEBDSLBHA	10.133.15.33
IA1WEBDSPPRD1	10.133.15.16
IA1WEBDSPPRD2	10.133.15.17
IA1FTSPRDAPP	10.133.15.24


Ravi/Sandeep
IA1HCIPRDAPP	10.133.15.23
IA1HCCPRDWD	10.133.15.28
IA1NFSPRDAPP	10.133.15.25
IA1OTASPRDAPP	10.133.17.147
IA1OTASPRDDB	10.133.17.146




CHG0229675 TTA change on 13th Mar

SAPCRMAPP4	Production	App	CPA	S4CRMEWM	10.207.61.187 
SAPCRMAPP4-HA	Production	App	CPA	S4CRMEWM	10.207.61.202
SAPCRMAPP3	Production	App	CPA	S4CRMEWM	10.207.61.60
EWMAPP1	Production	App	EMP	S4CRMEWM	10.207.61.77
EWMAPP3	Production	App	EMP	S4CRMEWM	10.207.61.114
EWMAPP3-HA	Production	App	EMP	S4CRMEWM	10.207.61.203



crm configure property maintenance-mode=true 
crm configure property maintenance-mode=false


ERROR: "SuSE Pacemaker cluster setting "no-quorum-policy" may not be set correctly."

FIX: The parameter "no-quorum-policy=ignore" should be set to "no-quorum-policy=stop"

10.162.186.206	tta-che01-pod1-phana-h8-12000-001.imzcloud.ibmammsap.local
ipmi 10.162.186.207	root  v4RCYvlEDz
TSLS4PRODDB


Change approvals
CHG0232408
CHG0232366



CS10758898 NewGKN Driveline Newton LLC -- GKNGKNSOLDEVgkn#gknsoldev#Inodes Utilization /interface/SMJ mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS10758928NewGKN Driveline Newton LLC -- GKNGKNSOLDEVgkn#gknsoldev#Disk Utilization /var mktemp: failed to create file via template /usr/local
CS10758937NewGKN Driveline Newton LLC -- GKNGKNSOLDEVgkn#gknsoldev#Disk Utilization /db2/SMA/sapdata2 mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS10758938NewGKN Driveline Newton LLC -- GKNGKNSOLDEVgkn#gknsoldev#Disk Utilization /db2/SMA mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS10759038NewGKN Driveline Newton LLC -- GKNGKNSOLDEVgkn#gknsoldev#Inodes Utilization /backup mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system
CS10759041NewGKN Driveline Newton LLC -- GKNGKNSOLDEVgkn#gknsoldev#Inodes Utilization /usr/sap/trans mktemp: failed to create file via template /usr/local/ncpa/var/log/XXXXXXXX: Read-only file system



Production
a2aeccprd1cs(App-Prod) - 100.126.35.120
a2aeccprd2cs(App-Ha) 100.126.35.89
a2aeccprd1as(App1)
100.126.35.69
a2aeccprd2as(App2)
100.126.35.60


a2apistg1as	                100.126.36.57			Development  
a2awebstg1p	                100.126.36.132			Development  
a2apistg1db	                100.126.36.63			Development  
a2aftpstgsvr2	                100.126.36.54			Development  


CHG0235224	IAG - British Airways -- IA2	19-03-2022 09:30:00	19-03-2022 16:30:00	Sandeep and Ravi
IA2GP5DB	10.133.15.113
IA2FIOPRDAPP1	10.133.15.88
IA2GP5DB-DR	10.199.15.211
IA2FIOPRDWD	10.133.15.80
IA2FIOPRDAPP2	10.133.15.79
IA2FIOPRDWDHA	10.133.15.81
IA2MDGPRDAPP	10.133.15.34
IA2FIOPRDDB	10.133.15.44


CHG0232372	American Airlines Inc -- A2A	19-03-2022 13:30:00	19-03-2022 22:00:00	Pooja and Ravi
a2apiprd1db	                100.126.35.72			Production  
a2apiprd1as	                100.126.35.31			Production  
a2apiprd2db	                100.126.35.77			Production  
a2awebprd1p	                100.126.35.49			Production  
a2awebprd1s	                100.126.35.87			Production  
a2asltprd2cs	                100.126.35.91			Production  
a2asltprd1cs	                100.126.35.66			Production  
	a2apiprd2cs	                100.126.35.99			Production  
	a2apiprd1cs	                100.126.35.115			Production  
a2asltprd1db	                100.126.35.47			Production  
a2asltprd2db	                100.126.35.52			Production  








//10.220.4.160/edsrep$  /edsrep 


[root@MGGGBJQECCX01 ~]$ cat /etc/fstab |grep -i X12
//10.220.4.160/edsrep$/EDI/X12  /X12    cifs  guest,_netdev,uid=20200,gid=3050,rw 0 0


[root@MGGGBJPECCX05 ibmrmalik]$ cat /etc/fstab |grep -i edsrep
#//10.220.4.160/edsrep$          /edsrep                 cifs guest,_netdev,uid=nepadm,gid=sapsys,rw 0 0
//10.220.4.160/edsrep  /edsrep      cifs        credentials=/etc/TUBA_credentials,uid=nepadm,gid=sapsys,rw 0 0




Restart OS on below VMs

SAPSID	Hostname		IBM IP address
S4D APP	BTKS4DCS01	10.134.10.9
S4D DB	BTKH4DDB01	10.134.10.24


 CHG0235624 	tngdevqasedb	                10.134.1.6			Development  retired server in change
 CHG0235625



CS10810666
CS10811692
CS10812004
CS10810563
CS10811558
CS10812061



	CS10814696	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mcllaepa11#Service Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)
CS10814682	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)
CS10814681	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-21-07-25 for det
	CS10814670	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mcllaepa11#Service Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)
CS10814671	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-19-57-19 for det
CS10814665	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 14 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-20-17-21 for de
CS10814660	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Service Pacemaker attrd CRITICAL: 0 /usr/lib64/pacemaker/attrd processes running (thresh 1:)
	CS10814659	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mcllaepa11#Service Pacemaker cib CRITICAL: 0 /usr/lib64/pacemaker/cib processes running (thresh 1:)
CS10814645	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Service Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)
CS10814644	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-21-37-28 for det
CS10814643	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-22-05-29 for det
CS10814639	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 18 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-20-57-25 for de
	CS10814637	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mcllaepa11#Service Pacemaker lrmd CRITICAL: 0 /usr/lib64/pacemaker/lrmd processes running (thresh 1:)
CS10814636	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-21-22-27 for det
CS10814635	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Service Pacemaker pengine CRITICAL: 0 /usr/lib64/pacemaker/pengine processes running (thresh 1:)
CS10814634	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mcllaepa01#EPAMCL (ABAP)|ABAP_SYS_EXP_CERTIFICATES|ABAP PSE certificates expiring
CS10814609	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)
CS10814610	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mclldepa11#Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-22-30-33 for det
CS10814608	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mcllaepa01#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-23-20-04-34 for de
CS10814607	Mhi Rj Aviation Ulc -- MCL	P2 - Major	mcl#mcllaepa11#Service Pacemaker crmd CRITICAL: 0 /usr/lib64/pacemaker/crmd processes running (thresh 1:)




CS10819383Mhi Rj Aviation Ulc -- MCLP2 - Majormcl#mcllicpj01#Service pacemakerd CRITICAL: 0 pacemakerd processes running (thresh 1:)
CS10819384Mhi Rj Aviation Ulc -- MCLP2 - Majormcl#mcllicpj01#Service Pacemaker stonithd CRITICAL: 0 stonithd processes running (thresh 1:)
CS10819362Mhi Rj Aviation Ulc -- MCLP2 - Majormcl#mcllicpj01#Service Pacemaker lrmd CRITICAL: 0 lrmd processes running (thresh 1:)
CS10819361Mhi Rj Aviation Ulc -- MCLP2 - Majormcl#mcllicpj01#Service Pacemaker crmd CRITICAL: 0 crmd processes running (thresh 1:)
CS10819359Mhi Rj Aviation Ulc -- MCLP2 - Majormcl#mcllicpj01#Service Pacemaker cib CRITICAL: 0 cib processes running (thresh 1:)




CHG0235954 DAL-NONPROD-DAL09 - Firmware  Upgrade Activity  - HDE and DEA	26-03-2022 07:30:00	26-03-2022 17:30:00
Firmware to be upgraded on the below pHana servers 

1 -Hostname - dlthdehdb3 	10.143.69.221	dal-dal09-pod1-phana-h2-768-01.imzcloud.ibmammsap.local
   IFN - 10.4.5.43
   Physical server - dal-dal09-pod1-phana-h2-768-01.imzcloud.ibmammsap.local
IPMI 10.143.69.247    root / zPA3GjW3sx


2 -Hostname - dltdeahdb	10.143.69.186	delta-dal09-phana-1024-01.imzcloud.ibmammsap.local
   IFN - 10.4.5.185
   Physical server - delta-dal09-phana-1024-01.imzcloud.ibmammsap.local
IPMI 10.143.69.188	root / HgpYWgEUZ6

SL case for dlthdehdb3 - CS2742856
SL case for dltdeahdb - CS2742861 

1- take the precheck
2 - Pre-reboot
3 - shutdown the server and poweroff from SL console
4 - Initiate the firmware upgrade for all component
5 - Monitor the SL case and followup
6 - Validate the server and release to SAP Team



TI3S4DAP02
use iinstall welcome123

sapcust with T@kasag0



CS10841960
chrome setting



syd04ammprx01	146.89.143.243


TTA print app20 all app servers of S4H


NPIEAF805          135.37.32.222                   HP LaserJet M506

NPIEA1D5F          135.37.32.224                   HP LaserJet M506

NPIBE89C6          135.133.100.137              HP LaserJet M506 

NPIB7165F          133.0.13.21                       HP LaserJet E60065

JSSWLJ1980        133.0.13.16                       HP LaserJet P3015

JSSWLJ1981        133.0.13.17                       HP LaserJet P3015

NP115F246         154.0.16.97                       HP LaserJet P3010

NP115F221         154.0.16.98                       HP LaserJet P3010	missing

NPI452EF5          135.21.31.175                   HP LaserJet M507

TSLJA08501         10.152.112.46                   HP Laserjet M507DN



SAPAPP31
SAPAPP31-HA
SAPAPP21
SAPAPP15
SAPAPP18

SAPAPP19
SAPAPP20
SAPAPP23
SAPAPP26
SAPAPP27

SAPAPP28
SAPAPP29
SAPAPP30
SAPAPP32
SAPAPP33

SAPAPP34
SAPAPP35
SAPAPP36
SAPAPP37


cron entry to restart cups service at 4AM daily		0 4 * * * systemctl restart cups.service
add all 10 printers
auto start service  systemctl enable cups.service
host file update

lpadmin -p NP115F221 -v socket://154.0.16.98 -E
lpadmin -p JSSWLJ1980 -v socket://133.0.13.16 -E
lpadmin -p JSSWLJ1981 -v socket://133.0.13.17 -E
lpadmin -p NP115F221 -v socket://154.0.16.98 -E
lpadmin -p NPI452EF5 -v socket://135.21.31.175 -E
lpadmin -p NPIB7165F -v socket://133.0.13.21 -E
lpadmin -p NPIBE89C6 -v socket://135.133.100.137 -E
lpadmin -p NPIEA1D5F -v socket://135.37.32.224 -E
lpadmin -p NPIEAF805 -v socket://135.37.32.222 -E
lpadmin -p NP115F246 -v socket://154.0.16.97 -E


device for npibe89c6: ipp://135.133.100.137/printers/NPIBE89C6


TSLBWPRDHDBDR - IFN IP: 100.64.4.34
SL No: J302DM1D
ILO IP - 10.230.1.23
User - USERID
Password - P@ssw0rd@1234
pass for ILO IP - P@ssw0rd@123



61006f04a9359c000e541ff2-d-appdisk1		PROD DC : Frankfurt 02	

Server: adzpc0ci
CFN IP -10.177.18.30
IMZ IP - 10.71.18.9

File system to be removed: /temp
Disk Space : 1 TB


CHG0238288
gltaduatas01	                10.92.4.138			Test  APP
gltaduatdb01	                10.92.4.134			Test  DB
gltmiuatdb01	                10.92.4.137			Test  DB
gltbwuatdb01	                10.92.4.168			Test  DB
gltmiuatas01	                10.92.4.139			Test  APP
gltbwuatas01	                10.92.4.148			Test  APP


CHG0238290
glts4uatas04	                10.92.4.147			Test APP
glts4uatas02	                10.92.4.159			Test  APP
glts4uatdb01	                10.92.4.163			Test  HANA DB
glts4uatas03	                10.92.4.165			Test  APP
glts4uatas01	                10.92.4.135			Test  APP CI




CPA:
SAPCRMAPP4
SAPCRMAPP4-HA

PRD:
SAPAPP31
SAPAPP31-HA

EMP:
EWMAPP3
EWMAPP3-HA


PDF Password
The downloaded PDF will be password protected. To open the file, you will need to enter the combination of the PAN (in lower case) and the date of birth in case of individual taxpayer or date of incorporation / formation for non-individual taxpayer in the format ddmmyyyy without any space. For example, if the PAN is AAAAA1234A and the date of birth is 21st January 1991 then your password will be aaaaa1234a21011991



CS10755875	03-15-2022 02:26:08	TI3	TI3S4DAP02	ti3#ti3s4dap02#Log Syslog-DStorage Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-14-21-55-57 for d	P2 - Major
CS10840925	03-29-2022 03:09:41	TI3	TI3S4DAP02	ti3#ti3s4dap02#Log Syslog-DStorage Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-28-23-39-31 for d	P2 - Major
CS10840976	03-29-2022 03:24:57	TI3	TI3S4DAP02	ti3#ti3s4dap02#Log Syslog-DStorage Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-28-23-54-33 for d	P2 - Major
CS10841080	03-29-2022 03:59:53	TI3	TI3S4DAP02	ti3#ti3s4dap02#Log Syslog-DStorage Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-29-00-29-38 for d	P2 - Major
CS10841235	03-29-2022 04:50:14	TI3	TI3S4DAP02	ti3#ti3s4dap02#Log Syslog-DStorage Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-29-01-19-43 for d	P2 - Major
CS10841259	03-29-2022 05:00:10	TI3	TI3S4DAP02	ti3#ti3s4dap02#Log Syslog-DStorage Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-29-01-29-43 for d	P2 - Major

CS10864198	04-02-2022 19:08:39	TI3	TI3S4PDB01	ti3#ti3s4pdb01#Disk Utilization /var/log/audit MINOR: Free 1141.17MB/14.99% (thresh @10.01:15%)	P3 - Minor
CS10671066	03-01-2022 03:34:06	TI3	TI3S4PDB01	ti3#ti3s4pdb01#Log Syslog-DStorage Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-03-01-06-03-55 for d	P2 - Major


Old ticket, found all gud


-rw-r--r--. 1 root root 323 Apr  5 02:06 cmas_logscanner_checklog_filters.protocol-2022-04-05-02-06-11
-rw-r--r--. 1 root root 323 Apr  5 02:51 cmas_logscanner_checklog_filters.protocol-2022-04-05-02-51-17
-rw-r--r--. 1 root root 323 Apr  5 03:16 cmas_logscanner_checklog_filters.protocol-2022-04-05-03-16-21
-rw-r--r--. 1 root root 323 Apr  5 03:46 cmas_logscanner_checklog_filters.protocol-2022-04-05-03-46-23
[root@ti3s4dap02 protocolfiles]# date
Wed Apr  6 07:47:06 CEST 2022
[root@ti3s4dap02 protocolfiles]# cat cmas_logscanner_checklog_filters.protocol-2022-04-05-03-46-23
CRITICAL Errors in messages (tag 7:CRITICAL_Syslog-DStorage)
Apr  5 01:23:42 ti3s4dap02 smbd[1516780]:  read_fd_with_timeout failed for client 0.0.0.0 read error = NT_STATUS_CONNECTION_RESET.
Apr  5 01:24:11 ti3s4dap02 smbd[1516868]:  read_fd_with_timeout failed for client 0.0.0.0 read error = NT_STATUS_CONNECTION_RESET.


[root@ti3s4dap02 protocolfiles]# mount -a
[root@ti3s4dap02 protocolfiles]# df -hT |grep -i cifs
//172.26.1.35/SAP                            cifs     1000G  758G  243G  76% /TIS_Interface
//172.31.24.143/Output/PDF                   cifs      280G  3.3G  277G   2% /ZEH_SDS_IMPORT
[root@ti3s4dap02 protocolfiles]# cat /etc/fstab |grep -i cifs
#//172.31.24.143/Output/PDF     /ZEH_SDS_IMPORT cifs    credentials=/etc/credentialsrm,uid=20400,gid=3050,vers=2.0,_netdev      0 0
//172.26.1.35/SAP      /TIS_Interface cifs    credentials=/etc/credentialsrm,uid=20400,gid=3050,vers=2.0,_netdev      0 0
//172.31.24.143/Output/PDF     /ZEH_SDS_IMPORT cifs    credentials=/etc/credentialsrm,uid=20400,gid=3050,vers=2.0,_netdev,dir_mode=0775,file_mode=0775      0 0
[root@ti3s4dap02 protocolfiles]# cat /etc/fstab |grep -i nfs
146.89.140.216:/sds /sds nfs rsize=8192,wsize=8192,timeo=14,intr



QAMHANAU02	qamasu01
10.63.43.100	syd04-pod1-6tb-host001.imzcloud.ibmammsap.local


CS10894016 AGEAS -- AGEP2 - Majorage#svad1srv0#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.SVAD1SRV0NewSQ-SAP-TRIO-B1
CS10893993AGEAS -- AGEP2 - Majorage#agesvcdmhsrv1#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.AGESVCDMHSRV1NewSQ-SAP-TRIO-B1(empty)04-08-2022 11:18:08 - Kyndryl Netcool Au
CS10893982 AGEAS -- AGEP2 - Majorage#svws1srv0#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.SVWS1SRV0NewSQ-SAP-TRIO-B1(empty)04-08-2022 11:18:16 - Kyndryl Netcool Au
CS10893981 AGEAS -- AGEP2 - Majorage#sves1hdbsrv01#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.SVES1HDBSRV01NewSQ-SAP-TRIO-B1(empty)04-08-2022 11:18:20 - Kyndryl Netcool Au
CS10893974 AGEAS -- AGEP2 - Majorage#svsd1srv0#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.SVSD1SRV0NewSQ-SAP-TRIO-B1


Home Control Singapore -- HCS   hcsecchdb0dev
AGEAS
Hengyuan Refining Company Berhad -- HGY
Pt Gunung Raja Paksi Tbk -- GRP
BRENNTAG PTE LTD -- BAP


user=ediuser,password=K{BE{sVu7?Agm[%G,ip=10.255.80.70,domain=IMZCLOUD


standby	
stop pacemaker
reboot node
register HSR as secondary
online


CHG0237365
This 04/08/2022 - 19:00 - NIX  remediation is for the following CIs:
dltsxaadb	                10.4.5.5			Development  
dltswchwd	                10.4.5.242			Development  
dlthsggat	                10.4.5.24			Development  
dlthsehap	                10.4.5.22			Development  
dlthsehdb2	                10.4.5.168			Development  


Master ticket for SNG issue CS10911832
SL Case for Network : CS2779404


CS10911536	Amos Group Limited -- AM3	P1 - Severe	am3#am3s4prddb#Ping Availability CRITICAL - 10.70.21.10: rta nan. lost 100% Attention commas replaced by dots.	AM3S4PRDDB	10.116.145.56	sng01-pod2-4tb-host03.imzcloud.ibmammsap.local
	
CS10911619	Amos Group Limited -- AM3	P1 - Severe	am3#am3s4qasdb#Ping Availability CRITICAL - 10.70.22.19: rta nan. lost 100% Attention commas replaced by dots.	AM3S4QASDB	10.116.205.251	sng01-pod2-4tb-host01.imzcloud.ibmammsap.local
	
CS10911675	Amos Group Limited -- AM3	P1 - Severe	am3#Ping Availability CRITICAL - am3s4prdap01: rta nan. lost 100% Attention commas replaced by dots.	AM3S4PRDAP01	
CS10911549	Amos Group Limited -- AM3	P1 - Severe	am3#am3s4devap01#Ping Availability CRITICAL - 10.70.22.20: rta nan. lost 100% Attention commas replaced by dots.	AM3S4DEVAP01	
CS10911649	Amos Group Limited -- AM3	P1 - Severe	am3#Ping Availability CRITICAL - am3s4qasap01: rta nan. lost 100% Attention commas replaced by dots.	AM3S4QASAP01
CS10911678	Amos Group Limited -- AM3	P1 - Severe	am3#am3webdisqas#Ping Availability CRITICAL - 10.70.22.16: rta nan. lost 100% Attention commas replaced by dots.	AM3WEBDISQAS	
CS10911593	Amos Group Limited -- AM3	P1 - Severe	am3#am3s4devdb#Ping Availability CRITICAL - 10.70.22.14: rta nan. lost 100% Attention commas replaced by dots.	AM3S4DEVDB	
CS10911650	Amos Group Limited -- AM3	P1 - Severe	am3#am3s4prdap02#Ping Availability CRITICAL - 10.70.21.8: rta nan. lost 100% Attention commas replaced by dots.	AM3S4PRDAP02	SNG01-SL	
CS10911679	Amos Group Limited -- AM3	P1 - Severe	am3#am3webdisprd#Ping Availability CRITICAL - 10.70.21.7: rta nan. lost 100% Attention commas replaced by dots.	AM3WEBDISPRD


CS10917109
tta#ttaprojqadb#Host Reboot CRITICAL: Uptime 0 minutes (thresh 30 min)
10.162.186.228	tta-che01-pod1-phana-h4-6000-003.imzcloud.ibmammsap.local


RCA  9th April 745 AM
lbupg1db01 <= lbupg1db01ha 

Master/Slave Set: msl_SAPHana_PG1_HDB02 [rsc_SAPHana_PG1_HDB02]
     Masters: [ lbupg1db01ha ]
     Stopped: [ lbupg1db01 ]
     
Apr 08 22:01:45 [5314] lbupg1db01       crmd:     info: abort_transition_graph: Transition 294168 aborted by status-1-fail-count-rsc_SAPHana_PG1_HDB02.monitor_60000 doing create fail-count-rsc_SAPHana_PG1_HDB02#monitor_60000=1: Transient attribute change | cib=0.679225.8 source=abort_unless_down:317 path=/cib/status/node_state[@id='1']/transient_attributes[@id='1']/instance_attributes[@id='status-1'] complete=true
Apr 08 22:01:45 [5314] lbupg1db01       crmd:     info: abort_transition_graph: Transition 294168 aborted by status-1-last-failure-rsc_SAPHana_PG1_HDB02.monitor_60000 doing create last-failure-rsc_SAPHana_PG1_HDB02#monitor_60000=1649469705: Transient attribute change | cib=0.679225.9 source=abort_unless_down:317 path=/cib/status/node_state[@id='1']/transient_attributes[@id='1']/instance_attributes[@id='status-1'] complete=true
Apr 08 22:01:45 [5313] lbupg1db01    pengine:     info: unpack_config:  Watchdog-based self-fencing will be performed via SBD if fencing is required and stonith-watchdog-timeout is positive
Apr 08 22:01:45 [5313] lbupg1db01    pengine:   notice: unpack_config:  On loss of CCM Quorum: Ignore
Apr 08 22:01:45 [5313] lbupg1db01    pengine:     info: determine_online_status_fencing:        Node lbupg1db01 is active
Apr 08 22:01:45 [5313] lbupg1db01    pengine:     info: determine_online_status:        Node lbupg1db01 is online
Apr 08 22:01:45 [5313] lbupg1db01    pengine:     info: determine_online_status_fencing:        Node lbupg1db01ha is active
Apr 08 22:01:45 [5313] lbupg1db01    pengine:     info: determine_online_status:        Node lbupg1db01ha is online
Apr 08 22:01:45 [5313] lbupg1db01    pengine:     info: determine_op_status:    Operation monitor found resource rsc_TSMTDP_PG1_HDB02 active on lbupg1db01
Apr 08 22:01:45 [5313] lbupg1db01    pengine:  warning: unpack_rsc_op_failure:  Processing failed monitor of rsc_ip_PG1_HDB02 on lbupg1db01: unknown error | rc=1
Apr 08 22:01:45 [5313] lbupg1db01    pengine:  warning: unpack_rsc_op_failure:  Processing failed monitor of rsc_SAPHanaTopology_PG1_HDB02:0 on lbupg1db01: unknown error | rc=1
Apr 08 22:01:45 [5313] lbupg1db01    pengine:  warning: unpack_rsc_op_failure:  Processing failed monitor of rsc_stonith-sbd on lbupg1db01: unknown error | rc=1
Apr 08 22:01:45 [5313] lbupg1db01    pengine:  warning: unpack_rsc_op_failure:  Processing failed monitor of rsc_SAPHana_PG1_HDB02:0 on lbupg1db01: unknown error | rc=1
Apr 08 22:01:45 [5313] lbupg1db01    pengine:     info: determine_op_status:    Operation monitor found resource rsc_TSMTDP_PG1_HDB02 active on lbupg1db01ha




Approve 
CHG0240093 04/13/2022 - 21:00 - NIX - ZEC - PATCH




/dev/mapper/pcssapdbvg-backups_lv           ext4       11T  7.6T  2.9T  73% /sapdb_backups


CS10917204 tta#tsleecqa01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TSLEECQA01- KB0010973

158.87.44.0/23 via 10.207.61.1 dev eth0
158.87.46.0/23 via 10.207.61.1 dev eth0


route add 158.87.44.0 gw 10.207.63.255 dev vlan0
route add 158.87.46.0 gw 10.207.63.255 dev vlan0

route add -net 158.87.44.0 gw 10.207.63.255 netmask 255.255.255.0 dev vlan0

route add -net 158.87.46.0 gw 10.207.63.255 netmask 255.255.255.0 dev vlan0

359  2022-01-19 09:09:32 route add -net 158.87.44.0 netmask 255.255.254.0 gw 10.207.63.1
  360  2022-01-19 09:10:07 route add -net 158.87.46.0 netmask 255.255.254.0 gw 10.207.63.1



vlan0     Link encap:Ethernet  HWaddr 3C:FD:FE:86:5A:80  
          inet addr:10.207.63.185  Bcast:10.207.63.255  Mask:255.255.255.0


ps4adm
psjadm
db2ps4
smdadm
daaadm


CHG0240621


This system is not registered with an entitlement server. You can use subscription-manager to register.
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/RedHat%20Satellite%20infra%20%26%20Chef%20recipe


10.143.69.173	dalhana-1024-61.xsportal.local		dlthdehdb

[root@DAL09AMMCHEF01 ~]# export CHEF_ORG=dal
[root@DAL09AMMCHEF01 ~]# knife node list |grep -i dlthdehdb
dlthdehdb.imzcloud.ibmammsap.local
dlthdehdb2
dlthdehdb3.imzcloud.ibmammsap.local


export CHEF_ORG=dal;rake bootstrap:cms3x[root,10.4.5.11,cms3x_cfg,production,dlthdehdb.imzcloud.ibmammsap.local,dal13amm,"IBM AMM Customers/Delta Air Lines -- DAL/Servers - Linux"]

export CHEF_ORG=dal;rake bootstrap:cms3x[root,10.4.5.11,cms3x_cfg,production,dlthdehdb.imzcloud.ibmammsap.local,dal09amm,"IBM AMM Customers/Delta Airlines Inc (2435738)/Servers - Linux"]

export CHEF_ORG=dlb;rake bootstrap:cms3x[root,10.13.2.20,cms3x_cfg,production,DLBDBWAP01.imzcloud.ibmammsap.local,che01amm,"IBM AMM Customers/Dilip Buildcon Limited (0000024362)/Servers - Linux"]


/tmp/pacemaker_validation_new/pacemaker_validation/run_pacemaker_validation.py




GKNADSCI	10.15.80.84	EPJ (node1 App Cluster )	Production
GKNADSCIH	10.15.80.20	EPJ (node2 App Cluster )	Production


CS10999678


CS11001674


route  add  -net 10.170.0.0 netmask 255.255.254.0 gw 10.28.26.1

route  add  -net 10.170.4.0 netmask 255.255.254.0 gw 10.28.26.1

route  add  -net 10.170.8.0 netmask 255.255.254.0 gw 10.28.26.1


10.170.0.0   via   10.28.26.1
10.170.4.0   via   10.28.26.1   
10.170.8.0   via   10.28.26.1   


CS11007182 P2 MCLLICPJ11 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj11#Cleared and Re-fired: Log PaceMaker-stonith-ng Found 1 errors. See /usr/local/ncpa/va
CS11007111 P2 MCLLICPJ11 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj11#Cleared and Re-fired: Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/
CS11007110 P2 MCLLICPJ11 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj11#Cleared and Re-fired: Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/
CS11007189 P2 MCLLICPJ01 Mhi Rj Aviation Ulc -- MC mcl#mcllicpj01#Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas
CS11007104 P2 MCLLICPJ01 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj01#Log PaceMaker-stonith-ng Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cm
CS11007105 P2 MCLLICPJ01 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj01#Cleared and Re-fired: Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/


CS11010621 P2 MCLLICPJ11 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj11#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_log
CS11010619 P2 MCLLICPJ01 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj01#Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas
CS11010617 P2 MCLLICPJ01 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj01#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_log
CS11010618 P2 MCLLICPJ11MON01-SL MCL mcl#mcllicpj11#Log PaceMaker-stonith-ng Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cm
CS11010616 P2 MCLLICPJ11 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj11#Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas
CS11010615 P2 MCLLICPJ01 Mhi Rj Aviation Ulc -- MCL mcl#mcllicpj01#Log PaceMaker-stonith-ng Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cm


plz chk and close below incidents for server as well related to same change CHG0239004
ps2-s4p-ci ,ps2-s4p-db-ha,ps2-s4p-ci-ha,ps2-s4p-db

CS11011270 P2 PS2-S4P-DB-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-db-ha#Log PaceMaker-log Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_l
CS11011268 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Log PaceMaker-crmd Found 3 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_log
CS11011269 P2 PS2-S4P-DB Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-db#Service corosync.service CRITICAL: corosync.service is inactive (dead) since Sat 2022
CS11011266 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Log PaceMaker-stonith-ng Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cm
CS11011234 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Service Pacemaker pengine CRITICAL: 0 /usr/lib/pacemaker/pengine processes running (t
CS11011233 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Resources CRM CRITICAL: Unmanaged resources found: stonith-sbd(stonith:external/sbd):
CS11011227 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Resources CRM CRITICAL: Unmanaged resources found: stonith-sbd(stonith:external/sb
CS11011224 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (
CS11011226 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes runnin
CS11011221 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)
CS11011222 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service Pacemaker attrd CRITICAL: 0 /usr/lib/pacemaker/attrd processes running (th
CS11011219 P2 PS2-S4P-DB-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-db-ha#Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes runnin
CS11011210 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Log PaceMaker-stonith-ng Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cm
CS11011208 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service Pacemaker stonithd CRITICAL: 0 /usr/lib/pacemaker/stonithd processes runni
CS11011211 P2 PS2-S4P-CI Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci#Service pacemaker.service CRITICAL: pacemaker.service is inactive (dead)
CS11011206 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service Pacemaker cib CRITICAL: 0 /usr/lib/pacemaker/cib processes running (thresh
CS11011203 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)
CS11011202 P2 PS2-S4P-DB Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-db#Service saphostexec CRITICAL: 0 /usr/sap/hostctrl/exe/saphostexec processes running (
CS11011199 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service Pacemaker crmd CRITICAL: 0 /usr/lib/pacemaker/crmd processes running (thre
CS11011194 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)
CS11011191 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Service cron CRITICAL: 0 cron processes running (thresh 1:)
CS11011190 P2 PS2-S4P-CI-HA Pak Suzuki Motor Company Ltd (Psmcl) --PS2 ps2#ps2-s4p-ci-ha#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_


Ref change no change CHG0239004
NO new error
-rw-r--r-- 1 root root  923 Apr 30 05:52 cmas_logscanner_checklog_filters.protocol-2022-04-30-05-52-54
-rw-r--r-- 1 root root  923 Apr 30 05:57 cmas_logscanner_checklog_filters.protocol-2022-04-30-05-57-55
-rw-r--r-- 1 root root 3331 Apr 30 06:02 cmas_logscanner_checklog_filters.protocol-2022-04-30-06-02-55
-rw-r--r-- 1 root root  751 Apr 30 06:07 cmas_logscanner_checklog_filters.protocol-2022-04-30-06-07-57
[ibmrmalik@ps2-s4p-db-ha protocolfiles]$ date
Sat Apr 30 09:52:15 UTC 2022

[ibmrmalik@ps2-s4p-ci ~]$ sudo su -
Directory: /root
Sat Apr 30 09:54:38 UTC 2022
[root@ps2-s4p-ci ~]# ps -ef |grep -i saphostexec
root      6484  6359  0 09:55 pts/1    00:00:00 grep --color=auto -i saphostexec
root      7900     1  0 02:44 ?        00:00:01 /usr/sap/hostctrl/exe/saphostexec pf=/usr/sap/hostctrl/exe/host_profile
[root@ps2-s4p-ci ~]# ps -ef |grep -i attrd
root      7624  6359  0 09:55 pts/1    00:00:00 grep --color=auto -i attrd
haclust+ 23742 23738  0 05:29 ?        00:00:01 /usr/lib/pacemaker/attrd
[root@ps2-s4p-ci ~]# ps -ef |grep -i crmd
root     12405  6359  0 09:55 pts/1    00:00:00 grep --color=auto -i crmd
haclust+ 23744 23738  0 05:29 ?        00:00:02 /usr/lib/pacemaker/crmd
[root@ps2-s4p-ci ~]# ps -ef |grep -i pacemakerd
root     12409  6359  0 09:55 pts/1    00:00:00 grep --color=auto -i pacemakerd
root     23738     1  0 05:29 ?        00:00:01 /usr/sbin/pacemakerd -f



[ibmrmalik@ps2-s4p-ci-ha ~]$ sudo su -
Directory: /root
Sat Apr 30 09:54:42 UTC 2022
[root@ps2-s4p-ci-ha ~]# ps -ef |grep -i saphostexec
root      5053     1  0 02:33 ?        00:00:03 /usr/sap/hostctrl/exe/saphostexec pf=/usr/sap/hostctrl/exe/host_profile
root     13217 12785  0 09:56 pts/1    00:00:00 grep --color=auto -i saphostexec
[root@ps2-s4p-ci-ha ~]# ps -ef |grep -i attrd
root     13282 12785  0 09:56 pts/1    00:00:00 grep --color=auto -i attrd
haclust+ 29173 29169  0 05:40 ?        00:00:01 /usr/lib/pacemaker/attrd
[root@ps2-s4p-ci-ha ~]# ps -ef |grep -i crmd
root     14535 12785  0 09:56 pts/1    00:00:00 grep --color=auto -i crmd
haclust+ 29175 29169  0 05:40 ?        00:00:01 /usr/lib/pacemaker/crmd
[root@ps2-s4p-ci-ha ~]# ps -ef |grep -i pacemakerd
root     17616 12785  0 09:56 pts/1    00:00:00 grep --color=auto -i pacemakerd
root     29169     1  0 05:40 ?        00:00:01 /usr/sbin/pacemakerd -f



spsvppalase01 - Not conencting , getting access denied
spsvbpdaase01 - Sudo issue
spsvbpaaapp01 - Sudo issue


ibmdrksankar
ibmdrspandey
ibmdrajha
ibmdrsprathipati

Security#1

useradd 

Local user for DR with sudo access

504  2022-04-30 21:33:13 useradd ibmdrksankar
  505  2022-04-30 21:33:24 useradd ibmdrspandey
  506  2022-04-30 21:33:32 useradd ibmdrajha
  507  2022-04-30 21:33:39 useradd ibmdrsprathipati
  508  2022-04-30 21:33:54 passwd ibmdrksankar
  509  2022-04-30 21:34:15 passwd ibmdrspandey
  510  2022-04-30 21:34:37 passwd ibmdrajha
  511  2022-04-30 21:34:54 passwd ibmdrsprathipati
  512  2022-04-30 21:35:19 usermod -g sapsys_ww ibmdrksankar
  513  2022-04-30 21:35:29 usermod -g sapsys_ww ibmdrspandey
  514  2022-04-30 21:35:37 usermod -g sapsys_ww ibmdrajha
  515  2022-04-30 21:35:43 usermod -g sapsys_ww ibmdrsprathipati


CHG0240572	PDRS4DEV2DB
PDRS4DEV2DB , PDRS4DEV2AP,
CS11032256 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11032253 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-Authentication Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/
CS11032251 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/
CS11032245 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-Hardware Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_
CS11032243 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-Authentication Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/
CS11032244 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11032242 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11032240 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Service rpcbind CRITICAL: 0 rpcbind processes running (thresh 1:)
CS11032239 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-ErrorStates Found 3 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11032238 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11031822 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-Authentication Found 2 errors. See /usr/local/ncpa/var/log/protocolfiles/
CS11031810 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11031717 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11031592 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11031587 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-Hardware Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_
CS11031479 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11031447 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma
CS11031378 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-Authentication Found 2 errors. See
CS11031347 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-Hardware Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_l
CS11031301 P2 PDRS4DEV2DB Pikdare S.P.A. -- PDR pdr#pdrs4dev2db#Log Syslog-Hardware Found 16 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_
CS11031296 P2 PDRS4DEV2AP Pikdare S.P.A. -- PDR pdr#pdrs4dev2ap#Log Syslog-ErrorStates Found 4 errors. See /usr/local/ncpa/var/log/protocolfiles/cma



CHG0241333 05/08/2022 - 10:00 - NIX - DLB - PATCH


b2bread / P@ssw0rd		

Subsystem sftp  internal-sftp
 
Match Group sftpgroup
   ChrootDirectory /sftpusers/chroot/
   ForceCommand internal-sftp
   X11Forwarding no
   AllowTcpForwarding no
   
   
Specific permission to a user to a specific path only
setfacl -m u:b2bread:r /sftpusers/chroot/b2bread


CHG0241581 || 05/07/2022 - 13:00 - NIX - AP4 - PATCH

.28.140	10.198.2.140 - VM Name - A0EGSG014XVM005
ECCAP1PRD	172.28.28.141	10.198.2.141 - VM Name - A0EGSG014XVM006


CS11059213	LSPI -- LSP	P2 - Major	lsp#lzaeccsbx0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAECCSBX0- KB0010973
CS11059212	LSPI -- LSP	P2 - Major	lsp#lzagrcdev0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAGRCDEV0- KB0010973
CS11059210	LSPI -- LSP	P2 - Major	lsp#lzaeccprd0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAECCPRD0- KB0010973
CS11059206	LSPI -- LSP	P2 - Major	lsp#lzabwprd0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZABWPRD0- KB0010973

CS11059201	LSPI -- LSP	P2 - Major	lsp#lzabjsbx0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZABJSBX0- KB0010973
CS11059202	LSPI -- LSP	P2 - Major	lsp#lzabjdev0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZABJDEV0- KB0010973
CS11059200	LSPI -- LSP	P2 - Major	lsp#lzaadsbx0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAADSBX0- KB0010973
CS11059199	LSPI -- LSP	P2 - Major	lsp#lzaadqas0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAADQAS0- KB0010973
CS11059197	LSPI -- LSP	P2 - Major	lsp#lzaadprd0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LZAADPRD0- KB0010973



SuSE case  https://scc.suse.com/support/cases/00346364#02s5q000003VM9FAAW		00346364
SNOW case CS11061918
ogypxp021
it was taking 10+ minutes to log into that server

Update https://kyndryl.slack.com/archives/C028DSXDGTG/p1651847878692389

OGYDBP037	10.139.9.77	10.25.9.168
OGYPXP021	PXP	10.139.8.16	10.25.8.26



P2 CS11060565 wa2#Log Syslog_All May 6 05:47:13 a0331p3pdbspk02 Had[9325]: VCS CRITICAL V-16-1-50086 CPU usage on pdbspk02 is 98%
P2 CS11061750 wa2#a0331v2rapsod15#Ping Availability CRITICAL - 10.131.96.2: rta nan. lost 100% Attention commas replaced by dots.
P2 CS11061258 wa2#a0331p3rdbsdl20#Ping Availability CRITICAL - 10.93.173.153: rta nan. lost 100% Attention commas replaced by dots.


\\KRRGSAPAPWGA\backup1		wgaadm/SAPibm#123456789
\\KRRGSAPAPWGA\backup2
Prod - Hana DB		krrdbprd1	10.139.120.46
Prod - Hana DB HA	krrdbprd2	10.139.120.70
Dev - Hana DB		KRRDBDEV	10.139.128.63



S4H QA: ECCTEST

and


PRD SAPAPP15
SAPAPP18
SAPAPP19
SAPAPP20
SAPAPP21
SAPAPP23
SAPAPP26
SAPAPP27
SAPAPP28
SAPAPP29
SAPAPP30
SAPAPP31
SAPAPP31-HA
SAPAPP32
SAPAPP33
SAPAPP34
SAPAPP35
SAPAPP36
SAPAPP37



Printer Details:
IP :                       135.37.12.52
Printer Model :  HP LaserJet M506
Queue name :   NPIE75DF0


IP :                         135.37.12.49
Printer Model :  HP LaserJet M506
Queue name :     NPIEA1D3B


135.37.12.52	NPIE75DF0
135.37.12.49	NPIEA1D3B


lpadmin -p NPIE75DF0 -v socket://135.37.12.52 -E

lpadmin -p NPIEA1D3B -v socket://135.37.12.49 -E

cupsenable	NPIE75DF0
cupsaccept	NPIE75DF0

cupsenable	NPIEA1D3B
cupsaccept	NPIEA1D3B

CS11080723 P2 DLTHQEHAP4 Delta Air Lines -- DAL dal#dlthqehap4#Ping Availability CRITICAL - 10.4.5.39: rta nan. lost 100% Attention commas replaced by dots.
CS11080711 P2 DLTHDBBSI02 Delta Air Lines -- DAL dal#dlthdbbsi02#Ping Availability CRITICAL - 10.4.5.28: rta nan. lost 100% Attention commas replaced by dots.
CS11080692 P2 DLTHSBBSI02 Delta Air Lines -- DAL dal#dlthsbbsi02#Ping Availability CRITICAL - 10.4.5.27: rta nan. lost 100% Attention commas replaced by dots.
CS11080688 P2 DLTHPEHP3 Delta Air Lines -- DAL dal#dlthpehp3#Ping Availability CRITICAL - 10.4.5.55: rta nan. lost 100% Attention commas replaced by dots.
CS11080684 P2 DLTHPEHP4 Delta Air Lines -- DAL dal#dlthpehp4#Ping Availability CRITICAL - 10.4.5.56: rta nan. lost 100% Attention commas replaced by dots.
CS11080681 P2 DLTHPEHP1 Delta Air Lines -- DAL dal#dlthpehp1#Ping Availability CRITICAL - 10.4.5.53: rta nan. lost 100% Attention commas replaced by dots.
CS11080680 P2 DLTHPBBSI Delta Air Lines -- DAL dal#dlthpbbsi#Ping Availability CRITICAL - 10.4.5.50: rta nan. lost 100% Attention commas replaced by dots.
CS11080678 P2 DLTDEAHDB Delta Air Lines -- DAL dal#dltdeahdb#Ping Availability CRITICAL - 10.4.5.185: rta nan. lost 100% Attention commas replaced by dots.
CS11080679 P2 DLTHPEHAP11 Delta Air Lines -- DAL dal#dlthpehap11#Ping Availability CRITICAL - 10.4.5.154: rta nan. lost 100% Attention commas replaced by dots.


Dev - pdrconprd - bcpadm
Prod - pdrcoprod - bc0adm

in DEV
user : CPIDS  
VM : PDRCONPRD  10.25.134.16  10.21.0.30  SUSE
Folder : /opt/sap/CPI_DS/file-exchange
Change file permission to owner/Group : bcpadm sapsys
and full permission

In PROD
user : CPIDSPRD  
VM : PDRCOPROD  10.25.136.12  10.21.2.15  SUSE
Folder : /usr/sap/CP0/cpids_admin/DataServicesAgent/file-exchange
Change file permission to owner/Group : bc0adm sapsys
and full permission 



CHG0240579 05/15/2022 - 15:00 - NIX - PDR - PATCH
CHG0240577 05/15/2022 - 20:00 - NIX - PDR - PATCH


[root@hrmazsp1db ~]# crm configure show |grep -i colocation
colocation col_saphana_ip_SP1_HDB02 inf: rsc_gip_SP1_HDB02:Started rsc_TSMTDP_SP1_HDB02:Started msl_SAPHana_SP1_HDB02:Master

[root@hrmazsp1db ~]# crm configure show |grep -i order
order ord_SAPHana_SP1_HDB02 Optional: cln_SAPHanaTopology_SP1_HDB02 msl_SAPHana_SP1_HDB02


colocation col_saphana_ip_HHA_HDB00 inf: rsc_ip_HHA_HDB00:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master

order ord_SAPHana_HHA_HDB00 Optional: cln_SAPHanaTopology_HHA_HDB00 msl_SAPHana_HHA_HDB00




CS11096845	Halifax Regional Municipality -- HRM	P2 - Major	hrm#hrmazsp1ap1#Service Pacemaker pengine CRITICAL: 0 pengine processes running (thresh 1:)

CS11096821	Halifax Regional Municipality -- HRM	P2 - Major	hrm#hrmazsp1ap1ha#Service corosync.service CRITICAL: corosync.service is inactive (dead)


CS11096811	Halifax Regional Municipality -- HRM	P2 - Major	hrm#hrmazsp1ap1ha#Service Pacemaker attrd CRITICAL: 0 attrd processes running (thresh 1:)
CS11096808	Halifax Regional Municipality -- HRM	P2 - Major	hrm#hrmazsp1ap1#Service Pacemaker cib CRITICAL: 0 cib processes running (thresh 1:)

CS11096804	Halifax Regional Municipality -- HRM	P2 - Major	hrm#hrmazsp1ap1ha#Service Pacemaker cib CRITICAL: 0 cib processes running (thresh 1:)
CS11096806	Halifax Regional Municipality -- HRM	P2 - Major	hrm#hrmazsp1ap1#Service Pacemaker lrmd CRITICAL: 0 lrmd processes running (thresh 1:)



=>Server/Host name................................: or9.zf-world.com (zffpapp001.zf-world.com, zffpapp001-ha.zf-world.com)
Please change IP for below printers on OR9
AN01 -> 140.171.152.175
AN02 -> 140.171.152.177

[root@zffpapp001 ~]# lpstat -t|grep -i AN01
device for AN01: socket://140.171.152.175
AN01 accepting requests since Mon Apr 18 18:35:46 2022
printer AN01 is idle.  enabled since Mon Apr 18 18:35:46 2022

[root@zffpapp001 ~]# lpstat -t|grep -i AN02
device for AN02: socket://140.171.152.177
AN02 accepting requests since Tue Mar 16 14:20:30 2021
printer AN02 is idle.  enabled since Tue Mar 16 14:20:30 2021


CHG0240158	14-05-2022 06:30:00	14-05-2022 10:30:00

[root@jp0811zbe1007 ~]# zypper locks;cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports; df -hT |grep -i nfs;df -hT |grep -i cifs

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)     
2 | atmel-firmware   | package | (any)     
3 | ipw-firmware     | package | (any)     
4 | mpt-firmware     | package | (any)     

NAME="SLES"
VERSION="12-SP3"
VERSION_ID="12.3"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP3"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp3"
Linux jp0811zbe1007 4.4.180-94.153-default #1 SMP Mon Jan 31 19:00:11 UTC 2022 (005398b) x86_64 x86_64 x86_64 GNU/Linux
Sat May 14 10:26:42 JST 2022
      Local time: Sat 2022-05-14 10:26:42 JST
  Universal time: Sat 2022-05-14 01:26:42 UTC
        RTC time: Sat 2022-05-14 01:26:42
       Time zone: Asia/Tokyo (JST, +0900)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to 
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

tok02ammyum01.imzcloud.ibmammsap.local:/sds nfs4      4.0T  3.6T  173G  96% /sds



[root@jp0811zbe1007 ~]# zypper locks;cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports; df -hT |grep -i nfs;df -hT |grep -i cifs

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)     
2 | atmel-firmware   | package | (any)     
3 | ipw-firmware     | package | (any)     
4 | mpt-firmware     | package | (any)     

NAME="SLES"
VERSION="12-SP3"
VERSION_ID="12.3"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP3"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp3"
Linux jp0811zbe1007 4.4.180-94.161-default #1 SMP Fri Apr 8 11:27:41 UTC 2022 (920f586) x86_64 x86_64 x86_64 GNU/Linux
Sat May 14 10:57:58 JST 2022
      Local time: Sat 2022-05-14 10:57:58 JST
  Universal time: Sat 2022-05-14 01:57:58 UTC
        RTC time: Sat 2022-05-14 01:57:58
       Time zone: Asia/Tokyo (JST, +0900)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to 
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.

tok02ammyum01.imzcloud.ibmammsap.local:/sds nfs4      4.0T  3.6T  173G  96% /sds


OS ID ibmdrrthota created , password is   q#pi13Yld6CGK1$
  452  2022-04-30 21:37:25 useradd ibmdrajha
  455  2022-04-30 21:37:56 usermod -g sapsys_ww ibmdrksankar
  459  2022-04-30 21:38:22 passwd ibmdrspandey
  463  2022-04-30 21:42:13 cat /etc/sudoers |grep -i sapsys_ss
  464  2022-04-30 21:42:18 cat /etc/sudoers |grep -i sapsys_ww



CHG0242100  Grohe AG -- GH2 Linux   5/20/2022  20:00
CHG0242000  SIRMAN S.P.A. -- SIR  Linux   5/18/2022  20:00


CS11142659	GKN Driveline Newton LLC -- GKN	P2 - Major	gkn#gknpeccprddbh#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNPECCPRDDBH- KB0010973
CS11142657	GKN Driveline Newton LLC -- GKN	P2 - Major	gkn#gknpeccprddb#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNPECCPRDDB- KB0010973
CS11142658	GKN Driveline Newton LLC -- GKN	P2 - Major	gkn#gkneccprdcih#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNECCPRDCIH- KB0010973
CS11142656	GKN Driveline Newton LLC -- GKN	P2 - Major	gkn#gknsoldev#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNSOLDEV- KB0010973
CS11142654	GKN Driveline Newton LLC -- GKN	P2 - Major	gkn#gkneccprdci#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNECCPRDCI- KB0010973
CS11142655	GKN Driveline Newton LLC -- GKN	P2 - Major	gkn#gkneccdevqa#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on GKNECCDEVQA- KB0010973



samhanau01	SYD04CLPOOL01DS2


	CS11155580 P2 GH2SV008104 Grohe AG -- GH2 gh2#gh2sv008104#Log PaceMaker-log Found 13 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-11-37-41 for d
	CS11155457 P2 GH2SV008107 Grohe AG -- GH2 gh2#gh2sv008107#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-07-58-34 for d
	CS11155456 P2 GH2SV008104 Grohe AG -- GH2 gh2#gh2sv008104#Service Pacemaker crmd CRITICAL: 0 crmd processes running (thresh 1:)
	CS11155454 P2 GH2SV008108 Grohe AG -- GH2 gh2#gh2sv008108#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-07-40-51 for d
	CS11155453 P2 GH2SV008108 Grohe AG -- GH2 gh2#gh2sv008108#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-04-34-37 for d
	CS11155452 P2 GH2SV008107 Grohe AG -- GH2 gh2#gh2sv008107#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-03-59-27 for d
	CS11155450 P2 GH2SV008107 Grohe AG -- GH2 gh2#gh2sv008107#Service Pacemaker pengine CRITICAL: 0 pengine processes running (thresh 1:)
	CS11155447 P2 GH2SV008107 Grohe AG -- GH2 gh2#gh2sv008107#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-07-28-29 for d
	CS11155444 P2 GH2SV008108 Grohe AG -- GH2 gh2#gh2sv008108#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-07-25-50 for d
	CS11155441 P2 GH2SV008107 Grohe AG -- GH2 gh2#gh2sv008107#Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-04-21-29 for d
CS11155439 P2 GH2SV008105 Grohe AG -- GH2 gh2#gh2sv008105#Service sbd.service CRITICAL: sbd.service is inactive (dead) since Sat 2022-05-21 04:24:18 CEST: 2min 47s ago
	CS11155437 P2 GH2SV008108 Grohe AG -- GH2 gh2#gh2sv008108#Service cron CRITICAL: 0 cron processes running (thresh 1:)
CS11155436 P2 GH2SV008105 Grohe AG -- GH2 gh2#gh2sv008105#Service corosync.service CRITICAL: corosync.service is inactive (dead) since Sat 2022-05-21 04:24:19 CEST: 2min 46s ago
	CS11155431 P2 GH2SV008108 Grohe AG -- GH2 gh2#gh2sv008108#Resources DRBD CRITICAL: Role value Unknown found for resource r0 on host gh2sv008107
CS11155432 P2 GH2SV008105 Grohe AG -- GH2 gh2#gh2sv008105#Service pacemakerd CRITICAL: 0 pacemakerd processes running (thresh 1:)
	CS11155433 P2 GH2SV008108 Grohe AG -- GH2 gh2#gh2sv008108#Service Pacemaker stonithd CRITICAL: 0 stonithd processes running (thresh 1:)
	CS11155428 P2 GH2SV008104 Grohe AG -- GH2 gh2#gh2sv008104#Service Pacemaker pengine CRITICAL: 0 pengine processes running (thresh 1:)
CS11155429 P2 GH2SV008105 Grohe AG -- GH2 gh2#gh2sv008105#Service Pacemaker attrd CRITICAL: 0 attrd processes running (thresh 1:)
	CS11155426 P2 GH2SV008104 Grohe AG -- GH2 gh2#gh2sv008104#Log PaceMaker-log Found 14 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-05-21-10-57-37 for d

CHG0242100



crm configure show >>/tmp/configure_backup


Before
primitive OraLSN oralsnr \
        params sid=TP1 home="/oracle/TP1/12102" user=oratp1 listener=LISTENER_TP1 tns_admin="/oracle/TP1/12102/network/admin/tnsnames.ora" \
        op start interval=0s timeout=120s \
        op stop interval=0s timeout=120s \
        op monitor interval=120 timeout=60 \
        op_params depth=0
primitive OraSrv oracle \
        params sid=TP1 home="/oracle/TP1/121" user=oratp1 shutdown_method=immediate ipcrm=orauser \
        op start interval=0s timeout=120s \
        op stop interval=0s timeout=120s \
        op monitor interval=120s timeout=60s

After
primitive OraLSN oralsnr \
        params sid=TP1 home="/oracle/TP1/19.0.0" user=oratp1 listener=LISTENER_TP1 tns_admin="/oracle/TP1/19.0.0/network/admin/tnsnames.ora" \
        op start interval=0s timeout=120s \
        op stop interval=0s timeout=120s \
        op monitor interval=120 timeout=60 \
        op_params depth=0
primitive OraSrv oracle \
        params sid=TP1 home="/oracle/TP1/19" user=oratp1 shutdown_method=immediate ipcrm=orauser \
        op start interval=0s timeout=120s \
        op stop interval=0s timeout=120s \
        op monitor interval=120s timeout=60s



CHG0242094
[PRD-SNG01/DR-CHE01] [DR] Home Control Singapore ( HCS) Client Activation DR test

Prod Hostname	CFN IP	                IFN IP	               DR Hostname	        CFN IP	                IFN IP
HCSECCHDB0PRD	172.28.28.135	10.198.2.135	HCSECC0PRDDR1	172.18.18.142	10.204.2.138
ECCCI0PRD	        172.28.28.140	10.198.2.140	ECCCI0PRD	        172.28.28.140	10.198.2.140
ECCAP1PRD	        172.28.28.141	10.198.2.141	ECCAP1PRD	        172.28.28.141	10.198.2.141




CS11180341	Home Control Singapore -- HCS	P1 - Severe	hcs#eccci0dev#Host Reboot CRITICAL: Uptime 3 minutes (thresh 30 min)	ECCCI0DEV	
CS11180333	Home Control Singapore -- HCS	P1 - Severe	hcs#hcsecchdb0dev#Host Reboot CRITICAL: Uptime 0 minutes (thresh 30 min)	HCSECCHDB0DEV
CS11180332	Home Control Singapore -- HCS	P1 - Severe	hcs#eccci0qas#Host Reboot CRITICAL: Uptime 4 minutes (thresh 30 min)	ECCCI0QAS	
CS11180329	Home Control Singapore -- HCS	P1 - Severe	hcs#eccci0dev#Service SAPRouter CRITICAL: 0 saprouter processes running (thresh 1:)	ECCCI0DEV

/dev/s4dappvg/oraclepoc_lv


lpadmin -p GR54 -v socket://GR54.perkinelmer.com:515 -E

	CS11193158	Liberty Utilities (Canada) Corp -- LBU	P1 - Severe	lbu#lbuvs1db01#Unable to ping LBUVS1DB01 (10.139.32.155) from FRDAL13WEBD01.
	CS11193156	Liberty Utilities (Canada) Corp -- LBU	P1 - Severe	lbu#lbuph1db01#Unable to ping LBUPH1DB01 (10.139.10.166) from FRDAL13WEBD01.
C	S11193155	Liberty Utilities (Canada) Corp -- LBU	P1 - Severe	lbu#lbuvg1db01#Unable to ping LBUVG1DB01 (10.139.32.194) from FRDAL13WEBD01.
	CS11193154	Liberty Utilities (Canada) Corp -- LBU	P1 - Severe	lbu#lbuvh2db01#Unable to ping LBUVH2DB01 (10.139.32.196) from FRDAL13WEBD01.

CS11193508	Liberty Utilities (Canada) Corp -- LBU	P2 - Major	lbu#lbuvh2db01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUVH2DB01- KB0010973
CS11193509	Liberty Utilities (Canada) Corp -- LBU	P2 - Major	lbu#lbuvs1db01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUVS1DB01- KB0010973
CS11193507	Liberty Utilities (Canada) Corp -- LBU	P2 - Major	lbu#lbuvg1db01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUVG1DB01- KB0010973
CS11193505	Liberty Utilities (Canada) Corp -- LBU	P2 - Major	lbu#lbuph1db01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUPH1DB01- KB0010973
CS11193504	Liberty Utilities (Canada) Corp -- LBU	P2 - Major	lbu#lbuph1db01-dr#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUPH1DB01-DR- KB0010973


10.65.11.30	wdc04-pod4-6tb-host004.imzcloud.ibmammsap.local
root w%q,#B9KQK.7gP

10.65.11.30	wdc04-pod4-6tb-host004.imzcloud.ibmammsap.local

10.65.11.30	wdc04-pod4-6tb-host004.imzcloud.ibmammsap.local



IPMI  root   m8KL67us8g

number:CS2844899 


colocation col_saphana_ip_PAM_HDB00 2000: rsc_ip_PAM_HDB00:Started msl_SAPHana_PAM_HDB00:Master rsc_TSMTDP_PAM_HDB00:Started
order ord_SAPHana_PAM_HDB00 Optional: cln_SAPHanaTopology_PAM_HDB00 msl_SAPHana_PAM_HDB00 rsc_TSMTDP_PAM_HDB00


colocation col_saphana_ip_PAM_HDB00 2000: rsc_ip_PAM_HDB00:Started rsc_TSMTDP_PAM_HDB00:Started msl_SAPHana_PAM_HDB00:Master
order ord_SAPHana_PAM_HDB00 Optional: cln_SAPHanaTopology_PAM_HDB00 msl_SAPHana_PAM_HDB00


colocation col_saphana_ip_HHA_HDB00 inf: rsc_ip_HHA_HDB00:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master
order ord_SAPHana_HHA_HDB00 Optional: cln_SAPHanaTopology_HHA_HDB00 msl_SAPHana_HHA_HDB00


[root@pamhanau01 ~]# crm configure show |grep -i colocation
colocation col_saphana_ip_PAM_HDB00 2000: rsc_ip_PAM_HDB00:Started rsc_TSMTDP_PAM_HDB00:Started msl_SAPHana_PAM_HDB00:Master
[root@pamhanau01 ~]# crm configure show |grep -i order
order ord_SAPHana_PAM_HDB00 Optional: cln_SAPHanaTopology_PAM_HDB00 msl_SAPHana_PAM_HDB00






[root@pamhanau01 ~]# crm config show |grep -i colocation
colocation col_saphana_ip_PAM_HDB00 2000: rsc_ip_PAM_HDB00:Started rsc_TSMTDP_PAM_HDB00:Started msl_SAPHana_PAM_HDB00:Master
[root@pamhanau01 ~]# crm config show |grep -i order
order ord_SAPHana_PAM_HDB00 Optional: cln_SAPHanaTopology_PAM_HDB00 msl_SAPHana_PAM_HDB00



[root@hrmazdp1db ~]# last
uxscan   pts/2        100.65.40.5      Thu Jun  2 03:21   still logged in
ibmrmali pts/0        146.89.142.228   Thu Jun  2 03:20   still logged in
reboot   system boot  4.12.14-95.83-de Thu Jun  2 03:17 - 03:22  (00:04)
dp1adm   pts/0        146.89.140.60    Thu Jun  2 02:59 - crash  (00:17)


CS11226976Perkinelmer, Inc. -- PRKP1 - Severeprk#prdh04#Mountpoint Interface CRITICAL: /sapio/PR1 did not respond in 3 sec. Seems to be stale. :
CS11227026 Perkinelmer, Inc. -- PRKP1 - Severeprk#prap01#Mountpoint Interface CRITICAL: /sapmnt/PR1 did not respond in 3 sec. Seems to be stale. : /sapstage did not respond in 3 sec. Seems to be stale. : /o
CS11227011 Perkinelmer, Inc. -- PRKP1 - Severeprk#prsv10#Mountpoint Interface CRITICAL: /opt/PR1/taxware did not respond in 3 sec. Seems to be stale. :
CS11227003 Perkinelmer, Inc. -- PRKP1 - Severeprk#prdh04#Mountpoint Interface CRITICAL: /sapio/PR1 did not respond in 3 sec. Seems to be stale. :


CHG0244974
DS agent reinstall	ps -ef |grep -i ds_agent

BSS	a1asisbx02  stopped		Ravi	Done
PYS	AHECSSAP01  stopped		Ravi	DOne
PYS	ahecshdb01  stopped		Ravi	Done

XIS	AHPOSSAP01  stopped			Pooja	   
XID	AHPODSAP01	stopped			Pooja

BSD	ahbsidev01 stopped		Ravi	A0F0US014XVM011	Done
PYD	ahecdsap01	 stopped	Ravi	A0F0US014XVM015	DOne
PYD	ahecdhdb01	 stopped	Ravi	Done

GRD   a1agrdhdb01 stopped		Pooja
GRD    a1agrdapp01 stopped		Pooja

PYQ    AHECQSAP01	stopped		Ravi	Done
PYQ    a1ahecqsap02 stopped		Ravi	Done	
PYQ    AHECQHDB01	stopped		Ravi	Done
BSQ    ahbsisbx01	stopped		Ravi	Done

WDQ   a1ahecwdq01  stopped		Pooja
XIQ   AHPOQSAP01 stopped		Pooja
GRQ   a1agrqapp01 stopped		Pooja
GRQ   a1agrqdb01  stopped		Pooja


PQ2   AHECQ2SAP01 stopped		Ravi	Done
PQ2   AHECQ2HDB01 stopped		Ravi	Done
XQ2   AHPOQ2SAP01 stopped		Pooja
BQ2   ahbsiqa201  stopped		Pooja


[root@AHBSISBX01 tmp]$ rpm -qa |grep -i ds_agent
ds_agent-20.0.0-4416.el6.x86_64
You have mail in /var/spool/mail/root

Installed Packages
Name        : ds_agent
Arch        : x86_64
Version     : 20.0.0
Release     : 4416.el6
Size        : 172 M
Repo        : installed
Summary     : Trend Micro Deep Security Agent
URL         : http://www.trendmicro.com/
License     : Copyright (c) 2004-2010, Trend Micro Inc.
Description : The ds_agent program communicates with the Trend Micro
            : Deep Security Manager and controls the local firewall,
            : content filtering, integrity monitoring, and log inspection rules.




522  2022-06-02 21:16:46 for port in $(echo "4118 4119 4120 4122"); do nc -zv 169.55.28.72 $port; done
  523  2022-06-02 21:17:42 ping fmsprdtren001.prdcloud.fms.ibmcloud.com
  524  2022-06-02 21:18:07 ping fmsprdtren002.prdcloud.fms.ibmcloud.com
  525  2022-06-02 21:18:49 rpm -qa |grep -i ds_agent
  526  2022-06-02 21:20:27 chef-client
  527  2022-06-02 21:25:25 rpm -qa |grep -i ds_agent
  528  2022-06-02 21:27:36 shutdown -r now
  529  2022-06-02 21:32:35 rpm -qa |grep -i ds_agent
  530  2022-06-02 21:32:52 ps -ef |grep -i ds_agent
  531  2022-06-02 21:33:25 cat /etc/*release
  532  2022-06-02 21:33:40 /etc/init.d/ds_agent status
  533  2022-06-02 21:33:52 ps -ef |grep -i ds_agent
  534  2022-06-02 21:34:36 cd /opt/ds_agent
  535  2022-06-02 21:34:50 ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
  536  2022-06-02 21:35:26 ./dsa_control -r
  537  2022-06-02 21:35:42 ./dsa_control -a dsm://169.55.28.72:4120
  538  2022-06-02 21:36:15 ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"


507  2022-06-02 22:41:39 /etc/init.d/ds_agent stop
  508  2022-06-02 22:42:21 rpm -evh ds_agent-10.0.0-2736.el6.x86_64
  509  2022-06-02 22:42:42 rpm -ev ds_agent-10.0.0-2736.el6.x86_64
  510  2022-06-02 22:43:42 cd /tmp
  511  2022-06-02 22:44:02 vi Linux_AgentDeploymentScript.sh
  512  2022-06-02 22:44:21 chmod 777 Linux_AgentDeploymentScript.sh
  513  2022-06-02 22:44:40 ./Linux_AgentDeploymentScript.sh
  514  2022-06-02 22:45:15 rpm -qa |grep -i ds_agent
  515  2022-06-02 22:45:58 yum info ds_agent
  516  2022-06-02 22:47:32 history


CHG0245264	07-06-2022 08:30:00 - 07-06-2022 12:30:00	
HFCWDQAPP1
HFCHEQAPP1

Send email notification of completion to:

HollyFrontier:
Pat Swierk - Pat.Swierk@HollyFrontier.com
Demondre Rodgers - Demondre.Rodgers@HollyFrontier.com
Karl Csiszar - Karl.Csiszar@HollyFrontier.com
Shipra Srivastava - Shipra.Srivastava@hollyfrontier.com

Kyndryl:
DPE: Milind Shauche - Milind.Shauche@kyndryl.com
PDL: Parth Patel - parth.patel@kyndryl.com
PDL: Rich Weklar - rich.weklar@kyndryl.com

Pat.Swierk@HollyFrontier.com; Demondre.Rodgers@HollyFrontier.com; Karl.Csiszar@HollyFrontier.com; Shipra.Srivastava@hollyfrontier.com
Milind.Shauche@kyndryl.com; parth.patel@kyndryl.com; rich.weklar@kyndryl.com


CS11266247 - conspbw4hapq - IMZ login to server not working  - notes have been added. thank you. (edited) 

CHEF_ORG=con knife node show conspbw4hapq.imzcloud.ibmammsap.local -a linuxad_auth.kerberos_rdns
conspbw4hapq.imzcloud.ibmammsap.local:
  linuxad_auth.kerberos_rdns: false
  
  
CS11266787	Mhi Rj Aviation Ulc -- MCL	P4 - Minimal	Executing salt module ibm_inventory.get on 5bb26b86-7c0b-483f-9d5c-f2062ca17f39/mcllahpo51
CS11266786	Mhi Rj Aviation Ulc -- MCL	P4 - Minimal	Executing salt module ibm_inventory.get on 7cd229ea-d0a9-4f38-83ea-95203ba43088/mcllaeqa52
CS11266784	Mhi Rj Aviation Ulc -- MCL	P4 - Minimal	Executing salt module ibm_inventory.get on 92e52e32-e779-4630-8ec1-74ff42365667/mcllabqa51
CS11266783	Mhi Rj Aviation Ulc -- MCL	P4 - Minimal	Executing salt module ibm_inventory.get on 699ab22a-3040-4d0e-aad8-986f149291c8/mcllahpo52
CS11266782	Mhi Rj Aviation Ulc -- MCL	P4 - Minimal	Executing salt module ibm_inventory.get on c8ad1e96-c860-478c-a90b-6274ed41368c/mcllaeqa53
CS11266780	Mhi Rj Aviation Ulc -- MCL	P4 - Minimal	Executing salt module ibm_inventory.get on 2c217ac7-3e17-45bd-b196-4c0ea1ed4067/mcllaeqa51
CS11266779	Mhi Rj Aviation Ulc -- MCL	P4 - Minimal	Executing salt module ibm_inventory.get on 5a370f67-035b-4008-ad04-930d525f17a9/mcllabqa52
  
  
  
SM9CSGCLX02			10.135.226.142	Quality					Q33 - HANA DB
SM9CSGCLX01			10.135.226.23		Development				T33  
  *************************************************************************
*    Server Type: Development                                                 *
*       Hostname: sm9csgclx01                                                 *
*         CFN IP: 10.139.226.168                                              *
*         IFN IP: 10.135.226.54                                               *
*        SAP SID: T33      
  
  
  
  
journalctl --since "2022-06-06 00:00:00" --until "2022-06-06 23:59:59"
  
 
CHG0243873 06/12/2022 - 05:00 - NIX - PRK - PATCH.    approve

 CS11274345 Mhi Rj Aviation Ulc -- MCLmcl#mcllaepa03#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.P2 - Major MCLLAEPA03
CS11274347 Mhi Rj Aviation Ulc -- MCLmcl#mcllaeqa51#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.P2 - Major MCLLAEQA51
CS11274350 Mhi Rj Aviation Ulc -- MCLmcl#mcllaepa01#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.P2 - Major MCLLAEPA01
CS11274349 Mhi Rj Aviation Ulc -- MCLmcl#mcllaepa02#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.P2 - Major MCLLAEPA02
CS11274348 Mhi Rj Aviation Ulc -- MCLmcl#mcllaeqa53#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.P2 - Major MCLLAEQA53
CS11274346 Mhi Rj Aviation Ulc -- MCLmcl#mcllaepa11#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.P2 - Major MCLLAEPA11
:white_check_mark:
1


CHG0242433   SunCor tickets
All PaaS HEC Suncor system will be stopped, except for the following:
P1D
P1H
P1M
PB1
PB6
PC1
PG1
PN1
PO1
PP6
PR1
PW1
PW2
PZ1
TC1 

The purpose of this change is to cover the stopping on the SAP applications/databases, and provide suppression until monitoring is disabled.


etgrws04p	root d%2TT2m-Udy`Qc8     or    A999tjZroo83jS}
etgrws09p	root  
etgrws22p



PROD - SNG
DR - Chennai
Server - hgyp09dbap01




CS11313107
Server Type: QA                                                          *
*       Hostname: br3qsapss30                                                 *
*         CFN IP: 10.3.112.85                                                 *
*         IFN IP: 10.138.10.80                                                *
*        SAP SID: Q4H
9:46
second node is
Server Type: QA                                                          *
*       Hostname: br3qsapss31                                                 *
*         CFN IP: 10.3.112.67                                                 *
*         IFN IP: 10.138.10.105                                               *
*        SAP SID: Q4H






CS11321546	Farmoquimica S.A. -- Z0H	P1 - Severe	Device system down data centre


Hostname	                 Device Type	                   Used For	           CDIR	Customer Name	                          Trio
z0hqmpiprad01	         Windows Server	           Production	            Z0H	Farmoquimica S.A. -- Z0H	          SAPB2				OK
z0hibmpmd1	         Windows Server	           Production	            Z0H	Farmoquimica S.A. -- Z0H	          SAPB2				OK
z0hactdir01	                 Windows Server	           Production	            Z0H	Farmoquimica S.A. -- Z0H	          SAPB2			OK
z0hactdir02	                 Windows Server	           Production	            Z0H	Farmoquimica S.A. -- Z0H	          SAPB2			OK
z0hqmerprap01	         Windows Server	           Production	            Z0H	Farmoquimica S.A. -- Z0H	          SAPB2				OK
z0hibmact1	                 Windows Server	           Production	            Z0H	Farmoquimica S.A. -- Z0H	          SAPB2			OK
z0hqmpidvad02	         Windows Server	           Development	    Z0H	Farmoquimica S.A. -- Z0H	          SAPB2					OK


z0hqmpidvad02		10.16.30.13	10.100.30.20
z0hqmpiprad01		10.16.30.10	10.100.30.13	
z0hibmpmd1		10.16.30.15	10.100.30.22
z0hactdir01		10.16.30.9	10.100.30.7
z0hactdir02		10.16.30.6	10.100.30.12
z0hqmerprap01		10.16.30.30
z0hibmact1		10.16.30.12	10.100.30.25
z0hqmpidvad02		10.16.30.13	10.100.30.20


QAS (tsleecqa01)
BQA (ttslbwqadb01)




RCA RCA0007867 BR3
CS11316933	Bombardier Recreational Products Inc -- BR3	P1 - Severe	br3#br3qsapss31#Q4HBR3 (ABAP)|ABAP_SYSTEM_AVAILABILITY|ABAP System not available	BR3QSAPSS31
CS11316891	Bombardier Recreational Products Inc -- BR3	P1 - Severe	br3#br3qsapss30#Host Reboot CRITICAL: Uptime 0 minutes (thresh 60 min)	BR3QSAPSS30
CHG0246608 is the ref change




[root@ogyqgl005 ~]# lsscsi | grep -i /dev/sdr
[3:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdr
[root@ogyqgl005 ~]# lsscsi | grep -i /dev/sds
[3:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sds
sdr - SCSI 3:0:2:0
sds - SCSI 3:0:3:0


Required swap is 64 GB, configured swap is 48.0 GB. Check for "Memory Swap" alert tickets and adjust if necessary
BIOS (Firmware) release date is older than 2465 days


u to share your details (along with PAN& your mobile number) with us at orm@cpc.incometax.gov.in.


 CS11344566Perkinelmer, Inc. -- PRKprk#prdb05#Mountpoint Interface CRITICAL: /usr/sap/smtrans did not respond in 3 sec. Seems to be stale. :P1 - SeverePRDB05SQ-SAP-TRIO-B2
CS11344670 Perkinelmer, Inc. -- PRKprk#npsv059#Unable to ping NPSV059 (10.151.0.73) from FRDAL13WEBD01.P1 - SevereNPSV059SQ-SAP-TRIO-B2
CS11344702 Perkinelmer, Inc. -- PRKprk#npsv07#Host Reboot CRITICAL: Uptime 3 minutes (thresh 30 min)P1 - SevereNPSV07SQ-SAP-TRIO-B2


[root@npsv17 ~]# ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[/]' '{print $4,"- SCSI",$7}'
sda - SCSI 0:0:0:0
sdb - SCSI 0:0:1:0
sdc - SCSI 0:0:2:0
sdd - SCSI 0:0:3:0
sde - SCSI 0:0:4:0
sdf - SCSI 0:0:5:0
sdg - SCSI 0:0:6:0
sdh - SCSI 0:0:8:0
sdi - SCSI 0:0:9:0
sdj - SCSI 0:0:10:0
sdk - SCSI 0:0:11:0
sdl - SCSI 0:0:12:0
sdm - SCSI 0:0:13:0
	sdn - SCSI 0:0:14:0	on DSP60
	sdo - SCSI 0:0:15:0	on DSP60
	sdp - SCSI 3:0:0:0	on DSP60
	sdq - SCSI 3:0:1:0	on DSP60
sdr - SCSI 3:0:2:0

Disk name /dev/sdn is not utilized. The disk size is 256G
Disk name /dev/sdo is not utilized. The disk size is 128G
Disk name /dev/sdp is not utilized. The disk size is 256G
Disk name /dev/sdq is not utilized. The disk size is 128G



Server Type: Development                                                 *
*       Hostname: npsv24                                                      *
*         CFN IP: 165.88.67.200                                               *
*         IFN IP: 10.151.0.200                                                *
*        SAP SID: PXD 

Disk name /dev/sdg is not utilized. The disk size is 150G
 Disk name /dev/sdh is not utilized. The disk size is 40G
 Disk name /dev/sdj is not utilized. The disk size is 150G
 Disk name /dev/sdk is not utilized. The disk size is 40G
 Disk name /dev/sdl is not utilized. The disk size is 13G
 Disk name /dev/sdm is not utilized. The disk size is 150G
 Disk name /dev/sdn is not utilized. The disk size is 40G
 Disk name /dev/sdo is not utilized. The disk size is 13G
 Disk name /dev/sdp is not utilized. The disk size is 150G
 Disk name /dev/sdq is not utilized. The disk size is 40G
 Disk name /dev/sdr is not utilized. The disk size is 13G
 
 [root@npsv24 ~]# ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[/]' '{print $4,"- SCSI",$7}'
sda - SCSI 0:0:0:0
sdb - SCSI 0:0:1:0
sdc - SCSI 0:0:2:0
sdd - SCSI 0:0:3:0
sde - SCSI 0:0:4:0
sdf - SCSI 0:0:5:0
sdg - SCSI 0:0:6:0
	sdh - SCSI 0:0:8:0	65
sdi - SCSI 0:0:9:0
	sdj - SCSI 0:0:10:0	65
	sdk - SCSI 0:0:11:0	65
	sdl - SCSI 0:0:12:0	65
	sdm - SCSI 0:0:13:0	65
	sdn - SCSI 0:0:14:0	65
	sdo - SCSI 0:0:15:0	65
	sdp - SCSI 3:0:0:0	65
	sdq - SCSI 3:0:1:0	65
	sdr - SCSI 3:0:2:0	65
sds - SCSI 3:0:3:0


Server Type: Development                                                 *
*       Hostname: npsv059                                                     *
*         CFN IP: 165.88.67.73                                                *
*         IFN IP: 10.151.0.73                                                 *
*        SAP SID: DV2, JV6

 Disk name /dev/sdq is not utilized. The disk size is 135G
 Disk name /dev/sdr is not utilized. The disk size is 135G
 Disk name /dev/sds is not utilized. The disk size is 134G
 Disk name /dev/sdt is not utilized. The disk size is 134G
 Disk name /dev/sdx is not utilized. The disk size is 135G
 Disk name /dev/sdy is not utilized. The disk size is 135G
 Disk name /dev/sdz is not utilized. The disk size is 135G
 Disk name /dev/sdaa is not utilized. The disk size is 135G
 Disk name /dev/sdac is not utilized. The disk size is 135G
 Disk name /dev/sdar is not utilized. The disk size is 32G
 
 
 sdq - SCSI 3:0:1:0
sdr - SCSI 3:0:2:0
sds - SCSI 3:0:3:0
sdt - SCSI 3:0:4:0
sdu - SCSI 3:0:5:0
sdv - SCSI 3:0:6:0
sdw - SCSI 3:0:8:0
sdx - SCSI 3:0:9:0
sdy - SCSI 3:0:10:0
sdz - SCSI 3:0:11:0
sdaa - SCSI 3:0:12:0
sdac - SCSI 3:0:14:0
sdar - SCSI 4:0:14:0


CS11344427
The datastore on which the NFS server VM resides was out of space, had to clear space by removing the snapshot and moving the Vms to diff datastore.Once cleaned up the server was manually started.

lssci

CHG0246220	23-06-2022 09:30:00	23-06-2022 11:30:00	SAO01-SL
This 06-22-2022 23:00:00 - NIX  remediation is for the following CIs:
consps4happ	                10.16.1.101			Production
[root@consps4happ ~]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux consps4happ 2.6.32-754.43.1.el6.x86_64 #1 SMP Wed Nov 17 07:27:32 EST 2021 x86_64 x86_64 x86_64 GNU/Linux
Thu Jun 23 01:24:25 -03 2022
consps4hapd:/usr/sap/trans      /usr/sap/trans  nfs     defaults        1       1
//172.16.0.24/tesouraria_prd   /usr/sap/skyline/prd/tesouraria  cifs credentials=/root/cifs_credential,dir_mode=0755,file_mode=0755,uid=20000,gid=3050 0 0
#//10.143.16.180/sap/ /usr/sap/waccess/bpmon_monitoring cifs credentials=/root/cifs_credential_sap,dir_mode=0755,file_mode=0755,uid=20200,gid=3050 0 0
//10.150.122.169/tesouraria /usr/sap/skyline/s4p/tesouraria cifs credentials=/root/tesouraria_cred,dir_mode=0755,file_mode=0755,uid=20000,gid=3050 0 0
//10.143.16.58/Infraero /usr/sap/infraero/s4p/carga cifs _netdev,credentials=/root/cifs_credential_Infraero,dir_mode=0755,file_mode=0755,uid=20000,gid=3050 0 0
OK: No read-only file systems found
                     nfs     54G   43G  8.0G  85% /usr/sap/trans
                     nfs    6.0T  3.7T  2.0T  65% /sds
-bash: timedatectl: command not found

[root@consps4happ ~]$  cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux consps4happ 2.6.32-754.47.1.el6.x86_64 #1 SMP Thu Mar 31 02:32:43 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
Thu Jun 23 02:00:16 -03 2022
consps4hapd:/usr/sap/trans      /usr/sap/trans  nfs     defaults        1       1
//172.16.0.24/tesouraria_prd   /usr/sap/skyline/prd/tesouraria  cifs credentials=/root/cifs_credential,dir_mode=0755,file_mode=0755,uid=20000,gid=3050 0 0
#//10.143.16.180/sap/ /usr/sap/waccess/bpmon_monitoring cifs credentials=/root/cifs_credential_sap,dir_mode=0755,file_mode=0755,uid=20200,gid=3050 0 0
//10.150.122.169/tesouraria /usr/sap/skyline/s4p/tesouraria cifs credentials=/root/tesouraria_cred,dir_mode=0755,file_mode=0755,uid=20000,gid=3050 0 0
//10.143.16.58/Infraero /usr/sap/infraero/s4p/carga cifs _netdev,credentials=/root/cifs_credential_Infraero,dir_mode=0755,file_mode=0755,uid=20000,gid=3050 0 0
OK: No read-only file systems found
                     nfs     54G   43G  8.0G  85% /usr/sap/trans
-bash: timedatectl: command not found


 
conspdfdbapp	                10.16.1.104			Production  
[root@conspdfdbapp ~]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux conspdfdbapp 2.6.32-754.43.1.el6.x86_64 #1 SMP Wed Nov 17 07:27:32 EST 2021 x86_64 x86_64 x86_64 GNU/Linux
Thu Jun 23 01:24:28 -03 2022
10.80.1.19:/usr/sap/trans /usr/sap/trans        nfs     rw,hard,intr,rsize=32768,wsize=32768    0       0
OK: No read-only file systems found
                     nfs     40G   31G  7.0G  82% /usr/sap/trans
                     nfs    6.0T  3.7T  2.0T  65% /sds
-bash: timedatectl: command not found

[root@conspdfdbapp ~]$  cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exportsRed Hat Enterprise Linux Server release 6.10 (Santiago)
Linux conspdfdbapp 2.6.32-754.47.1.el6.x86_64 #1 SMP Thu Mar 31 02:32:43 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
Thu Jun 23 02:00:23 -03 2022
10.80.1.19:/usr/sap/trans /usr/sap/trans        nfs     rw,hard,intr,rsize=32768,wsize=32768    0       0
OK: No read-only file systems found
                     nfs     40G   31G  7.0G  82% /usr/sap/trans
-bash: timedatectl: command not found



consps4hdbp2	                10.16.1.116			Production  
consps4hdbp2:~ # zypper locks;cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports; df -hT |grep -i nfs;df -hT |grep -i cifs

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | mpt-firmware     | package | (any)

NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux consps4hdbp2 4.12.14-95.93-default #1 SMP Fri Mar 4 16:48:12 UTC 2022 (8f58f5b) x86_64 x86_64 x86_64 GNU/Linux
Thu Jun 23 01:24:49 -03 2022
      Local time: Thu 2022-06-23 01:24:49 -03
  Universal time: Thu 2022-06-23 04:24:49 UTC
        RTC time: Thu 2022-06-23 04:24:49
       Time zone: Etc/GMT+3 (-03, -0300)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.
sao01ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.7T  2.0T  65% /sds

consps4hdbp2:~ # zypper locks;cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports; df -hT |grep -i nfs;df -hT |grep -i cifs

# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | mpt-firmware     | package | (any)

NAME="SLES"
VERSION="12-SP4"
VERSION_ID="12.4"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP4"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles_sap:12:sp4"
Linux consps4hdbp2 4.12.14-95.96-default #1 SMP Tue Apr 5 22:02:28 UTC 2022 (07365c8) x86_64 x86_64 x86_64 GNU/Linux
Thu Jun 23 02:31:24 -03 2022
      Local time: Thu 2022-06-23 02:31:24 -03
  Universal time: Thu 2022-06-23 05:31:24 UTC
        RTC time: Thu 2022-06-23 05:31:24
       Time zone: Etc/GMT+3 (-03, -0300)
 Network time on: no
NTP synchronized: yes
 RTC in local TZ: no
OK: No read-only file systems found
# See the exports(5) manpage for a description of the syntax of this file.
# This file contains a list of all directories that are to be exported to
# other computers via NFS (Network File System).
# This file used by rpc.nfsd and rpc.mountd. See their manpages for details
# on how make changes in this file effective.
sao01ammyum01.imzcloud.ibmammsap.local:/sds nfs4      6.0T  3.7T  2.0T  65% /sds




[root@consps4happ ~]$ df -hT |grep -i cifs
                     cifs   100G   29G   72G  29% /usr/sap/skyline/prd/tesouraria
                     cifs    60G   20G   41G  34% /usr/sap/infraero/s4p/carga



CHG0246943 0
Upgrade RHEL 6.10 to 8.2 on below application servers:
SD5 IA2S4HDEVAPP  10.133.16.42


knife node policy set IA1S4HDEVAPP.imzcloud.ibmammsap.local production cms3x_chef_client -c /etc/chef/client.rb

knife node show IA1S4HDEVAPP.imzcloud.ibmammsap.local -c /etc/chef/client.rb


from Deepankar B V (Kyndryl) to Everyone20:39
IA2FIODEVDBAP 10.133.16.43 D1 IA1FIODEVAPP 10.133.16.21 FD1 IA1FIODEVDB 10.133.16.20 IA1S4HDEVAPP 10.133.16.19 SD5 IA2S4HDEVAPP 10.133.16.42
from Deepankar B V (Kyndryl) to Everyone20:39
IA2FIODEVDBAP 10.133.16.43 D1 IA1FIODEVAPP 10.133.16.21 FD1 IA1FIODEVDB 10.133.16.20 IA1S4HDEVAPP 10.133.16.19 SD5 IA2S4HDEVAPP 10.133.16.42


from Deepankar B V (Kyndryl) to everyone:    8:39 PM
        IA2FIODEVDBAP   10.133.16.43	DOne
D1    IA1FIODEVAPP    10.133.16.21	DOne
FD1    IA1FIODEVDB    10.133.16.20	DOne
        IA1S4HDEVAPP    10.133.16.19	Done
SD5     IA2S4HDEVAPP    10.133.16.42	Done



This is cluster system
zffpapp001	100.126.67.140
zffpapp001-ha	100.126.67.141


zffpdb001	100.126.67.145
zffpdb001-ha	100.126.67.146


Support Cases keyboard_arrow_right 00352819
https://scc.suse.com/support/cases/00352819


hb_report -u root -f "2022/06/28 07:00" -t "2022/06/28 11:400" /tmp/hb_report_log

reboot system boot 4.12.14-95.80-de Tue Jun 28 08:07 - 11:13 (03:06)

reboot system boot 4.12.14-95.80-de Tue Jun 28 10:03 - 11:13 (01:09)

[ibmrmalik@zffpdb001 ~]$ date
Tue Jun 28 11:14:22 CEST 2022

CS11386357 Allianz Life Insurance Comp of NA -- AZ1P2 - Majorazl#azlefpdbapp01#Disk Utilization /userdata CRITICAL: Free 3569.04MB/6.19% (thresh @5.01:10%)
CS11386202 Allianz Life Insurance Comp of NA -- AZ1P2 - Majorazl#azlefpdbapp01#Disk Utilization /userdata CRITICAL: Free 4380.57MB/7.60% (thresh @5.01:10%) (edited) 
CS11385993 Allianz Life Insurance Comp of NA -- AZ1P3 - Minorazl#azlefpdbapp01#Disk Utilization /userdata MINOR: Free 5990.69MB/10.39% (thresh @10.01:15%)
CS11385893 Allianz Life Insurance Comp of NA -- AZ1P3 - Minorazl#azlefpdbapp01#Disk Utilization /userdata MINOR: Free 6951.69MB/12.06% (thresh @10.01:15%)
 
CS11386502 Allianz Life Insurance Comp of NA -- AZ1P2 - Majorazl#azlefpdbapp01#Disk Utilization /userdata CRITICAL: Free 3569.04MB/6.19% (thresh @5.01:10%)

CS11386904 Perkinelmer, Inc. -- PRKP1 - Severeprk#prdh04#Mountpoint Interface CRITICAL: /sapio/PR1 did not respond in 3 sec. Seems to be stale. :
CS11386897 Perkinelmer, Inc. -- PRKP1 - Severeprk#prap01#Mountpoint Interface CRITICAL: /sapmnt/PR1 did not respond in 3 sec. Seems to be stale. : /sapstage did not respond in 3 sec. Seems to be stale. : /o



Those servers are not showing up in Ansible ILMT  - no Software scans

https://github.kyndryl.net/CMS/Platform-Support/wiki/ILMT-&-CIT-scan-verification-in-VM
oltpl1apdb	all gud as per github doc
oltpl3ap
oltpl3ap-ha
oltpl3db	cron missing	cron not running
(2022-05-11 10:26:01) (2022-05-11 10:26:01) Starting Hardware Scan script (linux 9.2.25.0)
(2022-06-28 10:41:29) (2022-06-28 10:41:29) Starting Hardware Scan script (linux 9.2.25.0)


oltpl3db-ha	cron missing	cron not running
(2022-05-11 12:12:02) (2022-05-11 12:12:02) Starting Hardware Scan script (linux 9.2.25.0)
(2022-06-28 10:41:38) (2022-06-28 10:41:38) Starting Hardware Scan script (linux 9.2.25.0)


[root@oltpl1apdb ~]# crontab -l
26,56 * * * * "/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh" > /var/opt/ansible/GTS/ILMT/logs/crontab.log 2>&1
0 2 * * 6 /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT



 1005  2022-06-29 14:08:01 cd /var/opt/ansible/GTS
 1006  2022-06-29 14:08:05 ls -ltr
 1007  2022-06-29 14:08:31 cd CIT/
 1008  2022-06-29 14:08:33 ls -ltr
 1009  2022-06-29 14:08:38 cd ..
 1010  2022-06-29 14:08:43 cd ILMT/
 1011  2022-06-29 14:08:45 ls -ltr
 1012  2022-06-29 14:09:12 cd work/
 1013  2022-06-29 14:09:22 ls -ltr
 1014  2022-06-29 14:09:29 cat computer.yml
 1015  2022-06-29 14:10:44 cd ..
 1016  2022-06-29 14:10:47 cd CIT/
 1017  2022-06-29 14:10:50 cd work/
 1018  2022-06-29 14:11:17 cat citcomputer.yml
 1019  2022-06-29 14:11:38 crontab -l |grep ILMT
 1020  2022-06-29 14:12:44 cd /var/opt/ansible/GTS/ILMT/
 1021  2022-06-29 14:12:57 ls -ltr
 1022  2022-06-29 14:13:08 cd logs/
 1023  2022-06-29 14:13:09 ls -ltr
 1024  2022-06-29 14:13:18 cat log.txt
 1025  2022-06-29 14:14:05 cat log.txt |grep -i  "Starting Hardware Scan script"
 1026  2022-06-29 14:14:15 date
 1027  2022-06-29 14:14:37 cat log.txt |grep -i  "Hardware Scan was successful"
 1028  2022-06-29 14:15:03 cat log.txt |grep -i  "Hardware Scan script finished"
 1029  2022-06-29 14:16:24 cd  /var/opt/ansible/GTS/CIT/logs
 1030  2022-06-29 14:16:41 ls -ltr
 1031  2022-06-29 14:17:19 cat scan_aic.log |grep -i "ILMT & CIT scanning finished"
 1032  2022-06-29 14:17:25 date


image@2019@CMAS

As per the PDL suggestions - OS Team restarted the NMB and SMB services on ADZPC0DB-HA.
Post restart of the services on the server, PDL informed that the output of systemctl status nmb.service looks better now.


We are still needing this problem resolved.
Would it be possible to check the settings and configuration for the qc0 share - \\10.177.19.6\interfaces - and compare it to the pc0 share - \\10.177.18.11\interfaces ? Since the qc0 one works just fine but pc0 does not.
Is there any way we could some how use the qc0 share in the interim? Like use a script to copy files for pc0 to qc0 folders so we could retrieve them? Or please any other ideas for resolution. We are pretty desperate to have this working.

ADZQC0DBCI  has \\10.177.19.6\interfaces

RCA0006645 ref for 5 why for the samba RCA


ticket for 2FA reset for your Azure account: INC6690663

CS11420153 - br3#br3qsapdb33#Resource Pacemaker TSM CRITICAL: Resource rsc_TSM is in status Stopped

SUSE CASE CREATED
00353644 - Resource rsc_TSMTDP_Q4H_HDB30 is in status Stopped, cluster cannot start it
https://scc.suse.com/support/cases/00353644

#scx-sapb1-br3


CHG0246886-07/07/2022 - 20:00 - NIX - WA2 - PATCH -08-07-2022 06:30:00 - 08-07-2022 13:30:00
This 07/07/2022 - 20:00 - NIX  remediation is for the following CIs:
wa2epqadb1	                10.191.1.74			Development 	suse not registered 	verified
wa2crqdb01	                10.191.1.76			Development 	not found		verified 
wa2prxyqas1	                10.191.1.61			Development  
wa2epqap01	                10.191.1.36			Development  				verified
wa2crqap01                       10.191.1.71                       Non-Prod				verified

Additional Special Instructions from Requestor: Please install KDUMP with KB0015500

 hostsfile_entry[10.249.69.38] (cms3x_cfg::etc line 27) had an error: ArgumentError: /etc/hosts has a line without hostname: 
 
 
 
 
 
 
 RCA ref server
 
 ES9 System
zffpdb008	100.126.67.24
zffpdb008-ha	100.126.67.76
zffpapp008	100.126.67.39
zffpapp008-ha	100.126.67.28



CS11440746	AGEAS -- AGE	P2 - Major	age#svnd1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVND1SRV0- KB0010973
CS11440745	AGEAS -- AGE	P2 - Major	age#svts1srv1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVTS1SRV1- KB0010973
CS11440743	AGEAS -- AGE	P2 - Major	age#svns1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVNS1SRV0- KB0010973
CS11440744	AGEAS -- AGE	P2 - Major	age#svvs1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVVS1SRV0- KB0010973
CS11440741	AGEAS -- AGE	P2 - Major	age#svmd1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVMD1SRV0- KB0010973
CS11440742	AGEAS -- AGE	P2 - Major	age#svmq1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVMQ1SRV0- KB0010973

CS11440738	AGEAS -- AGE	P2 - Major	age#sveq1srv0#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVEQ1SRV0- KB0010973
CS11440739	AGEAS -- AGE	P2 - Major	age#svcs1hdbsrv01#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVCS1HDBSRV01- KB0010973
CS11440735	AGEAS -- AGE	P2 - Major	age#agesvepmhsrv2#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESVEPMHSRV2- KB0010973
CS11440734	AGEAS -- AGE	P2 - Major	age#agesvbq1hsrv1#Cleared and Re-fired: Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESVBQ1HSRV1- KB0010973



chg0246348

SMP A1ASMPDB01	10.4.10.73 SAP - SAP/DB stopped
SMJ A1ASMPJAVA	10.4.10.75 SAP - SAP/DB stopped
GRP a1agrpapp01 10.15.130.28 SAP - SAP/DB stopped
GRP a1agrphdb01 10.15.130.19 HANA - SAP/DB stopped


PYP AHECPSAP01	10.4.9.11 SAP	- SAP/DB stopped
PYP ahecpsap02	10.4.9.16 SAP	- SAP/DB stopped


PYP ahecpsap03	10.4.9.17 SAP	- SAP/DB stopped	DOne
PYP a1ahecpsap04 10.4.10.109 SAP  - SAP/DB stopped	Done
PYP ahecphdb01	 10.4.9.10 HANA primary  - SAP/DB stopped	Done
PYP ahecphdb01dr 10.12.1.10 HANA Secondary - SAP/DB stopped



CHG0246315


plz check these, once you got time
CS11447761GKN Driveline Newton LLC -- GKNP1 - Severegkn#gkneccdevqa#Unable to ping GKNECCDEVQA (10.15.81.24) from FRDAL13WEBD01.
CS11447763GKN Driveline Newton LLC -- GKNP1 - Severegkn#gknfioridev#Unable to ping GKNFIORIDEV (10.15.81.22) from FRDAL13WEBD01.
CS11447759GKN Driveline Newton LLC -- GKNP1 - Severegkn#gknsoldev#Unable to ping GKNSOLDEV (10.15.81.20) from FRDAL13WEBD01.
CS11447756GKN Driveline Newton LLC -- GKNP1 - Severegkn#gknadsdev#Unable to ping GKNADSDEV (10.15.81.21) from FRDAL13WEBD01.
:white_check_mark:
1


[root@ahecphdb01dr ~]# subscription-manager release --show
Consumer profile "95b5debe-e318-4e70-a972-80b4dd06ced7" has been deleted from the server. You can use command clean or unregister to remove local profile.


CS11469207	AGEAS -- AGE	P2 - Major	age#svvs1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVVS1SRV0- KB0010973
CS11469206	AGEAS -- AGE	P2 - Major	age#svwd1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVWD1SRV0- KB0010973
CS11469205	AGEAS -- AGE	P2 - Major	age#svws1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVWS1SRV0- KB0010973
CS11469204	AGEAS -- AGE	P2 - Major	age#svts1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVTS1SRV0- KB0010973
CS11469203	AGEAS -- AGE	P2 - Major	age#svns1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVNS1SRV0- KB0010973
CS11469202	AGEAS -- AGE	P2 - Major	age#svmd1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVMD1SRV0- KB0010973
CS11469201	AGEAS -- AGE	P2 - Major	age#svnd1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVND1SRV0- KB0010973
CS11469200	AGEAS -- AGE	P2 - Major	age#svls1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVLS1SRV0- KB0010973
CS11469198	AGEAS -- AGE	P2 - Major	age#svjq1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVJQ1SRV0- KB0010973
CS11469197	AGEAS -- AGE	P2 - Major	age#svjs1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVJS1SRV0- KB0010973
CS11469199	AGEAS -- AGE	P2 - Major	age#svlq1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVLQ1SRV0- KB0010973
CS11469196	AGEAS -- AGE	P2 - Major	age#svld1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVLD1SRV0- KB0010973
CS11469194	AGEAS -- AGE	P2 - Major	age#svcs1hdbsrv01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVCS1HDBSRV01- KB0010973
CS11469195	AGEAS -- AGE	P2 - Major	age#svfd1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVFD1SRV0- KB0010973
CS11469193	AGEAS -- AGE	P2 - Major	age#svcs1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVCS1SRV0- KB0010973
CS11469192	AGEAS -- AGE	P2 - Major	age#svcd1srv0#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVCD1SRV0- KB0010973
CS11469190	AGEAS -- AGE	P2 - Major	age#spsvppalase01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SPSVPPALASE01- KB0010973
CS11469189	AGEAS -- AGE	P2 - Major	age#spsvspdsase01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SPSVSPDSASE01- KB0010973
CS11469188	AGEAS -- AGE	P2 - Major	age#spsvwpawapp11#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SPSVWPAWAPP11- KB0010973
CS11469187	AGEAS -- AGE	P2 - Major	age#svcc2srv1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SVCC2SRV1- KB0010973
CS11469186	AGEAS -- AGE	P2 - Major	age#spsvepajapp01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SPSVEPAJAPP01- KB0010973
CS11469172	AGEAS -- AGE	P2 - Major	age#cccp2srv0-dr#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CCCP2SRV0-DR- KB0010973
CS11469170	AGEAS -- AGE	P2 - Major	age#agesvtq2srv1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESVTQ2SRV1- KB0010973
CS11469171	AGEAS -- AGE	P2 - Major	age#agesng01web01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESNG01WEB01- KB0010973
CS11469169	AGEAS -- AGE	P2 - Major	age#agesveqmhsrv1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESVEQMHSRV1- KB0010973
CS11469167	AGEAS -- AGE	P2 - Major	age#agesvcqmhsrv1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESVCQMHSRV1- KB0010973
CS11469168	AGEAS -- AGE	P2 - Major	age#agespsvspsrv2#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESPSVSPSRV2- KB0010973
CS11469166	AGEAS -- AGE	P2 - Major	age#agesvcpmhsrv1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on AGESVCPMHSRV1- KB0010973



ibm-ras-india.gpcloudservice.com


[root@tdpppopdbapp ~]# who -b
         system boot  Jul  6 17:04
         
         Jul  6 17:05:00 tdpppopdbapp kernel: [    0.584376] pci 0000:00:15.3: BAR 13: failed to assign [io  size 0x1000]
Jul  6 17:05:00 tdpppopdbapp kernel: [    0.584378] pci 0000:00:15.4: BAR 13: failed to assign [io  size 0x1000]
Jul  6 17:05:00 tdpppopdbapp kernel: [    0.584379] pci 0000:00:15.5: BAR 13: failed to assign [io  size 0x1000]
Jul  6 17:05:00 tdpppopdbapp kernel: [    0.584380] pci 0000:00:15.6: BAR 13: failed to assign [io  size 0x1000]
Jul  6 17:05:00 tdpppopdbapp kernel: [    0.584382] pci 0000:00:15.7: BAR 13: failed to assign [io  size 0x1000]
Jul  6 17:05:00 tdpppopdbapp kernel: [    0.584383] pci 0000:00:16.3: BAR 13: failed to assign [io  size 0x1000]
Jul  6 17:05:00 tdpppopdbapp kernel: [    0.584385] pci 0000:00:16.4: BAR 13: failed to assign [io  size 0x1000]

Jul  6 17:05:03 tdpppopdbapp rpc.gssd[1902]: ERROR: failed to read service info
Jul  6 17:05:03 tdpppopdbapp smbd[2316]:   kerberos_kinit_password TDPPPOPDBAPP$@IMZCLOUD.IBMAMMSAP.LOCAL failed: Preauthentication failed
Jul  6 17:05:05 tdpppopdbapp kernel: [  103.224748] tmhook: module verification failed: signature and/or required key missing - tainting kernel
Jul  6 17:05:05 tdpppopdbapp geoclue[4289]: (geoclue:4289): Geoclue-WARNING **: Failed to connect to avahi service: Daemon not running
Jul  6 17:05:20 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command 'zypper' failed with return code: 7
Jul  6 17:05:26 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:26 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:26 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:26 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:26 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command 'zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command '/usr/bin/zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command 'zypper' failed with return code: 7
Jul  6 17:05:27 tdpppopdbapp salt-minion[2323]: [ERROR   ] Command 'zypper' failed with return code: 4


Memory
16:10:01       594384   5534836  14077872     42.78    360284  15989836  48063288     57.74  26689116   2900228       376
16:20:01       559112   5500164  14112504     42.88    360448  15990200  48106028     57.79  26722492   2900532       372
16:30:01       561224   5502936  14109652     42.88    360608  15990816  48091468     57.78  26720752   2901024       372
16:40:02       583600   5525840  14086144     42.80    360756  15991504  48068764     57.75  26697036   2901656       432
16:50:01       594044   5534068  14078064     42.78    360876  15989176  48063420     57.74  26690012   2899248       416
17:00:02       566948   5507460  14104752     42.86    361044  15989516  48228564     57.94  26714624   2899488       360
Average:       501879   5500583  14082492     42.79    349310  16077823  48150179     57.85  26676331   2989802       408

17:05:02     LINUX RESTART      (4 CPU)

17:10:01    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
17:20:01     29549676  30819660   1569884      4.77     56096   1558856   3259788      3.92   2089484    836644       124
17:30:01     29529700  30805840   1583456      4.81     61120   1559692   3252576      3.91   2106896    835976       152
17:40:01     29324716  30759140   1628172      4.95     66344   1710088   3199288      3.84   2260996    881900       180
17:50:01     29343188  30782644   1604872      4.88     70644   1710700   3244204      3.90   2247388    877432       104
18:00:01     29343632  30798664   1588248      4.83     75012   1721560   3247920      3.90   2236896    885668       104
18:10:01     29343872  30803460   1583384      4.81     78720   1722320   3234236      3.89   2236788    885700       124
18:20:01     29344028  30808340   1578188      4.80     82576   1723008   3193536      3.84   2247216    874224       152
18:30:01     29344832  30813796   1573096      4.78     86412   1723716   3141296      3.77   2245148    874844       116


14:40:01        CPU     %user     %nice   %system   %iowait    %steal     %idle
14:50:01        all     16.67      0.00     83.33      0.00      0.00      0.00
15:00:01        all     16.92      0.00     83.08      0.00      0.00      0.00
15:10:01        all     18.12      0.00     81.88      0.00      0.00      0.00
15:20:01        all     17.64      0.00     82.36      0.00      0.00      0.00
15:30:02        all     17.44      0.00     82.56      0.00      0.00      0.00
15:40:01        all     17.02      0.00     82.98      0.00      0.00      0.00
15:50:01        all     16.66      0.00     83.34      0.00      0.00      0.00
16:00:02        all     16.83      0.00     83.17      0.00      0.00      0.00
16:10:01        all     16.97      0.00     83.03      0.00      0.00      0.00
16:20:01        all     16.59      0.00     83.40      0.00      0.00      0.00
16:30:01        all     16.98      0.00     83.02      0.00      0.00      0.00
16:40:02        all     17.14      0.00     82.86      0.00      0.00      0.00
16:50:01        all     16.79      0.00     83.21      0.00      0.00      0.00
17:00:02        all     16.90      0.00     83.10      0.00      0.00      0.00
Average:        all     16.91      0.00     83.09      0.00      0.00      0.00

17:05:02     LINUX RESTART      (4 CPU)

17:10:01        CPU     %user     %nice   %system   %iowait    %steal     %idle
17:20:01        all      1.25      0.00      0.88      0.07      0.00     97.81
17:30:01        all      1.15      0.00      0.87      0.06      0.00     97.93
17:40:01        all      1.62      0.00      0.93      0.09      0.00     97.37
17:50:01        all      1.09      0.00      0.88      0.06      0.00     97.97
18:00:01        all      1.06      0.00      0.91      0.06      0.00     97.98
18:10:01        all      1.15      0.00      0.90      0.06      0.00     97.88
18:20:01        all      1.00      0.00      0.84      0.06      0.00     98.09
18:30:01        all      1.03      0.00      0.87      0.06      0.00     98.04
18:40:01        all      1.20      0.00      0.92      0.07      0.00     97.82
18:50:01        all      1.01      0.00      0.85      0.06      0.00     98.08
19:00:01        all      1.04      0.00      0.89      0.06      0.00     98.01
19:10:01        all      3.48      0.05      1.83      0.29      0.00     94.36



158.87.44.0/23 via 10.6.1.1 dev eth0
158.87.46.0/23 via 10.6.1.1 dev eth0


[root@penad15sl ~]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux penad15sl 2.6.32-754.47.1.el6.x86_64 #1 SMP Thu Mar 31 02:32:43 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
Thu Jul 14 18:41:48 PDT 2022
#DAL09AMMYUM01:/kdump/crash/pena_kdumps /kdump/crash/pena_kdumps/ nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found
                     nfs    6.0T  3.7T  2.0T  66% /sds
-bash: timedatectl: command not found
/usr/sap/trans *(rw,sync)
You have new mail in /var/spool/mail/root
[root@penad15sl ~]$ grep -i zone /etc/sysconfig/clock
# The time zone of the system is defined by the contents of /etc/localtime.
ZONE="America/Pacific"

[root@penad15sl ~]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux penad15sl 2.6.32-754.47.1.el6.x86_64 #1 SMP Thu Mar 31 02:32:43 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
Thu Jul 14 18:59:07 PDT 2022
#DAL09AMMYUM01:/kdump/crash/pena_kdumps /kdump/crash/pena_kdumps/ nfs rsize=8192,wsize=8192,timeo=14,intr
OK: No read-only file systems found
-bash: timedatectl: command not found
/usr/sap/trans *(rw,sync)
[root@penad15sl ~]$ grep -i zone /etc/sysconfig/clock
# The time zone of the system is defined by the contents of /etc/localtime.
ZONE="America/Pacific"



CS11491894 NewAdler Pelzer Holding GmbHADZPX0DBadz#adzpx0db#Host Reboot CRITICAL: Uptime 1 minutes (thresh 30 min)
CS11491854 NewAdler Pelzer Holding GmbHADZPC0CIadz#adzpc0ci#Host Reboot CRITICAL: Uptime 1 minutes (thresh 30 min)
CS11491814 NewEasa Husain Al-Yousifi & Sons Co. -- YSFYSF-EHQ-DBAPPysf#ysf-ehq-dbapp#Host Reboot CRITICAL: Uptime 4 minutes (thresh 30 min)
CS11491792 NewTecnicas Reunidas S.A. -- TRETREBOBIPRDAP1tre#trebobiprdap1#Host Reboot CRITICAL: Uptime 1 minutes (thresh 30 min)
CS11491806 NewUniversita Commerciale Luigi Boccon -- Z4FZ4FCRMDEVz4f#z4fcrmdev#Host Reboot CRITICAL: Uptime 2 minutes (thresh 30 min)
CS11491806 NewUniversita Commerciale Luigi Boccon -- Z4FZ4FCRMDEVz4f#z4fcrmdev#Host Reboot CRITICAL: Uptime 2 minutes (thresh 30 min)
CS11491797 NewArnoldo Mondadori Editore SpA -- ARMARMFKSAP301AParm#armfksap301ap#Host Reboot CRITICAL: Uptime 1 minutes (thresh 30 min)
CS11491871 NewArnoldo Mondadori Editore SpA -- ARMARMFKSAP305A1arm#armfksap305a1#Host Reboot CRITICAL: Uptime 3 minutes (thresh 30 min)
CS11491829 NewIAG - British Airways -- IA2IA2ICCPRDDR2ia2#ia2iccprddr2#Uptime System-Rebooted CRITICAL: uptime: 0:5m. boot: 2022-07-15 07:25:28 (UTC) Attention commas replaced by dots.
CS11491880 NewSmiths Group plc -- SM9SM9D185173005sm9#sm9d185173005#Host Reboot CRITICAL: Uptime 0 minutes (thresh 30 min)



params ipaddr=146.89.140.222 login="vsphere.local\crmstnmgr" ipport=443 ssl=1 ssl_insecure=1 plug=armfksap305a1 shell_timeout=600 filter="filter.names=armfksap305a1" passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60 \


 ipaddr=146.89.140.222 login="vsphere.local\crmstnmgr" ipport=443 ssl=1 ssl_insecure=1 plug=armfksap301a1 filter="filter.names=armfksap301a1" passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60 shell_timeout=600 \
 
 
 [root@armfksap301ap ~]$ getpass.py -g crmstnmgr
MDkyNGMxYzY1ZjEw@


[root@armfksap305ap ~]$ getpass.py -g crmstnmgr
MDkyNGMxYzY1ZjEw@


fence_vmware_rest -a 146.89.140.222 -l "vsphere.local\crmstnmgr" -p MDkyNGMxYzY1ZjEw@ -z -o list --ssl-insecure --filter="filter.names=armfksap305a1"


CS11498766	Tech Data Corporation -- ZEC	P2 - Major	zec#gbwpas9#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.
CS11498765	Tech Data Corporation -- ZEC	P2 - Major	zec#uspokdchd01#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.
CS11498764	Tech Data Corporation -- ZEC	P2 - Major	zec#uspokpmha02#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.
CS11498763	Tech Data Corporation -- ZEC	P2 - Major	zec#gbwqas0#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.
CS11498762	Tech Data Corporation -- ZEC	P2 - Major	zec#uspokqcha01#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.
CS11498761	Tech Data Corporation -- ZEC	P2 - Major	zec#uspokdmhd01#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.

CS11499162   major sev1 created

GBWNDB1
	GBWPAS0
	GBWPAS2
	GBWPAS3
	GBWPAS4
	GBWPAS5
	GBWPAS8
	GBWPAS9
	GBWQAS0
	GBWQAS2
	GBWQAS3
	GBWQAS4
	GBWQAS5
	
	GBWQDB1
	GBWQHDB03
	USPOKDCHA01
	USPOKDCHD01
	USPOKDMHA01
	USPOKPCHA01
		USPOKPCHD01
	USPOKPMHDB01
	USPOKQCHA01
	USPOKQCHD01
	USPOKQMHA01
	USPOKQMHD01
	
	
	
158.87.44.128  10.6.2.255       255.255.255.0 UG   0     0       0 net0
158.87.46.128  10.6.2.255       255.255.255.0 UG   0     0       0 net0


route add -net 158.87.44.0 netmask 255.255.255.0 gw 10.6.2.1
route add -net 158.87.46.0 netmask 255.255.255.0 gw 10.6.2.1



route add 158.87.44.0 gw 10.6.2.1 dev net0
route add 158.87.46.0 gw 10.6.2.1 dev net0



[root@sveq1srv0 ~]# ip route get 158.87.44.0
158.87.44.0 via 10.6.2.1 dev eth0  src 10.6.2.11


[root@ci3tmg-prddb ~]# lscpu
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
Address sizes:       43 bits physical, 48 bits virtual
CPU(s):              112
On-line CPU(s) list: 0-111
Thread(s) per core:  1
Core(s) per socket:  56


ZFFPAR01DSE220DR

CHG0250268 and CHG0250271   CHG0250283



CHG0249287
JP0811ZBE100B
JP0811ZBE100A


VC cred  tsmcrmstnmgr - aZP8US%SprBhSl@
vsphere.local\tsmcrmstnmgr

fence_vmware_rest -a 146.89.168.20 -l "vsphere.local\tsmcrmstnmgr" -p aZP8US%SprBhSl@ -z -o list --ssl-insecure --filter="filter.names=jp0811zbe100b"

iostat -x


su - prdadm -c "hdbnsutil -sr_register --remoteHost=tsls4proddb --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=NODEB"


10.162.186.219	tta-che01-pod1-phana-h8-12000-002.imzcloud.ibmammsap.local


CS11579331 Breadtalk Group Pte Ltd -- BTKP1 - Severebtk#btkc1qcs01#Host Reboot CRITICAL: Uptime 4 minutes (thresh 30 min)
CS11579323 Breadtalk Group Pte Ltd -- BTKP1 - Severebtk#btkw1qws01#Host Reboot CRITICAL: Uptime 2 minutes (thresh 30 min)
CS11579322 Breadtalk Group Pte Ltd -- BTKP1 - Severebtk#btkh1qdb01#Host Reboot CRITICAL: Uptime 0 minutes (thresh 30 min)
CS11579317 Breadtalk Group Pte Ltd -- BTKP1 - Severebtk#btkw1qws02#Host Reboot CRITICAL: Uptime 4 minutes (thresh 30 min)



/nfsshare_Q



CS11577420 P2: ia1#ia1s4hdevapp#Disk Utilization /nfsshare_Q FATAL

CS11579483 The Ogilvy Group Inc -- OGYP1 - Severeogy#ogysm2028#Unable to ping OGYSM2028 (10.139.8.13) from FRDAL13WEBD01.

CS11579450	Liberty Utilities (Canada) Corp -- LBU	P1 - Severe	lbu#lbupp1ap02#Host Reboot CRITICAL: Uptime 2 minutes (thresh 30 min)
CS11579446	Liberty Utilities (Canada) Corp -- LBU	P1 - Severe	lbu#lbupm1ap01#Host Reboot CRITICAL: Uptime 2 minutes (thresh 30 min)


SAP B2:
ogysm2028	Production	The Ogilvy Group Inc -- OGY		OK
lbupg1ap01	Production	Liberty Utilities (Canada) Corp -- LBU	OK
krraddns1	Production	Kuraray C. Ltd -- KRR			WIndows
lbupm1ap01	Production	Liberty Utilities (Canada) Corp -- LBU	OK
ogypxn004	Production	The Ogilvy Group Inc -- OGY		OK
krraddns2	Production	Kuraray C. Ltd -- KRR			Windows
lbupp1ap02	Production	Liberty Utilities (Canada) Corp -- LBU	OK
gsapbotst	QA	Kuraray C. Ltd -- KRR				Windows
lbuqd1ap01	QA	Liberty Utilities (Canada) Corp -- LBU		WIndows
lbudo2db01	Development	Liberty Utilities (Canada) Corp -- LBU	Windows
lbuqx2ap01	QA	Liberty Utilities (Canada) Corp -- LBU		Windows
gsapbosim	QA	Kuraray C. Ltd -- KRR				Windows
lbuvg1ap02	Pre-Production	Liberty Utilities (Canada) Corp -- LBU	OK
krrlimsdev01	Development	Kuraray C. Ltd -- KRR			WIndows
da7bwpapp01	Production	Danone Public Benefit Corporation -- DA7
lbujumpsvrnp	Development	Liberty Utilities (Canada) Corp -- LBU
lbudmfap01	Development	Liberty Utilities (Canada) Corp -- LBU


lbupg1ap01	Linux Server	Production
lbupm1ap01		Production
lbupp1ap02	Linux Server	Production
lbuqd1ap01	Windows Server	QA
lbuqx2ap01	Windows Server	QA
lbuvg1ap02	Linux Server	Pre-Production



Ref sev1 CS11579411 amm#ammwdc04custesx069#State is equal to Not responding AND State is equal to Unknown


Could you kindly mount /nfsshare_Q on server ia1s4hqasdbn2(10.133.17.152).
 The source nfsshare_Q is from IA1NFSPRDAPP.
 IA1NFSPRDAPP 10.133.15.25 66.248.244.25
7:03
so need to mount nfsshare_Q which is on IA1NFSPRDAPP(66.248.244.25)
7:03
to ia1s4hqasdbn2(10.133.17.152)


ref
the same nfsshare_Q is mounted on the below

IA1PODEVAPP	10.133.16.32
7:10
if it helps you to compare


CS11579593 The Ogilvy Group Inc -- OGYP1 - Severeammwdc04custesx069 Not Responding
CS11579594 Liberty Utilities (Canada) Corp -- LBUP1 - Severeammwdc04custesx069 Not Responding
CS11579596 Kuraray C. Ltd -- KRRP1 - Severeammwdc04custesx069 Not Responding
CS11579599 Panasonic North America -- PN8P1 - Severeammwdc04custesx069 Not Responding


CS11580070Liberty Utilities (Canada) Corp -- LBUP2 - Majorlbu#lbupg1ap01ha#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on LBUPG1AP01HA- KB0010973
CS11579550Liberty Utilities (Canada) Corp -- LBUP2 - Majorlbu#lbupg1ap01#Service Pacemaker lrmd CRITICAL: 0 /usr/lib/pacemaker/lrmd processes running (thresh 1:)
CS11579548Liberty Utilities (Canada) Corp -- LBUP2 - Majorlbu#lbupg1ap01#Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)
CS11579547Liberty Utilities (Canada) Corp -- LBUP2 - Majorlbu#lbupg1ap01#Service Pacemaker crmd CRITICAL: 0 /usr/lib/pacemaker/crmd processes running (thresh 1:)
CS11579539Liberty Utilities (Canada) Corp -- LBUP2 - Majorlbu#lbuqp1ap01#CheckFS DFhanging Nagios agent not running or hung. Possibly a file system issue.


Old Printer details
Printer Name-HP LEASER JET ENTERPRISE M507
Model No- BOISB-1807-00
IP Address- 135.110.181.4
queue name NPI03578B

New Printer details
Printer Name- HPLESER JET ENTERPRISES MANAGED M605m
Model No- CNDXJ4V612
IP Address- 135.110.181.171
Hostname : NPIA4ACD8

lpadmin -p NPIA4ACD8 -v socket://135.110.181.171 -E

lpstat -t |grep NPIA4ACD8

lpadmin -x NPIA4ACD8

lpq -P NPIA4ACD8

135.110.181.171 NPIA4ACD8


SAPAPP15	Done
SAPAPP18	Done
SAPAPP19	Done
SAPAPP20	Done
SAPAPP21	DOne
SAPAPP23	DOne
SAPAPP26	DOne
SAPAPP27	Done
SAPAPP28	Done
SAPAPP29	Done
SAPAPP30	Done

SAPAPP31	Done
SAPAPP31-HA	Done
SAPAPP32	Done
SAPAPP33	Done
SAPAPP34	Done
SAPAPP35	Done
SAPAPP36	Done
SAPAPP37	Done
SAPAPP38	Done
SAPAPP39	Done
SAPAPP40	Done
SAPAPP41	Done
SAPAPP42	Done





added printer on SAPAPP15 to SAPAPP30, need to work on remaining servers..


CHG0251038 07/30/2022 - 20:00 - NIX - LBU - PATCH - Q3'2022
CHG0251030 07/30/2022 - 20:00 - NIX - LBU - PATCH - Q3'2022


Sathish's issue
For the below servers, there was issues in updating the syslogs retention to 180 days and chef team asked to get OS team help
sapapp40
EWMAPP3
ttas4proqaapp

[root@sapapp35 ~]# cat /etc/rsyslog.conf
#### MODULES ####
$ModLoad imuxsock # provides support for local system logging (e.g. via logger command)
$ModLoad imklog   # provides kernel logging support (previously done by rklogd)
#### GLOBAL DIRECTIVES ####
$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat
# Include all config files in /etc/rsyslog.d/
$IncludeConfig /etc/rsyslog.d/*.conf
#### RULES ####
*.info;mail.none;authpriv.none;cron.none                /var/log/messages
authpriv.*                                              /var/log/secure
mail.*                                                  -/var/log/maillog
cron.*                                                  /var/log/cron
*.emerg                                                 *
uucp,news.crit                                          /var/log/spooler
local7.*                                                /var/log/boot.log



[root@sapapp40 ~]# cat /etc/rsyslog.conf
#### MODULES ####
$ModLoad imuxsock # provides support for local system logging (e.g. via logger command)
$ModLoad imklog   # provides kernel logging support (previously done by rklogd)
#### GLOBAL DIRECTIVES ####
$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat
# Include all config files in /etc/rsyslog.d/
$IncludeConfig /etc/rsyslog.d/*.conf
#### RULES ####
*.info;mail.none;authpriv.none;cron.none                /var/log/messages
authpriv.*                                              /var/log/secure
mail.*                                                  -/var/log/maillog
cron.*                                                  /var/log/cron
*.emerg                                                 *
uucp,news.crit                                          /var/log/spooler
local7.*                                                /var/log/boot.log




Aruna's issue

Mahesh's ticket
Please create the following directories in
VM (Dev) :
FBSAPD01FGCL 10.199.98.11 10.250.98.11 SUSE BDA

Directories :
/FCA_DENMARK_INTERFACES/FCADK_DEV/Out/Banks/PBS/
/FCA_DENMARK_INTERFACES/FCADK_DEV/ArcOut/Banks/PBS/

/FCA_DENMARK_INTERFACES/FCADK_UAT/Out/Banks/PBS/
/FCA_DENMARK_INTERFACES/FCADK_UAT/ArcOut/Banks/PBS/

/FCA_DENMARK_INTERFACES/FCADK_MIG/Out/Banks/PBS/
/FCA_DENMARK_INTERFACES/FCADK_MIG/ArcOut/Banks/PBS/

********************************
VM (Prod):
FBSAPP01FGCL 10.199.99.11 10.250.99.11 SUSE BPA

Directories :
/FCA_DENMARK_INTERFACES/FCADK_PROD/Out/Banks/PBS/
/FCA_DENMARK_INTERFACES/FCADK_PROD/ArcOut/Banks/PBS/

Any queries, please reach out to Mahesh.naik.p@kyndryl.com or tincrosnatu@deloitte.it





CS11599991 Wawa, Inc. -- WA2P2 - Majorwa2#wa2scpdb01#Log PaceMaker-crmd Found 8 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-07-28-14-14-15 for de

CS11599951 Wawa, Inc. -- WA2P2 - Majorwa2#wa2scpdb01s#Resources DRBD CRITICAL: Role value Unknown found for resource r2 on host wa2scpdb01

CHG0250547	Dal13

bs4ss1028	                10.211.8.37			Development  	cannot connect
bs4dsj020	                10.211.8.126			Development  
bs4bod013	                10.211.8.40			Development  
bs4pd5022	                10.211.6.8			Development  
bs4cpd015	                10.211.8.42			Development  
bs4dg0009	                10.211.8.19			Development  
bs4nw1016	                10.211.8.39			Development  
bs4dsm019	                10.211.8.131			Development  
bs4nw2017	                10.211.8.38			Development  


journalctl --since "2022-07-23 00:00:00" --until "2022-07-23 23:59:59"  >>/tmp/journallogs_23July.txt


400 GB swap  
first on 01s
sdc                          8:32   0    2T  0 disk
sdd                          8:48   0    1T  0 disk


sdd1 created 400GB disk

/dev/vgswap/lvswap

db crashed

sdc                      8:32   0    2T  0 disk
sdd                      8:48   0    1T  0 disk


[root@wa2scpdb01 ~]# cat /etc/fstab |grep -i swap
/dev/vgswap/lvswap


check kdump configured on wa2scpdb01s and update SUSE ticket which you will create..

These VMs need to have ALL their configured memory as reserved. Please access V Center and check configuration

case to suse
- Apps DBA was unable to bring the database up as they see more than 15 processess are in orphen state causing issue to start the db. Also they are unable to kill the processes.
- Teams proceeded to reboot the server and the server was brought up on wa2scpdb01 as cluster was on unamanaged state. SAP team requests to bring the applications and DB on the same old wa2scpdb01s instead of wa2scpdb01 as they performed some sql changes on the node.
- OS team proceeded to set the cluster to managed and moved the filesystems to wa2scpdb01s.
- PDL team proceeded to bring the database and applications up.
- As per previous findings on the swap space, teams verified the swap space once again and confirmed that it was completely used. So teams decided to increase the swap space from 47gb to 400gb.
- To Increase the SWAP Space teams have to bring the Applications and DB down to make the required changes on releasing the old swap from OS level.
- OS team Increased the SWAP Space to 400gb on wa2scpdb01s and requests PDL to proceed with bringing the DB & Applications up.
- PDL confirms that Application and Database is up

SUSE  Support Cases  00356655


CS11655578 Delta pHANA inaccessible
SL sev1 number:CS2946616 for 



[root@agesvsd1srv01 ~]# ip route get 146.89.140.182
146.89.140.182 via 10.6.1.1 dev eth0  src 10.6.1.189
    cache  mtu 1500 hoplimit 64
    
    146.89.140.0    10.6.1.1        255.255.252.0   UG        0 0          0 eth0
    
    route add -net 10.116.145.0 netmask 255.255.255.192 gw 0.0.0.0

10.116.145.0    0.0.0.0         255.255.255.192 U         0 0          0 bond0

ping 10.116.145.18


[root@sng01ammtsm004 ~]# ip route get 10.116.145.18
10.116.145.18 dev bond0 src 10.116.205.228

10.116.145.0/26 dev bond0 scope link

10.116.145.0    0.0.0.0         255.255.255.192 U         0 0          0 eth2


ip route add 10.116.145.0/26 gw 0.0.0.0 dev eth2


[root@sng01ammtsm004 ~]# netstat -nr
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         146.89.140.129  0.0.0.0         UG        0 0          0 bond0.822
10.0.0.0        10.116.205.129  255.252.0.0     UG        0 0          0 bond0
10.116.35.128   0.0.0.0         255.255.255.192 U         0 0          0 bond0
10.116.145.0    0.0.0.0         255.255.255.192 U         0 0          0 bond0
10.116.172.64   10.116.205.129  255.255.255.192 UG        0 0          0 bond0
10.116.205.128  0.0.0.0         255.255.255.128 U         0 0          0 bond0
146.89.140.128  0.0.0.0         255.255.255.192 U         0 0          0 bond0.822
161.26.0.0      10.116.205.129  255.255.0.0     UG        0 0          0 bond0
166.8.0.0       10.116.205.129  255.252.0.0     UG        0 0          0 bond0
169.60.136.128  146.89.140.129  255.255.255.192 UG        0 0          0 bond0.822
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 bond0
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 bond0.822




Change approval
CHG0248617, CHG0245927, CHG0245943



CS11661556	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-04-11
CS11661542	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-14-05
CS11661533	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-54-03
CS11661535	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-49-09
CS11661530	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-bpadb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-02-14
CS11661518	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-bpadb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-07-09
CS11661516	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-29-07
CS11661509	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-44-03
CS11661511	Certified IT Consultants - TMG -- CI3	P1 - Severe	ci3#ci3tmg-bpadb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-27-10

CS11661568	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 3 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-19
CS11661569	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-01
CS11661566	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-ErrorStates Found 15 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-55-5
CS11661557	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-21
CS11661560	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-14-05
CS11661554	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpadb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-27-10
CS11661552	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-29-07
CS11661551	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-44-03
CS11661550	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-ErrorStates Found 15 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-30-5
CS11661545	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-ErrorStates Found 10 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-49-0
CS11661547	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-ErrorStates Found 10 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-09-0
CS11661546	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-ErrorStates Found 10 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-44-0
CS11661548	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-21
CS11661541	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 3 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-54
CS11661537	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpadb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-42-08
CS11661539	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-ErrorStates Found 15 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-45-5
CS11661534	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-ErrorStates Found 15 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-40-5
CS11661527	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-11
CS11661528	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpadb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-02-08
CS11661531	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-ErrorStates Found 15 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-10-5
CS11661520	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-54-03
CS11661519	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-50
CS11661513	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prddb#Log Syslog-ErrorStates Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-19-12
CS11661512	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-05-35
CS11661515	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-04-24
CS11661517	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 3 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-43
CS11661510	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-bpaapp#Log Syslog-Authentication Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-06-51
CS11661508	Certified IT Consultants - TMG -- CI3	P2 - Major	ci3#ci3tmg-prdapp#Log Syslog-Authentication Found 3 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-08-05-07-04


[root@tdpdcprdap1 ~]# df -hT /softdump
Filesystem                    Type  Size  Used Avail Use% Mounted on
/dev/mapper/softdumpvg-softlv ext4  246G   11G  223G   5% /softdump



FORMAL RCA - dal#dlthdehdb3#Unable to ping DLTHDEHDB3 (10.4.5.43) from FRDAL13WEBD01.
CS11655578	SL case number: CS2946616

Case with suse Support Cases keyboard_arrow_right 00357404
https://scc.suse.com/support/cases/00357404#02s5q000006HaPPAA0

=[ DONE ]===================================================================
  Log file tar ball: /var/log/scc_dlthdehdb3_220805_0740.txz
  Log file size:     7.4M
  Log file md5sum:   821d85977de32cf8d6db4803c0c141e5


07:20:01    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
07:30:01     65263292 257952032 487507920     61.61   1259732 215917432 560134024     70.79 498867704 203681732       280
07:40:01     65263716 257953672 487505444     61.61   1259732 215918512 560182648     70.80 498865960 203683292       264
07:50:01     65265084 257957156 487503196     61.61   1259732 215920304 559977112     70.77 498866940 203684900       304
08:00:01     65266776 257947372 487512540     61.61   1259732 215908596 560021024     70.78 498857416 203683224       308
08:10:01     65273668 257956164 487504588     61.61   1259732 215910348 559957604     70.77 498856664 203684796       184
08:20:01     65251508 257936068 487514872     61.62   1259732 215920300 559948140     70.77 498856800 203694576       608
Average:     65176504 257831364 487554848     61.62   1259621 215963135 559814254     70.75 498908335 203729769       281

09:14:12     LINUX RESTART      (80 CPU)

09:20:01    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
09:30:01    619258452 619135300 134764392     17.03    173744  36092680 193289620     24.43 137317088  32379092        16
09:40:01    613864120 613896100 139991480     17.69    177288  36235724 195340636     24.69 142725188  32296624       368
09:50:01    611278288 611338512 142565384     18.02    180768  36239820 198880180     25.14 145297364  32299608       316
10:00:01    610048944 610125948 143769748     18.17    184224  36259568 199446244     25.21 146502896  32318636       456
10:10:01    604852392 604927416 148959884     18.83    187636  36260896 206171556     26.06 151722920  32310608       736
10:20:01    602559164 602642356 151246712     19.12    191100  36263336 206934436     26.15 153992692  32300836       356

dlthdehdb3:/var/log/sa # dmesg -T |grep -i fail
[Thu Aug  4 09:13:52 2022] pci 0000:18:00.0: BAR 7: failed to assign [mem size 0x00200000 64bit pref]
[Thu Aug  4 09:13:52 2022] pci 0000:18:00.1: BAR 7: failed to assign [mem size 0x00200000 64bit pref]
[Thu Aug  4 09:13:52 2022] pci 0000:18:00.2: BAR 7: failed to assign [mem size 0x00200000 64bit pref]
[Thu Aug  4 09:13:52 2022] pci 0000:18:00.3: BAR 7: failed to assign [mem size 0x00200000 64bit pref]
[Thu Aug  4 09:13:52 2022] pci 0000:18:00.1: BAR 10: failed to assign [mem size 0x00080000 64bit pref]
[Thu Aug  4 09:13:52 2022] pci 0000:18:00.2: BAR 10: failed to assign [mem size 0x00080000 64bit pref]
[Thu Aug  4 09:13:52 2022] pci 0000:18:00.3: BAR 10: failed to assign [mem size 0x00080000 64bit pref]
[Thu Aug  4 09:14:15 2022] tmhook: module verification failed: signature and/or required key missing - tainting kernel


CS11662110 The Ogilvy Group Inc -- OGYP2 - Majorogy#ogypxn001-ha#Resources CRM CRITICAL: 1 or more Stopped resources found: vcenter-fencing-ogypxn001(stonith:fence_vmware_rest):Stopped Stopped: [ ogypxn001-haOGYPXN001-HA(empty)SQ-SAP-TRIO-B2Incident08-05-2022 06:56:22 - Kyndryl Netcool AuSelect record for action: 


CS11661638 The Ogilvy Group Inc -- OGYP2 - Majorogy#ogysbw018#Disk Utilization /home CRITICAL: Free 40.88MB/9.04% (thresh @5.01:10%)OGYSBW018(empty)SQ-SAP-TRIO-B2Incident08-05-2022 05:19:51 - Kyndryl Netcool AuSelect record for action: 

CS11661915 The Ogilvy Group Inc -- OGYP2 - Majorogy#ogyqbj014#CPU CPU-Utilization CRITICAL: CPU Usage 100% (thresh 90%) user=62.69% system=37.31% iowait=0.00% idle=0.00%OGYQBJ014(empty)SQ-SAP-TRIO-B2Incident08-05-2022 06:15:50 - Kyndryl Netcool AuSelect record for action: 

CS11661653 The Ogilvy Group Inc -- OGYP2 - Majorogy#ogyqgr034#Disk Utilization /export CRITICAL: Free 3759.89MB/6.57% (thresh @5.01:10%)


CHG0251647

	TGYBWAQASDB	10.20.11.6	Done
	TGYBWJQASDB	10.20.11.8	Done
	TGYBWJQASAP	        10.20.11.10	DOne	
TGYBWAQASAP	10.20.11.7
TGYERPQASDB	         10.20.11.13
TGYERPQASAP	         10.20.11.9


CS11666531 and CS11667506

IA2FTPDEVAPP
Aug  6 10:29:20 IA2FTPDEVAPP kernel: pmd_set_huge: Cannot satisfy [mem 0xf0000000-0xf0200000] with a huge-page mapping due to MTRR override.

[root@IA2FTPDEVAPP ~]$ cat /var/log/messages |grep -i cannot
Aug  6 06:12:35 IA2FTPDEVAPP rsyslogd[2237665]: message repeated 32 times: [cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]]
Aug  6 06:13:55 IA2FTPDEVAPP rsyslogd[2237665]: cannot resolve hostname 'logagg.example.com': Inappropriate ioctl for device [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]
Aug  6 06:15:25 IA2FTPDEVAPP rsyslogd[2237665]: cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]
Aug  6 06:23:53 IA2FTPDEVAPP rsyslogd[2237665]: message repeated 5 times: [cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]]
Aug  6 06:24:25 IA2FTPDEVAPP rsyslogd[2237665]: cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]
Aug  6 07:51:19 IA2FTPDEVAPP rsyslogd[2237665]: message repeated 57 times: [cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]]
Aug  6 07:51:49 IA2FTPDEVAPP rsyslogd[2237665]: cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]
Aug  6 10:29:20 IA2FTPDEVAPP kernel: pmd_set_huge: Cannot satisfy [mem 0xf0000000-0xf0200000] with a huge-page mapping due to MTRR override.
Aug  6 10:29:38 IA2FTPDEVAPP rsyslogd[1833]: cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]
Aug  6 10:29:38 IA2FTPDEVAPP rsyslogd[1833]: cannot resolve hostname 'logagg.example.com' [v8.1911.0-7.el8_4.2 try https://www.rsyslog.com/e/2027 ]
Binary file (standard input) matches
[root@IA2FTPDEVAPP ~]$ date
Sat Aug  6 11:05:59 UTC 2022


[root@IA2FTPDEVAPP ~]$ dmesg -T |grep -i fail
[Sat Aug  6 10:31:15 2022] pci 0000:00:15.3: BAR 13: failed to assign [io  size 0x1000]
[Sat Aug  6 10:31:15 2022] pci 0000:00:15.4: BAR 13: failed to assign [io  size 0x1000]
[Sat Aug  6 10:31:15 2022] pci 0000:00:15.5: BAR 13: failed to assign [io  size 0x1000]


RedHat case 03284163
https://access.redhat.com/support/cases/#/case/03284163


Aug@@newdelhi@@45
ibmsgaur

lbuqa1db01	                10.139.32.34			QA  
lbuqp1db01	                10.139.32.88			QA  	all gud
lbuql1db01	                10.139.32.63			QA  
lbuqg1db01	                10.139.32.39			QA  	all gud
lbuql1ap01	                10.139.32.68			QA  
lbuqg1ap01	                10.139.32.86			QA  
lbuqa1ap01	                10.139.32.61			QA  
lbuqp1ap01	                10.139.32.62			QA 	all gud 
lbuqf1ap01	                10.139.32.70			QA  
LBUQS1DB02	         	10.139.32.198	                QA	all gud



Require DSM Url format as dsm://hostOrIp:port/. Invalid param policyid:49
[root@lbuqs1db02 tmp]#

Response:
Attempting to connect to https://fmsprdtren001.prdcloud.fms.ibmcloud.com:4120/


HSE	dlthsehdb2	10.143.69.228	delta-dal09-phana-2048-03.imzcloud.ibmammsap.local	firmware is upto date
HME	dlthemhdb4	10.143.69.178	delta-dal09-phana-4096-02.imzcloud.ibmammsap.local	firmware is upto date
HQE	dlthqehdb2	10.120.28.95	dal-dal09-pod1-phana-h2-3000-01.imzcloud.ibmammsap.local	upto date just one optional update pending
HPE	dlthpehdb4	10.143.69.160	delta-dal09-phana-4096-03.imzcloud.ibmammsap.local	firmware is upto date


I wanted to fix cluster issue of HPE

DEA	DLTDEAHDB

QEA	DLTQEAHDB

vmem


10.148.74.149 via 10.65.126.193 dev bond0 src 10.65.126.213
ip route add 10.148.74.149/32 gw 10.65.126.193 dev bond0 src 10.65.162.199

10.148.74.149 via 10.65.162.129 dev bond0 src 10.65.162.199 


https://web.yammer.com/main/org/kyndryl.com/threads/eyJfdHlwZSI6IlRocmVhZCIsImlkIjoiMTg2MzE2MjE5Mjk1MzM0NCJ9



CHG0251676 & CHG0251678

a0001p5rapp0014 - 146.89.169.133  imz / 10.36.106.250 bondo - TSM server


From  npsbxhdb04 , we need to reach bond0 in TSM




please monitor Wawa channel and check SuSE ticket 00358152,


Source
DLTHQGGA1 10.4.5.42 10.250.17.42
DLTHQGGAT 10.4.5.34 10.250.17.34
DLTQEGGAT 10.4.5.176 10.250.17.180

Destination
DLTHSGGAT 10.4.5.24 10.250.17.24


CHG0251861	
dltdeahdb	                10.4.5.185		phana	Development	10.143.69.186	delta-dal09-phana-1024-01.imzcloud.ibmammsap.local
dltdxaadb	                 10.4.5.213                    Development	non hana
dlthdehdb	                10.4.5.11		vhana	Development	10.143.69.173	dalhana-1024-61.xsportal.local



10.143.69.254	delta-dal09-phana-4096-04.imzcloud.ibmammsap.local



100.64.253.6 TSLCFNS4PASCS TSLCFNS4PASCS .corp.tatasteel.com CFP
To be replaced with â€“
100.64.253.6 TSLCFNS4PASCS TSLCFNS4PASCS.corp.tatasteel.com CFP



CS11754787Takasago International Corporation -- TI3Takasago International Corporation -- TI...Incident08-19-2022 09:28:20
P2 - Majorti3#ti3s4qdb02#Memory Virtual CRITICAL: Free Memory 4.93% (thresh 5:%

CS11754331


CS11754819
add route towards subnet 10.170.64.0/24 with gateway as 10.207.61.1 in the following 2 servers

ttas4hpdb	        (CFN-10.170.61.250/IFN-10.207.61.161)
ttas4hpdb-ha	(CFN-10.170.61.224/IFN-10.207.61.154)

ip route add 10.170.64.0/24 via 10.207.61.1



qlaqp1s4haap
QLA-TELSTRA INTERNATIONAL HK LIMITED -PG1
QLATOK02DS89DR


ql2eps2dc2a
QL2 -TELSTRA INTERNATIONAL HK LIMITED -PG1
QL2TOK02DS149DR




ql2qp1cmg
QL2TOK02DS149DR
QL2 -TELSTRA INTERNATIONAL HK LIMITED -PG1

ql2qp1kfx
QL2TOK02DS149DR
QL2 -TELSTRA INTERNATIONAL HK LIMITED -PG1


 ql3au02dsdb
 QL3TOK02DS159DR
 QL3 - TELSTRA INTERNATIONAL HK LIMITED -PG1
 
 ql3au02shardb
QL3TOK02DS159DR 
 QL3 - TELSTRA INTERNATIONAL HK LIMITED -PG1


CS11762918 Arnoldo Mondadori Editore SpA -- ARMARM IC4SAP-SL SAP LOBIncident08-20-2022 14:30:33
P2 - Majorarm#armfksap301db#Service Pacemaker stonithd CRITICAL: 0 /usr/lib/pacemaker/stonithd processes running (thresh 1:)
CS11762912 Arnoldo Mondadori Editore SpA -- ARMARM IC4SAP-SL SAP LOBIncident08-20-2022 14:30:22
P2 - Majorarm#armfksap301ap#Service Pacemaker crmd CRITICAL: 0 /usr/lib/pacemaker/crmd processes running (thresh 1:)
CS11762913 Arnoldo Mondadori Editore SpA -- ARMARM IC4SAP-SL SAP LOBIncident08-20-2022 14:30:22
P2 - Majorarm#armfksap301db#Service pacemakerd CRITICAL: 0 /usr/sbin/pacemakerd processes running (thresh 1:)
CS11762908 Arnoldo Mondadori Editore SpA -- ARMARM IC4SAP-SL SAP LOBIncident08-20-2022 14:30:21
P2 - Majorarm#armfksap301db#Service Pacemaker lrmd CRITICAL: 0 /usr/lib/pacemaker/lrmd processes running (thresh 1:)



Linux Servers:
	wa2scpap01	10.191.2.44
	wa2scpap01s	10.191.2.19
	wa2scpdb01	10.191.2.62
	wa2scpdb01s	10.191.2.22
	wa2bwpap01	10.191.1.143	
	wa2bwpap02	10.191.1.140	- Non-pacemaker clusster
	wa2bwpdb01	10.191.2.32	- Non-pacemaker clusster
	wa2bwpdb02	10.191.2.39	- Non-pacemaker clusster
	wa2bwpdb03	10.191.2.13	- Non-pacemaker clusster
	wa2xipaap01	10.191.2.57
	wa2xipaap01s	10.191.2.9
	wa2xipaap02	10.191.2.21
	wa2xipaap02s	10.191.2.7

Commands to run:
uname -a;uptime;date;free -ah;sar -u 1 4 | egrep -i "average|idle";crm_mon -1Afr;drbdadm status



WA2SCPAP01  WA2SCPAP01  10.191.2.44
WA2SCPAP01S wa2scpap01s   10.191.2.19
WA2SCPDB01  WA2SCPDB01  10.191.2.62
WA2SCPDB01S wa2scpdb01s   10.191.2.22

COMMAND TO EXECUTE ON ABOVE SERVERS:
uname -a;uptime;date;free -ah;sar -u 1 4 | egrep -i "average|idle";crm_mon -1Afr;drbdadm status


qlaqp1podb		qlaqp1podb  QLATOK02DS89DR	 qlaqp1slmdb	QLATOK02DS89DR
QLA-TELSTRA INTERNATIONAL HK LIMITED -PG1



Login issue
SPSVBPDAASE01

SPSVPPALASE01



CS11793493 is the master ticket

CS11791608

CHG0254023 approval

BAPCCD0100   remove 256 disk if added by samuel


[root@lbupm1ap01 ~]# df -hT /usr/sap/DAA/
Filesystem                        Type  Size  Used Avail Use% Mounted on
/dev/mapper/pm1appvg-usrsapdaa_lv xfs   4.0G  1.8G  2.3G  45% /usr/sap/DAA

usrsapdab_lv



CHG0253764 
CHG0253753
 
CS11807758 Delta Air Lines -- DALP2 - Majordal#dltqeahap1#Service master CRITICAL: 0 master processes running (thresh 1:)
CS11807756 Delta Air Lines -- DALP2 - Majordal#dltqeahap1#Service postfix/master CRITICAL: 0 postfix/master processes running (thresh 1:)
CS11807754 Delta Air Lines -- DALP2 - Majordal#dltqeahap1#Service postfix CRITICAL: 0 postfix processes running (thresh 1:)
CS11807755 Delta Air Lines -- DALP2 - Majordal#dltqwchwd#Service sshd CRITICAL: 0 sshd processes running (thresh 1:)
CS11807743 Delta Air Lines -- DALP2 - Majordal#dltqwchwd#Service cron CRITICAL: 0 cron processes running (thresh 1:)



 CS11831351 - hfc#hfcxbwhndb1#Unable to ping HFCXBWHNDB1 (10.92.9.74) from FRDAL13WEBD01.
The server hfcxbwhndb1 is down due to hardware error.
SL team is investigating the issue (SL case CS2983075- Moonlight)

hfc-dal13-pod2-phana-h4-6000-02.imzcloud.ibmammsap.local
 HFCXBWHNDB1 (10.92.9.74) 
 #scx-sapb2-hfc
 
 
 
 [root@tslgldev ibmrmalik]# cat /etc/sudoers.d/sudoers
%custapp ALL=(ALL) NOPASSWD:ALL,SUROOT,RESTRICTED_CMDS



10.155.223.59	dalhana-1024-20.xsportal.local




[root@zffpapp001 ~]# cat /etc/fstab |grep -i /usr/sap/OR9/zf/filetransfer
//frda90134.emea.zf-world.com/c90134_74$/filetransfer /usr/sap/OR9/zf/filetransfer cifs domain=ADTRW,credentials=/sapmnt/OR9/profile/or9adm_adtrw.smb,uid=or9adm,gid=sapsys,file_mode=0700,dir_mode=0700,soft,vers=2.1 0 0




Source :
12:31
*******************************************************************************
*    Server Type: Production                                                  *
*       Hostname: IA1NFSPRDAPP                                                *
*         CFN IP: 66.248.244.25                                               *
*         IFN IP: 10.133.15.25                                                *
*        SAP SID: n/a                                                         *
****************************************************************************
12:31
Target 1 : issue server :
12:31
*    Server Type: QA                                                          *
*       Hostname: ia1s4hqasapn2                                               *
*         CFN IP: 66.248.245.163                                              *
*         IFN IP: 10.133.17.164                                               *
*        SAP SID: SQ2
12:32
target 2: correct one:
12:32
*******************************************************************************
*    Server Type: QA                                                          *
*       Hostname: IA1S4HQASAPP                                                *
*         CFN IP: 66.248.245.140                                              *
*         IFN IP: 10.133.17.140                                               *
*        SAP SID: SQ1
12:32
/nfsshare_Q/Inbound
12:34
/nfsshare_Q/Inbound/TR_PSR



=>Server/Host name................................: zffpapp008, zffpapp008-ha, zffsappdb007

Please change the IP address for printer DD88 as follows:

Old Address:	140.171.62.165
New Address:	10.23.163.231

[root@zffpapp008 ~]# lpstat -t |grep -i DD88
device for dd88: lpd://10.23.163.231


[root@zffpapp008-ha ~]# lpstat -t |grep -i DD88
device for dd88: lpd://10.23.163.231


[root@zffsappdb007 ~]# lpstat -t |grep 140.171.62.165
device for dd88: lpd://140.171.62.165


lpadmin -p DD88 -v socket://10.23.163.231 -E


CS11848321Meggitt PLC -- MGGP2 - Majormgg#mgggbjpeccx17#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MGGGBJPECCX17- KB0010973
CS11848320Meggitt PLC -- MGGP2 - Majormgg#mgggbjpeccx16#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MGGGBJPECCX16- KB0010973
CS11848319Meggitt PLC -- MGGP2 - Majormgg#mgggbjpeccx13#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on MGGGBJPECCX13- KB0010973


gpay-11186546410@okbizaxis


CHG0253009, 
CHG0254243, CHG0254245, 
CHG0253020 approvals


CS11882043 HO for Linux peer - Files transfer issue from Peoplesoft
Ticket CS11885854 was raised with network team.



[8:17 AM] YUAN YUAN
    Ravi MALIK



CS11885806
HollyFrontier
 Corporation -- HFC
P2 - Major
hfc#hfcwdpapp1#Cleared and Re-fired: Log PaceMaker-stonith-ng Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protoco





CS11885804
HollyFrontier
 Corporation -- HFC
P2 - Major
hfc#hfcwdpapp1#Cleared and Re-fired: Log PaceMaker-crmd Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022


 


CS11885805
HollyFrontier
 Corporation -- HFC
P2 - Major
hfc#hfcwdpapp1#Cleared and Re-fired: Log PaceMaker-corosync Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-





<https://teams.microsoft.com/l/message/19:d4f9194cec1245feb11016147f50e0dc@thread.tacv2/1662691664118?tenantId=f260df36-bc43-424c-8f44-c85226657b01&amp;groupId=982dd7c1-14ca-4651-8b19-43f1af4e1648&amp;parentMessageId=1662691664118&amp;teamName=MA SAP Troop B&amp;channelName=01-Dispatching&amp;createdTime=1662691664118&amp;allowXTenantAccess=false>


 Nagios not completing the checks #2642 
 
CHG0253003, CHG0253004, CHG0253009




WAWA monotoring
CS11568527

    
Is needed monitoring and attach the output requested every hour:


Servers
wa2prddb01  - 100.64.20.56 
wa2prddb01s - 100.64.20.53 


Output 
uname -a;uptime;date;iostat 2 3;sar 2 5;svmon -O unit=GB


CS11917830
SIRS4DEVHANA	fra02-pod2-4tb-host07.imzcloud.ibmammsap.local
[root@sirs4devhana ~]$ dmesg -T |grep -i cannot
[Wed Sep 14 06:10:41 2022] pmd_set_huge: Cannot satisfy [mem 0xf0000000-0xf0200000] with a huge-page mapping due to MTRR override.
[root@sirs4devhana ~]$ date
Wed Sep 14 06:14:45 CEST 2022

[root@sirs4devhana ~]$ cat /var/log/messages |grep -i taint
Sep 14 06:11:04 sirs4devhana kernel: [   25.748721] tmhook: loading out-of-tree module taints kernel.
Sep 14 06:11:04 sirs4devhana kernel: [   25.748805] tmhook: module verification failed: signature and/or required key missing - tainting kernel
[root@sirs4devhana ~]$ date
Wed Sep 14 06:23:50 CEST 2022

Sep 14 06:01:56 sirs4devhana systemd[1]: os_check.service: Failed to run 'start' task: Cannot allocate memory
Sep 14 06:02:49 sirs4devhana systemd[1]: os_check.service: Failed to fork: Cannot allocate memory
Sep 14 06:02:52 sirs4devhana systemd[1]: os_check.service: Failed to run 'start' task: Cannot allocate memory
Sep 14 06:04:18 sirs4devhana systemd[1]: os_check.service: Failed to fork: Cannot allocate memory
Sep 14 06:04:18 sirs4devhana systemd[1]: os_check.service: Failed to run 'start' task: Cannot allocate memory
Sep 14 06:04:35 sirs4devhana systemd[1]: os_check.service: Failed to fork: Cannot allocate memory
Sep 14 06:04:35 sirs4devhana systemd[1]: os_check.service: Failed to run 'start' task: Cannot allocate memory
Sep 14 06:06:59 sirs4devhana systemd[1]: os_check.service: Failed to fork: Cannot allocate memory
Sep 14 06:07:10 sirs4devhana systemd[1]: os_check.service: Failed to run 'start' task: Cannot allocate memory
Sep 14 06:08:11 sirs4devhana systemd[1]: os_check.service: Failed to fork: Cannot allocate memory
Sep 14 06:08:11 sirs4devhana systemd[1]: os_check.service: Failed to run 'start' task: Cannot allocate memory
Sep 14 06:10:53 sirs4devhana boot.local[1350]:    for example because of hardware which cannot be set to a specific frequency
Sep 14 06:10:53 sirs4devhana kernel: [    3.261950] pmd_set_huge: Cannot satisfy [mem 0xf0000000-0xf0200000] with a huge-page mapping due to MTRR override.
[root@sirs4devhana ~]$ date
Wed Sep 14 06:24:18 CEST 2022


[root@sirs4devhana ~]$ sar -r -f
Linux 4.12.14-95.105-default (sirs4devhana) 	09/14/22 	_x86_64_	(16 CPU)

00:00:01    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
00:10:01      3368516    580680 111677804     85.62         8   9180092 113603004     85.72 116191516   3928200     52068
00:20:02      3323220    229624 112395956     86.18         8   9177088 115127512     86.87 116842056   3986964     45276
00:30:01      3475080    130388 112795512     86.48         8   8914244 114975240     86.76 117067568   3899996     28844
00:40:01      3317096         0 113199660     86.79         8   8745292 115383056     87.07 117235820   3964836      7600
00:50:01      3421612     22336 113595344     87.10         8   8245636 114283664     86.24 117195292   3898228     18888
01:00:01      3273940         0 113903080     87.33         8   8081292 114290704     86.24 117337300   3894840     21880
01:10:01      3253404         0 113906308     87.33         8   8098108 114214332     86.18 117234100   4023312     42664
01:20:01      3410064     18260 113967440     87.38         8   7881232 114192800     86.17 117196416   3901788     20932
01:30:01      2663856         0 114136308     87.51         8   8457028 114224452     86.19 117355556   4480056     34704
01:40:02      2656872         0 114234468     87.59         8   8365636 114180676     86.16 117458116   4395468     45936
01:50:02      2650476         0 113694516     87.17         8   8875404 113500272     85.65 117050372   4779124     36756
02:00:02      3243500         0 114084564     87.47         8   7939224 113373176     85.55 117343984   3942404     41192
02:10:02      2762160         0 114252456     87.60         8   8253136 113444868     85.60 117548876   4221536     37180
Average:      3139984     75484 113526417     87.04         8   8477955 114214904     86.18 117158229   4101289     33378

06:11:02     LINUX RESTART	(16 CPU)
[root@sirs4devhana ~]$ 


[root@sirs4devhana ~]$ sar -u -f
Linux 4.12.14-95.105-default (sirs4devhana) 	09/14/22 	_x86_64_	(16 CPU)

00:00:01        CPU     %user     %nice   %system   %iowait    %steal     %idle
00:10:01        all     13.27      0.02      4.57      0.15      0.00     81.98
00:20:02        all      6.76      0.00      3.05      0.15      0.00     90.04
00:30:01        all      4.63      0.00      2.74      0.08      0.00     92.55
00:40:01        all      5.19      0.00      3.29      1.56      0.00     89.96
00:50:01        all      5.28      0.00      3.56      0.36      0.00     90.79
01:00:01        all      5.94      0.00      3.91      0.66      0.00     89.48
01:10:01        all      6.04      0.00      3.21      0.35      0.00     90.40
01:20:01        all      4.60      0.00      2.90      0.38      0.00     92.11
01:30:01        all      4.75      0.00      3.17      1.10      0.00     90.99
01:40:02        all      6.12      0.00     10.82     42.00      0.00     41.06
01:50:02        all      4.38      0.00      4.65     15.34      0.00     75.63
02:00:02        all      3.96      0.00      1.87      4.09      0.00     90.08
02:10:02        all      2.29      0.00     11.26     49.11      0.00     37.33
Average:        all      5.63      0.00      4.54      8.87      0.00     80.96

06:11:02     LINUX RESTART	(16 CPU)

Sep 14 01:41:47 sirs4devhana python[25696]: ('Error : cpu status', IndexError('list index out of range',))
Sep 14 01:41:47 sirs4devhana python[25696]: ('Error : Version update ', OSError(12, 'Cannot allocate memory'))
Sep 14 01:41:47 sirs4devhana python[25696]: Error : Getting hostname
Sep 14 01:41:47 sirs4devhana python[25696]: Error : Getting ifn/cfn ip
Sep 14 01:41:50 sirs4devhana auditbeat[2235]: 2022-09-14T01:41:50.218+0200


Support Cases keyboard_arrow_right 00361921


[1:32 PM] Piyush Srivastava
1. Account Name: Saputo Inc (SAU)
2. Production Site: Toronto 01 (3.x)	
3. DR Site: Montreal 01 (3.x)		
4. Production VLAN: (CFN - 1141 | IMZ - 1204)5. DR VLAN: (CFN -Â Â Â | IMZ - )6. PG Name: (CFN - unknownÂ Â | IMZ - unknown)
7. RPO: unknown
8. VMs in scope for SRM Configuration:	SAU - RP13

[1:32 PM] Piyush Srivastava
saupr1scs01p
saupr1app02pÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  
saupr1app01pÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  
saupr1db01p

[1:35 PM] Piyush Srivastava
add to new PG and RP.



CHG0254864	15-09-2022 06:30:00	15-09-2022 10:30:00
br3qhcias31	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.72       QA		qhc-SAP LOB  
br3qhcias30	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.48       QA		qhc-SAP LOB  
br3fscmdb60	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.200       Training fcm-SAP LOB-hdb 	HANA 
br3qwdpas31	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.77       QA		qwd-SAP LOB  
br3qwzpas30	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.14.7       QA		qwz-SAP LOB  
br3qwdpas30	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.53       QA		qwd-SAP LOB  
br3qwzpas31	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.14.9       QA		qwz-SAP LOB  
br3fscmas60	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.204       Training      fcm-SAP LOB  


[root@br3fscmdb60 ds_agent]# ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.driverOffline: true
Component.AM.mode: driver-offline


[root@br3fscmas60 ds_agent]# ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.driverOffline: true
Component.AM.mode: driver-offline
AgentStatus.lastAgentToManagerSession: 1663210670

https://web.yammer.com/main/org/kyndryl.com/threads/eyJfdHlwZSI6IlRocmVhZCIsImlkIjoiMTkxNjYzMjYwNjE1NDc1MiJ9




[root@consppoapp ~]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux consppoapp 2.6.32-754.47.1.el6.x86_64 #1 SMP Thu Mar 31 02:32:43 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
Thu Sep 15 01:07:05 -03 2022
OK: No read-only file systems found
                     nfs    6.0T  3.9T  1.8T  69% /sds
-bash: timedatectl: command not found


[root@consppoapp ~]$ cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Linux consppoapp 2.6.32-754.47.1.el6.x86_64 #1 SMP Thu Mar 31 02:32:43 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
Thu Sep 15 01:17:16 -03 2022
OK: No read-only file systems found
-bash: timedatectl: command not found


CHG0256283

glibc-32bit 
[root@tpadbs ~]# rpm -qa |grep -i glibc-32bit
glibc-32bit-2.26-13.65.1.x86_64

	glibc-i18ndata 	SUSEConnect -p sle-module-basesystem/15.2/x86_64	zypper install glibc-i18ndata-2.26-13.62.1
	
glibc-locale-32bit or glibc-locale-base-32bit 
[root@tpadbs ~]# rpm -qa |grep -i glibc-locale-base-32bit
glibc-locale-base-32bit-2.26-13.65.1.x86_64

libgcc_s1-32bit 

[root@tpadbs ~]# rpm -qa |grep -i libgcc
libgcc_s1-32bit-11.2.1+git610-1.3.9.x86_64
libgcc_s1-11.2.1+git610-1.3.9.x86_64

	libidn11-32bit 	SUSEConnect -p sle-module-basesystem/15.2/x86_64	zypper install libidn11-32bit-1.34-3.2.2
	libX11-6-32bit	SUSEConnect -p sle-module-basesystem/15.2/x86_64	zypper install libX11-6-32bit-1.6.5-3.9.1 
libcurl4-32bit 

[root@tpadbs ~]# rpm -qa |grep -i libcurl4-32bit
libcurl4-32bit-7.66.0-150200.4.36.1.x86_64


libz1-32bit 

[root@tpadbs ~]# rpm -qa |grep -i libz1-32bit
libz1-32bit-1.2.11-150000.3.33.1.x86_64

	libuuid1-32bit	SUSEConnect -p sle-module-basesystem/15.2/x86_64	zypper install libuuid1-32bit-2.33.2-4.16.1
[root@tpadbs ~]# rpm -qa |grep -i libuuid1-32bit
libuuid1-32bit-2.33.2-150100.4.21.1.x86_64






10.116.205.145	ple-sng01-pod2-phana-h2-3000-01.imzcloud.ibmammsap.local
148825391
SL sev1 number:CS3009744 



# | Name             | Type    | Repository
--+------------------+---------+-----------
1 | adaptec-firmware | package | (any)
2 | atmel-firmware   | package | (any)
3 | ipw-firmware     | package | (any)
4 | mpt-firmware     | package | (any)

10.162.186.155	tta-che01-pod1-phana-h8-6000-001.imzcloud.ibmammsap.local

10.162.186.161
root   yTmYHqZ9QU



1. Start a terminal

2. Elevate your permissions to sudo: sudo su

3. Utilize lsof to identify the DNS service running on the system (should be dnsmasq, but to double confirm:

[root@peu-a4q-ci ~]$ lsof -i :53 -S COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME dnsmasq 2207 dnsmasq 4u IPv4 33907 0t0 UDP localhost:domain dnsmasq 2207 dnsmasq 5u IPv4 33908 0t0 TCP localhost:domain (LISTEN)

4. Restart the DNS service with systemctl:

systemctl restart <service>, in our case: systemctl restart dnsmasq

The DNS cache on your system is now clear.


IP : 135.110.181.164
Queue Name : NPI450E92

135.110.181.164 	NPI450E92

echo "135.110.181.164 NPI450E92" >>/etc/hosts
lpadmin -p NPI450E92 -v socket://135.110.181.164 -E

cupsenable NPI450E92
cupsaccept NPI450E92

PRD:

sapapp31 10.207.61.84 10.170.61.40
sapapp31-ha 10.207.61.222 10.170.61.123
SAPAPP21 10.207.61.80 10.170.61.131
SAPAPP15 10.207.61.37 10.170.61.121
SAPAPP18 10.207.61.70 10.170.61.116
SAPAPP19 10.207.61.215 10.170.61.74
SAPAPP20 10.207.61.195 10.170.61.48

SAPAPP23 10.207.61.130 10.170.61.226
SAPAPP26 10.207.61.48 10.170.61.176
SAPAPP27 10.207.61.47 10.170.61.166
SAPAPP28 10.207.61.58 10.170.61.211
SAPAPP29 10.207.61.85 10.170.61.141
SAPAPP30 10.207.61.95 10.170.61.161
SAPAPP32 10.207.61.46 10.170.61.52
SAPAPP33 10.207.61.235 10.170.61.88
SAPAPP34 10.207.61.230 10.170.61.94

SAPAPP35 10.207.61.39 10.170.61.62
SAPAPP36 10.207.61.197 10.170.61.115
SAPAPP37 10.207.61.156 10.170.61.107
SAPAPP38 10.207.61.134 10.170.61.237
SAPAPP39 10.207.61.167 10.170.61.212
SAPAPP40 10.207.61.149 10.170.61.252
SAPAPP41 10.207.61.151 10.170.61.248
SAPAPP42 10.207.61.242 10.170.61.139



QAS:
ECCTEST 10.207.63.19 10.170.63.25



[root@wa2bwpap02 tempfs]# vgcfgrestore vgclients
  /etc/lvm/backup/vgclients: stat failed: No such file or directory
  Couldn't read volume group metadata from file.
  Failed to read VG vgclients from /etc/lvm/backup/vgclients
  Restore failed.
  Couldn't find device with uuid 982duJ-x4iI-PNoE-AGeb-vqp8-UGgp-iMPPl8.
  Couldn't find device with uuid ybKv0d-bIdK-dBhM-WJyk-mhw0-T7ge-lHY74w.
  Couldn't find device with uuid frI8Mv-KJP6-Ov01-PJ0x-6ReN-JDC1-xb41Xl.

CHG0256271

br3sscmdb16	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.144       Development		scm-SAP LOB-hdb  HANA
br3sgtsdb15	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.97       Development		sgt-SAP LOB-hdb  HANA
br3dsapa50	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.30       Development		d4h-SAP LOB  
br3tgtsdb26	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.70       QA		tgt-SAP LOB-hdb 	HANA
br3dscmas56	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.130       Development		dcm-SAP LOB  
br3dhana50	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.27       Development		d4h-SAP LOB-hdb 	HANA 
br3tscmdb26	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.83       QA		tcm-SAP LOB-hdb  	HANA
br3dgtsas55	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.60       Development		dgt-SAP LOB  
br3tgtsas25	SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.79       QA		tgt-SAP LOB


br3dsapa50	ds agent not capable
br3dgtsas55	ds agent not capable


TSLS4HMCKAP2
CPU upgrade
Error: 422 Client Error: Unprocessable Entity for url: https://opaas.amm.ibmcloud.com/api/v1/instances/62a21435e52daf000d888402
Applying patch/post failed: 422 Client Error: Unprocessable Entity for url: https://opaas.amm.ibmcloud.com/api/v1/instances/62a21435e52daf000d888402
A failure has occurred in one of the actions, stopping other actions
Modify CPU
Server:
tsls4hmckap2
Status:
Completed with failures
Run at:
09/22/2022 12:01 AM CDT
SNOW:
CS11971399


GLTSMDDB01-DR	vhana
	wdc04-pod3-6tb-host007.imzcloud.ibmammsap.local


USPOKPMHDB01		wdc04-pod3-6tb-host007.imzcloud.ibmammsap.local

Ref sev1 ticket CS11977349       CS11977470 host down WDC

CHG0244849
SNO	SERVER NAME	FILE SYSTEM NAME	               STORAGE to Remove
1     ia2otapprdapp	/opt/opentext/volume_storage 	300 GB
2     ia2otappdapdr	/opt/opentext/volume_storage 	300 GB


[root@ia2otapprdapp ~]$ rpm -qa |grep -i ds_agent
ds_agent-10.0.0-3186.el6.x86_64

[root@ia2otappdapdr ~]$ rpm -qa |grep -i ds_agent
ds_agent-11.0.0-662.el6.x86_64

[root@ia2otapprdapp ~]$ lvs |grep -i opentext_vg
  archive_lv        opentext_vg -wi-ao----  50.00g
  backup_lv         opentext_vg -wi-ao----  41.99g
  dpdir_lv          opentext_vg -wi-ao----  10.00g
  extdir_lv         opentext_vg -wi-ao----  10.00g
  imgdir_lv         opentext_vg -wi-ao----  28.00g
  isodir_lv         opentext_vg -wi-ao----  50.00g
  opentext_lv       opentext_vg -wi-ao----  50.00g
  tomcat_lv         opentext_vg -wi-ao----  22.00g
  volume_buffer_lv  opentext_vg -wi-ao----  50.00g
  volume_storage_lv opentext_vg -wi-a-----   1.44t

[root@ia2otapprdapp ~]$ pvs |grep -i opentext_vg
  /dev/sdc   opentext_vg lvm2 a--u 700.00g    0
  /dev/sdd   opentext_vg lvm2 a--u  67.00g    0
  /dev/sde   opentext_vg lvm2 a--u 416.00g    0
  /dev/sdf   opentext_vg lvm2 a--u 300.00g    0
  /dev/sdg   opentext_vg lvm2 a--u 301.00g    0


REXPBFCHANA2
10.135.58.154	fra02-pod1-6tb-host002.imzcloud.ibmammsap.local

REXBFCHANA1
10.112.232.28	Rexel-pHANA-1.xsportal.local

REXQBFCHANA3
10.135.58.154	fra02-pod1-6tb-host002.imzcloud.ibmammsap.local

Nw ticket for REX CHG0254169


source 9.81.139.51    
destination imz 10.135.1.33	cfn 10.134.1.30


msodbcsql17-17.8.1.1-1.x86_64.rpm  , mssql-tools-17.8.1.1-1.x86_64.rpm ,  unixODBC-2.3.7-1.suse.x86_64.rpm


CHG0254866	28-09-2022 06:30:00	28-09-2022 14:30:00
br3fsapdb60    SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.127       Development        f4h-SAP LOB-hdb  
br3ssolas11    SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.87       Development        -SAP LOB  
br3scs-dev    SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.93       Development        dcs-SAP LOB-sdb  
br3fsapas60    SUSE Linux Enterprise Server 12 SP4 12.4        10.138.10.170       Development        f4h-SAP LOB  


CHG0228070
CHG0228069

CHG0256286	29-09-2022 06:30:00	29-09-2022 14:30:00

br3psolss42  SUSE 10.138.13.47 Production psj-SAP LOB
br3psolss43  SUSE 10.138.13.51 Production psj-SAP LOB
br3psolas41  SUSE 10.138.13.46 Production psj-SAP LOB
br3scs-prod  SUSE 10.138.13.6 Production pcs-SAP LOB-sdb
br3phcias40  SUSE 10.138.13.29 Production phc-SAP LOB
br3phcias41  SUSE 10.138.13.36 Production phc-SAP LOB


HO Linux- CS11746028 - Wawa Hypercare Monitoring and update every 2 hours at scx-sapb1-wa2
10.191.2.44
10.191.2.19
10.191.2.62
10.191.2.22

CHG0228073
ACTIVATIONURL='dsm://169.55.28.72:4120/'

/opt/ds_agent/dsa_control -r
/opt/ds_agent/dsa_control -a dsm://169.55.28.72:4120/ "policyid:49" "relaygroupid:1"


/opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/ "policyid:49" "relaygroupid:1"



egrs4hdevapp	SUSE Linux Enterprise Server 12 SP4 12.4        10.135.6.11       Development		s4d-SAP LOB  
egrs4hqasdb	SUSE Linux Enterprise Server 12 SP4 12.4        10.135.6.12       Development		s4d-SAP LOB-hdb  
egrwd-qas	SUSE Linux Enterprise Server 12 SP4 12.4        10.135.6.13       QA		wdq-SAP LOB  
egrwd-dev	SUSE Linux Enterprise Server 12 SP4 12.4        10.135.6.17       Development		wdd-SAP LOB  
ercerpd1	Red Hat Enterprise Linux Server 6.10 (Santiago)        10.5.1.101       Development		erd-SAP LOB-syb  
ercerpq1	Red Hat Enterprise Linux Server 6.10 (Santiago)        10.5.1.102       Development		erq-SAP LOB-syb  
egrs4hqasapp	SUSE Linux Enterprise Server 12 SP4 12.4        10.135.6.16       QA		s4q-SAP LOB 


a2aeccstg1as
a2aeccstg2as
a2asolprd1dci
a2asolprd1js

a2awebstg1p
a2asltstg2ci
a2asoldev1dci
a2apistg1db
a2apistg1as
a1a_a1asmpdb01





    

IA1OTASPRDAPP	Disk can be added

IA1S4HPRDAPP	Disk can be added

IA1SP1DB	vHANA cannot add a new disk need to migrate to bigger VM

IA1SP1DB-HA	vHANA cannot add a new disk need to migrate to bigger VM



Instance 	SID	PROD 	CFN IP	IMZ IP 
ERP	P02 DB	aprerpprdd	10.10.21.40	10.135.197.26
	P02 App	aprerpprd1	10.10.21.47	10.135.197.67
PI	PIP DB	aprpiprddbn	10.10.21.21	10.135.197.37
	PIP App	aprpiprdapn	10.10.21.22	10.135.197.66



A2AHANAPR1DB	wdc04-pod4-4tb-host01.imzcloud.ibmammsap.local


cs12135561, cs12135560


krrdbtst.imzcloud.ibmammsap.local --- 10.139.128.19	Retired
krrtpvasopdb1.imzcloud.ibmammsap.local --- 10.139.120.21	Windows
krrdbprd1.imzcloud.ibmammsap.local --- 10.139.120.46	Linux
krraddns1.imzcloud.ibmammsap.local --- 10.139.120.17	Windows


634  df -hT /usr/sap/SD1/SUM
  635  pvs
  636  vgs sd1tempvg
  637  lsscsi|grep sdh
  638  lsof /usr/sap/SD1/SUM
  639  umount /usr/sap/SD1/SUM
  640  umount -l /usr/sap/SD1/SUM
  641  lvremove /dev/mapper/sd1tempvg-sd1temp_lv
  642  lvchange -an /dev/mapper/sd1tempvg-sd1temp_lv
  643  lvremove /dev/mapper/sd1tempvg-sd1temp_lv
  645  pvs
  646  vgremove sd1tempvg
  647  pvdisplay -m /dev/sdh
  648  pvremove /dev/sdh
  649  echo 1 > /sys/block/sdh/device/delete
  650  pvs
  651  vi /etc/fstab


[root@IA1S4HDEVAPP ~]$ df -hT /usr/sap/SD1/SUM
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/sd1tempvg-sd1temp_lv ext3   97G   41G   52G  44% /usr/sap/SD1/SUM

[root@IA1S4HDEVAPP ~]$ pvs
  PV         VG        Fmt  Attr PSize     PFree
 /dev/sdh   sd1tempvg lvm2 a--   <100.00g 1020.00m


[root@IA1S4HDEVAPP ~]$ vgs sd1tempvg
  VG        #PV #LV #SN Attr   VSize    VFree
  sd1tempvg   1   1   0 wz--n- <100.00g 1020.00m
You have new mail in /var/spool/mail/root
[root@IA1S4HDEVAPP ~]$ lsscsi|grep sdh
[0:0:8:0]    disk    VMware   Virtual disk     1.0   /dev/sdh


[root@IA1S4HQASAPP ~]$ df -hT /usr/sap/SQ1/stage
Filesystem                   Type  Size  Used Avail Use% Mounted on
/dev/mapper/stagevg-stage_lv ext4   97G   40G   53G  44% /usr/sap/SQ1/stage

[root@IA1S4HQASAPP ~]$ vgs stagevg
  VG      #PV #LV #SN Attr   VSize    VFree
  stagevg   1   1   0 wz--n- <100.00g 1020.00m
You have mail in /var/spool/mail/root

[root@IA1S4HQASAPP ~]$ pvs |grep -i stagevg
  /dev/sdf   stagevg  lvm2 a--  <100.00g 1020.00m

[root@IA1S4HQASAPP ~]$ lsscsi|grep sdf
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf




[root@IA1FIODEVAPP ~]$ df -hT /usr/sap/FD1/SUM
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/fd1tempvg-fd1temp_lv ext3   97G   43G   50G  46% /usr/sap/FD1/SUM

[root@IA1FIODEVAPP ~]$ vgs fd1tempvg
  VG        #PV #LV #SN Attr   VSize    VFree
  fd1tempvg   1   1   0 wz--n- <100.00g 1020.00m
You have new mail in /var/spool/mail/root

[root@IA1FIODEVAPP ~]$ pvs
  PV         VG        Fmt  Attr PSize    PFree
  /dev/sda2  rootvg    lvm2 a--   <39.51g       0
  /dev/sda3  rootvg    lvm2 a--   <56.00g  <12.50g
  /dev/sdb   fd1appvg  lvm2 a--  <128.00g       0
  /dev/sdd   fd1appvg  lvm2 a--   <32.00g  <26.00g
  /dev/sde   swapvg    lvm2 a--   <62.00g       0
  /dev/sdf   fd1tempvg lvm2 a--  <100.00g 1020.00m

[root@IA1FIODEVAPP ~]$ lsscsi|grep sdf
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf


krrdbtst.imzcloud.ibmammsap.local --- 10.139.128.19	retired
krrtpvasopdb1.imzcloud.ibmammsap.local --- 10.139.120.21	Windows
krrdbprd1.imzcloud.ibmammsap.local --- 10.139.120.46	Linux
krraddns1.imzcloud.ibmammsap.local --- 10.139.120.17	Windows


Those activities should be:

1-Unmount old SAP GTD Server, IP 10.80.1.18(CONSPGWAPD 10.16.1.18), transport directory (/usr/sap/trans , if exists) on SAP GTP O.S Server, IP 10.80.1.94(CONSPGWAPP 10.16.1.97).
2-Mount the remote directory (/usr/sap/trans) from SAP GTD Server in Google, IP 10.90.200.14: mount IP 10.90.200.14:/usr/sap/trans /usr/sap/trans or/and add in /etc/fstab: 10.90.200.14:/usr/sap/trans     /usr/sap/trans         nfs     defaults        0  0.

[root@conspgwapp ~]$ df -hT /usr/sap/trans
Filesystem           Type  Size  Used Avail Use% Mounted on
10.80.1.18:/usr/sap/trans
                     nfs    40G   16G   23G  41% /usr/sap/trans



CS12161454	done
CS12161442	done
CS12160640	auto cleared
CS12159638	done
CS12159636	auto cleared
CS12159632	auto cleared



Implement  Kdump | Oscar feature in the following list of servers:	number:CS3061973
wa2rsqadb1      10.191.1.9		ammdal13seiesx034.imzcloud.ibmammsap.local
wa2s1qadb1     10.191.1.62		ammdal13seiesx031.imzcloud.ibmammsap.local
WA2PRXYQAS1   10.191.1.61		ammdal13seiesx026.imzcloud.ibmammsap.local



CS12173438
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogypxn001#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)

CS12173054
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogypxn004#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)

CS12172744
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogypxp021#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)

CS12172122
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogyppm030#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)

CS12172106
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogypgr033#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)

CS12172105
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogysm2028#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)

CS12172045
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogypxp022#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)

CS12171163
The Ogilvy Group Inc -- OGY
P2 - Major
ogy#ogysj1029#(Escalated after RPO Threshold of 120 minutes):Virtual machine vSphere Replication RPO is violated by 1 minute(s)




[root@bapv330900 ~]# cat /etc/fstab |grep -i swap
/dev/rootvg/pageing00   swap    swap    defaults 0 0

[root@bapv330900 ~]# vgs rootvg
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   3   9   0 wz--n- 209.48g 86.48g

[root@bapv330900 ~]# free -gh
             total       used       free     shared    buffers     cached
Mem:           61G       6.2G        55G       396M       357M       3.6G
-/+ buffers/cache:       2.2G        59G
Swap:          47G       3.3G        44G


BPA -- mcllabpa01 -- 10.138.0.24  
BPA -- mcllabpa11 -- 10.138.0.26 
BPA -- mclldbpa01 -- 10.138.0.15 --- DB Server
BPA -- mclldbpa11 --10.138.0.29 --- DB Server


 Node mcllabpa11:
* Node mcllabpa01:


CHG0258853	18-10-2022 07:00:00	18-10-2022 11:00:00
Please remove the filesystems as given  below for the respective servers.

IA2S4HDEVAPP 10.133.16.42 /usr/sap/SD5/SUM	DONE
IA2MDGDEVAPP 10.133.16.73 /usr/sap/GD5/SUM	DONE
IA2FIODEVDBAP 10.133.16.43 /usr/sap/FD5/SUM	DONE

IA2S4HQASAPP 10.133.17.158 /usr/sap/SQ5/stage	DONE
IA2MDGQAAPP 10.133.17.156 /usr/sap/GQ5/stage	DONE
IA2FIOQASDBAP 10.133.17.159 /usr/sap/FQ5/stage	DONE


CHG0257319 , CHG0257570, 




CS12195857
Meggitt
 PLC -- MGG
P2 - Major
mgg#mgggbjqeccy05#Service crond CRITICAL: 0 crond processes running (thresh 1:)





CS12195862
Meggitt
 PLC -- MGG
P2 - Major
mgg#mgggbjqgtsy03#Service crond CRITICAL: 0 crond processes running (thresh 1:)





CS12195883
Meggitt
 PLC -- MGG
P2 - Major
mgg#mgggbjqgtsy04#Service crond CRITICAL: 0 crond processes running (thresh 1:)




CHG0257570 19-10-2022 07:30:00	19-10-2022 11:30:00
This 10/18/2022 - 21:00 - NIX  remediation is for the following CIs:



Source IP-185.129.225.1 (185.129.225.1)

Destination: IP-66.248.244.13 (66.248.244.13)

port : 3200



CHG0257219 10/21/2022 - 11:00 - NIX - LBU - PATCH - Q4 2022- Troop B(SAPB2) - Batch Q1-2/ Q2-3A (7 servers)
CHG0257222 10/21/2022 - 11:00 - NIX - LBU - PATCH - Q4 2022- Troop B(SAPB2) - Batch Q1-1 (10 servers)
CHG0257223 10/21/2022 - 11:00 - NIX - LBU - PATCH - Q4 2022- Troop B(SAPB2) - Batch Q2-1 (8 servers)



CHG0255325 10/20/2022 - 20:00 - NIX - AGE - PATCH - Q3,Q4 2022 - Troop C(SAPB1) 21-10-2022 06:30:00	21-10-2022 14:30:
svcq1srv0	A0EASG014XVM017	Red Hat Enterprise Linux Server 6.10 (Santiago)        10.6.2.16       Development		xq1,cq1-SAP LOB  
sveq1srv0	A0EASG014XVM001	Red Hat Enterprise Linux Server 6.10 (Santiago)        10.6.2.11       QA		eq1,rq1-SAP LOB  
agesvcqmhsrv1	SUSE Linux Enterprise Server 12 SP4 12.4        10.6.2.72       QA		bq1,cqm-SAP LOB-hdb  
agesveqmhsrv1	SUSE Linux Enterprise Server 12 SP4 12.4        10.6.2.71       QA		eqm-SAP LOB-hdb  
svjq1srv0	A0EASG014XVM004	Red Hat Enterprise Linux Server 6.10 (Santiago)        10.6.2.12       QA		jq1-SAP LOB  
svlq1srv0	A0EASG014XVM023	Red Hat Enterprise Linux Server 6.10 (Santiago)        10.6.2.19       QA		lq1-SAP LOB-syb  




/dev/mapper/eq1appvg-eq1usrEQ1_lv           ext3    24G  8.4G   15G  38% /usr/sap/EQ1

/dev/eq1appvg/eq1usrEQ1_lv    /usr/sap/EQ1  ext3        defaults    1 2


/dev/mapper/eq1appvg-eq1usrEQ1_lv
                     ext3   6.9G  3.9G  2.7G  59% /usr/sap/EQ1
					 
					 
					 
[root@sveq1srv0 EQ1]# df -hT .
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/eq1appvg-eq1usrEQ1_lv
                     ext3   24G  8.4G   15G  38% /usr/sap/EQ1

/dev/eq1appvg/eq1usrEQ1_lv    /usr/sap/EQ1  ext3        defaults    1 2


Name	Class
SJMPWDAA01	Linux Server
SJMDEPAA01	Linux Server
SJMPEPAA01	Linux Server
SJMPPQDB01	Linux Server
SJMPCPDB01N	Linux Server
SJMPCPAA02	Linux Server
SJMPPQAA01	Linux Server
SJMQWDAA01	Linux Server
SJMQPQDB01	Linux Server
SAPDPQDB01	Linux Server
SJMDPQJA01	Linux Server
SJMQCPDB01N	Linux Server
SJMDCPDB01N	Linux Server
SJMQBDBA01	Linux Server
SJMPBJDB01	Linux Server
SJMDFPAA01	Linux Server
SJMDCPAA01	Linux Server
SJMDWDWD01	Linux Server
SJMPPQAA02	Linux Server
SJMPEPAA02	Linux Server
SJMPFPAA01	Linux Server
SJMQEPAA01	Linux Server
SJMQFPAA01	Linux Server
SJMPCPAA01	Linux Server
SJMPEPDB01N	Linux Server
SJMQPQJA01	Linux Server
SJMQCPAA01	Linux Server
SJMQEPDB01N	Linux Server
SJMDBJDB01	Linux Server
SJMDEPDB01N	Linux Server


S12236031
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:30:22
P1 - Severe
hfc#hfcsjphndb1#Resource Pacemaker sbd Error signing on to the CIB service: Transport endpoint is not connected





CS12236053
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:30:30
P1 - Severe
hfc#hfcsjphndb1#Resource Pacemaker Colocation ERROR: status: crm_mon (rc=107): Error: cluster is not available on this node





CS12236060
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:30:34
P1 - Severe
hfc#hfcsjphndb1#Resource Pacemaker Colocation ERROR: status: crm_mon (rc=107): Error: cluster is not available on this node





CS12236073
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:30:57
P1 - Severe
hfc#hfcsjphndb1ha#Log PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-10-23-01-09-40 for





CS12236081
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:31:05
P1 - Severe
hfc#hfcsjphndb1ha#Log PaceMaker-log Found 1 errors. See /usr/local/ncpa/var/log/protocolfiles/cmas_logscanner_checklog_filters.protocol-2022-10-23-01-19-46 for





CS12236082
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:31:05
P1 - Severe
hfc#hfcsjphndb1#Resource Pacemaker Active Nodes CRITICAL: /usr/local/ncpa/var/log/HKABl8oJ





CS12236085
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:31:15
P1 - Severe
hfc#hfcsmphndb1#Resource Pacemaker Colocation CRITICAL: Colocation Failure - Master/Slave Set: msl_SAPHana_SMP_HDB02 [rsc_SAPHana_SMP_HDB02] - rsc_ip on hfcsmph





CS12236091
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:31:29
P1 - Severe
hfc#hfcsjphndb1ha#Resource Pacemaker TSM Error signing on to the CIB service: Transport endpoint is not connected





CS12236089
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:31:29
P1 - Severe
hfc#hfcsmphndb1ha#Resource Pacemaker Colocation ERROR: status: crm_mon (rc=107): Error: cluster is not available on this node





CS12236096
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:31:46
P1 - Severe
hfc#hfcsmphndb1ha#Resource Pacemaker Active Nodes CRITICAL: /usr/local/ncpa/var/log/u6W0eVk1





CS12236122
HollyFrontier
 Corporation -- HFC
HFC
 IC4SAP-SL SAP LOB
Incident
10-23-2022 18:38:04
P1 - Severe
hfc#hfcsmphndb1ha#Resource Pacemaker TSM Error signing on to the CIB service: Transport endpoint is not connected



krrdbtst.imzcloud.ibmammsap.local --- 10.139.128.19		Linux	Test Connectivity - Ansible success
krrtpvasopdb1.imzcloud.ibmammsap.local --- 10.139.120.21	Windows
krrdbprd1.imzcloud.ibmammsap.local --- 10.139.120.46	Linux	Test Connectivity - Ansible success
krraddns1.imzcloud.ibmammsap.local --- 10.139.120.17	Windows



aprscmprd - Add disc 2.5GB + 2.5GB on both the sites FRA and PAR. As this server is part of DR. Post adding the disk please expand to (/db2/db2<sid>)more to this FS on each server.

aprscmdev - Add disc of 2.5GB. Post adding the disk please expand to (/db2/db2<sid>)more to this FS on each server

aprerpqas - Add disc of 80GB. Post adding the disk please expand to /dev/mapper/a11logvg-db2_A11_log_dir_lv ext4 80G 76G 211M 100% /db2/A11/log_dir




CS12082983	ftp disable
CS12082961	ftp disable
CS12082909	ftp disable
CS12082873	ftp disable
CS12082816	ftp disable


CS12208104	long list ansible

CS12208034	closed
CS12208001	closed

CS12206769	closed

CS12207427	to windows
CS12206405	to windows
CS12196642	to windows
CS12182236	to windows
CS12173734


CHG0257227 10/28/2022 - 10:00 - NIX - LBU - PATCH - Q4 2022- Troop B(SAPB2) - Batch- PP-1/Q2-2 (10 servers)
CHG0257225 10/28/2022 - 10:00 - NIX - LBU - PATCH - Q4 2022- Troop B(SAPB2) - Batch PP-2/QS2-3 (8 servers)



[14:23] Kavya Mini Soman
    



CS12267614
Perkinelmer, Inc. -- PRK
prk#npsv10rapp#10.151.0.188(10.151.0.188) is unreachable. The host has failed to respond to the ping request.
P1 - Severe
NPSV10RAPP
SQ-SAP-TRIO-B2

CS12267610
Perkinelmer, Inc. -- PRK
prk#prdb11#10.151.0.114(10.151.0.114) is unreachable. The host has failed to respond to the ping request.
P1 - Severe
PRDB11
SQ-SAP-TRIO-B2

CS12267615
Perkinelmer, Inc. -- PRK
prk#prvm119#10.151.0.77(10.151.0.77) is unreachable. The host has failed to respond to the ping request.
P1 - Severe
PRVM119
SQ-SAP-TRIO-B2

CS12267616
Perkinelmer, Inc. -- PRK
prk#npsv81#10.151.0.22(10.151.0.22) is unreachable. The host has failed to respond to the ping request.
P1 - Severe
NPSV81
SQ-SAP-TRIO-B2

CS12267613
Perkinelmer, Inc. -- PRK
prk#npsbx11#10.151.0.117(10.151.0.117) is unreachable. The host has failed to respond to the ping request.
P1 - Severe
NPSBX11
SQ-SAP-TRIO-B2

CS12267611
Perkinelmer, Inc. -- PRK
prk#npsvd107#10.151.0.124(10.151.0.124) is unreachable. The host has failed to respond to the ping request.
P1 - Severe
NPSVD107
SQ-SAP-TRIO-B2

CS12267612
Perkinelmer, Inc. -- PRK
prk#prsvp107#10.151.0.123(10.151.0.123) is unreachable. The host has failed to respond to the ping request.
P1 - Severe
PRSVP107
SQ-SAP-TRIO-B2





CS12137232	malgorzata.tylkowska@kyndryl.com
CS12137231		
CS12136373
CS12136261
CS12136247

Amul complaint no 2205729




Nov  1 22:07:12 gknadsprddbh kernel: [    0.028000] NMI watchdog: Shutting down hard lockup detector on all cpus
Nov  1 22:07:21 gknadsprddbh systemd[2263]: Reached target Shutdown.
Nov  1 22:10:31 gknadsprddbh systemd[12647]: Reached target Shutdown.
Nov  1 22:12:02 gknadsprddbh systemd[13246]: Reached target Shutdown.
Nov  1 22:15:01 gknadsprddbh systemd[20237]: Reached target Shutdown.
Nov  1 22:15:02 gknadsprddbh systemd[20233]: Reached target Shutdown.
[root@gknadsprddbh ~]$ date
Tue Nov  1 22:16:38 EDT 2022




[root@gknadsprddbh ~]$ cat /var/log/messages |grep -i fence
Nov  1 22:05:34 gknadsprddbh pengine[28774]:  warning: Cluster node gknadsprddbh will be fenced: ITM_EPJ_DB2 failed there
Nov  1 22:05:36 gknadsprddbh pengine[28774]:   notice: Stop of failed resource ITM_EPJ_DB2 is implicit after gknadsprddbh is fenced
Nov  1 22:05:36 gknadsprddbh pengine[28774]:   notice:  * Fence (reboot) gknadsprddbh 'ITM_EPJ_DB2 failed there'
Nov  1 22:20:01 gknadsprddbh crmd[27744]:   notice: Fencer successfully connected


[root@gknadsprddbh ~]$ cat /var/log/messages |grep -i cannot
Nov  1 22:07:12 gknadsprddbh kernel: [    0.104227] pmd_set_huge: Cannot satisfy [mem 0xf0000000-0xf0200000] with a huge-page mapping due to MTRR override.

[Tue Nov  1 22:07:25 2022] tmhook: module verification failed: signature and/or required key missing - tainting kernel
[root@gknadsprddbh ~]$


[root@gknadsprddbh ~]$ cat /proc/mtrr
reg00: base=0x000000000 (    0MB), size=16384MB, count=1: write-back
reg01: base=0x0c0000000 ( 3072MB), size= 1024MB, count=1: uncachable


Sev1 CS12295922 gkn#gknadsprddbh#Host Reboot CRITICAL: Uptime 0 minutes (thresh 30 min)
    

SuSE case Support Cases  00374197

CHG0260672
Patch Group (QA1) - sm9d185183002	SUSE	10.135.226.109	QA	Q11 - SAP  (App/DB) - DB2 10.5
Patch Group (QA1) - sm9d185183003	SUSE	10.135.226.125	QA	Q33 - SAP  (App/DB) - DB2 10.5
Patch Group (QA1) - sm9csgclx02	SUSE	10.135.226.179	QA	Q33 - SAP  (DB) - HANA			fra02-pod2-4tb-host11.imzcloud.ibmammsap.local
Patch Group (Dev1) - sm9d185183001	SUSE	10.135.226.24	Development	T11 - SAP  (App/DB) - DB2 10.5
Patch Group (Dev1) - sm9d185183004	SUSE	10.135.226.15	Development	T34 - SAP  (App/DB) - DB2 10.5
Patch Group (Dev1) - sm9v235492015	SUSE	10.135.226.17	Development	T14 - SAP  (App/DB) - DB2 10.5
Patch Group (Dev1) - sm9csgclx01	SUSE	10.135.226.54	Development	T33 - SAP  (DB) - HANA
Patch Group (Dev1) - sm9erp-sbx	SUSE	10.135.226.92	Development	<SID> - SAP <Landscape> (App/DB)
Patch Group (QA2) - sm9v235492019	SUSE	10.135.227.67	QA	Q16 - SAP  (App/DB) - DB2 10.5
Patch Group (Dev2) - sm9d185183013	SUSE	10.135.226.37	QA	T20 - SAP  (App/DB) - DB2 10.5



right click the vm
hit migrate
hit change computer resource
select resource pool  ( be careful do not move cluster or hosts, select resource pool )
select the resource pool  and hit next, next and finish



CHG0260675	04-11-2022 01:30:00	04-11-2022 13:30:00
Patch Group (Dev3) - sm9l184932037	SUSE	10.135.226.43	QA	GTD - SAP  (App/DB) - DB2 10.5
Patch Group (Dev3) - sm9v235652010	SUSE	10.135.226.25	Development	GRD - SAP  (App/DB) - DB2 10.5
Patch Group (Dev3) - sm9d18493061	SUSE	10.135.226.22	Development	GWD - SAP  (App/DB) - DB2 10.5
Patch Group (Dev2) - sm9l184932034	SUSE	10.135.226.39	Development	BWD - SAP  (App/DB) - DB2 10.5
Patch Group (Dev2) - sm9d184932042	SUSE	10.135.228.15	Development	EWD - SAP  (App) - NA
Patch Group (Dev2) - sm9v184932032	SUSE	10.135.226.42	Development	ECD - SAP  (App/DB) - DB2 10.5
Patch Group (Dev2) - sm9d18493056	SUSE	10.135.226.29	QA	CED - SAP  (App/DB) - DB2 10.5



lbuponss02.imzcloud.ibmammsap.local --- 10.139.32.159	linux
lbuvd1ap01.imzcloud.ibmammsap.local --- 10.139.32.179	WINDOWS
lbuqa2ih01.imzcloud.ibmammsap.local --- 10.139.32.189	WINDOWS
lbuqo1ap02.imzcloud.ibmammsap.local --- 10.139.32.47	WINDOWS
lbudo1ap01.imzcloud.ibmammsap.local --- 10.139.32.50	WINDOWS
lbujumpserver.imzcloud.ibmammsap.local --- 10.139.10.159	Windows
lbupfnpt01.imzcloud.ibmammsap.local --- 10.139.10.162	Linux
lbuponss01.imzcloud.ibmammsap.local --- 10.139.10.188	LINUX
lbuvx1db01.imzcloud.ibmammsap.local --- 10.139.32.172	WINDOWS
lbuvx1ap02.imzcloud.ibmammsap.local --- 10.139.32.182	WINDOWS
lbuvx1ap01.imzcloud.ibmammsap.local --- 10.139.32.137	WINDOWS




CHG0262170 	IAG HANA upscale

10.143.69.218
root M84esPvR2U


CS12377872
Tata Steel Limited -- TTA
tta#sapapp37#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPAPP37- KB0010973
P2 - Major
SAPAPP37

CS12377929
Tata Steel Limited -- TTA
tta#ttactrl01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTACTRL01- KB0010973
P2 - Major
TTACTRL01

CS12377922
Tata Steel Limited -- TTA
tta#ttas4happ-ha#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTAS4HAPP-HA- KB0010973
P2 - Major
TTAS4HAPP-HA

CS12377886
Tata Steel Limited -- TTA
tta#tpeccprddbci#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TPECCPRDDBCI- KB0010973
P2 - Major
TPECCPRDDBCI

CS12377812
Tata Steel Limited -- TTA
tta#ewmapp3-ha#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on EWMAPP3-HA- KB0010973
P2 - Major
EWMAPP3-HA

CS12377921
Tata Steel Limited -- TTA
tta#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ttas4hpdb- KB0010973
P2 - Major
ttas4hpdb

CS12377801
Tata Steel Limited -- TTA
tta#biprdapp1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on BIPRDAPP1- KB0010973
P2 - Major
BIPRDAPP1

CS12377915
Tata Steel Limited -- TTA
tta#ttaprojqadb#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTAPROJQADB- KB0010973
P2 - Major
TTAPROJQADB

CS12377790
Tata Steel Limited -- TTA
tta#asddev#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ASDDEV- KB0010973
P2 - Major
ASDDEV

CS12377930
Tata Steel Limited -- TTA
tta#ttawebdprd#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTAWEBDPRD- KB0010973
P2 - Major
TTAWEBDPRD

CS12377807
Tata Steel Limited -- TTA
tta#crmdevapp#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on CRMDEVAPP- KB0010973
P2 - Major
CRMDEVAPP

CS12377864
Tata Steel Limited -- TTA
tta#sapapp23#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPAPP23- KB0010973
P2 - Major
SAPAPP23

CS12377926
Tata Steel Limited -- TTA
tta#tscmlprd#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TSCMLPRD- KB0010973
P2 - Major
TSCMLPRD

CS12377925
Tata Steel Limited -- TTA
tta#ttajcaphdb#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTAJCAPHDB- KB0010973
P2 - Major
TTAJCAPHDB

CS12377774
Tata Steel Limited -- TTA
tta#adsprds#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ADSPRDS- KB0010973
P2 - Major
ADSPRDS

CS12377874
Tata Steel Limited -- TTA
tta#sapapp42#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPAPP42- KB0010973
P2 - Major
SAPAPP42

CS12377888
Tata Steel Limited -- TTA
tta#tpeccapp2#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TPECCAPP2- KB0010973
P2 - Major
TPECCAPP2

CS12377809
Tata Steel Limited -- TTA
tta#essmssdev#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ESSMSSDEV- KB0010973
P2 - Major
ESSMSSDEV

CS12377877
Tata Steel Limited -- TTA
tta#sapbowapp#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPBOWAPP- KB0010973
P2 - Major
SAPBOWAPP

CS12377913
Tata Steel Limited -- TTA
tta#sapapp31-ha#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPAPP31-HA- KB0010973
P2 - Major
SAPAPP31-HA

CS12377822
Tata Steel Limited -- TTA
tta#ewmqa#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on EWMQA- KB0010973
P2 - Major
EWMQA

CS12377829
Tata Steel Limited -- TTA
tta#ewmapp1#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on EWMAPP1- KB0010973
P2 - Major
EWMAPP1

CS12377821
Tata Steel Limited -- TTA
tta#ewmapp3#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on EWMAPP3- KB0010973
P2 - Major
EWMAPP3

CS12377811
Tata Steel Limited -- TTA
tta#ewmdev#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on EWMDEV- KB0010973
P2 - Major
EWMDEV

CS12377873
Tata Steel Limited -- TTA
tta#sapbidev#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPBIDEV- KB0010973
P2 - Major
SAPBIDEV

CS12377810
Tata Steel Limited -- TTA
tta#essmssdev-dr#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on ESSMSSDEV-DR- KB0010973
P2 - Major
ESSMSSDEV-DR

CS12377924
Tata Steel Limited -- TTA
tta#ttas4hpdb-dr#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TTAS4HPDB-DR- KB0010973
P2 - Major
TTAS4HPDB-DR

CS12377918
Tata Steel Limited -- TTA
tta#tsgpprd#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TSGPPRD- KB0010973
P2 - Major
TSGPPRD

CS12377875
Tata Steel Limited -- TTA
tta#sapbodev#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPBODEV- KB0010973
P2 - Major
SAPBODEV

CS12377876
Tata Steel Limited -- TTA
tta#sapbiqa01#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on SAPBIQA01- KB0010973
P2 - Major
SAPBIQA01

CS12377887
Tata Steel Limited -- TTA
tta#tpjump#Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running on TPJUMP- KB0010973
P2 - Major
TPJUMP




havhav1008- remove 1024GB disk added accidently

CHG0257029 17-11-2022 07:30:00	17-11-2022 12:30:00
ia1podevdb    Red Hat Enterprise Linux 8.2 (Ootpa)        10.133.16.31       Development        pd1-SAP LOB-syb	storage migration from  IA1UK016BCB231 in A0B4UK01 to ammlon02custesx075.imzcloud.ibmammsap.local , IA1UK016BCB232 in A0B4UK01	Snapshot taken
ia1weddspdev1    Red Hat Enterprise Linux 8.2 (Ootpa)        10.133.16.22       Development        wd1-SAP LOB	snapshot taken
ia1podevapp    Red Hat Enterprise Linux 8.2 (Ootpa)        10.133.16.32       Development        pd1-SAP LOB   IA1UK016BCB230 in A0B4UK01 to ammlon02custesx075.imzcloud.ibmammsap.local , IA1UK016BCB232 in A0B4UK01	snapshot taken
ia1hccdevwd    Red Hat Enterprise Linux 8.2 (Ootpa)        10.133.16.37       Development        wd2-SAP LOB	 IA1UK016BCB231 in A0B4UK01 to ammlon02custesx077.imzcloud.ibmammsap.local , IA1UK016BCB232 in A0B4UK01
ia1hcidevapp	snapshot taken




hfcsjphndb1dr
Linux Server
Production
WDC04-SL
US-Washington 04 [3.x]
HFC
HollyFrontier Corporation -- HFC
IC4SAP-SL
SAPB2
10.92.227.8
10.28.27.28

hfcsmphndb1dr
Linux Server
Production
WDC04-SL
US-Washington 04 [3.x]
HFC
HollyFrontier Corporation -- HFC
IC4SAP-SL
SAPB2
10.92.227.17
10.28.27.23

uspokdchd01
Linux Server
Development
WDC04-SL
US-Washington 04 [3.x]
ZEC
Tech Data Corporation -- ZEC
IC4SAP-SL
SAPB2
10.25.213.36

hfcsjphndb1dr - 10.92.227.8
hfcsmphndb1dr - 10.92.227.17
uspokdchd01 - 10.25.213.36

CS12380568 - OTAS Prod Folder Copy for IA1
CS12380584 - OTAS Prod Folder Copy for IA2


YAWFPETHBJK
NUXAUV77RX7


approve 
CHG0256195	Done

CHG0262966	DPE approval missing


CHG0255337	19-11-2022 07:30:00	19-11-2022 13:30:00
agehvcpmhsrv2		che01-pod1-4tb-host02.imzcloud.ibmammsap.local
agehvepmhsrv3		che01-pod1-6tb-host004.imzcloud.ibmammsap.local

#supportconfig -i BOOT
#cp /boot/initrd-4.12.14-95.93-default /root/initrd-4.12.14-95.93-default-after-update
#cp /boot/vmlinuz-4.12.14-95.93-default /root/vmlinuz-4.12.14-95.93-default-after-update
#cp /boot/grub2/grub.cfg /root/grub.cfg-after-update 



DR - agehvcpmhsrv2    10.8.3.130    10.70.112.132
Primary - agesvcpmhsrv1    10.6.3.59    10.70.111.60



DR - agehvepmhsrv3    10.8.3.163    10.70.112.139
Primary - agesvepmhsrv2    10.6.3.89    10.70.111.89


pdrs4prd2d    Suse Enterprise 15 SP2 for SAP        10.25.134.116      Production        ecp-SAP LOB-hdb
pdrs4prd2dbha    Suse Enterprise 15 SP2 for SAP        10.25.134.81       Production        ecp-SAP LOB-hdb  



pdrs4prd2ap    Suse Enterprise 15 SP2 for SAP APP    10.25.134.61       Production        ecp-SAP LOB
pdrs4prd2apha    Suse Enterprise 15 SP2 for SAP APP    10.25.134.64       Production        ecp-SAP LOB

172.21.94.233	Ubuntu KVM
ibmrmalik
WelcomeIndia@12345


Approve change
CHG0263255


Approve
CHG0261709 - IAG - IA1
CHG0261713 - IAG - IA2



CHG0262780	23-11-2022 07:30:00	23-11-2022 11:30:00
Patch Group (2.1) - dg1erpslmdg	Redhat	10.143.30.12	Development	SMA,SMJ - SAP  (App/DB) - Sybase ASE	1.27TB 589GB	DG1DAL13CAB162	11.72TB 9.12TB		Snapshot size is 588GB
Patch Group (1.1) - dg1erpdevdg	Redhat	10.143.31.11	Development	DEV - SAP  (App/DB) - Sybase ASE	1.59TB 1.32TB DAL13POOL1POD1DSP390	23.44TB 20.01TB		Snapshot is 1.32TB

CHG0263255	23-11-2022 07:00:00	25-11-2022 23:59:59
SLES 15 upgrade for LON proxies



Connect-VIServer -Server 146.89.142.201 -User imzcloud\ibmrmalik -Password 'Nov2022&Jan2023'


#password   requisite pam_pwquality.so try_first_pass local_users_only retry=3 authtok_type=




RJP - Raj Petro Specialities Pvt Ltd






[root@tqanerpprdapp ~]# cat /etc/hosts |grep -i 130.214.87.207
130.214.87.207  I500281-iflmap.hcisbp.eu3.hana.ondemand.com

[root@tqanerpprdapp ~]# cat /etc/hosts |grep -i l500281-iflmap.hcisbp.eu3.hana.ondemand.com
157.133.141.174 l500281-iflmap.hcisbp.eu3.hana.ondemand.com


[root@tqanerpprdapp ~]# cat /etc/hosts |grep -i 130.214.87.207
130.214.87.207  I500281-iflmap.hcisbp.eu3.hana.ondemand.com




ttas4happ - app cluster node

ttas4happ-ha - app cluster node

ttas4hpdb - db cluster node

ttas4hpdb-ha - db cluster node

ttas4hanaqdb

tsls4hmckdb2

tpsolman



rexjumpsrvr.imzcloud.ibmammsap.local --- 10.135.1.42	WIndows predeployment
rexpbfcweb3.imzcloud.ibmammsap.local --- 10.135.1.16	WIndows
rexppaweb1n.imzcloud.ibmammsap.local --- 10.135.1.12	WINDOWS
rexqpaeng1n.imzcloud.ibmammsap.local --- 10.135.2.11	WINDOWS
rexqpaweb1n.imzcloud.ibmammsap.local --- 10.135.2.16	WINDOWS
rexppaeng1n.imzcloud.ibmammsap.local --- 10.135.1.8		WINDOWS
rexqbfcweb2.imzcloud.ibmammsap.local --- 10.135.2.20	WINDOWS
rexqbfcapp2.imzcloud.ibmammsap.local --- 10.135.2.46	WINDOWS
rexpbfctse2.imzcloud.ibmammsap.local --- 10.135.1.29	WINDOWS
rexpbfcapp2.imzcloud.ibmammsap.local --- 10.135.1.13	WINDOWS
rexpbfcweb2.imzcloud.ibmammsap.local --- 10.135.1.11	WINDOWS
rexqbfctse2.imzcloud.ibmammsap.local --- 10.135.2.66	WINDOWS
REXQBFCHANA1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.199	LINUX	Login not working
REXPCGSAPP3.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.1.68	WINDOWS
REXQBFCWEB1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.201	WINDOWS
REXPCGSWEB1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.1.70	WINDOWS
REXBFCTSE1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.203	WINDOWS
REXQBFCAPP1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.200	WINDOWS
REXBFCSSAS1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.202	WINDOWS
REXPCGSAPP2.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.1.67	WINDOWS
REXWTSDEV01.IMZCLOUD.IBMAMMSAP.LOCAL --- 169.254.72.4	WINDOWS
REXQCGSSQL1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.198	WINDOWS
REXRED-DC15PRO.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.204	WINDOWS
REXPCGSAPP4.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.1.69	WINDOWS
REXPCGSSQL1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.1.65	WINDOWS
REXPCGSAPP1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.1.66	WINDOWS
REXQCGSAPP1.IMZCLOUD.IBMAMMSAP.LOCAL --- 10.135.2.197	WINDOWS
rexbfcweb01n.hgm.imzcloud.ibmammsap.local --- rexbfcweb01n.imzcloud.ibmammsap.local	WINDOWS
rexbfcapp2n.hgm.imzcloud.ibmammsap.local --- rexbfcapp2n.imzcloud.ibmammsap.local	WINDOWS
rexbfcapp1n.hgm.imzcloud.ibmammsap.local --- rexbfcapp1n.imzcloud.ibmammsap.local	WINDOWS
rexbfcweb02.hgm.imzcloud.ibmammsap.local --- rexbfcweb02.imzcloud.ibmammsap.local	WINDOWS
rexbfcapp1n.hgm.imzcloud.ibmammsap.local_tmp_test --- 10.135.1.101	WINDOWS



CHG0264208   is on 05,06 and 07 of dec 2022

CHG0264209 is on 07,08 and 09 of dec 2022



st xaviers
hkg 


tdmprdhana.imzcloud.ibmammsap.local --- 10.4.20.6
tdmdevhana.imzcloud.ibmammsap.local --- 10.4.20.139
tdmqashana.imzcloud.ibmammsap.local --- 10.4.20.142

The ip mentioned in the ticket does not have any server associated

tdmprdhana.imzcloud.ibmammsap.local --- 10.4.20.6
Correct imz ip is 10.4.20.9
fatal: [tdmprdhana.imzcloud.ibmammsap.local]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 10.4.20.6 port 22: Connection timed out", "unreachable": true}


tdmdevhana.imzcloud.ibmammsap.local --- 10.4.20.139
Correct ip is 10.4.20.7
fatal: [tdmdevhana.imzcloud.ibmammsap.local]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 10.4.20.139 port 22: Connection timed out", "unreachable": true}


tdmqashana.imzcloud.ibmammsap.local --- 10.4.20.142
Correct ip is 10.4.20.8
fatal: [tdmqashana.imzcloud.ibmammsap.local]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 10.4.20.142 port 22: Connection timed out", "unreachable": true}


ZFF-RP2
zffpapp011        zffpapp011-ha    zffpapp011    NCP (Primary App)        SAP Aschau CE        SLES 12 SP2    149.223.100.109        
zffpapp013        zffpapp013-ha    zffpapp013    P9P (Primary App)        SAP Aschau SCM        SLES 12 SP2    149.223.100.148    
zffpapp024        zffpapp024-ha    zffpapp024    ADP (Primary App)        SAP HR1            SLES 12 SP4    149.223.100.158        
zffpdb011        zffpdb011-ha    zffpdb011    NCP (Primary DB)        SAP Aschau CE        SLES 12 SP2    149.223.100.114        
zffpdb013        zffpdb013-ha    zffpdb013    P9P (Primary DB)        SAP Aschau SCM        SLES 12 SP2    149.223.100.153        
zffpdb024        zffpdb024-ha    zffpdb024    ADP (Primary DB)        SAP HR1            SLES 12 SP4    149.223.100.163    


ibmdrrmalik  PjBrZ)*5|ODwXre

Jump server
169.51.128.210 


kyndryltest20    VfSrkK%QDYB8kj@

sudo rootsh works

 /usr/local/bin/enable_dr_3.x.py
 
 
 CHG0263805 03-12-2022 09:30:00	03-12-2022 21:30:00
 Increase CPU's/ Memory in spsvepaeapp01 server 
 CPU's and Memory upgrade on spsvepaeapp01 - 
Login to v- center and increase RAM from 32GB to 64GB add another 8cpu's to spsvepaeapp01 server
spsvepaeapp01	10.6.3.12	10.70.111.12

old RAM 32    new RAM 64
old cpu 8     new cpu 16



need 2 TB of storage general purpose SSD

Make in 200 GB each 10 file systems. 


/TSMSTG/CCSTG10
/TSMSTG/CCSTG11
/TSMSTG/CCSTG12
/TSMSTG/CCSTG13
/TSMSTG/CCSTG14
/TSMSTG/CCSTG15
/TSMSTG/CCSTG16
/TSMSTG/CCSTG17
/TSMSTG/CCSTG18
/TSMSTG/CCSTG19

nvme14n1                   259:17   0     2T  0 disk

lvcreate  -L 15G swapvg -n swap_lv


[root@ahcias01tsm01 ~]# df -hT |grep -i TSMSTG
/dev/mapper/tsmcache_vg-tsmccstg2_lv ext4      494G  111G  358G  24% /TSMSTG/CCSTG2
/dev/mapper/tsmcache_vg-tsmccstg1_lv ext4      494G  216G  253G  47% /TSMSTG/CCSTG1


lvcreate  -L 200G tsmcache_vg -n tsmccstg10_lv


mkfs.ext4 /dev/tsmcache_vg/tsmccstg10_lv

LV Path                /dev/tsmcache_vg/tsmccstg10_lv

/dev/tsmcache_vg/tsmccstg10_lv	/TSMSTG/CCSTG10 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg11_lv	/TSMSTG/CCSTG11 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg12_lv	/TSMSTG/CCSTG12 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg13_lv	/TSMSTG/CCSTG13 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg14_lv	/TSMSTG/CCSTG14 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg15_lv	/TSMSTG/CCSTG15 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg16_lv	/TSMSTG/CCSTG16 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg17_lv	/TSMSTG/CCSTG17 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg18_lv	/TSMSTG/CCSTG18 ext4 rw 1 3 
/dev/tsmcache_vg/tsmccstg19_lv	/TSMSTG/CCSTG19 ext4 rw 1 3 



CHG0262641  approval



[root@br3sscmdb16 etc]$ id ibmspeddapalli
uid=196029(ibmspeddapalli) gid=1513(domain_users) groups=1513(domain_users),7625(ibm amm support master access group (global)),11041(amm - sap projects (global)),11074(amm - sap projects (india)),10927(amm - sap admins (global)),10960(amm - sap admins (india)),15705(sapadmins_in),15672(sapadmins_ww),2508(vpn access),18459(sapsys_in),18426(sapsys_ww)

[root@br3tscmdb22 ~]# id ibmspeddapalli
uid=196029(ibmspeddapalli) gid=1513(domain_users) groups=7625(ibm amm support master access group (global)),11041(amm - sap projects (global)),11074(amm - sap projects (india)),10927(amm - sap admins (global)),10960(amm - sap admins (india)),15705(sapadmins_in),15672(sapadmins_ww),2508(vpn access),18459(sapsys_in),18426(sapsys_ww),1513(domain_users)



CHG0258137 and CHG0261355  approval


CHG0264667		08-12-2022 07:00:00	08-12-2022 13:00:00
CST/CDT - 12/07/2022 - 20:30 - NIX - TTA - PATCH - Q3,Q4 2022 - Troop C(SAPB1)	


Patch Group () - ttas4hpdb-dr	Linux	100.64.4.10	Disaster recovery	S4P - SAP HANA (DB)






CS12501247	

[root@z0hqmcsdbap01 ~]# df -hT /sapdb/CSP/sapdata*
Filesystem                                Type  Size  Used Avail Use% Mounted on
/dev/mapper/cspdatavg-sapdbCSPsapdata1_lv xfs    25G   21G  4.5G  83% /sapdb/CSP/sapdata1
/dev/mapper/cspdatavg-sapdbCSPsapdata2_lv xfs    25G   21G  4.5G  83% /sapdb/CSP/sapdata2
/dev/mapper/cspdatavg-sapdbCSPsapdata3_lv xfs    25G   21G  4.5G  83% /sapdb/CSP/sapdata3
/dev/mapper/cspdatavg-sapdbCSPsapdata4_lv xfs    25G   21G  4.5G  83% /sapdb/CSP/sapdata4
[root@z0hqmcsdbap01 ~]# vgs cspdatavg
  WARNING: Couldn't find device with uuid y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  WARNING: VG cspdatavg is missing PV y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  VG        #PV #LV #SN Attr   VSize   VFree
  cspdatavg   2   7   0 wz-pn- 511.99g 391.99g




dd if=/dev/sdxx of=/tmp/sdxx.out bs=1M count=10


vgreduce cspdatavg --removemissing

cspdatavg





[ansible@CI3BODEV ~]$ df -hT /var
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                     ext4  9.8G  5.6G  3.7G  61% /var
[ansible@CI3BODEV ~]$ df -hiT /var
Filesystem           Type Inodes IUsed IFree IUse% Mounted on
/dev/mapper/VolGroup-lv_var
                     ext4   633K  633K     0  100% /var
[ansible@CI3BODEV ~]$ cat /etc/*release
LSB_VERSION=base-4.0-amd64:base-4.0-ia32:base-4.0-noarch:core-4.0-amd64:core-4.0-ia32:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-ia32:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-ia32:printing-4.0-noarch
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Red Hat Enterprise Linux Server release 6.10 (Santiago)
[ansible@CI3BODEV ~]$ uptime
 03:57:09 up 48 days, 21:06,  3 users,  load average: 0.46, 0.25, 0.22

[ansible@CI3BODEV ~]$ sudo su -
sudo: unknown defaults entry `maxseq'
sudo: unable to create /var/log/sudo-io/ansible/00/01/RM: No space left on device
sudo: error initializing I/O plugin sudoers_io


[root@CI3BODEV 00]$ df -hiT /var
Filesystem           Type Inodes IUsed IFree IUse% Mounted on
/dev/mapper/VolGroup-lv_var
                     ext4   633K  382K  252K   61% /var
[root@CI3BODEV 00]$ df -hT /var
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_var
                     ext4  9.8G  3.7G  5.7G  40% /var


[root@CI3BODEV 00]$ tail -2 /usr/local/ncpa/var/log/ncpa_passive.log
2022-12-09 04:32:49,753 25604 INFO Message from NRDP server: OK
2022-12-09 04:32:49,754 25604 INFO Meta output from NRDP server: 227 checks processed.
[root@CI3BODEV 00]$ date
Fri Dec  9 04:34:45 EET 2022
[root@CI3BODEV 00]$ /etc/init.d/ncpa_listener status
NCPA Listener: Service is running. (pid 25578)
[root@CI3BODEV 00]$ /etc/init.d/ncpa_passive status
NCPA Passive: Service is running. (pid 25604)


CHG0264849	09-12-2022 11:30:00	09-12-2022 21:30:00
IA1S4HDEVAPP	360gb	IA1UK016BCB231	14.65   9.91  10.88		
IA1S4HQASAPP	189		IA1UK016BCB230	14.65	10.5	9.67
IA1FIODEVAPP	188		IA1UK016BCB231	14.65   9.91  10.88	
IA1FIOQASAPP	164		IA1UK016BCB230	14.65	10.5	9.67	
IA1FIODEVDB		278		IA1UK016BCB230	14.65	10.5	9.67	
IA1FIOQASDB		310		IA1UK016BCB231	14.65   9.91  10.88	


Snapshots for below
SD1    IA1S4HDEVAPP    10.133.16.19	
SQ1    IA1S4HQASAPP    10.133.17.140
FD1    IA1FIODEVAPP    10.133.16.21
FQ1    IA1FIOQASAPP    10.133.17.142




CHG0264885	09-12-2022 11:30:00	09-12-2022 21:30:00

FD5 IA2FIODEVDBAP	350		IA1UK016BCB231	14.65   9.91  10.88
GD5 IA2MDGDEVAPP	178		LON02POOL2DS200	23.44	21.75	15.73
SD5 IA2S4HDEVAPP	1.08TB	IA1UK016BCB230	14.65	10.5	9.67	cannot take snapshot


FQ5 IA2FIOQASDBAP	382		IA1UK016BCB230	14.65	10.5	9.67	cannot take snapshot
GQ5 IA2MDGQAAPP		259		LON02POOL2DS200	23.44	21.75	15.73	
SQ5 IA2S4HQASAPP	228		IA1UK016BCB230	14.65	10.5	9.67	cannot take snapshot


CHG0264885
CHG0264849


Approve
CHG0258807 CST/CDT - 12/17/2022 - 20:00 - NIX - MM3 - PATCH - HC - Q4 2022- Troop B(SAPB2) - UFP & UEP
CHG0258817 CST/CDT - 12/20/2022 - 20:00 - NIX - MM3 - PATCH - HC -Q4 2022- Troop B(SAPB2) - UEP_DR & UFP_DR



cat /etc/audit/auditd.conf     and change the max log file action to rotate
max_log_file_action = rotate

restart auditd.service but it may not restarta s its disabled so should refresh after the next reboot

https://github.kyndryl.net/CMS/Platform-Support/issues/3560			AGEAS ansible install
https://github.kyndryl.net/CMS/cms-opaas-api/issues/23789			opaas toe xtend the ds in dal09

sles_cis_rule_6_1_10: false
sles_cis_rule_6_1_11: false




Server Type: Production                                                  *
*       Hostname: tdmprdhana                                                  *
*         CFN IP: 192.168.7.9                                                 *
*         IFN IP: 10.4.20.9                                                   *
*         SBR IP: 10.208.126.150                                              *
*        SAP SID: HP1                                                         *
*   HANA Tenancy: SDC  




 Server Type: QA                                                          *
*       Hostname: tdmqashana                                                  *
*         CFN IP: 192.168.7.8                                                 *
*         IFN IP: 10.4.20.8                                                   *
*         SBR IP: 10.208.126.189                                              *
*        SAP SID: HQ1                                                         *
*   HANA Tenancy: SDC  




   Server Type: Development                                                 *
*       Hostname: tdmdevhana                                                  *
*         CFN IP: 192.168.7.7                                                 *
*         IFN IP: 10.4.20.7                                                   *
*         SBR IP: 10.208.126.182                                              *
*        SAP SID: HD1                                                         *
*   HANA Tenancy: SDC  


9 SEPT


5 OCT

25 and 26 Oct   




CTASK0654919
* Hostname: tscmlmock *
* CFN IP: 10.170.62.143 *
* IFN IP: 10.207.62.36
10 AM snapshot




Hostname: hgyd09dbap01Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
CFN IP: 10.34.182.18Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
IFN IP: 10.70.182.10Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
SAP SID: A09, D09Â Â Â Â 


Â Hostname: hgyp09dbap01
CFN IP: 10.34.181.31Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
IFN IP: 10.134.181.12Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
Â SAP SID: P09Â Â Â Â Â Â Â Â 


- It should contain characters from three of the following four categories:
i.            English uppercase characters (A through Z) --- No 	ucredit=-1
ii.           English lowercase characters (a through z) --- Yes	Icredit=-1
iii.          Base 10 digits (0 through 9) --- Yes					dcredit=-1
iv.          Non-alphabetic characters (for example, !, $, #, %) --- No.	ocredit=-1



pam-config -a --cracklib --cracklib-minlen=10 --cracklib-lcredit=-1 --cracklib-ucredit=-1 --cracklib-dcredit=-1 --pwhistory --pwhistory-use_authtok --pwhistory-remember=3


Minimum password length should be 10 characters
	Password should have one UPPERCASE Character
	Password should have one LOWERCASE Character
	Password should have one Numeric Character
Minimum Passwords to Remember or Password History is 4
Accounts should be lockout after 5 attempts.

--------------------------------------------------------------------------------------

CS12532096, CS12532098, CS12620938, CS12627051


CS12635308
Halifax
 Regional Municipality -- HRM
P1 - Severe
hrm#hrmazsftpprdr#Unable to ping HRMAZSFTPPRDR (172.29.22.133) from FRDAL13WEBD01.





CS12635306
Halifax
 Regional Municipality -- HRM
P1 - Severe
hrm#hrmazxp1apdr#Unable to ping HRMAZXP1APDR (172.29.22.244) from FRDAL13WEBD01.





CS12635302
Halifax
 Regional Municipality -- HRM
P1 - Severe
hrm#hrmazwp1apdr#Unable to ping HRMAZWP1APDR (172.29.22.141) from FRDAL13WEBD01.





CS12635266
Halifax
 Regional Municipality -- HRM
P1 - Severe
hrm#hrmazcp1apdr#Unable to ping HRMAZCP1APDR (172.29.22.136) from FRDAL13WEBD01.


*/1 * * * * /bin/chown s4padm:sapsys -R /OracleHCM


2845 cr  ajio
899.64 cr   firstcry
5224  flipkat 
359 myntra
679.41 ajio



Extend the datastore size DALDAL09POOL1POD1DSP925 to 12TB #3699


10.134.2.14 / 172.24.2.14	TNGDEVEAPP40	
 /tng_backup
 
 

	Hostname: TNGDEVEAPP40Â  -Â  CFN IP: 172.24.2.14
Hostname: TNGQASEAPP20Â  -Â  CFN IP: 172.24.2.13
Hostname: TNGDEVERPDBÂ Â  -Â  CFN IP: 172.24.1.13
Hostname: TNGQASERPDBÂ Â  -Â  CFN IP: 172.24.1.12

Â 
Database TNGPRODERPDB 10.134.1.11 / 172.24.1.11
Application Server TNGPRODEAPP00 10.134.2.11 / 172.24.2.11
Application Server TNGPRODEAPP01 10.134.2.12 / 172.24.2.12
Â 





Source Server: 10.238.1.68 (Azure)
Destination Server: 10.250.10.148 (PSMC

 â€œps2-pop-ciâ€ (hosted at Azure) to â€œps-sdms.psmcl.com.pkâ€
 
 
10.250.10.148	 ps-sdms.psmcl.com.pk



Datastore extension request #8253
https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/issues/8253





LZAUS016BCA037 extend to 12 TB in DAL09
LZAUS016BCA106 extend to 18 TB in DAL09

Datastore extension request #8255
https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/issues/8255






IA2POPRDDB	66.248.244.197	10.133.15.102
IA2S4HQASAPP 10.133.17.158 login not works	ok
IA2S4HDEVAPP 10.133.16.42 login not works	ok
IA2FIODEVDBAP 10.133.16.43 login not works	ok
ia2otasapprd 10.133.15.137 login not works	ok

AHECDSAP01 - 10.4.10.21
AHPOSSAP01 - 10.4.10.14

---------------------------------------------------------------------------------------------------


CS12731708 It's a SNOW Ticket and to fix that issue SL Ticket was raised and its ticket number is CS3179199


apprh60	10.68.200.12	A0DTUS014XVM003
apprh65	10.68.200.13	A0DTUS014XVM004
ciprh01node2	10.68.200.11	A0DTUS014XVM002_restore



Azure/AWS -- Portal links and access procedure

list of accounts on Azure and Aws 

SME Precheck script

Also test the prechecks on different Azure/aws machines to understand gateway is not pingable for other Azure accounts aswell






CHG0267978
Take OS VM snap short for below servers.

Target Servers of this task:

jpzetftpq01	10.216.15.36	              No SAP running
tsmwdqas01	10.216.15.16	Quality        WQ1
jp0811zbe2010	10.216.15.79	Quality        HQ1 S4 HANA App QA 
jp0811zbe2015	10.216.15.8	Quality        HQ1 S4 HANA DB


2)Upgrade SLES12 SP03 â†’ SP04

jpzetftpq01 10.216.15.36 No SAP running  on TOK02POOL1POD1DSP49
tsmwdqas01 10.216.15.16 Quality WQ1
jp0811zbe2010 10.216.15.79 Quality HQ1 S4 HANA App QA
jp0811zbe2015 10.216.15.8 Quality HQ1 S4 HANA DB


Patch 
jpzetftpq01    10.216.15.36                  No SAP running
tsmwdqas01    10.216.15.16    Quality        WQ1


jp0811zbe2010    10.216.15.79    Quality        HQ1 S4 HANA App QA
jp0811zbe2015	10.216.15.8	Quality        HQ1 S4 HANA DB






CHG0266806	Dal13
Patch Group (D3) - wa2s1dadb1	SUSE	10.191.1.11	Development	S1D - SAP  (App/DB)	WA2DAL13POD2POOL1UMAPOD2DSP104
Patch Group (D3) - wa2fidadb1	SUSE	10.191.1.15	Development	FID - SAP  (App/DB)	WA2DAL13POD2POOL1UMAPOD2DSP104
Patch Group (D3) - wa2ep7adb1	Linux	10.191.1.24	Development	EP7 - SAP  (App/DB)	WA2DAL13POD2POOL1UMAPOD2DSP104


NOTE:  
Task: Set root password per KB0017634./nTask:  
Activate Kdump for SLES KB0015500./n1/nTask:  
Activate Kdump for RHEL6 KB0018359./n2/nTask:  
Check antivirus per KB0017634, and update per KB0016632./n3/nTask: Vmware vSphere Client, 
Enable VM monitoring per KB0017982./n4/nTask: Enable VMWare logging per KB0019028.

50 saree
50 + 20
50 30 30 dry clean



kdump:

Patch Group (SBX) - dlthsggat    Redhat    10.4.5.24    Development    HSG - SAP  (App/DB) - Sybase
Patch Group (SBX) - dlthsehap    Redhat    10.4.5.22

penad15sl    Redhat    10.4.8.10



Increase network card = 10 Gb on  BR3PMIGSQL01 and BR3PMIGA01
Increase the RAM from 192GB to 512GB on BR3PMIGSQL01 
Allocate SWAP size RAM*1.5 times on BR3PMIGSQL01  and tune the system




CHG0268049
Patch Group (QA1) - dltqeahap5	Redhat	10.4.5.222	QA	QEA - SAP  (App) - NA
Patch Group (QA1) - dlthqehap4	Redhat	10.250.17.39	Development	HQE - SAP  (App) - Sybase
Patch Group (QA1) - dlthqgga2	SUSE	10.4.5.137	QA	HQG - SAP  (App) - NA
Patch Group (QA1) - dltqeahap4	Redhat	10.4.5.221	QA	QEA - SAP  (App) - NA
Patch Group (QA1) - dlthqehap5	Redhat	10.4.5.45	Development	HQE - SAP  (App) - NA



146.89.173.192/26 via 10.199.98.1 dev eth0 
146.89.174.192/26 via 10.199.98.1 dev eth0 




route add -net 146.89.174.192/26 gw 10.199.98.1 dev eth0

route add 146.89.142.119 gw 146.89.142.127 dev bond0



CS12825096  Monika request
	CS12825521  Mohan 	DOne
requirement isÂ ssh sapautodr@<new_server>Â -- from control server should work without prompting for password

approve shift allowance

apply shift allowance-self






[root@fbsapp01fgcl ~]$ lscpu		change to 4
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                2


memory  
[root@fbsapp01fgcl ~]$ free -gh
             total       used       free     shared    buffers     cached
Mem:           22G        12G       9.4G       945M       389M        10G
-/+ buffers/cache:       1.9G        20G
Swap:          47G       554M        47G


Increase CPU to 4 cores and memory to 128GB on server, 


GBWPAS0    gbwpas0    Linux Server    Installed    None    No    10.25.215.49 - working
GBWPAS2    GBWPAS2    Linux Server    Installed    None    No    10.25.215.34
GBWPAS3    GBWPAS3    Linux Server    Installed    None    No    10.25.215.10
GBWPAS4    GBWPAS4    Linux Server    Installed    None    No    10.25.215.26
GBWPAS5    GBWPAS5    Linux Server    Installed    None    No    10.25.215.31


pcbadm



CHG0267507||CST/CDT - 02/11/2023 - 12:30 - NIX - AP4 - PATCH - HC - 1Q23- Troop C(SAPB1)
CHG0270497|| CST/CDT - 02/10/2023 - 10:00 - NIX - TDP - PATCH - 1Q23- Troop C(SAPB1)


ABAP primitives by Suresh

https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/SLES_12_SP4_ABAP_CLUSTER_PRIMITIVES.md


[12:52] Suresh Jayamani
wait_for_leasetime_on_stop=true 

[12:52] Suresh Jayamani
we need to add this for exports 



CHG0267283Â 

CHG0269242 - Surendra I have given in th

CHG0270222

CHG0270914 Â  approve Mel


CHG0268270, CHG0268271, CHG0268328	santosh

CHG0270372   mamtha



CHG0269552
Patch Group (-) - scrbwqdefra80	SUSE	100.126.64.18	QA	WQ1 - SAP  (App) - NA
Patch Group (-) - scrbwqdefra70	SUSE	100.126.64.17	QA	WQ1 - SAP  (DB) - HANA



CHG0270720
CST/CDT - 02/11/2023 - 01:00 - NIX - BS5 || Perform SLE12 SP4->SLES12 SP5 upgrade - Production. 
Update Linux service pack level for the servers listed in this change.

Current version: SLES 12 SP04
Target version: SLES 12 SP05

List of VMS to be upgraded."

Patch Group () - bs5solman	SUSE	10.141.132.14	Production	SOJ - SAP  (App/DB) - Sybase		FAILED  - Gateway 132.132.0.1 is not reachable
Patch Group () - bs5eccprd	SUSE	10.141.132.25	Production	<SID> - SAP <Landscape> (App/DB)	FAILED  - Gateway 132.132.0.1 is not reachable


For sczprddb-ha:/var/log/scc_sczprddb-ha_230211_0350.txz
For sczprddb:/var/log/scc_sczprddb_230211_0351.txz



CTASK0679133
Please  take the VM snapshot for these servers.

PRD:
ProdcutionÂ  - V33Â Â Â  LinuxÂ Â Â  BAPV330900Â Â Â Â  10.134.3.7		2.09TB		SNG01POOL1DS248	Total Capacity
23.44 TB
Provisioned Space
20.61 TB
ProdcutionÂ  - V12Â Â Â  LinuxÂ Â Â  BAPV120400Â Â Â Â  10.134.3.6		2.31TB	SNG01POOL1DS314	Total Capacity
23.44 TB
Provisioned Space
19.27 TB
ProdcutionÂ  - V11Â Â Â  LinuxÂ Â Â  BAPV110100Â Â Â Â  10.134.3.11	760GB	SNG01POOL1DS329	Total Capacity
23.44 TB
Provisioned Space
19.94 TB



CHG0271478
15-02-2023 07:00:00	15-02-2023 11:00:00
snapshot on server tscmlmock		CTASK0685231



CHG0270953 || CST/CDT - 02/19/2023 - 10:00 - NIX - ZFF - PATCH - 1Q23- Troop C(SAPB1)
CHG0269967 || CST/CDT - 02/17/2023 - 06:00 - NIX - QLA - PATCH - 1Q23- Troop C(SAPB1)	DOne

 CHG0268867 	done
 CHG0267795
 
 
 CHG0268509Â Â Â  CST/CDT - 02/18/2023 - 10:00 - NIX - BAP - PATCH - 1Q23- Troop C(SAPB1) || Perform SLE12 SP4->SLES12 SP5 upgrade
 CHG0268510Â Â Â  CST/CDT - 02/18/2023 - 10:00 - NIX - BAP - PATCH - 1Q23- Troop C(SAPB1)
 
 -----------------------------------------------------------------------------------------------------------------
 
 

Change approval 

CHG0266820 CST/CDT - 02/21/2023 - 20:00 - NIX - WA2 - PATCH - 1Q23- Troop C(SAPB1)Â 
CHG0270258 CST/CDT - 02/22/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - 1Q23- Troop C(SAPB1)Â 

CHG0267501	approved



sapapp15		up
sapapp18		up
sapapp19		up
sapapp20		up
sapapp21		up
sapapp23		up
sapapp26		up
sapapp27		up
sapapp28		up
sapapp29		up
sapapp30		up
sapapp31		up
sapapp32		up
sapapp33		up
sapapp34		up
sapapp35		up
sapapp36		up
sapapp37		up
sapapp38		up
sapapp39		up
sapapp40		up
sapapp41		up
sapapp42		up
sapcrmapp3		up		
sapcrmapp4		up
ewmapp3			up
ewmapp1			up

biprdapp3		up
biprdapp1		up
tscmlprd		up
tsgpprd			up
sappoprdc		up
essmssdev		up
adsprds			up
ttagrcprd		up
ttar3dev		up
sapborepo		up
sapboprd		up
sapbowapp		up
sapcrmdi		up
ttas4happ		up
ttapoprd		up
ttawebdprd

/sds/sap/MSD_Software/SAP_Automation/Scripts/kdump/KdumpEnablement.py



ttactrl01



lpadmin -p SI24 -v socket://SI24.perkinelmer.com -E

lpadmin -p IN06 -v socket://IN06.perkinelmer.com -E




CHG0270228
CHG0270368



Please check and do the required configuration changes to the below listed servers to reach same NTP Server and to fix Time Sync issue, so that all 4 servers will reach to the same NTP server and on same Time zone
Application ServerÂ Â Â  J2QÂ Â Â  TBOS4QASAP2Â Â Â  100.126.48.102	Windows
Add App ServerÂ Â Â Â Â Â Â  J2QÂ Â Â  TBOS4QASAP3Â Â Â  100.126.48.39
Add App ServerÂ Â Â Â Â Â Â  J2QÂ Â Â  TBOS4QASAP4Â Â Â  100.126.48.40
DatabaseÂ Â Â Â Â Â Â  H2QÂ Â Â  TBOS4QASDB2Â Â Â  100.126.48.103


1 unmount "old" /usr/sap/trans nfs (it's mounted from cloud gh2sv008101 at the moment) on gh2sv008103, gh2sv008107, gh2sv008108 QA and PRD SAP application serversÂ 
2 mount "new" /usr/sap/trans from sv008101n on gh2sv008103, gh2sv008107, gh2sv008108 QA and PRD SAP application servers

sv008101n connection info
FQDN sv008101n.germany.central-it.grohe
Service IP 10.171.1.68





CHG0272601 approve change


Â CHG0272134 CST/CDT - 03/02/2023 - 21:00 - NIX - MGG - PATCH - HC - VULN - 1Q23- Troop C(SAPB1)Â 


Â CHG0272598 CST/CDT - 03/03/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - 1Q23- Troop C(SAPB1)Â 








Changes in next few days
CHG0272906 - LIN: @Ravi MALIK, SAP: @Rashmipriya AS

CHG0272917 - LIN: @Ravi MALIK, SAP: @Srinithi Rangamannar





Feb 25 11:22:06 br3psolss41 stonith-ng[14907]: Â  notice: vcenter-fencing-br3psolss40 can fence (reboot) br3psolss40: dynamic-listFeb 25 11:22:12 br3psolss41 kernel: [1451749.309197] drbd r2 br3psolss40: PingAck did not arrive in time.Feb 25 11:22:12 br3psolss41 kernel: [1451749.309269] drbd r2 br3psolss40: conn( Connected -> NetworkFailure ) peer( Primary -> Unknown )Feb 25 11:22:12 br3psolss41 kernel: [1451749.309270] drbd r2/0 drbd2: disk( UpToDate -> Consistent )Feb 25 11:22:12 br3psolss41 kernel: [1451749.309271] drbd r2/0 drbd2 br3psolss40: pdsk( UpToDate -> DUnknown ) repl( Established -> Off )Feb 25 11:22:12 br3psolss41 kernel: [1451749.309287] drbd r2 br3psolss40: ack_receiver terminatedFeb 25 11:22:12 br3psolss41 kernel: [1451749.309288] drbd r2 br3psolss40: Terminating ack_recv threadFeb 25 11:22:12 br3psolss41 kernel: [1451749.310396] drbd r2: Preparing cluster-wide state change 4106019143 (1->-1 0/0)Feb 25 11:22:12 br3psolss41 kernel: [1451749.310398] drbd r2: Committing cluster-wide state change 4106019143 (0ms)Feb 25 11:22:12 br3psolss41 kernel: [1451749.310399] drbd r2/0 drbd2: disk( Consistent -> UpToDate )Feb 25 11:22:13 br3psolss41 kernel: [1451749.354036] drbd r2 br3psolss40: Connection closedFeb 25 11:22:13 br3psolss41 kernel: [1451749.354048] drbd r2 br3psolss40: conn( NetworkFailure -> Unconnected )Feb 25 11:22:13 br3psolss41 kernel: [1451749.354060] drbd r2 br3psolss40: Restarting receiver threadFeb 25 11:22:13 br3psolss41 kernel: [1451749.354065] drbd r2 br3psolss40: conn( Unconnected -> Connecting )

[6:14 PM] Gerald Delgado Mora
Feb 25 11:22:12 br3psolss41 kernel: [1451749.309269] drbd r2 br3psolss40: conn( Connected -> NetworkFailure ) 


As per BHT update, there was datastore disconnect as per ESXi host logs. BHT team working with IBM cloud why DS was disconnected via SL ticket(CS3253393)






Some very important and high impact work done by us in say last 6 months
Contributed towards the in place RHEL 6.x to 8.x and SuSE upgrade from SuSE 12 ti SuSE 15.
Involved in major customer DR tests(TATA Steel) and successfully performed multiple tests till date.

	
What are we doing over and above our day-day jobs to help Kyndryl
Working proactively to reduce ticket count and avoid Sev1 due to datastore overprovisioning issues.
	
How are we making ourselves future ready by certifications, working on new technologies or multicloud platforms.
Team has completed Azure foundation certification(AZ-900) and few have also completed the AZ104 admin level certification. 
	
Some exceptional client appreciations or rewards we got
NA



CHG0273140 CST/CDT - 03/11/2023 - 19:00 - NIX - MGG - PATCH - HC - VULN - 1Q23- Troop C(SAPB1)
CHG0272910 CST/CDT - 03/11/2023 - 19:00 - NIX - MGG - PATCH - HC - VULN - 1Q23- Troop C(SAPB1)
CHG0267842 CST/CDT - 03/11/2023 - 10:00 - NIX - IA2 - PATCH - 1Q23- Troop C(SAPB1)




crm configure show >>/tmp/configure_backup

[root@br3qscmdb36 ~]# crm configure show |grep -i order
Existing
order ord_SAPHana_QCM_HDB36 Optional: cln_SAPHanaTopology_QCM_HDB36 msl_SAPHana_QCM_HDB36 TSMTDP_QCM_HDB36

Expected
order ord_SAPHana_HHA_HDB00 Optional: cln_SAPHanaTopology_HHA_HDB00 msl_SAPHana_HHA_HDB00
order ord_SAPHana_QCM_HDB36 Optional: cln_SAPHanaTopology_QCM_HDB36 msl_SAPHana_QCM_HDB36

[root@br3qscmdb36 ~]# crm configure show |grep -i colocation
Existing
colocation col_saphana_ip_QCM_HDB36 2000: rsc_ip_QCM_HDB36:Started msl_SAPHana_QCM_HDB36:Master TSMTDP_QCM_HDB36:Started

Expected
colocation col_saphana_ip_HHA_HDB00 inf: rsc_ip_HHA_HDB00:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master

colocation col_saphana_ip_QCM_HDB36 2000: rsc_ip_QCM_HDB36:Started TSMTDP_QCM_HDB36:Started msl_SAPHana_QCM_HDB36:Master


[root@br3qscmdb36 ~]# crm configure show |grep -i colocation
colocation col_saphana_ip_QCM_HDB36 2000: rsc_ip_QCM_HDB36:Started TSMTDP_QCM_HDB36:Started msl_SAPHana_QCM_HDB36:Master
[root@br3qscmdb36 ~]# crm configure show |grep -i order
order ord_SAPHana_QCM_HDB36 Optional: cln_SAPHanaTopology_QCM_HDB36 msl_SAPHana_QCM_HDB36
[root@br3qscmdb36 ~]# date
Tue Mar  7 05:44:52 EST 2023





[root@br3qgtsdb36 ~]$ crm configure show |grep -i order
Existing
order ord_SAPHana_QGT_HDB35 Optional: cln_SAPHanaTopology_QGT_HDB35 msl_SAPHana_QGT_HDB35 rsc_TSMTDP_QGT_HDB35

Expected
order ord_SAPHana_HHA_HDB00 Optional: cln_SAPHanaTopology_HHA_HDB00 msl_SAPHana_HHA_HDB00



[root@br3qgtsdb36 ~]$ crm configure show |grep -i colocation
colocation col_saphana_ip_QGT_HDB35 2000: rsc_ip_QGT_HDB35:Started msl_SAPHana_QGT_HDB35:Master rsc_TSMTDP_QGT_HDB35:Started

colocation col_saphana_ip_HHA_HDB00 inf: rsc_ip_HHA_HDB00:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master
colocation col_saphana_ip_QGT_HDB35 2000: rsc_ip_QGT_HDB35:Started rsc_TSMTDP_QGT_HDB35:Started msl_SAPHana_QGT_HDB35:Master



[root@br3qgtsdb36 ~]$ crm configure show |grep -i colocation
colocation col_saphana_ip_QGT_HDB35 2000: rsc_ip_QGT_HDB35:Started rsc_TSMTDP_QGT_HDB35:Started msl_SAPHana_QGT_HDB35:Master
[root@br3qgtsdb36 ~]$ crm configure show |grep -i order
order ord_SAPHana_QGT_HDB35 Optional: cln_SAPHanaTopology_QGT_HDB35 msl_SAPHana_QGT_HDB35
[root@br3qgtsdb36 ~]$ date
Tue Mar  7 06:02:57 EST 2023



HSE	dlthsehdb2	10.143.69.228	delta-dal09-phana-2048-03.imzcloud.ibmammsap.local


10.143.69.229
root   Upl9Mekhz5




DP VMWare: Creating "VMware Tools with file system quiescing and application quiescing (VSS) disabled" snapshot for virtual machine 'DLBPCSDA00'


PFC >170
mtrr >1725
itc > any price


https://samuel.sap.mgapp.ibm.com/MGG/buildInformation?id=640899442332220590d43cd0&name=Overview



SL case to fix connectivity raised number:CS3272963 
FRA02
66.248.241.38			fra02-pod1-6tb-host001.imzcloud.ibmammsap.local
66.248.241.9			fra02-pod1-6tb-host001.imzcloud.ibmammsap.local
66.248.241.38			fra02-pod1-6tb-host001.imzcloud.ibmammsap.local
66.248.241.14			fra02-pod1-6tb-host003.imzcloud.ibmammsap.local
66.248.241.47		    fra02-pod1-6tb-host001.imzcloud.ibmammsap.local 
\

cat /opt/tivoli/tsm/client/ba/bin/dsm.sys


PRK-PerkinElmer-PG6		prdb12	https://10.176.198.120/dr/#/sitepair/all/ed4b371d-2b4f-4b5e-83c1-cded8812791a/2ce6dbd2-00fb-444e-88a9-40d634210269/c405e891-f007-4a36-b5b8-4e484328bc62/8464f8c5-fe04-45b2-a90c-ed662bf41eeb/58994310-cff5-413f-befa-8c5433ed6963/9a29e687-694d-486a-9715-957c80239603/groups/group/vms?serverGuid=c405e891-f007-4a36-b5b8-4e484328bc62&type=DrReplicationVmProtectionGroup&value=vm-protection-group-3331764



npsv05	PRK-PerkinElmer-PG2	


prsvp107	PRK-PerkinElmer-PG1

prdbtws	PRK-PerkinElmer-PG5



prdb07	PRK-PerkinElmer-PG11 - prdb07	move to prk263  removed from srm in prog once done readd to new datastore


# traceroute -i eth2 10.85.0.158
# traceroute -i eth2 10.0.80.11
# mtr -rc 10 --no-dns --address 10.134.120.235 10.85.0.158
# mtr -rc 10 --no-dns --address 10.134.120.235 10.0.80.11
# ping -c 5 -I eth2 10.85.0.158
# ping -c 5 -I eth2 10.0.80.11
--

From the TSM server, wanted to see if you could conduct the following, example:

--
# traceroute 10.134.120.23
# mtr -rc 10 -n 10.134.120.23
# ping -c 5 10.134.120.23



Register Complaint		MSEB high bill
ICRS Complaint ID : [0000027259576]


Please create FS with 5GB on S4Q (Details below) and share FS across S4d and S4P systems from VG "s4qappvg".
S4Q to S4P is pending
S4Q
Hostname: ti3s4qap02
IFN IP: 10.7.115.14


S4P
Hostname: ti3s4pap01
IFN IP: 10.7.123.113



Please create a group 'interfaces' with GID 7550 in lbuts1ap01 server and assign this group to ts1adm user as secondary group


sapbowapp_restore_12122020
sapapp28_restore_09162021



CHG0265614CST/CDT - 03/26/2023 - 10:00 - NIX - HRM - PATCH - HC - 1Q23- Troop C(SAPB1) - Batch 7a - DR    change approve



q50919766@ybl







CS13044986 SL access to moonlight raised
Do request for account via UAT - FOllow https://kyndryl.sharepoint.com/sites/sei-iam/SitePages/iam--end-users--create-user-id.aspx and Do request for privileges via UAT - https://kyndryl.sharepoint.com/sites/sei-iam/SitePages/iam--end-users--change-profile.aspx


CHG0268728 - Prechecks attached all good
CHG0273612 - Prechecks attached 1 vm SAP issue, rest all good, will inform the PDL to check and solve
CHG0268729 - Prechecks attached all good




High level steps for the implementation,Make sure to take the required backups as per KBMake sure to take a pre-reboot (before patching)Make sure to have root password handyMake sure the serial console is accessibleUse #zypper update $(cat /tmp/devrpm) ---- to patch the serverFor SLES15 use #zypper update $(cat /tmp/devrpm_SLES15) ---- to patch the serverRebootValidate and perform if any additional activities, such as, kdump configuration, ds_agent upgrade, etc...



CHG0265636		18-03-2023 06:30:00	- 18-03-2023 14:30:00
As we discussed please do this activity during this CR https://learn.microsoft.com/en-us/azure/virtual-machines/maintenance-notifications-portal

Patch Group (5a) - hrmazsp1db	SUSE	172.29.25.14	Production	SP1 - SAP  (DB) - HANA
Patch Group (5a) - hrmazsp1dbha	SUSE	172.29.25.16	Production	SP1 - SAP  (DB) - HANA
Patch Group (5a) - hrmazsp1ap2	SUSE	172.29.25.17	Production	SP1 - SAP  (App)
Patch Group (5a) - hrmazsp1ap3	SUSE	172.29.25.15	Production	SP1 - SAP  (App)
Patch Group (5a) - hrmazsp1ap1	SUSE	172.29.25.13	Production	SP1 - SAP  (App)
Patch Group (5a) - hrmazsp1ap1ha	SUSE	172.29.25.18	Production	SP1 - SAP  (App)



sbd -d /dev/disk/by-id/scsi-36001405bfdbcc2fbb544f5f8253abfe5  message LOCAL clear
sbd -d /dev/disk/by-id/scsi-360014055d61df0d47e041dab1250ddbc  message LOCAL clear
sbd -d /dev/disk/by-id/scsi-36001405c82bdcda94cf4024a372fec8f message LOCAL clear



SBD_DEVICE="/dev/disk/by-id/scsi-36001405bfdbcc2fbb544f5f8253abfe5;/dev/disk/by-id/scsi-360014055d61df0d47e041dab1250ddbc;/dev/disk/by-id/scsi-36001405c82bdcda94cf4024a372fec8f;"





CHG0272076   American Airlines Inc. -- A2A   Linux   3/25/2023   10:00
CHG0272077   American Airlines Inc. -- A2A   Linux   3/25/2023   10:00


asdtstap	asdtstap	10.156.20.87	asdtstap	Frankfurt 02	2	A0B4DE01CB	ammfra02custesx099.imzcloud.ibmammsap.local
asdtstdb	asdtstdb	10.156.20.84	asdtstdb	Frankfurt 02	2	AMM_VHANA_CA	fra02-pod2-4tb-host15.imzcloud.ibmammsap.local	vHana



1. # less /etc/logrotate.d/syslog |grep log
2. # ls -l <directory>


/etc/logrotate.d/syslog |grep
/etc/security/audit/config
/etc/security/audit/events

in the OS of the mentioned servers:
	
tdppcs4papp1	10.16.0.128		10.209.2.23 
tdppcs4papp2	10.16.0.7
tdppcs4pdb	10.16.0.27

tdpdcprdap1	10.16.0.18
tdpdcprdap2	10.16.0.13		TDPDCPRDAP2	TDPDCPRDAP2	Linux Server	Retired
tdpdcprdhdb	10.16.0.8



CS13084827 CS13084709 CS13084749




sm9d185173005
sm9h182172004



CHG0274835
Patch Group (3.1) - pbl-z-pap-a	SUSE	10.199.18.14	Production	PAP - SAP  (App/DB) - Oracle 12c
Patch Group (3.2) - pbl-sap-fbp	SUSE	10.199.18.21	Production	FBP - SAP  (App/DB) - Oracle 12c





Drive /c0/e8/s4 - Detailed Information :
Shield Counter = 0
Media Error Count = 2
Other Error Count = 0
Drive Temperature =  33C (91.40 F)
Predictive Failure Count = 0
S.M.A.R.T alert flagged by drive = No
SN = 6SLAKHMG0000N6060GY9
Firmware Revision = 0730000B



Drive /c0/e8/s16 - Detailed Information :
Shield Counter = 0
Media Error Count = 0
Other Error Count = 4
Drive Temperature =  32C (89.60 F)
Predictive Failure Count = 0
S.M.A.R.T alert flagged by drive = No
SN = 6SLAC7K90000N54308CW
Firmware Revision = 0730000B




CHG0275548
Patch Group (N/A) - fbsapp01fgcl	SUSE	10.199.99.11	Production	BPA - SAP  (App) - NA
Current version: SLES 12 SP02
Target version: SLES 12 SP05



300323-2559549 giftr ticket



change CHG0276461 starts at 7 AM [ OS resource to be on standby]

change CHG0276465 starts at 8 AM [OS resource to be on standby]

and apart from these two, you have a change tomorrow CHG0273923


sapapp31 - and 31-ha

CPA

sapcrmapp4

sapcrmapp4-ha

Â 

EMP

ewmapp3

ewmapp3-ha





[Yesterday 22:19] Yorleni Jimenez Alvarado
    General

Hi team, please your help to add approval for below changes. Thanks!
CHG0273767 CST/CDT - 04/04/2023 - 20:00 - NIX - HFC - OS Update SLES 12 SP04 to SP05 - NON PROD
CHG0273786 CST/CDT - 04/05/2023 - 20:00 - NIX - HFC - OS Update SLES 12 SP04 to SP05 - NON PROD
CHG0273791 CST/CDT - 04/06/2023 - 20:00 - NIX - HFC - OS Update SLES 12 SP04 to SP05 - NON PROD


Thank you!
Your document has been uploaded successfully.

Please Note:If you have uploaded an address proof while updating your Contact Details , please Click here and update your address.
We will review the same and confirm the status of your request through email/SMS within 2 working days. You can also check the status of submission by clicking here .
Reference Number: CD2304047540333

https://www.citibank.co.in/IbsJsps/cboldocstatusinter.jsp



CS13174358 master ticket ccp#ammdal13seiesx026#State is equal to Not responding AND State is equal to Unknown




CHG0273787 HollyFrontier Corporation -- HFC Linux 4/8/2023 22:00
CHG0273792 HollyFrontier Corporation -- HFC Linux 4/8/2023 22:00


Coupon Code

Q10IANJ9RMDR

04/08/2023~04/07/2024


Due to CHG0274986 closed at 08-04-2023 16:13:25 IST
sm9cnlcslx01:~ # ps -ef |grep -i pacemaker
root      80406  80402  0 09:53 ?        00:00:03 sbd: watcher: Pacemaker
root      80418      1  0 09:53 ?        00:00:03 /usr/sbin/pacemakerd -f
haclust+  80419  80418  0 09:53 ?        00:00:44 /usr/lib/pacemaker/cib
root      80420  80418  0 09:53 ?        00:00:01 /usr/lib/pacemaker/stonithd
root      80421  80418  0 09:53 ?        00:00:01 /usr/lib/pacemaker/lrmd
haclust+  80422  80418  0 09:53 ?        00:00:00 /usr/lib/pacemaker/attrd
haclust+  80423  80418  0 09:53 ?        00:00:00 /usr/lib/pacemaker/pengine
haclust+  80424  80418  0 09:53 ?        00:00:02 /usr/lib/pacemaker/crmd
root     128151 128091  0 13:47 pts/2    00:00:00 grep --color=auto -i pacemaker
sm9cnlcslx01:~ # uptime
 13:47pm  up   4:37,  3 users,  load average: 3.06, 2.62, 2.46





https://www.getdroidtips.com/realme-8-android-13-update/
https://www.getdroidtips.com/unlock-bootloader-realme/





CHG0277479

Please mount - 10.6.2.16 - /dev/mapper/installvg-install_lv
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ext3Â Â  295GÂ  152GÂ  129GÂ  55% /install

in 10.6.3.15






cross mount to host CS13219659 , this storage will be returned back once activity completed

hcils4dbpr00




CHG0277122	CST/CDT - 04/15/2023 - 10:00 - NIX - HRM - PATCH - 1Q23,2Q23- Troop C(SAPB1)
CHG0277123	CST/CDT - 04/15/2023 - 10:00 - NIX - HRM - PATCH - 1Q23,2Q23- Troop C(SAPB1)




lbupp1db01 -> [NODEDR] lbupp1db01dr
lbupp1db01 -> [NODEB] lbupp1db01ha
lbupp1db01 -> [NODEA] lbupp1db01


hdbnsutil -sr_register --replicationMode=async --name=NODEDR --remoteInstance=00 --remoteHost=lbupp1db01ha



CHG0274313 12-04-2023 06:30:00	12-04-2023 16:30:00		DAL13-SL
Patch Group (DEV-1) - bs4db0004	SUSE	10.211.8.14	Development	DB0 - SAP  (App) - NA
Patch Group (DEV-1) - bs4dng010	SUSE	10.211.8.20	Development	DNG - SAP  (App/DB) - Sybase
	Patch Group (DEV-1) - bs4de0001	SUSE	10.211.8.25	Development	DE0 - SAP  (DB) - HANA
Patch Group (DEV-1) - bs4dx0005	SUSE	10.211.8.15	Development	DX0 - SAP  (DB) - Sybase
Patch Group (DEV-1) - bs4wdd019	SUSE	10.211.6.6	Development	WDD - SAP  (App) - NA
	Patch Group (DEV-1) - bs4db0003	SUSE	10.211.8.13	Development	DB0 - SAP  (DB) - HANA
Patch Group (DEV-1) - bs4ewd007	SUSE	10.211.8.17	Development	EWD - SAP  (App/DB) - Sybase
Patch Group (DEV-1) - bs4dx0006	SUSE	10.211.8.16	Development	DX0 - SAP  (App) - NA
Patch Group (DEV-1) - bs4de0002	SUSE	10.211.8.12	Development	DE0 - SAP  (App) - NA



rear backup on HANA servers
snapshot on rest	done
chk ds agent	latest
chk kdump	configured
HC VULN
VM logging  enabled already on all
default gnome target to multi-user



OUTPUT=ISO
BACKUP=NETFS
BACKUP_OPTIONS="nfsvers=3,nolock"
#ISO_MKISOFS_BIN="/usr/bin/ebiso" # ONLY IF UEFI Loader 
BACKUP_URL=nfs://146.89.142.214/rearbackups
NETFS_KEEP_OLD_BACKUP_COPY=yes
MODULES_LOAD=( autofs4 scsi_mod scsi_dh_alua scsi_dh_emc scsi_dh_rdac dm_mod dm_multipath sg drm_panel_orientation_quirks vmw_pvscsi vmxnet3 serio_raw libata crc32c_intel drm libahci ahci ttm ata_piix sd_mod fb_sys_fops sysimgblt sysfillrect syscopyarea drm_kms_helper vmwgfx ata_generic raid6_pq xor btrfs button ac pcc_cpufreq shpchp i2c_piix4 vmw_vmci joydev pcspkr cryptd vmw_balloon glue_helper crypto_simd aes_x86_64 aesni_intel pcbc libcrc32c ghash_clmulni_intel crc32_pclmul sb_edac xfs msr iscsi_boot_sysfs iscsi_ibft af_packet vsock vmw_vsock_vmci_transport binfmt_misc fscache sunrpc grace lockd nfs dns_resolver nfsv4 auth_rpcgss rpcsec_gss_krb5 tmhook x_tables ip_tables iptable_filter bmhook )
REQUIRED_PROGS=( "${REQUIRED_PROGS[@]}" snapper chattr lsattr )
COPY_AS_IS=( "${COPY_AS_IS[@]}" /usr/lib/snapper/installation-helper /etc/snapper/config-templates/default )
BACKUP_PROG_INCLUDE=( /var/lib/machines /srv /opt /var/spool /var/cache /var/lib/libvirt/images /var/tmp /var/lib/named /var/lib/mysql /var/lib/pgsql /tmp /var/log /var/lib/mariadb /usr/local /var/lib/mailman /home /var/opt /var/opt/BESClient )
POST_RECOVERY_SCRIPT=( 'if snapper --no-dbus -r $TARGET_FS_ROOT get-config | grep -q "^QGROUP.*[0-9]/[0-9]" ; then snapper --no-dbus -r $TARGET_FS_ROOT set-config QGROUP= ; snapper --no-dbus -r $TARGET_FS_ROOT setup-quota && echo snapper setup-quota done || echo snapper setup-quota failed ; else echo snapper setup-quota not used ; fi' )
ONLY_INCLUDE_VG=("system")
EXCLUDE_VG=( sapdata saplog sapshared )
BACKUP_PROG_EXCLUDE=( "${BACKUP_PROG_EXCLUDE[@]}" '/sapmnt/*' )
#SECURE_BOOT_BOOTLOADER="/boot/efi/EFI/sles/shim.efi" # ONLY IF your VHANA Boot loader is UEFI


Healthcheck remediation exclusions

without reboot option

comment all Non OS FS entries in fstab

for RHEL6 exclusion
-------------------
rhel6_cis_rule_6_1_10: false
rhel6_cis_rule_6_1_11: false

rhel8cis_rule_6_1_10: false
rhel8cis_rule_6_1_11: false

for Suse
sles_cis_rule_6_1_10: false
sles_cis_rule_6_1_11: false




DPE would know the tshirt size to change it to?
unlike hot add for CPU and Memory in VC does AWS or Azure not have any similar option
even without having access to AWS or Azure one can initiate it from Samuel
optional components in Samuel if left as default will it take as per what is configured for rest
When doing from OPAAS or AWS portal vm should be deallocated, does that not apply when doing from Samuel or it takes care of it
Who to decide which snapshot should be taken instance or volume as its all usage based charges


lsblk -o +SERIAL


9 Mar 10AM-1:30PM EST					9 Mar 7:30PM -11.00pm
20 Mar 4PM-7:30PM EST					21 Mar 1.30AM 5:00 AM
23 Mar 2PM - 24 Mar 3:30AM EST			23 Mar 11:30 PM - 24 Mar 1:00 PM
26 Mar 1:30PM -5:30PM EST				26 mar 11PM-27 Mar 3AM
31 Mar 11:30AM - 2PM					31 Mar 9PM - 1130PM
6 Apr 6:30AM -11:30AM					6 Apr 4 PM - 9PM






CHG0277521	14-04-2023 06:30:00	14-04-2023 14:30:00		FRA02-SL
Current version: SLES 12 SP04
Target version: SLES 12 SP05
Patch Group () - egrs4hdevapp	SUSE	10.135.6.11	Development	S4D - SAP  (App) - NA
Patch Group () - egrs4hqasdb	SUSE	10.135.6.12	Development	S4D - SAP  (DB) - HANA		vHANA running BIOS
Patch Group () - egrs4hqasapp	SUSE	10.135.6.16	QA	S4Q - SAP  (App) - NA

 Hostname: egrs4hdevapp                                                *
*         CFN IP: 10.21.0.18                                                  *
*         IFN IP: 10.135.6.11                                                 *
*        SAP SID: S4D


Hostname: egrs4hqasdb                                                 *
*         CFN IP: 10.21.0.13                                                  *
*         IFN IP: 10.135.6.12                                                 *
*        SAP SID: S4D 


 Hostname: egrs4hqasapp                                                *
*         CFN IP: 10.21.0.33                                                  *
*         IFN IP: 10.135.6.16                                                 *
*        SAP SID: S4Q 



CHG0277948 - CTASK0718987 - Please Take SNAPSHOT of below servers

Â 

EEPÂ Â Â  CIÂ Â Â  MGGGBJPECCX13Â Â Â  10.133.18.8Â Â Â Â Â Â 
EEPÂ Â Â  app1Â Â Â  MGGGBJPECCX17Â Â Â  10.133.18.20Â Â Â Â Â 
EEPÂ Â Â  app2Â Â Â  MGGGBJPECCX16Â Â Â  10.133.18.72Â Â Â Â Â Â Â Â Â 
EEPÂ Â Â  app3Â Â Â  MGGGBJPECCX15Â Â Â  10.133.18.11Â Â Â Â Â Â Â Â Â Â 
SMPÂ Â Â  ABAP-SolmanÂ Â Â  MGGGBJPSOLX03Â Â Â  10.133.18.7Â Â Â Â Â 
SJPÂ Â Â  Java-SolmanÂ Â Â  MGGGBJPSOLX13Â Â Â  10.133.18.17


SU User: root
Payload: <37>Apr 27 22:20:44 ttagrcprd su: (to root) uxscan on pts/160
<37>Apr 27 21:43:16 ewmapp3 su: (to root) uxscan on pts/167
<37>Apr 27 21:05:05 tsls4proddbh su: (to root) uxscan on pts/108

Log Source:  ttagrcprd@10.170.61.35, ewmapp3@10.170.61.204, tsls4proddbh@10.170.61.78 




Please assist to install/update the following HMAC Cipher in sftp dev/qas (10.70.110.42). The request is needed due to GlobalPay do not support an outdated HMAC Cipher. Per checking, this was previously done by Ravi and Kishor.
sftp dev/qas svmq1srv1 10.6.2.42 10.70.110.42
HMACs Ciphers supported for SFTP Client:
hmac-sha256
hmac-sha2-256
hmac-sha512
hmac-sha2-512






Q12 - Pi-Square   --> Q12 - DR




CS13341535: Sev1 : All OS command is taking much time in server dlthpehdb4 - 10.4.5.177




Issue with below 2:



dlthemhdb4:~ # cat /etc/*release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 2




dlthpehdb4:~ # cat /etc/*release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 2



both above are clients on suse 12 sp2 and have issues with

dlthpehdb4:~ # cat /etc/fstab |grep -i nfs
10.250.17.12:/backup_hpe /backup_hpe nfs nfsvers=4.1,_netdev,defaults 0 0


Works fine on this one

[root@daldlthqedb3 ~]# df -hT |grep -i nfs
dal09ammyum01.imzcloud.ibmammsap.local:/sds nfs4Â Â Â Â Â  6.0TÂ  4.3TÂ  1.4TÂ  77% /sds
10.250.17.12:/backup_hpeÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  nfs4Â Â Â Â Â  6.0TÂ  2.2TÂ  3.5TÂ  40% /backup_hpe
[root@daldlthqedb3 ~]# cat /etc/*release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 4


DLTHDEHAP is the source




mtr , iperf3 utilities in scrbwpdefra11


-----------------------------------------------------------------

SFTP dev svmq1srv1	10.6.2.42	10.70.110.42
ED1 sved1srv0	10.6.1.11

Please create the following directories in sftp dev (10.70.110.42) and then mount these directories from sftp dev to ED1 server.
10.70.110.42:/usr/sap/sftp/FinancialReports		/usr/sap/sftp/FinancialReports		nfs		_netdev,defaults 0 0 
10.70.110.42:/usr/sap/sftp/FinancialReports/TrialBalance		/usr/sap/sftp/FinancialReports/TrialBalance		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/GeneralJournal		/usr/sap/sftp/FinancialReports/GeneralJournal		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/GeneralLedger		/usr/sap/sftp/FinancialReports/GeneralLedger		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/PurchaseJournal		/usr/sap/sftp/FinancialReports/PurchaseJournal		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/IncomeStatement		/usr/sap/sftp/FinancialReports/IncomeStatement		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/IncomeStatement/IS_Main		/usr/sap/sftp/FinancialReports/IncomeStatement/IS_Main		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/IncomeStatement/IS_Sales_Channels		/usr/sap/sftp/FinancialReports/IncomeStatement/IS_Sales_Channels		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/CostCenter/			/usr/sap/sftp/FinancialReports/CostCenter/		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/CostCenter/Cost_Center		/usr/sap/sftp/FinancialReports/CostCenter/Cost_Center		nfs		_netdev,defaults 0 0
10.70.110.42:/usr/sap/sftp/FinancialReports/CostCenter/Cost_Center_Breakdown		/usr/sap/sftp/FinancialReports/CostCenter/Cost_Center_Breakdown		nfs		_netdev,defaults 0 0



18001080

CHG0280146 04-05-2023 18:30:00

-	Additional 28 CPUs and 72 GB RAM on each of the hosts : sapapp31 & sapapp31-ha
-	Add 300GB additional storage for mount point creation on host: sapapp31 to run upgrade tool

To place the cluster in maintenance mode:
#crm configure property maintenance-mode=true

To place the cluster back in managed mode:
#crm configure property maintenance-mode=false


 vgcreate tempvg /dev/sdX (PV)
lvcreate -L 300G -n templv tempvg
mkfs.ext2/3/4 path of lvdisplay						/dev/CS14515030_vg/CS14515030_lv
XFS format a new LV  mkfs.xfs /dev/vg_xfs/xfs_db
mkdir /SAPHRSP
mount
vi /etc/fstab

new CPU is +28= 12+28=40
new ram is +72 = 128+72=200



[root@sapapp31 ~]# lscpu |grep -i cpu
CPU op-mode(s):        32-bit, 64-bit
CPU(s):                12
On-line CPU(s) list:   0-11
CPU family:            6
Model name:            Intel(R) Xeon(R) Platinum 8280L CPU @ 2.70GHz
CPU MHz:               2700.000
NUMA node0 CPU(s):     0-11
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap xsaveopt arat md_clear flush_l1d arch_capabilities

[root@sapapp31 ~]# free -gh
             total       used       free     shared    buffers     cached
Mem:          125G       123G       2.2G        47G       797M       100G
-/+ buffers/cache:        21G       103G
Swap:          95G       607M        95G




[root@sapapp31-ha ~]# lscpu |grep -i cpu
CPU op-mode(s):        32-bit, 64-bit
CPU(s):                12
On-line CPU(s) list:   0-11
CPU family:            6
Model name:            Intel(R) Xeon(R) Platinum 8280L CPU @ 2.70GHz
CPU MHz:               2700.000
NUMA node0 CPU(s):     0-11
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap xsaveopt arat md_clear flush_l1d arch_capabilities
[root@sapapp31-ha ~]# free -gh
             total       used       free     shared    buffers     cached
Mem:          125G       117G       8.3G        43G       849M        91G
-/+ buffers/cache:        24G       100G
Swap:          95G       1.6G        94G




847882973787



CHG0278712 | BUR | LIX				Approved
CHG0280324 | BUR | LIX | ORA		Approved
CHG0279563 | LIX | ORA				Approved by Sandeep J

CHG0280277




APRH.perkinelmer.com (165.88.186.62)



Queue: 	DNS:	                               Make/Model:
APRH	APRH.perkinelmer.com	HP LaserJet Pro 4002dn		165.88.186.62
APRK	APRK.perkinelmer.com	HP LaserJet Pro 4002dn		165.88.186.63
APRJ	APRJ.perkinelmer.com	HP LaserJet Pro 4002dn		165.88.186.64
WI09	WI09.perkinelmer.com	HP LaserJet Pro 4002dn		165.88.186.65



lpadmin -p APRH -v socket://APRH:9100
lpadmin -p APRK -v socket://APRK:9100
lpadmin -p APRJ -v socket://APRJ:9100
lpadmin -p WI09 -v socket://WI09:9100



cupsenable 	APRH
cupsaccept APRH


br3psolss40:/sapstage/Linux_Fleet-Osquery-v5.0.5_BRP.x86_64.rpm



CHG0278331 - Precheck- https://samuel.sap.mgapp.ibm.com/PDR/buildInformation?id=6459e3a68f8bf5b11783a2ab&name=Overview Â  Â  Â  Â  Â  Â  
CHG0278950 - Precheck- https://samuel.sap.mgapp.ibm.com/NL1/buildInformation?id=6459e35306a2a43af52b7c33&name=OverviewÂ 




CHG0279181 Mhi Rj Aviation Ulc -- MCL Linux 5/10/2023 20:00

CHG0279179 Mhi Rj Aviation Ulc -- MCL Linux 5/10/2023 20:00


SAPAPP15 - 10.207.61.37				186 patches

SAPAPP36 - 10.207.61.197			185 patches

SAPAPP31 - 10.207.61.84				334 patches

TTAR3DEV - 10.207.61.72				182 patches

BIPRDAPP1 - 10.207.61.28			119 patches

TSLS4PRODDB - 10.207.61.123			289 patches

EWMAPP1 - 10.207.61.77				319 patches

ttas4hpdb - 10.207.61.161			150 patches

ttapodev - 10.207.62.156			171 patches






/dev/nvme7n1   refreshvg lvm2 a--  512.00g 12.00g
[root@hcils4dbqa00 ~]# df -hT /Refresh
Filesystem                      Type  Size  Used Avail Use% Mounted on
/dev/mapper/refreshvg-refreshlv xfs   500G  543M  500G   1% /Refresh

[root@hcils4dbqa00 Refresh]# lvdisplay |grep -i refreshvg
  LV Path                /dev/refreshvg/refreshlv
  VG Name                refreshvg
  
  /dev/nvme7n1             lvm2 ---  512.00g 512.00g

Name:

appDisk1

ID:

6434d37cfb2bd70012e374af

Type:

gp2

EBS volume ID:

vol-0b33415ccd12a46ab




Name:

appDisk2

ID:

64363b59fb2bd70012e374e9

Type:

gp2

EBS volume ID:

vol-0e9747a67f02b7189



  
  
  [root@hcils4dbqa00 /]# dmsetup info -c | grep refreshlv
refreshvg-refreshlv  254  13 L--w    1    1      0 LVM-SLMnkwD7ufBOaKZDaIAKoP2FEUgSL9g041YJTN3E8BZKbdzMdq02dFeGNU7acWsv
lsof | grep "254,13"


[19:19] Soma Gupta Gupta
    Outage start time : 05-09-2023 05:31:00
Outage End time  : 05-09-2023 06:35:00
Infra issue             : N/A
hold if any            : N/A
RCA Type             : Formal
RCA Assigned to  : Ravi MALIK
Assignment Grp   : MA-ASGN-SAP-LIN
RCA/PRB              : RCA0009799/PRB0061904
Impacted CI         : TGYERPPRDAP1
(1 liked)Edited<https://teams.microsoft.com/l/message/19:9b0a6b86d59841f8bdde95eb253c1cac@thread.tacv2/1683640154180?tenantId=f260df36-bc43-424c-8f44-c85226657b01&amp;groupId=d8d41ec6-244e-4f62-aa14-9ea57d36fff7&amp;parentMessageId=1683639780503&amp;teamName=MA-SAP-B2&amp;channelName=scx-sapb2-tgy&amp;createdTime=1683640154180&amp;allowXTenantAccess=false>





10.194.67.56
root    K7PF7aMfs4

Loot : SonyLiv Premium For Free (2 Years)

Login To Your Sony Liv Account > Activate Offer > Apply Code : SL1UDJYU2G

Repeat This Process 4 Times On Single Account & Get Free 2 Years Sony Liv Premium Subscription.




AGESVTQ2SRV1Â Â Â  10.6.2.123Â Â Â  10.70.110.116

//AGESVTQ2SRV1/STRS_Output
//AGESVTQ2SRV1/STRS_Output/SOA_DIVISION
//AGESVTQ2SRV1/STRS_Output/SOA_STORE
//10.92.99.149/STRS_Output/SOA_DIVISION		source missing




CHG0274593 & CHG0274594



CHG0280775	13-05-2023 06:30:00   13-05-2023 17:30:00	FRA02
Current version: SLES 12 SP04
Target version: SLES 12 SP05

This 05/12/2023 - 10:00 - NIX  remediation is for the following CIs:

Patch Group (Prod2) - sm9p185173114	SUSE	10.135.224.28	Production	P20 - SAP  (App/DB) - DB2 10.5
Patch Group (Prod2) - sm9v235532009	SUSE	10.135.224.34	Production	P14 - SAP  (App/DB) - DB2 10.5
Patch Group (Prod2) - sm9v185173118	SUSE	10.135.224.31	Production	P16 - SAP  (App/DB) - DB2 10.5

snapshot task CTASK0733915



CHG0280899- DR Hana- Ravi malik to take care on 18th


elleman.lopez.garita@kyndryl.com and default password is Ch@ngem3




Hi AP team, please provide OS SME for below changes. Thanks! General
CHG0275789 CST/CDT - 05/19/2023 - 11:00 - NIX - LBU - OS Update SLES 12 SP04 to SP05 - HC - VULN - NON PROD		approved
CHG0275790 CST/CDT - 05/19/2023 - 11:00 - NIX - LBU -OS Update SLES 12 SP04 to SP05 - HC - VULN- NON PROD		approved
CHG0275791 CST/CDT - 05/19/2023 - 11:00 - NIX - LBU - OS Update SLES 12 SP04 to SP05 - HC - VULN - NON PROD



CHG0280899 18-05-2023 06:30:00 18-05-2023 11:30:00
Sp4 to SP5 Upgrade

Patch Group (Prod1A) - sm9dcnlcslx01Â Â  Â SUSEÂ Â  Â 10.210.240.11Â Â  Â Disaster recoveryÂ Â  Â P33 - SAP Â (DB) - HANA

10.127.235.193	smiths-par01-pod1-phana-1024-01.imzcloud.ibmammsap.local




on tsls4hmckap2:
RAM -- Increase from 159GB to 250GB
CPU -- Increase from 40CPU to 64CPU


On tsls4hmckap2:
RAM -- Increase from 159GB to 250GB
CPU -- Increase from 40CPU to 64CPU




eval "export SSHPASS='""$(echo "May2023&July2023")""'";sshpass -e ssh -q -n ibmrmalik@10.139.120.81 -o "ConnectTimeout 3" -o Â "StrictHostKeyChecking no"Â  "uname -sn"

eval "export SSHPASS='""$(echo "<your password>")""'";sshpass -e ssh -q -n ibmrmalik@10.139.120.81 -o "ConnectTimeout 3" -o Â "StrictHostKeyChecking no"Â  "uname -sn"



CHG0275539	19-05-2023 06:30:00	19-05-2023 09:30:00
Patch Group () - zffdappdb003	Redhat	100.126.67.26	Development	SE1, SE3, SE6 - SAP  (DB) - Oracle 19.14.0.0.0 





GKNADSPRDDB on ammdal13custesx046.imzcloud.ibmammsap.local
gknadsprddbh on ammdal13custesx054.imzcloud.ibmammsap.local

[root@gknadsprddb log]$
 Log file tar ball: /var/log/scc_gknadsprddb_230518_2149.txz
  Log file size:     5.5M
  Log file md5sum:   2a9f7aa3cc5a19f7da01b99ce80cc119
=============================================================================


[root@gknadsprddb log]$ uptime
 22:09pm  up   2:05,  2 users,  load average: 0.09, 0.21, 0.28
[root@gknadsprddb log]$ date
Thu May 18 22:09:05 EDT 2023






[root@gknadsprddbh log]$
==[ DONE ]===================================================================
  Log file tar ball: /var/log/scc_gknadsprddbh_230518_2150.txz
  Log file size:     6.0M
  Log file md5sum:   bc6a039ca33d93d39e49b5997c426fba
=============================================================================

[root@gknadsprddbh log]$ uptime
 22:09pm  up  10:22,  9 users,  load average: 0.57, 0.78, 0.88
[root@gknadsprddbh log]$ date
Thu May 18 22:09:26 EDT 2023



hb_report -f "2023/05/18 00:00" -t "2023/05/18 23:59" /tmp/hb_report-$(date +"%Y%m%d-%H%M")




hb_report -f "2023/05/18 18:30" -t "2023/05/18 21:30" /tmp/hb_report-$(date +"%Y%m%d-%H%M")
[root@gknadsprddbh ~]$ hb_report -f "2023/05/18 10:00" -t "2023/05/18 13:00" /tmp/hb_report-$(date +"%Y%m%d-%H%M")
INFO: gknadsprddbh# The report is saved in /tmp/hb_report-20230518-2339.tar.bz2


[root@gknadsprddb log]$ hb_report -f "2023/05/18 18:30" -t "2023/05/18 21:30" /tmp/hb_report-$(date +"%Y%m%d-%H%M")
INFO: gknadsprddb# The report is saved in /tmp/hb_report-20230518-2232.tar.bz2



146.89.173.192  100.126.67.1    255.255.255.192 UG    0      0        0 net0
146.89.174.192  100.126.67.1    255.255.255.192 UG    0      0        0 net0



GATEWAY10=100.126.67.1
NETMASK10=255.255.255.192
ADDRESS10=146.89.173.192
GATEWAY10=100.126.67.1
NETMASK10=255.255.255.192
ADDRESS10=146.89.174.192





additional vCPU - 12 vCPU		current is 4   final will be 16 CPU
Additional memory -  24GB 		current is 24	dinal will be 40GB RAM




[11:27] Senthil D S
    
imzcloud.ibmammsap.local/IBM AMM Customers/IAG GBS Limited (0000024562)/Servers - Linux/

-rw------- 1 root   root   26640384 May 19 23:34 scc_tslbwprdhdbdr_230519_2319.txz



CHG0277085	20-05-2023 07:30:00	20-05-2023 11:30:00	Dal09 Automation
Patch Group (PROD3) - dlthpehap10	Redhat	10.4.5.158	Production	<SID> - SAP <Landscape> (App)
Patch Group (PROD3) - dlthpehap9	Redhat	10.4.5.156	Production	<SID> - SAP <Landscape> (App)
Patch Group (PROD3) - dlthpghap5	Redhat	10.4.5.188	Production	HPG - SAP  (App) - NA


CHG0280536	20-05-2023 07:30:00	20-05-2023 15:30:00	Manual	SNG		Anupam
OS Upgrade from SUSE Linux 12 SP2/SP4 to SP5 
agesvepmhsrv2 Linux Server Suse Linux 12 SP4 Suse Linux 12 SP5
AGESVCPMHSRV1 Linux Server Suse Linux 12 SP4 Suse Linux 12 SP5
SVCC2SRV0 Linux Server Suse Linux 12 SP2 Suse Linux 12 SP5
SVCC2SRV1 Linux Server Suse Linux 12 SP2 Suse Linux 12 SP5




    Team - CS12151692,CS12182219,CS12206371 - Pls assign to OS team



TSLS4PRODDB - 10.207.61.123		tta-che01-pod1-phana-h8-12000-001.imzcloud.ibmammsap.local		BIOS	Critical  Critical updates solve known reliability and or vulnerability concerns. 2.52 6-27-2022	2.60 10-7-2022
TSLS4PRODDBH - 10.207.61.113	tta-che01-pod1-phana-h8-12000-002.imzcloud.ibmammsap.local		BIOS	Critical  Critical updates solve known reliability and or vulnerability concerns. 2.41 2-15-2022	2.60 10-7-2022

CS13425444 PS2-WDP-APP
CS13425537 PS2-S4P-CI
CS13425538 PS2-S4P-DB
CS13425548 PS2-S4P-DB-HA
CS13425551 PS2-S4P-CI



HANA servers rear for CHG0280407  all xfs

	Patch Group (15) - br3qsapdb20	SUSE	10.138.10.230	QA	<SID> - SAP <Landscape> (DB)	15,18

Patch Group (15) - br3tsapdb22	SUSE	10.138.10.157	Test	<SID> - SAP <Landscape> (DB)	14,17

Patch Group (15) - br3qgtsdb20	SUSE	10.138.10.148	QA	<SID> - SAP <Landscape> (DB)	15,18

Patch Group (15) - br3tgtsdb22	SUSE	10.138.10.173	Test	<SID> - SAP <Landscape> (DB)	14,17

Patch Group (15) - br3tscmdb22	SUSE	10.138.10.183	Test	<SID> - SAP <Landscape> (DB)	14,17

Patch Group (15) - br3qscmdb20	SUSE	10.138.10.171	QA	<SID> - SAP <Landscape> (DB)		15,18


Patch Group (15) - br3tgtsas22	SUSE	10.138.10.161	Test	<SID> - SAP <Landscape> (App)	16,28
Patch Group (15) - br3tscmas22	SUSE	10.138.10.101	Test	<SID> - SAP <Landscape> (App)	16,30
Patch Group (15) - br3qscmas20	SUSE	10.138.10.175	QA	<SID> - SAP <Landscape> (App)		16,29	
Patch Group (15) - br3qsapas20	SUSE	10.138.10.91	QA	<SID> - SAP <Landscape> (App)		16,30
Patch Group (15) - br3qgtsas20	SUSE	10.138.10.179	QA	<SID> - SAP <Landscape> (App)		16,30
Patch Group (15) - br3tsapas22	SUSE	10.138.10.116	Test	<SID> - SAP <Landscape> (App)	16,29


to comment lines 2 through 4 of bla.conf:
sed -i '2,4 s/^/#/' /etc/fstab

to uncomment
sed -i '/'#'/s/^#//g' /etc/fstab	working to uncomment





ifdown vlan1;ifup vlan1



eval "export SSHPASS='""$(echo 'May2023&July2023')""'";sshpass -e ssh -q -n ibmrmalik@10.139.16.11 -o "ConnectTimeout 3" -o "StrictHostKeyChecking no"Â  "uname -sn"


sshpass -p 'May2023&July2023' ssh ibmrmalik@10.139.16.11 'ls /tmp'

sshpass -p 'May2023&July2023' ssh -q -n ibmrmalik@10.139.16.11 -o "StrictHostKeyChecking no" '"ls /tmp"'



CHG0281484

br3qscmss36Â Â Â  10.138.10.107Â Â Â Â  QAÂ Â Â  QCM - SAPÂ  (App) -Â  ABAP Cluster
br3qscmss37Â Â Â  10.138.10.76Â Â Â  QAÂ Â Â  QCM - SAPÂ  (App) -Â  ABAP Cluster

Â 

br3qgtsss35Â Â Â  10.138.10.38Â Â Â  QAÂ Â Â  QGT - SAPÂ  (App) - ABAP Cluster
br3qgtsss36 10.138.10.62Â Â Â  QAÂ Â Â  QGT - SAPÂ  (App) - ABAP Cluster

Â 

br3qsapss31Â Â Â  SUSEÂ Â Â  10.138.10.105Â Â Â  QAÂ Â Â  Q4H - SAPÂ  (App) - ABAP Cluster
br3qsapss30Â Â Â  SUSEÂ Â Â  10.138.10.80Â Â Â  QAÂ Â Â  Q4H - SAPÂ  (App) - ABAP Cluster

Â 


br3qgtsdb36Â Â Â  SUSEÂ Â Â  10.138.10.58Â Â Â  QAÂ Â Â  QGT - SAPÂ  (DB) - HANA				mon01-pod1-4tb-host08.imzcloud.ibmammsap.local	vHana
	br3qgtsdb37Â Â Â  SUSEÂ Â Â  10.138.10.82Â Â Â  QAÂ Â Â  QGT - SAPÂ  (DB) - HANA		primary				mon01-pod1-4tb-host07.imzcloud.ibmammsap.local	vHana   23-25

Â 

br3qscmdb37Â Â Â  SUSEÂ Â Â  10.138.10.145Â Â Â  QAÂ Â Â  QCM - SAPÂ  (DB) - HANA		mon01-pod1-4tb-host07.imzcloud.ibmammsap.local	vHana
	br3qscmdb36Â Â Â  SUSEÂ Â Â  10.138.10.88Â Â Â  QAÂ Â Â  QCM - SAPÂ  (DB) - HANA		primary			mon01-pod1-4tb-host16.imzcloud.ibmammsap.local	vHana		23-25

Â 

br3qsapdb32Â Â Â  SUSEÂ Â Â  10.138.10.194Â Â Â  QAÂ Â Â  <SID> - SAP <Landscape> (HANA)			mon01-pod1-6tb-host005.imzcloud.ibmammsap.local	vHana
	br3qsapdb33Â Â Â  SUSEÂ Â Â  10.138.10.190Â Â Â  QAÂ Â Â  <SID> - SAP <Landscape> (HANA)	primary				mon01-pod1-6tb-host006.imzcloud.ibmammsap.local	vHana	24-27

presnap link https://samuel.sap.mgapp.ibm.com/BR3/buildInformation?id=6471587ed2da9b1cfb2363a2&name=Overview

1	Standby the primary node
2	Perform Actvity on HANA primary ( Both OS patching and CIS remediation)
	Ask SAP to register the patched node as secondary
3	Attach back the Primary node to cluster ( set the node backÂ  online)
4	Wait for the HSR Sync
5	Set HA node standby
6	Perform Actvity on HANA HAN node ( Both OS patching and CIS remediation)
7	HSR registration
8	Attach back the HA node to cluster ( set the node backÂ  online)
9	Wait for the HSR Sync
Â 	Â 
Â 	Â 
1	Standby the ASCS node (primary node)
2	Complete OS activities
3	Attach back the node by keeping it online
4	wait for the automatic ERS failover (ERS will be on the patched node)
5	Standby of HA node
6	Complete OS activities
7	Attach back the node by keeping it online
8	wait for the automatic ERS failover (ERS will be on the patched node)


lrwxrwxrwx 1 root rootÂ Â  18 May 27 01:49 /usr/bin/python -> /usr/bin/python2.7
lrwxrwxrwx 1 root rootÂ Â  18 May 27 01:49 /usr/bin/python3 -> /usr/bin/python3.4


Health Check\Vulnerability remediation from Samuel - Known issues:

 
1. Python version error - Make sure the python version is 2.7 or SLES12, and 3.6 for SLES15
2. Cryptography error - Install the python cryptography package "zypper in python3-cryptography"
3. THP (Transparent huge pages) error - Make sure to disable THP (steps can be found in KB KB0016944 - page no 38 in the attachment)
4. "btrfs command not found" error - Make sure the env variable for btrfs in grun.cfg is set"
    # echo $btrfs_relative_path (if the path is empty, set using below command)
    # export btrfs_relative_path=/usr/sbin/btrfs
    
5. Auditd deamon error - Make sure the auditd service is started, if not, enable the server and reboot the server 
    # systemctl enable auditd
	
	
	
# systemctl get-default
graphical.target

# systemctl set-default multi-user.target

# systemctl isolate multi-user.target

# systemctl get-default 
multi-user.target



cat /sys/kernel/mm/transparent_hugepage/enabled
sed -i 's/quiet/quiet transparent_hugepage=never/g' /etc/default/grub
grub2-mkconfig -o /boot/grub2/grub.cfg



#python -V
#ls -l /usr/bin/python* --> to check if we have other(new) versions
#rm -rf /tmp/Python* 2>/dev/null --> to delete python version 2
#rm -f /usr/bin/python && ln -s /usr/bin/python3 /usr/bin/python 



TASK [sles-cis-bundle : SCORED | 6.2.20 | PATCH | Ensure shadow group is empty] ***
changed: [br3qgtsdb36.imzcloud.ibmammsap.local]

TASK [sles-cis-bundle : include_tasks] *****************************************
included: /tmp/awx_351334_zqmcx_24/project/roles/sles-cis-bundle/tasks/reboot.yml for br3qgtsdb36.imzcloud.ibmammsap.local

TASK [sles-cis-bundle : reboot machine] ****************************************
changed: [br3qgtsdb36.imzcloud.ibmammsap.local]

TASK [Run CIS on Windows] ******************************************************
skipping: [br3qgtsdb36.imzcloud.ibmammsap.local]

RUNNING HANDLER [sles-cis-bundle : sysctl flush ipv4 route table] **************
changed: [br3qgtsdb36.imzcloud.ibmammsap.local]

RUNNING HANDLER [sles-cis-bundle : restart auditd] *****************************
changed: [br3qgtsdb36.imzcloud.ibmammsap.local]

RUNNING HANDLER [sles-cis-bundle : generate new grub config] *******************
fatal: [br3qgtsdb36.imzcloud.ibmammsap.local]: FAILED! => {"changed": true, "cmd": ["/usr/sbin/grub2-mkconfig", "-o", "/boot/grub2/grub.cfg"], "delta": "0:00:02.730244", "end": "2023-05-27 04:37:21.491369", "msg": "non-zero return code", "rc": 127, "start": "2023-05-27 04:37:18.761125", "stderr": "Generating grub configuration file ...\\nFound theme: /boot/grub2/themes/SLE/theme.txt\\nFound linux image: /boot/vmlinuz-4.12.14-95.120-default\\nFound initrd image: /boot/initrd-4.12.14-95.120-default\\nFound linux image: /boot/vmlinuz-4.12.14-95.114-default\\nFound initrd image: /boot/initrd-4.12.14-95.114-default\\n/etc/grub.d/80_suse_btrfs_snapshot: line 11: btrfs: command not found", "stderr_lines": ["Generating grub configuration file ...", "Found theme: /boot/grub2/themes/SLE/theme.txt", "Found linux image: /boot/vmlinuz-4.12.14-95.120-default", "Found initrd image: /boot/initrd-4.12.14-95.120-default", "Found linux image: /boot/vmlinuz-4.12.14-95.114-default", "Found initrd image: /boot/initrd-4.12.14-95.114-default", "/etc/grub.d/80_suse_btrfs_snapshot: line 11: btrfs: command not found"], "stdout": "", "stdout_lines": []}

RUNNING HANDLER [sles-cis-bundle : restart sshd] *******************************

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
br3qgtsdb36.imzcloud.ibmammsap.local : ok=248  changed=124  unreachable=0    failed=1    skipped=114  rescued=0    ignored=0   




TASK [sles-cis-bundle : SCORED | 6.2.20 | PATCH | Ensure shadow group is empty] ***
changed: [br3qscmdb37.imzcloud.ibmammsap.local]

TASK [sles-cis-bundle : include_tasks] *****************************************
included: /tmp/awx_351332_t7_1mjec/project/roles/sles-cis-bundle/tasks/reboot.yml for br3qscmdb37.imzcloud.ibmammsap.local

TASK [sles-cis-bundle : reboot machine] ****************************************
changed: [br3qscmdb37.imzcloud.ibmammsap.local]

TASK [Run CIS on Windows] ******************************************************
skipping: [br3qscmdb37.imzcloud.ibmammsap.local]

RUNNING HANDLER [sles-cis-bundle : sysctl flush ipv4 route table] **************
changed: [br3qscmdb37.imzcloud.ibmammsap.local]

RUNNING HANDLER [sles-cis-bundle : restart auditd] *****************************
changed: [br3qscmdb37.imzcloud.ibmammsap.local]

RUNNING HANDLER [sles-cis-bundle : generate new grub config] *******************
fatal: [br3qscmdb37.imzcloud.ibmammsap.local]: FAILED! => {"changed": true, "cmd": ["/usr/sbin/grub2-mkconfig", "-o", "/boot/grub2/grub.cfg"], "delta": "0:00:02.804948", "end": "2023-05-27 04:25:38.591996", "msg": "non-zero return code", "rc": 127, "start": "2023-05-27 04:25:35.787048", "stderr": "Generating grub configuration file ...\\nFound theme: /boot/grub2/themes/SLE/theme.txt\\nFound linux image: /boot/vmlinuz-4.12.14-95.120-default\\nFound initrd image: /boot/initrd-4.12.14-95.120-default\\nFound linux image: /boot/vmlinuz-4.12.14-95.114-default\\nFound initrd image: /boot/initrd-4.12.14-95.114-default\\n/etc/grub.d/80_suse_btrfs_snapshot: line 11: btrfs: command not found", "stderr_lines": ["Generating grub configuration file ...", "Found theme: /boot/grub2/themes/SLE/theme.txt", "Found linux image: /boot/vmlinuz-4.12.14-95.120-default", "Found initrd image: /boot/initrd-4.12.14-95.120-default", "Found linux image: /boot/vmlinuz-4.12.14-95.114-default", "Found initrd image: /boot/initrd-4.12.14-95.114-default", "/etc/grub.d/80_suse_btrfs_snapshot: line 11: btrfs: command not found"], "stdout": "", "stdout_lines": []}

RUNNING HANDLER [sles-cis-bundle : restart sshd] *******************************

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
br3qscmdb37.imzcloud.ibmammsap.local : ok=248  changed=123  unreachable=0    failed=1    skipped=114  rescued=0    ignored=0



TASK [sles-cis-bundle : SCORED | 6.2.20 | PATCH | Ensure shadow group is empty] ***
ok: [br3qsapdb32.imzcloud.ibmammsap.local]

TASK [sles-cis-bundle : include_tasks] *****************************************
included: /tmp/awx_351373_tfu5d14z/project/roles/sles-cis-bundle/tasks/reboot.yml for br3qsapdb32.imzcloud.ibmammsap.local

TASK [sles-cis-bundle : reboot machine] ****************************************
changed: [br3qsapdb32.imzcloud.ibmammsap.local]

TASK [Run CIS on Windows] ******************************************************
skipping: [br3qsapdb32.imzcloud.ibmammsap.local]

PLAY [all] *********************************************************************

TASK [Remove socks5 tunel handler] *********************************************
skipping: [br3qsapdb32.imzcloud.ibmammsap.local]

PLAY RECAP *********************************************************************
br3qsapdb32.imzcloud.ibmammsap.local : ok=241  changed=20   unreachable=0    failed=0    skipped=120  rescued=0    ignored=0



Your Request is submitted successfully. The processing will be completed in 24 hours. Please do not perform any transaction during the period. Reference ID is 25106509




1.    CHG0280839	approved
2.    CHG0279192	approved
3.    CHG0280844	approved
4.    CHG0280818	need SR OS engineer assigned
5.    CHG0280845	approved
	  CHG0282968	OS performer assignment pending
	  
	  
--------------------------------------
CS13482831
zffpapp001- 100.126.67.140
zffpapp001-ha- 100.126.67.141 
zffsappdb006- 100.126.67.45 
zffsappdb001- 100.126.67.20

Please rename the following print queue, but keep the same IP address:

Old Printer:	412_LLGMX_ADB_490B
New Printer:	412_LLGMX_ADB_4406A

For confirmation, the IP address is 10.28.223.9

lpadmin -p 412_LLGMX_ADB_4406A -v socket://10.28.223.9 -E

CS13482053
 zffsappdb001-100.126.67.20 
 zffpapp001-ha -100.126.67.141
 zffpapp001 100.126.67.140
 zffsappdb006  100.126.67.45

Please change the IP Address to a printer according to below details in S02 and OR9

Printer name :          MT1P10003
New IP :                  10.243.86.206

Printer name :          MT1P10004
New IP :                  10.243.86.205 


[root@zffpapp001 ~]# lpstat -t |grep -i MT1P10003
device for mt1p10003: lpd://10.243.122.247/mt1p10003
mt1p10003 accepting requests since Thu May 25 08:58:49 2023
printer mt1p10003 is idle.  enabled since Thu May 25 08:58:49 2023

[root@zffpapp001 ~]# lpstat -t |grep -i MT1P10004
device for mt1p10004: lpd://10.243.122.232/mt1p10004
mt1p10004 accepting requests since Thu May 25 08:59:06 2023
printer mt1p10004 is idle.  enabled since Thu May 25 08:59:06 2023


[root@zffpapp001 ~]# lpadmin -x mt1p10003

[root@zffpapp001 ~]# 

lpadmin -p mt1p10003 -v socket://10.243.86.206 -E

lpadmin -p mt1p10004 -v socket://10.243.86.205  -E



CHG0282205	Upgrade - CST/CDT - 06/09/2023 - 20:00 - NIX - S5C - Perform SLE12 SP4->SLES12 SP5 upgrade - 1Q23,2Q23- Troop C(SAPB1)
CHG0274323	Upgrade - CST/CDT - 06/10/2023 - 23:00 - NIX - BS4 - PATCH - HC - VULN - 1Q23,2Q23- Troop C(SAPB1)



CS13486280
e02.zf-world.com (zffsappdb006), s02.zf-world.com (zffsappdb001), or9.zf-world.com (zffpapp001.zf-world.com, zffpapp001-ha.zf-world.com)
zffsappdb001-100.126.67.20 
 zffpapp001-ha -100.126.67.141
 zffpapp001 100.126.67.140
 zffsappdb006  100.126.67.45


Please change IP for printer queue CZEP64001 on E02, S02, OR9 :
Name:                    oldIP:
CZEP64001    10.11.49.114
Name:                    newIP:
CZEP64001    10.11.48.114


[root@zffpapp001 ~]# lpadmin -x mt1p10003

[root@zffpapp001 ~]# 

lpadmin -p CZEP64001 -v socket://10.11.48.114 -E

lpadmin -p mt1p10004 -v socket://10.243.86.205  -E



Reclaiming following unused disks, while reclaiming there will be no impact to customers

IFNIP	Disk Name with Size	Disk Name	Size	CIDR

ziv-ecc-prd    10.78.0.22	 Disk name /dev/sdd is not utilized. The disk size is 5.9T 	 /dev/sdd 	5900	ALR
ziv-ecc-prd     10.78.0.22	 Disk name /dev/sdj is not utilized. The disk size is 261G 	 /dev/sdj 	261	ALR
ziv-ecc-prd     10.78.0.22	 Disk name /dev/sdc is not utilized. The disk size is 144G 	 /dev/sdc 	144	ALR
ziv-ecc-prd     10.78.0.22	 Disk name /dev/sdm is not utilized. The disk size is 40G 	 /dev/sdm 	40	ALR
ZIV-ECC-DEV    10.78.0.6	 Disk name /dev/sdq is not utilized. The disk size is 2.4T 	 /dev/sdq 	2400	ALR
ZIV-ECC-DEV    10.78.0.6	 Disk name /dev/sdg is not utilized. The disk size is 262G 	 /dev/sdg 	262	ALR
ZIV-ECC-DEV    10.78.0.6	 Disk name /dev/sdh is not utilized. The disk size is 262G 	 /dev/sdh 	262	ALR
ZIV-ECC-DEV    10.78.0.6	 Disk name /dev/sdi is not utilized. The disk size is 262G 	 /dev/sdi 	262	ALR
ZIV-ECC-DEV    10.78.0.6	 Disk name /dev/sdj is not utilized. The disk size is 261G 	 /dev/sdj 	261	ALR
ZIV-ECC-DEV    10.78.0.6	 Disk name /dev/sdk is not utilized. The disk size is 261G 	 /dev/sdk 	261	ALR
ZIV-ECC-DEV    10.78.0.6	 Disk name /dev/sdf is not utilized. The disk size is 128G 	 /dev/sdf 	128	ALR




open-vm-tools 12.x will not be released on RHEL 7, however some of the vulnerabilities address in 12.x have been backported to open-vm-tools 11.x.
https://access.redhat.com/solutions/6972129


vmware-config-tools.pl --default

Check version   vmware-toolbox-cmd -v

service vmware-tools status

for RHEL 
 yum install open-vm-tools or yum update open-vm-tools
 zypper update open-vm-tools
 
 
 
 
 
 1.	Output Device :- WBKPROD
Printer Model Name:-  HONEYWELL MODEL PM43
Printer IP : 135.9.13.47
Printer Queue Name  : WBKPROD
 
 
2.	Output Device :- WBKHU 
         Printer Model Name:-  HONEYWELL MODEL PM43
         Printer IP : 135.9.13.46
         Printer Hostname :- WBKHU


3.	Output Device :- WBKLASERJET (GRN LASERJET M#2 PRINTER)
Printer Model Name: HP LaserJet M507
Printer IP : 135.9.121.72
Printer Hostname : NPI03778F




lpadmin -p WBKPROD -v socket://135.9.13.47:9100;lpadmin -p WBKHU -v socket://135.9.13.46:9100;lpadmin -p NPI03778F -v socket://135.9.121.72:9100



cupsenable WBKPROD;cupsaccept WBKPROD;cupsenable WBKHU;cupsaccept WBKHU;cupsenable NPI03778F;cupsaccept NPI03778F


lpstat -t |grep WBKPROD
lpstat -t |grep WBKHU
lpstat -t |grep NPI03778F



CHG0283961--- App Cluster --10 Node -- Ravi Malik


CHG0283964





CHG0281562	17-06-2023 06:30:00	17-06-2023 12:30:00
CST/CDT - 06/16/2023 - 20:00 - NIX - WA2 - PATCH & OS Upgrade to SLES 12 SP5 - 1Q23,2Q23- Troop C(SAPB1)

Patch Group (P4) - wa2fipap01	SUSE	10.191.1.138	Production	FIP - SAP  (App)	SuSE Pacemaker cluster setting "no-quorum-policy" may not be set correctly
Patch Group (P4) - wa2fipdb02	SUSE	10.191.1.136	Production	FIP - SAP  (DB)		Required swap is 64 GB, configured swap is 36.0 GB. Check for Pacemaker cluster setting "no-quorum-policy" may not be set correctly.
Patch Group (P4) - wa2fipap01s	SUSE	10.191.1.135	Production	FIP - SAP  (App)	KDUMP not active
Patch Group (P4) - wa2fipdb01	SUSE	10.191.1.137	Production	FIP - SAP  (DB)		Required swap is 64 GB, configured swap is 36.0 GB. Check for Pacemaker cluster setting "no-quorum-policy" may not be set correctly.




Using screen for gaining access to any disconnected session
 
screen -S RaviM     # RaviM could be any name for referring to the session
 
to get back the sesssion
[root@bapv110100 ~]# screen -list
There are screens on:
        128135.RaviM    (Attached)
        107347.RaviM    (Attached)
2 Sockets in /var/run/screens/S-root.


to connect to any session use
screen -x 128135.RaviM    # name from the output above




CHG0284279 17-06-2023 11:00:00	17-06-2023 13:00:00
TPECCAPP1
RAM â€“ no changes, vCPU â€“ augment from 12 to 24 (These will be reverted back after SPS upgrade)




OS team to reserve the permanent disk of 300 GB and extend the below file systems by 50GB each on server tpeccprddbci (10.207.71.24):

/oracle/TEP/sapdata1
/oracle/TEP/sapdata2
/oracle/TEP/sapdata3
/oracle/TEP/sapdata4
/oracle/TEP/sapdata5
/oracle/TEP/sapdata6


tpeccprddbci:oratep 59> df -h /oracle/TEP/sapdata*
Filesystem Size Used Avail Use% Mounted on
/dev/mapper/tepdatavg-oracle_TEP_sapdata1_lv 200G 166G 35G 83% /oracle/TEP/sapdata1
/dev/mapper/tepdatavg-oracle_TEP_sapdata2_lv 200G 166G 35G 83% /oracle/TEP/sapdata2
/dev/mapper/tepdatavg-oracle_TEP_sapdata3_lv 200G 165G 35G 83% /oracle/TEP/sapdata3
/dev/mapper/tepdatavg-oracle_TEP_sapdata4_lv 200G 165G 35G 83% /oracle/TEP/sapdata4
/dev/mapper/tepdatavg-oracle_TEP_sapdata5_lv 200G 165G 35G 83% /oracle/TEP/sapdata5
/dev/mapper/tepdatavg-oracle_TEP_sapdata6_lv 200G 147G 54G 74% /oracle/TEP/sapdata6




CHG0284801	21-06-2023 06:30:00	24-06-2023 08:30:00

Reclaiming following unused disks, while reclaiming there will be no impact to customers, in the following order ( QAS, Pre Prod, Prod)	FRA02
PDL 	Aleksandr Zaytsev     DPE 	Aleksandr Zaytsev

IFNIP	Disk Name with Size	Disk Name	Size	CIDR	Type

100.126.64.18	SCRBWQDEFRA80	Disk name /dev/sde is not utilized. The disk size is 32G 	 /dev/sde 	32	APM	QAS                ( First to reclaim ) 	DONE
[root@scrbwqdefra80 ~]$ lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdb
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdd
[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sde



100.126.64.76	SCRBWRDEFRA50	Disk name /dev/sde is not utilized. The disk size is 1.5T 	 /dev/sde 	1500	APM	Pre-Prod ( second to reclaim  )		DONE
100.126.64.76	SCRBWRDEFRA50	Disk name /dev/sdc is not utilized. The disk size is 64G 	 /dev/sdc 	64	APM	Pre-Prod  ( second to reclaim  )		DONE
100.126.64.76	SCRBWRDEFRA50	Disk name /dev/sdg is not utilized. The disk size is 32G 	 /dev/sdg 	32	APM	Pre-Prod ( second to reclaim  )			DONE

[root@scrbwrdefra50 ~]$ lsscsi

	[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
	[0:0:4:0]    disk    VMware   Virtual disk     1.0   /dev/sde
	[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdg
	
[root@scrbwrdefra50 ~]$ pvdisplay -m /dev/sde
  "/dev/sde" is a new physical volume of "1.50 TiB"
  --- NEW Physical volume ---
  PV Name               /dev/sde
  VG Name
  PV Size               1.50 TiB
  Allocatable           NO
  PE Size               0
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               egcY4D-UCeh-gQa0-WSas-sJSM-F7Sy-rdr8Y2



100.126.64.77	SCRBWRDEFRA60	Disk name /dev/sdc is not utilized. The disk size is 64G 	 /dev/sdc 	64	APM	Pre-Prod ( second to reclaim  )		DONE
100.126.64.77	SCRBWRDEFRA60	Disk name /dev/sdf is not utilized. The disk size is 32G 	 /dev/sdf 	32	APM	Pre-Prod  ( second to reclaim  )	DONE

[root@scrbwrdefra60 ~]$ lsscsi

[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdf


100.126.64.139	SCRBWPDEFRA20	Disk name /dev/sdc is not utilized. The disk size is 64G 	 /dev/sdc 	64	APM	Prod  ( Third  reclaim )		DOne
100.126.64.139	SCRBWPDEFRA20	Disk name /dev/sdl is not utilized. The disk size is 32G 	 /dev/sdl 	32	APM	Prod ( Third  reclaim )			DOne
[root@scrbwpdefra20 ~]$ lsscsi

[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdl



100.126.64.141	SCRBWPDEFRA30	Disk name /dev/sdc is not utilized. The disk size is 64G 	 /dev/sdc 	64	APM	Prod ( Third  reclaim )			DOne
100.126.64.141	SCRBWPDEFRA30	Disk name /dev/sde is not utilized. The disk size is 32G 	 /dev/sde 	32	APM	Prod ( Third  reclaim )			DOne

[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sde



reboot   system boot  4.12.14-122.153- Wed Jun 21 08:37 - 08:47  (00:10)   Logs missing between 8:01 and 8:36 on 21 June

Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1307 audit(1687314614.254:28366619): cwd="/usr/sap/hostctrl/work"
Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1302 audit(1687314614.254:28366619): item=0 name="/usr/sap/hostctrl/exe/sapcimb" inode=335544484 dev=08:04 mode=0100750 ouid=0 ogid=79 rdev=00:00 nametype=NORMAL
Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1302 audit(1687314614.254:28366619): item=1 name="/lib64/ld-linux-x86-64.so.2" inode=3858574 dev=00:2c mode=0100755 ouid=0 ogid=0 rdev=00:00 nametype=NORMAL
Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1327 audit(1687314614.254:28366619): proctitle=2F7573722F7361702F686F73746374726C2F6578652F73617063696D62002D666F726D617400666C6174002D74726163656C6576656C0031002D636F6E74696E75652D6F6E2D6572726F72002D656E756D69002D6E616D65737061636500726F6F742F63696D7632002D636C617373005341505F495453414D4F5350726F6365
Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1300 audit(1687314614.274:28366620): arch=c000003e syscall=59 success=yes exit=0 a0=7feb3ed2a5ac a1=7fff72eafe00 a2=7fff72eb16d8 a3=7feb40713a10 items=2 ppid=237456 pid=237458 auid=4294967295 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=(none) ses=4294967295 comm="sh" exe="/bin/bash" key=(null)
Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1309 audit(1687314614.274:28366620): argc=3 a0="sh" a1="-c" a2=2F62696E2F7368202D632027504154483D222F62696E3A2F7362696E3A2F7573722F62696E3A2F7573722F7362696E3A2F657463222073797363746C202D6E20226B65726E656C2E73686D6D61782227
Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1307 audit(1687314614.274:28366620): cwd="/usr/sap/hostctrl/work"
Jun 21 08:01:14 tslbwprdhdbdr kernel: audit: type=1302 audit(1687314614.274:28366620): item=0 name="/bin/sh" inode=3650485 dev=00:2c mode=0100755 ouid=0 ogid=0 rdev=00:00 nametype=NORMAL
Jun 21 08:36:56 tslbwprdhdbdr kernel: Linux version 4.12.14-122.153-default (geeko@buildhost) (gcc version 4.8.5 (SUSE Linux) ) #1 SMP Tue Mar 7 14:13:19 UTC 2023 (9f7af45)
Jun 21 08:36:56 tslbwprdhdbdr kernel: Command line: BOOT_IMAGE=/vmlinuz-4.12.14-122.153-default root=UUID=e8002023-99cc-4d89-89a2-72faa365afe9 resume=/dev/sda3 splash=silent intel_idle.max_cstate=1 processor.max_cstate=1 transparent_hugepage=never numa_balancing=disable quiet showopts crashkernel=1024M,high crashkernel=512M,low
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x008: 'MPX bounds registers'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x010: 'MPX CSR'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x020: 'AVX-512 opmask'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x040: 'AVX-512 Hi256'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x080: 'AVX-512 ZMM_Hi256'
Jun 21 08:36:56 tslbwprdhdbdr kernel: x86/fpu: Supporting XSAVE feature 0x200: 'Protection Keys User registers'


Jun 21 07:47:02 tslbwprdhdbdr python[208538]: * -10709: Connection failed (RTE:[89006] System call 'connect' failed, rc=111:Connection refused {10.170.64.45:56866 -> 10.170.64.45:30213} (10.170.64.45:56866 -> tslbwprdhdbdr:30213))
Jun 21 07:47:02 tslbwprdhdbdr python[208538]: * -10709: Connection failed (RTE:[89006] System call 'connect' failed, rc=111:Connection refused {10.170.64.45:56882 -> 10.170.64.45:30213} (10.170.64.45:56882 -> tslbwprdhdbdr:30213))



Lenovo Service Request:â€‰3000205565: #eHardware - Drive 1 has a fault [S4BDU863]

tslbwprdhdbdr:~ # dmesg -T |grep -i cannot
[Wed Jun 21 08:36:55 2023] pmd_set_huge: Cannot satisfy [mem 0xc0000000-0xc0200000] with a huge-page mapping due to MTRR override.
[Wed Jun 21 08:36:58 2023] shpchp 0000:01:00.0: Cannot get control of SHPC hotplug

tslbwprdhdbdr:/var/log # cat messages |grep -i "Jun 20 18:5*" |grep -i cannot
Jun 20 18:52:25 tslbwprdhdbdr python[151776]: ls: cannot access '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 18:52:25 tslbwprdhdbdr python[151776]: ls: cannot access '/usr/sap/hostctrl/SMDAgent/default/heap-dump.addons': No such file or directory

06-20-2023 18:50:25
Jun 20 18:51:29 tslbwprdhdbdr python[76461]: ('Error : Network service status.', IndexError('list index out of range',))

Jun 20 18:53:45 tslbwprdhdbdr python[151776]: * -10709: Connection failed (RTE:[89006] System call 'connect' failed, rc=111:Connection refused {10.170.64.45:56932 -> 10.170.64.45:30213} (10.170.64.45:56932 -> tslbwprdhdbdr:30213))
Jun 20 18:53:46 tslbwprdhdbdr python[151776]: * -10709: Connection failed (RTE:[89006] System call 'connect' failed, rc=111:Connection refused {10.170.64.45:56948 -> 10.170.64.45:30213} (10.170.64.45:56948 -> tslbwprdhdbdr:30213))

tslbwprdhdbdr:/var/log # cat messages |grep -i "Jun 20 18:*" |grep -i cannot
Jun 20 18:52:25 tslbwprdhdbdr python[151776]: ls: cannot access '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 18:52:25 tslbwprdhdbdr python[151776]: ls: cannot access '/usr/sap/hostctrl/SMDAgent/default/heap-dump.addons': No such file or directory



Jun 20 23:09:27 tslbwprdhdbdr python[14661]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 23:09:27 tslbwprdhdbdr python[14661]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.addons': No such file or directory

Jun 20 23:10:47 tslbwprdhdbdr python[14661]: * -10709: Connection failed (RTE:[89006] System call 'connect' failed, rc=111:Connection refused {10.170.64.45:64762 -> 10.170.64.45:30213} (10.170.64.45:64762 -> tslbwprdhdbdr:30213))
Jun 20 23:10:47 tslbwprdhdbdr python[14661]: * -10709: Connection failed (RTE:[89006] System call 'connect' failed, rc=111:Connection refused {10.170.64.45:64774 -> 10.170.64.45:30213} (10.170.64.45:64774 -> tslbwprdhdbdr:30213))


Jun 20 14:35:23 tslbwprdhdbdr python[259475]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 15:39:39 tslbwprdhdbdr python[343394]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 16:43:55 tslbwprdhdbdr python[441089]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 17:48:11 tslbwprdhdbdr python[76461]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 18:52:25 tslbwprdhdbdr python[151776]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 19:56:40 tslbwprdhdbdr python[231878]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 21:00:56 tslbwprdhdbdr python[312721]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 22:05:12 tslbwprdhdbdr python[386840]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 20 23:09:27 tslbwprdhdbdr python[14661]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 00:13:42 tslbwprdhdbdr python[98483]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 01:17:57 tslbwprdhdbdr python[176321]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 02:22:17 tslbwprdhdbdr python[262310]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 03:26:35 tslbwprdhdbdr python[350583]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 04:30:50 tslbwprdhdbdr python[425338]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 05:35:06 tslbwprdhdbdr python[50892]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 06:39:22 tslbwprdhdbdr python[133454]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 07:44:29 tslbwprdhdbdr python[208538]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 08:37:47 tslbwprdhdbdr python[19378]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory
Jun 21 09:41:38 tslbwprdhdbdr python[123227]: ln: failed to create symbolic link '/usr/sap/hostctrl/SMDAgent/default/heap-dump.hprof': No such file or directory


Jun 20 18:51:29 tslbwprdhdbdr python[76461]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 20 19:55:44 tslbwprdhdbdr python[151776]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 20 21:00:00 tslbwprdhdbdr python[231878]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 20 22:04:15 tslbwprdhdbdr python[312721]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 20 23:08:31 tslbwprdhdbdr python[386840]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 00:12:46 tslbwprdhdbdr python[14661]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 01:17:01 tslbwprdhdbdr python[98483]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 02:21:17 tslbwprdhdbdr python[176321]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 03:25:39 tslbwprdhdbdr python[262310]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 04:29:54 tslbwprdhdbdr python[350583]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 05:34:10 tslbwprdhdbdr python[425338]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 06:38:25 tslbwprdhdbdr python[50892]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 07:42:41 tslbwprdhdbdr python[133454]: ('Error : Network service status.', IndexError('list index out of range',))
Jun 21 09:40:42 tslbwprdhdbdr python[19378]: ('Error : Network service status.', IndexError('list index out of range',))





CHG0282217 CST/CDT - 06/23/2023 - 20:00 - NIX - A1A - RHEL Upgrade - PATCH - HC - VULN - 1Q23,2Q23- Troop B(SAPB2)	Done
CHG0282129 CST/CDT - 06/23/2023 - 20:00 - NIX - A1A - RHEL Upgrade - PATCH - HC - VULN - 1Q23,2Q23- Troop B(SAPB2)

CHG0280508	CST/CDT - 06/24/2023 - 20:00 - NIX - SZU - PATCH - 1Q23,2Q23- Troop C(SAPB1)





CHG0285895	Reclaiming following unused disks, while reclaiming there will be no impact to customers 
CHG0284113
CHG0284114
CHG0284115



10.135.192.150	 /dev/sdc 	1500	KST			DONE		kstamqm8dqv

[root@kstamqm8dqv ~]# blkid /dev/sdc
[root@kstamqm8dqv ~]# lsscsi |grep -i sdc
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
sdc                                   8:32   0  1.5T  0 disk



10.135.192.182	 /dev/sdc 	2000	KST		kstciams1	DONE

[root@kstciams1 ~]# blkid /dev/sdc
[root@kstciams1 ~]# lsscsi |grep -i sdc
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc	

	
10.135.191.8	 /dev/sdc 	1100	KST		kstdmpsrcs		DONE
[root@kstdmpsrcs ~]# blkid /dev/sdc
[root@kstdmpsrcs ~]# lsscsi |grep -i sdc
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc



10.135.192.163	 /dev/sdc 	180		KST			DONE	
10.135.192.163	 /dev/sdh 	33		KST			DONE
	
[root@kstcitmqt4 ~]# blkid /dev/sdc
[root@kstcitmqt4 ~]# blkid /dev/sdh
[root@kstcitmqt4 ~]# lsscsi |grep -i sdc
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[root@kstcitmqt4 ~]# lsscsi |grep -i sdh
[0:0:8:0]    disk    VMware   Virtual disk     1.0   /dev/sdh
[root@kstcitmqt4 ~]# lsblk |grep -i sdc
sdc                                   8:32   0  180G  0 disk
[root@kstcitmqt4 ~]# lsblk |grep -i sdh
sdh                                   8:112  0   33G  0 disk



10.135.192.144	 /dev/sdl 	123		KST		kstcigwdq1		DONE
[root@kstcigwdq1 ~]# pvdisplay -m /dev/sdl
  --- Physical volume ---
  PV Name               /dev/sdl
  VG Name               gwqdatavg
  PV Size               123.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              31487
  Free PE               31487
  Allocated PE          0
  PV UUID               81lKWO-EHLL-7nEQ-1GdB-4Gx3-WrMv-leaoyZ

  --- Physical Segments ---
  Physical extent 0 to 31486:
    FREE

[root@kstcigwdq1 ~]# vgreduce gwqdatavg /dev/sdl
  Removed "/dev/sdl" from volume group "gwqdatavg"


10.135.192.189	 /dev/sdd 	64		KST			DONE
[root@ksteatt5ts ~]# blkid /dev/sdd
[root@ksteatt5ts ~]# lsscsi |grep -i sdd
[0:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sdd


10.135.192.157	 /dev/sdg 	316		KST			DONE
[root@ksthmqm8qa ~]# blkid /dev/sdg
[root@ksthmqm8qa ~]# lsscsi |grep -i sdg
[0:0:6:0]    disk    VMware   Virtual disk     1.0   /dev/sdg



10.135.192.188	 /dev/sdp 	512		KST
[root@kstemqt5dqv ~]# blkid /dev/sdp			DONE
[root@kstemqt5dqv ~]# lsscsi |grep -i sdp
[33:0:0:0]   disk    VMware   Virtual disk     1.0   /dev/sdp

10.135.192.188	 /dev/sr0	1		KST	cant be deleted 
[root@kstemqt5dqv ~]# lsscsi |grep -i sr0
[0:0:0:0]    cd/dvd  NECVMWar VMware SATA CD00 1.00  /dev/sr0


10.135.191.38	 /dev/sdm 	128		KST		DONE
[root@kstempsrcs ~]# blkid /dev/sdm
[root@kstempsrcs ~]# lsscsi |grep -i sdm
[0:0:13:0]   disk    VMware   Virtual disk     1.0   /dev/sdm



10.135.191.53	 /dev/sdc 	420		KST			DONE
[root@kstgwpsrcs ~]# blkid /dev/sdc
[root@kstgwpsrcs ~]# lsscsi |grep -i sdc
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc



10.135.191.64	 /dev/sdc 	354		KST		Done
10.135.191.64	 /dev/sdm 	32		KST		DONE
[root@kstspop ~]# blkid /dev/sdc
[root@kstspop ~]# blkid /dev/sdm
[root@kstspop ~]# lsscsi |grep -i sdc
[2:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[root@kstspop ~]# lsscsi |grep -i sdm
[2:0:13:0]   disk    VMware   Virtual disk     1.0   /dev/sdm



10.135.192.153	 /dev/sdg 	128		KST
[root@kstpmtzn02 ~]# blkid /dev/sdg
[root@kstpmtzn02 ~]# lsscsi |grep -i sdg
[0:0:6:0]    disk    VMware   Virtual disk     1.0   /dev/sdg



10.135.191.20	 /dev/sdc 	268		KST
[root@kstpmpsrcs ~]# lsscsi |grep -i sdc
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc



CS13569644
Cenovus
 Energy -- HOE
P1 - Severe
hoe#vht2qdb1#Resource Pacemaker sbd CRITICAL: Resource rsc_st is in status FAILED			172.31.254.200


CS13569660
Cenovus
 Energy -- HOE
P1 - Severe
hoe#vht2qdb2#Resource Pacemaker sbd CRITICAL: Resource rsc_st is in status FAILED			172.31.254.209




CHG0286214 - 12 - APP cluster - 28-06-2023 06:30:00	- 28-06-2023 15:30:00

SUSE premigration script from samuel  ---samuel -OS Ops
stop application/db  -- manual =====  during this time need to take rear backup
take snapshot where ever possible, rear backup (need to discuss) ===    TSM team to inititate the each server need to evaluate
reselect the server, exuecute suse migration and post job under OS Ops it will patch server reboots and mounts the FS files and other prechecks
NOTE : when copy serfver name from change to samuel, copy only IFN and filter in the samuel which is better way to avoid error during server selection
application/db start  --- manual


"Update Linux service pack level for the servers listed in this change.

Current version: SLES 12 SP04
Target version: SLES 12 SP05

List of VMS to be upgraded."

Patch Group (6) - br3qscmss36	SUSE	10.138.10.107	QA	QCM - SAP  (App) - NA
Patch Group (6) - br3qgtsdb36	SUSE	10.138.10.58	QA	QGT - SAP  (DB) - HANA
Patch Group (6) - br3qgtsss36	SUSE	10.138.10.62	QA	QGT - SAP  (App) - NA
Patch Group (6) - br3qgtsdb37	SUSE	10.138.10.82	QA	QGT - SAP  (DB) - HANA
Patch Group (6) - br3qscmdb37	SUSE	10.138.10.145	QA	QCM - SAP  (DB) - HANA
Patch Group (6) - br3qgtsss35	SUSE	10.138.10.38	QA	QGT - SAP  (App) - NA
Patch Group (6) - br3qscmdb36	SUSE	10.138.10.88	QA	QCM - SAP  (DB) - HANA
Patch Group (6) - br3qscmss37	SUSE	10.138.10.76	QA	QCM - SAP  (App) - NA
Patch Group (7) - br3qsapdb32	SUSE	10.138.10.194	QA	<SID> - SAP <Landscape> (DB)
Patch Group (7) - br3qsapss31	SUSE	10.138.10.105	QA	Q4H - SAP  (App) - NA
Patch Group (7) - br3qsapss30	SUSE	10.138.10.80	QA	Q4H - SAP  (App) - NA
Patch Group (7) - br3qsapdb33	SUSE	10.138.10.190	QA	<SID> - SAP <Landscape> (DB)
	
	
	https://samuel.sap.mgapp.ibm.com/BR3/buildInformation?id=649b95889e525c68ed41c7de&name=Overview
	
	
br3qscmss36

br3qscmss37	10.138.10.76

br3qgtsss36	10.138.10.62

br3qgtsss35	10.138.10.38

br3qscmdb36 br3qscmdb37 

br3qgtsdb36	SUSE	10.138.10.58	
br3qgtsdb37	SUSE	10.138.10.82

br3qsapdb32	SUSE	10.138.10.194
br3qsapdb33	SUSE	10.138.10.190



CHG0286099

CHG0286100

CHG0286098

CHG0286101

CHG0286055




7875767215  Satpute

CHG0286576
Host name             CFN IP                   IMZ IP
wa2scpdb01	     10.150.5.161	10.191.2.62
wa2scpdb01s      10.150.5.190	10.191.2.22
wa2scpap01	      10.150.5.160	10.191.2.44
wa2scpap01s       10.150.5.170	10.191.2.19



Infra team and vmware teams have been engaged and we are asked to increase the size of the disks in wa2scpdb01.Please refer to the attached screenshot.
Hard disk 3: 1.953TB to be increased to 2 TB
Hard disk 4: 1.029TB to be increased to 1100GB

[root@wa2scpdb01 ~]# crm_mon -1Afr
Stack: corosync
Current DC: wa2scpdb01s (version 1.1.19+20181105.ccd6b5b10-3.31.1-1.1.19+20181105.ccd6b5b10) - partition with quorum
Last updated: Thu Jun 29 21:37:36 2023
Last change: Thu Mar  9 23:29:51 2023 by root via cibadmin on wa2scpdb01s

2 nodes configured
37 resources configured

Online: [ wa2scpdb01 wa2scpdb01s ]

Full list of resources:

 vcenter-fencing-wa2scpdb01     (stonith:fence_vmware_rest):    Started wa2scpdb01s
 vcenter-fencing-wa2scpdb01s    (stonith:fence_vmware_rest):    Started wa2scpdb01
 Resource Group: group-vol-scp
     vol_scpdatavg      (ocf::heartbeat:LVM):   Started wa2scpdb01s
     vol_scplogvg       (ocf::heartbeat:LVM):   Started wa2scpdb01s
     vol_scparchvg      (ocf::heartbeat:LVM):   Started wa2scpdb01s
 Resource Group: group-fs-scp
     fs-backup_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oracle_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orascp_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orascp1_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oran_lv (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-mirrloga_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-mirrlogb_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-logarch_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oraloga_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oralogb_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapbackup_lv    (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapcheck_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata1_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata2_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata3_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata4_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata99_lv    (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orareorg_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orasaptrc_lv    (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oracli_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orastg_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
 Master/Slave Set: master-slave-res [group-drbd]
     Masters: [ wa2scpdb01s ]
     Slaves: [ wa2scpdb01 ]
 Resource Group: group-ora-scp
     IP_DB_SCP  (ocf::heartbeat:IPaddr2):       Started wa2scpdb01s
     OraLSN     (ocf::heartbeat:oralsnr):       Started wa2scpdb01s
     OraSrv     (ocf::heartbeat:oracle):        Started wa2scpdb01s
     TSM_ORA    (systemd:dsmcad_ora):   Started wa2scpdb01s
     TSM_ORAlog (systemd:dsmcad_oralog):        Started wa2scpdb01s

Node Attributes:
* Node wa2scpdb01:
    + master-DRBD0-res                  : 10000
    + master-DRBD1-res                  : 10000
    + master-DRBD2-res                  : 10000
* Node wa2scpdb01s:
    + master-DRBD0-res                  : 10000
    + master-DRBD1-res                  : 10000
    + master-DRBD2-res                  : 10000

Migration Summary:
* Node wa2scpdb01s:
* Node wa2scpdb01:
[root@wa2scpdb01 ~]# crm status
Stack: corosync
Current DC: wa2scpdb01s (version 1.1.19+20181105.ccd6b5b10-3.31.1-1.1.19+20181105.ccd6b5b10) - partition with quorum
Last updated: Thu Jun 29 21:37:40 2023
Last change: Thu Mar  9 23:29:51 2023 by root via cibadmin on wa2scpdb01s

2 nodes configured
37 resources configured

Online: [ wa2scpdb01 wa2scpdb01s ]

Full list of resources:

 vcenter-fencing-wa2scpdb01     (stonith:fence_vmware_rest):    Started wa2scpdb01s
 vcenter-fencing-wa2scpdb01s    (stonith:fence_vmware_rest):    Started wa2scpdb01
 Resource Group: group-vol-scp
     vol_scpdatavg      (ocf::heartbeat:LVM):   Started wa2scpdb01s
     vol_scplogvg       (ocf::heartbeat:LVM):   Started wa2scpdb01s
     vol_scparchvg      (ocf::heartbeat:LVM):   Started wa2scpdb01s
 Resource Group: group-fs-scp
     fs-backup_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oracle_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orascp_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orascp1_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oran_lv (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-mirrloga_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-mirrlogb_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-logarch_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oraloga_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oralogb_lv      (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapbackup_lv    (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapcheck_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata1_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata2_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata3_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata4_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-sapdata99_lv    (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orareorg_lv     (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orasaptrc_lv    (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-oracli_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
     fs-orastg_lv       (ocf::heartbeat:Filesystem):    Started wa2scpdb01s
 Master/Slave Set: master-slave-res [group-drbd]
     Masters: [ wa2scpdb01s ]
     Slaves: [ wa2scpdb01 ]
 Resource Group: group-ora-scp
     IP_DB_SCP  (ocf::heartbeat:IPaddr2):       Started wa2scpdb01s
     OraLSN     (ocf::heartbeat:oralsnr):       Started wa2scpdb01s
     OraSrv     (ocf::heartbeat:oracle):        Started wa2scpdb01s
     TSM_ORA    (systemd:dsmcad_ora):   Started wa2scpdb01s
     TSM_ORAlog (systemd:dsmcad_oralog):        Started wa2scpdb01s






[root@wa2scpdb01 ~]# lsscsi |grep -i sdc
[4:0:2:0]    disk    VMware   Virtual disk     2.0   /dev/sdc
[root@wa2scpdb01 ~]# lsscsi |grep -i sdd
[4:0:3:0]    disk    VMware   Virtual disk     2.0   /dev/sdd


sdc                      8:32   0    2T  0 disk
sdd                      8:48   0    1T  0 disk
â”œâ”€sdd1                   8:49   0  200G  0 part
â”‚ â””â”€vgswap-lvswap      254:0    0  400G  0 lvm  [SWAP]
â””â”€sdd2                   8:50   0  200G  0 part
  â””â”€vgswap-lvswap      254:0    0  400G  0 lvm  [SWAP]



[root@wa2scpdb01s ~]# lsscsi |grep -i sdc
[2:0:2:0]    disk    VMware   Virtual disk     2.0   /dev/sdc
[root@wa2scpdb01s ~]# lsscsi |grep -i sdd
[2:0:3:0]    disk    VMware   Virtual disk     2.0   /dev/sdd

sdc                          8:32   0    2T  0 disk
sdd                          8:48   0    1T  0 disk
â””â”€sdd1                       8:49   0  400G  0 part
  â””â”€vgswap-lvswap          254:0    0  400G  0 lvm  [SWAP]






[root@da5migsrv ~]# pvs
  PV         VG        Fmt  Attr PSize  PFree
  /dev/sda2  rootvg    lvm2 a--  95.49g 18.09g
  /dev/sdb   vgswap    lvm2 a--  24.00g     0
  /dev/sdc   ftptestvg lvm2 a--   5.00g     0
  /dev/sdd   ftptestvg lvm2 a--  15.00g  4.99g
[root@da5migsrv ~]# lsscsi |grep -i sde
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sde
[root@da5migsrv ~]# lsblk
NAME                  MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda                     8:0    0   96G  0 disk
â”œâ”€sda1                  8:1    0  517M  0 part /boot
â””â”€sda2                  8:2    0 95.5G  0 part
  â”œâ”€rootvg-usrlv      254:0    0   10G  0 lvm  /usr
  â”œâ”€rootvg-rootlv     254:1    0   10G  0 lvm  /
  â”œâ”€rootvg-bigfixlv   254:3    0   10G  0 lvm  /var/opt/BESClient
  â”œâ”€rootvg-homelv     254:4    0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv      254:5    0   10G  0 lvm  /opt
  â”œâ”€rootvg-pageing00  254:6    0    2G  0 lvm
  â”œâ”€rootvg-tmplv      254:7    0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv      254:8    0 10.2G  0 lvm  /var
  â””â”€rootvg-vloglv     254:9    0 10.2G  0 lvm  /var/log
sdb                     8:16   0   24G  0 disk
â””â”€vgswap-lvswap       254:2    0   24G  0 lvm  [SWAP]
sdc                     8:32   0    5G  0 disk
â””â”€ftptestvg-ftptestlv 254:10   0   15G  0 lvm
sdd                     8:48   0   15G  0 disk
â””â”€ftptestvg-ftptestlv 254:10   0   15G  0 lvm
sde                     8:64   0  3.6T  0 disk
sr0                    11:0    1 1024M  0 rom
[root@da5migsrv ~]# blkid /dev/sde
[root@da5migsrv ~]#




[root@da5oprddbci ~]# lsscsi |grep -i sdz
[3:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdz
[root@da5oprddbci ~]# pvs |grep -i sdz
[root@da5oprddbci ~]#



Cannot create a test bubble image for group 'GID-bf4e91ef-0159-4698-8af6-48c0b072e8ad' on vSphere Replication Server 'AMMWDC04VRS001.imzcloud.ibmammsap.local' (address '127.0.0.1'). A runtime error occurred in the vSphere Replication Management Server. Exception details: 'Config file hbrcfg.GID-bf4e91ef-0159-4698-8af6-48c0b072e8ad.10704442.vmx.162671 size is 92456, maximum supported size is 81920; Copying config file from instance; Creating image of instance of GID-bf4e91ef-0159-4698-8af6-48c0b072e8ad; Creating test-bubble image of GID-bf4e91ef-0159-4698-8af6-48c0b072e8ad'.


ammdal10srm001





CHG0281377 ==> a1ahecqsap02 	Lakshmi
Hostname: a1ahecqsap02                                                *
*         CFN IP: 10.100.2.76                                                 *
*         IFN IP: 10.4.10.77 

Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         10.100.2.1      0.0.0.0         UG        0 0          0 net1
10.4.10.0       0.0.0.0         255.255.255.0   U         0 0          0 net0
10.100.2.0      0.0.0.0         255.255.255.0   U         0 0          0 net1
146.89.140.0    10.4.10.1       255.255.252.0   UG        0 0          0 net0
146.89.140.50   10.4.10.1       255.255.255.255 UGH       0 0          0 net0
146.89.168.0    10.4.10.1       255.255.252.0   UG        0 0          0 net0
146.89.173.192  10.4.10.1       255.255.255.192 UG        0 0          0 net0
146.89.174.192  10.4.10.1       255.255.255.192 UG        0 0          0 net0
158.87.44.0     10.4.10.1       255.255.254.0   UG        0 0          0 net0
158.87.46.0     10.4.10.1       255.255.254.0   UG        0 0          0 net0
169.55.16.128   10.4.10.1       255.255.255.240 UG        0 0          0 net0
169.55.28.32    10.4.10.1       255.255.255.224 UG        0 0          0 net0
169.55.28.64    10.4.10.1       255.255.255.240 UG        0 0          0 net0
169.55.192.96   10.4.10.1       255.255.255.224 UG        0 0          0 net0
169.60.136.0    10.4.10.1       255.255.252.0   UG        0 0          0 net0
169.62.212.64   10.4.10.1       255.255.255.192 UG        0 0          0 net0
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 net0
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 net1


Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
default         _gateway        0.0.0.0         UG    0      0        0 net1
10.4.10.0       0.0.0.0         255.255.255.0   U     0      0        0 net0
10.100.2.0      0.0.0.0         255.255.255.0   U     0      0        0 net1
146.89.140.0    10.4.10.1       255.255.252.0   UG    0      0        0 net0
dal09ammtsm001  10.4.10.1       255.255.255.255 UGH   0      0        0 net0
146.89.168.0    10.4.10.1       255.255.252.0   UG    0      0        0 net0
146.89.173.192  10.4.10.1       255.255.255.192 UG    0      0        0 net0
146.89.174.192  10.4.10.1       255.255.255.192 UG    0      0        0 net0
158.87.44.0     10.4.10.1       255.255.254.0   UG    0      0        0 net0
158.87.46.0     10.4.10.1       255.255.254.0   UG    0      0        0 net0
169.55.16.128   10.4.10.1       255.255.255.240 UG    0      0        0 net0
169.55.28.32    10.4.10.1       255.255.255.224 UG    0      0        0 net0
169.55.28.64    10.4.10.1       255.255.255.240 UG    0      0        0 net0
169.55.192.96   10.4.10.1       255.255.255.224 UG    0      0        0 net0
169.60.136.0    10.4.10.1       255.255.252.0   UG    0      0        0 net0
169.62.212.64   10.4.10.1       255.255.255.192 UG    0      0        0 net0
link-local      0.0.0.0         255.255.0.0     U     1002   0        0 net0
link-local      0.0.0.0         255.255.0.0     U     1003   0        0 net1


CHG0281378 ==> ahbsisbx01		Vigneshwari
Hostname: AHBSISBX01                                                  *
*         CFN IP: 10.100.2.12                                                 *
*         IFN IP: 10.4.10.12

========================= Routes =========================
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         10.100.2.1      0.0.0.0         UG        0 0          0 net1
10.4.10.0       0.0.0.0         255.255.255.192 U         0 0          0 net0
10.100.2.0      0.0.0.0         255.255.255.192 U         0 0          0 net1
10.100.2.0      0.0.0.0         255.255.255.0   U         0 0          0 net1
146.89.140.0    10.4.10.1       255.255.252.0   UG        0 0          0 net0
146.89.168.0    10.4.10.1       255.255.248.0   UG        0 0          0 net0
146.89.173.192  10.4.10.1       255.255.255.192 UG        0 0          0 net0
146.89.174.192  10.4.10.1       255.255.255.192 UG        0 0          0 net0
158.87.44.0     10.4.10.1       255.255.254.0   UG        0 0          0 net0
158.87.46.0     10.4.10.1       255.255.254.0   UG        0 0          0 net0
169.54.69.96    10.4.10.1       255.255.255.224 UG        0 0          0 net0
169.55.16.128   10.4.10.1       255.255.255.240 UG        0 0          0 net0
169.55.28.32    10.4.10.1       255.255.255.224 UG        0 0          0 net0
169.55.28.64    10.4.10.1       255.255.255.240 UG        0 0          0 net0
169.55.192.96   10.4.10.1       255.255.255.224 UG        0 0          0 net0
169.60.136.128  10.4.10.1       255.255.255.192 UG        0 0          0 net0
169.60.136.192  10.4.10.1       255.255.255.192 UG        0 0          0 net0
169.62.212.64   10.4.10.1       255.255.255.192 UG        0 0          0 net0
169.254.0.0     0.0.0.0         255.255.254.0   U         0 0          0 net1
169.254.0.0     0.0.0.0         255.255.254.0   U         0 0          0 net0

  
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
default         _gateway        0.0.0.0         UG    100    0        0 net0
default         _gateway        0.0.0.0         UG    101    0        0 net1
10.4.10.0       0.0.0.0         255.255.255.192 U     100    0        0 net0
10.100.2.0      0.0.0.0         255.255.255.192 U     101    0        0 net1
146.89.140.0    _gateway        255.255.252.0   UG    100    0        0 net0
146.89.168.0    _gateway        255.255.248.0   UG    100    0        0 net0
146.89.173.192  _gateway        255.255.255.192 UG    100    0        0 net0
146.89.174.192  _gateway        255.255.255.192 UG    100    0        0 net0
158.87.44.0     _gateway        255.255.254.0   UG    100    0        0 net0
158.87.46.0     _gateway        255.255.254.0   UG    100    0        0 net0
169.54.69.96    _gateway        255.255.255.224 UG    100    0        0 net0
169.55.16.128   _gateway        255.255.255.240 UG    100    0        0 net0
169.55.28.32    _gateway        255.255.255.224 UG    100    0        0 net0
169.55.28.64    _gateway        255.255.255.240 UG    100    0        0 net0
169.55.192.96   _gateway        255.255.255.224 UG    100    0        0 net0
169.60.136.128  _gateway        255.255.255.192 UG    100    0        0 net0
169.60.136.192  _gateway        255.255.255.192 UG    100    0        0 net0
169.62.212.64   _gateway        255.255.255.192 UG    100    0        0 net0
link-local      0.0.0.0         255.255.255.0   U     0      0        0 net1
link-local      0.0.0.0         255.255.254.0   U     0      0        0 net0

  



10.100.2.12     ahbsisbx01.aa.com ahbsisbx01
10.4.10.12      ahbsisbx01.aa.com ahbsisbx01



ahbsisbx01 <-> AHECQSAP01 (PYQ CI) this connection works fine    
ahbsisbx01 <-> A1AAHECQSAP02 (PYQ APP server) this connection don't work



10.100.2.0/24 via 0.0.0.0 dev net1



A replication error occurred at the vSphere Replication Server for replication 'wa2_wa2scpdb01'. Details: 'No connection to VR Server for virtual machine wa2_wa2scpdb01 on host ammdal13seiesx028.imzcloud.ibmammsap.local in cluster 3X-SAP-Cluster in DAL13: Disk size mismatch'.



[root@lberpdev ~]# uptime
 14:12:16 up 42 min, 10 users,  load average: 0.62, 0.67, 0.78
[root@lberpdev ~]# last
ibmrmali pts/1        146.89.140.60    Fri Jul  7 14:11   still logged in
ibmsgaur pts/7        146.89.140.60    Fri Jul  7 13:58   still logged in
ibmpk1   pts/5        146.89.140.60    Fri Jul  7 13:53   still logged in
ibmsnair pts/3        146.89.140.60    Fri Jul  7 13:48   still logged in
ibmsgaur pts/1        146.89.140.60    Fri Jul  7 13:43 - 14:02  (00:18)
ibmsgaur pts/0        146.89.140.60    Fri Jul  7 13:42   still logged in
reboot   system boot  5.4.17-2136.313. Fri Jul  7 13:30   still running


08:50:01 AM kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
12:00:01 PM  72833972  99878872  91416832     55.66    217624  78048724 147227816     68.61  61727092  22796088      1780
12:10:01 PM  72825756  99872456  91425048     55.66    217640  78050224 147289356     68.64  61721880  22798844      4068
12:20:01 PM  72829172  99878936  91421632     55.66    217656  78053016 147175144     68.59  61721624  22801356       264
12:30:01 PM  72826760  99879876  91424044     55.66    217672  78056096 147315996     68.65  61719720  22804076      2812
12:40:01 PM  72842184  99898784  91408620     55.65    217688  78059480 147216728     68.61  61716384  22807180      2784
12:50:01 PM  72826376  99885864  91424428     55.66    217704  78062164 147190288     68.60  61719188  22809656      2704
01:00:01 PM  72820788  99882528  91430016     55.66    217720  78064120 147268504     68.63  61724468  22816392      1824
01:10:02 PM  72787036  99850248  91463768     55.69    217736  78065516 147198132     68.60  61756528  22819380       600
01:20:01 PM  72748204  99812436  91502600     55.71    217752  78066376 147184588     68.59  61781356  22822144      1856
Average:     72864314  99883140  91386490     55.64    217120  78029301 147246809     68.62  61790148  22722107      1786

01:30:22 PM  LINUX RESTART      (20 CPU)
[root@lberpdev log]# date
Fri Jul  7 14:34:45 HKT 2023


01:40:02 PM kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
01:50:01 PM 157281212 160100656   6969596      4.24     54920   3574008   5110472      2.38   3693684   2116024      1016
02:00:01 PM 108031424 111495204  56219384     34.23     54936  50802660 145859260     67.97   6902688  47713280       716
02:10:01 PM 107715612 111195344  56535196     34.42     54952  50897776 145924408     68.01   7213668  47691204      2696


				CPU     %user     %nice   %system   %iowait    %steal     %idle
12:10:01 PM     all      1.12      0.00      0.80      0.02      0.00     98.06
12:20:01 PM     all      1.11      0.00      0.77      0.02      0.00     98.10
12:30:01 PM     all      1.13      0.00      0.78      0.02      0.00     98.07
12:40:01 PM     all      1.15      0.00      0.81      0.02      0.00     98.02
12:50:01 PM     all      1.09      0.02      0.80      0.02      0.00     98.07
01:00:01 PM     all      1.11      0.00      0.78      0.02      0.00     98.09
01:10:02 PM     all      1.13      0.00      0.79      0.02      0.00     98.06
01:20:01 PM     all      1.15      0.00      0.78      0.02      0.00     98.04
Average:        all      1.11      0.00      0.77      0.02      0.00     98.09

01:30:22 PM  LINUX RESTART      (20 CPU)

01:40:02 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle
01:50:01 PM     all      1.24      0.00      0.92      0.03      0.00     97.81
02:00:01 PM     all      1.96      0.00      2.25      0.11      0.00     95.68
02:10:01 PM     all      1.15      0.00      0.80      0.03      0.00     98.02
Average:        all      1.45      0.00      1.32      0.06      0.00     97.17



Course 1: https://learndigital.withgoogle.com/d...

Course 2: https://learndigital.withgoogle.com/d...

Course 3: https://learndigital.withgoogle.com/d...

Course 4: https://learndigital.withgoogle.com/d...

Course 5: https://learndigital.withgoogle.com/d...





CS13666054 Bombardier Recreational Products Inc -- BR3 P1 - Severe br3#br3psoldb42#Resource Pacemaker vIP CRITICAL: Resource rsc_ip is in status Stopped BR3PSOLDB42
CS13666052 Bombardier Recreational Products Inc -- BR3 P1 - Severe br3#br3psoldb42#Resource Pacemaker TSM CRITICAL: Resource rsc_TSM is in status Stopped BR3PSOLDB42
CS13666055
Bombardier
 Recreational Products Inc -- BR3
P1 - Severe
br3#br3psoldb43#Resource Pacemaker TSM CRITICAL: Resource rsc_TSM is in status Stopped

CS13666056
Bombardier
 Recreational Products Inc -- BR3
P1 - Severe
br3#br3psoldb43#Resource Pacemaker vIP CRITICAL: Resource rsc_ip is in status Stopped



CRS-rTCP-6J8R-QMBVc



CHG0288784  CHE01-SL || TTA ||NON PRODUCTION || SUSE upgrade on QS4 DB and App	13-07-2023 07:00:00 - 13-07-2023 19:00:00
SUSE upgrade on QS4 DB and App 
ttaprojqadb 	10.207.63.183	10.162.186.228	tta-che01-pod1-phana-h4-6000-003.imzcloud.ibmammsap.local
ttas4proqaapp	10.207.63.25

SLES 12SP2 to SLES15SP2 migration

presnap done https://samuel.sap.mgapp.ibm.com/TTA/buildInformation?id=64af51b71af439c2fa1cde2f&name=Overview

backup location
ttaprojqadb:/tmp/backup # pwd
/tmp/backup

ttaprojqadb:~ # systemctl --type=service |egrep -e "cups.service|vsftpd.service|postfix.service|dnsmasq.service"
  postfix.service                                                                           loaded active running Postfix Mail Transport Agent

[root@ttas4proqaapp ~]# systemctl --type=service |egrep -e "cups.service|vsftpd.service|postfix.service|dnsmasq.service"
  postfix.service                                                                           loaded active running Postfix Mail Transport Agent



IMM ip 10.162.186.190 - tta-che01-pod1-phana-h4-6000-003.imzcloud.ibmammsap.local

please check if you can able to access IMM 

root  t7ne26FDdk


SL case for NFS mapping the ISO and the memory replacement post the upgrade number:CS3472322 

fsf-che0101c-fz.service.softlayer.com:/IBM02SEV393684_318/data01/SLE-15-SP2-Full-x86_64-GM-Media.iso




CHG0288651   14-07-2023 11:00:00  20-07-2023 08:30:00
Reclaiming following unused disks, while reclaiming there will be no impact to customers,

IFNIP	Disk Name with Size	Disk Name	Size	CIDR	Hostname

10.12.255.157	Disk name /dev/sde is not utilized. The disk size is 1T 	Â /dev/sde 	1000	PN8	PN8US7LECCQ2
10.12.255.157	Disk name /dev/sdh is not utilized. The disk size is 1T 	Â /dev/sdh 	1000	PN8	PN8US7LECCQ2
10.12.255.157	Disk name /dev/sdi is not utilized. The disk size is 1T 	Â /dev/sdi 	1000	PN8	PN8US7LECCQ2

[root@pn8us7leccq2 ~]# blkid /dev/sde
/dev/sde: UUID="2A065c-sMVp-ty1J-j8nJ-oQbK-4Qaw-4avkI8" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sdh
/dev/sdh: UUID="ZFBmGe-3jXc-cIx4-RCcx-gY7s-cYqd-nEYDyh" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sdi
/dev/sdi: UUID="FpLQ5Y-HyAI-psXz-joT0-o3Ez-BFzy-VtQxwI" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sdj
/dev/sdj: UUID="dtNHrQ-5Cas-ALA9-7oOD-AUzJ-2gTR-26v4Nw" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sdr
/dev/sdr: UUID="KjxEP6-Cnni-alYM-MzMk-hwyf-AQXb-vVImnA" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sds
/dev/sds: UUID="GQJ3i5-ZCMb-KddG-tLKm-qvp2-KmTF-XBTf7d" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sdt
/dev/sdt: UUID="GE4KmT-U2V3-5MWE-XkIp-f6KI-psPn-cqMf0E" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sdu
/dev/sdu: UUID="c9YBPK-SZpT-aWL3-YQLz-V75T-kPdo-xNRThU" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# blkid /dev/sdv
/dev/sdv: UUID="CBWr0Z-AeiH-RyIx-vLYx-WLae-0948-Vm1hf2" TYPE="LVM2_member"
[root@pn8us7leccq2 ~]# pvs
  PV         VG             Fmt  Attr PSize    PFree
  /dev/sda2  rootvg         lvm2 a--    95.49g   20.49g
  /dev/sdb   rootvg         lvm2 a--    50.00g    2.00g
  /dev/sdc   CQ2migVG       lvm2 a--   200.00g 1020.00m
  /dev/sdd   cq2archvg      lvm2 a--    72.00g       0
			/dev/sde   cq2datavg      lvm2 a--  1024.00g 1024.00g
  /dev/sdf   cq2logvg       lvm2 a--    32.00g   25.00g
  /dev/sdg   cq2datavg      lvm2 a--  1024.00g  865.25g
			/dev/sdh   cq2datavg      lvm2 a--  1024.00g 1024.00g
			/dev/sdi   cq2datavg      lvm2 a--  1024.00g 1024.00g
			/dev/sdj   cq2datavg      lvm2 a--   640.00g  640.00g
  /dev/sdk   cq2archvg      lvm2 a--   128.00g   86.99g
  /dev/sdl   cq2interfacevg lvm2 a--     4.00g    2.00g
  /dev/sdm   cq2logvg       lvm2 a--   120.00g   70.00g
  /dev/sdn   backupvg       lvm2 a--   512.00g   12.00g
  /dev/sdo   cq2datavg      lvm2 a--   255.00g   76.04g
  /dev/sdp   cq2datavg      lvm2 a--   255.00g   96.25g
  /dev/sdq   cq2datavg      lvm2 a--   255.00g   96.25g
			/dev/sdr   cq2datavg      lvm2 a--   255.00g  255.00g
			/dev/sds   cq2datavg      lvm2 a--   255.00g  255.00g
			/dev/sdt   cq2datavg      lvm2 a--   255.00g  255.00g
			/dev/sdu   cq2datavg      lvm2 a--   255.00g  255.00g
			/dev/sdv   cq2datavg      lvm2 a--   255.00g  255.00g
  /dev/sdw   cq2appvg       lvm2 a--   160.00g   60.00g


[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sde
  --- Physical volume ---
  PV Name               /dev/sde
  VG Name               cq2datavg
  PV Size               1.00 TiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              262143
  Free PE               262143
  Allocated PE          0
  PV UUID               2A065c-sMVp-ty1J-j8nJ-oQbK-4Qaw-4avkI8

  --- Physical Segments ---
  Physical extent 0 to 262142:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sdh
  --- Physical volume ---
  PV Name               /dev/sdh
  VG Name               cq2datavg
  PV Size               1.00 TiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              262143
  Free PE               262143
  Allocated PE          0
  PV UUID               ZFBmGe-3jXc-cIx4-RCcx-gY7s-cYqd-nEYDyh

  --- Physical Segments ---
  Physical extent 0 to 262142:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sdi
  --- Physical volume ---
  PV Name               /dev/sdi
  VG Name               cq2datavg
  PV Size               1.00 TiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              262143
  Free PE               262143
  Allocated PE          0
  PV UUID               FpLQ5Y-HyAI-psXz-joT0-o3Ez-BFzy-VtQxwI

  --- Physical Segments ---
  Physical extent 0 to 262142:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sdj
  --- Physical volume ---
  PV Name               /dev/sdj
  VG Name               cq2datavg
  PV Size               640.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              163839
  Free PE               163839
  Allocated PE          0
  PV UUID               dtNHrQ-5Cas-ALA9-7oOD-AUzJ-2gTR-26v4Nw

  --- Physical Segments ---
  Physical extent 0 to 163838:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sdr
  --- Physical volume ---
  PV Name               /dev/sdr
  VG Name               cq2datavg
  PV Size               255.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              65279
  Free PE               65279
  Allocated PE          0
  PV UUID               KjxEP6-Cnni-alYM-MzMk-hwyf-AQXb-vVImnA

  --- Physical Segments ---
  Physical extent 0 to 65278:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sds
  --- Physical volume ---
  PV Name               /dev/sds
  VG Name               cq2datavg
  PV Size               255.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              65279
  Free PE               65279
  Allocated PE          0
  PV UUID               GQJ3i5-ZCMb-KddG-tLKm-qvp2-KmTF-XBTf7d

  --- Physical Segments ---
  Physical extent 0 to 65278:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sdt
  --- Physical volume ---
  PV Name               /dev/sdt
  VG Name               cq2datavg
  PV Size               255.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              65279
  Free PE               65279
  Allocated PE          0
  PV UUID               GE4KmT-U2V3-5MWE-XkIp-f6KI-psPn-cqMf0E

  --- Physical Segments ---
  Physical extent 0 to 65278:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sdu
  --- Physical volume ---
  PV Name               /dev/sdu
  VG Name               cq2datavg
  PV Size               255.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              65279
  Free PE               65279
  Allocated PE          0
  PV UUID               c9YBPK-SZpT-aWL3-YQLz-V75T-kPdo-xNRThU

  --- Physical Segments ---
  Physical extent 0 to 65278:
    FREE

[root@pn8us7leccq2 ~]# pvdisplay -m /dev/sdv
  --- Physical volume ---
  PV Name               /dev/sdv
  VG Name               cq2datavg
  PV Size               255.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              65279
  Free PE               65279
  Allocated PE          0
  PV UUID               CBWr0Z-AeiH-RyIx-vLYx-WLae-0948-Vm1hf2

  --- Physical Segments ---
  Physical extent 0 to 65278:
    FREE


[root@pn8us7leccq2 ~]# lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdb
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[0:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sdd
		[0:0:4:0]    disk    VMware   Virtual disk     1.0   /dev/sde
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf
[0:0:6:0]    disk    VMware   Virtual disk     1.0   /dev/sdg
		[0:0:8:0]    disk    VMware   Virtual disk     1.0   /dev/sdh
		[0:0:9:0]    disk    VMware   Virtual disk     1.0   /dev/sdi
		[0:0:10:0]   disk    VMware   Virtual disk     1.0   /dev/sdj
[0:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdk
[0:0:12:0]   disk    VMware   Virtual disk     1.0   /dev/sdl
[0:0:13:0]   disk    VMware   Virtual disk     1.0   /dev/sdm
[0:0:14:0]   disk    VMware   Virtual disk     1.0   /dev/sdn
[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdo
[1:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdp
[1:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdq
		[2:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdr
		[2:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sds
		[2:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdt
		[3:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdu
		[3:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdv
[3:0:15:0]   disk    VMware   Virtual disk     1.0   /dev/sdw




10.12.255.49	Disk name /dev/sde is not utilized. The disk size is 64G 	Â /dev/sde 	64	PN8	PN8US7LECCP6
10.12.255.49	Disk name /dev/sdg is not utilized. The disk size is 128G 	Â /dev/sdg 	128	PN8	PN8US7LECCP6
10.12.255.49	Disk name /dev/sdk is not utilized. The disk size is 243G 	Â /dev/sdk 	243	PN8	PN8US7LECCP6

10.12.255.79	Disk name /dev/sdc is not utilized. The disk size is 60G 	Â /dev/sdc 	60	PN8	PN8US7LECCD5
10.12.255.79	Disk name /dev/sdl is not utilized. The disk size is 250G 	Â /dev/sdl 	250	PN8	PN8US7LECCD5

10.12.255.83	Disk name /dev/sdc is not utilized. The disk size is 256G 	Â /dev/sdc 	256	PN8	PN8US7LGRD0

10.12.255.152	Disk name /dev/sdk is not utilized. The disk size is 146G 	Â /dev/sdk 	146	PN8	PN8US7LBCQ0

10.12.255.157	Disk name /dev/sdj is not utilized. The disk size is 640G 	Â /dev/sdj 	640	PN8	PN8US7LECCQ2
10.12.255.157	Disk name /dev/sdr is not utilized. The disk size is 255G 	Â /dev/sdr 	255	PN8	PN8US7LECCQ2
10.12.255.157	Disk name /dev/sds is not utilized. The disk size is 255G 	Â /dev/sds 	255	PN8	PN8US7LECCQ2
10.12.255.157	Disk name /dev/sdt is not utilized. The disk size is 255G 	Â /dev/sdt 	255	PN8	PN8US7LECCQ2
10.12.255.157	Disk name /dev/sdu is not utilized. The disk size is 255G 	Â /dev/sdu 	255	PN8	PN8US7LECCQ2
10.12.255.157	Disk name /dev/sdv is not utilized. The disk size is 255G 	Â /dev/sdv 	255	PN8	PN8US7LECCQ2


CHG0288036
FRCHEPRXY01 - 146.89.142.102
FRDAL09PRXY02 - 146.89.140.26
FRDALPRXY02 - 146.89.142.247
frdwdcprxy02 - 146.89.142.26
FRFRAPRXY01 - 146.89.140.240
FRLON02PRXY02 - 146.89.140.121
FRLONPRXY02 - 146.89.143.173





CHG0288652Â  20-07-2023 08:30:00 - 22-07-2023 08:30:00
Reclaiming following unused disks, while reclaiming there will be no impact to customers,

IFNIP	Disk Name with Size	Disk Name	Size	CIDR	Hostname	Note
10.12.255.43	Disk name /dev/sde is not utilized. The disk size is 200G 	Â /dev/sde 	200	PN8	PN8US7LBCP0	7/19/23, after midnight EDT
10.12.255.43	Disk name /dev/sdg is not utilized. The disk size is 100G 	Â /dev/sdg 	100	PN8	PN8US7LBCP0	7/19/23, after midnight EDT
10.12.255.45	Disk name /dev/sdp is not utilized. The disk size is 285G 	Â /dev/sdp 	285	PN8	PN8US7LDBCP2	7/19/23, after midnight EDT
10.12.255.45	Disk name /dev/sdq is not utilized. The disk size is 4G 	Â /dev/sdq 	4	PN8	PN8US7LDBCP2	7/19/23, after midnight EDT


CHG0288036 
SET 2
FRCHEPRXY02 - 146.89.142.103
FRDAL09PRXY01 - 146.89.140.25
FRDALPRXY01 - 146.89.142.244
frdwdcprxy01 - 146.89.142.25
	FRFRAPRXY02 - 146.89.140.241
FRLON02PRXY01 - 146.89.140.120
FRLONPRXY01 - 146.89.143.172


cleanup any errors and wait for the sync to complete and SFAIL to change

remote host is the one that is in sync

--name is for the sfail node NODE a or SITEA

Run below from the server that is standby(out of sync)
su - s4padm -c "hdbnsutil -sr_register --remoteHost=br3psoldb41 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=SITEB"  

for HANA with --online keyword 
su - sm3adm -c "hdbnsutil -sr_register --remoteHost=vhsm3db1 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --online --name=NODEB"


[root@vhsm3db2 ~]# cat /etc/sysconfig/sbd | grep -e ^SBD_DEVICE=
SBD_DEVICE="/dev/disk/by-id/scsi-360014052a34023a8d9f4016898752175;/dev/disk/by-id/scsi-3600140526ab82b9ed46424982d68aafa;/dev/disk/by-id/scsi-360014058875aad2689749a4add656d06;"


[root@vhsm3db2 ~]# ls -l /dev/disk/by-id/scsi-
scsi-14d534654202020201a01c68958056045911b3dc043458d2a        scsi-14d534654202020208568f1e3f0020e48bd94d326d0d375ff        scsi-360022480316b1742695ba0f151fa8dd9
scsi-14d534654202020201a01c68958056045911b3dc043458d2a-part1  scsi-14d53465420202020cf1ff4ddb9731f4b8e302b44c2dc30af        scsi-36002248051ab22185f796e46d8b791d7
scsi-14d534654202020201a01c68958056045911b3dc043458d2a-part2  scsi-14d53465420202020dec54d8b5508fb468faf82dcc110504c        scsi-36002248051ab22185f796e46d8b791d7-part1
scsi-14d534654202020201a01c68958056045911b3dc043458d2a-part3  scsi-14d53465420202020eff98e33a796a1428e8f42488e1fe116        scsi-36002248071a8f4eee6966edce3caa23c
scsi-14d534654202020201a01c68958056045911b3dc043458d2a-part4  scsi-14d53465420202020f790d7c91520e840b69a82e0fdec06c4        scsi-360022480766cbc8774dba68f958fd9a5
scsi-14d534654202020201f499c9e0c9883479e33f60f21770dd1        scsi-3600224801a01c68958053dc043458d2a                        scsi-3600224808568f1e3f002d326d0d375ff
scsi-14d53465420202020316b1742695b3e41ac93a0f151fa8dd9        scsi-3600224801a01c68958053dc043458d2a-part1                  scsi-360022480cf1ff4ddb9732b44c2dc30af
scsi-14d5346542020202051ab22185f796d4983a66e46d8b791d7        scsi-3600224801a01c68958053dc043458d2a-part2                  scsi-360022480dec54d8b550882dcc110504c
scsi-14d5346542020202051ab22185f796d4983a66e46d8b791d7-part1  scsi-3600224801a01c68958053dc043458d2a-part3                  scsi-360022480eff98e33a79642488e1fe116
scsi-14d5346542020202071a8f4eee696f647a47d6edce3caa23c        scsi-3600224801a01c68958053dc043458d2a-part4                  scsi-360022480f790d7c9152082e0fdec06c4
scsi-14d53465420202020766cbc8774db9b4ab9e6a68f958fd9a5        scsi-3600224801f499c9e0c98f60f21770dd1




#qIG0lo[p@#Dre^



NFS Servers are listed below:

Add 200 GBs more space to accommodate additional backups to both Prod and Nonprod /interfaces_ms


Non-Prod: Cluster
wa2nfsdev1 - 100.64.22.114
wa2nfsdev1-ha - 100.64.22.113

Nonprod
wa2dev-nfs:/export/interfaces_ms  250G  144G  107G  58% /interfaces_ms


Prod: Cluster
wa2nfsprd1 - 100.64.20.44
wa2nfsprd1-ha - 100.64.20.42
DR:
wa2nfsprd1-dr - 100.64.127.189

Prod
10.150.4.91:/export/interfaces_ms   600G  463G  138G  78% /interfaces_ms




wa2mssprodi2 - 10.191.1.251
wa2mssqasd1 - 10.191.1.118
	wa2mssqasi1 - 10.191.1.103
	wa2mssqasi2 - 10.191.1.55
	wa2mssqasw2 - 10.191.1.109
	wa2mssqasw3 - 10.191.1.107
	WA2PBSQAS01 - 10.191.1.26
	
	
	
	CHG0288960 Parle Biscuits Pvt. Ltd -- PPL Linux 7/26/2023 10:00
CHG0288966 Parle Biscuits Pvt. Ltd -- PPL Linux 7/27/2023 10:00




    
General Hi Team, Please provide OS SME approval for the below changes. Thanks.
CHG0289168   Halifax Regional Municipality -- HRM    Linux    7/27/2023    10:00
CHG0289274   Halifax Regional Municipality -- HRM    Linux    7/27/2023    10:00



2990
4910




Patch Group (D1.0) - mm9umbappdb	SUSE	10.191.200.73	Development	 UMB (App/DB)
[root@mm9umbappdb ~]# lsblk -o +serial
NAME                                  MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS             SERIAL
nvme0n1                               259:0    0   64G  0 disk                         vol039c15cbf2afcd9fa
â”œâ”€nvme0n1p1                           259:3    0    2M  0 part
â”œâ”€nvme0n1p2                           259:4    0   20M  0 part /boot/efi
â””â”€nvme0n1p3                           259:5    0   64G  0 part /
nvme1n1                               259:1    0   64G  0 disk                         vol0270ec507b3934d62
â””â”€nvme1n1p2                           259:2    0   62G  0 part
  â”œâ”€rootvg-homelv                     254:1    0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv                      254:2    0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv                      254:4    0 14.7G  0 lvm  /tmp
  â”œâ”€rootvg-varlv                      254:8    0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv                     254:11   0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp                     254:13   0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit                254:17   0    4G  0 lvm  /var/log/audit
  â”œâ”€rootvg-varoptansible              254:24   0    5G  0 lvm  /var/opt/ansible
  â””â”€rootvg-vcrashlv                   254:27   0  1.3G  0 lvm  /var/crash



Patch Group (D1.0) - mm9umdappdb	SUSE	10.191.200.77	Development	 UMD (App/DB)
[root@mm9umdappdb ~]# lsblk -o +serial
NAME                                  MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS             SERIAL
nvme0n1                               259:0    0   64G  0 disk                         vol03009e8697ed4ed23
â”œâ”€nvme0n1p1                           259:8    0    2M  0 part
â”œâ”€nvme0n1p2                           259:9    0   20M  0 part /boot/efi
â””â”€nvme0n1p3                           259:10   0   64G  0 part /
nvme1n1                               259:1    0  512G  0 disk                         vol0febbaace3a472e3b
nvme2n1                               259:2    0   64G  0 disk                         vol0f0459d8b456f71fa
â””â”€nvme2n1p2                           259:4    0   62G  0 part
  â”œâ”€rootvg-homelv                     254:10   0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv                      254:11   0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv                      254:13   0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv                      254:15   0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv                     254:20   0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp                     254:21   0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit                254:24   0    4G  0 lvm  /var/log/audit
  â”œâ”€rootvg-varoptansible              254:29   0    5G  0 lvm  /var/opt/ansible
  â””â”€rootvg-vcrashlv                   254:31   0  1.3G  0 lvm  /var/crash




Patch Group (D1.0) - mm9uedapp	SUSE	10.191.200.85	Development	 UED (App)
NAME                               MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS           SERIAL
nvme0n1                            259:0    0   64G  0 disk                       vol0a98c1e11ea8da18f
â”œâ”€nvme0n1p1                        259:1    0    2M  0 part
â”œâ”€nvme0n1p2                        259:2    0   20M  0 part /boot/efi
â””â”€nvme0n1p3                        259:3    0   64G  0 part /
nvme2n1                            259:5    0   64G  0 disk                       vol07be8b93649bc24aa
â””â”€nvme2n1p2                        259:6    0   62G  0 part
  â”œâ”€rootvg-homelv                  254:1    0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv                   254:2    0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv                   254:3    0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv                   254:4    0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv                  254:5    0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp                  254:8    0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit             254:10   0    4G  0 lvm  /var/log/audit
  â”œâ”€rootvg-varoptansible           254:11   0    5G  0 lvm  /var/opt/ansible
  â””â”€rootvg-vcrashlv                254:12   0  1.3G  0 lvm  /var/crash



Patch Group (D1.0) - mm9uxdappdb	SUSE	10.191.200.115	Development	 UXD (App/DB)
nvme0n1                               259:0    0   64G  0 disk                         vol04575463ed5036b94
â”œâ”€nvme0n1p1                           259:1    0    2M  0 part
â”œâ”€nvme0n1p2                           259:2    0   20M  0 part /boot/efi
â””â”€nvme0n1p3                           259:3    0   64G  0 part /

nvme1n1                               259:5    0   64G  0 disk                         vol0260b333b420d728d
â””â”€nvme1n1p2                           259:7    0   62G  0 part
  â”œâ”€rootvg-homelv                     254:15   0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv                      254:18   0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv                      254:20   0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv                      254:26   0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv                     254:28   0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp                     254:30   0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit                254:32   0    4G  0 lvm  /var/log/audit
  â”œâ”€rootvg-varoptansible              254:33   0    5G  0 lvm  /var/opt/ansible
  â””â”€rootvg-vcrashlv                   254:34   0  1.3G  0 lvm  /var/crash





Patch Group (D1.0) - mm9uedhndb	SUSE	10.191.200.110	Development	 UED (DB) - HANA
nvme1n1                  259:0    0   64G  0 disk                  vol018615885b459014f
â””â”€nvme1n1p2              259:4    0   62G  0 part
  â”œâ”€rootvg-homelv        254:5    0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv         254:6    0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv         254:7    0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv         254:8    0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv        254:9    0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp        254:10   0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit   254:11   0    4G  0 lvm  /var/log/audit
  â””â”€rootvg-varoptansible 254:12   0    5G  0 lvm  /var/opt/ansible


nvme0n1                  259:6    0   96G  0 disk                  vol08d5b1a9f3f5a4267
â”œâ”€nvme0n1p1              259:8    0    2M  0 part
â”œâ”€nvme0n1p2              259:9    0   20M  0 part /boot/efi
â””â”€nvme0n1p3              259:10   0   96G  0 part /




Patch Group (D1.0) - mm9uwdapp	SUSE	10.191.200.120	Development	 UWD (App)
nvme0n1                  259:1    0   64G  0 disk                  vol08c98984c40d93051
â”œâ”€nvme0n1p1              259:5    0    2M  0 part
â”œâ”€nvme0n1p2              259:6    0   20M  0 part /boot/efi
â””â”€nvme0n1p3              259:7    0   64G  0 part /
nvme2n1                  259:2    0   64G  0 disk                  vol0ace24a1733982832
â””â”€nvme2n1p2              259:4    0   62G  0 part
  â”œâ”€rootvg-homelv        254:4    0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv         254:6    0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv         254:8    0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv         254:10   0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv        254:12   0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp        254:15   0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit   254:16   0    4G  0 lvm  /var/log/audit
  â”œâ”€rootvg-varoptansible 254:19   0    5G  0 lvm  /var/opt/ansible
  â””â”€rootvg-vcrashlv      254:20   0  1.3G  0 lvm  /var/crash



Patch Group (D1.0) - mm9ufdapp	SUSE	10.191.200.124	Development	 UFD (App)
nvme0n1                            259:0    0   64G  0 disk                       vol02814cf30a221c73e
â”œâ”€nvme0n1p1                        259:1    0    2M  0 part
â”œâ”€nvme0n1p2                        259:2    0   20M  0 part /boot/efi
â””â”€nvme0n1p3                        259:3    0   64G  0 part /
nvme1n1                            259:4    0   64G  0 disk                       vol02913da29d36941c2
â””â”€nvme1n1p2                        259:5    0   62G  0 part
  â”œâ”€rootvg-homelv                  254:3    0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv                   254:4    0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv                   254:7    0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv                   254:8    0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv                  254:9    0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp                  254:11   0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit             254:12   0    4G  0 lvm  /var/log/audit
  â”œâ”€rootvg-varoptansible           254:14   0    5G  0 lvm  /var/opt/ansible
  â””â”€rootvg-vcrashlv                254:16   0  1.3G  0 lvm  /var/crash




CHG0289805	done
CHG0289865 	done
CHG0288355	done
CHG0291092	disposition_type is incorrect showing scheduled in each row. Get the sheet checked
CHG0291123  disposition_type is incorrect showing scheduled in each row. Get the sheet checked



Patch Group (Q4) - wa2mssqasw3    Redhat    10.191.1.107    QA    MSSQA - SAP  ()
Patch Group (Q4) - wa2mssqasd1    Redhat    10.191.1.118    QA    MSSQA - SAP  ()
Patch Group (Q4) - wa2mssqasi1    Redhat    10.191.1.103    QA    N/A - SAP  ()
Patch Group (Q4) - wa2mssqasw2    Redhat    10.191.1.109    QA    MSSQA - SAP  ()
Patch Group (Q4) - wa2mssqasi2    Redhat    10.191.1.55    QA    MSSQA - SAP  ()




CHG0289805    Nippon Life India Asset Management Limited -- NL1   Linux    8/4/2023   20:00
CHG0289865    Nippon Life India Asset Management Limited -- NL1   Linux    8/5/2023   20:00





CI: HAVHAV1018

what was done so far :

1. We found that on HAVHAV1018 exists only path /arc/pbs and it is totally empty.
[root@havhav1018 ~]# df -hT /arc/pbs
Filesystem              Type  Size  Used Avail Use% Mounted on
192.168.191.13:/arc/pbs nfs   9.7G  4.8G  4.4G  53% /arc/pbs
[root@havhav1018 ~]# cd /arc/pbs
[root@havhav1018 pbs]# ls -ltr
total 4
drwxr-xr-x 3 pc4adm sapsys 4096 Jul 28 18:04 PC4

above FS Is not empty i see PC4 folder inside it 
[root@havhav1018 pbs]# du -sh *
1.1G    PC4


 This was the reason why customer archiving SAP jobs were failing because it requires /arc/pbs/PC4/100
2. we created subdirectories PC4/100 manually and gave required permissions
3. SAP job is running fine, path /arc/pbs/PC4/100 now contains some archive files
4. Customer informed us that Job is ok, but old archives are missing, it means that there should not be folders as we created but some another mount point containing old files and it should be 250GB of size

Note:
- /arc/pbs is mounted from havhav1009
- once missing FS is found, we need to gather files created in above step 3.





required path is /arc/pbs/PC4/100


and it seems that PC4/100 should be overmounted 


not PC4/100 are only folders created by me in /arc/PBS 


we need to find original FS , its size should be 250GB


/arc/pbs/PC4/100/

Server Type: Production                                                  *
*       Hostname: havhav1018                                                  *
*         CFN IP: 192.168.191.14                                              *
*         IFN IP: 10.199.191.7                                                *
*        SAP SID: PC4     



 Server Type: Production                                                  *
*       Hostname: havhav1009                                                  *
*         CFN IP: 192.168.191.13                                              *
*         IFN IP: 10.199.191.11                                               *
*        SAP SID: PC4   


PBS_CFIF_20230306_124137_0
PBS_CFIF_20230404_201130_0


/PBS/CFIFLDR3_ADK

/PBS/CSD_LOAD

/arc/pbs/PC4/100


CHG0292993 created for resource augmentation
Pause the replication
cluster in maintenace mode
Extend the disk in VC
rescan the disk  with echo 1 > /sys/block/sdX/device/rescan
use pvresize to increase the PV pvresize /dev/sdf
fdisk -l /dev/sdf
pvresize /dev/sdX  it updates the VG also
pvscan |grep -i prdappvg



CHG0291521    Halifax Regional Municipality -- HRM   Linux    8/5/2023    20:00
CHG0291525    Halifax Regional Municipality -- HRM   Linux    8/5/2023    20:00







Pankajesh's change CHG0287226 on Friday at 6:30 AM to 1:30 PM
	Patch Group (Q1.0) - mm9ufqapp	SUSE	10.191.200.75	QA	 UFQ (App)		root vol038a004141b26eaed    boot vol0c10233f9ccca7e63
	Patch Group (Q1.0) - mm9uwqapp	SUSE	10.191.200.122	QA	 UWQ (App)		root vol007e480ae0bb087d3   boot vol0a80ae64b585f1f76
Patch Group (Q1.0) - mm9ueqapp	SUSE	10.191.200.97	QA	 UEQ (App)		root vol089b62941c13d9373   boot vol02654833c2550a0c5
Patch Group (Q1.0) - mm9ueqhndb	SUSE	10.191.200.90	QA	 UEQ (DB) - HANA		root vol0051339f2c20ab392   boot vol0b13d1d7345901446
Patch Group (Q1.0) - mm9uxqappdb	SUSE	10.191.200.92	QA	 UXQ (App/DB)		root  vol02dbc536e769f7ab0  boot vol08bd4f738f1f3106b
Patch Group (Q1.0) - mm9ufqhndb	SUSE	10.191.200.93	QA	 UFQ (DB) - HANA		root vol0277b7bfdf16437be   boot vol0ef2ce81bba78a277

b.	OFFLINE, auditd, No OS Patching 


Commenting  multiple lines of fstab

to comment lines 2 through 4 of bla.conf:
sed -i '2,4 s/^/#/' /etc/fstab

to uncomment
sed -i '/'#'/s/^#//g' /etc/fstab	working to uncomment


#python -V
#ls -l /usr/bin/python* --> to check if we have other(new) versions


Health Check\Vulnerability remediation from Samuel - Known issues:

 

1. Python version error - Make sure the python version is 2.7 or SLES12, and 3.6 for SLES15

 

2. Cryptography error - Install the python cryptography package "zypper in python3-cryptography"

 

3. THP (Transparent huge pages) error - Make sure to disable THP (steps can be found in KB KB0016944 - page no 38 in the attachment)

 

4. "btrfs command not found" error - Make sure the env variable for btrfs in grun.cfg is set"
    # echo $btrfs_relative_path (if the path is empty, set using below command)
    # export btrfs_relative_path=/usr/sbin/btrfs
    
5. Auditd deamon error - Make sure the auditd service is started, if not, enable the server and reboot the server 
    # systemctl enable auditd
	
	-------------------------------------------------------------------------------------------------------------
	
	b. On servers running RHEL 7 or SUSE 12 upwards, set the default gnome target to multi-user.

# systemctl get-default
graphical.target

# systemctl set-default multi-user.target

# systemctl isolate multi-user.target

# systemctl get-default 
multi-user.target


Ansible remediation is changing the DB log permission, so DB won't start.
*/10 * * * * find /var/log/* -type f -exec chmod g-wx,o-rwx '{}' + -o -type d -not -path /var/log/hist -not -path /var/log/sssd -exec chmod g-wx,o-rwx '{}' +

comment the above form hana servers and change the permissions if changed
We have to set the permission after HANA DB  server remediation in case any issue at DB start.

[6/29 1:57 PM] Sreejesh U

# chmod 755 /var/log/HDBHA/
# chmod 755 /var/log/HDBHA/state_monitor/
# chmod 755 /var/log/HDBHA/state_monitor/state_monitor.log 


check cronjob that changes the var/log permissions for hana



----------------------------------------------------------------------------------------

[root@mm9ufqapp ~]# cd /etc/profile.d/
[root@mm9ufqapp profile.d]# ls -ltr
total 256
-rw-r--r-- 1 root root   626 Feb  9  2016 desktop-data.sh
-rw-r--r-- 1 root root   951 Feb  9  2016 desktop-data.csh
-rw-r--r-- 1 root root  1425 Apr  9  2018 xdg-environment.sh
-rw-r--r-- 1 root root   983 Apr  9  2018 xdg-environment.csh
-rw-r--r-- 1 root root  3487 Apr  9  2018 profile.sh
-rw-r--r-- 1 root root  3963 Apr  9  2018 profile.csh
-rw-r--r-- 1 root root    83 Apr  9  2018 ls.zsh
-rw-r--r-- 1 root root   721 Apr  9  2018 ls.tcsh
-rw-r--r-- 1 root root  1560 Apr  9  2018 ls.bash
-rw-r--r-- 1 root root  2444 Apr  9  2018 lang.sh
-rw-r--r-- 1 root root  3053 Apr  9  2018 lang.csh
-rw-r--r-- 1 root root   603 Apr  9  2018 csh.ssh
-rw-r--r-- 1 root root 17907 Apr  9  2018 complete.bash
-rw-r--r-- 1 root root   303 Apr  9  2018 alias.tcsh
-rw-r--r-- 1 root root  1264 Apr  9  2018 alias.ash
-rw-r--r-- 1 root root   757 May 25  2018 gawk.sh
-rw-r--r-- 1 root root  1107 May 25  2018 gawk.csh
-rw-r--r-- 1 root root    91 May  5  2020 python.sh
-rw-r--r-- 1 root root    91 May  5  2020 python.csh
-rw-r--r-- 1 root root 39814 Apr 12  2021 complete.tcsh
-rw-r--r-- 1 root root 30230 Apr 12  2021 bindkey.tcsh
-rw-r--r-- 1 root root   256 May  7  2022 zzz-groff.sh
-rw-r--r-- 1 root root   381 May  7  2022 zzz-groff.csh
-rw-r--r-- 1 root root   690 Oct  4  2022 sh.ssh
-rw-r--r-- 1 root root  1679 Oct  4  2022 alljava.sh
-rw-r--r-- 1 root root  1220 Oct  4  2022 alljava.csh
-rw-r--r-- 1 root root  1440 Oct  4  2022 alias.bash
-rw-r--r-- 1 root root   366 Nov  8  2022 krb5.sh
-rw-r--r-- 1 root root   378 Nov  8  2022 krb5.csh
-rw-r--r-- 1 root root   662 Dec 14  2022 bash_completion.sh
-rw-r--r-- 1 root root    42 Mar 13 15:01 path.sh
-rw-r--r-- 1 root root   284 Mar 13 16:16 tmout.sh
-rwxr-xr-x 1 root root   505 Apr  3 17:42 IBMSAPmsg.sh
-rwxr-xr-x 1 root root  4376 Apr 19 13:04 IBM_OS_Check.sh
-rw-r--r-- 1 root root   186 Apr 24 10:11 git.csh
-rw-r--r-- 1 root root 11799 Apr 25 06:51 zzz-glib2.sh
-rw-r--r-- 1 root root 14013 Apr 25 06:51 zzz-glib2.csh
-rw-r--r-- 1 root root   103 Aug  3 23:22 autologout.csh
[root@mm9ufqapp profile.d]# cat autologout.csh
# BEGIN ANSIBLE MANAGED
# Set session timeout - CIS ID 5.4.5
set -r autologout=15                                ----->edit this lie and remove -r and save
# END ANSIBLE MANAGED[root@mm9ufqapp profile.d]# vi autologout.csh
[root@mm9ufqapp profile.d]# su - ufqadm
mm9ufqapp:ufqadm 54>



vi /etc/profile.d/autologout.csh
remove -r 





	ql2qp1cmg    10.22.89.28
ql2qp1pic    10.22.89.17
ql2eps2dc2a    10.22.90.78
ql2qp1podwas    10.22.89.40
ql2qp1pxy    10.22.90.7
ql2qp1tam    10.22.89.18
ql2qpcognos    10.22.89.53
ql2qpcognosdb    10.22.89.13



ql2qt1pic    10.22.149.21
	ql2qt1cmg    10.22.149.24
ql2qt1podwas    10.22.149.11
ql2qt1pxy    10.22.90.14
ql2qt1tam    10.22.149.6
ql2qd1tam    10.22.90.15
ql2qd1pic    10.22.149.13



TSLS4PRODDB		10.207.61.123
TSLS4PRODDBH	10.207.61.113
TSLS4PRODDBDR


2358

CHG0293275    Authorize    Low    /PROD/FRA02-SL/WP1 - update network settings    19/08/2023 17:00    19/08/2023 19:00
CHG0293248    Authorize    Low    /NON-PROD/FRA02-SL/WR1 - update network settings    16/08/2023 12:00    16/08/2023 13:00
CHG0293237    Authorize    Low    /NON-PROD/FRA02-SL/WQ1 - update network settings    11/08/2023 12:00    11/08/2023 13:00
CHG0293232    Authorize    Low    /NON-PROD/FRA02-SL/WD1 - update network settings    09/08/2023 15:00    09/08/2023 16:00

dalhana-1024-12.xsportal.local
Management
10.155.223.105
User
root
Password
JVWNv352L9


new pw  OgYggrdDWUo6ek1




root  W4F611%LEuPZ3T@


CHG0290752  CST/CDT - 08/09/2023 - 20:00 - NIX - BR3 - PATCH - HC - VULN - 1Q23,2Q23,3Q23- Troop C(SAPB1) 10-08-2023 06:30:00	10-08-2023 17:30:00
This 08/09/2023 - 20:00 - NIX  remediation is for the following CIs:
Patch Group (1) - br3dgtsdb55	SUSE	10.138.10.64	Development	DGT - SAP  (DB) - HANA
Patch Group (1) - br3dscmdb56	SUSE	10.138.10.66	Development	DCM - SAP  (DB) - HANA
Patch Group (1) - br3dhana50	SUSE	10.138.10.27	Development	D4H - SAP  (DB) - HANA
Patch Group (2) - br3ssapdb10	SUSE	10.138.10.73	Development	SXH - SAP  (DB) - HANA
Patch Group (2) - br3sgtsdb15	SUSE	10.138.10.97	Development	SGT - SAP  (DB) - HANA

	Patch Group (1) - br3dsapa52	SUSE	10.138.10.28	Development	WDP - SAP  (App) - NA
	Patch Group (1) - br3nfs-dev	SUSE	10.138.10.117	Development	NA - SAP  () - NA
	Patch Group (1) - br3dsapa50	SUSE	10.138.10.30	Development	D4H - SAP  (App) - NA
	Patch Group (1) - br3dscmas56	SUSE	10.138.10.130	Development	DCM - SAP  (App) - NA
	Patch Group (1) - br3scs-dev	SUSE	10.138.10.93	Development	DCS - SAP  (DB) - MAXDB
	Patch Group (1) - br3dgtsas55	SUSE	10.138.10.60	Development	DGT - SAP  (App) - NA
Patch Group (2) - br3ssapas10	SUSE	10.138.10.68	Development	SX4 - SAP  (App) - NA
Patch Group (2) - br3sgtsas15	SUSE	10.138.10.61	Development	SGT - SAP  (App) - NA



patch with file  zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt)
vmlogging  checked
kdump
ssh vulnerability

presnap link
https://samuel.sap.mgapp.ibm.com/BR3/buildInformation?id=64d43e43263c09d9283e5d37&name=Overview


HC
https://samuel.sap.mgapp.ibm.com/BR3/buildInformation?id=64d46025288e4973c569e664&name=Overview


Openssh upgrade
https://samuel.sap.mgapp.ibm.com/BR3/buildInformation?id=64d46668288e4973c569eb9f&name=Overview


Post snap link 
https://samuel.sap.mgapp.ibm.com/BR3/buildInformation?id=64d48657263c09d9283e8b42&name=Overview

Manual HC fix
For HC manual remediation ( after SAMUEL) 

Here are the script details:

Script location                  : /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix

Execution procedure      : python /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix/hc_remediation_linux_v6.py



autologout.csh issue, i checked and found. So will remove -r before handover to SAP team. 


[root@br3fsapdb60 ~]# cat /etc/profile.d/autologout.csh
# BEGIN ANSIBLE MANAGED
# Set session timeout - CIS ID 5.4.5
set -r autologout=15
# END ANSIBLE MANAGED[



Ansible remediation is changing the DB log permission, so DB won't start.
*/10 * * * * find /var/log/* -type f -exec chmod g-wx,o-rwx '{}' + -o -type d -not -path /var/log/hist -not -path /var/log/sssd -exec chmod g-wx,o-rwx '{}' +

comment the above form hana servers and change the permissions if changed
We have to set the permission after HANA DB  server remediation in case any issue at DB start.

[6/29 1:57 PM] Sreejesh U

# chmod 755 /var/log/HDBHA/
# chmod 755 /var/log/HDBHA/state_monitor/
# chmod 755 /var/log/HDBHA/state_monitor/state_monitor.log 


check cronjob that changes the var/log permissions for hana





CHG0290756   12-08-2023 06:30:00  12-08-2023 15:30:00

Manual QA Cluster with NZDT  . Have to cover HC vulnerability.

Patch Group (6) - br3qscmss36	SUSE	10.138.10.107	QA	QCM - SAP  (App) - NA	ASCS
Patch Group (6) - br3qscmss37	SUSE	10.138.10.76	QA	QCM - SAP  (App) - NA	ERS

Patch Group (6) - br3qgtsss35	SUSE	10.138.10.38	QA	QGT - SAP  (App) - NA	ASCS
Patch Group (6) - br3qgtsss36	SUSE	10.138.10.62	QA	QGT - SAP  (App) - NA	ERS

Patch Group (7) - br3qsapss30	SUSE	10.138.10.80	QA	Q4H - SAP  (App) - NA	ASCS
Patch Group (7) - br3qsapss31	SUSE	10.138.10.105	QA	Q4H - SAP  (App) - NA	ERS


Patch Group (6) - br3qgtsdb36	SUSE	10.138.10.58	QA	QGT - SAP  (DB) - HANA			mon01-pod1-4tb-host08.imzcloud.ibmammsap.local
Patch Group (6) - br3qgtsdb37	SUSE	10.138.10.82	QA	QGT - SAP  (DB) - HANA			mon01-pod1-4tb-host07.imzcloud.ibmammsap.local

Patch Group (6) - br3qscmdb37	SUSE	10.138.10.145	QA	QCM - SAP  (DB) - HANA				mon01-pod1-4tb-host07.imzcloud.ibmammsap.local
Patch Group (6) - br3qscmdb36	SUSE	10.138.10.88	QA	QCM - SAP  (DB) - HANA					mon01-pod1-4tb-host16.imzcloud.ibmammsap.local

Patch Group (7) - br3qsapdb32	SUSE	10.138.10.194	QA	<SID> - SAP <Landscape> (DB) - HANA			mon01-pod1-6tb-host005.imzcloud.ibmammsap.local
Patch Group (7) - br3qsapdb33	SUSE	10.138.10.190	QA	<SID> - SAP <Landscape> (DB) - HANA			mon01-pod1-6tb-host006.imzcloud.ibmammsap.local

zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt|grep -v done)



HANA Node
						 1    Standby the secondary node
                         2    Perform Actvity on HANA secondary ( Both OS patching and CIS remediation) zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt|grep -v done)
                         3    Attach back the secondary node back to cluster ( set the node back  online)
                         4    Wait for the HSR Sync
                         5    Set Primary node standby
                         6    Perform Actvity on HANA primary node ( Both OS patching and CIS remediation) zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt|grep -v done)
                         7    HSR registration
                         8    Attach back the primary node back to cluster ( set the node back  online)
                         9    Wait for the HSR Sync

 

App servers:
                    1    Standby the ASCS node (primary node)    6 hours
                         2    Complete OS activities
                         3    Attach back the node by keeping it online
                         4    wait for the automatic ERS failover (ERS will be on the patched node) zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt|grep -v done)
                         5    Standby of HA node
                         6    Complete OS activities     
                         7    Attach back the node by keeping it online     
                         8    wait for the automatic ERS failover (ERS will be on the patched node) zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt|grep -v done)

 
                             
                              crm node standby node     
                              crm node online node

All related to the change CHG0290756. Everything is completed and validated. Just that the alerts got generated after the change closure as always





CHG0292377    Mitsubishi Motors Corporation -- MMC    Linux    8/11/2023  20:00
CHG0289180    Torrent Gas Pvt Limited -- TGP    Linux       8/15/2023    10:00


CHG0288577 ,  CHG0285374

su - hp1adm -c "hdbnsutil -sr_register --remoteHost=jp0811zbe1009 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay --name=<NODENAME A or B>"



su - hp1adm -c "hdbnsutil -sr_register --remoteHost=jp0811zbe1009 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay --name=<NODENAME A or B>"




su - qgtadm -c "hdbnsutil -sr_register --remoteHost=br3qgtsdb37 --remoteInstance=35 --replicationMode=sync --operationMode=logreplay --name=NODEA"


su - qcmadm -c "hdbnsutil -sr_register --remoteHost=br3qgtsdb37 --remoteInstance=35 --replicationMode=sync --operationMode=logreplay --name=NODEA"




CHG0289535 CST/CDT - 08/18/2023 - 20:00 - NIX - MCL - OS Update SLES 12 SP04 to SP05 - PROD
CHG0289536 CST/CDT - 08/18/2023 - 20:00 - NIX - MCL - OS Update SLES 12 SP04 to SP05 - PROD

146.89.141.178 via 10.138.0.1 dev eth0

route add -net 146.89.141.178 gw 10.137.4.1 netmask 255.255.255.255 dev eth0



wget http://mon01ammsmt01.imzcloud.ibmammsap.local/repo/tools/clientSetup4SMT.sh
  735  2023-08-16 04:15:36 chmod 777 clientSetup4SMT.sh.1
  736  2023-08-16 04:15:52 ./clientSetup4SMT.sh.1 dal09ammsmt01.imzcloud.ibmammsap.local
  737  2023-08-16 04:16:07 ./clientSetup4SMT.sh.1 --host mon01ammsmt01.imzcloud.ibmammsap.local



CS13868644
Unmount /backup mount from host hcils4fqa00 (	10.93.65.48	    10.100.100.40) which is shared from dev box hcils4fdv00 (10.93.65.11	10.100.100.10)
DPE approved for 50 GB separately, we need to create a new mount /backup on hcils4fqa00


ILMT
LBUVS1DB02		10.139.32.215
lbups1db02		10.139.10.111
lbups1db02-dr	10.143.64.48
lbups1db02ha	10.139.10.125



Please check for OOM errors in /var/log/syslog once.

Sure, For this you can either configure the CloudWatch Agent to capture memory utilisation of the instances or you can install third party monitoring tools like 'Atop' which will store the historical data of the CPU and Memory utilisation so that you can review these metrics or more on configuring Cloudwatch Agent to capture Memory metrics, you can refer: 

    Collect metrics and logs from Amazon EC2 instances and on-premises servers with the CloudWatch agent:	
    [+] https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html

For more on Atop tool, you can refer: 

    How do I configure the ATOP and SAR monitoring tools for my EC2 instance running Amazon Linux, RHEL, CentOS, or Ubuntu?	
    [+] https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-configure-monitoring-tools/
	
	
	
Actually Snapshot are the volume backup, We can create volume out of it from the snapshot if any data loss.

In case of AMI, we can create a instance with same state before patch.

If there is any recent AMI available, we can spin up an instance and check the configuration changes done.



[13:45] Ravi MALIK
    CHG0291109
Patch Group () - bt1h1qdb01    SUSE    10.192.69.151    Development    <Landscape> <SID> (DB) - HANA
Patch Group () - bt1f1qdb01    SUSE    10.192.69.110    Development    <Landscape> <SID> (App/DB) - Sybase
Patch Group () - bt1c1qcs01    SUSE    10.192.69.247    Development    <Landscape> <SID> (App)
Patch Group () - bt1h4qdb01    SUSE    10.192.69.46    Development    <Landscape> <SID> (DB) - HANA
CHG0291110
Patch Group () - bt1s1qdb01    SUSE    10.192.69.212    Development    <Landscape> <SID> (App/DB) - Sybase
Patch Group () - bt1s4qcs01    SUSE    10.192.69.51    Development    <Landscape> <SID> (App)
Patch Group () - bt1p1qdb01    SUSE    10.192.69.253    Development    <Landscape> <SID> (App/DB) - Sybase
Patch Group () - bt1w1qws01    SUSE    10.192.71.45    Development    <Landscape> <SID> (App)
Patch Group () - bt1w1qws02    SUSE    10.192.71.27    Development    <Landscape> <SID> (App)


sev 1 CS13870796
10.250.21.157	BT1S4QCS01	
10.250.21.43	BT1H4QDB01
10.250.21.240	bt1p1qdb01
10.250.21.77	bt1s4dcs01


client raised sev1 that on  Dev server BT1H4QDB01 S4Q Apps DB not accessible.
post patching client unable to access BT1S4QCS01,BT1H4QDB01 these 2 server.

[root@bt1s4qcs01 ~]# df -hT |grep -i nfs
bt1p1qdb01:/imageshare                       nfs4       10G   47M   10G   1% /imageshare
bt1s4dcs01:/usr/sap/trans                    nfs4       75G   19G   57G  25% /usr/sap/trans
bt1p1qdb01:/usr/sap/interface                nfs4       10G   52M   10G   1% /usr/sap/interface
bt1p1qdb01:/interface/P1Q                    nfs4       46M  3.0M   43M   7% /interface/P1Q




file="<filename>"; curl -s https://d1mg6achc83nsz.cloudfront.net/badeb0498b44e32e2e2222ed61f3990890ac637e766708c311a17b4060679644/us-east-1/$file  | bash


uname -a
Impacted servers	DS agent version is ds_agent-20.0.0-6912.SuSE_15.x86_64 on all

	BT1C1QCS01	10.192.69.247	10.250.21.219	C1Q
[ibmrmalik@bt1c1qcs01 ~]$ uname -a
Linux bt1c1qcs01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux

	BT1H1QDB01	10.192.69.151	10.250.21.151	H1Q
[ibmrmalik@bt1h1qdb01 ~]$ uname -a
Linux bt1h1qdb01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux

	BT1H4QDB01	10.192.69.46	10.250.21.43	H4Q
[ibmrmalik@bt1h4qdb01 ~]$ uname -a
Linux bt1h4qdb01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux

	BT1P1QDB01	10.192.69.253	10.250.21.240	P1Q		bt1p1qdb01 i-04a75ac60e7cd3ced
	Aug 17 21:21:20 bt1p1qdb01 ds_am.init[5078]: The ds_am module is lack of KernelSupport package for kernel 5.14.21-150400.24.81-default
Aug 17 21:21:31 bt1p1qdb01 ds_am.init[5597]: The ds_am module is lack of KernelSupport package for kernel 5.14.21-150400.24.81-default
[ibmrmalik@bt1p1qdb01 ~]$ uname -a
Linux bt1p1qdb01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux

	BT1S1QDB01	10.192.69.212	10.250.21.19	S1Q			Aug 18 09:53:05 bt1s1qdb01 ds_am.init[3566]: The ds_am module is lack of KernelSupport package for kernel 5.14.21-150400.24.81-default
[root@bt1s1qdb01 tmp]# uname -a
Linux bt1s1qdb01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux

	BT1S4QCS01	10.192.69.51	10.250.21.157	S4Q
[ibmrmalik@bt1s4qcs01 ~]$ uname -a
Linux bt1s4qcs01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux


Non - Impacted 

BT1W1QWS01	10.192.71.45	10.250.23.11	 ds_agent-20.0.0-6313.SuSE_15.x86_64
Aug 17 02:13:57 bt1w1qws01 ds_am.init[14999]: The ds_am module is lack of KernelSupport package for kernel 5.14.21-150400.24.81-default
[ibmrmalik@bt1w1qws01 ~]$ uname -a
Linux bt1w1qws01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux

BT1W1QWS02	10.192.71.27	10.250.23.42	ds agent version is ds_agent-20.0.0-6313.SuSE_15.x86_64
Aug 17 02:16:21 bt1w1qws02 ds_am.init[13403]: The ds_am module is lack of KernelSupport package for kernel 5.14.21-150400.24.81-default
Aug 17 02:16:21 bt1w1qws02 ds_am.init[13834]: The ds_am module is lack of KernelSupport package for kernel 5.14.21-150400.24.81-default
[ibmrmalik@bt1w1qws02 ~]$ uname -a
Linux bt1w1qws02 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux






BT1P1QDB01	10.192.69.253	10.250.21.240	P1Q		bt1p1qdb01 i-04a75ac60e7cd3ced
[ibmrmalik@bt1p1qdb01 ~]$ uname -a
Linux bt1p1qdb01 5.14.21-150400.24.81-default #1 SMP PREEMPT_DYNAMIC Tue Aug 8 14:10:43 UTC 2023 (90a74a8) x86_64 x86_64 x86_64 GNU/Linux


nvme7n1                               259:10   0   48G  0 disk                         vol0ca54fa96eef6d2bd
â””â”€system-swap                         254:0    0   48G  0 lvm  [SWAP]
nvme8n1                               259:11   0   64G  0 disk                         vol04dc28decb62b41b3
â””â”€nvme8n1p2                           259:12   0   62G  0 part
  â”œâ”€rootvg-homelv                     254:20   0    5G  0 lvm  /home
  â”œâ”€rootvg-optlv                      254:21   0   10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv                      254:22   0   10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv                      254:23   0   10G  0 lvm  /var
  â”œâ”€rootvg-vloglv                     254:24   0   10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp                     254:25   0    2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit                254:26   0    4G  0 lvm  /var/log/audit
  â”œâ”€rootvg-varoptansible              254:27   0    5G  0 lvm  /var/opt/ansible
  â””â”€rootvg-vcrashlv                   254:28   0  1.3G  0 lvm  /var/crash
nvme0n1                               259:2    0   64G  0 disk                         vol056fb7efe62dadbb6
â”œâ”€nvme0n1p1                           259:5    0    2M  0 part
â”œâ”€nvme0n1p2                           259:6    0   20M  0 part /boot/efi
â””â”€nvme0n1p3                           259:7    0   64G  0 part /



CHG0290667 CST/CDT - 08/22/2023 - 20:00 - NIX - GLT - PATCH - 1Q23,2Q23,3Q23- Troop B(SAPB2)

CHG0292507 CST/CDT - 08/22/2023 - 20:00 - NIX - GLT - PATCH - 1Q23,2Q23,3Q23- Troop B(SAPB2)

prechecks pref the ones from script pls


CHG0290339 CST/CDT - 08/21/2023 - 20:00 - NIX - HOE - PATCH - HC - 1Q23,2Q23,3Q23- Troop B(SAPB2)

precehcks from script





There is an ongoing MCI in Dal 13 and the wa2xipaap02 is affected

wa2xipaap02		10.191.2.21
wa2xipaap02s	10.191.2.7


but the wa2xipaap02s is not.



Linux SME CHG0290955




CS13893099

 Hostname: wa2xipaap02s                                                *
*         CFN IP: 10.150.5.174                                                *
*         IFN IP: 10.191.2.7 

Hostname: wa2xipaap02                                                 *
*         CFN IP: 10.150.5.169                                                *
*         IFN IP: 10.191.2.21  




CHG0290974    American Airlines -- A1A        Linux       8/25/2023     20:00
CHG0286147    Hino Motors Ltd -- HNO        Linux       8/26/2023     20:00

/home/v33_sftp_user/.ssh path had permission issues

it was with permissions 775 and on 32 it was 700 so changed that

later when checked it was the parent folder /home/v33_sftp_user with 775 again and that should have to be 700 also which once done was all gud

 BAPV330900	10.134.3.7

[root@bapv330900 .ssh]# ls -ld /home/v33_sftp_user/.ssh
drwxrwxr-x 2 v33_sftp_user sapsys 4096 Aug 24 12:04 /home/v33_sftp_user/.ssh


[root@bapv330900 .ssh]# chmod 700 /home/v33_sftp_user/.ssh
[root@bapv330900 .ssh]# ls -ld /home/v33_sftp_user/.ssh
drwx------ 2 v33_sftp_user sapsys 4096 Aug 24 12:04 /home/v33_sftp_user/.ssh


[root@bapv330900 ~]# stat /home/v33_sftp_user/.ssh
  File: '/home/v33_sftp_user/.ssh'
  Size: 4096            Blocks: 8          IO Block: 4096   directory
Device: fe16h/65046d    Inode: 131424      Links: 2
Access: (0700/drwx------)  Uid: (54719/v33_sftp_user)   Gid: ( 3050/  sapsys)
Access: 2023-08-25 13:32:59.277758127 +0800
Modify: 2023-08-24 12:04:46.321491513 +0800
Change: 2023-08-24 12:28:15.775436563 +0800
 Birth: -


[root@bapv330900 log]# cat messages |grep -i "error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108" |less
Aug 21 10:57:08 bapv330900 sshd[5087]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:57:10 bapv330900 sshd[5087]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:57:12 bapv330900 sshd[5087]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:59:06 bapv330900 sshd[26479]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:59:08 bapv330900 sshd[26479]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:59:10 bapv330900 sshd[26479]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108

CHG0286679  19-08-2023 20:30:00  20-08-2023 04:30:00  server time 00:00 to 0800

Aug 19 23:59:04 bapv330900 sshd[50223]: Accepted publickey for v33_sftp_user from 10.116.83.108 port 42538 ssh2: RSA SHA256:wlc030cF6ZNFXyJQ1Q+y7OrxJAHb7rAC8A2Z4kP3kr0
Aug 19 23:59:05 bapv330900 sshd[50231]: Received disconnect from 10.116.83.108 port 42538:11: disconnected by user
Aug 19 23:59:05 bapv330900 sshd[50231]: Disconnected from 10.116.83.108 port 42538


Aug 21 10:53:05 bapv330900 sshd[1850]: Accepted publickey for v33_sftp_user from 10.116.83.108 port 50714 ssh2: RSA SHA256:wlc030cF6ZNFXyJQ1Q+y7OrxJAHb7rAC8A2Z4kP3kr0
Aug 21 10:53:06 bapv330900 sshd[1853]: Received disconnect from 10.116.83.108 port 50714:11: disconnected by user
Aug 21 10:53:06 bapv330900 sshd[1853]: Disconnected from 10.116.83.108 port 50714
Aug 21 10:55:04 bapv330900 sshd[3158]: Accepted publickey for v33_sftp_user from 10.116.83.108 port 50718 ssh2: RSA SHA256:wlc030cF6ZNFXyJQ1Q+y7OrxJAHb7rAC8A2Z4kP3kr0
Aug 21 10:55:05 bapv330900 sshd[3161]: Received disconnect from 10.116.83.108 port 50718:11: disconnected by user
Aug 21 10:55:05 bapv330900 sshd[3161]: Disconnected from 10.116.83.108 port 50718

Aug 21 10:57:08 bapv330900 sshd[5087]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:57:08 bapv330900 sshd[5087]: Postponed keyboard-interactive for v33_sftp_user from 10.116.83.108 port 50724 ssh2 [preauth]
Aug 21 10:57:10 bapv330900 sshd[5087]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:57:10 bapv330900 sshd[5087]: Postponed keyboard-interactive for v33_sftp_user from 10.116.83.108 port 50724 ssh2 [preauth]
Aug 21 10:57:12 bapv330900 sshd[5087]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108
Aug 21 10:57:12 bapv330900 sshd[5087]: Failed keyboard-interactive/pam for v33_sftp_user from 10.116.83.108 port 50724 ssh2
Aug 21 10:57:12 bapv330900 sshd[5087]: error: maximum authentication attempts exceeded for v33_sftp_user from 10.116.83.108 port 50724 ssh2 [preauth]
Aug 21 10:59:06 bapv330900 sshd[26479]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108


[root@bapv330900 log]# history |grep -i 2023-08-21
   79  2023-08-21 10:51:46 df -h
   80  2023-08-21 10:52:28 ls -ld /usr/sap/interfaces/V33/boa/ob/Archive
   81  2023-08-21 10:52:49 date
   82  2023-08-21 10:54:04 ls -ltr
   83  2023-08-21 10:54:36 ls -ld  /usr/sap/interfaces/V33/boa
   84  2023-08-21 10:54:43 cd ..
   85  2023-08-21 10:54:45 ll
   86  2023-08-21 10:55:30 chmod -R 775 v33_sftp_user
   87  2023-08-21 10:55:35 ls -l v33_sftp_user
   88  2023-08-21 10:55:42 ls -ltr
   89  2023-08-21 11:05:28 pwd
   90  2023-08-21 11:05:45 cd â€˜/usr/sap/interfaces/V33/boa/ob
   91  2023-08-21 11:06:07 cd /usr/sap/interfaces/V33/boa/ob
   92  2023-08-21 11:06:13 ls -ltr
   93  2023-08-21 11:07:13 cd AC_Outbox
   94  2023-08-21 11:07:15 ls -l
   95  2023-08-21 11:07:36 cd ..
   96  2023-08-21 11:07:39 ll
   97  2023-08-21 11:07:45 cd ..
   98  2023-08-21 11:07:53 pqd
   99  2023-08-21 11:07:56 pwd
  100  2023-08-21 11:07:57 ll
  101  2023-08-21 11:08:16 chmod -R 777 ebs ob/
  102  2023-08-21 11:08:23 cd ob
  103  2023-08-21 11:08:25 ll
  104  2023-08-21 11:08:36 cd AC_Outbox
  105  2023-08-21 11:08:40 ls -ltr
  
  
  Aug 21 10:55:30 bapv330900 rootsh[1b259]: ibmspeddapalli: 032: #033[0;92m[root@bapv330900 home]##033[m chmod -R 775 v33_sftp_user
Aug 21 10:55:35 bapv330900 rootsh[1b259]: ibmspeddapalli: 033: #033[0;92m[root@bapv330900 home]##033[m ls -l v33_sftp_user



Aug 21 10:57:07 bapv330900 sshd[5087]: Authentication refused: bad ownership or modes for file /home/v33_sftp_user/.ssh/authorized_keys

Aug 21 10:57:07 bapv330900 audispd[2552]: node=bapv330900 type=USER_AUTH msg=audit(1692586627.108:70162): pid=5087 uid=0 auid=4294967295 ses=4294967295 msg='op=pubkey acct="v33_sftp_user" exe="/usr/sbin/sshd" hostname=? addr=10.116.83.108 terminal=ssh res=failed'
Aug 21 10:57:07 bapv330900 sshd[5090]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=10.116.83.108  user=v33_sftp_user
Aug 21 10:57:07 bapv330900 sshd[5090]: pam_sss(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=10.116.83.108 user=v33_sftp_user
Aug 21 10:57:07 bapv330900 sshd[5090]: pam_sss(sshd:auth): received for user v33_sftp_user: 10 (User not known to the underlying authentication module)
Aug 21 10:57:08 bapv330900 audispd[2552]: node=bapv330900 type=USER_AUTH msg=audit(1692586628.448:70163): pid=5090 uid=0 auid=4294967295 ses=4294967295 msg='op=PAM:authentication acct="?" exe="/usr/sbin/sshd" hostname=10.116.83.108 addr=10.116.83.108 terminal=ssh res=failed'
Aug 21 10:57:08 bapv330900 sshd[5087]: error: PAM: User not known to the underlying authentication module for v33_sftp_user from 10.116.83.108


OS engineer found /home/v33_sftp_user/.ssh path had permission issues.
Technical team found on server v32 has permission 700 and on v33 permission is 775 As well on parent folder r /home/v33_sftp_user have permission also 775 so change the permission to 700 post which v33 server working fine .
Post which found Date issue on server .
OS team adjusted the source server date time to current local time. However, After checking the VMware tools services version, team noticed that the server is showing as 2026-03-22. The date is incorrect.
To correct the date time in the server, OS team is adjusting the date/time in the local system and update the same in the Hardware clock and tried to reboot the server.
Following the rebooting the server, we have verified that all files are visible in the SAP applications. moreover, the date and time issue has been fixed.
Assigned Informal RCA to OS engineer .



/sapmnt/P34   sm9d185173116


CHG0295850    CST/CDT - 08/26/2023 - 20:00 - NIX - SM9 - PATCH - HC - VULN - 1Q23,2Q23,3Q23- SAPB1,SAPD1
CHG0295855    CST/CDT - 08/25/2023 - 20:00 - NIX - SM9 - PATCH - HC - VULN - 1Q23,2Q23,3Q23- SAPB1,SAPD1



EWMAPP1	Linux Server	Installed	EMP	10.207.61.77	10.170.61.68
EWMAPP3-HA	Linux Server	Installed		10.207.61.203	10.170.61.213	
EWMAPP3	Linux Server	Installed		10.207.61.114	10.170.61.204

Printer Model Name : Intermec PM43 (203 dpi)
Printer IP                     : 131.0.12.138
Printer Hostname      :  Intermec
Queue Name  : Intermec


lpadmin -p Intermec -v socket://131.0.12.138 -E


131.0.12.138   Intermec




Presnap for all 9 servers  https://samuel.sap.adai.kyndryl.com/SM9/buildInformation?id=64e9591af28ef4bdd7362172&name=Overview
HC  https://samuel.sap.adai.kyndryl.com/SM9/buildInformation?id=64e96ecdf28ef4bdd73639b2&name=Overview
Postsnap validation https://samuel.sap.adai.kyndryl.com/SM9/buildInformation?id=64e97e9ff28ef4bdd73654de&name=Overview

Script location                  : /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix

Execution procedure      : python /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix/hc_remediation_linux_v6.py


CHG0295855	26-08-2023 06:30:00	26-08-2023 18:30:00

This 08/25/2023 - 20:00 - NIX  remediation is for the following CIs:

Patch Group (Prod1A) - sm9a185173115	SUSE	10.135.224.24	Production	P33 - SAP  (App) - NA
Patch Group (Prod1A) - sm9h185173115	SUSE	10.135.224.23	Production	P33 - SAP  (App) - NA

Patch Group (Prod1A) - sm9h18517311a	SUSE	10.135.224.27	Production	P34 - SAP  (App) - NA
Patch Group (Prod1A) - sm9d18517311a	SUSE	10.135.224.26	Production	P34 - SAP  (App) - NA

Patch Group (Prod1A) - sm9hcnlcslx01	SUSE	10.135.224.21	Production	P33 - SAP  (DB) - HANA
Patch Group (Prod1A) - sm9cnlcslx01	SUSE	10.135.224.25	Production	P33 - SAP  (DB) - HANA

Patch Group (Prod1A) - sm9h185173116	SUSE	10.135.224.45	Production	P34 - SAP  () - DB2
Patch Group (Prod1A) - sm9d185173116	SUSE	10.135.224.29	Production	P34 - SAP  (DB) - DB2


CHG0296152	26-08-2023 06:30:00	26-08-2023 12:30:00

This 08/25/2023 - 20:00 - NIX  remediation is for the following CIs:

Patch Group (Prod1A) - sm9dcnlcslx01	SUSE	10.210.240.11	Disaster recovery	P33 - SAP  (DB) - HANA


Resource Group: g-ascs
     ip-p33-ascs        (ocf::heartbeat:IPaddr2):       Started sm9a185173115
     vol_p33ascsvg      (ocf::heartbeat:LVM):   Started sm9a185173115
     fs-ascs01lv        (ocf::heartbeat:Filesystem):    Started sm9a185173115
     rsc_sap_p33_ascs   (ocf::heartbeat:SAPInstance):   Started sm9a185173115
 Resource Group: g-ers
     ip-p33-ers02       (ocf::heartbeat:IPaddr2):       Started sm9h185173115
     vol_p33ersvg       (ocf::heartbeat:LVM):   Started sm9h185173115
     fs-ers02lv (ocf::heartbeat:Filesystem):    Started sm9h185173115
     rsc_sap_p33_ers    (ocf::heartbeat:SAPInstance):   Started sm9h185173115
 Resource Group: g-nfs
     ip-p33-nfs (ocf::heartbeat:IPaddr2):       Started sm9a185173115
     vol_p33globalvg    (ocf::heartbeat:LVM):   Started sm9a185173115
     fs-sapmnt  (ocf::heartbeat:Filesystem):    Started sm9a185173115
     fs-inter   (ocf::heartbeat:Filesystem):    Started sm9a185173115
     fs-3party  (ocf::heartbeat:Filesystem):    Started sm9a185173115
     export-sapmnt      (ocf::heartbeat:exportfs):      Started sm9a185173115
     export-inter       (ocf::heartbeat:exportfs):      Started sm9a185173115
     export-3party      (ocf::heartbeat:exportfs):      Started sm9a185173115
     fs-trans   (ocf::heartbeat:Filesystem):    Started sm9a185173115
     export-trans       (ocf::heartbeat:exportfs):      Started sm9a185173115


 Resource Group: g-ascs
     ip-p33-ascs        (ocf::heartbeat:IPaddr2):       Started sm9a185173115 (unmanaged)
     vol_p33ascsvg      (ocf::heartbeat:LVM):   Started sm9a185173115 (unmanaged)
     fs-ascs01lv        (ocf::heartbeat:Filesystem):    Started sm9a185173115 (unmanaged)
     rsc_sap_p33_ascs   (ocf::heartbeat:SAPInstance):   Started sm9a185173115 (unmanaged)
 Resource Group: g-ers
     ip-p33-ers02       (ocf::heartbeat:IPaddr2):       Started sm9h185173115 (unmanaged)
     vol_p33ersvg       (ocf::heartbeat:LVM):   Started sm9h185173115 (unmanaged)
     fs-ers02lv (ocf::heartbeat:Filesystem):    Started sm9h185173115 (unmanaged)
     rsc_sap_p33_ers    (ocf::heartbeat:SAPInstance):   Started sm9h185173115 (unmanaged)
 Resource Group: g-nfs
     ip-p33-nfs (ocf::heartbeat:IPaddr2):       Started sm9a185173115 (unmanaged)
     vol_p33globalvg    (ocf::heartbeat:LVM):   Started sm9a185173115 (unmanaged)
     fs-sapmnt  (ocf::heartbeat:Filesystem):    Started sm9a185173115 (unmanaged)
     fs-inter   (ocf::heartbeat:Filesystem):    Started sm9a185173115 (unmanaged)
     fs-3party  (ocf::heartbeat:Filesystem):    Started sm9a185173115 (unmanaged)
     export-sapmnt      (ocf::heartbeat:exportfs):      Started sm9a185173115 (unmanaged)
     export-inter       (ocf::heartbeat:exportfs):      Started sm9a185173115 (unmanaged)
     export-3party      (ocf::heartbeat:exportfs):      Started sm9a185173115 (unmanaged)
     fs-trans   (ocf::heartbeat:Filesystem):    Started sm9a185173115 (unmanaged)
     export-trans       (ocf::heartbeat:exportfs):      Started sm9a185173115 (unmanaged)





 Resource Group: g-ascs
     ip-p34-ascs        (ocf::heartbeat:IPaddr2):       Started sm9d18517311a
     vol_p34ascsvg      (ocf::heartbeat:LVM):   Started sm9d18517311a
     fs-scs03lv (ocf::heartbeat:Filesystem):    Started sm9d18517311a
     rsc_sap_p34_scs    (ocf::heartbeat:SAPInstance):   Started sm9d18517311a
 Resource Group: g-ers
     ip-p34-ERS04       (ocf::heartbeat:IPaddr2):       Started sm9h18517311a
     vol_p34ersvg       (ocf::heartbeat:LVM):   Started sm9h18517311a
     fs-ERS04lv (ocf::heartbeat:Filesystem):    Started sm9h18517311a
     rsc_sap_p34_ers    (ocf::heartbeat:SAPInstance):   Started sm9h18517311a
 Resource Group: g-nfs
     ip-p34-nfs (ocf::heartbeat:IPaddr2):       Started sm9d18517311a
     vol_p34nfs (ocf::heartbeat:LVM):   Started sm9d18517311a
     fs-sapmnt  (ocf::heartbeat:Filesystem):    Started sm9d18517311a
     export-sapmnt      (ocf::heartbeat:exportfs):      Started sm9d18517311a
     fs-inter   (ocf::heartbeat:Filesystem):    Started sm9d18517311a
     export-inter       (ocf::heartbeat:exportfs):      Started sm9d18517311a
     fs-3party  (ocf::heartbeat:Filesystem):    Started sm9d18517311a
     export-3party      (ocf::heartbeat:exportfs):      Started sm9d18517311a
	 
	 
 Resource Group: g-ascs
     ip-p34-ascs        (ocf::heartbeat:IPaddr2):       Started sm9d18517311a (unmanaged)
     vol_p34ascsvg      (ocf::heartbeat:LVM):   Started sm9d18517311a (unmanaged)
     fs-scs03lv (ocf::heartbeat:Filesystem):    Started sm9d18517311a (unmanaged)
     rsc_sap_p34_scs    (ocf::heartbeat:SAPInstance):   Started sm9d18517311a (unmanaged)
 Resource Group: g-ers
     ip-p34-ERS04       (ocf::heartbeat:IPaddr2):       Started sm9h18517311a (unmanaged)
     vol_p34ersvg       (ocf::heartbeat:LVM):   Started sm9h18517311a (unmanaged)
     fs-ERS04lv (ocf::heartbeat:Filesystem):    Started sm9h18517311a (unmanaged)
     rsc_sap_p34_ers    (ocf::heartbeat:SAPInstance):   Started sm9h18517311a (unmanaged)
 Resource Group: g-nfs
     ip-p34-nfs (ocf::heartbeat:IPaddr2):       Started sm9h18517311a (unmanaged)
     vol_p34nfs (ocf::heartbeat:LVM):   Started sm9h18517311a (unmanaged)
     fs-sapmnt  (ocf::heartbeat:Filesystem):    Started sm9h18517311a (unmanaged)
     export-sapmnt      (ocf::heartbeat:exportfs):      Started sm9h18517311a (unmanaged)
     fs-inter   (ocf::heartbeat:Filesystem):    Started sm9h18517311a (unmanaged)
     export-inter       (ocf::heartbeat:exportfs):      Started sm9h18517311a (unmanaged)
     fs-3party  (ocf::heartbeat:Filesystem):    Started sm9h18517311a (unmanaged)
     export-3party      (ocf::heartbeat:exportfs):      Started sm9h18517311a (unmanaged)


	 
	 
Resource Group: group-fs
     fs-backup  (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-aoddba  (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2     (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34 (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_db2dump (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_log_archive     (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_log_dir (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_log_retrieve    (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_sapdata1        (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_sapdata2        (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_sapdata3        (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_sapdata4        (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_saptmp1 (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_saptmp2 (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_saptmp3 (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_P34_saptmp4 (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2_db2p34      (ocf::heartbeat:Filesystem):    Started sm9d185173116
     fs-db2p34_db2_software     (ocf::heartbeat:Filesystem):    Started sm9d185173116
 Resource Group: group-vol
     vol_p34logvg       (ocf::heartbeat:LVM):   Started sm9d185173116
     vol_p34archvg      (ocf::heartbeat:LVM):   Started sm9d185173116
     vol_p34datavg      (ocf::heartbeat:LVM):   Started sm9d185173116
 Master/Slave Set: master-slave-res [group-drbd]
     Masters: [ sm9d185173116 ]
     Slaves: [ sm9h185173116 ]
 Resource Group: group_db2_p34
     ip-db2     (ocf::heartbeat:IPaddr2):       Started sm9d185173116
     rsc_db2_p34        (ocf::heartbeat:DB2):   Started sm9d185173116
     TSM_DB2    (systemd:dsmcad_db2):   Started sm9d185173116
     TSM_DB2log (systemd:dsmcad_db2log):        Started sm9d185173116
 vcenter-fencing-sm9d185173116  (stonith:fence_vmware_rest):    Started sm9h185173116
 vcenter-fencing-sm9h185173116  (stonith:fence_vmware_rest):    Started sm9d185173116



Resource Group: group-fs
     fs-backup  (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-aoddba  (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2     (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34 (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_db2dump (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_log_archive     (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_log_dir (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_log_retrieve    (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_sapdata1        (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_sapdata2        (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_sapdata3        (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_sapdata4        (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_saptmp1 (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_saptmp2 (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_saptmp3 (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_P34_saptmp4 (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2_db2p34      (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
     fs-db2p34_db2_software     (ocf::heartbeat:Filesystem):    Started sm9d185173116 (unmanaged)
 Resource Group: group-vol
     vol_p34logvg       (ocf::heartbeat:LVM):   Started sm9d185173116 (unmanaged)
     vol_p34archvg      (ocf::heartbeat:LVM):   Started sm9d185173116 (unmanaged)
     vol_p34datavg      (ocf::heartbeat:LVM):   Started sm9d185173116 (unmanaged)



presnap
root pw revert
snapshot



CHG0296185 

[root@sm9d185173005 ~]# df -hT /export/sapuseraudit/
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/p11globalvg-audit_lv xfs   2.7T  2.4T  240G  92% /export/sapuseraudit


[root@sm9d185173005 ~]# df -hT /export/sapuseraudit
Filesystem                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/p11globalvg-audit_lv xfs   3.0T  2.4T  540G  82% /export/sapuseraudit



sm9h185173005    10.135.224.37 
sm9d185173005    10.135.224.39

[root@sm9d185173005 ~]# drbdadm status
r0 role:Primary
  volume:0 disk:UpToDate
  volume:1 disk:UpToDate
  volume:2 disk:UpToDate
  volume:3 disk:UpToDate
  volume:4 disk:UpToDate
  volume:5 disk:UpToDate
  sm9h185173005 role:Secondary
    volume:0 peer-disk:UpToDate
    volume:1 peer-disk:UpToDate
    volume:2 peer-disk:UpToDate
    volume:3 peer-disk:UpToDate
    volume:4 peer-disk:UpToDate
    volume:5 peer-disk:UpToDate

r1 role:Primary
  disk:UpToDate
  sm9h185173005 role:Secondary
    peer-disk:UpToDate

r2 role:Secondary
  disk:UpToDate
  sm9h185173005 role:Primary
    peer-disk:UpToDate


[root@sm9d185173005 ~]# pvscan |grep -i p11globalvg
  PV /dev/drbd0   VG p11globalvg     lvm2 [511.98 GiB / 0    free]
  PV /dev/drbd3   VG p11globalvg     lvm2 [511.98 GiB / 1.88 GiB free]
  PV /dev/drbd4   VG p11globalvg     lvm2 [511.98 GiB / 0    free]
  PV /dev/drbd5   VG p11globalvg     lvm2 [511.98 GiB / 0    free]
  PV /dev/drbd6   VG p11globalvg     lvm2 [511.98 GiB / 0    free]
  PV /dev/drbd7   VG p11globalvg     lvm2 [511.98 GiB / 0    free]


[root@sm9d185173005 ~]# grep -r "drbd0" /etc/drbd.d/r*
/etc/drbd.d/r0.res:    device /dev/drbd0;


 volume 6 {
    device /dev/drbd8;
    disk /dev/sdm;
    meta-disk internal;
 }



drbdadm create-md r0/6


Secondary node
drbdadm  disconnect r2; drbdadm secondary r2; drbdadm connect r2 --discard-my-data
On primary node
drbdadm  disconnect r2; drbdadm primary r2; drbdadm connect r2




[root@hgyp09dbap01 ~]# su - p09adm
hgyp09dbap01:p09adm 53> pwd
/home/p09adm
hgyp09dbap01:p09adm 54> crontab -l
# Created on 2021/10/24 as part of Migration
*/4 * * * * ssh sftpp09@hgyp09dbap01 '/local/data/interface/P09/DISI0XX/scripts/1sapdmztoP09.sh' >/dev/null 2>/dev/null			user@10.34.192.152
*/2 * * * * ssh sftpp09@hgyp09dbap01 '/local/data/interface/P09/DISI0XX/scripts/2sapP09toomg.sh' >/dev/null 2>/dev/null
*/2 * * * * ssh sftpp09@hgyp09dbap01 '/local/data/interface/P09/DISI0XX/scripts/3tasomgtoP09.sh' >/dev/null 2>/dev/null
*/2 * * * * ssh sftpp09@hgyp09dbap01 '/local/data/interface/P09/DISI0XX/scripts/4tasP09todmz.sh' >/dev/null 2>/dev/null
*/2 * * * * ssh sftpp09@hgyp09dbap01 '/local/data/interface/P09/DISI0XX/scripts/filemod.sh' >/dev/null 2>/dev/null
0 17 * * * ssh sftpp09@hgyp09dbap01 '/local/data/interface/P09/DISI0XX/scripts/RymnetP09.sh' >/dev/null 2>/dev/null




lpadmin -p NPID288E0 -v socket://10.40.107.91:9100



remove 192.168.10.25    NPID288E0

add 10.40.107.91	NPID288E0	


Kernel version in precheck and post check will not match as the one as per 2nd Aug is an older one and one in precheck is a newer kernel that should not get updated




wa2_wa2crqap01

wa2_wa2fipdb02

wa2_wa2pbsprd01

wa2_wa2mssqasi2	login not working

wa2_wa2mssprodi1

wa2s1dadb1


gltmedevas01

gltnwadevas01

glt_glts4prdas05

npvm21   windows validated uptime is >20 days


hfc_hfchppapp2ha

hfcwddapp1

hfchpqappdb

prdb02a

prdb11



01:03:14 PM  LINUX RESTART      (32 CPU)



CHG0297597	05-09-2023 06:30:00	05-09-2023 09:30:00
CST/CDT - 09/04/2023 - 20:00 - NIX - BS5 - PATCH - 1Q23,2Q23,3Q23- SAPB1,SAPD1

This 09/04/2023 - 20:00 - NIX  remediation is for the following CIs:
Patch Group () - bs5eccqas	SUSE	10.141.133.44	Development	<SID> - SAP <Landscape> (DB)		FAILED  Gateway 132.133.0.1 is not reachable. Ping was not successful.		nda1KXrluK8x&&&	FAILED  Gateway 132.133.0.1 is not reachable.
Patch Group () - bs5eccdev	SUSE	10.141.133.23	Development	<SID> - SAP <Landscape> (App/DB)	FAILED  Gateway 132.133.0.1 is not reachable. Ping was not successful.		meBeGnFFsG8Fc25	FAILED  Gateway 132.133.0.1 is not reachable.



Patch Group (QA-1) - vhvq3wd1    SUSE    172.31.254.137    QA    VQ3 - SAP  (App)		pKuYas43qD(L27@
Patch Group (QA-1) - vhvq1wd1    SUSE    172.31.254.136    QA    VQ1 - SAP  (App)		GC(Mg)@qq7nw5Np
Patch Group (QA-1) - vheq3ap1    SUSE    172.31.254.135    QA    EQ3 - SAP  (App)		@u0jRnLpxdKAgLR
Patch Group (QA-1) - vheq1ap1    SUSE    172.31.254.134    QA    EQ1 - SAP  (App)		1jGT*AkiH0)p^8x
Patch Group (QA-1) - vhe3qdb1    SUSE    172.31.254.133    QA    E3Q - SAP  (DB) - HANA		)9jmLnZQCrpsin1
Patch Group (QA-1) - vhe1qdb1    SUSE    172.31.254.132    QA    E1Q - SAP  (DB) - HANA		oiKSRGjnFysYJBB




Patch Group (QA1) - dltqeahap5Â Â Â  RedhatÂ Â Â  10.4.5.222Â Â Â  QAÂ Â Â  QEA - SAPÂ  (App) - NA				r39IkGGC@qaMTWY
Patch Group (QA1) - dlthqehap4Â Â Â  RedhatÂ Â Â  10.4.5.39Â Â Â  DevelopmentÂ Â Â  HQE - SAPÂ  (App) - Sybase		uJaRD*h2jkJQvpC
Patch Group (QA1) - dlthqgga2Â Â Â  SUSEÂ Â Â  10.4.5.137Â Â Â  QAÂ Â Â  HQG - SAPÂ  (App) - NA					#Wbzt!Z1k6TNTz0
Patch Group (QA1) - dltqeahap4Â Â Â  RedhatÂ Â Â  10.4.5.221Â Â Â  QAÂ Â Â  QEA - SAPÂ  (App) - NA					!T)d!!*4tOyBRYt
Patch Group (QA1) - dlthqehap5Â Â Â  RedhatÂ Â Â  10.4.5.45Â Â Â  DevelopmentÂ Â Â  HQE - SAPÂ  (App) - NA		nZ80vXRM6R77lhy
Patch Group (QA2) - dlthqehap3Â Â Â  RedhatÂ Â Â  10.4.5.38Â Â Â  DevelopmentÂ Â Â  HQE - SAPÂ  (App) - Sybase	apF!1!!O(RzowKe
Patch Group (QA2) - dltqeahap2Â Â Â  RedhatÂ Â Â  10.4.5.220Â Â Â  QAÂ Â Â  QEA - SAPÂ  (App) - NA				!N1pA(dt2eKAbvy
Patch Group (QA2) - dlthqehap2Â Â Â  RedhatÂ Â Â  10.4.5.37Â Â Â  DevelopmentÂ Â Â  HQE - SAPÂ  (App) - Sybase	ntzOJhOaPh3Hdwg
Patch Group (QA2) - dltqeahap3Â Â Â  RedhatÂ Â Â  10.4.5.219Â Â Â  QAÂ Â Â  QEA - SAPÂ  (App) - NA				uxLUmEQNYdr867l
Patch Group (Q3) - dlthqehapÂ Â Â  RedhatÂ Â Â  10.4.5.33Â Â Â  ProductionÂ Â Â  HQE - SAPÂ  (App)				fpX^(OOKJxbvZaO


 Placeholder Create Error: Unable to find a placeholder datastore for the host/cluster (unavailable). Any placeholder datastores registered with the SRM server that were deleted and recreated in the vCenter Server will need to be removed and re-added as a new placeholder datastore with the SRM server as well. The object 'vim.Datastore:0bc9e230-c75e-47a2-9515-201b9ee90e38:datastore-3809' has already been deleted or has not been completely created
 
  Placeholder Create Error: Unable to find a placeholder datastore for the host/cluster (unavailable). Any placeholder datastores registered with the SRM server that were deleted and recreated in the vCenter Server will need to be removed and re-added as a new placeholder datastore with the SRM server as well. The object 'vim.Datastore:0bc9e230-c75e-47a2-9515-201b9ee90e38:datastore-3809' has already been deleted or has not been completely created
 
 
  A replication error occurred at the vSphere Replication Server for replication 'bap_bapjumpserver'. Details: 'No connection to VR Server for virtual machine bap_bapjumpserver on host ammsng01custesx083.imzcloud.ibmammsap.local in cluster A0B4SG01CB in A0B4SG01: Network'.
  
  
   Placeholder Create Error: Unable to find a placeholder datastore for the host/cluster (unavailable). Any placeholder datastores registered with the SRM server that were deleted and recreated in the vCenter Server will need to be removed and re-added as a new placeholder datastore with the SRM server as well. The object 'vim.Datastore:0bc9e230-c75e-47a2-9515-201b9ee90e38:datastore-3809' has already been deleted or has not been completely created
  
  Cluster
 AMMCHE01CA
Host
 ammche01custesx012.imzcloud.ibmammsap.local
Storage
 CHE01POOL1POD1DSP570
 
 
 BAPCHE01POOL1POD1DSP924
AMMCHE01CA


 BAPSNG01POOL1POD2DSP1043
A0B4SG01CB





CHG0297901	08-09-2023 07:00:00	08-09-2023 11:00:00
This 09/07/2023 - 20:30 - NIX  remediation is for the following CIs:		4Sp8MsVY!!)NuFl
Patch Group () - ttas4hpdb-dr	SUSE	100.64.4.10	Disaster recovery	<SID> - SAP <Landscape> (DB)

presnap  https://samuel.sap.adai.kyndryl.com/TTA/buildInformation?id=64fa7a371092bf1a92d0b66b&name=Overview

[ibmrmalik@ttas4hpdb-dr ~]$ cat /etc/os-release;uname -a;ip route;date
NAME="SLES"
VERSION="15-SP2"
VERSION_ID="15.2"
PRETTY_NAME="SUSE Linux Enterprise Server 15 SP2"
ID="sles"
ID_LIKE="suse"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles:15:sp2"
Linux ttas4hpdb-dr 5.3.18-150200.24.145-default #1 SMP Fri Mar 10 06:55:12 UTC 2023 (486c80d) x86_64 x86_64 x86_64 GNU/Linux
default via 10.170.64.1 dev vlan1
10.170.64.0/24 dev vlan1 proto kernel scope link src 10.170.64.7
100.64.3.0/24 dev vlan81 proto kernel scope link src 100.64.3.44
100.64.4.0/24 dev vlan0 proto kernel scope link src 100.64.4.10
146.89.140.0/22 via 100.64.4.1 dev vlan0
146.89.168.0/21 via 100.64.4.1 dev vlan0
146.89.173.192/26 via 100.64.4.1 dev vlan0
146.89.174.192/26 via 100.64.4.1 dev vlan0
158.87.46.0/23 via 100.64.4.1 dev vlan0
169.55.16.128/28 via 100.64.4.1 dev vlan0
169.55.28.32/27 via 100.64.4.1 dev vlan0
169.55.28.64/28 via 100.64.4.1 dev vlan0
169.55.192.96/27 via 100.64.4.1 dev vlan0
169.60.136.0/22 via 100.64.4.1 dev vlan0
Fri Sep  8 07:12:10 IST 2023



[root@ttas4hpdb-dr ~]# rpm -qa --queryformat '%{NAME}\n' > installed-software.bak
[root@ttas4hpdb-dr ~]# systemctl --type=service |egrep -e "cups.service|vsftpd.service|postfix.service|dnsmasq.service"
  postfix.service                                                                           loaded active running Postfix Mail Transport Agent
[root@ttas4hpdb-dr ~]# cp /etc/security/limits.conf  backup
You have new mail in /var/spool/mail/root
[root@ttas4hpdb-dr ~]# pwd
/root


[root@ttas4hpdb-dr ~]# rpm -qa |grep -i ds_agent
ds_agent-20.0.0-5137.SuSE_15.x86_64


[root@ttas4hpdb-dr ds_agent]# rpm -qa|grep -i ds_agent
ds_agent-20.0.0-7476.SuSE_15.x86_64



[root@ttas4hpdb-dr ~]# zypper info ds_agent
Refreshing service 'SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local'.
Loading repository data...
Reading installed packages...


Information for package ds_agent:
---------------------------------
Repository     : @System
Name           : ds_agent
Version        : 20.0.0-5137.SuSE_15
Arch           : x86_64
Vendor         : Trend Micro Inc.
Support Level  : unknown
Installed Size : 175.6 MiB
Installed      : Yes
Status         : up-to-date
Source package : ds_agent-20.0.0-5137.SuSE_15.src
Upstream URL   : http://www.trendmicro.com/
Summary        : Trend Micro Deep Security Agent
Description    :
    The ds_agent program communicates with the Trend Micro
    Deep Security Manager and controls the local firewall,
    content filtering, integrity monitoring, and log inspection rules.


dr server root pw SA##rgOpor^Uqyk



[root@ttas4hpdb-dr ~]# df -hT
Filesystem     Type      Size  Used Avail Use% Mounted on
devtmpfs       devtmpfs  378G  8.0K  378G   1% /dev
tmpfs          tmpfs     566G  4.0K  566G   1% /dev/shm
tmpfs          tmpfs     378G  3.1M  378G   1% /run
tmpfs          tmpfs     378G     0  378G   0% /sys/fs/cgroup
/dev/sdb3      ext4      147G  8.2G  131G   6% /
/dev/sdb1      ext2     1008M   92M  866M  10% /boot
/dev/sdb2      vfat      500M   26M  475M   6% /boot/efi
/dev/sdb4      xfs       150G  429M  150G   1% /usr/sap
/dev/sdc1      xfs       1.1T   65G  981G   7% /sapmnt/shared
/dev/sdb5      xfs       593G   25G  569G   5% /sapmnt/log
/dev/sdc2      xfs       1.9T  152G  1.8T   8% /sapmnt/data
tmpfs          tmpfs      76G     0   76G   0% /run/user/1001
tmpfs          tmpfs      76G     0   76G   0% /run/user/3050
tmpfs          tmpfs      76G     0   76G   0% /run/user/193933
tmpfs          tmpfs      76G     0   76G   0% /run/user/128758


[root@ttas4hpdb-dr ~]# df -hT
Filesystem     Type      Size  Used Avail Use% Mounted on
devtmpfs       devtmpfs  378G  8.0K  378G   1% /dev
tmpfs          tmpfs     566G     0  566G   0% /dev/shm
tmpfs          tmpfs     378G  3.0M  378G   1% /run
tmpfs          tmpfs     378G     0  378G   0% /sys/fs/cgroup
/dev/sdc3      ext4      147G  7.6G  132G   6% /
/dev/sdc1      ext2     1008M   88M  870M  10% /boot
/dev/sdc2      vfat      500M   26M  475M   6% /boot/efi
/dev/sdc4      xfs       150G  429M  150G   1% /usr/sap
/dev/sdb2      xfs       1.9T  152G  1.8T   8% /sapmnt/data
/dev/sdb1      xfs       1.1T   65G  981G   7% /sapmnt/shared
/dev/sdc5      xfs       593G   25G  569G   5% /sapmnt/log
tmpfs          tmpfs      76G     0   76G   0% /run/user/1001
tmpfs          tmpfs      76G     0   76G   0% /run/user/3050
tmpfs          tmpfs      76G     0   76G   0% /run/user/193933





 Master/Slave Set: master-slave-res [group-drbd] (unmanaged)
     Resource Group: group-drbd:0
         DRBD0-res      (ocf::linbit:drbd):     Slave ogypxn001-ha (unmanaged)
         DRBD1-res      (ocf::linbit:drbd):     Slave ogypxn001-ha (unmanaged)
         DRBD2-res      (ocf::linbit:drbd):     Slave ogypxn001-ha (unmanaged)
     Resource Group: group-drbd:1
         DRBD0-res      (ocf::linbit:drbd):     Master ogypxn001 (unmanaged)
         DRBD1-res      (ocf::linbit:drbd):     Master ogypxn001 (unmanaged)
         DRBD2-res      (ocf::linbit:drbd):     Master ogypxn001 (unmanaged)
 Resource Group: group_ora_pxn
     ip-ora-pxn (ocf::heartbeat:IPaddr2):       Started ogypxn001 (unmanaged)
     OraLSN     (ocf::heartbeat:oralsnr):       Started ogypxn001 (unmanaged)
     OraSrv     (ocf::heartbeat:oracle):        Started ogypxn001 (unmanaged)
     TSM_ORA    (systemd:dsmcad_ora):   Started ogypxn001 (unmanaged)
     TSM_ORAlog (systemd:dsmcad_oralog):        Started ogypxn001 (unmanaged)



drbd sync failure:
First on secondary node, then on primary node
Secondary node
drbdadm  disconnect r2; drbdadm secondary r2; drbdadm connect r2 --discard-my-data
On primary node
drbdadm  disconnect r2; drbdadm primary r2; drbdadm connect r2





CTASK0815551   CHG0297771  09-09-2023 09:30:00  10-09-2023 09:30:00
Affected VMs: ( Both VMs are to be moved ) 
bs4pe0073 		10.211.4.77		GfNJ686^6Cm$gRb
bs4pe0073-ha 	10.211.4.71		8Qr3MW!4*uwZG06

Change Steps: - KB0019470  Hana Cluster Maintenance Procedure (Manual and using Automation)

For Pacemaker 2.0 and Pacemaker 1.1 team can follow the below procedure

1.    crm resource maintenance <msl resource> ( put master slave resource to maintenance mode )
2.    crm resource maintenance <Ip resource> ( put Ip resource to maintenance mode )
3.    crm cluster stop ( stop the cluster )
4.    Perform the scheduled activity 
5.    crm cluster start ( start the cluster )
6.    crm resource refresh <clone resource> ( refresh clone resource )
7.    crm resource refresh <msl resource> ( refresh master slave resource )
8.    crm resource maintenance <msl resource> false ( remove master slave resource from maintenance mode )
9.    crm resource maintenance <ip resource> false ( remove ip resource from maintenance mode )
10.    Verify the cluster status




For Pacemaker 2.0 and Pacemaker 1.1 team can follow the below procedure

1.    crm resource maintenance <msl resource> ( put master slave resource to maintenance mode )
2.    crm resource maintenance <Ip resource> ( put Ip resource to maintenance mode )
3.    crm cluster stop ( stop the cluster )
4.    Perform the scheduled activity 
5.    crm cluster start ( start the cluster )
6.    crm resource refresh <clone resource> ( refresh clone resource )
7.    crm resource refresh <msl resource> ( refresh master slave resource )
8.    crm resource maintenance <msl resource> false ( remove master slave resource from maintenance mode )
9.    crm resource maintenance <ip resource> false ( remove ip resource from maintenance mode )
10.    Verify the cluster status




1.    crm resource maintenance msl_SAPHana_PRD_HDB00 ( put master slave resource to maintenance mode )
2.    crm resource maintenance rsc_ip_PRD_HDB00 ( put Ip resource to maintenance mode )
3.    crm cluster stop ( stop the cluster )
4.    Perform the scheduled activity 
5.    crm cluster start ( start the cluster )
6.    crm resource refresh cln_SAPHanaTopology_PRD_HDB00 ( refresh clone resource )
7.    crm resource refresh msl_SAPHana_PRD_HDB00 ( refresh master slave resource )
8.    crm resource maintenance msl_SAPHana_PRD_HDB00 false ( remove master slave resource from maintenance mode )
9.    crm resource maintenance rsc_ip_PRD_HDB00 false ( remove ip resource from maintenance mode )
10.    Verify the cluster status

Online: [ 
tsls4proddb 10.207.61.123
tsls4proddbh 10.207.61.113


Full List of Resources:
  * rsc_stonith-sbd     (stonith:external/sbd):  Started tsls4proddb
  * Clone Set: cln_SAPHanaTopology_PRD_HDB00 [rsc_SAPHanaTopology_PRD_HDB00]:
    * Started: [ tsls4proddb tsls4proddbh ]
  * Clone Set: msl_SAPHana_PRD_HDB00 [rsc_SAPHana_PRD_HDB00] (promotable):
    * Masters: [ tsls4proddb ]
    * Slaves: [ tsls4proddbh ]
  * rsc_ip_PRD_HDB00    (ocf::heartbeat:IPaddr2):        Started tsls4proddb
  * rsc_TSMTDP_PRD_HDB00        (systemd:dsmcad_hana):   Started tsls4proddb

Node Attributes:
  * Node: tsls4proddb:
    * hana_prd_clone_state              : PROMOTED
    * hana_prd_op_mode                  : logreplay
    * hana_prd_remoteHost               : tsls4proddbh
    * hana_prd_roles                    : 4:P:master1:master:worker:master
    * hana_prd_site                     : NODEA
    * hana_prd_sra                      : -
    * hana_prd_srah                     : -
    * hana_prd_srmode                   : sync
    * hana_prd_sync_state               : PRIM
    * hana_prd_version                  : 2.00.059.04
    * hana_prd_vhost                    : tsls4proddb
    * lpa_prd_lpt                       : 1694223722
    * master-rsc_SAPHana_PRD_HDB00      : 150
  * Node: tsls4proddbh:
    * hana_prd_clone_state              : DEMOTED
    * hana_prd_op_mode                  : logreplay
    * hana_prd_remoteHost               : tsls4proddb
    * hana_prd_roles                    : 4:S:master1:master:worker:master
    * hana_prd_site                     : NODEB
    * hana_prd_srah                     : -
    * hana_prd_srmode                   : sync
    * hana_prd_sync_state               : SOK
    * hana_prd_version                  : 2.00.059.04
    * hana_prd_vhost                    : tsls4proddbh
    * lpa_prd_lpt                       : 30
    * master-rsc_SAPHana_PRD_HDB00      : 100





glt_gltmiprddb01	no cluster

gltasqasdb01	no cluster

gltb4qasdb01	no cluster

gltmeqasdb01	no cluster

hfcde1hndb1		no cluster

hfchbdhndb1		no cluster

hfcsmphndb1ha	cluster is gud running secondary node






[11:56] Guruprasad Gulladi Ramachandra
     Server Type: Production                                                  *
*       Hostname: ogypxn001                                                   *
*         CFN IP: 10.25.8.206                                                 *
*         IFN IP: 10.139.8.223                                                *
*        SAP SID: PXN            

*******************HA************************
***************************************************************************
*    Server Type: Production                                                  *
*       Hostname: ogypxn001-ha                                                *
*         CFN IP: 10.25.8.157                                                 *
*         IFN IP: 10.139.8.60                                                 *
*        SAP SID: PXN                                                         *
**************************************


:s/"inode64,nobarrier"/"noatime,nodiratime,inode64,logbufs=8"/

op monitor interval=30s timeout=40s


Cluster Configuration
----------------------

vcenter host map                              : Unknown                                             [ FAILED ]
Vcenter shell_timeout                         : 60                                                  [ FAILED ]

Vcenter Login                                 : vsphere.local\ogycrmstnmgr                          [ FAILED ]

Vcenter filter.names                          : Unknown                                             [ FAILED ]

vcenter host map                              : Unknown                                             [ FAILED ]
Fencing shell_timeout                         : 60                                                  [ FAILED ]

Vcenter Login                                 : vsphere.local\ogycrmstnmgr                          [ FAILED ]

Vcenter filter.names                          : Unknown                                             [ FAILED ]



primitive vcenter-fencing-ogypxn001 stonith:fence_vmware_rest \
        params ipaddr=146.89.142.40 login="vsphere.local\ogycrmstnmgr" plug=ogypxn001 pcmk_host_map="hostname:ogypxn001" password_script="/usr/local/sbin/getpass.py -g ogycrmstnmgr" shell_timeout=60 ssl=1 ssl_insecure=1 login_timeout=60 filter="filter.names=ogypxn001" \
        op stop interval=0 on-fail=ignore timeout=60s \
        op start interval=0 on-fail=restart timeout=60s \
        op monitor enabled=false on-fail=restart timeout=60s interval=30
primitive vcenter-fencing-ogypxn001-ha stonith:fence_vmware_rest \
        params ipaddr=146.89.142.40 login="vsphere.local\ogycrmstnmgr" plug=ogypxn001-ha password_script="/usr/local/sbin/getpass.py -g ogycrmstnmgr" shell_timeout=60 ssl=1 ssl_insecure=1 login_timeout=60 filter="filter.names=ogypxn001-ha" \
        op stop interval=0 on-fail=ignore timeout=60s \
        op start interval=0 on-fail=restart timeout=60s \
        op monitor enabled=false on-fail=restart timeout=60s interval=30
		
		
		
primitive vcenter-fencing-node1 stonith:fence_vmware_rest \
        params ipaddr=vcenterip login="vsphere.local\crmstnmgr" filter="filter.names=vm_name" pcmk_host_map="hostname:vm_name" ssl=1 ssl_insecure=1 passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60 shell_timeout=600 \
        op stop interval=0 on-fail=ignore timeout=60s \
        op start interval=0 on-fail=ignore timeout=60s \
        op monitor enabled=false on-fail=restart timeout=60s interval=60 
        
primitive vcenter-fencing-node2 stonith:fence_vmware_rest \
        params ipaddr=vcenterip login="vsphere.local\crmstnmgr" filter="filter.names=vm_name" pcmk_host_map="hostname:vm_name" ssl=1 ssl_insecure=1 passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60 shell_timeout=600 \
        op stop interval=0 on-fail=ignore timeout=60s \
        op start interval=0 on-fail=ignore timeout=60s \
        op monitor enabled=false on-fail=restart timeout=60s interval=60 




DB	ogypxn001	10.139.8.223
DB HA	ogypxn001-ha	10.139.8.60

APP	ogypxn002	10.139.8.59
APP2	ogypxn003	10.139.8.32
APP3	ogypxn004	10.139.8.22
APP HA	ogypxn002-ha	10.139.8.184



3 - Install  the latest pacemaker-tools version from the directory   "/sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker" .  Should be executed on issue node. 
        follow below steps.

   # cd /sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker
   # rpm -Uvh pacemaker-tools-1.4-3.noarch.rpm

4 - Validate the RPM
 # rpm -qa |grep pacemaker-tools



DLTDEAHDB	CS14006519
10.143.69.186	delta-dal09-phana-1024-01.imzcloud.ibmammsap.local

indrayani818@icici


Patch Group () - hm8eccci0-dr	SUSE	10.26.1.157	Production	<Landscape> <SID> ()	vol034affb7dde852cd1	vol034301efffe397272
Patch Group () - hm8ecchdb0-dr	SUSE	10.26.1.179	Production	<Landscape> <SID> (DB) - HANA	vol0194eaac38a9f9924  vol07b72faf3f3afb9e3
Patch Group () - hm8eccap1-dr	SUSE	10.26.1.143	Production	<Landscape> <SID> ()		vol0c38ad2028cccb702 vol0f1bcd8aca61fc445


[root@br3qscmdb36 ~]# crm configure show |grep -i order
order ord_SAPHana_QCM_HDB36 Optional: cln_SAPHanaTopology_QCM_HDB36 msl_SAPHana_QCM_HDB36

order ord_SAPHana_HHA_HDB00 Optional: cln_SAPHanaTopology_HHA_HDB00 msl_SAPHana_HHA_HDB00

[root@br3qscmdb36 ~]# crm configure show |grep -i colocation
colocation col_saphana_ip_QCM_HDB36 2000: rsc_ip_QCM_HDB36:Started TSMTDP_QCM_HDB36:Started msl_SAPHana_QCM_HDB36:Master

colocation col_saphana_ip_HHA_HDB00 inf: rsc_ip_HHA_HDB00:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master



order ord_SAPHana_HHA_HDB00 Optional: cln_SAPHanaTopology_HHA_HDB00 msl_SAPHana_HHA_HDB00




colocation col_saphana_ip_QCM_HDB36 2000: rsc_ip_QCM_HDB36:Started TSMTDP_QCM_HDB36:Started msl_SAPHana_QCM_HDB36:Master


colocation col_saphana_ip_QCM_HDB36 inf: rsc_ip_QCM_HDB36:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master




expected sequence
colocation col_saphana_ip_HHA_HDB00 inf: rsc_ip_HHA_HDB00:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master

current is 
colocation col_saphana_ip_QCM_HDB36 2000: rsc_ip_QCM_HDB36:Started TSMTDP_QCM_HDB36:Started msl_SAPHana_QCM_HDB36:Master

colocation col_saphana_ip_QCM_HDB36 2000: rsc_ip_QCM_HDB36:Started TSMTDP_QCM_HDB36:Started msl_SAPHana_QCM_HDB36:Master




CHG0290379    Cenovus Energy -- HOE  Linux    9/16/2023    09:00
CHG0298701 Cenovus Energy -- HOE Linux 9/16/2023 09:00







Step 1:

Queue Name : NPI64B6A0

Printer IP : 135.116.33.115

Printer Model : HP Laserjet M507DN

 

Step 2: 

Add following entry to /etc/hosts files of app servers (SHM and PRD)

 

135.116.33.115             NPI64B6A0

 

Step 3:

Schedule Periodic restart of Queue name in crontab


SAPAPP15	10.207.61.37
SAPAPP18	10.207.61.70
SAPAPP19	10.207.61.215
SAPAPP20	10.207.61.195
SAPAPP21	10.207.61.80
SAPAPP23	10.207.61.130
SAPAPP26	10.207.61.48
			SAPAPP27	10.207.61.47
SAPAPP28	10.207.61.58
SAPAPP29	10.207.61.85


SAPAPP30	10.207.61.95
SAPAPP31	10.207.61.84
SAPAPP31-HA	10.207.61.222
SAPAPP32	10.207.61.46
SAPAPP33	10.207.61.235
SAPAPP34	10.207.61.230
SAPAPP35	10.207.61.39
SAPAPP36	10.207.61.197
SAPAPP37	10.207.61.156


SAPAPP38	10.207.61.134
SAPAPP39	10.207.61.167
SAPAPP40	10.207.61.149
SAPAPP41	10.207.61.151
SAPAPP42	10.207.61.242
SAPAPP43	10.207.61.152
tgcs4hmap3	10.207.63.101



lpadmin -p NPI64B6A0 -v lpd://135.116.33.115 -E


lpstat -t |grep -i NPI64B6A0


#restart of cups service daily at 0000 Hrs IST
0 0 * * * /bin/systemctl restart cups.service



 985  2023-09-15 11:08:20 lpstat -t |grep -i NPI64B6A0
  986  2023-09-15 11:08:36 lpadmin -p NPI64B6A0 -v lpd://135.116.33.115 -E
  987  2023-09-15 11:08:44 lpstat -t |grep -i NPI64B6A0
  988  2023-09-15 11:08:56 cupsenable NPI64B6A0
  989  2023-09-15 11:09:21 cupsaccept NPI64B6A0
  990  2023-09-15 11:12:05 vi /etc/hosts
  991  2023-09-15 11:16:42 echo "135.116.33.115             NPI64B6A0"  >>/etc/hosts
  992  2023-09-15 11:16:53 cat /etc/hosts |grep -i NPI64B6A0
  993  2023-09-15 11:17:21 crontab -l




CHG0285376	16-09-2023 06:30:00		16-09-2023 15:30:00

This 09/15/2023 - 20:00 - NIX  remediation is for the following CIs:

Patch Group () - ia1sp1db-dr	SUSE	10.199.15.231	Production	<SID> - SAP <Landscape> (DB)
	Patch Group () - ia1sp1db	SUSE	10.133.15.116	Production	<SID> - SAP <Landscape> (DB)
	Patch Group () - ia1sp1db-ha	SUSE	10.133.15.120	Production	<SID> - SAP <Landscape> (DB)
	Patch Group () - ia1bp1db	SUSE	10.133.15.121	Production	<SID> - SAP <Landscape> (DB)
	Patch Group () - ia1bp1db-ha	SUSE	10.133.15.117	Production	<SID> - SAP <Landscape> (DB)

Patch Group (2.3) - ia1bpcprdapp	Redhat	10.133.15.22	Production	BP1 - SAP  (App) - NA
Patch Group (2.2) - ia1s4hprdapp	Redhat	10.133.15.13	Production	SP1 - SAP  (App) - NA ds is latest rest need update

ds agent is old needs update
root pw revert as per 1password
systemctl --type=service |egrep -e "cups.service|vsftpd.service|postfix.service|dnsmasq.service"

Downupgrade from 8.6 to 8.2:-
===========================	
1. Verify that the current OS version is Red Hat Enterprise Linux 8:
# cat /etc/redhat-release
Red Hat Enterprise Linux release 8.6 (Ootpa)

2. CMS offering is RHEL8.2 so we need to down grade it from RHEL8.4 to RHEL8.2.
Set subscription manager release to RHEL8.2
# subscription-manager release --set=8.2

 Downgrade redhat-release and kernel
# yum downgrade redhat-release

 Install Supported level of Kernel package for RHEL8.2 kernel which is 4.18.0-193.
# yum list kernel-4.18.0-193*
Available Packages
kernel.x86_64      4.18.0-193.28.1.el8_2   @rhel-8-for-x86_64-baseos-rpms

 # yum install kernel-modules-4.18.0-193.28.1.el8_2.x86_64 kernel-devel-4.18.0-193.28.1.el8_2.x86_64 kernel-tools-4.18.0-193.28.1.el8_2.x86_64 kernel-headers-4.18.0-193.28.1.el8_2.x86_64 kernel-modules-extra-4.18.0-193.28.1.el8_2.x86_64 kernel-core-4.18.0-193.28.1.el8_2.x86_64 kernel-tools-libs-4.18.0-193.28.1.el8_2.x86_64 kernel-4.18.0-193.28.1.el8_2.x86_64

 
3. Reboot system and make sure system is booting with rhel 8.2.


[root@IA1S4HPRDAPP ds_agent]$ date
Sat Sep 16 04:54:49 CEST 2023
[root@IA1S4HPRDAPP ds_agent]$ uname -a
Linux IA1S4HPRDAPP 4.18.0-193.28.1.el8_2.x86_64 #1 SMP Fri Oct 16 13:38:49 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
[root@IA1S4HPRDAPP ds_agent]$ cat /etc/*release
LSB_VERSION=core-4.1-amd64:core-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch
NAME="Red Hat Enterprise Linux"
VERSION="8.2 (Ootpa)"
ID="rhel"
ID_LIKE="fedora"
VERSION_ID="8.2"
PLATFORM_ID="platform:el8"
PRETTY_NAME="Red Hat Enterprise Linux 8.2 (Ootpa)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:redhat:enterprise_linux:8.2:GA"
HOME_URL="https://www.redhat.com/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"

REDHAT_BUGZILLA_PRODUCT="Red Hat Enterprise Linux 8"
REDHAT_BUGZILLA_PRODUCT_VERSION=8.2
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="8.2"
Red Hat Enterprise Linux release 8.2 (Ootpa)
Red Hat Enterprise Linux release 8.2 (Ootpa)
[root@IA1S4HPRDAPP ds_agent]$ rpm -qa |grep -i ds_agent
ds_agent-20.0.0-7719.el8.x86_64



[root@IA1BPCPRDAPP ds_agent]$ date
Sat Sep 16 04:55:53 CEST 2023
[root@IA1BPCPRDAPP ds_agent]$ uname -a
Linux IA1BPCPRDAPP.imzcloud.ibmammsap.local 4.18.0-193.28.1.el8_2.x86_64 #1 SMP Fri Oct 16 13:38:49 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux
[root@IA1BPCPRDAPP ds_agent]$ cat /etc/*release
LSB_VERSION=core-4.1-amd64:core-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch
NAME="Red Hat Enterprise Linux"
VERSION="8.2 (Ootpa)"
ID="rhel"
ID_LIKE="fedora"
VERSION_ID="8.2"
PLATFORM_ID="platform:el8"
PRETTY_NAME="Red Hat Enterprise Linux 8.2 (Ootpa)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:redhat:enterprise_linux:8.2:GA"
HOME_URL="https://www.redhat.com/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"

REDHAT_BUGZILLA_PRODUCT="Red Hat Enterprise Linux 8"
REDHAT_BUGZILLA_PRODUCT_VERSION=8.2
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="8.2"
Red Hat Enterprise Linux release 8.2 (Ootpa)
Red Hat Enterprise Linux release 8.2 (Ootpa)
[root@IA1BPCPRDAPP ds_agent]$ rpm -qa |grep -i ds_agent
ds_agent-20.0.0-7719.el8.x86_64

systemctl list-unit-files -t service


nfs-blkmap.service                      disabled
nfs-convert.service                     disabled
nfs-idmapd.service                      static
nfs-mountd.service                      static
nfs-server.service                      enabled
nfs-utils.service                       static
nfsdcld.service                         static
nftables.service                        disabled




SAPAPP15 10.207.61.37

SAPAPP18 10.207.61.70

SAPAPP19 10.207.61.215

SAPAPP20 10.207.61.195

SAPAPP21 10.207.61.80

SAPAPP23 10.207.61.130

SAPAPP26 10.207.61.48

SAPAPP27 10.207.61.47

SAPAPP28 10.207.61.58

SAPAPP29 10.207.61.85



SAPAPP30 10.207.61.95

SAPAPP31 10.207.61.84

SAPAPP31-HA 10.207.61.222

SAPAPP32 10.207.61.46

SAPAPP33 10.207.61.235

SAPAPP34 10.207.61.230

SAPAPP35 10.207.61.39

SAPAPP36 10.207.61.197

SAPAPP37 10.207.61.156

SAPAPP38 10.207.61.134

SAPAPP39 10.207.61.167

SAPAPP40 10.207.61.149

SAPAPP41 10.207.61.151

SAPAPP42 10.207.61.242

SAPAPP43 10.207.61.152

tgcs4hmap3 10.207.63.101

[07:32] Rajat Sinha

cronjob for restart at midnight



NPI64B6A0	135.116.33.115
NPI450E44	135.116.33.109
NPI037754	135.116.33.149


lpadmin -p NPI64B6A0 -v lpd://135.116.33.115 -E;lpadmin -p NPI450E44 -v lpd://135.116.33.109 -E;lpadmin -p NPI037754 -v lpd://135.116.33.149 -E

cupsenable NPI64B6A0;cupsenable NPI450E44;cupsenable NPI037754
cupsaccept NPI64B6A0;cupsaccept NPI450E44;cupsaccept NPI037754


echo "135.116.33.115             NPI64B6A0"  >>/etc/hosts;echo "135.116.33.109             NPI450E44"  >>/etc/hosts;echo "135.116.33.149             NPI037754"  >>/etc/hosts




FAILED  - /ixos/adlib is not mounted
[root@zffsappdb006 ~]# df -hT |grep -i ixos
/dev/mapper/e02appvg-ixos_exchange_lv                      ext4       25G  2.8G   21G  13% /ixos/exchange
salfde-emc3.ad.trw.com:/qc_ixos_exchange/ixos_exchange/E02 nfs       4.7T  3.7T 1002G  79% /data/ixos/exchange/E02
alfa90100.ad.trw.com:/c90100_95/E02                        nfs       6.0T  3.9T  2.1T  65% /ixos/E02
[root@zffsappdb006 ~]# cat /etc/fstab |grep -i /ixos/adlib
salfde-emc2.ad.trw.com:/qc_ixos_adlib/ixos_adlib        /ixos/adlib     nfs defaults,nfsvers=3,intr,soft 0 0



    
S4H QA - tdpqcs4qapp1		10.209.3.14		10.32.0.32
POQ - tdpqpoqdbapp			10.209.3.16		10.32.0.37	

/INTERFACE/BY/SCM/OUTBOUND/SAPDATA
/INTERFACE/BY/INBOUND/BYAPPS
/INTERFACE/BY/SCM/ARCHDATA



S4H DEV --> tdpdcs4dapp1    10.209.3.59		10.32.0.57
POD ---> tdpdpoddbapp		10.209.3.12		10.32.0.11

[root@tdpdcs4dapp1 ~]# df -hT /INTERFACE/BY/SCM/OUTBOUND/SAPDATA
Filesystem                                                Type  Size  Used Avail Use% Mounted on
/dev/mapper/s4dappvg-INTERFACE_BY_SCM_OUTBOUND_SAPDATA_LV xfs  1014M   34M  981M   4% /INTERFACE/BY/SCM/OUTBOUND/SAPDATA
[root@tdpdcs4dapp1 ~]# df -hT /INTERFACE/BY/SCM/ARCHDATA
Filesystem                                     Type  Size  Used Avail Use% Mounted on
/dev/mapper/s4dappvg-INTERFACE_BY_SCM_ARCHDATA xfs  1014M   37M  978M   4% /INTERFACE/BY/SCM/ARCHDATA
[root@tdpdcs4dapp1 ~]# df -hT /INTERFACE/BY/INBOUND/BYAPPS
Filesystem                                       Type  Size  Used Avail Use% Mounted on
/dev/mapper/s4dappvg-INTERFACE_BY_INBOUND_BYAPPS xfs  1014M   34M  981M   4% /INTERFACE/BY/INBOUND/BYAPPS



MqpzfURzARlD4xt    custapp



APP:
vhsmpcs1    172.31.252.5
vhsmpcs2    172.31.252.23

 

vhsmpap1    172.31.252.7
vhsmpap2    172.31.252.20
vhsmpap3    172.31.252.33






a0810v1wappw115		10.108.35.50
a0810v1wappw117		10.108.32.194
a0810v1wappw118		10.108.32.195
a0810v1wdbsw120		10.108.35.53




10.152.66.22     TSLJA08282


SAPAPP15 10.207.61.37
SAPAPP18 10.207.61.70
SAPAPP19 10.207.61.215
SAPAPP20 10.207.61.195
SAPAPP21 10.207.61.80
SAPAPP23 10.207.61.130
SAPAPP26 10.207.61.48
SAPAPP27 10.207.61.47
SAPAPP28 10.207.61.58

SAPAPP29 10.207.61.85
SAPAPP30 10.207.61.95
SAPAPP31 10.207.61.84
SAPAPP31-HA 10.207.61.222
SAPAPP32 10.207.61.46
SAPAPP33 10.207.61.235
SAPAPP34 10.207.61.230
SAPAPP35 10.207.61.39
SAPAPP36 10.207.61.197
SAPAPP37 10.207.61.156


SAPAPP38 10.207.61.134
SAPAPP39 10.207.61.167
SAPAPP40 10.207.61.149
SAPAPP41 10.207.61.151
SAPAPP42 10.207.61.242
SAPAPP43 10.207.61.152
tgcs4hmap3 10.207.63.101




985  2023-09-15 11:08:20 lpstat -t |grep -i TSLJA08282
  986  2023-09-15 11:08:36 lpadmin -p TSLJA08282 -v lpd://10.152.66.22 -E
  987  2023-09-15 11:08:44 lpstat -t |grep -i TSLJA08282
  988  2023-09-15 11:08:56 cupsenable TSLJA08282
  989  2023-09-15 11:09:21 cupsaccept TSLJA08282
   991  2023-09-15 11:16:42 echo "10.152.66.22             TSLJA08282"  >>/etc/hosts
  992  2023-09-15 11:16:53 cat /etc/hosts |grep -i TSLJA08282




meetings
KT or help to junniots
SME approvals
adhoc requests




[root@penap15sl ~]$ stat /etc/ssh/sshd_config
  File: `/etc/ssh/sshd_config'
  Size: 3080            Blocks: 8          IO Block: 4096   regular file
Device: fd00h/64768d    Inode: 1050175     Links: 1
Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2023-09-25 12:01:56.258671030 -0700
Modify: 2023-09-25 12:01:56.244671054 -0700
Change: 2023-09-25 12:01:56.248671047 -0700
[root@penap15sl ~]$ date
Thu Sep 28 20:02:16 PDT 2023

[root@penap15sl ~]$ uptime
 20:02:32 up 4 days, 22:09,  2 users,  load average: 0.12, 0.13, 0.16

Patched at Tue 19 Sep 2023 12:41:31 PM PDT


/home/ibmlakasapu/


584  2023-09-25 11:35:08 mv AM2PENA_Plan202309240400180000065619445 /usr2/P15/CL100/AM/In/
  585  2023-09-25 11:35:24 mv AM2PENA_Plan202309250400180000080760274 /usr2/P15/CL100/AM/In/
  586  2023-09-25 11:34:30 cd /usr2/P15
  587  2023-09-25 11:34:32 ls -lrt
  588  2023-09-25 11:34:42 cd CL100/AM/In
  589  2023-09-25 11:34:44 ls -lrt
  590  2023-09-25 11:34:46 pwd
  591  2023-09-25 11:35:28 ls -lrt
  592  2023-09-25 11:35:44 chown p15adm:sapsys *
  593  2023-09-25 11:35:46 ls -lrt
  594  2023-09-25 11:36:27 chmod 755 *

[root@penap15sl log]$ diff /etc/ssh/sshd_config /etc/ssh/sshd_config.bck.092523
107,110d106
<
< # Jim Hardy 25 Sep 2023 CS14069510
< Subsystem sftp internal-sftp
<
[root@penap15sl log]$ diff  /etc/ssh/sshd_config.20230925-CS14069510
diff: missing operand after `/etc/ssh/sshd_config.20230925-CS14069510'
diff: Try `diff --help' for more information.
[root@penap15sl log]$ diff /etc/ssh/sshd_config /etc/ssh/sshd_config.20230925-CS14069510
107,110d106
<
< # Jim Hardy 25 Sep 2023 CS14069510
< Subsystem sftp internal-sftp
<

[root@penap15sl ~]$ [root@penap15sl 05]$ rpm -qa --last
redhat-release-server-6Server-6.10.0.13.el6_10.10.x86_64 Sat 23 Sep 2023 09:41:37 PM PDT
openssh-clients-5.3p1-125.el6_10.x86_64       Sat 23 Sep 2023 09:41:37 PM PDT
openssh-askpass-5.3p1-125.el6_10.x86_64       Sat 23 Sep 2023 09:41:37 PM PDT
openssh-server-5.3p1-125.el6_10.x86_64        Sat 23 Sep 2023 09:41:36 PM PDT
openssh-5.3p1-125.el6_10.x86_64               Sat 23 Sep 2023 09:41:36 PM PDT
unix2dos-2.2-35.el6.x86_64                    Tue 19 Sep 2023 12:41:31 PM PDT


24 Sept Saurabh Shrivastava  24-09-2023 13:30:00 24-09-2023 17:30:00
 Konduru Ratna Sai Jahnavi and Mallikarjun  24-09-2023 09:30:00 24-09-2023 13:30:00      




Patch Group (1) - ahecssap01	Redhat	10.4.10.11	Development	PYS - SAP  (App) - Sybase   -There are no dsmcad processes running
Patch Group (2) - ahpodsap01 Redhat 10.4.10.24 Development XID - SAP (App/DB) - Sybase	Gateway 10.100.2.1 is not reachable. Ping was not successful


/usr/bin/python /usr/local/sap/scripts/os_check_and_fix_v1.0.py



ogydbj017.imzcloud.ibmammsap.local --- 10.139.9.38
ogydbp037.imzcloud.ibmammsap.local --- 10.139.9.77
ogydbw015.imzcloud.ibmammsap.local --- 10.139.9.40
ogyddi026.imzcloud.ibmammsap.local --- 10.139.9.60
ogydgl006.imzcloud.ibmammsap.local --- 10.139.9.33
ogydgp025.imzcloud.ibmammsap.local --- 10.139.9.59
ogydgr035.imzcloud.ibmammsap.local --- 10.139.9.35
ogydpm032.imzcloud.ibmammsap.local --- 10.139.9.36
ogypbj011.imzcloud.ibmammsap.local --- 10.139.8.25
ogypbp040.imzcloud.ibmammsap.local --- 10.139.8.44
ogypbp041.imzcloud.ibmammsap.local --- 10.139.8.52
ogypbw008.imzcloud.ibmammsap.local --- 10.139.8.36
ogypbw009.imzcloud.ibmammsap.local --- 10.139.8.21
ogypgr033.imzcloud.ibmammsap.local --- 10.139.8.19
ogyppm030.imzcloud.ibmammsap.local --- 10.139.8.24
ogypxn002-ha.imzcloud.ibmammsap.local --- 10.139.8.184
ogypxn004.imzcloud.ibmammsap.local --- 10.139.8.22



Action plan needed, *** please take logs / screen copies that will help to troubleshoot further if needed ****

1- Kill  ALL the processes that are stuck (the PID number might have changed, search by process name):

        "root       7007   6979  0 Mar05 ?        00:00:00 /bin/sh /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT",
        "root       7185   7007  0 Mar05 ?        00:00:00 /bin/sh /var/opt/ansible/GTS/ILMT/automation/run_sw.sh",

2- Check whether the inventory files are outdated, if that is the case please delete them (we will generate new ones):

/var/opt/ansible/GTS/ILMT/work/slmtag_scan.xml
/var/opt/ansible/GTS/ILMT/work/tlm_hw_last.xml
/var/opt/ansible/GTS/CIT/work/*_hardware.xml
/var/opt/ansible/GTS/CIT/work/*_isotag.xml

3- Run new scans manually and wait till they execute successfully, check that they are not getting stuck again: or generating errors:
/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh
/var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT

4- Check that the scan inventory files are up to date - from current day - see files in point 2.

5- Package the inventory files into one bundle file, run command:
/var/opt/ansible/GTS/ILMT/automation/pack_results.sh

6- Check in folder /var/opt/ansible/GTS/ILMT/output that a bundle file has been generated, should show the current date.

Once this is done, i will check with Ansible team that they are running the needed fetch job.

If something goes wrong, please zip and send those folders:
/var/opt/ansible/GTS/ILMT/logs
/var/opt/ansible/GTS/ILMT/work
/var/opt/ansible/GTS/ILMT/output

Check for org name in lower case

/var/opt/ansible/GTS/ILMT/config/computer_properties.yml

/var/opt/ansible/GTS/CIT/work/computer_properties.yml
 
 
 
4n(5LYMm!PAAe37



99900471  Jitendra
99948132  Sandeep
99900472   salman



10.207.72.255

route add -net 10.170.72.0 netmask 255.255.255.0 gw 10.170.72.255

CHG0298218 || CST/CDT - 10/18/2023 - 20:00 - NIX - IA1 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1
CHG0298212 ||    CST/CDT - 10/20/2023 - 20:00 - NIX - IA2 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1.


CS14105869   TTA


CHG0300215  SM9 



they should go to partner.suse.com & click on â€œBecome a partner / Applyâ€.

 

They will be able to join an existing account & this will auto-approve their application.


, please share the current OS patch Kernel version
ttas4hanadapp		10.207.62.146		
ttas4hanaqdb		10.207.63.174
ttas4hpdb			10.207.61.161




Fri 10/6/2023 8:30 PM - 9:30 PM
Dear all, 

As per our latest report we noticed that all of you have some non-compliant weeks and, we noticed that they used to claim in our pooled WBS Codes. As per our last communication those codes were going to be closed on September 30th to start with our new claim structure on October 1st. To facilitate your claim, we are going to enable the WBS on one specific hour. We request your support to please complete your pending entries on that time that will be on Fri 10/6/2023 8:30 PM - 9:30 PM IST.



  

My HO to OS Linux Team. Thanks in advance.


CS14112882

CS14112901

CS14112884

CS14112887

CS14112890	BS4PX0080

CS14112897

CS14112900


CHG0299627    Breadtalk Singapore -- BT1    Linux    10/18/2023    7:00
CHG0299629    Breadtalk Singapore -- BT1    Linux    10/18/2023    7:00

CHG0301188 CST/CDT - 10/17/2023 - 20:00 - NIX - GKN - PATCH - HC - Y2023- SAPB2

CHG0301324	prk

CHG0301325



CHG0298206   14-10-2023 06:30:00   14-10-2023 14:30:00
CST/CDT - 10/13/2023 - 20:00 - NIX - IA2 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1

With reference to the change CHG0298206,the versions for  Red hat servers are locked to RHEL 8.6,the current version is RHEL 8.2.

After OS patches, all Redhat servers should go to RHEL 8.6.

Pls validate Vmlogging, kdump and ds_agent, if you found old version of ds_agent pls install new version(ds_agent-20.0.0-7119.el8).
				  
use kdump helper script to configure kdump on RedHat servers for this change

FRA	Patch Group () - ia2sp5db-dr	SUSE	10.199.15.221	Production	SP5 - SAP  (DB) - HANA	
LON02	Patch Group () - ia2sp5db-ha	SUSE	10.133.15.114	Production	SP5 - SAP  (DB) - HANA	
LON02	Patch Group () - ia2sp5db	SUSE		10.133.15.112	Production	SP5 - SAP  (DB) - HANA	
LON02	Patch Group (-) - ia2s4hprdapp1	Redhat	10.133.15.59	Production	SP5 - SAP  (App) - NA	
LON02	Patch Group (-) - ia2s4hprdapp3	Redhat	10.133.15.87	Production	SP5 - SAP  (App) - NA	
LON02	Patch Group (-) - ia2s4hprdapp2	Redhat	10.133.15.40	Production	SP5 - SAP  (App) - NA	
LON02	Patch Group (-) - ia2s4hprdapp4	Redhat	10.133.15.42	Production	SP5 - SAP  (App) - NA	


pre snap  https://samuel.sap.adai.kyndryl.com/IA2/buildInformation?id=6529ec1a60030f3322f71253&name=Overview

root pw reset done to default, remember to revert it back
ds agent update
kdump		/sds/sap/MSD_Software/SAP_Automation/Scripts/kdump/KdumpEnablement.py
vmlogging
nmon
sar
snapshot
dsmc -i


To enter maintenance mode :

crm maintenance on
crm resource maintenance msl_SAPHana_QCM_HDB36
crm resource maintenance rsc_ip_QCM_HDB36

To take out of maintenance and make it managed:

crm maintenance off
crm resource refresh cln_SAPHanaTopology_QCM_HDB36
crm resource refresh msl_SAPHana_QCM_HDB36
crm resource maintenance msl_SAPHana_QCM_HDB36 false
crm resource maintenance rsc_ip_QCM_HDB36 false



su - sp5adm

sapcontrol -nr 00 â€“function StopSystem

sapcontrol -nr 00 â€“function GetProcessList

sapcontrol -nr 00 â€“function StopService

cleanipc 00 remove

ps -ef | grep -i sp5adm



nmon upgrade, if you found nmon is older verion(el6), pls uninstall and install new version.
#rpm -ev rpm_name
#cd /sds/sap/MSD_Software/SAP_Automation/Scripts/linux_utility/nmon
#rpm -ivh rpm_name  ==> you can see multiple rpm's, select OS verions based rpm's (we have different rpm's for SUSE and RedHat)



[root@ia2sp5db ds_agent]# ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.driverOffline: true
Component.AM.mode: driver-offline
AgentStatus.lastAgentToManagerSession: 1697261498



[root@ia2sp5db-ha ds_agent]# ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.driverOffline: true
Component.AM.mode: driver-offline
AgentStatus.lastAgentToManagerSession: 1697261489


[root@ia2sp5db-dr ds_agent]# ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.mode: not-capable
AgentStatus.lastAgentToManagerSession: 1697260478

[root@ia2sp5db-ha ~]# systemctl status ds_agent
â— ds_agent.service - Trend Micro Deep Security Agent
   Loaded: loaded (/usr/lib/systemd/system/ds_agent.service; enabled; vendor preset: disabled)
   Active: active (running) since Sat 2023-10-14 05:52:02 UTC; 21min ago
 Main PID: 4162 (ds_agent)
    Tasks: 64 (limit: 1024)
   CGroup: /system.slice/ds_agent.service
           â”œâ”€4162 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
           â”œâ”€4164 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
           â”œâ”€5983 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R
           â””â”€6006 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R

Oct 14 05:52:02 ia2sp5db-ha systemd[1]: Starting Trend Micro Deep Security Agent...
Oct 14 05:52:02 ia2sp5db-ha ds_agent.init[3940]: Starting ds_agent: ..done
Oct 14 05:52:02 ia2sp5db-ha systemd[1]: Started Trend Micro Deep Security Agent.
Oct 14 05:52:05 ia2sp5db-ha ds_am.init[6169]: The ds_am module is lack of KernelSupport package for kernel 5.3.18-150200.24.163-default
Oct 14 05:52:06 ia2sp5db-ha ds_am.init[6387]: The ds_am module is lack of KernelSupport package for kernel 5.3.18-150200.24.163-default


[root@ia2sp5db ~]# systemctl status ds_agent
â— ds_agent.service - Trend Micro Deep Security Agent
   Loaded: loaded (/usr/lib/systemd/system/ds_agent.service; enabled; vendor preset: disabled)
   Active: active (running) since Sat 2023-10-14 05:52:02 UTC; 21min ago
 Main PID: 4186 (ds_agent)
    Tasks: 64 (limit: 1024)
   CGroup: /system.slice/ds_agent.service
           â”œâ”€4186 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
           â”œâ”€4187 /opt/ds_agent/ds_agent -w /var/opt/ds_agent -b -i -e /opt/ds_agent/ext
           â”œâ”€6021 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R
           â””â”€6044 /opt/ds_agent/ds_am -g ../diag -v 5 -d /var/opt/ds_agent/am -P 1 -R

Oct 14 05:52:02 ia2sp5db systemd[1]: Starting Trend Micro Deep Security Agent...
Oct 14 05:52:02 ia2sp5db ds_agent.init[3971]: Starting ds_agent: ..done
Oct 14 05:52:02 ia2sp5db systemd[1]: Started Trend Micro Deep Security Agent.
Oct 14 05:52:05 ia2sp5db ds_am.init[6199]: The ds_am module is lack of KernelSupport package for kernel 5.3.18-150200.24.163-default
Oct 14 05:52:06 ia2sp5db ds_am.init[6415]: The ds_am module is lack of KernelSupport package for kernel 5.3.18-150200.24.163-default


Ansible remediation is changing the DB log permission, so DB won't start.
*/10 * * * * find /var/log/* -type f -exec chmod g-wx,o-rwx '{}' + -o -type d -not -path /var/log/hist -not -path /var/log/sssd -exec chmod g-wx,o-rwx '{}' +

comment the above form hana servers and change the permissions if changed
We have to set the permission after HANA DB  server remediation in case any issue at DB start.

[6/29 1:57 PM] Sreejesh U

# chmod 755 /var/log/HDBHA/
# chmod 755 /var/log/HDBHA/state_monitor/
# chmod 755 /var/log/HDBHA/state_monitor/state_monitor.log 


check cronjob that changes the var/log permissions for hana



 After Samuel HC remediation, do manual remediation
 After Samuel HC remediation, do manual remediation

For HC manual remediation ( after SAMUEL) 

Here are the script details:

Script location                  : /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix

Execution procedure      : python /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix/hc_remediation_linux_v6.py




HC for RHEL https://samuel.sap.adai.kyndryl.com/IA2/buildInformation?id=652a2f3b831f224677b2a5a7&name=Overview

HC for SUSE https://samuel.sap.adai.kyndryl.com/IA2/buildInformation?id=652a2fc10ec00317c268c4e7&name=Overview



Your FASTAG Number:34161FA820328614069B37C0Vehicle No:MA1YU2WTUK6E18883RC Number: Chasis Number:MA1YU2WTUK6E18883Engine Number:WTK4D21963Vehicle Class:Car / Jeep / VanCommercial Vehicle:NOPlace of Registration:PUNE




CHG0301602 to add route to 146.89.175.69 on zffdappdb003   100.126.67.26




tgcs4hdhdb - 10.207.62.44

removed 10.136.139.10 via 10.170.62.1 dev vlan1 from tgcs4hdhdb

[root@tgcs4hdhdb ~]# history |grep -i route
  383  2023-05-09 14:03:36 ip route show
  385  2023-05-09 14:12:17 ip route add 10.136.139.10/28 via 10.170.62.1
  390  2023-05-09 14:16:11 ip route show
  391  2023-05-09 14:22:54 ip route add -host 10.136.139.10 gw 10.170.62.1
  392  2023-05-09 14:23:11 route add -host 10.136.139.10 gw 10.170.62.1
  412  2023-05-09 18:09:28 route add -host 10.136.139.10 gw 10.170.62.1
  414  2023-05-09 18:10:07 route del -host 10.136.139.10 gw 10.170.62.1
  418  2023-05-09 18:12:04 more /etc/sysconfig/network/ifroute-vlan0
  419  2023-05-09 18:12:26 route add -host 10.136.139.10 gw 10.170.62.1
  421  2023-05-09 18:13:07 vi /etc/sysconfig/network/ifroute-vlan1
  422  2023-05-09 18:13:55 more /etc/sysconfig/network/ifroute-vlan1
  423  2023-05-09 18:14:11 vi /etc/sysconfig/network/ifroute-vlan1
  424  2023-05-09 18:14:38 more /etc/sysconfig/network/ifroute-vlan1




aprscmdev.imzcloud.ibmammsap.local --- 10.135.196.6
aprjumpserver.imzcloud.ibmammsap.local --- 10.135.197.61







custapp
uk&3E=Nz;p{oD^G+

CS14158821

Please create custapp user on the below servers and assign the same permissions to that as given in this server - TTAS4HANADAPP(reference)
[root@ttas4hanadapp ~]# id custapp
uid=54721(custapp) gid=100(users) groups=3050(sapsys),100(users)

TTANINLGRCDEV	10.207.62.33		
TTANINLGRCPRD	10.207.61.98
tgcs4hdhdb
tgcs4hdapp		10.207.62.46
tgcs4hqhdb		10.207.63.30
tgcs4hqapp			10.207.63.117

tgcs4hphdb		10.207.61.248
tgcs4hphdb-ha	10.207.61.181
tgcs4hpapp			10.207.61.132
tgcs4hpapp-ha		10.207.61.137
tgcpoddbapp		10.207.62.109
tgcpoqdbapp			10.207.63.47
tgcpopdbapp		10.207.61.254
tgcwddapp		10.207.62.101
tgcwdpapp		10.207.61.139


useradd custapp;id custapp;passwd custapp
usermod -a -G sapsys custapp
id custapp




CS14158900
Need the current  OS kernel patch version applied  for the listed servers.

sapapp21 		10.207.61.80
sapapp23 		10.207.61.130
sapapp31			10.207.61.84
sapapp31-ha 	10.207.61.222
tsls4proddb		10.207.61.123
tsls4proddbh	10.207.61.113
ttagrcprd		10.207.61.82



CHG0301015 CST/CDT - 10/24/2023 - 20:00 - NIX - GLT - PATCH - HC - Y2023- SAPB2
CHG0301016 CST/CDT - 10/24/2023 - 20:00 - NIX - GLT - PATCH - HC - Y2023- SAPB2


 128 GB each
tsls4hmckap3	10.207.63.214		TTACHE01CLPOOL1POD1DSP589
 
tsls4hmckap4	10.207.63.140		TTACHE01CLPOOL1POD1DSP589
 
tsls4hmckap5	10.207.63.52		TTACHE01CLPOOL1POD1DSP589
 
tsls4hmckap6	10.207.63.91		TTACHE01CLPOOL1POD1DSP589
 
tsls4hmckap7	10.207.63.114



CHG0298720	CST/CDT - 10/21/2023 - 20:00 - NIX - FBS - PATCH - HC - VULN - Y2023- SAPB1,SAPD1
CHG0298719	CST/CDT - 10/21/2023 - 20:00 - NIX - FBS - PATCH - HC - VULN - Y2023- SAPB1,SAPD1
 
 
 
 â€¢	We need to install the AWS CLI on the source system using the below method and perform the validation 
o	Install or update the latest version of the AWS CLI - AWS Command Line Interface (amazon.com)
https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
o	Please check from source server if  the s3 cli is successful 
ï‚§	$aws s3 ls
ï‚§	$aws s3 ls
 
â€¢	Validate the target bucket is accessible from above cli tool using below commands! The source port is random and destination port to be 443. 
o	aws s3 ls s3://hrcdevbucket/Development
o	https://hrcdevbucket.s3.ap-southeast-1.amazonaws.com/Development/
 
â€¢	Once done please let me know the assigned engineer details to share the credentials to upload the data. We want the data to be uploaded by each file system.



CGB/00035-0002.L.07
CGB/00032-0003.L.07


CHG0301271 change approval


[batusr@penap15sl ~]$ sftp sapusr@10.137.10.100
Connecting to 10.137.10.100...
sapusr@10.137.10.100's password:
[batusr@penap15sl ~]$
 
test after removing entries in *.pub file
[batusr@penap15sl .ssh]$ sftp sapusr@10.137.10.100
Connecting to 10.137.10.100...



CHG0300363	CST/CDT - 11/03/2023 - 20:00 - NIX - DAL - PATCH - Y2023- SAPB1,SAPD1




CHG0302004	 27-10-2023 06:30:00	27-10-2023 13:30:00
IMPORTANT ACTION FOR TASK 9 : PERFORM THE FOLLOWING STEPS ON THE FOLLOWING VM's ONLY)
VM's Current OS Service pack
dlthqgga2 SP2
dltqxaadb SP4
dltqwchwd SP4
a. SANITY REBOOT
b. PERFORM SERVICE PACK MIGRATION TO SP5 (FOLLOW THE KB ===> KB0019063 ) Take in consideration " dlthqgga2 is in SP2 "
c. REBOOT AGAIN
d. CONTINUE WITH NORMAL SAMUEL AUTOMATION WORKFLOW

please note - for the servers in SLES12-SP2 - first this server should go to SLES12-SP4 and then to SLES12-SP5

Patch Group (Q3) - dltqxaadb	SUSE	10.4.5.143	Development	<SID> - SAP <Landscape> (App/DB)		done

Patch Group (QA1) - dlthqgga2	SUSE	10.4.5.137	QA	HQG - SAP  (App) - NA		done

Patch Group () - dltqwchwd	SUSE	10.4.5.144	Development	<SID> - SAP <Landscape> (App)	done
		
		
Patch Group (Q3) - dlthqgga1	Redhat	10.4.5.42	Development	HQG - SAP  () - Sybase
	Patch Group (Q3) - dlthqggat	Redhat	10.4.5.34	Development	HQG - SAP  (App/DB) - Sybase ASE		ds agent ok
Patch Group (Q3) - dlthqehap	Redhat	10.4.5.33	Production	HQE - SAP  (App)
	Patch Group () - daldlthqedb3	SUSE	10.4.5.36	Development	<SID> - SAP <Landscape> (DB)			HANA		ds agent ok



kdump
dlthqgga1
dlthqggat
dlthqggat
dlthqehap


dlthqgga2
dltqxaadb
dltqwchwd



[Missing] 10.250.17.53:/EPI-USE/SAP on /EPI-USE/SAP type nfs (rw,bg,hard,intr,rsize=8192,wsize=8192,tcp,vers=3,timeo=600

[Missing] 10.250.17.53:/EPI-USE/SAP on /EPI-USE/SAP type nfs (rw,bg,hard,intr,rsize=8192,wsize=8192,tcp,vers=3,timeo=600)
  [New]     10.250.17.53:/EPI-USE/SAP on /EPI-USE/SAP type nfs (rw,bg,hard,intr,rsize=8192,wsize=8192,tcp,vers=3,timeo=600,addr=10.250.17.53)
  
  
[root@DLTHQGGAT ~]$ /opt/ds_agent/dsa_query -c "GetAgentStatus"|grep -i proxy
AgentStatus.10: dsm_proxy
AgentStatus.3: relay_proxy
AgentStatus.dsm_proxy: dsm_proxy://146.89.140.6:3128/
AgentStatus.relay_proxy: relay_proxy://146.89.140.6:3128/


# export PROXY_ADDR_PORT='146.89.140.6:3128'
#export RELAY_PROXY_ADDR_PORT=146.89.140.6:3128
#export POLICYID=â€™49â€™



id='49'>


[root@dltqxaadb ds_agent]# ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.mode: not-capable
AgentStatus.lastAgentToManagerSession: 1698383938


[root@dlthqgga1 ds_agent]$ ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.mode: not-capable
AgentStatus.lastAgentToManagerSession: 1698383929



CS14201058	Internal Infrastructure -- CCP	
 
P1 - Severe
	has#Provisioned Storage a0001v5wvcs0003.infra.mhas.ibm.com - Metric Disk Space potentially used is equal to 114%:WA2DAL13POD2POOL1UMAPOD2DSP172	a0001v5wvcs0003	SQ-SAP-TRIO-B1
CS14200708	Internal Infrastructure -- CCP	
 
P1 - Severe
	amm#Provisioned Storage ammdal13vcs001.imzcloud.ibmammsap.local - Metric Disk Space potentially used is equal to 108%:INEDAL13POOL1POD1DSE478	AMMDAL13VCS001	SQ-SAP-TRIO-B1
CS14200606	Internal Infrastructure -- CCP	
 
P1 - Severe
	amm#Provisioned Storage ammdal13vcs001.imzcloud.ibmammsap.local - Metric Disk Space potentially used is equal to 107%:DAL13POOL1DS222	AMMDAL13VCS001	SQ-SAP-TRIO-B1
 
 
 
 SRM issue with FRA and PAR #8728

https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/issues/8728





Change approval  CHG0300312 CST/CDT - 11/02/2023 - 10:00 - NIX - HRM - PATCH - HC - Y2023- SAPB2 - Batch 1a

CSR - CHG0300161 - 2023 Annual DR Test - American Airlines (A1A)
				
CHG0299079	Kuraray C. Ltd -- KRR     Linux	    11/5/2023   18:00


CS14220210 account unlock IAM


CS14221284

SAPAPP15 10.207.61.37
SAPAPP18 10.207.61.70
SAPAPP19 10.207.61.215
SAPAPP20 10.207.61.195
SAPAPP21 10.207.61.80
SAPAPP23 10.207.61.130

SAPAPP26 10.207.61.48
SAPAPP27 10.207.61.47
SAPAPP28 10.207.61.58
SAPAPP29 10.207.61.85
SAPAPP30 10.207.61.95
SAPAPP31 10.207.61.84

SAPAPP31-HA 10.207.61.222
SAPAPP32 10.207.61.46
SAPAPP33 10.207.61.235
SAPAPP34 10.207.61.230
SAPAPP35 10.207.61.39
SAPAPP36 10.207.61.197
SAPAPP37 10.207.61.156
SAPAPP38 10.207.61.134
SAPAPP39 10.207.61.167
SAPAPP40 10.207.61.149
SAPAPP41 10.207.61.151
SAPAPP42 10.207.61.242
SAPAPP43 10.207.61.152
tgcs4hmap3 10.207.63.101


135.37.12.52	WRMWDESP
135.37.12.43	SSPDESP
135.37.12.79	TWP1DESP
135.37.12.49	TWP2DESP
192.168.203.232	Â PWPDESP
135.37.12.92	POSILDESP
10.152.66.22	TSLJA08282



lpstat -t |grep -i WRMWDESP
lpadmin -p WRMWDESP -v lpd://135.37.12.52 -E
lpstat -t |grep -i WRMWDESP
cupsenable WRMWDESP
cupsaccept WRMWDESP
cat /etc/hosts |grep -i WRMWDESP

lpstat -t |grep -i SSPDESP
lpadmin -p SSPDESP -v lpd://135.37.12.43 -E
lpstat -t |grep -i SSPDESP
cupsenable SSPDESP
cupsaccept SSPDESP
cat /etc/hosts |grep -i SSPDESP

lpstat -t |grep -i TWP1DESP
lpadmin -p TWP1DESP -v lpd://135.37.12.79 -E
lpstat -t |grep -i TWP1DESP
cupsenable TWP1DESP
cupsaccept TWP1DESP
cat /etc/hosts |grep -i TWP1DESP

lpstat -t |grep -i TWP2DESP
lpadmin -p TWP2DESP -v lpd://135.37.12.49 -E
lpstat -t |grep -i TWP2DESP
cupsenable TWP2DESP
cupsaccept TWP2DESP
cat /etc/hosts |grep -i TWP2DESP

lpstat -t |grep -i PWPDESP
lpadmin -p PWPDESP -v lpd://192.168.203.232 -E
lpstat -t |grep -i PWPDESP
cupsenable PWPDESP
cupsaccept PWPDESP
cat /etc/hosts |grep -i PWPDESP

lpstat -t |grep -i POSILDESP
lpadmin -p POSILDESP -v lpd://135.37.12.92 -E
lpstat -t |grep -i POSILDESP
cupsenable POSILDESP
cupsaccept POSILDESP
cat /etc/hosts |grep -i POSILDESP

lpstat -t |grep -i TSLJA08282
lpadmin -p TSLJA08282 -v lpd://10.152.66.22 -E
lpstat -t |grep -i TSLJA08282
cupsenable TSLJA08282
cupsaccept TSLJA08282
cat /etc/hosts |grep -i TSLJA08282


[root@tgcpoqdbapp ~]# rpm -qa |grep -i telnet
telnet-1.2-150000.3.6.1.x86_64
[root@tgcpoqdbapp ~]#

[root@tgcpoddbapp ~]# rpm -qa |grep -i telnet
telnet-1.2-150000.3.6.1.x86_64




FC50



CHG0302758 	02-11-2023 07:30:00		08-11-2023 08:30:00	implement 
CS14237357   Change printer IP



CHG0302761 02-11-2023 07:30:00	02-11-2023 15:30:00  scheduled


[root@peu-ppe-dbci ~]# lsscsi |grep -i sdj
[32:0:10:0]  disk    VMware   Virtual disk     1.0   /dev/sdj		removed
[root@peu-ppe-dbci ~]# lsscsi |grep -i sdk
[32:0:11:0]  disk    VMware   Virtual disk     1.0   /dev/sdk		removed





New IP to be updated : 135.116.33.110

Combination Name/Location	Printer Make	Printer Model	Queue name 	IP Address
100 TON INVOICE PRINTER	HP	HP Laserjet M507DN	NPI450E44	135.116.33.110


135.116.33.110   NPI450E44



sed -i 's/135.116.33.109/135.116.33.110/g' /etc/hosts

old ip 135.116.33.109


lpstat -t |grep -i NPI450E44
lpadmin -x NPI450E44
sed -i 's/135.116.33.109/135.116.33.110/g' /etc/hosts
lpadmin -p NPI450E44 -v lpd://135.116.33.110 -E
cupsenable NPI450E44
cupsaccept NPI450E44
cat /etc/hosts |grep -i NPI450E44
lpstat -t |grep -i NPI450E44


SAPAPP15 10.207.61.37
SAPAPP18 10.207.61.70
SAPAPP19 10.207.61.215
SAPAPP20 10.207.61.195
SAPAPP21 10.207.61.80
SAPAPP23 10.207.61.130
SAPAPP26 10.207.61.48
SAPAPP27 10.207.61.47
SAPAPP28 10.207.61.58
SAPAPP29 10.207.61.85
SAPAPP30 10.207.61.95
SAPAPP31 10.207.61.84
SAPAPP31-HA 10.207.61.222
SAPAPP32 10.207.61.46
SAPAPP33 10.207.61.235
SAPAPP34 10.207.61.230
SAPAPP35 10.207.61.39
SAPAPP36 10.207.61.197
SAPAPP37 10.207.61.156
SAPAPP38 10.207.61.134
SAPAPP39 10.207.61.167
SAPAPP40 10.207.61.149
SAPAPP41 10.207.61.151
SAPAPP42 10.207.61.242
SAPAPP43 10.207.61.152
tgcs4hmap3 10.207.63.101




CHG0302880	CST/CDT - 11/05/2023 - 21:00 - NIX - MGG - PATCH - Y2023- SAPB1,SAPD1		Approved  45 min
CHG0302855	CST/CDT - 11/05/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1	45 min	
CHG0302878	CST/CDT - 11/06/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1




[root@peu-pip-dbci ~]# pvs |grep -i sdw
  /dev/sdw   pipappvg  lvm2 a--  128.00g 128.00g
[root@peu-pip-dbci ~]# pvs |grep -i sdx
  /dev/sdx   pipappvg  lvm2 a--   32.00g  32.00g
[root@peu-pip-dbci ~]# pvdisplay -m |grep -i /dev/sdw
  PV Name               /dev/sdw
[root@peu-pip-dbci ~]# pvdisplay -m |grep -i /dev/sdx
  PV Name               /dev/sdx
[root@peu-pip-dbci ~]# vgs pipappvg
  VG       #PV #LV #SN Attr   VSize VFree
  pipappvg   4  23   0 wz--n- 1.41t 463.98g
[root@peu-pip-dbci ~]# vgs pipappvg
  VG       #PV #LV #SN Attr   VSize VFree
  pipappvg   4  23   0 wz--n- 1.41t 463.98g
  
 --- Physical volume ---
  PV Name               /dev/sdw
  VG Name               pipappvg
  PV Size               128.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              32767
  Free PE               32767
  Allocated PE          0
  PV UUID               jauQua-5oTm-btDY-DwEA-NXQy-OtBr-yYn7cl

  --- Physical volume ---
  PV Name               /dev/sdx
  VG Name               pipappvg
  PV Size               32.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              8191
  Free PE               8191
  Allocated PE          0
  PV UUID               ESqpKC-mpZI-AXUz-RqGE-iyJf-i4Fv-zfogFK

[root@peu-pip-dbci ~]# lsscsi |grep -i /dev/sdw
[3:0:8:0]    disk    VMware   Virtual disk     2.0   /dev/sdw

[root@peu-pip-dbci ~]# lsscsi |grep -i /dev/sdx
[3:0:9:0]    disk    VMware   Virtual disk     2.0   /dev/sdx




CHG0302770 08-11-2023 08:30:00	 08-11-2023 15:30:00



CHG0302763	
10.192.69.151 (bt1h1qdb01)	Disk name /dev/nvme7n1 is not utilized. The disk size is 220.7G 	/dev/nvme7n1	220.7	BT1
nvme7n1                  259:8    0 220.7G  0 disk                  AWS22A0E7B533D0CEDFD




10.192.69.46 (bt1h4qdb01)	Disk name /dev/nvme9n1 is not utilized. The disk size is 220.7G 	/dev/nvme9n1	220.7	BT1
nvme9n1                     259:13   0 220.7G  0 disk                  AWS270FD153DA1F96E68

[root@bt1h4qdb01 ~]# lsblk -o +serial
NAME                        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS      SERIAL
nvme1n1                     259:0    0   125G  0 disk                  vol05230e6ab813ea8c7
â””â”€saplog-log                254:1    0   125G  0 lvm  /sapmnt/log
nvme3n1                     259:1    0   256G  0 disk                  vol0248a7777c9766a22
â””â”€tempvg-lv_TEMP_S4Q_Backup 254:3    0   255G  0 lvm
nvme0n1                     259:2    0    96G  0 disk                  vol0c55a6c4a64b734d2
â”œâ”€nvme0n1p1                 259:10   0     2M  0 part
â”œâ”€nvme0n1p2                 259:11   0    20M  0 part /boot/efi
â””â”€nvme0n1p3                 259:12   0    96G  0 part /
nvme6n1                     259:3    0    50G  0 disk                  vol0a8ed1fc3c672930a
â””â”€sapusrsap-usrsap          254:2    0    50G  0 lvm  /usr/sap
nvme2n1                     259:4    0     2G  0 disk                  vol079b1b174e1043699
â””â”€system-swap               254:0    0     2G  0 lvm  [SWAP]
nvme4n1                     259:5    0   295G  0 disk                  vol04b060eb77c9137a0
â””â”€sapdata-data              254:5    0   550G  0 lvm  /sapmnt/data
nvme5n1                     259:6    0    64G  0 disk                  vol08c806b7bf00eff81
â””â”€nvme5n1p2                 259:9    0    62G  0 part
  â”œâ”€rootvg-homelv           254:6    0     5G  0 lvm  /home
  â”œâ”€rootvg-optlv            254:7    0    10G  0 lvm  /opt
  â”œâ”€rootvg-tmplv            254:8    0    10G  0 lvm  /tmp
  â”œâ”€rootvg-varlv            254:9    0    10G  0 lvm  /var
  â”œâ”€rootvg-vloglv           254:10   0    10G  0 lvm  /var/log
  â”œâ”€rootvg-vartmp           254:11   0     2G  0 lvm  /var/tmp
  â”œâ”€rootvg-varlogaudit      254:12   0     4G  0 lvm  /var/log/audit
  â””â”€rootvg-varoptansible    254:13   0     5G  0 lvm  /var/opt/ansible
nvme7n1                     259:7    0   256G  0 disk                  vol03b51854142ab643f
â””â”€sapdata-data              254:5    0   550G  0 lvm  /sapmnt/data
nvme8n1                     259:8    0   300G  0 disk                  vol01ff2c5e13f11bf1c
â””â”€sapshared-shared          254:4    0   300G  0 lvm  /sapmnt/shared
nvme9n1                     259:13   0 220.7G  0 disk                  AWS270FD153DA1F96E68


[root@peu-pmp-dbci ~]# lsscsi |grep -i sdc
[32:0:2:0]   disk    VMware   Virtual disk     2.0   /dev/sdc


[root@peu-ppp-dbci ~]# lsscsi |grep -i sdd
[32:0:3:0]   disk    VMware   Virtual disk     2.0   /dev/sdd

[root@peu-ppp-dbci ~]# lsblk |grep -i sdd
sdd                                            8:48   0  618G  0 disk


CHG0302758
[root@peu-pap-ap2 ~]# lsscsi |grep -i sdc
[30:0:2:0]   disk    VMware   Virtual disk     2.0   /dev/sdc
[root@peu-pap-ap2 ~]# lsblk |grep -i sdc
sdc                          8:32   0  382G  0 disk


[root@peu-grp-dbci ~]# lsscsi |grep -i sdc
[32:0:2:0]   disk    VMware   Virtual disk     2.0   /dev/sdc
[root@peu-grp-dbci ~]# lsblk |grep -i sdc
sdc                                     8:32   0   1.8T  0 disk



[root@peu-pap-dbci ~]# lsblk |grep -i sdc
sdc                                            8:32   0     2T  0 disk
[root@peu-pap-dbci ~]# lsblk |grep -i sdd
sdd                                            8:48   0     2T  0 disk
[root@peu-pap-dbci ~]# lsblk |grep -i sde
sde                                            8:64   0     2T  0 disk
[root@peu-pap-dbci ~]# lsblk |grep -i sdf
sdf                                            8:80   0     2T  0 disk
[root@peu-pap-dbci ~]# lsscsi |grep -i sdc
[30:0:2:0]   disk    VMware   Virtual disk     2.0   /dev/sdc
[root@peu-pap-dbci ~]# lsscsi |grep -i sdd
[30:0:3:0]   disk    VMware   Virtual disk     2.0   /dev/sdd
[root@peu-pap-dbci ~]# lsscsi |grep -i sde
[30:0:4:0]   disk    VMware   Virtual disk     2.0   /dev/sde
[root@peu-pap-dbci ~]# lsscsi |grep -i sdf
[30:0:5:0]   disk    VMware   Virtual disk     2.0   /dev/sdf

CHG0302758
[root@peu-lc1-dbci ~]# lsscsi |grep -i sdc
[32:0:2:0]   disk    VMware   Virtual disk     2.0   /dev/sdc
[root@peu-lc1-dbci ~]# lsscsi |grep -i sdd
[32:0:3:0]   disk    VMware   Virtual disk     2.0   /dev/sdd
[root@peu-lc1-dbci ~]# lsblk |grep -i sdc
sdc                                  8:32   0    2T  0 disk
[root@peu-lc1-dbci ~]# lsblk |grep -i sdd
sdd                                  8:48   0  906G  0 disk



[root@peu-pap-ap1 ~]# lsblk |grep -i sdc
sdc                          8:32   0  382G  0 disk
[root@peu-pap-ap1 ~]# lsscsi |grep -i sdc
[30:0:2:0]   disk    VMware   Virtual disk     2.0   /dev/sdc



[root@peu-pai-dbci ~]# vgs paiappvg
  VG       #PV #LV #SN Attr   VSize VFree
  paiappvg   2  15   0 wz--n- 2.44t 2.23t
[root@peu-pai-dbci ~]# lvdisplay |grep -i paiappvg
  LV Path                /dev/paiappvg/3rdPartySoftware_PAI_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/applications_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/archiv_PAI_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/home_daaadm_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/home_paiadm_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/home_sapadm_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/interface_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/interface_PAI_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/sapmnt_PAI_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/sapstage_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/usr_sap_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/usr_sap_DAA_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/usr_sap_PAI_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/usr_sap_PAI_directlink_lv
  VG Name                paiappvg
  LV Path                /dev/paiappvg/usr_sap_ccms_lv
  VG Name                paiappvg


[root@peu-pai-dbci ~]# lsblk |grep -i sdr
sdr                                    65:16   0  1.2T  0 disk

[root@peu-pai-dbci ~]# lsscsi |grep -i sdr
[3:0:2:0]    disk    VMware   Virtual disk     2.0   /dev/sdr


 --- Physical volume ---
  PV Name               /dev/sdr
  VG Name               paiappvg
  PV Size               1.22 TiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              319999
  Free PE               319999
  Allocated PE          0
  PV UUID               M5DbqV-eCpH-i5JR-UoIW-BPKt-7Y9h-U4zAxS

  --- Physical Segments ---
  Physical extent 0 to 319998:
    FREE


[root@peu-pai-dbci ~]# lsscsi |grep -i sdr
[3:0:2:0]    disk    VMware   Virtual disk     2.0   /dev/sdr

[root@peu-pai-dbci ~]# lsblk |grep -i sdr
sdr                                    65:16   0  1.2T  0 disk



CHG0302758

[root@peu-aiq-dbci ~]# lsblk |grep -i sdl
sdl                                     8:176  0  256G  0 disk

[root@peu-aiq-dbci ~]# lsscsi |grep -i sdl
[0:0:12:0]   disk    VMware   Virtual disk     2.0   /dev/sdl


--- Physical volume ---
  PV Name               /dev/sdo
  VG Name               aiqarchvg
  PV Size               32.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              8191
  Free PE               8191
  Allocated PE          0
  PV UUID               aDqZGE-0Bsd-Kdhn-Q6PK-Bv48-pmmb-EIOPWy
  
  
[root@peu-aiq-dbci ~]# lvdisplay |grep -i aiqarchvg
  LV Path                /dev/aiqarchvg/backup_lv
  VG Name                aiqarchvg
  LV Path                /dev/aiqarchvg/db2_AIQ_log_archive_lv
  VG Name                aiqarchvg
  LV Path                /dev/aiqarchvg/db2_AIQ_log_retrieve_lv
  VG Name                aiqarchvg
  
[root@peu-aiq-dbci ~]# vgs aiqarchvg
  VG        #PV #LV #SN Attr   VSize   VFree
  aiqarchvg   4   3   0 wz--n- 735.98g 46.98g


[root@peu-aiq-dbci ~]# lsblk |grep -i sdo
sdo                                     8:224  0   32G  0 disk

[root@peu-aiq-dbci ~]# lsscsi |grep -i sdo
[0:0:15:0]   disk    VMware   Virtual disk     2.0   /dev/sdo




--- Physical volume ---
  PV Name               /dev/sdh
  VG Name               potdatavg
  PV Size               275.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              70399
  Free PE               70399
  Allocated PE          0
  PV UUID               eQW1ic-sCPL-fqYP-UosD-TkHw-LcsL-pQvkVX

  --- Physical volume ---
  PV Name               /dev/sdi
  VG Name               potdatavg
  PV Size               274.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              70143
  Free PE               70143
  Allocated PE          0
  PV UUID               N0zMbX-69Ud-yuSy-GseC-rHrn-AOi3-4973zL

  --- Physical volume ---
  PV Name               /dev/sdj
  VG Name               potdatavg
  PV Size               274.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              70143
  Free PE               70143
  Allocated PE          0
  PV UUID               1kzixQ-xKUW-CVb3-QtVA-I8sQ-whA9-rrBGpL

  --- Physical volume ---
  PV Name               /dev/sdk
  VG Name               potdatavg
  PV Size               274.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              70143
  Free PE               70143
  Allocated PE          0
  PV UUID               yipc7h-WQVx-dVN9-DExO-66gW-NlYq-5RTFJf

CHG0302758

[root@peu-pot-ci ~]$ lsscsi |grep -i sdh
[1:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdh		sdh      8:112  0  275G  0 disk

[root@peu-pot-ci ~]$ lsscsi |grep -i sdi
[1:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdi		sdi      8:128  0  274G  0 disk		done

[root@peu-pot-ci ~]$ lsscsi |grep -i sdj
[3:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdj		sdj      8:144  0  274G  0 disk		done

[root@peu-pot-ci ~]$ lsscsi |grep -i sdk
[3:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdk		sdk      8:160  0  274G  0 disk   done


[root@peu-pot-ci ~]$ lsblk |grep -i sdh
sdh                            8:112  0  275G  0 disk

[root@peu-pot-ci ~]$ lsblk |grep -i sdi
sdi                            8:128  0  274G  0 disk

[root@peu-pot-ci ~]$ lsblk |grep -i sdj
sdj                            8:144  0  274G  0 disk

[root@peu-pot-ci ~]$ lsblk |grep -i sdk
sdk                            8:160  0  274G  0 disk



CHG0302878

sm9d18493053		10.135.226.18
sm9d18493038		10.135.226.33
sm9d18493061		10.135.226.22



CHG0303474 CST/CDT - 11/09/2023 - 10:00 - NIX - HRM - PATCH - HC - Y2023- SAPB2 - Batch 3(a)


CS14248917




CHG0302770	08-11-2023 08:30:00    08-11-2023 15:30:00

a2asolprd1dci - 100.126.35.103 - MX2 

Disk name /dev/sdk is not utilized. The disk size is 118G
Disk name /dev/sdj is not utilized. The disk size is 119G
Disk name /dev/sdi is not utilized. The disk size is 119G

[root@a2asolprd1dci ~]# pvs |grep -i sdi
  /dev/sdi   mx2datavg lvm2 a--  119.00g  119.00g
[root@a2asolprd1dci ~]# pvs |grep -i sdj
  /dev/sdj   mx2datavg lvm2 a--  119.00g  119.00g
[root@a2asolprd1dci ~]# pvs |grep -i sdk
  /dev/sdk   mx2datavg lvm2 a--  118.00g  118.00g
[root@a2asolprd1dci ~]# lsscsi |grep -i sdi
[0:0:9:0]    disk    VMware   Virtual disk     1.0   /dev/sdi	119.00g
[root@a2asolprd1dci ~]# lsscsi |grep -i sdj
[0:0:10:0]   disk    VMware   Virtual disk     1.0   /dev/sdj	119.00g
[root@a2asolprd1dci ~]# lsscsi |grep -i sdk
[0:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdk	118.00g

[root@a2asolprd1dci ~]# pvscan |grep -i sdi
  PV /dev/sdi    VG mx2datavg       lvm2 [119.00 GiB / 119.00 GiB free]		deleted
You have new mail in /var/spool/mail/root
[root@a2asolprd1dci ~]# pvscan |grep -i sdj
  PV /dev/sdj    VG mx2datavg       lvm2 [119.00 GiB / 119.00 GiB free]		deleted
[root@a2asolprd1dci ~]# pvscan |grep -i sdk
  PV /dev/sdk    VG mx2datavg       lvm2 [118.00 GiB / 118.00 GiB free]		deleted

--- Physical volume ---
  PV Name               /dev/sdi
  VG Name               mx2datavg
  PV Size               119.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              30463
  Free PE               30463
  Allocated PE          0
  PV UUID               cwsCGE-bxuB-6fVm-ewOy-5Fs3-30NQ-mqhPDL

  --- Physical Segments ---
  Physical extent 0 to 30462:
    FREE

  --- Physical volume ---
  PV Name               /dev/sdj
  VG Name               mx2datavg
  PV Size               119.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              30463
  Free PE               30463
  Allocated PE          0
  PV UUID               wcnLiJ-982l-Ml5C-NKen-3PhF-rFZt-0k7qMg

  --- Physical Segments ---
  Physical extent 0 to 30462:
    FREE

  --- Physical volume ---
  PV Name               /dev/sdk
  VG Name               mx2datavg
  PV Size               118.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              30207
  Free PE               30207
  Allocated PE          0
  PV UUID               93jgTL-qKle-ECPm-9M4S-su3x-PAFq-DyvKAQ

  --- Physical Segments ---
  Physical extent 0 to 30206:
    FREE



100.126.36.164 - a2asltstg2ci - TS1

Disk name /dev/sdh is not utilized. The disk size is 3G

--- Physical volume ---
  PV Name               /dev/sdh
  VG Name               ts1logvg
  PV Size               3.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              767
  Free PE               767
  Allocated PE          0
  PV UUID               VCRqY1-X4he-HJDM-zpkE-JI0T-KR8Y-a7Ryi1

[root@a2asltstg2ci ~]# lsblk |grep -i sdh
sdh                                   8:112  0     3G  0 disk
[root@a2asltstg2ci ~]# lsscsi |grep -i sdh
[0:0:8:0]    disk    VMware   Virtual disk     1.0   /dev/sdh

/dev/sdh   ts1logvg     lvm2 a--    3.00g    3.00g

[0:0:8:0]    disk    VMware   Virtual disk     1.0   /dev/sdh




100.126.36.12 - a2aeccdev1dci - ED1

Disk name /dev/sdr is not utilized. The disk size is 32G

[root@a2aeccdev1dci ~]# blkid /dev/sdr
[root@a2aeccdev1dci ~]# pvs |grep -i sdr
[root@a2aeccdev1dci ~]# pvdisplay -m |grep -i sdr
[root@a2aeccdev1dci ~]# lsblk|grep -i sdr
sdr                                  65:16   0    32G  0 disk
[root@a2aeccdev1dci ~]# lsscsi|grep -i sdr
[1:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdr


appdisk23 scsi:1:1
appdisk12 scsi:1:2
appdisk11 scsi:0:15
appdisk1  scsi:0:5

[root@a2aeccdev1dci ~]# lsblk |grep -i 32G
sdf                                   8:80   0    32G  0 disk	appdisk1  scsi:0:5	[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf
sdo                                   8:224  0    32G  0 disk	appdisk11 scsi:0:15		[0:0:15:0]   disk    VMware   Virtual disk     1.0   /dev/sdo
sdq                                  65:0    0    32G  0 disk	appdisk23 scsi:1:1		[1:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdq
sdr                                  65:16   0    32G  0 disk	appdisk12 scsi:1:2		[1:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdr
[root@a2aeccdev1dci ~]# lsscsi|grep -i sdr
[1:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdr

[root@a2aeccdev1dci ~]# lsscsi|grep -i sdq
[1:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdq

[root@a2aeccdev1dci ~]# lsscsi|grep -i sdo
[0:0:15:0]   disk    VMware   Virtual disk     1.0   /dev/sdo

[root@a2aeccdev1dci ~]# lsscsi|grep -i sdf
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf



100.126.36.63 - a2apistg1db - PS1

Disk name /dev/sdh is not utilized. The disk size is 17G
 PV Name               /dev/sdh
  VG Name               ps1logvg
  PV Size               17.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              4351
  Free PE               4351
  Allocated PE          0
  PV UUID               k0ny6F-kO0N-CklH-2Dnx-NeEW-oqAp-VlleAp

  --- Physical Segments ---
  Physical extent 0 to 4350:
    FREE


[root@a2apistg1db ~]# pvdisplay -m |grep -i sdh
  PV Name               /dev/sdh
[root@a2apistg1db ~]# pvs|grep -i sdh

  /dev/sdh   ps1logvg     lvm2 a--   17.00g 17.00g
  
[root@a2apistg1db ~]# vgs ps1logvg
  VG       #PV #LV #SN Attr   VSize  VFree
  ps1logvg   2   9   0 wz--n- 80.99g 19.99g
  
[root@a2apistg1db ~]# pvscan |grep -i sdh
  PV /dev/sdh    VG ps1logvg        lvm2 [17.00 GiB / 17.00 GiB free]
  
[root@a2apistg1db ~]# lsscsi |grep -i sdh
[0:0:8:0]    disk    VMware   Virtual disk     1.0   /dev/sdh

[root@a2apistg1db ~]# lsblk |grep -i sdh
sdh                                   8:112  0    17G  0 disk

appdisk6 scsi:0:8



CS14253707 - please help with this request


CS14253907	
ThreatIc4#2k22d


Host	IP	ID	Activity	Password
ETD	ETD	ETD	ETD	ETD
ttaetdphdb	10.207.61.94	custsap	create ID and set password	Shared in separate email
[root@ttaetdphdb ~]# id custsap
uid=54722(custsap) gid=100(users) groups=100(users)
[root@ttaetdphdb ~]# date
Wed Nov  8 11:54:43 IST 2023

ttaetdpapp		10.207.61.99	custid	change password	Shared in separate email
[root@ttaetdpapp ~]# chage -l custid
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7

ttaetddhdb	10.207.62.99	custid	change password	Shared in separate email
[root@ttaetddhdb ~]# chage -l custid
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7

ttaetddapp	10.207.62.105	custid	change password	Shared in separate email
[root@ttaetddapp ~]# chage -l custid
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7



 BIS	 BIS	 BIS	 BIS	 BIS
ttabispapp	10.207.61.79	cust* IDs	change password	Shared in separate email
[root@ttabispapp ~]# cat /etc/shadow |grep -i cust*
custapp
custid
custsap

[root@ttabispapp ~]# chage -l custid
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7

[root@ttabispapp ~]# chage -l custapp
Last password change                                    : Nov 08, 2023
Password expires                                        : Feb 06, 2024
Password inactive                                       : Mar 07, 2024
Account expires                                         : never
Minimum number of days between password change          : 7
Maximum number of days between password change          : 90
Number of days of warning before password expires       : 7

[root@ttabispapp ~]# chage -l custsap
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7



ttabisdapp	10.207.62.51	cust* IDs	change password	Shared in separate email		
custsap
custid

[root@ttabisdapp ~]# chage -l custid
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7

[root@ttabisdapp ~]# chage -l custsap
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7

ttabisphdb	10.207.61.138	cust* IDs	change password	Shared in separate email
custid

[root@ttabisphdb ~]# chage -l custid
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7


ttabisdhdb	10.207.62.95	cust* IDs	change password	Shared in separate email
custsap
custid

[root@ttabisdhdb ~]# chage -l custid
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7

[root@ttabisdhdb ~]# chage -l custsap
Last password change                                    : Nov 08, 2023
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7


Please set the above credentials as described. This is a requirement for onboarding these servers in PIM system.
Also, share the cust* IDs list for BIS systems.


TTAS4HANADDB		10.207.62.123
TTAS4HANADAPP		10.207.62.146
TTAS4HANAQDB			10.207.63.174
TTAS4HANAQAPP		10.207.63.56
ttas4hpdb		10.207.61.161
ttas4hpdb-ha	10.207.61.154
ttas4happ		10.207.61.246
ttas4happ-ha	10.207.61.168
TTANINLGRCDEV	10.207.62.33
TTANINLGRCPRD			10.207.61.98


root had expired
ttas4hanaddb
ttas4hanadapp
ttaninlgrcdev




Node: sm9v235532009
NodeAlias: 10.135.224.34		qVXBWK79H9!aqKa
 
Node: sm9v235492019
NodeAlias: 10.135.227.67		TZuqLr!e9nFqWpB
 
Node: sm9v185173118
NodeAlias: 10.135.224.31		NufRogtBa.i9tMV
 
Node: sm9p185173114
NodeAlias: 10.135.224.28		N@do7i!kcKjv9j4
 
Node: sm9p118217v23
NodeAlias: 10.135.228.16		QG9sPvGDr2cby_6
 
Node: sm9p118217v22
NodeAlias: 10.135.224.57		C_h8xMqW8@ncu7g
 
Node: sm9l182172018
NodeAlias: 10.135.224.48		KMhUR..6yUbq3PV
 
Node: sm9l182172016
NodeAlias: 10.135.224.56		nZ_2Q8KBznHucAR
 
Node: sm9l182172013
NodeAlias: 10.135.224.53		Nh8-ezny2c_C_.Q
 
Node: sm9l182172012
NodeAlias: 10.135.224.59		D3u_Kg.4TUdFRkb
 
Node: sm9h185173005
NodeAlias: 10.135.224.37		Ff3pbcENX*Z6*kZ
 
Node: sm9h185173001
NodeAlias: 10.135.224.47		q-qdADKx4AnhrmZ
 
Node: sm9d185183004
NodeAlias: 10.135.226.15		ckqk9WXT.Pogaec
	
Node: sm9d185183003
NodeAlias: 10.135.226.125		2hJuDyy_RMq.NN8
 
Node: sm9d185183001
NodeAlias: 10.135.226.24		3LTk@XUDb9Hf2XQ
 
Node: sm9d185173005
NodeAlias: 10.135.224.39		BctdGisjXnv_o3F
 
Node: sm9d185173002
NodeAlias: 10.135.224.40		oX.vQUY!ACWrK4Y
 
Node: sm9d18493050
NodeAlias: 10.135.226.53		qPw2Hu*MQYCabjk
 
Node: sm9a182172009
NodeAlias: 10.135.224.49		xGvnP2!EkYdRJef




Loot : SonyLiv Premium For Free (2 Years)

Login To Your Sony Liv Account > Activate Offer > Apply Code : SL1UDJYU2G

Repeat This Process 4 Times On Single Account & Get Free 2 Years Sony Liv Premium Subscription.



CHG0300440 CST/CDT - 11/15/2023 - 20:00 - NIX - MCL - PATCH - Y2023- SAPB2

CHG0301032 CST/CDT - 11/16/2023 - 20:00 - NIX - MM9 - PATCH - HC - Y2023- SAPB2


ppldvcsa01.imzcloud.ibmammsap.local --- 10.207.65.40	WIN
ppldvocra01.imzcloud.ibmammsap.local --- 10.207.65.29	Win
pplprcsa01.imzcloud.ibmammsap.local --- 10.207.64.58	Win
pplprdsa01.imzcloud.ibmammsap.local --- 10.207.64.63	Win

ppldvecma01.imzcloud.ibmammsap.local --- 10.207.65.26	LIN
ppldvecmdb01.imzcloud.ibmammsap.local --- 10.207.65.27	Lin
pplprecma01.imzcloud.ibmammsap.local --- 10.207.64.94	Lin
pplprecmdb01.imzcloud.ibmammsap.local --- 10.207.64.99	Lin



CHG0301567	CST/CDT - 11/12/2023 - 09:00 - NIX - CO3 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1


nothing for A trio they are handling B shifts 

nirmalya tech gud, willinness positives more 
communication nend to work

Anand trying to control
work wise 
good appreciation
no impact in work
does not talkmuch
working on non critical work


Jitendra  doing more on windows
human erros 
attitude is gud
mistakes are odd
process stuff missing



CS14260716
CS14243730




CHG0303743 10-11-2023 08:30:00 10-11-2023 15:30:00
IFNIP	Disk Name with Size	Disk Name	Size	CIDR

10.7.1.71	Disk name /dev/sdc is not utilized. The disk size is 32G 	 /dev/sdc 	32	TQA
/dev/sdc   erdappvg lvm2 a--  128.00g  8.00g   disk size mismatch. All attached disks are used up, nothing to clear.


10.7.1.14	Disk name /dev/sdf is not utilized. The disk size is 500G 	 /dev/sdf 	500	TQA
DIsk name and size mismatch, no 500 GB disk attached[root@TQASOLMAN ~]$ lsblk|grep -i sdf
sdf                                    8:80   0   64G  0 disk
all attached disks are used up, nothing available to reclaim.


10.7.1.18	Disk name /dev/sdf is not utilized. The disk size is 250G 	 /dev/sdf 	250	TQA
10.7.1.18	Disk name /dev/sdd is not utilized. The disk size is 64G 	 /dev/sdd 	64	TQA
10.7.1.18	Disk name /dev/sde is not utilized. The disk size is 32G 	 /dev/sde 	32	TQA
[root@TQAADS ~]$ lsblk |grep -i sdf
[root@TQAADS ~]$ lsblk |grep -i sdd
sdd                                8:48   0   50G  0 disk
[root@TQAADS ~]$ lsblk |grep -i sde
[root@TQAADS ~]$ pvs
  PV         VG        Fmt  Attr PSize   PFree
  /dev/sda2  VolGroup  lvm2 a--u  39.51g    5.50g
  /dev/sdb   sybase_vg lvm2 a--u 300.00g 1020.00m
  /dev/sdc   adsappvg  lvm2 a--u 128.00g   20.07g
  /dev/sdd   VolGroup  lvm2 a--u  50.00g    2.00g

No disks matched. None of the disks on the server are available to be reclaimed.




CHG0303877 CST/CDT - 11/15/2023 - 20:00 - NIX - MCL - OS Update SLES 12 SP04 to SP05 - PROD

CHG0301319	Mhi Rj Aviation Ulc -- MCL  Linux	11/16/2023   10:00
CHG0301320	Mhi Rj Aviation Ulc -- MCL  Linux	11/17/2023   10:00


SNG-CHE 


 
CHG0299345	CST/CDT - 11/19/2023 - 20:00 - NIX - ZFF - PATCH - Y2023- SAPB1,SAPD1


CHG0303857	CST/CDT - 11/11/2023 - 21:00 - NIX - DAL - PATCH - Y2023- SAPB1,SAPD1
Patch Group (PROD1) - dlthpghap4	Redhat	10.4.5.189	Production	HPG - SAP  (App) - NA			RHEL 6.10
Patch Group (PROD4) - dlthpggat	Redhat	10.4.5.57	Production	HPG - SAP  (App/DB) - Sybase	RHEL 8.6
Patch Group (PROD4) - dltpwdhwd	SUSE	10.4.5.237	Production	<SID> - SAP <Landscape> (App)	SUSE 12SP4
Patch Group (PROD4) - dltpxadb1	SUSE	10.4.5.139	Production	<SID> - SAP <Landscape> (DB)	SUSE 12SP4	
Patch Group (PROD4) - dltpxaap1	SUSE	10.4.5.135	Production	<SID> - SAP <Landscape> (App)	SUSE 12SP4
Patch Group (PROD4) - dltpwchwd	SUSE	10.4.5.134	Production	<SID> - SAP <Landscape> (App)	SUSE 12SP4
Patch Group (PROD2) - dlthpgga1	Redhat	10.4.5.60	Production	HPG - SAP  (App) - Sybase		RHEL 6.10	
Patch Group (PROD3) - dlthpghap5	Redhat	10.4.5.188	Production	HPG - SAP  (App) - NA       RHEL 6.10

Operating system "Red Hat Enterprise Linux Server release 6.10 (Santiago) - 6.10" is currently out of support. (Support Ended on 30/Nov/2020 )

Operating system "SUSE Linux Enterprise Server 12 SP4 - (12 SP4)" is currently out of support. (Support Ended on 30/Jun/2023 )





CHG0302505-TTA-off-line migration of  tslbwdevdb & tsleecdevdb



CHG0303972 CST/CDT - 11/15/2023 - 20:00 - NIX - A2A - PATCH - Y2023- SAPB2	approved
CHG0303974 CST/CDT - 11/19/2023 - 10:00 - NIX - A2A - PATCH - Y2023- SAPB2	approved
CHG0303975 CST/CDT - 11/19/2023 - 10:00 - NIX - A2A - PATCH - Y2023- SAPB2	approved




dpimagetst1.imzcloud.ibmammsap.local --- 10.210.2.133		pending install
imagetestfbs1.imzcloud.ibmammsap.local --- 10.210.2.188		retired
imagetestfbs2.imzcloud.ibmammsap.local --- 10.210.2.199		retired
fbsdbdr21fgcl.imzcloud.ibmammsap.local --- 10.210.2.221		pending install
fbsdbdr02fgcl.imzcloud.ibmammsap.local --- 10.210.2.16		installed	
fbsdbdr11fgcl.imzcloud.ibmammsap.local --- 10.210.2.63		installed



ap01
31 OCT
18
13
10
7
2
1

ap03
30
28
26
16
14
9
4



CHG0303612   BR3 NZDT patching


4 Nov 6 hrs CHG0302758 PEU
HR Personnel no. 99945370 not allowed to claim on
WBS element CDE/00229-0400.L.


CS14267658	
CS14267660
CS14267669
CS14267638
CS14267642
CS14267650


NPI450E44




Change name- CHG0304243  15-11-2023 06:30:00   15-11-2023 21:00:00

Start date- 11-15-2023 06:30:00 IST

End date- 11-15-2023 21:00:00 IST

First vm to perform. 

tdpdcsolmgr   

10.209.3.13	Disk name /dev/sdq is not utilized. The disk size is 64G 	 /dev/sdq 	64	TDP

Second vm to perform. 

tdpqpoqdbapp

10.209.3.16	Disk name /dev/sdh is not utilized. The disk size is 128G 	 /dev/sdh 	128	TDP
10.209.3.16	Disk name /dev/sdg is not utilized. The disk size is 128G 	 /dev/sdg 	128	TDP

third prod vm to perform (before 9 AM IST or start after 5 PM IST )

tdpppopdbapp

10.209.2.17	Disk name /dev/sdh is not utilized. The disk size is 128G 	 /dev/sdh 	128	TDP
10.209.2.17	Disk name /dev/sdg is not utilized. The disk size is 128G 	 /dev/sdg 	128	TDP

-----------------------------

10.209.2.17	Disk name /dev/sdh is not utilized. The disk size is 128G 	 /dev/sdh 	128	TDP

[root@tdpppopdbapp ~]# pvs|grep -i sdh
  /dev/sdh   popdatavg lvm2 a--  128.00g  128.00g

[root@tdpppopdbapp ~]# lsscsi|grep -i sdh
[0:0:8:0]    disk    VMware   Virtual disk     2.0   /dev/sdh

[root@tdpppopdbapp ~]# pvscan |grep -i sdh
  PV /dev/sdh    VG popdatavg       lvm2 [128.00 GiB / 128.00 GiB free]
  
--- Physical volume ---
  PV Name               /dev/sdh
  VG Name               popdatavg
  PV Size               128.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              32767
  Free PE               32767
  Allocated PE          0
  PV UUID               cL7rw4-ZAOM-H04c-2Ewd-e8WR-rVID-2cvqND

  --- Physical Segments ---
  Physical extent 0 to 32766:
    FREE

  -----------------------------------------------------------------------------------------

10.209.2.17	Disk name /dev/sdg is not utilized. The disk size is 128G 	 /dev/sdg 	128	TDP

[root@tdpppopdbapp ~]# pvs|grep -i sdg
  /dev/sdg   popdatavg lvm2 a--  128.00g  128.00g

[root@tdpppopdbapp ~]# lsscsi|grep -i sdg
[0:0:6:0]    disk    VMware   Virtual disk     2.0   /dev/sdg


[root@tdpppopdbapp ~]# pvscan |grep -i sdg
  PV /dev/sdg    VG popdatavg       lvm2 [128.00 GiB / 128.00 GiB free]


 --- Physical volume ---
  PV Name               /dev/sdg
  VG Name               popdatavg
  PV Size               128.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              32767
  Free PE               32767
  Allocated PE          0
  PV UUID               paf2pO-b2TP-lLGn-XJVw-pcok-CJXe-EFRpuv

  --- Physical Segments ---
  Physical extent 0 to 32766:
    FREE

OPaaS request on instance 621e2fda367501000e265250 failed, if your instance is in a failed state, please contact a member of the OPaaS team to recover your instance.

--------------------------------------------------------------------------------------------------

10.209.3.16	Disk name /dev/sdh is not utilized. The disk size is 128G 	 /dev/sdh 	128	TDP
[root@tdpqpoqdbapp ~]# blkid /dev/sdh
/dev/sdh: UUID="vD94Pl-SM7p-p2SS-F5yX-n001-nVdL-2Jp63Z" TYPE="LVM2_member"

[root@tdpqpoqdbapp ~]# pvs|grep -i sdh
  /dev/sdh   poqdatavg lvm2 a--  128.00g  128.00g

[root@tdpqpoqdbapp ~]# lsscsi|grep -i sdh
[0:0:8:0]    disk    VMware   Virtual disk     2.0   /dev/sdh

[root@tdpqpoqdbapp ~]# pvscan |grep -i sdh
  PV /dev/sdh    VG poqdatavg       lvm2 [128.00 GiB / 128.00 GiB free]
  
--- Physical volume ---
  PV Name               /dev/sdh
  VG Name               poqdatavg
  PV Size               128.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              32767
  Free PE               32767
  Allocated PE          0
  PV UUID               vD94Pl-SM7p-p2SS-F5yX-n001-nVdL-2Jp63Z

  --- Physical Segments ---
  Physical extent 0 to 32766:
    FREE

-----------------------------------------------------------------

10.209.3.16	Disk name /dev/sdg is not utilized. The disk size is 128G 	 /dev/sdg 	128	TDP
[root@tdpqpoqdbapp ~]# blkid /dev/sdg
/dev/sdg: UUID="pboW52-7iMz-1Kd6-FkYQ-MD0F-YLvl-KLQQPm" TYPE="LVM2_member"

[root@tdpqpoqdbapp ~]# pvs|grep -i sdg
  /dev/sdg   poqdatavg lvm2 a--  128.00g  128.00g

[root@tdpqpoqdbapp ~]# lsscsi|grep -i sdg
[0:0:6:0]    disk    VMware   Virtual disk     2.0   /dev/sdg

[root@tdpqpoqdbapp ~]# pvscan |grep -i sdg
  PV /dev/sdg    VG poqdatavg       lvm2 [128.00 GiB / 128.00 GiB free]
  
 --- Physical volume ---
  PV Name               /dev/sdg
  VG Name               poqdatavg
  PV Size               128.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              32767
  Free PE               32767
  Allocated PE          0
  PV UUID               pboW52-7iMz-1Kd6-FkYQ-MD0F-YLvl-KLQQPm

  --- Physical Segments ---
  Physical extent 0 to 32766:
    FREE


----------------------------------------------------------
10.209.3.13	Disk name /dev/sdq is not utilized. The disk size is 64G 	 /dev/sdq 	64	TDP
[root@tdpdcsolmgr ~]# pvs |grep -i sdq
  /dev/sdq   smalogvg  lvm2 a--   64.00g   64.00g
  
[root@tdpdcsolmgr ~]# pvdisplay -m |grep -i sdq
  PV Name               /dev/sdq
  
[root@tdpdcsolmgr ~]# lsscsi|grep -i sdq
[3:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdq
[root@tdpdcsolmgr ~]# lsscsi |grep -i sdc
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc		appDisk1   64 GB   0:2
[root@tdpdcsolmgr ~]# lsscsi |grep -i sdg
[0:0:6:0]    disk    VMware   Virtual disk     1.0   /dev/sdg		appDisk5   64 GB   0:6
[root@tdpdcsolmgr ~]# lsscsi |grep -i sdm
[0:0:13:0]   disk    VMware   Virtual disk     1.0   /dev/sdm		appDisk9   64 GB   0:13


 --- Physical volume ---
  PV Name               /dev/sdq
  VG Name               smalogvg
  PV Size               64.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              16383
  Free PE               16383
  Allocated PE          0
  PV UUID               4BEa3H-CfWw-Jg1q-fUU5-SMxo-X30M-crCcR2

  --- Physical Segments ---
  Physical extent 0 to 16382:
    FREE

[root@tdpdcsolmgr ~]# pvscan |grep -i sdq
  PV /dev/sdq    VG smalogvg        lvm2 [64.00 GiB / 64.00 GiB free]

fatal: [tdpdcsolmgr.imzcloud.ibmammsap.local]: FAILED! => {"changed": true, "cmd": ["/home/ansible/sap-ops-process-8337/lvm/lvm_calculate.py", "checkdiskifactive", "{\\"/dev/sda\\":{\\"type\\":\\"null\\",\\"name\\":\\"root\\"},\\"/dev/sdj\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk8\\"},\\"/dev/sdk\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk14\\"},\\"/dev/sdl\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk15\\"},\\"/dev/sdm\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk9\\"},\\"/dev/sdn\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk10\\"},\\"/dev/sdo\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk11\\"},\\"/dev/sdb\\":{\\"type\\":\\"null\\",\\"name\\":\\"swap\\"},\\"/dev/sdc\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk1\\"},\\"/dev/sdd\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk2\\"},\\"/dev/sde\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk3\\"},\\"/dev/sdf\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk4\\"},\\"/dev/sdg\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk5\\"},\\"/dev/sdh\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk6\\"},\\"/dev/sdi\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk7\\"},\\"/dev/sdp\\":{\\"type\\":\\"null\\",\\"name\\":\\"appDisk12\\"}}", "appDisk13"], "delta": "0:00:00.051582", "end": "2023-11-15 07:06:19.825447", "msg": "non-zero return code", "rc": 1, "start": "2023-11-15 07:06:19.773865", "stderr": "", "stderr_lines": [], "stdout": "\\nRunning script..\\n\\nAction: Check if the target OPaaS storage is actively being used by the VM.\\n\\nChecking input file..\\n\\nFile /tmp/samuel-process-lvm-info.json found.\\n\\nChecking mapped data..\\n\\nERROR: Unable to get the VM disk of the OPaaS storage (appDisk13). It is possible that the storage is associated with a clustered disk or the OPaaS/VM disk mapping step couldn't map it.\\n\\nScript ended with exit code 1.", "stdout_lines": ["", "Running script..", "", "Action: Check if the target OPaaS storage is actively being used by the VM.", "", "Checking input file..", "", "File /tmp/samuel-process-lvm-info.json found.", "", "Checking mapped data..", "", "ERROR: Unable to get the VM disk of the OPaaS storage (appDisk13). It is possible that the storage is associated with a clustered disk or the OPaaS/VM disk mapping step couldn't map it.", "", "Script ended with exit code 1."]}
ERROR: Unable to get the VM disk of the OPaaS storage (appDisk13). It is possible that the storage is associated with a clustered disk or the OPaaS/VM disk mapping step couldn't map it.\\n\\nScript ended with exit code 1.", "stdout_lines": ["", "Running script..", "", "Action: Check if the target OPaaS storage is actively being used by the VM.", "", "Checking input file..", "", "File /tmp/samuel-process-lvm-info.json found.", "", "Checking mapped data..", "", "ERROR: Unable to get the VM disk of the OPaaS storage (appDisk13). It is possible that the storage is associated with a clustered disk or the OPaaS/VM disk mapping step couldn't map it.", "", "Script ended with exit code 1."]}




CHG0298988 CST/CDT - 11/18/2023 - 20:00 - NIX - LBU - PATCH - HC - VULN - Y2023- SAPB2 - Batch Group: PRD-2 (9 Servers)		approved
CHG0298989 CST/CDT - 11/18/2023 - 20:00 - NIX - LBU - PATCH - HC - VULN - Y2023- SAPB2 -  Batch Group: PRD-1 (9 Servers)	approved
CHG0298992 CST/CDT - 11/18/2023 - 20:00 - NIX - LBU - PATCH - HC - VULN - Y2023- SAPB2 - Batch Group: PRD-3 (7 Servers)		approved
CHG0298993 CST/CDT - 11/18/2023 - 20:00 - NIX - LBU - PATCH - HC - VULN - Y2023- SAPB2 - Batch Group: PRD-4 (9 Servers)		approved
CHG0298995 CST/CDT - 11/18/2023 - 20:00 - NIX - LBU - PATCH - HC - VULN - Y2023- SAPB2 - Batch Group: PRD-6 (7 Servers)		approved





CHG0302937	CST/CDT - 11/19/2023 - 20:00 - NIX - S5C - PATCH - HC - VULN - Y2023- SAPB1,SAPD1



CHG0303608    16-11-2023 07:30:00      16-11-2023 18:30:00

Patch Group (1) - br3dgtsdb55	SUSE	10.138.10.64	Development	DGT - SAP  (DB) - HANA
	Patch Group (1) - br3dsapa52	SUSE	10.138.10.28	Development	WDP - SAP  (App) - NA
Patch Group (1) - br3dscmdb56	SUSE	10.138.10.66	Development	DCM - SAP  (DB) - HANA
	Patch Group (1) - br3nfs-dev	SUSE	10.138.10.117	Development	NA - SAP  () - NA
	Patch Group (1) - br3dsapa50	SUSE	10.138.10.30	Development	D4H - SAP  (App) - NA
	Patch Group (1) - br3dscmas56	SUSE	10.138.10.130	Development	DCM - SAP  (App) - NA
	Patch Group (1) - br3scs-dev	SUSE	10.138.10.93	Development	DCS - SAP  (DB) - MAXDB
Patch Group (1) - br3dhana50	SUSE	10.138.10.27	Development	D4H - SAP  (DB) - HANA
	Patch Group (1) - br3dgtsas55	SUSE	10.138.10.60	Development	DGT - SAP  (App) - NA
	Patch Group (2) - br3ssapas10	SUSE	10.138.10.68	Development	SX4 - SAP  (App) - NA
	Patch Group (2) - br3sgtsas15	SUSE	10.138.10.61	Development	SGT - SAP  (App) - NA
Patch Group (2) - br3ssapdb10	SUSE	10.138.10.73	Development	SXH - SAP  (DB) - HANA
Patch Group (2) - br3sgtsdb15	SUSE	10.138.10.97	Development	SGT - SAP  (DB) - HANA



Health Check\Vulnerability remediation from Samuel - Known issues:


1. Python version error - Make sure the python version is 2.7 or SLES12, and 3.6 for SLES15

2. Cryptography error - Install the python cryptography package "zypper in python3-cryptography"

3. THP (Transparent huge pages) error - Make sure to disable THP (steps can be found in KB KB0016944 - page no 38 in the attachment)

4. "btrfs command not found" error - Make sure the env variable for btrfs in grun.cfg is set"
    # echo $btrfs_relative_path (if the path is empty, set using below command)
    # export btrfs_relative_path=/usr/sbin/btrfs
    
5. Auditd deamon error - Make sure the auditd service is started, if not, enable the server and reboot the server 
    # systemctl enable auditd
	

Set vm.swappiness=2 on all steady state vhana DB servers. Set vm.swappiness=10 on all steady state non-hana servers.
How to determine applicability:
Applicable to all SLES12 and SLES 15, RHEL 7 and RHEL 8 SAP machines. 
Check the current value:
cat /proc/sys/vm/swappiness
cat /etc/sysctl.conf | grep -i swappiness

	-------------------------------------------------------------------------------------------------------------
	
	b. On servers running RHEL 7 or SUSE 12 upwards, set the default gnome target to multi-user.

# systemctl get-default
graphical.target

# systemctl set-default multi-user.target

# systemctl isolate multi-user.target

# systemctl get-default 
multi-user.target


COmment fstab for HC
Commenting  multiple lines of fstab

to comment lines 2 through 4 of bla.conf:
sed -i '2,4 s/^/#/' ip.txt

to uncomment
sed -i '/'#'/s/^#//g' /etc/fstab	working to uncomment



sed -i '11,23 s/^/#/' /etc/fstab      # comments lines 11 to 23 in fstab

to uncomment

sed -i '11,23 /s/^#//g' /etc/fstab

Yes, to comment line containing specific string with sed, simply do:

sed -i '/<pattern>/s/^/#/g' file
And to uncomment it:

sed -i '/<pattern>/s/^#//g' file
In your case:

sed -i '/2001/s/^/#/g' file    (to comment out)
sed -i '/2001/s/^#//g' file    (to uncomment)



4.12.14-122.165

HC link  https://samuel.sap.adai.kyndryl.com/BR3/buildInformation?id=6555a201d2600dc3017e3aad&name=Overview



#CS14279612
mgggbjseccx04:/sapstage /sapstage2 nfs _netdev,defaults 0 0



CHG0299781 17-11-2023 07:30:00  17-11-2023 11:30:00
https://samuel.sap.adai.kyndryl.com/PN5/buildInformation?id=651440422700536f009941e5


Patch Group (1.1) - penat15sl  --A0EUUS014XVM002	Redhat	10.4.8.11	Development	<SID> - SAP <Landscape> (App/DB) - DB2
Patch Group () - pn5penat15sl2	Redhat	10.4.8.9	Development	<SID> - SAP <Landscape> (App)


CHG0304339	CST/CDT - 11/17/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1	approved
CHG0304340	CST/CDT - 11/17/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1	approved
CHG0304341	CST/CDT - 11/17/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1	approved
CHG0304351	CST/CDT - 11/18/2023 - 19:00 - NIX - SM9 - PATCH - HC - VULN - Y2023- SAPB1,SAPD1	approved




CHG0302679 18-11-2023 06:30:00  18-11-2023 10:30:00
IA1HCIPRDAPP	10.133.15.23  CTASK0842549



CHG0304349	19-11-2023 06:30:00   19-11-2023 18:30:00

	Patch Group (Prod3B) - sm9l182172003	SUSE	10.135.224.63	Production	ECP - SAP  (DB) - DB2	root login enabled		moved mv rear-initrd.cgz /var
	Patch Group (Prod3B) - sm9h182172003	SUSE	10.135.224.69	Production	ECP - SAP  (DB) - DB2	root login enabled		moved mv rear-initrd.cgz /var
	
	Patch Group (Prod3B) - sm9a182172008	SUSE	10.135.224.11	Production	ECP - SAP  (App) - NA		snap	done patch
	
	Patch Group (Prod3B) - sm9a182172007	SUSE	10.135.224.12	Production	ECP - SAP  (App) - NA		snap	done patch

	Patch Group (Prod3B) - sm9l182172004	SUSE	10.135.224.19	Production	ECP - SAP  (App) - NA		snap	done patch	ascs
	Patch Group (Prod3B) - sm9h182172004	SUSE	10.135.224.18	Production	ECP - SAP  (App) - NA		snap	done patch	ers
	
	Patch Group (Prod3A) - sm9l182172005	SUSE	10.135.224.51	Production	BWP - SAP  (DB) - DB2		done	done patch	moved mv rear-initrd.cgz /var
	Patch Group (Prod3A) - sm9h182172005	SUSE	10.135.224.54	Production	BWP - SAP  (DB) - DB2		done	done patch	moved mv rear-initrd.cgz /var


	Patch Group (Prod3A) - sm9l182172006	SUSE	10.135.224.55	Production	BWP - SAP  (App) - NA		snap	done patch
	Patch Group (Prod3A) - sm9h182172006	SUSE	10.135.224.46	Production	BWP - SAP  (App) - NA		snap	done patch


presnap  https://samuel.sap.adai.kyndryl.com/SM9/buildInformation?id=6559633524701c669b3b6833&name=Overview
HC https://samuel.sap.adai.kyndryl.com/SM9/buildInformation?id=65599f9f6d442ddfae587089&name=Overview

screen -S CHG0304349     # RaviM could be any name for referring to the session
 
to get back the sesssion
[root@bapv110100 ~]# screen -list
There are screens on:
        128135.RaviM    (Attached)
        107347.RaviM    (Attached)
2 Sockets in /var/run/screens/S-root.


to connect to any session use
screen -x 128135.RaviM    # name from the output above

crm resource clear g-ascs` to remove this constraint

crm resource clear group_db2_ecp    to remove this constraint




zip -r /tmp/az3nfsbwp_sap_log $(find . -type f -mtime +85)


CHG0299482	CST/CDT - 11/24/2023 - 10:00 - NIX - ZFF - PATCH - Y2023- SAPB1,SAPD1		approved
CHG0303112	CST/CDT - 11/26/2023 - 20:00 - NIX - S5C - PATCH - HC - VULN - Y2023- SAPB1,SAPD1



  ACTIVE            '/dev/vg-EFP-NFS/sapmntefp' [183.00 GiB] inherit
  ACTIVE            '/dev/vg-EFP-NFS/saptrans' [45.00 GiB] inherit
  ACTIVE            '/dev/vg-BWP-NFS/sapmntbwp' [85.00 GiB] inherit
  ACTIVE            '/dev/vg-BWP-NFS/saptrans' [50.00 GiB] inherit


/dev/vg-BWP-NFS/sapmntbwp	/az3nfsbwp/generic      xfs _netdev,defaults 0 0 
/dev/vg-BWP-NFS/saptrans   /az3nfsbwp/sap 			xfs _netdev,defaults 0 0 
/dev/vg-EFP-NFS/sapmntefp	/az3nfsefp/generic  	xfs _netdev,defaults 0 0     
/dev/vg-EFP-NFS/saptrans   /az3nfsefp/sap  			xfs _netdev,defaults 0 0 




No new ticket

fixed by updating the fstab with missing FS entries and mounting the folders as lvbased FS
Ref master ticket CS14298777



/usr/local/sap/log/patch/patch_list_Nov_02_2023.txt




CS14303371
ZFF
PROD DC	Frankfurt 02
DR DC	Paris




10.207.63.101
10.207.63.11
10.207.63.66
10.207.63.185


change approval

CHG0305030
CHG0301890	

 zffpapp001
 OK
15 minutes
 ammpar01vcs001.imzcloud.ibmammsap.local
 ammpar01vrc001
ZFF - ZF Friedrichshafen PG1

ZFFPAR01DSE220DR

 Object 'GID-0ee6c5f0-6087-41fd-a16c-777353373eda' is locked by another ongoing operation in vSphere Replication Management Server. Try again later.
 
 
 
 zffpdb001
 OK
30 minutes
 ammpar01vcs001.imzcloud.ibmammsap.local
 ammpar01vrc001
ZFF - ZF Friedrichshafen PG1


Add back  zffpdb001-ha   to ZFF - ZF Friedrichshafen PG1 PG


CS14323723
ESXi host: dal13-pod1-6tb-host006.imzcloud.ibmammsap.local
There is a failed DIMM
 
krrdbprd11-dr -->> Affected VM
lnasv139-ha -->> No outage yet
lnasv205br -->> No outage yet
lnasv211 -->> No outage yet
lnasv258 -->> No outage yet



CHG0299895	Takasago International Corporation -- TI3  Linux	12/1/2023   20:00
CHG0299894	Takasago International Corporation -- TI3  Linux	12/16/2023   20:00




Patch Group () - ti3s4qdb02	Redhat	10.7.115.27	Development	<SID> - SAP <Landscape> () - HDB

Patch Group () - ti3s4dap02	Redhat	10.7.115.22	Development	<SID> - SAP <Landscape> ()


10.7.115.6

/mnt/c/Users/RaviMALIK/Downloads/Downloads/prechecks



[root@ti3s4qdb02 usr]# ls -ltr
total 176
lrwxrwxrwx.   1 root root    10 Aug 12  2018 tmp -> ../var/tmp
drwxr-xr-x.   2 root root  4096 Aug 12  2018 games
drwx------.   2 root root 16384 Feb 10  2021 lost+found
drwxr-xr-x.   4 root root  4096 Feb 10  2021 src
drwxr-xr-x.  37 root root  4096 Feb 10  2021 include
drwxr-xr-x.  13 root root  4096 Feb 16  2021 local
drwxr-xr-x. 131 root root  4096 May 23  2023 share
drwxr-xr-x.  40 root root  4096 May 23  2023 libexec
dr-xr-xr-x.  38 root root  4096 May 23  2023 lib
dr-xr-xr-x.  70 root root 69632 Jul 21 08:47 lib64
dr-xr-xr-x.   2 root root 20480 Aug 10 11:27 sbin
dr-xr-xr-x.   2 root root 36864 Sep 28 22:01 bin
drwxr-xr-x.   8 root root   173 Dec  2 08:42 sap
[root@ti3s4qdb02 usr]# cd tmp
[root@ti3s4qdb02 tmp]# pwd
/usr/tmp
[root@ti3s4qdb02 tmp]# df -hT .
Filesystem                Type  Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-vartmp ext4  2.0G  201M  1.6G  11% /var/tmp


#/dev/mapper/rootvg-usrlv /usr                    ext4    defaults        1 2

CHG0298435	CST/CDT - 12/10/2023 - 20:00 - NIX - SZU - PATCH - HC - VULN - Y2023- SAPB1,SAPD1
CHG0298432	CST/CDT - 12/10/2023 - 20:00 - NIX - SZU - PATCH - HC - VULN - Y2023- SAPB1,SAPD1
 
 
 
Nippon
Axis


CHG0299219	Tokyo Seimitsu Co., Ltd. -- TSM   Linux	   12/8/2023   19:00
CHG0304944	Tecnicas Reunidas S.A. -- TRE     Linux	   12/10/2023  10:00
CHG0304945	Tecnicas Reunidas S.A. -- TRE     Linux	   12/10/2023  10:00


CHG0304948	Tecnicas Reunidas S.A. -- TRE    Linux	  12/13/2023   10:00
CHG0304950	Tecnicas Reunidas S.A. -- TRE    Linux	  12/14/2023   10:00

CHG0304955 & CHG0304957



eUd@yE3bC@eQJ!r

/usr/local/bin/enable_dr_3.x.py

CHG0304955	Tecnicas Reunidas S.A. -- TRE    Linux	  12/17/2023   10:00

CHG0302627	


CHG0299220	Tokyo Seimitsu Co., Ltd. -- TSM    Linux	12/9/2023   19:00
CHG0299221	Tokyo Seimitsu Co., Ltd. -- TSM    Linux	12/15/2023  19:00






CHG0305801 - CST/CDT - 12/07/2023 - 10:00 - NIX - ZFF - PATCH - Y2023- SAPB1,SAPD1


CHG0305995


CS14353257   printer
PRD:
sapapp31 10.207.61.84 10.170.61.40
sapapp31-ha 10.207.61.222 10.170.61.123
SAPAPP21 10.207.61.80 10.170.61.131
SAPAPP15 10.207.61.37 10.170.61.121
SAPAPP18 10.207.61.70 10.170.61.116
SAPAPP19 10.207.61.215 10.170.61.74
SAPAPP20 10.207.61.195 10.170.61.48
SAPAPP23 10.207.61.130 10.170.61.226
SAPAPP26 10.207.61.48 10.170.61.176
SAPAPP27 10.207.61.47 10.170.61.166
SAPAPP28 10.207.61.58 10.170.61.211


SAPAPP29 10.207.61.85 10.170.61.141
SAPAPP30 10.207.61.95 10.170.61.161
SAPAPP32 10.207.61.46 10.170.61.52
SAPAPP33 10.207.61.235 10.170.61.88
SAPAPP34 10.207.61.230 10.170.61.94
SAPAPP35 10.207.61.39 10.170.61.62
SAPAPP36 10.207.61.197 10.170.61.115
SAPAPP37 10.207.61.156 10.170.61.107


SAPAPP38 10.207.61.134 10.170.61.237
SAPAPP39 10.207.61.167 10.170.61.212
SAPAPP40 10.207.61.149 10.170.61.252
SAPAPP41 10.207.61.151 10.170.61.248
SAPAPP42 10.207.61.242 10.170.61.139
SAPAPP43 10.207.61.152


QAS:
TGCS4HMAP3 10.207.63.101


printer ip 172.28.170.53
queue TSL_GAM

172.28.170.53  TSL_GAM

lpstat -t |grep -i TSL_GAM
echo "172.28.170.53  TSL_GAM" >> /etc/hosts
lpadmin -p TSL_GAM -v lpd://172.28.170.53 -E
cupsenable TSL_GAM
cupsaccept TSL_GAM
cat /etc/hosts |grep -i TSL_GAM
lpstat -t |grep -i TSL_GAM


ping 172.28.170.53

cat /etc/hosts |grep -i 172.28.170.53;lpstat -t |grep -i NPI99930C;echo "172.28.170.53  NPI99930C" >> /etc/hosts;cat /etc/hosts |grep -i NPI99930C;lpadmin -p NPI99930C -v lpd://172.28.170.53 -E;lpstat -t |grep -i NPI99930C;cupsenable NPI99930C;cupsaccept NPI99930C


NPI99930C

Printer hostname - NPI99930C
Printer model- HP LaserJet M507
Printer ip - ( 172.28.170.53)


CS14353257

sed -i 's/TSL_GAM/NPI99930C/g' /etc/hosts

cat /etc/hosts |grep -i TSL_GAM;cat /etc/hosts |grep -i NPI99930C;sed -i 's/TSL_GAM/NPI99930C/g' /etc/hosts;cat /etc/hosts |grep -i TSL_GAM;cat /etc/hosts |grep -i NPI99930C;lpstat -t |grep -i TSL_GAM;lpadmin -x TSL_GAM;lpadmin -p NPI99930C -v lpd://172.28.170.53 -E;cupsenable NPI99930C;cupsaccept NPI99930C;lpstat -t |grep -i NPI99930C




lpadmin -p NPI99930C -v lpd://172.28.170.53 -E

lpr -P NPI99930C /usr/share/cups/data/testprint      to give a test print

lpstat -W completed					to check if the print is successful

[root@sapapp43 ~]# lpr -P NPI99930C /usr/share/cups/data/testprint
[root@sapapp43 ~]# cat /var/log/cups/error_log

ErrorLog /var/log/cups/error_log
AccessLog /var/log/cups/access_log
PageLog /var/log/cups/page_log


E [07/Dec/2023:21:37:46 +0530] [Job 1] Print job was not accepted.

E [08/Dec/2023:00:00:01 +0530] Unable to open listen socket for address [v1.::1]:631 - Cannot assign requested address.
E [08/Dec/2023:13:26:04 +0530] [cups-driverd] Unable to open \"/usr/share/cups/model/ppd\" - No such file or directory
E [08/Dec/2023:13:26:04 +0530] [Client 8] Returning IPP client-error-not-possible for CUPS-Add-Modify-Printer (ipp://localhost:631/printers/NPI99930C) from localhost
E [08/Dec/2023:13:26:15 +0530] [cups-driverd] Unable to open \"/usr/share/cups/model/ppd\" - No such file or directory
E [08/Dec/2023:13:26:15 +0530] [cups-driverd] Unable to open \"/usr/share/cups/model/ppd\" - No such file or directory
E [08/Dec/2023:13:26:15 +0530] copy_model: empty PPD file
E [08/Dec/2023:13:26:15 +0530] [Client 15] Returning IPP server-error-internal-error for CUPS-Add-Modify-Printer (ipp://localhost:631/printers/NPI99930C) from localhost


Go to the network set up on the printer and to network services , disable ipv6 (turn off)

Go to Link speed (still within network set up menu) and change to 100TX full 

systemctl stop firewalld.service

Step 1: disable the firewall
Step 2: configure the printer
Step 3: re-enable the firewall.

ask any user in that office to connect to other server and see if they can print


sapapp37
sapapp34



srthrqappdb		10.71.74.46, patching failed for this system, the server does not boot with new kernel and as customer did not approve extension, we started SAP and as per DPE this will be re-scheduled to later date
[root@srthrqappdb ~]# uname -a
Linux srthrqappdb 4.12.14-122.176-default #1 SMP Wed Sep 6 13:47:43 UTC 2023 (4766b7f) x86_64 x86_64 x86_64 GNU/Linux
[root@srthrqappdb ~]# rpm -qa --last
ds_agent-20.0.0-8268.SuSE_12.x86_64           Thu Nov 23 16:23:00 2023
saptune-3.1.0-4.15.1.x86_64                   Wed Nov 22 19:36:48 2023
webkit2gtk-4_0-injected-bundles-2.40.5-2.146.1.x86_64 Wed Nov 22 19:36:47 2023
[root@srthrqappdb ~]# uptime
 08:51am  up 19 days 13:11,  2 users,  load average: 0.17, 0.27, 0.26

Patched on 22 Nov



Patch Group () - s1kscpdbci-dr		10.191.51.6	SUSE	10.191.51.6	Production	<Landscape> <SID> (App/DB)
[root@s1kscpdbci-dr ~]# uptime
 03:28:42  up 18 days 13:01,  2 users,  load average: 0.06, 0.11, 0.12
[root@s1kscpdbci-dr ~]# rpm -qa --last
cloud-regionsrv-client-plugin-azure-2.0.0-150000.6.99.1.noarch Thu Nov 23 14:11:36 2023
cloud-regionsrv-client-addon-azure-1.0.5-150000.6.99.1.noarch Thu Nov 23 14:11:36 2023
cloud-regionsrv-client-10.1.3-150000.6.99.1.noarch Thu Nov 23 14:11:33 2023
cluster-md-kmp-default-5.14.21-150400.24.97.1.x86_64 Thu Nov 23 14:11:31 2023
gfs2-kmp-default-5.14.21-150400.24.97.1.x86_64 Thu Nov 23 14:11:29 2023
ocfs2-kmp-default-5.14.21-150400.24.97.1.x86_64 Thu Nov 23 14:11:28 2023
python3-pysmbc-1.0.23-150400.6.69.x86_64      Thu Nov 23 14:11:26 2023
dlm-kmp-default-5.14.21-150400.24.97.1.x86_64 Thu Nov 23 14:11:26 2023

patched on 23 Nov


Patch Group () - s1ksppdbci-dr	SUSE	10.191.51.5	Production	<Landscape> <SID> (App/DB)
[ibmrmalik@s1ksppdbci-dr ~]$ uptime
 03:48:14  up 18 days 13:21,  1 user,  load average: 0.61, 0.30, 0.21
[ibmrmalik@s1ksppdbci-dr ~]$ uname -a
Linux s1ksppdbci-dr 5.14.21-150400.24.97-default #1 SMP PREEMPT_DYNAMIC Fri Oct 27 10:29:06 UTC 2023 (8546fda) x86_64 x86_64 x86_64 GNU/Linux
[ibmrmalik@s1ksppdbci-dr ~]$ rpm -qa --last |less
cloud-regionsrv-client-plugin-azure-2.0.0-150000.6.99.1.noarch Thu Nov 23 14:11:47 2023
cloud-regionsrv-client-addon-azure-1.0.5-150000.6.99.1.noarch Thu Nov 23 14:11:47 2023

Patched on 23 Nov

Patch Group () - s1ksbpdbci-dr	SUSE	10.191.51.4	Production	<Landscape> <SID> (App/DB)
[root@s1ksbpdbci-dr ~]# uptime
 03:47:37  up 18 days 13:20,  2 users,  load average: 0.33, 0.24, 0.20
[root@s1ksbpdbci-dr ~]# uname -a
Linux s1ksbpdbci-dr 5.14.21-150400.24.97-default #1 SMP PREEMPT_DYNAMIC Fri Oct 27 10:29:06 UTC 2023 (8546fda) x86_64 x86_64 x86_64 GNU/Linux
[root@s1ksbpdbci-dr ~]# rpm -qa --last |less
cloud-regionsrv-client-plugin-azure-2.0.0-150000.6.99.1.noarch Thu Nov 23 14:11:15 2023
cloud-regionsrv-client-addon-azure-1.0.5-150000.6.99.1.noarch Thu Nov 23 14:11:15 2023

pateched on 23 Nov





check patching status for zffnappdb013	

[root@zffnappdb013 ~]# uname -a
Linux zffnappdb013 4.12.14-122.176-default #1 SMP Wed Sep 6 13:47:43 UTC 2023 (4766b7f) x86_64 x86_64 x86_64 GNU/Linux
[root@zffnappdb013 ~]# uptime
 07:31am  up 25 days  7:53,  4 users,  load average: 0.35, 0.35, 0.39
[root@zffnappdb013 ~]# rpm -qa --last
ds_agent-20.0.0-8268.SuSE_12.x86_64           Thu Nov 23 17:51:13 2023
saptune-3.1.0-4.15.1.x86_64                   Thu Nov 16 18:41:01 2023

Patched on16 Nov



check patching status for -- Patch Group () - zffsappdb007	SUSE	100.126.67.25	Development	ES1, ES0, ES3 - SAP <Landscape> (App/DB)

[root@zffsappdb007 ~]# uptime
 07:24am  up 4 days 12:13,  2 users,  load average: 0.82, 1.32, 1.59
[root@zffsappdb007 ~]# rpm -qa --last
typelib-1_0-WebKit2-4_0-2.40.5-2.146.1.x86_64 Thu Dec  7 19:07:34 2023
saptune-3.1.0-4.15.1.x86_64                   Thu Dec  7 19:07:34 2023

Patched on 7th Dec





CHG0305443	CST/CDT - 12/17/2023 - 20:00 - NIX - S5C - HC - VULN - Y2023- SAPB1,SAPD1



CHG0304554	Dilip Buildcon Limited -- DB1 (AWS)   Linux	12/16/2023   11:30
CHG0304556	Dilip Buildcon Limited -- DB1 (AWS)   Linux	12/16/2023   11:30




SBD_DEVICE="/dev/disk/by-id/scsi-360014057e1e3a0128ce4b37b79e6c466;/dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00;/dev/disk/by-id/scsi-3600140594852f6a277648f49ff5000c1;"

[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-360014057e1e3a0128ce4b37b79e6c466 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1

[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1
sbd -d == Slots on disk /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 NOT dumped
sbd failed; please check the logs.

[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-3600140594852f6a277648f49ff5000c1 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1

[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-360014057e1e3a0128ce4b37b79e6c466 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1
[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1
sbd -d == Slots on disk /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 NOT dumped
sbd failed; please check the logs.
[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-3600140594852f6a277648f49ff5000c1 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1

CHG0306572  sssd 

Dec 13 18:24:01 [11244] vhsjpcs1 stonith-ng:   notice: initiate_remote_stonith_op:      Requesting peer fencing (reboot) targeting vhsjpcs2 | id=3865f446-8a02-430f-80f6-61cd073b6709 state=0

[root@vhsjpcs1 log]# cat messages |grep -i "Dec 13 18:24*"




CHG0306436
10.15.81.22	Disk name /dev/sde is not utilized. The disk size is 32G 	 /dev/sde 	32	done
[root@gknfioridev ~]$ lsscsi |grep -i sde
[0:0:4:0]    disk    VMware   Virtual disk     1.0   /dev/sde
[root@gknfioridev ~]$ pvdisplay -m /dev/sde
  Failed to find physical volume "/dev/sde".
[root@gknfioridev ~]$ blkid /dev/sde

 PV         VG        Fmt  Attr PSize   PFree
  /dev/sda2  rootvg    lvm2 a--   63.49g  3.06g
  /dev/sdb   rootvg    lvm2 a--   50.00g 14.00g
  /dev/sdc   nwddatavg lvm2 a--   32.00g     0		[0:0:2:0]	
  /dev/sdd1  nwddatavg lvm2 a--   16.00g 16.00g
  /dev/sdf   nwdlogvg  lvm2 a--   32.00g 12.00g		[0:0:5:0]
  /dev/sdg   nwdarchvg lvm2 a--   64.00g 47.00g
  /dev/sdh   nwddatavg lvm2 a--  128.00g 11.99g
  /dev/sdi   nwdappvg  lvm2 a--  200.00g 54.00g

[root@gknfioridev ~]$ lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdb
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[0:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sdd
[0:0:4:0]    disk    VMware   Virtual disk     1.0   /dev/sde
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf
[0:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdg
[3:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdh
[3:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdi





10.15.81.21	Disk name /dev/sdc is not utilized. The disk size is 100G 	 /dev/sdc 	100		done
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdc

fatal: [gknadsdev.imzcloud.ibmammsap.local]: FAILED! => {"changed": true, "cmd": ["/home/ansible/sap-ops-process-5875/lvm/lvm_calculate.py", "checkdiskifactive", "{\\"/dev/sda\\":{\\"type\\":\\"Performance\\",\\"name\\":\\"root\\"},\\"/dev/sdd\\":{\\"type\\":\\"Performance\\",\\"name\\":\\"appDisk2\\"},\\"/dev/sdb\\":{\\"type\\":\\"Performance\\",\\"name\\":\\"swap\\"},\\"/dev/sde\\":{\\"type\\":\\"Performance\\",\\"name\\":\\"appDisk3\\"},\\"/dev/sdg\\":{\\"type\\":\\"Performance\\",\\"name\\":\\"appDisk5\\"},\\"/dev/sdf\\":{\\"type\\":\\"Performance\\",\\"name\\":\\"appDisk4\\"}}", "appDisk1"], "delta": "0:00:00.034810", "end": "2023-12-13 23:26:57.311209", "msg": "non-zero return code", "rc": 1, "start": "2023-12-13 23:26:57.276399", "stderr": "", "stderr_lines": [], "stdout": "\\nRunning script..\\n\\nAction: Check if the target OPaaS storage is actively being used by the VM.\\n\\nChecking input file..\\n\\nFile /tmp/samuel-process-lvm-info.json found.\\n\\nChecking mapped data..\\n\\nERROR: Unable to get the VM disk of the OPaaS storage (appDisk1). It is possible that the storage is associated with a clustered disk or the OPaaS/VM disk mapping step couldn't map it.\\n\\nScript ended with exit code 1.", "stdout_lines": ["", "Running script..", "", "Action: Check if the target OPaaS storage is actively being used by the VM.", "", "Checking input file..", "", "File /tmp/samuel-process-lvm-info.json found.", "", "Checking mapped data..", "", "ERROR: Unable to get the VM disk of the OPaaS storage (appDisk1). It is possible that the storage is associated with a clustered disk or the OPaaS/VM disk mapping step couldn't map it.", "", "Script ended with exit code 1."]}



10.15.81.20	Disk name /dev/sdj is not utilized. The disk size is 64G 	 /dev/sdj 	64	[0:0:10:0]	appDisk5	done
10.15.81.20	Disk name /dev/sdi is not utilized. The disk size is 64G 	 /dev/sdi 	64	[0:0:9:0]	appDisk4	done
10.15.81.20	Disk name /dev/sdh is not utilized. The disk size is 64G 	 /dev/sdh 	64	[0:0:8:0]	appDisk8
10.15.81.20	Disk name /dev/sdg is not utilized. The disk size is 64G 	 /dev/sdg 	64	[0:0:6:0]	appDisk2	Done

[root@gknsoldev ~]$ lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdb
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[0:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sdd
[0:0:4:0]    disk    VMware   Virtual disk     1.0   /dev/sde
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf
[0:0:6:0]    disk    VMware   Virtual disk     1.0   /dev/sdg
[0:0:8:0]    disk    VMware   Virtual disk     1.0   /dev/sdh
[0:0:9:0]    disk    VMware   Virtual disk     1.0   /dev/sdi
[0:0:10:0]   disk    VMware   Virtual disk     1.0   /dev/sdj
[0:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdk
[0:0:12:0]   disk    VMware   Virtual disk     1.0   /dev/sdl
[0:0:13:0]   disk    VMware   Virtual disk     1.0   /dev/sdm
[0:0:14:0]   disk    VMware   Virtual disk     1.0   /dev/sdn
[1:0:0:0]    cd/dvd  NECVMWar VMware SATA CD00 1.00  /dev/sr0



CHG0306281	Kuraray C. Ltd -- KRR   Linux	 12/26/2023     22:00



CHG0305751	Gulf States Toyota -- GLT  Linux	12/23/2023    20:00



CS14380134 

#Ansible: cron job
29,59 * * * * "/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh" > /var/opt/ansible/GTS/ILMT/logs/crontab.log 2>&1
0 2 * * 6 /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT

25,55 * * * * /usr/bin/sudo "/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh" > /var/opt/ansible/GTS/ILMT/logs/crontab.log 2>/dev/null
0 2 * * 6 /usr/bin/sudo /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT 2>/dev/null

[root@daldltqeahdb1 ~]# cat /var/opt/ansible/GTS/ILMT/work/computer.yml
endpointID: daldltqeahdb1-1677133823
Agent Version: 9.2.30.0
Catalog Version: 1313082.0
Operating System: LINUX SUSE Linux Enterprise Server 15 SP2 x86_64 64
DNS Name: daldltqeahdb1
Computer Name: daldltqeahdb1
IP Address:  10.143.69.181
 10.4.5.140
 10.250.17.140
vmmanagerPresent:
vtechEnabled: false



CHG0301057	Gulf States Toyota -- GLT     Linux	12/23/2023     20:00



CS14382572 TTA pw proof     tsls4proddb:/etc/pam.d # pwd
cat /etc/pam.d/common-password-pc

tsls4proddb
tsls4proddb:~ # cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

tsls4proddbh
tsls4proddbh:~ # cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp15
[root@sapapp15 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp18
[root@sapapp18 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp19
[root@sapapp19 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp20
[root@sapapp20 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp21
[root@sapapp21 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp23
[ibmrmalik@sapapp23 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp26
[ibmrmalik@sapapp26 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp27
[ibmrmalik@sapapp27 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp28
[root@sapapp28 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp29
[ibmrmalik@sapapp29 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp30
[ibmrmalik@sapapp30 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapcrmapp3
[ibmrmalik@sapcrmapp3 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
password        requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password        required        pam_pwhistory.so        remember=8
password        optional        pam_gnome_keyring.so    use_authtok
password        sufficient      pam_unix.so     use_authtok nullok shadow try_first_pass
password        required        pam_sss.so      use_authtok


ewmapp1
[root@ewmapp1 ~]$ cat /etc/pam.d/common-password-pc
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
password        requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password        required        pam_pwhistory.so        remember=8
password        optional        pam_gnome_keyring.so    use_authtok
password        sufficient      pam_unix.so     use_authtok nullok shadow try_first_pass
password        required        pam_sss.so      use_authtok


sapapp31
[root@sapapp31 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp31-ha
[root@sapapp31-ha ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapcrmapp4
[root@sapcrmapp4 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
password        requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password        required        pam_pwhistory.so        remember=8
password        optional        pam_gnome_keyring.so    use_authtok
password        sufficient      pam_unix.so     use_authtok nullok shadow try_first_pass
password        required        pam_sss.so      use_authtok


sapcrmapp4-ha
[root@sapcrmapp4-ha ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
password        requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password        required        pam_pwhistory.so        remember=8
password        optional        pam_gnome_keyring.so    use_authtok
password        sufficient      pam_unix.so     use_authtok nullok shadow try_first_pass
password        required        pam_sss.so      use_authtok

ewmapp3
[root@ewmapp3 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
password        requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password        required        pam_pwhistory.so        remember=8
password        optional        pam_gnome_keyring.so    use_authtok
password        sufficient      pam_unix.so     use_authtok nullok shadow try_first_pass
password        required        pam_sss.so      use_authtok


ewmapp3-ha
[root@ewmapp3-ha ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
password        requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password        required        pam_pwhistory.so        remember=8
password        optional        pam_gnome_keyring.so    use_authtok
password        sufficient      pam_unix.so     use_authtok nullok shadow try_first_pass
password        required        pam_sss.so      use_authtok


sapapp32
[root@sapapp32 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp33
[root@sapapp33 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp34
[root@sapapp34 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp35
[root@sapapp35 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp36
[root@sapapp36 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp37
[root@sapapp37 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp38
[root@sapapp38 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp39
[root@sapapp39 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp40
[root@sapapp40 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp41
[root@sapapp41 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


sapapp42
[root@sapapp42 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok

sapapp43
[root@sapapp43 ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
# Updated by Ansible
#
# This file is autogenerated by pam-config. All manual
# changes will be overwritten!
#
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so use_authtok remember=8
password   optional pam_gnome_keyring.so use_authtok
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok


ttagrcprd
[root@ttagrcprd ~]# cat /etc/pam.d/common-password-pc
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
password        requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password        required        pam_pwhistory.so        remember=8
password        optional        pam_gnome_keyring.so    use_authtok
password        sufficient      pam_unix.so     use_authtok nullok shadow try_first_pass
password        required        pam_sss.so      use_authtok



rsc_stonith-sbd_start_0 on vht2qdb1 'unknown error' (1): call=590, status=Error, exitreason='',
    last-rc-change='Thu Dec 14 23:22:37 2023', queued=0ms, exec=27516ms
	
	
9975073735 



Can someone help me with the next scan op for 
ttaetdpapp	CHE01	SUSE Linux Enterprise Server for SAP Applications 15 SP2 15.2	10.207.61.99
tgcwdpapp	CHE01	SUSE Linux Enterprise Server for SAP Applications 15 SP2 15.2	10.207.61.139
tgcwddapp	CHE01	SUSE Linux Enterprise Server for SAP Applications 15 SP2 15.2	10.207.62.101
 
Part of the CS14358910


CS14380134
CS14380055



Hostname: AHECPHDB01DR
IP: 10.12.1.10
kyndryl#1



intsv011 10.7.217.34 - login issue

AJhQukk(9MhqjM5


sapapp18		10.207.61.70
sapapp34		10.207.61.230
sapapp35		10.207.61.39
sapapp36		10.207.61.197

Please confirm once done.

 

Printer Model Name                 : CanoniR3225 PCL5e

Printer IP                                      : 132.147.10.160

Printer Hostname                       :  CanonDCD16B

 lpadmin -p CanonDCD16B -v lpd://132.147.10.160 -E
 
 
 CS14379667  printer config sandeep
 CS14395292  
 
 
 
 
mm9ufphndbdr	i-0e1f1898a59356b58		10.191.50.9			
 
mm9uephndbdr    i-090bfed0ba996d095		10.191.50.46





[root@vhsjpcs1 log]# zcat messages-20231217.gz |grep -i "Requesting peer fencing (reboot)"
Dec 13 18:24:01 vhsjpcs1 stonith-ng[11244]:  notice: Requesting peer fencing (reboot) targeting vhsjpcs2

Dec 13 18:24:00 vhsjpcs1 corosync[11205]:  [TOTEM ] A new membership (10.136.64.11:140) was formed. Members left: 2
Dec 13 18:24:00 vhsjpcs1 corosync[11205]:  [TOTEM ] Failed to receive the leave message. failed: 2
Dec 13 18:24:00 vhsjpcs1 sbd[11198]:   cluster:  warning: set_servant_health: Connected to corosync but requires both nodes present
Dec 13 18:24:00 vhsjpcs1 attrd[11246]:  notice: Node vhsjpcs2 state is now lost
Dec 13 18:24:00 vhsjpcs1 attrd[11246]:  notice: Removing all vhsjpcs2 attributes for peer loss
Dec 13 18:24:00 vhsjpcs1 attrd[11246]:  notice: Purged 1 peer with id=2 and/or uname=vhsjpcs2 from the membership cache
Dec 13 18:24:00 vhsjpcs1 sbd[11193]: warning: inquisitor_child: cluster health check: UNHEALTHY
Dec 13 18:24:00 vhsjpcs1 sbd[11193]: warning: inquisitor_child: Servant cluster is outdated (age: 7624081)
Dec 13 18:24:00 vhsjpcs1 corosync[11205]:  [QUORUM] Members[1]: 1
Dec 13 18:24:00 vhsjpcs1 corosync[11205]:  [MAIN  ] Completed service synchronization, ready to provide service.
Dec 13 18:24:00 vhsjpcs1 crmd[11248]:  notice: Node vhsjpcs2 state is now lost
Dec 13 18:24:00 vhsjpcs1 crmd[11248]: warning: Stonith/shutdown of node vhsjpcs2 was not expected
Dec 13 18:24:00 vhsjpcs1 pacemakerd[11230]:  notice: Node vhsjpcs2 state is now lost
Dec 13 18:24:00 vhsjpcs1 cib[11243]:  notice: Node vhsjpcs2 state is now lost
Dec 13 18:24:00 vhsjpcs1 cib[11243]:  notice: Purged 1 peer with id=2 and/or uname=vhsjpcs2 from the membership cache
Dec 13 18:24:00 vhsjpcs1 crmd[11248]:  notice: State transition S_IDLE -> S_POLICY_ENGINE
Dec 13 18:24:00 vhsjpcs1 crmd[11248]: warning: Stonith/shutdown of node vhsjpcs2 was not expected
Dec 13 18:24:00 vhsjpcs1 crmd[11248]:  notice: Updating quorum status to true (call=9313)
Dec 13 18:24:00 vhsjpcs1 stonith-ng[11244]:  notice: Node vhsjpcs2 state is now lost
Dec 13 18:24:00 vhsjpcs1 stonith-ng[11244]:  notice: Purged 1 peer with id=2 and/or uname=vhsjpcs2 from the membership cache
Dec 13 18:24:01 vhsjpcs1 pengine[11247]:  notice: On loss of CCM Quorum: Ignore
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Cluster node vhsjpcs2 will be fenced: peer is no longer part of the cluster
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Node vhsjpcs2 is unclean
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Processing failed monitor of stonith-sbd on vhsjpcs1: unknown error
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Processing failed start of stonith-sbd on vhsjpcs2: unknown error
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Forcing stonith-sbd away from vhsjpcs1 after 3 failures (max=3)
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Action fs-scs_lv_stop_0 on vhsjpcs2 is unrunnable (offline)
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Action nc-sjp-scs_stop_0 on vhsjpcs2 is unrunnable (offline)
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Action ip-sjp-scs_stop_0 on vhsjpcs2 is unrunnable (offline)
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Action rsc_sap_SJP_SCS01_stop_0 on vhsjpcs2 is unrunnable (offline)
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Scheduling Node vhsjpcs2 for STONITH
Dec 13 18:24:01 vhsjpcs1 pengine[11247]:  notice:  * Fence (reboot) vhsjpcs2 'peer is no longer part of the cluster'
Dec 13 18:24:01 vhsjpcs1 pengine[11247]:  notice:  * Move       fs-scs_lv             ( vhsjpcs2 -> vhsjpcs1 )
Dec 13 18:24:01 vhsjpcs1 pengine[11247]:  notice:  * Move       nc-sjp-scs            ( vhsjpcs2 -> vhsjpcs1 )
Dec 13 18:24:01 vhsjpcs1 pengine[11247]:  notice:  * Move       ip-sjp-scs            ( vhsjpcs2 -> vhsjpcs1 )
Dec 13 18:24:01 vhsjpcs1 pengine[11247]:  notice:  * Move       rsc_sap_SJP_SCS01     ( vhsjpcs2 -> vhsjpcs1 )
Dec 13 18:24:01 vhsjpcs1 pengine[11247]: warning: Calculated transition 8583 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-2.bz2
Dec 13 18:24:01 vhsjpcs1 crmd[11248]:  notice: Processing graph 8583 (ref=pe_calc-dc-1702517041-8987) derived from /var/lib/pacemaker/pengine/pe-warn-2.bz2
Dec 13 18:24:01 vhsjpcs1 crmd[11248]:  notice: Requesting fencing (reboot) targeting node vhsjpcs2
Dec 13 18:24:01 vhsjpcs1 stonith-ng[11244]:  notice: Client crmd.11248.340b69c3 wants to fence (reboot) 'vhsjpcs2' with device '(any)'
Dec 13 18:24:01 vhsjpcs1 stonith-ng[11244]:  notice: Requesting peer fencing (reboot) targeting vhsjpcs2
Dec 13 18:24:03 vhsjpcs1 stonith-ng[11244]:  notice: Requesting that vhsjpcs1 perform 'reboot' action targeting vhsjpcs2
Dec 13 18:24:03 vhsjpcs1 stonith-ng[11244]:  notice: stonith-sbd can fence (reboot) vhsjpcs2: dynamic-list
Dec 13 18:24:03 vhsjpcs1 stonith-ng[11244]:  notice: Delaying 'reboot' action targeting vhsjpcs2 on stonith-sbd for 24s (timeout=900s, requested_delay=0s, base=0s, max=30s)


CHG0306021	EC001  CST/CDT - 12/20/2023 - 11:30 - NIX - TTA - PATCH - Y2023- SAPB1,SAPD1
CHG0298429	CST/CDT - 12/23/2023 - 20:00 - NIX - SZU - PATCH - HC - VULN - Y2023- SAPB1,SAPD1
CHG0298433	CST/CDT - 12/23/2023 - 20:00 - NIX - SZU - PATCH - HC - VULN - Y2023- SAPB1,SAPD1


CS14398517
TSLLXVMS : T$L@VAScan$2023

TTAPODEV

TTAPOQAS

ttapoprd

TTANINLGRCDEV

TTANINLGRCPRD


please refer this server ----> ttas4hanadapp  



Made cluster managed, removed the constraint and verified the services
[root@tgcs4hpapp-Production ~]$ ps -ef |grep -i pacemaker
root       13939       1  0 02:45 ?        00:00:01 /usr/sbin/pacemakerd -f
haclust+   13940   13939  0 02:45 ?        00:00:06 /usr/lib/pacemaker/pacemaker-based
root       13941   13939  0 02:45 ?        00:00:02 /usr/lib/pacemaker/pacemaker-fenced
root       13942   13939  0 02:45 ?        00:00:02 /usr/lib/pacemaker/pacemaker-execd
haclust+   13943   13939  0 02:45 ?        00:00:01 /usr/lib/pacemaker/pacemaker-attrd
haclust+   13944   13939  0 02:45 ?        00:00:01 /usr/lib/pacemaker/pacemaker-schedulerd
haclust+   13945   13939  0 02:45 ?        00:00:02 /usr/lib/pacemaker/pacemaker-controld
root      754204  717859  0 07:54 pts/1    00:00:00 grep --color=auto -i pacemaker
[root@tgcs4hpapp-Production ~]$ date
Wed Dec 20 07:54:47 IST 2023


CS14395527
CS14395528
CS14395529



Hostname        IP
dlthdehdb3   10.4.5.43
dltdeahdb       10.4.5.185
dlthpehdb4    10.4.5.177
dlthpehdb4s 10.4.5.186




Printer Name-HP LEASER JET  ENTERPRISE M507
Printer Host Name : NPI9963AB
Model No- BOISB-1807-00
IP Address- 135.110.181.22



echo "135.110.181.22		NPI9963AB" 	>> /etc/hosts;lpadmin -p NPI9963AB -v lpd://135.110.181.22 -E;cupsenable NPI9963AB;cupsaccept NPI9963AB

lpr -P NPI9963AB /usr/share/cups/data/testprint      to give a test print

lpstat -W completed					to check if the print is successful

[root@sapapp43 ~]# lpr -P NPI9963AB /usr/share/cups/data/testprint
[root@sapapp43 ~]# cat /var/log/cups/error_log

ErrorLog /var/log/cups/error_log
AccessLog /var/log/cups/access_log
PageLog /var/log/cups/page_log


lpstat -t |grep -i NPI9963AB





sapapp31 10.207.61.84 10.170.61.40
sapapp31-ha 10.207.61.222 10.170.61.123

SAPAPP21 10.207.61.80 10.170.61.131
SAPAPP15 10.207.61.37 10.170.61.121
SAPAPP18 10.207.61.70 10.170.61.116
SAPAPP19 10.207.61.215 10.170.61.74
SAPAPP20 10.207.61.195 10.170.61.48
SAPAPP23 10.207.61.130 10.170.61.226
SAPAPP26 10.207.61.48 10.170.61.176

SAPAPP27 10.207.61.47 10.170.61.166
SAPAPP28 10.207.61.58 10.170.61.211
SAPAPP29 10.207.61.85 10.170.61.141
SAPAPP30 10.207.61.95 10.170.61.161
SAPAPP32 10.207.61.46 10.170.61.52
SAPAPP33 10.207.61.235 10.170.61.88
SAPAPP34 10.207.61.230 10.170.61.94
SAPAPP35 10.207.61.39 10.170.61.62
SAPAPP36 10.207.61.197 10.170.61.115

SAPAPP37 10.207.61.156 10.170.61.107
SAPAPP38 10.207.61.134 10.170.61.237
SAPAPP39 10.207.61.167 10.170.61.212
SAPAPP40 10.207.61.149 10.170.61.252
SAPAPP41 10.207.61.151 10.170.61.248
SAPAPP42 10.207.61.242 10.170.61.139
SAPAPP43 10.207.61.152


Mapped Memory "18675712 ( 17.81 GB)" and Reserved Memory "246415360 ( 235.00 GB)" are NOT equal
MemTotal:       240869112 kB




SZUPDPH01   10.20.44.104		tok02-pod1-6tb-host002.imzcloud.ibmammsap.localfor hana need to ensure th
SZUPDPH02   10.20.44.58


[root@vhsjpcs2 log]# rpm -qa --last |grep -i ds_agent
ds_agent-20.0.0-8438.SuSE_12.x86_64           Thu Dec 14 05:25:36 2023

[root@vhsjpcs2 02]# ls -ltr
total 28
-rw------- 1 root root   67 Dec 14 05:17 log
-rw------- 1 root root 2259 Dec 14 05:40 ttyout
-rw------- 1 root root   80 Dec 14 05:40 ttyin
-rw------- 1 root root  972 Dec 14 05:40 timing
-rw------- 1 root root   20 Dec 14 05:40 stdout
-rw------- 1 root root   20 Dec 14 05:40 stdin
-rw------- 1 root root   20 Dec 14 05:40 stderr
[root@vhsjpcs2 02]# pwd
/var/log/sudo-io/ibmnv/00/00/02


[root@vhsjpcs1 ~]# rpm -qa --last |grep -i ds_agent
ds_agent-20.0.0-8438.SuSE_12.x86_64           Thu Dec 14 05:35:03 2023


[root@vhsjpcs1 04]# ls -ltr
total 28
-rw------- 1 root root   67 Dec 14 05:14 log
-rw------- 1 root root   20 Dec 14 05:40 stdout
-rw------- 1 root root   20 Dec 14 05:40 stdin
-rw------- 1 root root   20 Dec 14 05:40 stderr
-rw------- 1 root root 2537 Dec 14 05:40 ttyout
-rw------- 1 root root   93 Dec 14 05:40 ttyin
-rw------- 1 root root  857 Dec 14 05:40 timing
[root@vhsjpcs1 04]# pwd
/var/log/sudo-io/ibmnv/00/00/04



CHG0307121 
erver name: DMSAPBOD		10.152.65.37
Current Instance Type:  Standard_D16as_v4
Target Instance Type: Standard_D8as_v4

Server name: LBERPDEV		10.152.65.38
Current Instance Type:  Standard_E20as_v4 
Target Instance Type: Standard_E16as_v4 

Server name: zdm2sea1pxy01	10.152.65.5
Current Instance Type:  Standard_DS3_v2
Target Instance Type: Standard_DS2_v2

Server name: zdm2ae01pxy01	10.93.0.5
Current Instance Type:  Standard_DS3_v2
Target Instance Type: Standard_DS2_v2 

10.152.65.37
10.152.65.38
10.152.65.5
10.93.0.5

CS14402634  BR3




 NINL S4P server - 10.170.61.172.


  1.  Invoice Office Printer -1 (Ground floor â€“ mostly used)
     *   Host Name : NPI9AFED1
     *   IP Address : 10.193.56.203
     *   Asset Id : TSLJA08632



  1.  Invoice Office Printer -2 (First  floor)
     *   Host Name : NPI99832A
     *   IP Address : 10.193.56.202
     *   Asset ID : TSLJA08592

echo "10.193.56.203		NPI9AFED1" 	>> /etc/hosts;lpadmin -p NPI9AFED1 -v lpd://10.193.56.203 -E;cupsenable NPI9AFED1;cupsaccept NPI9AFED1

echo "10.193.56.202		NPI99832A" 	>> /etc/hosts;lpadmin -p NPI99832A -v lpd://10.193.56.202 -E;cupsenable NPI99832A;cupsaccept NPI99832A

lpr -P NPI99832A /usr/share/cups/data/testprint      to give a test print

lpstat -W completed					to check if the print is successful




ammdal13custesx056.imzcloud.ibmammsap.local, DAL13POOL2POD1DSP491 in AMM_AMMDAL13_DC to ammdal13custesx056.imzcloud.ibmammsap.local, DAL13POOL1POD1DSP456 in AMM_AMMDAL13_DC

apprh60



pls share list here what you have in output folders, also those ILMT files:  computer.yml  scanner_status.yml 




[root@DLTHPEHP1 ~]$ cat /etc/ssh/sshd_config |grep -i MaxStartups
#MaxStartups 10



CHG0306959 - CST/CDT - 01/26/2024 - 10:00 - NIX - JUE - PATCH - 1Q24-SAPB1/D1
CHG0306112 - CST/CDT - 01/14/2024 - 20:00 - NIX - IA2 - PATCH - HC - VULN - 1Q24-SAPB1/D1


CHG0306114 - CST/CDT - 01/15/2024 - 20:00 - NIX - IA2 - PATCH - HC - VULN - 1Q24-SAPB1/D1
CHG0306116 - CST/CDT - 01/16/2024 - 20:00 - NIX - IA2 - PATCH - HC - VULN - 1Q24-SAPB1/D1




CHG0306951	CST/CDT - 01/09/2024 - 20:00 - NIX - APM - PATCH - HC - VULN - 1Q24-SAPB1/D1
 
CHG0306117	CST/CDT - 01/16/2024 - 20:00 - NIX - IA2 - PATCH - HC - VULN - 1Q24-SAPB1/D1
 
 
 
CHG0306548
CHG0307008
CHG0307188
CHG0307189
CHG0307190



CHG0306992	CST/CDT - 01/09/2024 - 11:30 - NIX - TTA - PATCH - 1Q24-SAPB1/D1
CHG0306994	CST/CDT - 01/11/2024 - 11:30 - NIX - TTA - PATCH - 1Q24-SAPB1/D1



CDIR	Name
TDP	TDPDCSOLMGR		not configured
TDP	TDPDCPRDAP1		not configured
TDP	TDPDCPRDHDB		configured
TDP	TDPDCS4DAPP1	not configured
TDP	TDPDCS4DDB		configured
TDP	TDPDPODDBAPP	not configured
TDP	TDPQPOQDBAPP	not configured
TDP	TDPQCS4QAPP1	not configured
TDP	TDPQCS4QDB		configured
TDP	TDPPPOPDBAPP	not configured
TDP	TDPPCS4PAPP1	not configured
TDP	TDPPCS4PDBDR	not configured
TDP	TDPPCS4PDB		configured


TTA	Tata Steel Limited	TSLEECDEVDB	configured
TTA	Tata Steel Limited	SAPEPQA		not configured
TTA	Tata Steel Limited	EWMAPP3		not configured
TTA	Tata Steel Limited	SAPAPP19	configured
TTA	Tata Steel Limited	SAPAPP18	not configured
TTA	Tata Steel Limited	SAPCRMAPP4-HA	not configured

TTA	Tata Steel Limited	TTAPROJQADB	configured
TTA	Tata Steel Limited	SAPAPP21	not configured
TTA	Tata Steel Limited	EWMAPP1		not configured
TTA	Tata Steel Limited	TSGPQA		not configured
TTA	Tata Steel Limited	SAPAPP23	not configured
TTA	Tata Steel Limited	SAPAPP20	not configured
TTA	Tata Steel Limited	TSLS4PRODDB	not configured
TTA	Tata Steel Limited	TSLBWPRDDB	configured
TTA	Tata Steel Limited	EWMAPP3-HA	not configured

TTA	Tata Steel Limited	ECCTEST		configured
TTA	Tata Steel Limited	SAPBOWAPP	not configured
TTA	Tata Steel Limited	SAPCRMQA	not configured
TTA	Tata Steel Limited	SAPAPP30	configured
TTA	Tata Steel Limited	JBDAIX4		not configured
TTA	Tata Steel Limited	SAPAPP27	not configured
TTA	Tata Steel Limited	SAPPOPRDC	not configured
TTA	Tata Steel Limited	SAPCRMDI	not configured
TTA	Tata Steel Limited	TSGPDEV		not configured
TTA	Tata Steel Limited	SAPAPP15	configured

TTA	Tata Steel Limited	GRCDEVNEW	not configured
TTA	Tata Steel Limited	SAPCRMAPP4	not configured
TTA	Tata Steel Limited	TSLGLDEV	not configured
TTA	Tata Steel Limited	SAPBOPRD	not configured
TTA	Tata Steel Limited	SAPAPP28	configured
TTA	Tata Steel Limited	SAPPOQAC	not configured
TTA	Tata Steel Limited	ESSMSSDEV	not configured
TTA	Tata Steel Limited	SAPBODEV	not configured
TTA	Tata Steel Limited	TSLS4PRODDBH	not configured
TTA	Tata Steel Limited	TSCMLPRD	not configured

TTA	Tata Steel Limited	ESSMSSDEV-DR	enabled
TTA	Tata Steel Limited	SAPBIDEV		enabled
TTA	Tata Steel Limited	SAPAPP31		disabled
TTA	Tata Steel Limited	SAPAPP31-HA		disabled
TTA	Tata Steel Limited	TTACTRL01		enabled
TTA	Tata Steel Limited	SAPBIQA01		enabled
TTA	Tata Steel Limited	TTAGRCPRD		enabled
TTA	Tata Steel Limited	TTAGRCDEV		enabled
TTA	Tata Steel Limited	SAPAPP33		disabled
TTA	Tata Steel Limited	SAPAPP32		enabled

TTA	Tata Steel Limited	SAPAPP34
TTA	Tata Steel Limited	SAPAPP36
TTA	Tata Steel Limited	SAPAPP37
TTA	Tata Steel Limited	TTAS4HANADDB
TTA	Tata Steel Limited	TTAWEBDPRD
TTA	Tata Steel Limited	TTAS4HAPP
TTA	Tata Steel Limited	TTAS4HAPP-HA
TTA	Tata Steel Limited	ttas4hpdb-ha
TTA	Tata Steel Limited	ttas4hanaqdb
TTA	Tata Steel Limited	SAPAPP40

TTA	Tata Steel Limited	SAPAPP39
TTA	Tata Steel Limited	SAPAPP38
TTA	Tata Steel Limited	TSLS4HMCKAP2
TTA	Tata Steel Limited	tsls4hmckdb2
TTA	Tata Steel Limited	TPJUMP
TTA	Tata Steel Limited	TTAS4HPDB-DR
TTA	Tata Steel Limited	ASDDEV
TTA	Tata Steel Limited	EWMQA
TTA	Tata Steel Limited	ttas4hpdb
TTA	Tata Steel Limited	TTAJCAPHDB

TTA	Tata Steel Limited	S4HDEV
TTA	Tata Steel Limited	TTAS4PROQAAPP
TTA	Tata Steel Limited	TSCMLQA
TTA	Tata Steel Limited	TSGPPRD
TTA	Tata Steel Limited	SAPAPP35
TTA	Tata Steel Limited	TTAR3DEV
TTA	Tata Steel Limited	EWMDEV
TTA	Tata Steel Limited	TTABKP01
TTA	Tata Steel Limited	TTAPOPRD
TTA	Tata Steel Limited	TSLBWDEVDB

TTA	Tata Steel Limited	SAPAPP29
TTA	Tata Steel Limited	CRMDEVAPP
TTA	Tata Steel Limited	SAPBOREPO
TTA	Tata Steel Limited	BIPRDAPP3
TTA	Tata Steel Limited	SAPAPP42
TTA	Tata Steel Limited	SAPCRMAPP3
TTA	Tata Steel Limited	ADSPRDS
TTA	Tata Steel Limited	SAPAPP26
TTA	Tata Steel Limited	SAPAPP41
TTA	Tata Steel Limited	BIPRDAPP1



CS14446910	
this 		bs4pe0073-ha	10.211.4.71	bs4pe0073-ha	Dallas 13	1	AMM_VHANA_CA	dal13-pod1-4tb-host22.imzcloud.ibmammsap.local
Jan 4 01:48:27     LINUX RESTART      (128 CPU)
system boot  Jan  4 01:48


[root@bs4pe0073-ha ~]# uptime
 07:45am  up 1 day  5:58,  2 users,  load average: 2.11, 1.91, 1.83
[root@bs4pe0073-ha ~]# date
Fri Jan  5 07:46:00 UTC 2024


7RMNEinVIbJGwIR

SBD clean
register HSR
then start
set online



map sds

TTAS4HANADDB
TTANINLGRCDEV
TTAS4HANADAPP
TTAPODEV
TTAPROJQADB
TTAS4PROQAAPP
TTAWEBDDEV



CHG0306993	 approval


s4hdev
Parse error while reading file /etc/default/grub          w x
                                                                                      x xYaST cannot continue and will quit.                       x x
                                                                                      x x                                                          x x
                                                                                      x xPossible causes and remedies:                             x x
                                                                                      x x 1. You made a mistake when changing the file by hand, thex x
                                                                                      x x    syntax is invalid. Try reverting the changes.         x x
                                                                                      x x 2. The syntax is in fact valid but YaST does not         x x
                                                                                      x x    recognize it. Please report a YaST bug.               x x
                                                                                      x x 3. YaST made a mistake and wrote invalid syntax earlier. x x
                                                                                      x x    Please report a YaST bug.                             x x
                                                                                      x x                                                          x x
                                                                                      x xCaller:                                                   x x
                                                                                      x x/usr/lib64/ruby/gems/2.5.0/gems/cfa-1.0.2/lib/cfa/augeas_px x
                                                                                      x xarser.rb:458:in `report_activity_error!'                  x x
                                                                                      x x                                                          x x
                                                                                      x xDetails: Augeas parsing error: Get did not match entire   v x
                                                                                      x xinput at /etc/default/grub:12:0, lens  
																					  
																					 
																					 
																					 
																					 
OS Linux
CS14449970
,
CS14449976
,
CS14449977
,
CS14449978
Service master CRITICAL: 0 master processes running (thresh 1:)





TPECCPRDDBCI
TPECCAPP2
TPECCQAS
TPECCAPP1
TPSOLMAN



TT3	TPECCDEV	CMS 3.x	SuSe	10.207.72.6	Installed									H. Jayadevappa
Harsha.Jayadevappa@kyndryl.com	Development		TED
	




	TT3	TPADBS	CMS 3.x	SuSe	10.207.71.10	Installed									H. Jayadevappa
Harsha.Jayadevappa@kyndryl.com	Production		ADB
	


TDP	TDPDCPRDAP1	CMS 3.x	SuSe	10.209.2.6	Installed									S. Nandikolmath
Somayya.Nandikolmath@kyndryl.com	Production		TRP
	




	TDP	TDPDCPRDHDB	CMS 3.x	SuSe	10.209.2.8	Installed
	TDP	TDPPPOPDBAPP	CMS 3.x	SuSe	10.209.2.17	Installed									S. Nandikolmath
Somayya.Nandikolmath@kyndryl.com	Production		POP
	




	TDP	TDPPCS4PAPP1	CMS 3.x	SuSe	10.209.2.23	Installed									S. Nandikolmath
Somayya.Nandikolmath@kyndryl.com	Production		S4P
	




	TDP	TDPPCS4PDBDR	CMS 3.x	SuSe	10.70.50.9	Installed									S. Nandikolmath
Somayya.Nandikolmath@kyndryl.com	Production		S4P
	




	TDP	TDPPCS4PDB	CMS 3.x	SuSe	10.209.2.30	Installed
	
	
	TDPDCPRDAP1
TDPDCPRDHDB
TDPPPOPDBAPP
TDPPCS4PAPP1
TDPPCS4PDBDR
TDPPCS4PDB

	

BAPV330900	10.134.3.7  -- non working

/usr/sap/interfaces/V33/sharedoc
/usr/sap/interfaces/V33/tw_einv
	

[root@sapapp30 ~]$ lpstat -t |grep -i NPI450E44
device for NPI450E44: lpd://135.116.33.110
NPI450E44 accepting requests since Tue Dec 26 21:21:27 2023
printer NPI450E44 disabled since Tue Dec 26 21:21:27 2023 -
NPI450E44-2744          prdadm          222208   Mon Jan  8 12:58:16 2024
NPI450E44-2745          prdadm          222208   Mon Jan  8 12:58:19 2024
NPI450E44-2746          prdadm          222208   Mon Jan  8 13:00:08 2024
NPI450E44-2747          prdadm          222208   Mon Jan  8 13:00:10 2024
NPI450E44-2748          prdadm          222208   Mon Jan  8 13:02:15 2024
NPI450E44-2749          prdadm          222208   Mon Jan  8 13:02:16 2024
NPI450E44-2750          prdadm          222208   Mon Jan  8 13:04:06 2024
NPI450E44-2751          prdadm          222208   Mon Jan  8 13:04:08 2024
NPI450E44-2752          prdadm          222208   Mon Jan  8 13:06:07 2024
NPI450E44-2753          prdadm          222208   Mon Jan  8 13:06:09 2024
NPI450E44-2754          prdadm          222208   Mon Jan  8 13:08:05 2024
NPI450E44-2755          prdadm          222208   Mon Jan  8 13:08:06 2024
NPI450E44-2756          prdadm          222208   Mon Jan  8 13:10:08 2024
NPI450E44-2757          prdadm          222208   Mon Jan  8 13:10:09 2024
NPI450E44-2758          prdadm          222208   Mon Jan  8 13:10:13 2024
NPI450E44-2759          prdadm          222208   Mon Jan  8 13:10:14 2024
NPI450E44-2760          prdadm          222208   Mon Jan  8 13:12:06 2024
NPI450E44-2761          prdadm          222208   Mon Jan  8 13:12:07 2024
NPI450E44-2762          prdadm          222208   Mon Jan  8 13:14:06 2024
NPI450E44-2763          prdadm          222208   Mon Jan  8 13:14:07 2024
NPI450E44-2764          prdadm          222208   Mon Jan  8 15:02:12 2024
NPI450E44-2765          prdadm          222208   Mon Jan  8 15:02:14 2024
NPI450E44-2766          prdadm          222208   Mon Jan  8 15:04:10 2024
NPI450E44-2767          prdadm          222208   Mon Jan  8 15:04:12 2024
NPI450E44-2768          prdadm          222208   Mon Jan  8 15:06:09 2024
NPI450E44-2769          prdadm          222208   Mon Jan  8 15:06:10 2024
NPI450E44-2770          prdadm          222208   Mon Jan  8 15:06:14 2024
NPI450E44-2771          prdadm          222208   Mon Jan  8 15:06:15 2024

[root@sapapp30 ~]$ cupsenable NPI450E44
[root@sapapp30 ~]$ lpstat -t |grep -i NPI450E44
device for NPI450E44: lpd://135.116.33.110
NPI450E44 accepting requests since Tue Jan  9 07:39:46 2024
printer NPI450E44 now printing NPI450E44-2745.  enabled since Tue Jan  9 07:39:46 2024
NPI450E44-2745          prdadm          222208   Mon Jan  8 12:58:19 2024
NPI450E44-2746          prdadm          222208   Mon Jan  8 13:00:08 2024
NPI450E44-2747          prdadm          222208   Mon Jan  8 13:00:10 2024
NPI450E44-2748          prdadm          222208   Mon Jan  8 13:02:15 2024
NPI450E44-2749          prdadm          222208   Mon Jan  8 13:02:16 2024
NPI450E44-2750          prdadm          222208   Mon Jan  8 13:04:06 2024
NPI450E44-2751          prdadm          222208   Mon Jan  8 13:04:08 2024
NPI450E44-2752          prdadm          222208   Mon Jan  8 13:06:07 2024
NPI450E44-2753          prdadm          222208   Mon Jan  8 13:06:09 2024
NPI450E44-2754          prdadm          222208   Mon Jan  8 13:08:05 2024
NPI450E44-2755          prdadm          222208   Mon Jan  8 13:08:06 2024
NPI450E44-2756          prdadm          222208   Mon Jan  8 13:10:08 2024
NPI450E44-2757          prdadm          222208   Mon Jan  8 13:10:09 2024
NPI450E44-2758          prdadm          222208   Mon Jan  8 13:10:13 2024
NPI450E44-2759          prdadm          222208   Mon Jan  8 13:10:14 2024
NPI450E44-2760          prdadm          222208   Mon Jan  8 13:12:06 2024
NPI450E44-2761          prdadm          222208   Mon Jan  8 13:12:07 2024
NPI450E44-2762          prdadm          222208   Mon Jan  8 13:14:06 2024
NPI450E44-2763          prdadm          222208   Mon Jan  8 13:14:07 2024
NPI450E44-2764          prdadm          222208   Mon Jan  8 15:02:12 2024
NPI450E44-2765          prdadm          222208   Mon Jan  8 15:02:14 2024
NPI450E44-2766          prdadm          222208   Mon Jan  8 15:04:10 2024
NPI450E44-2767          prdadm          222208   Mon Jan  8 15:04:12 2024
NPI450E44-2768          prdadm          222208   Mon Jan  8 15:06:09 2024
NPI450E44-2769          prdadm          222208   Mon Jan  8 15:06:10 2024
NPI450E44-2770          prdadm          222208   Mon Jan  8 15:06:14 2024
NPI450E44-2771          prdadm          222208   Mon Jan  8 15:06:15 2024





mount -t nfs che01ammyum01.imzcloud.ibmammsap.local:/sds /sds


If cupsservice gets disabled on any printer, check 
cat /etc/cups/printers.conf |grep -i ErrorPolicy
and ensure it is set to retry-job

%s/ErrorPolicy stop-printer/ErrorPolicy retry-job/g
lpadmin -x NPI600979;lpadmin -p NPI600979 -v lpd://135.23.181.28 -o printer-error-policy=retry-job -E;cupsenable NPI600979;cupsaccept NPI600979

lpadmin -p NPI600979 -v socket://backupZ4:9100 -o printer-error-policy=retry-job -E



CHG0307790 CST/CDT - 01/11/2024 - 10:00 - NIX - HRM - PATCH - HC - VULN - 1Q24-SAPB2 - Batch 1
CHG0307791 CST/CDT - 01/18/2024 - 10:00 - NIX - HRM - PATCH - HC - VULN - 1Q24-SAPB2 - Batch 2(b)
CHG0307764 CST/CDT - 01/18/2024 - 10:00 - NIX - HRM - PATCH - HC - VULN - 1Q24-SAPB2 - Batch 2(a)
CHG0307765 CST/CDT - 01/25/2024 - 10:00 - NIX - HRM - PATCH - HC - VULN - 1Q24-SAPB2 - Batch 3



PRD:
sapapp31 10.207.61.84 10.170.61.40
sapapp31-ha 10.207.61.222 10.170.61.123
SAPAPP21 10.207.61.80 10.170.61.131
SAPAPP15 10.207.61.37 10.170.61.121
SAPAPP18 10.207.61.70 10.170.61.116
SAPAPP19 10.207.61.215 10.170.61.74
SAPAPP20 10.207.61.195 10.170.61.48
SAPAPP23 10.207.61.130 10.170.61.226
SAPAPP26 10.207.61.48 10.170.61.176
SAPAPP27 10.207.61.47 10.170.61.166
SAPAPP28 10.207.61.58 10.170.61.211


SAPAPP29 10.207.61.85 10.170.61.141
SAPAPP30 10.207.61.95 10.170.61.161
SAPAPP32 10.207.61.46 10.170.61.52
SAPAPP33 10.207.61.235 10.170.61.88
SAPAPP34 10.207.61.230 10.170.61.94
SAPAPP35 10.207.61.39 10.170.61.62
SAPAPP36 10.207.61.197 10.170.61.115
SAPAPP37 10.207.61.156 10.170.61.107


SAPAPP38 10.207.61.134 10.170.61.237
SAPAPP39 10.207.61.167 10.170.61.212
SAPAPP40 10.207.61.149 10.170.61.252
SAPAPP41 10.207.61.151 10.170.61.248
SAPAPP42 10.207.61.242 10.170.61.139
SAPAPP43 10.207.61.152


QAS:
TGCS4HMAP3 10.207.63.101
ECCTEST - 10.207.63.19


CS14469217

Printer Model Name :CanoniR3225 PCL5e
Printer IP   : 132.147.10.160
Printer Hostname   :  CanonDCD16B
Printer Asset ID/MAC Address : 000085DCD16B


echo "132.147.10.160		CanonDCD16B" 	>> /etc/hosts;lpadmin -p CanonDCD16B -v lpd://132.147.10.160 -E;cupsenable CanonDCD16B;cupsaccept CanonDCD16B




CS14470075

create a mount point as below in tsgpprd  10.170.61.20 and assign it 5 GB and give it 755 permission for SGPADM sapsys.
 
/INTERFACE/TSGP_WF

[root@tsgpprd ~]$ lvdisplay |grep -i interface_TSGP_WF_lv
  LV Path                /dev/sgpappvg/interface_TSGP_WF_lv
  LV Name                interface_TSGP_WF_lv



CHG0307177 
CHG0307178


vmware-config-tools.pl --default




Hostname	IMZ IP Address	CFN IP Address
krrdbdev	10.139.128.63	10.120.1.177
 
krrdbtst11	10.139.128.106	10.120.1.202
 
krrdbprd11	10.139.120.81	10.120.1.9
krrdbprd21	10.139.120.114	10.120.1.60




7fAzG@YuI^CBVlF


CHG0307577 | Change Request | Kyndryl Service Desk (service-now.com)


CS14479493	New	Inoac Corporation -- INO	P2 - Major	Kindly provide utilization report of INO servers



CHG0306995	CST/CDT - 01/16/2024 - 11:30 - NIX - TTA - PATCH - 1Q24-SAPB1/D1
CHG0307465	CST/CDT - 01/17/2024 - 10:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1



lpadmin -x CanonDCD16B;lpadmin -p CanonDCD16B -v lpd://132.147.10.160 -o printer-error-policy=retry-job -E;cupsenable CanonDCD16B;cupsaccept CanonDCD16B


CanonDCD16B: lpd://132.147.10.160



Time worked	Work Date	04-01-2024	05-01-2024	06-01-2024	09-01-2024	10-01-2024	11-01-2024	12-01-2024	13-01-2024	Sum
Account	Number	Category	Comments	
Time Worked Last 10 Days
Al Yousifi -- YS2	Total										30 Minutes		30 Minutes
Bacardi-Martini B.V. -- BAC	Total				45 Minutes								45 Minutes
Bombardier Recreational Products Inc -- BR3	Total							10 Minutes					10 Minutes
Briggs & Stratton Corporation -- BS4	Total				2 Hours 0 Minutes								2 Hours 0 Minutes
Cenovus Energy -- HOE	Total						15 Minutes		45 Minutes			15 Minutes	1 Hour 15 Minutes
Delta Air Lines -- DAL	Total										30 Minutes	15 Minutes	45 Minutes
Inoac Corporation -- INO	Total										30 Minutes		30 Minutes
Internal Infrastructure -- CCP	Total					15 Minutes	1 Hour 0 Minutes				15 Minutes	1 Hour 15 Minutes	2 Hours 45 Minutes
Kuraray C. Ltd -- KRR	Total										30 Minutes		30 Minutes
MITSUBISHI MOTORS NORTH AMERICA INC -- MM9	Total					2 Hours 0 Minutes							2 Hours 0 Minutes
Perkinelmer, Inc. -- PRK	Total					15 Minutes							15 Minutes
Schibsted Norge As -- S5C	Total					30 Minutes							30 Minutes
Smiths Group plc -- SM9	Total						1 Hour 45 Minutes						1 Hour 45 Minutes
Tata Steel BSL Ltd -- BS5	Total								30 Minutes				30 Minutes
Tata Steel Downstream Products Limited -- TDP	Total					30 Minutes							30 Minutes
Tata Steel Limited -- TTA	Total				3 Hours 30 Minutes	30 Minutes		2 Hours 30 Minutes	1 Hour 0 Minutes	1 Hour 0 Minutes	3 Hours 0 Minutes		11 Hours 30 Minutes
The Tinplate Company of India Limited -- TT3	Total					30 Minutes							30 Minutes
Wawa, Inc. -- WA2	Total					1 Hour 0 Minutes					1 Hour 0 Minutes		2 Hours 0 Minutes
ZF Friedrichshafen AG -- ZFF	Total				30 Minutes						45 Minutes		1 Hour 15 Minutes
Sum	6 Hours 45 Minutes	5 Hours 30 Minutes	3 Hours 0 Minutes	2 Hours 40 Minutes	2 Hours 15 Minutes	1 Hour 0 Minutes	7 Hours 0 Minutes	1 Hour 45 Minutes	1 Day 5 Hours 55 Minutes





	CHG0307464	CST/CDT - 01/16/2024 - 10:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1	
	CHG0307463	CST/CDT - 01/18/2024 - 10:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1	
	CHG0307466	CST/CDT - 01/19/2024 - 10:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1	
	CHG0306916	CST/CDT - 01/20/2024 - 10:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1	
	CHG0306921	CST/CDT - 01/20/2024 - 14:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1	
	CHG0306922	CST/CDT - 01/20/2024 - 20:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1	
CHG0306924	CST/CDT - 01/21/2024 - 10:00 - NIX - ZFF - PATCH - HC - VULN - 1Q24-SAPB1/D1






[root@wa2scpdb01s ~]# sar -r -f
Linux 4.12.14-95.96-default (wa2scpdb01s)       01/17/24        _x86_64_        (64 CPU)

00:00:01    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
00:10:02     40227748  44598292 215785180     82.19    601180   4568980   7073856      1.04   8518472   1522376       884
00:20:01     40227988  44576532 215807376     82.19    601244   4546984   7137836      1.05   8535968   1500596       816
00:30:02     40192712  44572560 215804308     82.19    601332   4586184   7027680      1.03   8534040   1539624       836
Average:     40216149  44582461 215798955     82.19    601252   4567383   7079791      1.04   8529493   1520865       845

00:48:17     LINUX RESTART      (64 CPU)




CHG0306744 - CST/CDT - 01/23/2024 - 20:00 - NIX - BS4 - PATCH - HC - VULN - 1Q24-SAPB1/D1
CHG0306745 - CST/CDT - 01/24/2024 - 20:00 - NIX - BS4 - PATCH - HC - VULN - 1Q24-SAPB1/D1




CHG0308956




CS14529839
=>Server/Host name................................:s02.zf-world.com (zffsappdb001);or9.zf-world.com (zffpapp001.zf-world.com, zffpapp001-ha.zf-world.com)
=>System ID (only for SAP)........................:S02; OR9

-create new Dir in S02
/usr/sap/S02/zf/A976/einvoice/arch
/usr/sap/S02/zf/A976/einvoice/in
/abap4/sap/S02/976A/einvoice/out/ZF976
/abap4/sap/S02/976A/einvoice/log

first two already existed , created last two
[root@zffsappdb001 ~]# ls -ld /usr/sap/S02/zf/A976/einvoice/arch
drwxrwxr-x 2 abap4 intconv 4096 Oct 25 13:43 /usr/sap/S02/zf/A976/einvoice/arch
[root@zffsappdb001 ~]# ls -ld /usr/sap/S02/zf/A976/einvoice/in
drwxrwxr-x 2 abap4 intconv 4096 Oct 25 13:43 /usr/sap/S02/zf/A976/einvoice/in
[root@zffsappdb001 ~]# ls -ld /abap4/sap/S02/976A/einvoice/out/ZF976
ls: cannot access '/abap4/sap/S02/976A/einvoice/out/ZF976': No such file or directory
[root@zffsappdb001 ~]# ls -ld /abap4/sap/S02/976A/einvoice/log
ls: cannot access '/abap4/sap/S02/976A/einvoice/log': No such file or directory
[root@zffsappdb001 ~]# mkdir -p /abap4/sap/S02/976A/einvoice/out/ZF976
[root@zffsappdb001 ~]# mkdir -p /abap4/sap/S02/976A/einvoice/log
[root@zffsappdb001 ~]# ls -ld /abap4/sap/S02/976A/einvoice/out/ZF976
drwxr-sr-x 2 root intconv 4096 Jan 23 02:34 /abap4/sap/S02/976A/einvoice/out/ZF976
[root@zffsappdb001 ~]# ls -ld /abap4/sap/S02/976A/einvoice/log
drwxr-sr-x 2 root intconv 4096 Jan 23 02:34 /abap4/sap/S02/976A/einvoice/log



-create new Dir in OR9
/usr/sap/OR9/zf/A976/einvoice/arch
/usr/sap/OR9/zf/A976/einvoice/in
/abap4/sap/OR9/976A/einvoice/out/ZF976
/abap4/sap/OR9/976A/einvoice/log

[root@zffpapp001 ~]# ls -ld /usr/sap/OR9/zf/A976/einvoice/arch
drwxrwxr-x 2 abap4 intconv 4096 Oct 25 13:57 /usr/sap/OR9/zf/A976/einvoice/arch
[root@zffpapp001 ~]# ls -ld /usr/sap/OR9/zf/A976/einvoice/in
drwxrwxr-x 2 abap4 intconv 4096 Oct 25 13:57 /usr/sap/OR9/zf/A976/einvoice/in
[root@zffpapp001 ~]# ls -ld /abap4/sap/OR9/976A/einvoice/out/ZF976
ls: cannot access '/abap4/sap/OR9/976A/einvoice/out/ZF976': No such file or directory
[root@zffpapp001 ~]# mkdir -p /abap4/sap/OR9/976A/einvoice/out/ZF976
[root@zffpapp001 ~]# ls -ld /abap4/sap/OR9/976A/einvoice/out/ZF976
drwxr-xr-x 2 root root 6 Jan 23 02:36 /abap4/sap/OR9/976A/einvoice/out/ZF976
[root@zffpapp001 ~]# ls -ld /abap4/sap/OR9/976A/einvoice/log
drwxr-xr-x 2 root root 6 Jan 23 02:36 /abap4/sap/OR9/976A/einvoice/log


[root@zffpapp001-ha ~]# ls -ld /usr/sap/OR9/zf/A976/einvoice/arch
drwxrwxr-x 2 abap4 intconv 4096 Oct 25 13:57 /usr/sap/OR9/zf/A976/einvoice/arch
[root@zffpapp001-ha ~]# ls -ld /usr/sap/OR9/zf/A976/einvoice/in
drwxrwxr-x 2 abap4 intconv 4096 Oct 25 13:57 /usr/sap/OR9/zf/A976/einvoice/in
[root@zffpapp001-ha ~]# ls -ld /abap4/sap/OR9/976A/einvoice/out/ZF976
ls: cannot access '/abap4/sap/OR9/976A/einvoice/out/ZF976': No such file or directory
[root@zffpapp001-ha ~]# mkdir -p /abap4/sap/OR9/976A/einvoice/out/ZF976
[root@zffpapp001-ha ~]# ls -ld /abap4/sap/OR9/976A/einvoice/out/ZF976
drwxr-xr-x 2 root root 6 Jan 23 02:36 /abap4/sap/OR9/976A/einvoice/out/ZF976
[root@zffpapp001-ha ~]# ls -ld /abap4/sap/OR9/976A/einvoice/log
ls: cannot access '/abap4/sap/OR9/976A/einvoice/log': No such file or directory
[root@zffpapp001-ha ~]# mkdir -p /abap4/sap/OR9/976A/einvoice/log
[root@zffpapp001-ha ~]# ls -ld /abap4/sap/OR9/976A/einvoice/log
drwxr-xr-x 2 root root 6 Jan 23 02:36 /abap4/sap/OR9/976A/einvoice/log




-create new scripts/batch in S02 (copy from old ones starting with zf267xxx)
zf976-sftp_S02.sh in dir /home/s02adm
zf976-getsftp_csv_S02.sh in dir /home/s02adm
inside each  sh script modification has to be done: change everywhere 267 with 976.change also Trw267Usr with Zf976Usr (so Trw with Zf)
zf976-getsftp_csv_S02.batch in dir home/s02adm
zf976-sftp_S02.batch in dir home/s02adm


[root@zffsappdb001 s02adm]# ls -ltr |grep -i zf26
-rwxr--r-- 1 s02adm sapsys    32 Oct  5  2021 zf267-getsftp_csv_S02.batch
-rwxr--r-- 1 s02adm sapsys    31 Oct  5  2021 zf267-rmsftp_csv_S02.batch
-rwxr--r-- 1 s02adm sapsys   594 Oct  7  2021 zf267-getsftp_csv_S02.sh
-rwxr--r-- 1 s02adm sapsys    84 Oct  8  2021 zf267-sftp_S02.batch
-rwxr--r-- 1 s02adm sapsys   751 Oct  8  2021 zf267-sftp_S02.sh
kal main



-create new scripts/batch in OR9 (copy from old ones with zf267xxx)
zf976-sftp_OR9.sh in dir /home/or9adm
zf976-getsftp_csv_OR9.sh in dir /home/or9adm
inside each  sh script modification has to be done: change everywhere 267 with 976. change also Trw267Usr with Zf976Usr (so Trw with Zf)
zf976-getsftp_csv_OR9.batch in dir home/or9adm
zf976-sftp_OR9.batch in dir home/or9adm



cp zf267-sftp_OR9.sh zf976-sftp_OR9.sh
cp zf267-getsftp_csv_OR9.batch zf976-getsftp_csv_OR9.batch



pmc compliant  C97400   25 jan 


CS14511328
Printer Make/Model:                               HP Laserjet M507
Printer IP  :                                                 158.0.181.31
Printer Hostname  /Queue name :         NPI9983E6

echo "158.0.181.31			NPI9983E6" 	>> /etc/hosts;lpadmin -p NPI9983E6 -v lpd://158.0.181.31 -E;cupsenable NPI9983E6;cupsaccept NPI9983E6
lpadmin -x NPI9983E6;lpadmin -p NPI9983E6 -v lpd://158.0.181.31 -o printer-error-policy=retry-job -E;cupsenable NPI9983E6;cupsaccept NPI9983E6


PRD:
sapapp31 10.207.61.84 10.170.61.40
sapapp31-ha 10.207.61.222 10.170.61.123
SAPAPP21 10.207.61.80 10.170.61.131
SAPAPP15 10.207.61.37 10.170.61.121
SAPAPP18 10.207.61.70 10.170.61.116
SAPAPP19 10.207.61.215 10.170.61.74
SAPAPP20 10.207.61.195 10.170.61.48
SAPAPP23 10.207.61.130 10.170.61.226
SAPAPP26 10.207.61.48 10.170.61.176
SAPAPP27 10.207.61.47 10.170.61.166
SAPAPP28 10.207.61.58 10.170.61.211


SAPAPP29 10.207.61.85 10.170.61.141
SAPAPP30 10.207.61.95 10.170.61.161
SAPAPP32 10.207.61.46 10.170.61.52
SAPAPP33 10.207.61.235 10.170.61.88
SAPAPP34 10.207.61.230 10.170.61.94
SAPAPP35 10.207.61.39 10.170.61.62
SAPAPP36 10.207.61.197 10.170.61.115
SAPAPP37 10.207.61.156 10.170.61.107


SAPAPP38 10.207.61.134 10.170.61.237
SAPAPP39 10.207.61.167 10.170.61.212
SAPAPP40 10.207.61.149 10.170.61.252
SAPAPP41 10.207.61.151 10.170.61.248
SAPAPP42 10.207.61.242 10.170.61.139  
SAPAPP43 10.207.61.152


QAS:
TGCS4HMAP3 10.207.63.101






Please change IP for  printer queue LL13 on E02, S02, OR9 :
oldIP: 149.223.251.211
newIP: 149.223.251.52

lpadmin -p LL13 -v lpd://149.223.251.52 -o printer-error-policy=retry-job -E;cupsenable LL13;cupsaccept LL13


S02  zffsappdb001

OR9  zffpapp001 and zffpapp001-ha

E02  ZFFSAPPDB006






020 25501154  tax dept
0 c 06 01407022


CHG0308996 CST/CDT - 01/26/2024 - 20:00 - NIX - HOE - PATCH - 1Q24-SAPB2
CHG0309029 CST/CDT - 01/26/2024 - 20:00 - NIX - HOE - PATCH - 1Q24-SAPB2





CS14537957	Cenovus Energy -- HOE	hoe#vhsjdap1#172.31.254.6(172.31.254.6) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHSJDAP1	SQ-SAP-TRIO-B2
CS14537959	Cenovus Energy -- HOE	hoe#vht2qdb2#172.31.254.209(172.31.254.209) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHT2QDB2	SQ-SAP-TRIO-B2
CS14537918	Cenovus Energy -- HOE	hoe#vhep1ap3#172.31.252.31(172.31.252.31) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHEP1AP3	SQ-SAP-TRIO-B2
CS14537947	Cenovus Energy -- HOE	hoe#zhoeusw2sbd03#172.31.252.135(172.31.252.135) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	ZHOEUSW2SBD03	SQ-SAP-TRIO-B2
CS14537955	Cenovus Energy -- HOE	hoe#vhtp1ap1#172.31.252.14(172.31.252.14) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHTP1AP1	SQ-SAP-TRIO-B2
CS14537956	Cenovus Energy -- HOE	hoe#vheq2ap3#172.31.254.210(172.31.254.210) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHEQ2AP3	SQ-SAP-TRIO-B2
CS14537943	Cenovus Energy -- HOE	hoe#vhvp1wd1#172.31.252.21(172.31.252.21) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHVP1WD1	SQ-SAP-TRIO-B2
CS14537949	Cenovus Energy -- HOE	hoe#vhe3ddb1#172.31.254.14(172.31.254.14) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHE3DDB1	SQ-SAP-TRIO-B2
CS14537954	Cenovus Energy -- HOE	hoe#vhtp1cs1#172.31.252.18(172.31.252.18) is unreachable. The host has failed to respond to the ping request.	P1 - Severe	VHTP1CS1	SQ-SAP-TRIO-B2




[4:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sdm
[5:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdn
[5:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdo


hb_report -f "2024/01/03 23:30" -t "2024/01/04 02:59" /home/ibmrmalik/hb_report-$(date +"%Y%m%d-%H%M")



/var/log/scc_bs4pe0073_240124_0957

/var/log/scc_bs4pe0073-ha_240124_0955




Host Name
SZUPDPH01		10.20.44.104			ammtok02custesx016.imzcloud.ibmammsap.local		
SZUPDPH02		10.20.44.58				tok02-pod1-6tb-host002.imzcloud.ibmammsap.local		vhana

ammtok02custesx016.imzcloud.ibmammsap.local  - SL01KYAI
tok02-pod1-6tb-host002.imzcloud.ibmammsap.local - SL01GD0V

Information Requested
Hardware Serial No.
Hardware Brand/Model
Hardware Type (server, PC, etc.)



nvme1n1                  259:3    0  320G  0 disk                  vol0d5bc7cc1f6238ad4
â””â”€sapdata-data           254:3    0  320G  0 lvm  /sapmnt/data

vol-0d5bc7cc1f6238ad4



CHG0307766 CST/CDT - 02/01/2024 - 10:00 - NIX - HRM - PATCH - HC - VULN - 1Q24-SAPB2- Batch 4
CHG0308571 CST/CDT - 02/04/2024 - 13:00 - NIX - VXT - PATCH - HC - VULN - 1Q24-SAPB2




CHG0309374	CST/CDT - 02/08/2024 - 20:00 - NIX - HM8 - PATCH - 1Q24-SAPB1/D1	done
CHG0309375	CST/CDT - 02/08/2024 - 20:00 - NIX - HM8 - PATCH - 1Q24-SAPB1/D1	have SAP failures in SAMUEL, SAP to chekc and fix- OS approved
CHG0307282	CST/CDT - 02/08/2024 - 20:00 - NIX - SZU - PATCH - HC - VULN - 1Q24-SAPB1/D1	done
CHG0307283	CST/CDT - 02/08/2024 - 20:00 - WIN - SZU - PATCH - HC - VULN - 1Q24-SAPB1/D1	windows
CHG0308173	CST/CDT - 02/09/2024 - 13:00 - NIX - TTA - PATCH - 1Q24-SAPB1/D1	approved



IMZ connectivity issue  3 hours

Perkinelmer, Inc. -- PRK
Olin Corporation -- OLC
Universal City Studios LLC d/b/a -- Z0D
Elkay Manufacturing Company
Wawa, Inc. -- WA2
Gulf States Toyota -- GT4
Gulf States Toyota -- GLT
Consolidated Metco Inc. -- Z2Y




CHG0308827	


zffpapp001
zffpapp001-ha
zffsappdb006
zffsappdb001


new printer queue  TIMP00184	10.213.94.45


lpadmin -p TIMP00184 -v lpd://10.213.94.45 -o printer-error-policy=retry-job -E;cupsenable TIMP00184;cupsaccept TIMP00184


DAL sev1	CS14592230		10.4.5.36




CHG0309402 & CHG0310098.


CS14604174  sev1 nic issue		3 feb 15 min
hnosapdbd1 -- Hino Motors Ltd -- HNO -- SAP B2
szudvie02 -- Isuzu Motors Ltd -- SZU -- SAP B1


	10.191.2.32	wa2bwpdb01
	10.191.1.101	wa2bwqap02
	10.191.1.27	wa2crxdb01
	10.191.1.24	wa2ep7adb1
	10.191.1.254	wa2mssprodd1
	10.191.1.252	wa2mssprodi1
	10.191.1.241	wa2mssprods1
	10.191.1.247	wa2mssprodw1
	10.191.1.26	wa2pbsqas01
	100.64.20.53	wa2prddb01s
	10.191.2.55	wa2sjpadb1
	10.191.2.60	wa2smpadb1
	10.191.2.9	wa2xipaap01s
10.92.6.135	gstappq01	windows
10.92.6.138	gstappq02	windows
	10.92.6.221	gstatomq06
10.92.12.22	gstdbasqld01	windows
10.92.6.199	gstdenodoq01	windows
	10.92.5.211	gstopxyd02
10.92.12.17	gstsapalmd1	Windows
10.92.5.77	gstsqld01	windows
10.92.5.79	gstsqld02	windows
10.92.6.73	gstsqlq02	windows
10.92.6.205	gstsvcq01	windows
10.92.5.212	gstwebd01	windows
10.92.6.198	gstwebq01	windows
10.92.5.119	vpcsqld01	windows
	10.25.8.19	etgrws09hanad	
	10.25.8.13	etgrws22hanad
	10.92.0.139	gltbwprddb01
10.92.10.61	gltilentdb01	windows
	10.92.10.110	gltiqentdb01
	10.92.10.37	gltsmdevas01
	10.92.10.18	gltsmdevdb01



CS14605497 infra ticket
PRK
GLT
WAWA


CS14605497 is the master ticket. ticket to SL Cloud being raised to check the cause of the issue every Tuesday and Saturday approx 9:30 AM IST 




//10.140.0.131:/Archive      /Archive       cifs  -o username=shareid,passwd=ProKabbadi@12345,_netdev


username=shareid,passwd=ProKabbadi@12345 


Archive (file://LBUPO1AP02/Archive)


source - Linux - lbupf1ap01 - /interface/PS1/OpenText/Kubra/BILL/Archive - Folder 2023
Destination - Windows - lbupo1ap02 - H:\Interface\PS1\OpenText\Kubra\BILL\Archive


mount.cifs //LBUPO1AP02/Archive /Archive -o username=shareid,passwd=ProKabbadi@12345



CHG0308825 CST/CDT - 02/10/2024 - 19:00 - NIX - SN2 - PATCH - HC - VULN - 1Q24-SAPB2
CHG0308496 CST/CDT - 02/10/2024 - 20:00 - NIX - SCZ - PATCH - HC - VULN - 1Q24-SAPB2






prk#npdbtwsn#10.151.0.105(10.151.0.105)		No
prk#npsv10#10.151.0.87(10.151.0.87)			yes
prk#npsv07#10.151.0.146(10.151.0.146)		yes
prk#prdb03#10.151.0.67(10.151.0.67)			yes
prk#npvm16#10.151.0.40(10.151.0.40)			no
prk#prvm079#10.151.0.229(10.151.0.229)		no
prk#prvmapp202#10.151.0.145(10.151.0.145)	yes
prk#prvm159#10.151.0.204(10.151.0.204)		no
prk#prsv10#10.151.0.78(10.151.0.78)			no
prk#npsv66#10.151.0.119(10.151.0.119)		no
prk#npsv20#10.151.0.88(10.151.0.88)			no
prk#prdb05#10.151.0.83(10.151.0.83)			yes
glt#glts4qasas01#10.92.3.134(10.92.3.134)	no
glt#gltb4qasas01#10.92.3.140(10.92.3.140)	yes
glt#gltaduatas01#10.92.4.138(10.92.4.138)	no
glt#gltmiuatdb01#10.92.4.137(10.92.4.137)	yes
glt#gltme1asdb01#10.92.2.178(10.92.2.178)	yes
glt#gltb4qasdb01#10.92.3.71(10.92.3.71)		no
glt#gltmiprddb01#10.92.0.157(10.92.0.157)	no
prk#npsvh09#10.151.0.42(10.151.0.42)		no
prk#prap01#10.151.0.47(10.151.0.47)			yes
prk#npsv059#10.151.0.73(10.151.0.73)		no
prk#prdhdb04#10.151.0.153(10.151.0.153)		yes
prk#prvm17#10.151.0.34(10.151.0.34)			no
prk#prsv07#10.151.0.239(10.151.0.239)		no
prk#prdb02a#10.151.0.80(10.151.0.80)		no
prk#prdb12#10.151.0.69(10.151.0.69)			no
scz#sczprddb-ha#10.151.19.16(10.151.19.16)	no
scz#sczsap-qa1#10.151.19.21(10.151.19.21)
scz#sczprddb#10.151.19.28(10.151.19.28)
scz#sczsap-dv1#10.151.19.6(10.151.19.6)
prk#prap05#10.151.0.35(10.151.0.35)
prk#prdb10#10.151.0.108(10.151.0.108)
prk#npsvd107#10.151.0.124(10.151.0.124)
prk#npsvq107#10.151.0.118(10.151.0.118)
prk#prdb02f#10.151.0.25(10.151.0.25)
prk#prsv06#10.151.0.219(10.151.0.219)
prk#prvm119#10.151.0.77(10.151.0.77)
prk#npvmd100#10.151.0.49(10.151.0.49)
prk#npsvh12#10.151.0.12(10.151.0.12)
glt#gltasqasdb01#10.92.3.79(10.92.3.79)		no
glt#gltmiuatas01#10.92.4.139(10.92.4.139)
glt#gltmedevdb01#10.92.2.138(10.92.2.138)
glt#gltmedevas01#10.92.2.142(10.92.2.142)
glt#gltbwuatas01#10.92.4.148(10.92.4.148)
prk#prvmp100f#10.151.0.107(10.151.0.107)
glt#glts4devdb01#10.92.2.191(10.92.2.191)
prk#prvm0599#10.151.0.218(10.151.0.218)
glt#gltsmdevas01#10.92.10.37(10.92.10.37)
glt#glts4uatas01#10.92.4.135(10.92.4.135)
glt#gltilentas01#10.92.10.88(10.92.10.88)
glt#gltgrentdb01#10.92.10.24(10.92.10.24)
glt#gltb4devdb01#10.92.2.186(10.92.2.186)
prk#npvmapp202#10.151.0.144(10.151.0.144)
prk#prvm129#10.151.0.130(10.151.0.130)
prk#prdb11#10.151.0.114(10.151.0.114)
prk#prsvp107#10.151.0.123(10.151.0.123)
prk#npsv06#10.151.0.97(10.151.0.97)
prk#prdb07#10.151.0.84(10.151.0.84)
prk#npsv81#10.151.0.22(10.151.0.22)
prk#npsv08#10.151.0.20(10.151.0.20)
prk#prdb02a-ha#10.151.0.179(10.151.0.179)
prk#prdh04#10.151.0.85(10.151.0.85)
prk#npsv17#10.151.0.32(10.151.0.32)
prk#npsv04#10.151.0.141(10.151.0.141)
glt#glts4qasdb01#10.92.3.78(10.92.3.78)
glt#gltbwuatdb01#10.92.4.168(10.92.4.168)
prk#prdbtws#10.151.0.65(10.151.0.65)
glt#gltb4devas01#10.92.2.141(10.92.2.141)
glt#gltsmdevdb01#10.92.10.18(10.92.10.18)
glt#gltmeqasdb01#10.92.3.70(10.92.3.70)
glt#gltilentdb01#10.92.10.61(10.92.10.61)
prk#npvmdb201#10.151.0.178(10.151.0.178)
glt#gltwdprdas01#10.92.0.73(10.92.0.73)
glt#gltmeqasas01#10.92.3.135(10.92.3.135)
prk#npdbtws#10.151.0.55(10.151.0.55)
prk#prvm069#10.151.0.15(10.151.0.15)
prk#npsvhdb09#10.151.0.17(10.151.0.17)
prk#prvm059#10.151.0.164(10.151.0.164)
prk#prvm19#10.151.0.63(10.151.0.63)
prk#npvm15#10.151.0.11(10.151.0.11)
prk#prvmp100pod#10.151.0.129(10.151.0.129)
prk#npvmq100#10.151.0.64(10.151.0.64)
prk#prvm18#10.151.0.82(10.151.0.82




root pw reset via 1password
oscar still starting pacemaker




VM :

FRA02-SL	FBSAPD01FGCL	10.199.98.11	10.250.98.11	SUSE	BDA

add 32GB disk to root FS

remove 64GB and 128GB disk from server

sdc                        8:32   0  128G  0 disk
sdd                        8:48   0   64G  0 disk
sde                        8:64   0   32G  0 disk

Above 3 disks can be safely cleaned up and reclaimed
 
********************************
FRA02-SL	FBSAPP01FGCL	10.199.99.11	10.250.99.11	SUSE	BPA

add 32GB disk to root FS

remove 64GB and 128GB disk from server

sdc                        8:32   0  128G  0 disk
sdd                        8:48   0   64G  0 disk
sde                        8:64   0   32G  0 disk

Above 3 disks can be safely cleaned up and reclaimed
 
********************************

FRA02-SL	FBSAPD02FGCL	10.199.98.13	10.250.98.13	SUSE	PDA

remove 32GB, 64GB and 128GB disk from server
 
Can you please explain what are bellow disks ?

Disk name /dev/fd0 is not utilized. The disk size is 4K		
It corresponds to a removable disk ie Floppy drive etc or similar

Disk name /dev/sr0 is not utilized. The disk size is 1024M

 /dev/sr0 is a device on the scsi controller (hypervisor). The /dev/sr0 can be also a DVD- /CD-ROM or similar. The media in there has always 100% used as it is read-only. The /dev/sr0 in Nodegrid Manager means the hypervisor kept a CD/DVD assigned to the VM.
 
sdc                        8:32   0  128G  0 disk
sdd                        8:48   0   64G  0 disk
sde                        8:64   0   32G  0 disk

Above 3 disks can be safely cleaned up and reclaimed

********************************
 FRA02-SL	FBSAPP02FGCL	10.199.99.13	10.250.99.13	SUSE	PPA

add 32GB disk to /usr/sap/PPA

remove 64GB disk from server

sdd                        8:48   0   64G  0 disk
sde                        8:64   0   32G  0 disk

Above 2 disks can be safely cleaned up and reclaimed



CHG0306120	CST/CDT - 02/10/2024 - 10:00 - NIX - IA2 - PATCH - HC - VULN - 1Q24-SAPB1/D1
CHG0306131	CST/CDT - 02/14/2024 - 20:00 - NIX - IA1 - PATCH - HC - VULN - 1Q24-SAPB1/D1




BIPRDAPP1	mounted
TGCS4HMHDB3	mounted
TSLBWDEVDB		mounted
TSLBWPRDDB		mounted
TSLBWPRDHDBDR	mounted
TSLEECDEVDB	mounted
TSLS4PRODDB	
TSLS4PRODDBDR	mounted
TSLS4PRODDBH
TTAJCAPHDB	mounted
TTAPROJQADB	mounted
TTSLBWQADB01	mounted
ttas4hanaqdb	mounted
ttas4hpdb
ttas4hpdb-ha




TGCS4HMHDB3
TSLBWDEVDB
TSLEECDEVDB
TTAPROJQADB
TTSLBWQADB01
ttas4hanaqdb
 
 
BIPRDAPP1
TTAJCAPHDB
TSLBWPRDDB
TSLS4PRODDB - cluster
TSLS4PRODDBH - cluster
ttas4hpdb - cluster
ttas4hpdb-ha - cluster
 
 
TSLS4PRODDBDR
TSLBWPRDHDBDR



ZBQ062




CHG0310723	09-02-2024 07:30:00	09-02-2024 15:30:00
westus2-AZ
Patch Group (PP-1) - vheq2cs1	SUSE	172.31.254.197	Pre-Production	EQ2 - SAP  (App)		J2.zuRCLC4MyZii
Patch Group (PP-1) - vheq2cs2	SUSE	172.31.254.205	Pre-Production	EQ2 - SAP  (App)		AtZP2fksMf_jGmz


Patch Group (PP-1) - vheq2ap3	SUSE	172.31.254.210	Pre-Production	EQ2 - SAP  (App)		c_GW89qiAPXU4Qv	

Patch Group (PP-1) - vheq2ap1	SUSE	172.31.254.196	Pre-Production	EQ2 - SAP  (App)		k!Z*c7msy9CKe9a

	Patch Group (PP-1) - vhe2qdb1	SUSE	172.31.254.199	Pre-Production	E2Q - SAP  (DB) - HANA	*VnhNY29DHkynfD
	Patch Group (PP-1) - vhe2qdb2	SUSE	172.31.254.206	Pre-Production	E2Q - SAP  (DB) - HANA	hbGyb4-bKteVq6b	


[ vheq2cs1 vheq2cs2 ]
[ vhe2qdb1 vhe2qdb2 ]
[ vheq2cs1 vheq2cs2 ]

Samuel presnap  https://samuel.sap.adai.kyndryl.com/HOE/buildInformation?id=65c583700edfa0e450f9248c&name=Overview

Apps and DB stop  https://samuel.sap.adai.kyndryl.com/HOE/buildInformation?id=65c588467b38636f9cfb0ccc&name=Overview

azure snapshot  https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsysparm_article%3DKB0018602

KB0019746 : Azure and AWS - MANUAL OS PATCHING PROCEDURE USING PATCH LIST


zypper up $(cat /etc/zypp/QJAN24-patchlist|grep -v done)

 zypper up $(cat /etc/zypp/quarter/QJAN24-patchlist|grep -v done)
 
 
 HC link https://samuel.sap.adai.kyndryl.com/HOE/buildInformation?id=65c5bd51b8276e2d03ddf5e2&name=Overview
 
 
 Apps and db start
 https://samuel.sap.adai.kyndryl.com/HOE/buildInformation?id=65c5cd4d0edfa0e450f9bc19&name=Overview
 
 
 
 su - e2qadm -c "hdbnsutil -sr_register --remoteHost=vhe2qdb1 --remoteInstance=00 --replicationMode=sync --online --operationMode=logreplay --name=NODEB"
 
 start apps
 https://samuel.sap.adai.kyndryl.com/HOE/buildInformation?id=65c5cd4d0edfa0e450f9bc19&name=Overview
 
 
 CHG0310185 CST/CDT - 02/11/2024 - 20:00 - NIX - GLT - PATCH - HC - 1Q24-SAPB2  approved
CHG0310186 CST/CDT - 02/11/2024 - 20:00 - NIX - GLT - PATCH - HC - 1Q24-SAPB2   pending as didnt get time


master ticket CS14654745 and change CHG0307767

Feb 10 01:20:08 hrmazsp1ap3 sshd[16432]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 23708 ssh2
Feb 10 01:20:08 hrmazsp1ap3 sshd[16432]: Failed none for root from 10.102.251.11 port 23708 ssh2
Feb 10 01:30:08 hrmazsp1ap3 sshd[32618]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 25018 ssh2
Feb 10 01:30:08 hrmazsp1ap3 sshd[32618]: Failed none for root from 10.102.251.11 port 25018 ssh2
Feb 10 01:40:08 hrmazsp1ap3 sshd[45838]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 16206 ssh2
Feb 10 01:40:08 hrmazsp1ap3 sshd[45838]: Failed none for root from 10.102.251.11 port 16206 ssh2
Feb 10 01:50:07 hrmazsp1ap3 sshd[58362]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 40404 ssh2
Feb 10 01:50:07 hrmazsp1ap3 sshd[58362]: Failed none for root from 10.102.251.11 port 40404 ssh2
Feb 10 02:00:07 hrmazsp1ap3 sshd[71667]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 64906 ssh2
Feb 10 02:00:07 hrmazsp1ap3 sshd[71667]: Failed none for root from 10.102.251.11 port 64906 ssh2
Feb 10 02:10:09 hrmazsp1ap3 sshd[85836]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 40404 ssh2
Feb 10 02:10:09 hrmazsp1ap3 sshd[85836]: Failed none for root from 10.102.251.11 port 40404 ssh2
Feb 10 02:20:07 hrmazsp1ap3 sshd[98398]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 23344 ssh2
Feb 10 02:20:07 hrmazsp1ap3 sshd[98398]: Failed none for root from 10.102.251.11 port 23344 ssh2
Feb 10 02:30:07 hrmazsp1ap3 sshd[111217]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 47082 ssh2
Feb 10 02:30:07 hrmazsp1ap3 sshd[111217]: Failed none for root from 10.102.251.11 port 47082 ssh2
Feb 10 02:40:06 hrmazsp1ap3 sshd[123685]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 15130 ssh2
Feb 10 02:40:06 hrmazsp1ap3 sshd[123685]: Failed none for root from 10.102.251.11 port 15130 ssh2
Feb 10 02:50:09 hrmazsp1ap3 sshd[136400]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 45314 ssh2
Feb 10 02:50:09 hrmazsp1ap3 sshd[136400]: Failed none for root from 10.102.251.11 port 45314 ssh2
Feb 10 03:00:07 hrmazsp1ap3 sshd[147977]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 27052 ssh2
Feb 10 03:00:07 hrmazsp1ap3 sshd[147977]: Failed none for root from 10.102.251.11 port 27052 ssh2
Feb 10 03:10:08 hrmazsp1ap3 sshd[159769]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 56812 ssh2
Feb 10 03:10:08 hrmazsp1ap3 sshd[159769]: Failed none for root from 10.102.251.11 port 56812 ssh2
Feb 10 03:20:07 hrmazsp1ap3 sshd[171748]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 27914 ssh2
Feb 10 03:20:07 hrmazsp1ap3 sshd[171748]: Failed none for root from 10.102.251.11 port 27914 ssh2
Feb 10 03:30:07 hrmazsp1ap3 sshd[183585]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 44016 ssh2
Feb 10 03:30:07 hrmazsp1ap3 sshd[183585]: Failed none for root from 10.102.251.11 port 44016 ssh2
Feb 10 03:40:09 hrmazsp1ap3 sshd[195292]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 55354 ssh2
Feb 10 03:40:09 hrmazsp1ap3 sshd[195292]: Failed none for root from 10.102.251.11 port 55354 ssh2
Feb 10 03:50:08 hrmazsp1ap3 sshd[207021]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 47210 ssh2
Feb 10 03:50:08 hrmazsp1ap3 sshd[207021]: Failed none for root from 10.102.251.11 port 47210 ssh2
Feb 10 03:57:57 hrmazsp1ap3 SAPSP1_02[220053]: R49 Basis System: Communication error, CPIC-RC=CM_DEALLOCATED_ABEND(17), SAP-RC=GW_CONNECT_FAILED(236)
Feb 10 04:00:09 hrmazsp1ap3 sshd[221077]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 25190 ssh2
Feb 10 04:00:09 hrmazsp1ap3 sshd[221077]: Failed none for root from 10.102.251.11 port 25190 ssh2
Feb 10 04:40:08 hrmazsp1ap3 sshd[277072]: Failed keyboard-interactive/pam for root from 10.102.251.11 port 54412 ssh2


lpadmin -p TROYMICR -v lpd://10.120.13.18 -o printer-error-policy=retry-job -E;cupsenable TROYMICR;cupsaccept TROYMICR



POQ
TDPQPOQDBAPP	TDPQPOQDBAPP	Linux Server	Installed		10.209.3.16	10.32.0.37

S4Q
TDPQCS4QAPP1	tdpqcs4qapp1	Linux Server	Installed		10.209.3.14	10.32.0.32
TDPQCS4QDB	TDPQCS4QDB	Linux Server	Installed	 	10.209.3.15	10.32.0.20




SID:	S4P
Host Name	tdppcs4papp1  	tdpqcs4qapp1	TDPQCS4QDB
IP	: 10.16.0.128
Server2: S/4 HANA PROD APP2
SID:	S4P
Host Name:	tdppcs4papp2
IP	:10.16.0.7
PO Server: PO Prod

SID:	POP
Host Name: tdpppopdbapp		TDPQPOQDBAPP
IP:	10.16.0.11	






tpeccapp1   TTA_TCIL - PG  
tpadbs		TTA_TCIL - PG  
ttactrl01	TTA_PG3
sapapp43	PG6
ewmapp1		PG2
ttacangrcp	PG4
tsgpprd		PG2
ttaninlgrcprd	PG5

COlumn E should match with column I and move VMs to other datastores



SUSE ticket #
01238188




Approval
CHG0308035	Kuraray C. Ltd -- KRR	Linux	  2/18/2024   18:00
CHG0308287	Revvity, Inc. -- PRK	    Linux	  2/21/2024   17:00






CS14682398

EEP
MGGGBJPECCX13	Production	10.133.18.8		10.5.255.18
MGGGBJPECCX16	Production	10.133.18.72	10.5.255.37
MGGGBJPECCX17	Production	10.133.18.20	10.5.255.36
MGGGBJPECCX14	Production	10.133.18.107	10.5.255.19
MGGGBJPECCX15	Production	10.133.18.11	10.5.255.81
//10.228.32.39/Bank/EEP /interfaces/Bank

EVT
MGGGBJVECCX10	PreProduction	10.133.18.164	10.5.255.213
MGGGBJVECCX03	PreProduction	10.133.18.238	10.5.255.171
MGGGBJVECCX04	PreProduction	10.133.18.246	10.5.255.172
//10.228.32.39/Bank/EVT /interfaces/Bank

EEQ
MGGGBJQECCX03	Quality	10.133.18.232	10.5.255.167
MGGGBJQECCX04	Quality	10.133.18.224	10.5.255.168
//10.228.32.39/Bank/EEQ /interfaces/Bank

PEQ
MGGGBJQECCY05	Quality	10.133.18.230	10.5.255.181
MGGGBJQECCY04	Quality	10.133.18.210	10.5.255.222
//10.228.32.39/Bank/PEQ /interfaces/Bank

EED
MGGGBJDECCX03	Development	10.133.18.222	10.5.255.165
MGGGBJDECCX04	Development	10.133.18.218	10.5.255.166
//10.228.32.39/Bank/EED /interfaces/Bank

PED
MGGGBJDECCY03	Development	10.133.18.215	10.5.255.179
MGGGBJDECCY04	Development	10.133.18.250	10.5.255.180
//10.228.32.39/Bank/PED /interfaces/Bank



#CS14682398
//10.228.32.39/Bank/EEQ /interfaces/Bank  cifs    credentials=/etc/high_credentials,uid=eeqadm,gid=sapsys,rw 0 0


[root@mgggbjpeccx15-Production ~]$ cat /etc/high_credentials
username=Highradius
password=jXmaXX0oQu


/etc/bank_credential
username=erpbank 
password=jXmaXX0oQu



[root@sapapp40 data]# lpstat -t |grep -i NPID26853
device for NPID26853: lpd://10.40.110.22


lpadmin -p TSLJA08282 -v lpd://10.152.66.22 -o printer-error-policy=retry-job -E;cupsenable TSLJA08282;cupsaccept TSLJA08282




[root@sapapp26-Production ~]$ lpstat -t |grep -i NPI450E44
device for NPI450E44: lpd://135.116.33.110
NPI450E44 accepting requests since Tue Nov 14 14:35:40 2023
printer NPI450E44 disabled since Tue Nov 14 14:35:40 2023 -




[root@sapapp26-Production ~]$ lpstat -t |grep -i TSLJA08282
device for TSLJA08282: lpd://10.152.66.22
TSLJA08282 accepting requests since Tue Dec 12 04:53:09 2023


printer NPI450E44 disabled since Tue Nov 14 14:35:40 2023 -
        reason unknown
		
printer TSLJA08282 disabled since Tue Dec 12 04:53:09 2023 -
        reason unknown




ttaninlgrcprd	PG5
tscmlprd		PG2
sappoprdc		PG2
ttawebdprd 		PG5



tpadbs tcil from iscsi to 7
ttaninlgrcprd pg5 from iscsi to 7
tsgpprd pg2 iscsi to 7

https://www.youtube.com/watch?v=JXiJNCtWmcA


CS14534903 - The OSCAR software is not installed on server AZ3BWPDB01DR
CS14508576 - The OSCAR software is not installed on server AZ3EFPDB01DR



CHG0311133 CST/CDT - 02/26/2024 - 20:00 - NIX - OGY - HC - VULN - 1Q24-SAPB2
CHG0311134 CST/CDT - 02/26/2024 - 10:00 - NIX - OGY - HC - VULN - 1Q24-SAPB2

KB0014307 




sdf                                  8:80   0  200G  0 disk
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdf





[root@bapv721300 ~]# blkid /dev/sdy
/dev/sdy: UUID="UdawxP-CAzW-W13Q-Dor2-gnqG-yIj2-cfhuy7" TYPE="LVM2_member"
[root@bapv721300 ~]# lsscsi |grep -i sdy
[1:0:10:0]   disk    VMware   Virtual disk     1.0   /dev/sdy

 --- Physical volume ---
  PV Name               /dev/sdy
  VG Name               v72datavg
  PV Size               50.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              12799
  Free PE               12799
  Allocated PE          0
  PV UUID               UdawxP-CAzW-W13Q-Dor2-gnqG-yIj2-cfhuy7

  --- Physical Segments ---
  Physical extent 0 to 12798:
    FREE
	
	[1:0:10:0]   disk    VMware   Virtual disk     1.0   /dev/sdy






