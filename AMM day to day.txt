AMM 	Automated Modular Management

AMM (=Automated Modular Management in imzcloud domain)

IMZCloud\ibmsgaur - Password :   QuV2\Jw7UTzKH%hH  


Open Vpn

openvpn --config /etc/openvpn/client.ovpn --auth-user-pass

openvpn --config /home/rmalik/Downloads/Openvpn/Openvpnclient20200902.ovpn --auth-user-pass



openvpn --config /etc/openvpn/DAL.ovpn  --auth-user-pass
openvpn --config /etc/openvpn/WDC.ovpn  --auth-user-pass



Open VPN error:
ERROR: Linux route add command failed: external program exited with error status: 2
ip link delete tun0
close terminal and reopen a new one and connect back

update-crypto-policies --set LEGACY  (adding this line made TLS error go)



- Login to https://169.53.7.5 using IMZCloud credentials
- Go to "Available Connection Profiles: Yourself (user-locked profile)", once we click on this it will download the new profile (client.ovpn). Save at Desktop
2. Change permissions--
sudo chmod 664 client.ovpn
sudo chown root:openvpn client.ovpn
sudo mv client.ovpn /etc/openvpn/dal-client.ovpn
3. Connect using command--
sudo openvpn --config /etc/openvpn/dal-client.ovpn
(Use IMZCloud credentials to connect when asked)



https://w3id.sso.ibm.com/auth/sps/auth?FedName=samlidp2&FedId=uuid564ae2bf-0164-149c-8dbf-bedb46020ff9
https://ispim.amm.ibmcloud.com/itim/self/Home.do



NEW SERVICENOW LINK
CSM ServiceNow
https://ibmma.service-now.com/

#servicenow-support

-------------------------------------------------------------------------------------------------------------


Kindly assist to disable the crontab job in EP1 - 35 01 * * *
/home/postman/tibsscript/sap_to_moms.sh 2>&1  after the last run on 02
Jan 2018.

Please to do it after 09:00 hrs Singapore Time , on 02 Jan 2018 .

Kindly provide screenshot of crontab job depicting the change.

Thanks & Regards,
Uma Maheshwar Dev

CLDERPAPPP1 / 10.198.0.71



Solution:
login to vm
switch user to postman as per the cronjob detail using su - postman
crontab -l|grep -i sap_to_moms.sh
take the backup of crontab using crontab -l >> /tmp/crontabbackup.txt
crontab -e       gets the crontab in vi editor mode
use / to search the crontab entry inside the file
once the entry is found put a hash # and then save it with esc+:wq
----------------------------------------------------------------------------------------
FS corruption and VM in Maintenance mode with FS corruption

If the issue happens again we will need an e2image of the filesystem ____before____ the fsck is done. Replace /dev/hda1 with the path to the device. # e2image -r /dev/hda1 - | bzip2 > /tmp/02155442.e2i.bz2 But to be completely transparent there might be much we can provide even then. The messages that are being seen are VERY common are not the typical definition of corruption. When do I get "Clearing orphaned inode" errors in /var/log/messages ? https://access.redhat.com/solutions/284603


If the issue still persists after the file system check , collect the strace of resize2fs. The output of the strace command can be provided to the support team to further analyze the issue.

# strace -ffxvto resize2fs.strace resize2fs /dev/testvg/testlv

-------------------------------------------------------------------------------------------------
User creation in Linux:

To create a user account from a shell prompt:

    Open a shell prompt.

    If you are not logged in as root, type the command su - and enter the root password.

    Type useradd followed by a space and the username for the new account you are creating at the command line (for example, useradd jsmith). Press [Enter]. Often, usernames are variations on the user's name, such as jsmith for John Smith. User account names can be anything from the user's name, initials, or birthplace to something more creative.

    Type passwd followed by a space and the username again (for example, passwd jsmith).

    At the New password: prompt enter a password for the new user and press [Enter].

    At the Retype new password: prompt, enter the same password to confirm your selection. 

Modify user with commands found on this link

Creating a local user with specific uid and gid
 1014  2020-03-19 10:58:05 useradd v32adm
 1015  2020-03-19 10:58:19 passwd v32adm
 1016  2020-03-19 10:58:55 usermod -u 20110 v32adm      ->changing the uid of the user
 1017  2020-03-19 10:59:05 usermod -a -G sapsys v32adm  ->adding a new group to the user
 1018  2020-03-19 10:59:15 usermod -g sapsys v32adm     ->making the group primary
 1019  2020-03-19 10:59:19 id v32adm



https://www.tecmint.com/usermod-command-examples/



To fetch local users on any linux server

cat /etc/passwd | grep '/home' | cut -d: -f1
------------------------------------------------------------------------------------------------
App not starting team requested to clear Cache

[root@svaq1srv0 ibmshaidery]# free -g
            total       used       free     shared    buffers     cached
Mem:            31         22          8          0          1         18
-/+ buffers/cache:          3         28
Swap:           13  

#restart goferd daily         restart goferd service daily at 430 hrs system time
30 4 * * * /etc/init.d/goferd restart

0 4 * * * systemctl restart cups.service

# Gofer service restart every 12 hours
0 */12 * * * /sbin/service goferd restart

1. Clear PageCache only.

# sync; echo 1 > /proc/sys/vm/drop_caches

2. Clear dentries and inodes.

# sync; echo 2 > /proc/sys/vm/drop_caches

3. Clear PageCache, dentries and inodes.

# sync; echo 3 > /proc/sys/vm/drop_caches 


Clear the cache
echo3 > /proc/sys/vm/drop_caches

run free -g
total       used       free     shared    buffers     cached
Mem:            31          2         28          0          0          0
-/+ buffers/cache:          2         28
Swap:           13          0         13

Clear cache
sync; echo 1 > /proc/sys/vm/drop_caches

-------------------------------------------------------------------------------

extend LV
add 3 gb to /home/sm5uma 

lvdisplay to search if there is an lv with the name sm5uma if not look for the parent directory whic is home in this case

df -hT /home will give the output as /dev/mapper/VolGroup-lv_home

then check lvdisplay for that path
lvdisplay |grep lv_home  (lv_home is the logical volume name in this case replace it with the actual LV name)



#vgs 
#lvextend -L +40G  /dev/mapper/vg_data-lv_db 
# resize2fs /dev/mapper/vg_data-lv_db 

-----------------------------------------------------------------------------------
LVreduce process
Take a VM snapshot

Check the file type using df -hT:

for ext FS use the below:
The following command shrinks the logical volume lvol1 in volume group vg00 to be 64 megabytes. In this example, lvol1 contains a file system, which this command resizes together with the logical volume. This example shows the output to the command.
# lvreduce --resizefs -L 64M vg00/lvol1
fsck from util-linux 2.23.2
/dev/mapper/vg00-lvol1: clean, 11/25688 files, 8896/102400 blocks
resize2fs 1.42.9 (28-Dec-2013)
Resizing the filesystem on /dev/mapper/vg00-lvol1 to 65536 (1k) blocks.
The filesystem on /dev/mapper/vg00-lvol1 is now 65536 blocks long.

Size of logical volume vg00/lvol1 changed from 100.00 MiB (25 extents) to 64.00 MiB (16 extents).
Logical volume vg00/lvol1 successfully resized.
Specifying the - sign before the resize value indicates that the value will be subtracted from the logical volume's actual size. The following example shows the command you would use if, instead of shrinking a logical volume to an absolute size of 64 megabytes, you wanted to shrink the volume by a value 64 megabytes.
# lvreduce --resizefs -L -64M vg00/lvol1

For xfs, since reduction is not possible the approach is diffrent
Snapshot the server
Backup the data	(backup XFS file system using xfsdump (xfsdump -l 0 -f /home.image /dev/centos_example/home))
Remove current LV (lv remove){(umount /dev/centos_example/home)(lvremove /dev/centos_example/home)}
Create a smaller LV {(lvcreate -L 10G -n home centos_example)(mkfs.xfs /dev/centos_example/home)(mount /dev/centos_example/home /home)
Restore the data (Install xfsdump package which also includes xfsrestore)(xfsrestore -f /home.image /home)

The following command shrinks the logical volume lvol1 in volume group vg00 to be 64 megabytes. In this example, lvol1 contains a file system, which this command resizes together with the logical volume. This example shows the output to the command.
# lvreduce --resizefs -L 64M vg00/lvol1
fsck from util-linux 2.23.2
/dev/mapper/vg00-lvol1: clean, 11/25688 files, 8896/102400 blocks
resize2fs 1.42.9 (28-Dec-2013)
Resizing the filesystem on /dev/mapper/vg00-lvol1 to 65536 (1k) blocks.
The filesystem on /dev/mapper/vg00-lvol1 is now 65536 blocks long.

  Size of logical volume vg00/lvol1 changed from 100.00 MiB (25 extents) to 64.00 MiB (16 extents).
  Logical volume vg00/lvol1 successfully resized.
Specifying the - sign before the resize value indicates that the value will be subtracted from the logical volume's actual size. The following example shows the command you would use if, instead of shrinking a logical volume to an absolute size of 64 megabytes, you wanted to shrink the volume by a value 64 megabytes.
# lvreduce --resizefs -L -64M vg00/lvol1


hnosolmn:/home/ibmrmalik # blkid /dev/sdh   to check if the unused disk is actually not used up somewhere

LVreduce and free one disk

[root@btksjddb01 ~]# cat /etc/fstab |grep -i backup
/dev/sjdarchvg/backup_lv        /backup ext4    defaults        1 2

umount the lv 

run e2fsck to check for errors

[root@btksjddb01 ~]# pvs -o+pv_used |grep -i sjdarchvg
   PV         VG        Fmt  Attr PSize   PFree   Used
  /dev/sdd   sjdarchvg lvm2 a--  128.00g      0  128.00g
  /dev/sdg   sjdarchvg lvm2 a--   50.00g  13.99g  36.00g


reduce by 50GB

lvreduce --resizefs -L -50G /dev/sjdarchvg/backup_lv

[root@btksjddb01 ~]# lvreduce --resizefs -L -50G /dev/sjdarchvg/backup_lv
fsck from util-linux 2.29.2
/dev/mapper/sjdarchvg-backup_lv: clean, 27082/6684672 files, 2234810/26738688 blocks
resize2fs 1.43.8 (1-Jan-2018)
Resizing the filesystem on /dev/mapper/sjdarchvg-backup_lv to 13631488 (4k) blocks.
The filesystem on /dev/mapper/sjdarchvg-backup_lv is now 13631488 (4k) blocks long.

  Size of logical volume sjdarchvg/backup_lv changed from 102.00 GiB (26112 extents) to 52.00 GiB (13312 extents).
  Logical volume sjdarchvg/backup_lv successfully resized.




[root@btksjddb01 ~]# pvs -o+pv_used |grep -i sjdarchvg
  /dev/sdd   sjdarchvg lvm2 a--  128.00g  14.00g 114.00g
  /dev/sdg   sjdarchvg lvm2 a--   50.00g  50.00g      0



[root@btksjddb01 ~]# pvmove /dev/sdg
  No data to move for sjdarchvg.
  
  
  [root@btksjddb01 ~]# vgreduce sjdarchvg /dev/sdg
  Removed "/dev/sdg" from volume group "sjdarchvg"



[root@btksjddb01 ~]# e2fsck -f /dev/sjdarchvg/backup_lv
e2fsck 1.43.8 (1-Jan-2018)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information
/dev/sjdarchvg/backup_lv: 27082/3407872 files (0.3% non-contiguous), 2027146/13631488 blocks

mount -a


[root@btksjddb01 ~]# df -hT /backup
Filesystem                      Type  Size  Used Avail Use% Mounted on
/dev/mapper/sjdarchvg-backup_lv ext4   51G  6.7G   42G  14% /backup



[root@btksjddb01 ~]# pvs -o+pv_used |grep -i sjdarchvg     or pvs |grep -i sjdarchvg
  /dev/sdd   sjdarchvg lvm2 a--  128.00g  14.00g 114.00g



└─sjdappvg-usr_sap_ccms_lv            254:31   0   13G  0 lvm  /usr/sap/ccms
sdg                                     8:96   0   50G  0 disk
[root@btksjddb01 ~]#

Removing the pv and then the disk from VC


[root@btksjddb01 ~]# pvs
  PV         VG        Fmt  Attr PSize   PFree
  /dev/sda2  rootvg    lvm2 a--   95.49g  18.49g
  /dev/sdb   vgswap    lvm2 a--   48.00g      0
  /dev/sdc   sjdlogvg  lvm2 a--   64.00g   8.00g
  /dev/sdd   sjdarchvg lvm2 a--  128.00g  14.00g
  /dev/sde   sjddatavg lvm2 a--  312.00g 110.00g
  /dev/sdf   sjdappvg  lvm2 a--  160.00g  71.00g
  /dev/sdg             lvm2 ---   50.00g  50.00g
[root@btksjddb01 ~]# pvdisplay -m /dev/sdg
  "/dev/sdg" is a new physical volume of "50.00 GiB"
  --- NEW Physical volume ---
  PV Name               /dev/sdg
  VG Name
  PV Size               50.00 GiB
  Allocatable           NO
  PE Size               0
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               yL5ry7-mZAw-j8E3-QD6I-HZNg-IEH0-sx9OT6


remove the pv from lvm
pvremove "/dev/sdg"

verify with pvs output and this should not show up now


also verify lsblk and blkid for sdg

1003  2022-05-28 15:17:02 cat /etc/fstab |grep -i backup
 1004  2022-05-28 15:17:21 df -hT /backup
 1005  2022-05-28 15:17:37 df -hT /dev/sjdarchvg/backup_lv
 1006  2022-05-28 15:18:12 pvs -o+pv_used |grep -i sjdarchvg
 1007  2022-05-28 15:21:02 lvreduce --resizefs -L -50G /dev/sjdarchvg/backup_lv
 1008  2022-05-28 15:21:25 pvs -o+pv_used |grep -i sjdarchvg
 1009  2022-05-28 15:22:19 pvmove /dev/sdg
 1010  2022-05-28 15:22:56 vgreduce sjdarchvg /dev/sdg
 1011  2022-05-28 15:23:36 e2fsck -f /dev/sjdarchvg/backup_lv
 1012  2022-05-28 15:24:12 mount -a
 1013  2022-05-28 15:24:14 df -hT
 1014  2022-05-28 15:24:23 df -hT /backup
 1015  2022-05-28 15:24:44 pvs -o+pv_used |grep -i sjdarchvg
 1016  2022-05-28 15:24:57 lsblk
 1017  2022-05-28 15:30:11 blkid /dev/sdg
 1018  2022-05-28 15:30:35 pvs
 1019  2022-05-28 15:34:40 pvdisplay -m /dev/sdg
 1020  2022-05-28 15:37:00 pvremove "/dev/sdg"
 1021  2022-05-28 15:37:05 pvs
 1022  2022-05-28 15:37:12 blkid /dev/sdg
 1023  2022-05-28 15:37:17 lsblk
 1024  2022-05-28 15:37:23 history
 1025  2022-05-28 15:39:28 pvs |grep -i sjdarchvg
 1026  2022-05-28 15:43:25 ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[/]' '{print $4,"- SCSI",$7}'


-----------------------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------

 find out if there is a DR server for the following server
go into the web client for mon01 => site recovery  => protection groups  => MTS protection group

----------------------------------------------------------------------------------------------------------------
To check disk utilization for the current directory

du -mch --max-depth=1 .


du -a <path of the folder to check> |sort -n -r |head -n 15
du -a . |sort -n -r |head -n 15
ls -larth | head

du -h . | sort -hr | head -n10

Recently created files
find / -xdev -mtime -30

find path -mtime +2 -exec rm -rf {} \; ==> it will delete older then 2 days logs 

du -h <folder path>

find . -xdev -type f -size +1000000
find . -xdev -type f -size +1G
find . -xdev -type f -size +500M
find . -xdev -type f -size +1G
find / -type f -size +100M

Find / -name ‘*’ 	List all files and directories recursively starting from /

lsof /var |grep -i deleted
kill the pids holding those deleted files
 

du -xhs /opt/* | sort -h


du -xhs . | sort -h

folder size du -sh <FS name>

--------------------------------------------------------

Queue names for bin transfer are in the Siebel queues doc on Wiki
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Siebel_queues
-----------------------------------------------------------------------------------------------------------------------
lv extend task

first check the lv details

[root@EMCBOPRD ibmrmalik]# lvdisplay |grep -i pbosybase_lv
  LV Path                /dev/pbodatavg/pbosybase_lv
  LV Name                pbosybase_lv


[root@EMCBOPRD ibmrmalik]# df -hT grep /sybase/PBO
df: `grep': No such file or directory
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/pbodatavg-pbosybase_lv


                     ext3  7.9G  6.2G  1.4G  83% /sybase/PBO

df -hT to see the file system extension


--------------------------------------------------------------------------------------------------------------------------

Time zone change


cd /etc
1.cp localtime /tmp/localtime.old
2.rm localtime 

3. ln -s /usr/share/zoneinfo/Singapore localtime     change Singapore to the timezne u need to change to from the timezone list
4. date 

ln -s /usr/share/zoneinfo/America/New_York localtime

to get timezone list
ls /usr/share/zoneinfo

To get the path of any timezone check wiki to get the path IANA time zone database in wiki page https://en.wikipedia.org/wiki/List_of_time_zone_abbreviations

/usr/share/zoneinfo/America/New_York	EDT
/usr/share/zoneinfo/Asia/Jakarta   

ln -s /usr/share/zoneinfo/Europe/Madrid localtime	CEST

/usr/share/zoneinfo/Asia/Jakarta   to set WIB

CEST 2018 is CET
Below file gives the timezone to select any specific with ref to any other server that has correct timezone
[root@unqsapbpcdev ibmrmalik]# cat /etc/sysconfig/clock
ZONE="America/Bogota"

In Suse it can be done via YaST


PST->Global->pst8pdt

--------------------------------------------------------------------------------------------------------------------------

CIFS ports
Ports to be open bidirectional 
139 and 445

For NFS
 Port 111 (TCP and UDP) and 2049 (TCP and UDP) for the NFS server
 
 To test if the NFS server port is open
 
 netstat -ntlp | grep 111
 
 
 exportfs -rav

CIFS mount

//Spsvopivapp01/oom/JPP /wts_oom_JPP cifs username=msg_jp1,passwd=Brguest#123,_netdev,uid=20000,gid=3050 0 0

giving gid and uid in fstab and then mounting ensures proper permissions.

NFS consumers
To find what all NFS clients are connected to a NFS server
netstat | grep :nfs
ss -a|grep nfs
cat /var/lib/nfs/rmtab


https://bdoga.com/replacement-for-netstat/
SS stands for “Socket Statistics” and operates in a manner similar to netstat.
ss -lt
ss -ltp



//10.150.21.221/Upload/ITInventory/SBP/Upload/error             /usr/sap/s4hana/SBP/ITInventory/Upload/error            cifs credentials=/etc/Dystar_world,vers=3.0   WORKING entry in fstab server is Windows 2012 R2 Datacenter, which use 3.02 by default win 2012 uses 3.0

//10.1.161.14/Dystar-FTP/LocalUser/PIL/IB/ARP/INV      /usr/sap/interfaces/ARP/PIL/IB/INV   cifs credentials=/etc/Dystar_credentials   0   0  this simple entry in fstab works fine

mount.cifs -o user=svc.elo.sap,dom=DOMA1,password=s06H3OV6nyapFDq1fqmh //10.92.157.26/DocXtractorII-System /usr/transfer/eloinvoice

u just need cred and the target server. Access to target server is not reqd if ping is working fine.
fstab entry
//10.92.157.26/DocXtractorII-System      /usr/transfer/eloinvoice       cifs  credentials=/etc/eloinvoice_credential

//10.92.157.26/DocXtractorII-System      /usr/transfer/eloinvoice       cifs  credentials=/etc/eloinvoice_credential,uid=XXX,gid=XXX



//10.3.1.1/SAPEXCHANGE /mnt/sapexchangeIT/   -t cifs -o username=YSRVSAPEC,password=EC_SAP00,uid=908,gid=5003 


mount command
mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/IBP /usr/sap/s4hana/SBD/S4HANA_DC/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev
mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev,nofail
mount.cifs //10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP  -o username=YSRVSAPEC,passwd=EC_SAP00,_netdev,nofail,


fstab entry 
//10.1.161.14/Dystar-FTP/S4HANA_DC/SBD/FC /usr/sap/s4hana/SBD/S4HANA_DC/FC cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=908,gid=5003,_netdev 0 0 

//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=20210,gid=3050,_netdev,nofail 0 0

//10.1.161.14/Dystar-FTP/S4HANA_DC/SBQ/IBP /usr/sap/s4hana/SBQ/IBP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=20210,gid=3050,_netdev,sec=ntlm 0 0

//10.1.161.14/Dystar-FTP /Dystar-FTP cifs username=YSRVSAPEC,passwd=EC_SAP00,uid=20220,gid=3050,sec=ntlm

//10.210.18.60/SAP_Extracts     /interfaces/Azure/      cifs    credentials=/etc/credentials,uid=evtadm,gid=sapsys,sec=ntlmsspi 

Verify the CIFS and its failure 
 mount -vvv -t cifs -o credentials=/etc/credentialsDownloads989,uid=eepadm,gid=sapsys //172.22.5.20/CUSTOMER-PO/SAP_DOWNLOAD  /interfaces/SAPReports/3325


alternatively make the fstab entry and then mount the FS using mount -a

mount /usr/transfer/eloinvoice

******************************************************************************************************************************

[root@APLBREDE1 ~]# cat /etc/eloinvoice_credential
username=DOMA1\svc.elo.sap
password=s06H3OV6nyapFDq1fqmh

validate cifs for errors
 mount -v -t cifs //10.102.96.38/Interface /Interface -o credentials=/etc/credentials
 
 run like above to see what is failing
 
CIFS

mount -t cifs -o credentials=/etc/credentialsrm,uid=20400,gid=3050  //172.31.24.143/Output/PDF /ZEH_SDS_IMPORT

[root@ti3s4dap02 ~]# cat /etc/credentialsrm
username=tis_sap
domain=sea.takasago.com
password=T@ka11$$


mount -t cifs -o credentials=/etc/credentialsrm,uid=20400,gid=3050  //172.26.1.35/SAP /TIS_Interface
mount -t cifs -o credentials=/etc/credentialsrm,uid=20400,gid=3050  //172.31.24.143/Output/PDF /ZEH_SDS_IMPORT

CIFS windows share source should be with // and not \\

dmesg gives the proper reason for not being able to mount

dmesg -T    timestamp included

fstab entry
//172.31.24.143/Output/PDF      /ZEH_SDS_IMPORT cifs    credentials=/etc/credentialsrm,uid=20400,gid=3050,vers=2.0,_netdev      0 0

***********************************************************************************************************************************************

A couple of things to check out. I do something similar and you can test mount it directly using the mount command to make sure you have things setup right.
Permissions on credentials file

Make sure that this file is permissioned right.

$ sudo ls -l /etc/smb_credentials.txt 
-rw-------. 1 root root 54 Mar 24 13:19 /etc/smb_credentials.txt

Verbose mount

You can coax more info out of mount using the -v switch which will often times show you where things are getting tripped up.

$ sudo mount -v -t cifs //server/share /mnt \
    -o credentials=/etc/smb_credentials.txt

Resulting in this output if it works:

mount.cifs kernel mount options: ip=192.168.1.14,unc=\\server\share,credentials=/etc/smb_credentials.txt,ver=1,user=someuser,domain=somedom,pass=********

Check the logs

After running the above mount command take a look inside your dmesg and /var/log/messages or /var/log/syslog files for any error messages that may have been generated when you attempted the mount.
Type of security

You can pass a lot of extra options via the -o .. switch to mount. These options are technology specific, so in your case they're applicable to mount.cifs specifically. Take a look at the mount.cifs man page for more on all the options you can pass.

I would suspect you're missing an option to sec=.... Specifically one of these options:

   sec=
       Security mode. Allowed values are:
       ·   none - attempt to connection as a null user (no name)
       ·   krb5 - Use Kerberos version 5 authentication
       ·   krb5i - Use Kerberos authentication and forcibly enable packet 
           signing
       ·   ntlm - Use NTLM password hashing
       ·   ntlmi - Use NTLM password hashing and force packet signing
       ·   ntlmv2 - Use NTLMv2 password hashing
       ·   ntlmv2i - Use NTLMv2 password hashing and force packet signing
       ·   ntlmssp - Use NTLMv2 password hashing encapsulated in Raw NTLMSSP
           message
       ·   ntlmsspi - Use NTLMv2 password hashing encapsulated in Raw 
           NTLMSSP message, and force packet signing

       The default in mainline kernel versions prior to v3.8 was sec=ntlm. 
       In v3.8, the default was changed to sec=ntlmssp.

You may need to adjust the sec=... option so that it's either sec=ntlm or sec=ntlmssp.
References

    Thread: mount -t cifs results gives mount error(13): Permission denied


Details on windows share
https://wiki.centos.org/TipsAndTricks/WindowsShares
-------------------------------------------------------------------------------

SAP queue

Area- MSD-Tech & Subarea - APSSAPTechnical


-----------------------------------------------------------------------------------

146.89 linux server access denied issue

root
Set44now@ 
or May55now#	 image@2019@CMAS 
Chang3me
Th67#4hg
-------------------------------------------------------------------------------------
USE THIS TO REBOOTSTRAP

rebootstrapping and troubleshooting   IMZ login for user not working but for us it is working

service sssd stop;rm -rf /var/lib/sss/db/* ;rm -rf /etc/krb5.keytab ; kdestroy;chef-client 

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Chef (https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Chef)  

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Customers   customer short code

before RE-bootstrapping run cmd from chef server
[root@PAR01AMMCHEF01 ~]# CHEF_ORG=cma knife node show smdbuatum3.imzcloud.ibmammsap.local
Node Name:   smdbuatum3.imzcloud.ibmammsap.local
Environment: cma_production
FQDN:        smdb-uat-um3.blx.cma-cgm.com
IP:          10.5.26.20
Run List:    role[baseos]
Roles:       baseos, itcs104  

Password Maximum age from chef and whitelisted ids
export CHEF_ORG=
knife node show sjmdfpaa01.imzcloud.ibmammsap.local -a policy_linux_pass_max_age


org name for IBM internal servers fmsprodinfra

ON server itself
 686  2018-09-12 09:16:07 rpm -qa|grep -i chef
  687  2018-09-12 09:16:34 rpm -e chef-12.19.33-1.el6.x86_64
  688  2018-09-12 09:16:52 rm -rf /etc/chef /opt/chef /var/chef


ON chef server
 504  2018-09-12 09:18:54 export CHEF_ORG=cpw
  505  2018-09-12 09:19:00 knife environment list
  506  2018-09-12 09:20:23 knife node list|grep -i DCGHANAPREAP1
  507  2018-09-12 09:21:29 knife node delete -y dcghanapreap1.imzcloud.ibmammsap.local;knife client delete -y dcghanapreap1.imzcloud.ibmammsap.local
  509  2018-09-12 09:23:30 cd /root
  510  2018-09-12 09:23:38  ./root/bootstrap_v12.sh -o cpw -n DCGHANAPREAP1 -l -d imzcloud.ibmammsap.local -t osonly -e cpw_production


New bootstrap command

before RE-bootstrapping run cmd from chef server
[root@PAR01AMMCHEF01 ~]# CHEF_ORG=cma knife node show smdbuatum3.imzcloud.ibmammsap.local
Node Name:   smdbuatum3.imzcloud.ibmammsap.local
Environment: cma_production
FQDN:        smdb-uat-um3.blx.cma-cgm.com
IP:          10.5.26.20
Run List:    role[baseos]
Roles:       baseos, itcs104  

switch to cmschefadmin
rake bootstrap:cms3x[root,ip address,policy_name,policy_group,node_name,cms_site,ou}

username is root always 

ip is imz ip 

policy_group is cms3x_cfg

policy_name is production or development depending on the type of environment

node_name is the full hostname of your vm

cms_site is LON02AMMCHEF01 for lon and so on

You can normally omit the "site" and "OU" arguments because rake can figure them out.

[root@HKG02AMMCHEF01 ~]# export CHEF_ORG=lbd
[root@HKG02AMMCHEF01 ~]# echo $CHEF_ORG
lbd
[root@HKG02AMMCHEF01 ~]# knife node list
LBDTQ1App00.imzcloud.ibmammsap.local

[root@HKG02AMMCHEF01 ibmrmalik]# knife node list
LBDTQ1App00.imzcloud.ibmammsap.local.imzcloud.ibmammsap.local

[root@HKG02AMMCHEF01 ~]# knife node show LBDTQ1App00.imzcloud.ibmammsap.local
Node Name:   LBDTQ1App00.imzcloud.ibmammsap.local
Environment: lbd_production


See https://github.kyndryl.net/CMS/cms-chef/wiki/Bootstrapping-a-CMS3.x-Node
If you NEED to rebootstrap it with roles/environments (the way you are trying now) you will need to get the chef server’s root user public key added to the /root/.ssh/authorized_keys file on the node.

Most CMS3.x nodes are bootstrapped automatically by OPaaS. However if a node needs to be manually bootstrapped, follow this procedure.

Login to the chef server (ie dal09ammchef01) as the cmschefadmin userid (or use su - cmschefadmin)
Add the public ssh key for cmschefadmin (/home/cmschefadmin/.ssh/id_rsa.pub) to /root/.ssh/authorized_keys o the target node.

cd /home/cmschefadmin/cms-chef

Run CHEF_ORG=<org> rake bootstrap:cms3x[ ... ] to bootstrap the node
Run rake -D bootstrap:cms3x for documentation.
Note: You can normally omit the "site" and "OU" arguments because rake can figure them out.
Example: CHEF_ORG=apf rake bootstrap:cms3x[root,10.15.2.31,cms3x_cfg,production,apfs4qqdb.imzcloud.ibmammsap.local]

ECCX04.imzcloud.ibmammsap.local]
  419  2019-03-19 05:43:59 cd /home/cmschefadmin/cms-che
  420  2019-03-19 05:44:05 rake bootstrap:cms3x[root,10.133.18.21,cms3x_cfg,production,MGGGBJECCX04.imzcloud.ibmammsap.local]
  421  2019-03-19 05:52:39 ssh MGGGBJPECCX04
  422  2019-03-19 05:52:47 exit
  423  2019-03-19 06:50:42 export CHEF_ORG=mgg
  424  2019-03-19 06:50:49  rake bootstrap:cms3x[root,10.133.18.21,cms3x_cfg,production,MGGGBPECCX04.imzcloud.ibmammsap.local,,'IBM AMM Customers/Meggitt PLC (0000023807)/Servers - Linux]
  425  2019-03-19 06:51:04 cd /home/cmschefadmin/cms-chef
  426  2019-03-19 06:51:12 cd /home/cmschefadmin/cms-chef
  427  2019-03-19 06:51:17  rake bootstrap:cms3x[root,10.133.18.21,cms3x_cfg,production,MGGGBPECCX04.imzcloud.ibmammsap.local,,'IBM AMM Customers/Meggitt PLC (0000023807)/Servers - Linux]

genric cmd- rake bootstrap:cms3x[username,address,policy_name,policy_group,node_name,cms_site,ou]
cms_site is optional
ou is optional

e.g of the above cmd-  rake bootstrap:cms3x[root,10.7.96.22,cms3x_cfg,production,mips4devas.imzcloud.ibmammsap.local,fra02amm,'IBM AMM MIP- Linux'] 



----------------------------------------------------------------------------------------------

Add space

Steps to add space- 
            parted /dev/sdg mklabel GPT
	parted /dev/sdg mkpart primary ext2 1M 100%
	parted /dev/sdg set 1 lvm on
	vgcreate toolsvg /dev/sdg1
	 lvcreate -L 5G -n ITM toolsvg
	mkdir  /opt/monitor/IBM
	mkfs.ext4 /dev/toolsvg/ITM
	
	
	XFS format a new LV  mkfs.xfs /dev/vg_xfs/xfs_db

use df -hT that gives the file extension also. If the file system is not ext but xfs then resize2fs does not work instead use
xfs_growfs <full path of LV extended>

xfs_growfs: /dev/mapper/ampappvg-sapmnt_AMP_lv is not a mounted XFS filesystem
[root@kstampsrcs ibmshaidery]# df -hT /sapmnt/AMP/
Filesystem                         Type  Size  Used Avail Use% Mounted on
/dev/mapper/ampappvg-sapmnt_AMP_lv xfs   125G  123G  2.3G  99% /sapmnt/AMP
i have added 12GB to this fs and when try to run xfs_growfs command facing above issue
can you try with FS name ?
instead of LV name in xfs_growfs, put FS name



https://ibm.webex.com/meet/rmalik

btrfs filesystem resize +10G/M /mnt  

btrfs filesystem resize max / for adding up al the space available on the VG

to extend the btrfs 
lvresize -r -L +50G /dev/vg/machines

-----------------------------------------------------------------------------------

Add swap space   KB0015222   replication should be stopped new VM new LV and new swap of desired size should be done

parted /dev/sdm mklabel GPT
   parted /dev/sdm mkpart primary ext4 1M 100%
   parted /dev/sdm set 1 lvm on
   vgextend vg00 /dev/sdm1
   swapoff /dev/vg00/lv_swap
   lvextend -l+100%FREE /dev/vg00/lv_swap
   mkswap /dev/vg00/lv_swap
   swapon /dev/vg00/lv_swap

[root@ps2-pox-ci ibmrmalik]# cat /proc/swaps
Filename                                Type            Size    Used    Priority
/mnt/resource/swapfile                  file            50331644        0       -1


-----------------------------------------------------------------------------------
If any Linux server does not allow u to login and throws the access denied error then get the sssd service restarted

---------------------------------------------------------------------------------------------------------------------------


AV notification: AMM - Trend agent offline / out of date / not installed

1) For Linux servers:
- /etc/init.d/ds_agent stop - and wait until there is no processes - ps aux | grep ds_agent
- And after that:
 /etc/init.d/ds_agent start 
 /etc/init.d/ds_agent reset 
 /opt/ds_agent/dsa_control -a dsm://169.55.28.73:4120/			for port in $(echo "4118 4119 4120 4122"); do nc -zv 169.55.28.72 $port; done
- And after that ask Deniz Mazlum/San Francisco/IBM to take a look on DSM console.
William Zayas for Trend
#ciso-tm-ca for av issues

Yammer link
https://web.yammer.com/main/org/kyndryl.com/groups/eyJfdHlwZSI6Ikdyb3VwIiwiaWQiOiIxMTM5NzE2MDk2MDAifQ/feed?new=false&postType=ALL&sortBy=CREATED_AT

    robert.montavon@kyndryl.com he is person from Trend micro
	Ashok Rondla , Mohammed Nizamuddin



[root@lbuqf1ap01 ds_agent]# ./dsa_query -c "GetComponentInfo"  -r "au" "Offline" ;./dsa_query -c "GetComponentInfo"  -r "au" "AM.mode" ; ./dsa_query -c "GetAgentStatus" -r "au" "lastAgentToManagerSession"
Component.AM.mode: not-capable
AgentStatus.lastAgentToManagerSession: 1660017660

Security team has to fix, after ds agent is updated to latest if u get above, post in yammer and let security guys fix, you can close ur task as success.

Please use the following commands to reset and reactivate the dsa agents that are showing Component.AM.mode: not-capable:

cd /opt/ds_agent/

./dsa_control -r

./dsa_control -a dsm://169.55.28.72:4120




KB0014302 Troubleshooting Trend Micro Deep Security Agent (DSA) Antivirus on Windows and Linux

KB0016632 Installing/Upgrading Trend Micro DSA (Deep Security Agent) Antivirus on Linux

2) For windows servers:
- run "cmd" as Administrator and cd "C:\Program Files\Trend Micro\Deep Security Agent\"
- on cmd console: dsa_control.cmd -s=0
- from 'windows services' stop service "Trend Micro Deep Security Agent" and after awhile start service "Trend Micro Deep Security Agent"
- on cmd console: dsa_control.cmd -r
- on cmd console: dsa_control -a dsm://169.55.28.72:4120/
- And after that ask Deniz Mazlum/San Francisco/IBM to take a look on DSM console.

------------------------------------------------------------------------------------------------------
In the file: 
/etc/sysconfig/network/ifcfg-eth1
we need to add 2 lines:
 
GATEWAY = 10.115.128.1
DEFROUTE = yes

And remediate the AV issue on the servers below.
They do not report to AV console, use  KB0014302 Troubleshooting Trend Micro Deep Security Agent (DSA) Antivirus on Windows and Linux .
(Uninstall and reinstall the Agent, might need to reboot)


-------------------------------------------------------------------------------------------------------------------------------

hostname -f does not resolve FQDN

check the host file at cat /etc/hosts and ensure the hostfile entry is correct. It should have both entries one for CFN ip and other for IMZ ip

10.72.0.114     snchtnapd61.hec.network.lan     snchtnapd61
10.73.10.114    snchtnapd61.hec.network.lan     snchtnapd61

sequence is ip,FQDN and then short name

-----------------------------------------------------------------------------------------------------------------------------------
User creation in SFTP server:

transfer to IAM
Area: App-AMM	Sub area: ID Management	BIN: IAM

SNOW queue for IAM
SQ-CISO-GA-IAM	or MA-ASGN-CIS-IAM

ServiceNow: How To Request Support From ServiceNow Team
KB0010507  


Slack for IAM
cms-sq-id-access-cont

Slack for chef team
sq-chef-infra
----------------------------------------------------------------------------------------------------------

Vacation Calendar - https://vplanner.dst.ibm.com/team/index/48747/
On -call Page :- http://msdwindows.boulder.ibm.com/cmsindex.htm#SAP


Dashboard  :- http://146.89.3.136:8080/AMM_Dashboard/
Dashboard with performer wise backlog http://146.89.3.136:8080/AMM_Dashboard/BacklogsBINWise.jsp?bin=Steady State&customer=all
personal link http://146.89.3.136:8080/DynaAMM/getBINForm.jsp?sev1=rmalik
------------------------------------------------------------------------------------------------------------------

Find any user in any server in Linux

grep <username> /etc/shadow
---------------------------------------------------------------------------------------------------------------------

==============================  RESET USER ACCOUNT ===============================
DB ids are set to non-expire or not 
We ( AMM ) can't reset password for IMZ id even can't run rpam_tally command for IMZ user. IAM team reset the the password for IMZ id.

chage -l <username>
chage -l userNameHere   gives details of last pw change, expiry etc

to set pw to non expiry
passwd -x 99999 username


pam_tally2 --user=****adm
If user locked, failures will show some big numbers (  6 7 )
pam_tally2 --user=***adm --reset
pam_tally2 --user=username --reset

To fetch list of locked users
pam_tally2 --user


RHEL 8
https://www.2daygeek.com/lock-unlock-disable-enable-user-account-linux/

https://www.golinuxhub.com/2014/08/how-to-check-lock-status-of-any-user/



https://access.redhat.com/solutions/6046261
pam_tally2 --reset equivalent for RHEL 8 faillock --reset 

faillock --user  ibmavadgave


To display authentication failure records for username:

Raw
# faillock --user username
To reset authentication failure records for username:

Raw
# faillock --user username --reset

pam_tally2 is deprecated in RHEL8 and pam_faillock should be used in EL7 and EL8 instead


Other ways
/etc/shadow file.

Run the passwd command with the -l switch, to lock the given user account.

# passwd -l daygeek

Locking password for user daygeek.
passwd: Success
You can check the locked account status either by using passwd command or filter the given user name from ‘/etc/shadow’ file.

Checking the user account locked status using passwd command.
# passwd -S daygeek
or
# passwd --status daygeek

daygeek LK 2019-05-30 7 90 7 -1 (Password locked.)
The above output will show few pieces of information about the status of the password for the given account. In our example the output is LK meaning the password is locked.

LK: Password locked
NP: No password
PS: Password set
If the account is already locked, two exclamation marks will be prefixed to the user password at ‘/etc/shadow’ file.

# grep daygeek /etc/shadow

daygeek:!!$6$tGvVUhEY$PIkpI43HPaEoRrNJSRpM3H0YWOsqTqXCxtER6rak5PMaAoyQohrXNB0YoFCmAuh406n8XOvBBldvMy9trmIV00:18047:7:90:7:::
Run the passwd command with the -u switch to unlock the given user account.

# passwd -u daygeek

Unlocking password for user daygeek.
passwd: Success


Method-2: Locking & Unlocking user account with usermod command
The ‘usermod’ command is often used by Linux administrator’s to modify a given user account information. It is primarily used to add a user to a specific group.

Run the usermod command with the -L switch to lock the given user account.

# usermod --lock daygeek
or
# usermod -L daygeek
Locked user account status can be verified using passwd command or filtering the user from the ‘/etc/shadow’ file because usermod command does not have that option.

Checking the user account locked status using passwd command.

# passwd -S daygeek
or
# passwd --status daygeek

daygeek LK 2019-05-30 7 90 7 -1 (Password locked.)
Checking the user account locked status using /etc/shadow file.

# grep daygeek /etc/shadow

daygeek:!!$6$tGvVUhEY$PIkpI43HPaEoRrNJSRpM3H0YWOsqTqXCxtER6rak5PMaAoyQohrXNB0YoFCmAuh406n8XOvBBldvMy9trmIV00:18047:7:90:7:::
Run the usermod command with the -U switch to unlock the given user account.

# usermod --unlock daygeek
or
# usermod -U daygeek

Method-3: Enable and Disable SSH access for user in Linux
Alternatively, a user account can be locked by assigning the nologin shell to the given user. Once the user account is disabled, you will not be able to access the Linux system via SSH until the user account is activated. Run the below command to disable the user account.

# usermod -s /sbin/nologin daygeek
User account locked status can be verified from the ‘/etc/shadow’ file.

# grep daygeek /etc/passwd

daygeek:x:2240:2243::/home/daygeek:/sbin/nologin
We can activate the disabled user account by changing the old shell.

# usermod -s /bin/bash daygeek
Method-3(a): Changing the shell to /dev/null
‘/dev/null’ is a simple device which is implemented in software and not corresponding to any hardware device on the system.

dev/null looks empty when you read from it whereas data written to this device simply “disappear.”

User can be disabled by changing the shell to /dev/null as shown below.

# usermod -s /dev/null daygeek
It can be reversed by changing the shell back to the default shell of the user.

# usermod -s /bin/bash daygeek
Method-3(b): Changing the shell to false
‘/bin/false’ is just a binary that immediately exits, returning false, when it’s called. The user logs in and immediately sees the login prompt again.

Alternatively, User can be disabled by changing the shell to /bin/false as shown below.

# usermod -s /bin/false daygeek
It can be reversed by changing the shell back to the default shell of the user.

# usermod -s /bin/bash daygeek
Method-4: Locking & unlocking users with chage command
The ‘chage’ command is used to view and modify user password expiration information. It can be used to lock and unlock user accounts.

Set the expiration date to ‘0’ to lock user account with chage command as shown below.

# chage -E0 daygeek
When you set the expiration date to ‘0’, which means that the account expires a day after January 1, 1970. Please check the following output for details.

# chage -l daygeek
Last password change                    : Jan 07, 2021
Password expires                        : never
Password inactive                       : never
Account expires                         : Jan 02, 1970
Minimum number of days between password change        : 0
Maximum number of days between password change        : 99999
Number of days of warning before password expires     : 7
To reverse this change, run the following command.

# chage -E -1 daygeek



-------------------------------------------------------------------------------------------------

Syb987#pw

cat /etc/security/serviceids <id>   to see if it is allowed to login if listed here it is not so u need to comment it

to unlock any user

 passwd -u <uid>


to reset pw:
passwd <uid>

1--User set to non-expiry (In Chef file we can check if this user set to non-expiry), then just we need to rest it no password change 
if user locked 
2.---User not set to non-expiry and its set to expire in 90 days, then in that case we can change password only when the user provide teh default password


Use ‘/etc/pam.d/password-auth‘ configuration file to configure login attempts accesses. Open this file and add the following AUTH configuration line to it at beginning of the ‘auth‘ section.

auth        required      pam_tally2.so  file=/var/log/tallylog deny=3 even_deny_root unlock_time=1200

Now, verify or check the counter that user attempts with the following command.
pam_tally2 --user=tecmint


How to reset or unlock the user account to enable access again.
pam_tally2 --user=tecmint --reset

Verify login attempt is reset or unlocked
pam_tally2 --user=tecmint

to unlock all account

pam_tally2 --reset

refer
https://www.tecmint.com/use-pam_tally2-to-lock-and-unlock-ssh-failed-login-attempts/

 
-------------------------------------------------------------------------------------------------------------
if user says reset his password, so, we just need to run ( pam_tally2 --user=***adm --reset ) command to reset his password. 
we can't set the password for user, even if user mentioned password in mail / ticket to set that one.
-------------------------------------------------------------------------------------------------------------
we just can set the default password to DB user if they tell us reato do  
------------------------------------------------------------------------------------------------------------------------------


To check if any mount is readonly	sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh


df -h is hung issue	run strace df -h and see where it gets stuck.

If 'strace' is not a typo you can use command-not-found to lookup the package that contains it, like this

https://scc.suse.com/packages/20381863
strace not installed in suse 15
SUSEConnect -p sle-module-development-tools/15.2/x86_64
zypper install strace-5.3-1.44

zypper install net-tools-deprecated
this command need to execute, then you can find "ifconfig, netstat" etc., command

Note: ifconfig and route Are Obsolete
The ifconfig and route tools are obsolete. Use ip instead.

Check if the server was booted recently, if so chk if service is in stopped state. If stoped start it

check the fs stuck in fstab or mtab   /etc/fstab or /etc/mtab

chkconfig --list |grep nfs

[root@CLDBOBIADWD1 ibmrmalik]# chkconfig --list |grep nfs
nfs             0:off   1:off   2:on    3:on    4:on    5:on    6:off
nfslock         0:off   1:off   2:off   3:on    4:on    5:on    6:off

0-6  runlevels are there

3-4-5 = should be  on 

chkconfnig  nfs  on


dysfrdafrq20:/usr/sap # showmount -e 10.1.162.20
clnt_create: RPC: Program not registered
stop the nfs service from command line then
in Suse go to NFS server and type yast and start the nfs client service from GUI
do the same in client by starting nfs clients service using yast and then showmount will work
start NFS server service in NFS server via yast
 

Configure NFS
===============================
Server ip - 192.168.100
Client ip - 192.168.101
1. Install the NFS in Server System
2. Start NFS service
service rpcbind start and service nfs start --- chkconfig rpcbind/portmap/nfs on

3.Create shared directories in server
mkdir /dir_sharing_nfs
chmod 755 /dir_sharing_nfs

4. export shared directory on NFS server

vi /etc/exports
/dir ip_of_client(rw,sync,no_root_squash)
dir_sharing_nfs 192.168.101(rw,sync,no_root_squash) 
or (rw,sync,no_root_squash,no_subtree_check)

add no_root_squash  in your exports file
Code:
/media/nfs/   192.168.0.*(ro,sync,hard,intr,no_root_squash)
this will allow usgae of nfs by root with full permission or else by default nfs server is mounted using nobody user

Code:
#exportfs -a
to update your exports file

Client options include (defaults are listed first):
ro / rw :
a) ro : allow clients read only access to the share.
b) rw : allow clients read write access to the share.
sync / async :
a) sync : NFS server replies to request only after changes made by previous request are written to disk.
b) async : specifies that the server does not have to wait.
wdelay / no_wdelay
a) wdelay : NFS server delays committing write requests when it suspects another write request is imminent.
b) no_wdelay : use this option to disable to the delay. no_wdelay option can only be enabled if default sync option is enabled.
no_all_squash / all_squash :
a) no_all_squash : does not change the mapping of remote users.
b) all_squash : to squash all remote users including root.
root_squash / no_root_squash :
a) root_squash : prevent root users connected remotely from having root access. Effectively squashing remote root privileges.
b) no_root_squash : disable root squashing.

/etc/exports file:

$ exportfs -a

Do Not Use the no_root_squash Option

eg,
[root@iplsas4ap01 ibmrmalik]$ cat /etc/exports
/usr/sap/interface *(rw,async,no_subtree_check,insecure,no_root_squash)
/backup_new *(rw,async,no_subtree_check,insecure,no_root_squash)

exportfs -avr ->exports the folder to the nfs client

if any error with showmount -e 
try exportfs -r  and fix the issue, ensure the exports has (rw,sync,no_root_squash,no_subtree_check) and restart the exports

 
5. restart nfs service

############## CLIENT Part ###################
1. find out that shares available on the remote server or NFS Server.
showmount -e cfn_ip_of_server
showmount -e 192.168.0.100

2.Mount shared Directories on NFS client
Create a mount to mount the directory which you shared on server. if you need to mount on existing dir so, u can use that.
mount -t nfs ip_of_server:/directory_path /on_mounted_point
mount -t nfs 192.168.0.100:/dir_sharing_nfs /usr/sap/idm
The above command will mount that shared directory in “/usr/sap/idm” on the client server. You can verify it 
3. verify 
mount |grep nfs

4. To mount NFS directory Permanent in client across reboot has to entry in /etc/fstab
vi /etc/fstab
ip_of_server:/directory_path /mount nfs defaults 0 0
192.168.0.100:/dir_sharing_nfs /usr/sap/idm nfs defaults 0 0


RHEL mount hangs: nfs: server [...] not responding, still trying 

Issue

    NFS shares hang with the following error(s) in /var/log/messages:
    Raw

    kernel: nfs: server <servername> not responding, still trying

    Raw

    kernel: nfs: server <servername> not responding, timed out

# grep "not responding" /var/log/messages
Sep 29 22:54:39 client kernel: nfs: server server.example.com  not responding, still trying
# tcpdump -i eth0 -s 0 -w /tmp/tcpdump.pcap host server.example.com

================================
It's always best to carry out a quick assessment of the situation first:

    If other clients can see the NFS share, then the problem is likely to be on the client side
    If no clients can see the NFS share, then the problem is likely to be on the server side

Client Problems

If you have a problem on a particular client, try the following:

    Check your /etc/fstab file for errors
    Try mounting the filesystem from the command line : if it works, the problem is in /etc/fstab
    Try restarting the portmap (sudo /etc/init.d/portmap restart) then remounting

Server Problems

If you have a problem on the server, try the following:

    Check for errors in the syslog using grep "NFS" /var/log/syslog
    Check the local filesystem you are exporting (e.g. /dev/sdb) is mounted
    Check if the exported filesystem (e.g. /exports/myData) is mounted: if not, check the /etc/fstab file for errors
    Try mounting the filesystem from the command line : if it works, the problem is in /etc/fstab
    Check the /etc/exports file for errors
    Try restarting the NFS daemon (sudo /etc/init.d/nfs-kernel-server restart) then remounting
    Try restarting the portmap (sudo /etc/init.d/portmap restart) then remounting

If you still have problems:

    Check your firewall rules to see if they are blocking network traffic
======================================================== 
-------------------------------------------------------------------------------------------------------------------------------

Check ESX console :
Refer multi user chat between Ravi Pankaj and Sandeep dated 29th January titled Ravi Malik vendor group chat
---------------------------------------------------------------------------------------------------------------------------------
check for any user use the command:
pam_tally2 -u <ID>

logs to chk for errors with login
/var/log/secure
/var/log/message
-----------------------------------------------------------------------

searching details of mount in fstab

[root@FRAMAGSPO0003 ibmrmalik]# cat /etc/fstab |grep /usr/sap/CTS
172.22.0.140:/usr/sap/CTS     /usr/sap/CTS nfs   defaults       0 0

----------------------------------------------------------------------------
kEY FOR CHEF ACCESS pw is cHlorine88

C:\Program Files (x86)\PuTTY\keys for chef

add any user key in format mentioned in the file in /root/.ssh/authorizedkey

--------------------------------------------------------------------------------

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/%20Web%20Access


vSphere Client:
10.250.43.20 Dallas ===> 	https://146.89.140.53/vsphere-client/ (V6)		works
				https://146.89.141.97/vsphere-client/ Toronto		works
10.250.42.20 London  ==> New  	https://146.89.140.104/vsphere-client/ 			works
10.250.50.20 Frankfurt ==>	https://146.89.140.222/vsphere-client/ (V6)		works
10.250.51.20 Hong Kong  ==> 	https://146.89.141.40/vsphere-client/ (VC6)		works
10.250.41.120 Singapore ==> 	https://146.89.140.160/vsphere-client/ (V6)		works
Washington			https://146.89.142.40:9443/vsphere-client/  		works
Montreal			https://146.89.141.160/vsphere-client/ 			works
Chennai				https://146.89.142.92/vsphere-client/       		works
Paris				https://146.89.142.147/vsphere-client/      		works
Dallas13 - V6.0 - 		https://146.89.142.201/vsphere-client/			works
------------------------------------------------------------------------------------------------------------------------------------------------


Chef server
169.55.28.62(fmsprdchef01)  this is the public IP of main chef server, routed through openvpn and reachable from Windows jump box/server
regional chef server is ssh 146.89.140.151

From there, ssh to regional chef servers:
146.89.140.23    DAL09AMMCHEF01
146.89.140.87    LON02AMMCHEF01
146.89.140.151   SNG01AMMCHEF01
146.89.140.215   FRA02AMMCHEF01
146.89.141.23    HKG02AMMCHEF01
146.89.141.87    TOR01AMMCHEF01
146.89.141.151   MON01AMMCHEF01
146.89.142.23    WDC04AMMCHEF01
146.89.142.87    CHE01AMMCHEF01

after login to regional chef...you can connect any customer server  for  troubleshooting 
par01ammchef01


from this connection we can
check ssd service status ...can unlock  our  id


chef-client run		synch with chef server and  update  missing conf


to unlock any user

 passwd -u <uid>


to reset pw:
passwd <uid>


passord set to non expiry
passwd -x 99999 yhisftp
check password expiry date and time

[root@YHIEPS01 ibmrmalik]# chage -l yhisftp
Last password change                                    : Mar 16, 2018
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 1
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 7


Pw never expire
 chage -E -1 -I -1 -m -1 -M -1 -W -1 ansible
 chage -m 7 -M 99999 -I -1 -E -1 ansible

for root chage -I -1 -m 0 -M 90 -E -1 root

chage -m 7 -M 99999 -I -1 -E -1 ansible
 

Options:
  -d, --lastday LAST_DAY        set date of last password change to LAST_DAY
  -E, --expiredate EXPIRE_DATE  set account expiration date to EXPIRE_DATE
  -h, --help                    display this help message and exit
  -I, --inactive INACTIVE       set password inactive after expiration
                                to INACTIVE
  -l, --list                    show account aging information
  -m, --mindays MIN_DAYS        set minimum number of days before password
                                change to MIN_DAYS
  -M, --maxdays MAX_DAYS        set maximim number of days before password
                                change to MAX_DAYS
  -R, --root CHROOT_DIR         directory to chroot into
  -W, --warndays WARN_DAYS      set expiration warning days to WARN_DAYS




-----------------------------------------------------------------------------------------------------------------

CPU
DISK
RAM 
info from console

cat /proc/cpuinfo |grep -i processor
free -g		RAM
lsblk |grep disk = for disk	

blkid /dev/sdX to get the uuid and see if that id is used before deleting that unutilized disk
veryfy with pvs also

------------------------------------------------------------------------------------------------------------

Search for any package installed:

[root@sved1hdbsrv01 ibmrmalik]# rpm -qa |grep -i c++
compat-libstdc++-33-3.2.3-69.el6.i686
libstdc++-4.4.7-16.el6.x86_64
compat-sap-c++-4.7.2-10.el6_5.x86_64
compat-libstdc++-33-3.2.3-69.el6.x86_64

---------------------------------------------------------------------------------------------------

Access denied via putty but works from chef. 

Check df -h for any disk full

less /var/log/messages
service sssd status  < -- run that command on terminal where you want to check status 

first check messages logs  if you see any logs  related to sssd 
then check sssd status 

------------------------------------------------------------------------------------------------------


For checking Red Hat support articles we can use the following credentials:
 
ID -> ibm-itdcloud
Password -> masterpiece
 
To open a support case -> https://access.redhat.com/support/cases/
CAse with redhat
Redhat Vendor Support-  https://access.redhat.com/  
User ID:    ahtlinux  Password:  X4hkJyUK      expired

reach out to 
Balaji Selvadurai
Murthy Puranapanda
Suresh Jayamani
Sreejesh U
Vijayanand Kottukal Vinodan
Binoj Paingottoor


https://access.redhat.com/support/contact/technicalSupport    for calling RHEL to get assignment or help quickly
English

9 AM to 6 PM Mon-Fri (local time)

For customers in India:
International

Toll-free:000-800-919-0891000-800-919-0893For customers outside India:Not toll-free:+61290556976Out of business hours:
International

Toll-free:000-800-919-0892
Premium subscribers with Severity 1 or 2 issues who require support outside of local business hours should call their regional center as listed.

Proactive case b4 any major upgrade https://access.redhat.com/articles/5387111


Redhat need .vmes file along with .vmss file too
vmsn, vmem and vmss required  

pune.ravi / Rm@03021981  redhat account credentials


Case with SuSE
https://scc.suse.com/support/cases/
ravi.malik@kyndryl.com
Nov2023&Jan2024

-----------------------------------------------------------------------------------------------------
1. how to collect logs (IMP VM needs to put in "Suspend" mode before reboot)...please check wiki, as it has screen shots etc
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Hung%20VM%20Memory%20Dump

2. How to create case with vendors such as RedHat in this case :
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/RedHat%20Support%20Access

Thanks.
1. Here are the steps to create vmss file when there is a Hung VM:
First ssh to ESXi host where the hung VM is located. Get root password from Softlayer portal
once you logged run this command from tmp folder
/tmp # esxtop –b –d 5 -n 100 > output-perf-statistics-file.csv
This csv file will have resource utilization on the ESX host at that time.
Wait for this to complete before suspending the VM.
Next we will need to suspend the VM to create vmss file for OS Vendor.
Use the vSphere Client to connect to vCenter Server (I would suggest to RDP to the local vCenter, launch vSphere Client in that DC so that download of the file would be faster)
 1-   Select the hung virtual machine in the inventory.
 2-   Open the console tab, and take a screenshot.
 3-  Right-click the virtual machine, and select Power - Suspend.
    Wait for the Suspend virtual machine task to complete.
  4-  Browse the datastore where the virtual machine configuration files are stored.
M
  5-  Locate the .vmss file in the directory of the virtual machine.
  6- Right-click the .vmss file, and download it to the vCenter.  (Download has to be completed before powering on the VM)
  7-  Power on VM
  8- Open a case with Red Hat and send this file to them if requested.



Step 1.Login into vsphere client on DC where VM hosted.
Step 2.Select the hung virtual machine in the inventory.
Step 3.Take a screenshot ( Right-click on the virtual machine in the inventory and click on Take Snapshot.)
Step 4.Right-click the virtual machine, and select Power - Suspend.
Step 5.Wait for the Suspend virtual machine task to complete.
Step 6.Browse the datastore where the virtual machine configuration files are stored.

IMP - Select the .vmsn or .vmss file and download to  your local machine


VMSS to machine
https://www.symantec.com/connect/articles/collect-full-memory-dump-vmware-virtual-machine-vm

----------------------------------------------------------------------------------------------------------------------------------



Mount issues:

df -hT
1. Try to create test file
2. fsck
3. mount -a
4. check fstab entry, if entry is with cifs so, please check username and password or credential file. ( i don't know how to where to check )
5, if there is doubel entry in fstab so, has to unmount 1 entry
6. mount and umount fix issue most of the time
7. try to access both VM should be pinging each other.
8. Customer ip should be available in fstab entry not imz ip. 
9. service nfs status 



fsck error even after umounting
Error:

fsck from util-linux 2.20.1
e2fsck 1.42.9 (4-Feb-2014)
/dev/mapper/ubuntu–vg-root is mounted.
e2fsck: Cannot continue, aborting.

To fix:

fsck -nf /dev/sda1
n -> dry-run: will not do any change (just checking)
f -> force : sometimes it says clean but you can force a new check
-----------------------------------------------------------------------------------

Client trio alias
CMS 3.x AP SUPER CLIENT TRIO

----------------------------------------------------------------------------------

C drive running out of space

C:\Windows\System32\winevt\Logs
keep 3 months logs and delete the rest
delete temp folder contents and check user folders

to analyse the folder size
https://www.microsoft.com/en-us/p/treesize-free/9nblggh40881?activetab=pivot:overviewtab

------------------------------------------------------------------------------------

monitoring bin

Area: MSD_TEC
sub-Area: TSMONITORING

-----------------------------------------------------------------------------
ds_agent is using high CPU

    To start: /etc/init.d/ds_agent start
    To display status: /etc/init.d/ds_agent status
    To stop: /etc/init.d/ds_agent stop
    To reset: /etc/init.d/ds_agent reset
    To restart: /etc/init.d/ds_agent restart

-----------------------------------------------------------------------------

ITM agent

check status  ITM mointoring agent and version
/opt/monitor/IBM/ITM/bin/cinfo -r

[root@LBDFQ1App00 ibmrmalik]# /opt/monitor/IBM/ITM/bin/cinfo -r

1.x  /opt/IBM/ITM/bin/cinfo -r

*********** Thu Apr 26 14:34:08 HKT 2018 ******************
User: root Groups: root sapinst
Host name : LBDFQ1App00  Installer Lvl:06.23.03.00
CandleHome: /opt/monitor/IBM/ITM
***********************************************************
Host         Prod  PID    Owner  Start  ID   ..Status
LBDFQ1App00  sa    61000                FQ1  ...process not running

run the below from /opt/monitor/IBM/ITM/bin
./itmcmd agent -o <ID from above output> start <value of prod from above>    to start ITM agent
[root@LBDFQ1App00 bin]# ./itmcmd agent -o FQ1 start sa     --> to start the service if stopped

Alternate:
/etc/init.d/ITMAgents1 restart
/etc/init.d/ITMAgents1 restart

WIndows ITM agent
Start > Programs > IBM Tivoli Monitoring > Manage Tivoli Monitoring Services
click start and top rite search for tivoli and open teh app and select and start the service.

ITM for SUSE
# systemctl status ITMAgents1.service


check agent status
/opt/monitor/IBM/ITM/bin/cinfo -i -z



1.x
On all ITM agent offline issues, kindly follow the below process.
 Please login to the intended server
 cd /opt/IBM/ITM/bin
 check the status of the agent using ./cinfo -r
 1.1 If agents are not running , start all the agents using the command with sudo or as root
 ./itmcmd agent start all
 1.2 If agents are displayed as running in cinfo -r output for each agent check the following
 cat /opt/IBM/ITM/config/lz.config | grep -i cmslist
 cat /opt/IBM/ITM/config/ul.config | grep -i cmslist
 cat /opt/IBM/ITM/config/um.config | grep -i cmslist
 cat /opt/IBM/ITM/config/yn.config | grep -i cmslist
 the output should display two of the following ips
 for Pod1 , 146.89.140.50 / .51 /.52 /.53 /.54 /.55
 for Pod 2 146.89.140.72 / .73 /.74 / .75/ .76/.77
 if the Ips dispalyed in cat command output are correct , execute the following
 ./itmcmd agent stop all
 ./itmcmd agent start all
 1.3 If the IPs displayed in above cat commands are not as per the prescribed range
 please reconfigure each agent for which it is not in the prescribed range using
 ./itmcmd config -A lz ( / ul / um/ yn ) . depending on which agent is being reconfigured .
 The config inputs wud be
 will it connect to TEMS – selct the option for yes
 next provide the RTEMS Ip
 network protocol1 -ip.spipe
 network protocol2 – ip.pipe
 remaining you can proceed by providing the default values
 at the last line
 will it connect to secondary tems – select yes
 provide another RTEMS IP
 network protocol1 -ip.spipe
 network protocol2 – ip.pipe
 remaining proceed with default value
 ,and restart the agent after completion .
 1.4 For some cases it has been observed that after recent patching or any other activity on the server the ITM directory goes missing
 For such cases
 OS teams should check on why the directory went missing .
 And to resolve offline for :LZ and :UL agent
 they need to perform following steps
 ps -ef | grep klzagent –kill the process
 ps -ef | grep kulagent –kill the process
 ps -ef | grep kcawd – kill the process
 then perform below steps assuming /tmp has enough space
 cd /tmp
 tar -xf /sds/local/sceplus/agents/ITM/ITM6_LINUX_64_06230300_SCE.tar
 cd TEMA1
 ./esm_instTEMA.sh -t lz -a lx8266 -h /opt/IBM/ITM -r RTEMS IP1 -f RTEMSIP2 -c <customercode in small letters> -l <hostname in small letters>
 where RTEMSIP1 and RTEMS IP2 need to be entered from the valid list
 for Pod1 , 146.89.140.50 / .51 /.52 /.53 /.54 /.55
 for Pod 2 146.89.140.72 / .73 /.74 / .75/ .76/.77
 e.g.
 ./esm_instTEMA.sh -t lz -a lx8266 -h /opt/IBM/ITM -r 146.89.140.50 -f 146.89.140.51 -c b03 -l byanpdweb02

---------------------------------------------------------------------------------
Suse release

CTUBWQB1AP01:/etc/init.d # cat /etc/SuSE-release
SUSE Linux Enterprise Server 12 (x86_64)
VERSION = 12
PATCHLEVEL = 2
# This file is deprecated and will be removed in a future service pack or release.
# Please check /etc/os-release for details about this release.


Case with SuSE https://scc.suse.com/support/requests 
https://scc.suse.com/support/requests 

ravi.malik@kyndryl.com
Nov2023&Jan2024	


portal.suse.com
ravi.malik@kyndryl.com
R@vi@03T@n@y@16	or ProKabbadi@12345  new one Nov2023&Jan2024

Since you are running a cluster, please upload also hb_report:

For the cluster hb_report, follow the instructions in the link below. You need to generate the hb_report for the time the issue occurred:

    https://www.suse.com/support/kb/doc/?id=000017501


Microsoft support link
https://serviceshub.microsoft.com/support/manage/9ab2e5e9-3975-4f3a-9168-28cea1bd8441?state=open
eyes
white_check_mark
raised_hands





2:27
use your kyndryl ID to login

dmidecode -s system-serial-number    to get the serial no
dmidecode | grep -i serial
Ravi:~$ dmidecode -t system | grep Serial
	Serial Number: 1B7WC63


 
FTP Sites using file zilla
 
Upload the file(s) to one of the following FTP sites, choose the geographically closest site:
 
North America
FTP:	ftp://support-ftp.us.suse.com/incoming/
FTPS:	ftps://support-ftp.us.suse.com/incoming/
 
EMEA
FTP:	ftp://support-ftp.emea.suse.com/incoming
FTPS:	ftps://support-ftp.emea.suse.com/incoming
FTP Login
 
The FTP server is an anonymous FTP server, login as "anonymous" and use an e-mail address as the password.
For more information on anonymous FTP please visit http://www.faqs.org/faqs/ftp-list/faq/.
 


[root@tsls4proddb ibmrmalik1]$ dmidecode -s system-serial-number
 
 
	 Case with SuSE is raised via IBM portl with below details
	 - Product : SUSE Linux Enterprise Server for SAP Applications
	- Customer number  or Account CMR Number:   0444858 for CMS 3.x

	- Country Region : United States
	
	Kernel Version and date of release in suse patches
	https://www.suse.com/support/kb/doc/?id=000019587
------------------------------------------------------------------------------------------------

add disk and lv extend :
refer chat with Ajay dated 28 Feb

extend vg without creating pv of newly added disk
vgextend <vgname> /dev/sde(<path of new disk>)


------------------------------------------------------------------------------------------------

Check any rpm installed

rpm -qa |grep -i <rpm name to search>


change pw

passwd root


Upgrade rpm
rpm -Uvh <package name>


install rpm
rpm -ivh <package name>

uninstall rpm
rpm -evh <package name>


root pw:May55now#

------------------------------------------------------------------------------------------------------------------

Single user mode root pw change
SuSE
https://srvfail.com/reset-lost-root-password-suse-linux-enterprise-server/

refer PSL amm chat dated 31 May


Rescue mode:

Rescue mode provides the ability to boot a small Red Hat Enterprise Linux environment entirely from CD-ROM, or some other boot method, instead of the system’s hard drive. As the name implies, rescue mode is provided to rescue you from something. During normal operation, your Red Hat Enterprise Linux system uses files located on your system’s hard drive to do everything â€” run programs, store your files, and more.

Emergency Mode:

In emergency mode, you are booted into the most minimal environment possible. The root file system is mounted read-only and almost nothing is set up. The main advantage of emergency mode over single-user mode is that the init files are not loaded. If init is corrupted or not working, you can still mount file systems to recover data that could be lost during a re-installation.

Single-User mode:

In single-user mode, your computer boots to runlevel 1. Your local file systems are mounted, but your network is not activated. You have a usable system maintenance shell. Unlike rescue mode, single-user mode automatically tries to mount your file system. Do not use single-user mode if your file system cannot be mounted successfully. You cannot use single-user mode if the runlevel 1 configuration on your system is corrupted.




------------------------------------------------------------------------------------------------------------------------
Chef bootstrapping

Re-Bootstrap

Note: This should be the last option but if you have to do it, please make sure you are in right host

- Login to the host which needs to be cleaned up, double check the hostname

- find out the chef rpm ( rpm -qa|grep -i chef)

- Remove the chef rpm ( rpm -e chef-11.18.12-1.el6.x86_64  or rpm -e chef-12.4.3-1.el6.x86_64 )

- Delete chef dirs ( rm -rf /etc/chef;rm -rf /var/cache/chef; rm -rf /opt/chef )

- Login to the chef server and remove the node and client from the chef.



    export the chef org
    knife node list|grep -i <nodename>
    knife node delete -y <full hostname>; knife client delete -y <full hostname>



- bootstrap


Steps to follow: access denied issues

First try to restart "sssd restart"
check sssd errors
location of logs 

tail -f /var/log/secure
/var/log/sssd/ldap_child
/var/log/messages

might need NTP restart if the error is related to clock skew too great

service ntpd stop ; ntpd -gq ; service ntpd start

[root@svjq1srv0 ~]# service ntpd stop
Shutting down ntpd:                                        [  OK  ]
[root@svjq1srv0 ~]# ntpdate 146.89.140.140
15 Feb 21:47:45 ntpdate[2920]: adjust time server 146.89.140.140 offset -0.193682 sec
[root@svjq1srv0 ~]# ntpdate 146.89.140.141
15 Feb 21:47:52 ntpdate[2929]: adjust time server 146.89.140.141 offset -0.201054 sec
 

7:18:53 PM: [root@svjq1srv0 ~]# service ntpd start
Starting ntpd:                                             [  OK  ]

Manually start NTP

service ntpd stop 
ntpdate 146.89.140.138 
service ntpd start

if the access is still not working then check the below

To check if the server needs rebootstrapping
run chef-client from the server with issue
[root@drssfra002 ~]# chef-client

Server Response:
----------------
Failed to authenticate as 'drssfra002.imzcloud.ibmammsap.local'. Ensure that your node_name and client key are correct.

Server Response:
----------------
Failed to authenticate as 'drssfra002.imzcloud.ibmammsap.local'. Ensure that your node_name and client key are correct.

if you get message similar to above means the chef server does not have the details of this host and it have been deleted or got corrupted so you need to rebootstrap.

Even before doing bootstrapping try running

service sssd stop;rm -rf /var/lib/sss/db/*;mv /etc/krb5.keytab /etc/krb5.keytab_bk;rm -rf /tmp/krb*;kdestroy;

systemctl stop sssd;mv /etc/krb5.keytab /etc/krb5.keytab.backup;rm -rf /var/lib/sss/db/*;rm -f /tmp/krb5*


11a) kdestroy -A && rm -f /etc/krb5.keytab
11b) From the opaas UI for the VM in question, Select options, Run Adhoc Ansible Job, and select `linux-ad` from the drop down
	In the extra vars text box, add the following:
	{
	  "ad_ou": "<OU for this customer VM>"
	}
        Example:
            {
              "ad_ou": "IBM AMM Customers/SDM Test (01234)/Servers - Linux"
            }

https://github.kyndryl.net/CMS/Platform-Support/wiki/Troubleshooting-IMZ-login-issues---Linux

If you want to delete keytab and credentials cache file and re-create it, please run:

kdestroy -A && rm -f /etc/krb5.keytab && 	


If sssd service restart fails with error "Failed to read keytab [default]: No such file or directory"

Run chef-client -n linuxad_auth, this will run the linuxad_auth cookbook which will try to re-generate the keytab if missing


Please follow the SOP if customer having login issue with IMZ user.
get customer username and password and sudo ...
# service sssd stop
# rm -rf /var/lib/sss/db/*
Remove /etc/krb5.keytab
# mv /etc/krb5.keytab /etc/krb5.keytab_bk
# kdestroy
# chef-client
Note: After running chef-client if it is unsuccessful with error code (1) then run bellow command
check bellow file
===================
1) After running chef-client,  file krb5.keytab must update with latest time stamp as shown bellow
	[root@zdbecpap1 ]# ls -l /etc/krb5.keytab
	-rw------- 1 root root 1212 Sep 16 00:43 krb5.keytab
	[root@zdbecpap1 etc]#
2) if  this file krb5.keytab is not updated or showing old date then run bellow command.
# chef-client -n linuxad_auth

kdestroy -A && rm -f /etc/krb5.keytab && chef-client

chef client failed with 
Error Downloading Packages:
  1:nfs-utils-1.2.3-78.el6_10.2.x86_64: failure: nfs-utils-1.2.3-78.el6_10.2.x86_64.rpm from rhel-6-server-rpms: [Errno 256] No more mirrors to try

rm -fr /var/cache/yum/*

https://github.kyndryl.net/CMS/cms-chef/wiki/Linux-Active-Directory-Troubleshooting


rm -rf /tmp/krb*;cp /etc/krb5.keytab /etc/krb5.keytab_backup;service sssd stop;rm -rf /var/lib/sss/db/* ;rm -rf /etc/krb5.keytab ; kdestroy;chef-client
rm -rf /tmp/krb*;service sssd stop;rm -rf /var/lib/sss/db/* ;rm -rf /etc/krb5.keytab ; kdestroy;chef-client


on the affected server
Check the version of chef rpm
[root@drssfra002 ~]# rpm -qa|grep -i chef
chef-12.19.33-1.el6.x86_64


remove the chef from the VM
rpm -e chef-12.19.33-1.el6.x86_64

remove chef directories
rm -rf /etc/chef /opt/chef /var/chef

- Login to the chef server and remove the node and client from the chef.

    export the chef org

export CHEF_ORG=drs   (here drs is the org name found in wiki page for the cust)

to get chef cust code:
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Customers (https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Customers)  

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Chef Roles File (https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Chef Roles File)  

then run the below to export the environment list to be used for bootstrapping

FRA02AMMCHEF01.ibmammsap.local: ~ # knife environment list
_default
drs_production

here we get the environment name as drs_production
Check if the node name is on the chef server if found delete else skip this step

    knife node list|grep -i <nodename>
    knife node delete -y <full hostname>; knife client delete -y <full hostname>

export CHEF_ORG=cb4
knife node delete BWPRDApp1.imzcloud.ibmammsap.local -y
knife client delete BWPRDApp1.imzcloud.ibmammsap.local -y
export CHEF_ORG=cb4;/root/bootstrap_v12.sh -o cb4 -n BWPRDApp1 -l -d imzcloud.ibmammsap.local -t osonly -e cb4_production

run re-bootstrap command from a chef regional server

./bootstrap_v12.sh -o ORG -n HOSTNAME -l -d imzcloud.ibmammsap.local -t osonly -e ENVIRONMENT 

./bootstrap_v12.sh -o drs -n drssfra002 -l -d imzcloud.ibmammsap.local -t osonly -e drs_production 

./bootstrap_v12.sh -o cb4 -n dcghanapreap1 -l -d imzcloud.ibmammsap.local -t osonly -e cb4_production

./bootstrap_v12.sh -o sm5 -n CLDERPAPPD1 -l -d imzcloud.ibmammsap.local -t osonly -e sm5_production
Ref
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Chef (https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Chef)  
-------------------------------------------------------------------------------------------------------------------------
location of logs 

tail -f /var/log/secure
/var/log/sssd/ldap_child

(Mon Apr  2 17:09:43 2018) [[sssd[ldap_child[11525]]]] [ldap_child_get_tgt_sync] (0x0010): Failed to init credentials: Clock skew too great

---------------------------------------------------------------------------------------------------------------------------
corrupted fs fix:
before fsck 
we will need an e2image of the filesystem ____before____ the fsck is done. Replace /dev/hda1 with the path to the device. # e2image -r /dev/hda1 - | bzip2 > /tmp/02155442.e2i.bz2

e2fsck -f <fs path >

---------------------------------------------------------------------------------------------------------------------------------

This is the path for storcli for RHEL servers:

/opt/MegaRAID/storcli/storcli64

---------------------------------------------------------------------------------------------------------------------------
We dont have access to IaaS server but have access to Iaas+ servers


--------------------------------------------------------------------------------------------------------------------------

Request for root access

1. user name or group name needed access
2. list of servers where access is needed
3. the date until when the access is requested
4. Business justification on why it is needed 

----------------------------------------------------------------------------------------------------------------------------
knowledgebase link

https://persistentsystems-my.sharepoint.com/:x:/r/personal/asmita_vadgave_persistent_co_in/Documents/Knowledge Base Doc ( problem resolution ).ods?d=wb032628acc0844b787164d53ad5f60c0&e=4%3A5b0091b15bb842cfb190c137ea3ca402 (https://persistentsystems-my.sharepoint.com/:x:/r/personal/asmita_vadgave_persistent_co_in/Documents/Knowledge Base Doc %28 problem resolution %29.ods?d=wb032628acc0844b787164d53ad5f60c0&e=4%3A5b0091b15bb842cfb190c137ea3ca402)  

-------------------------------------------------------------------------------------------------------------------------------

Mounting and umounting

putty here for keep handy.
1. check fstab entry that should be standard as per wiki.
I changed the fstab entry and set as per wiki.

2. tried to umount but couldn't do because device was busy so, checked below steps
lsof -a /path of drive which mounted ( busy )
fuser  /path of drive which mounted ( busy )
umount -l //path of drive which mounted ( busy ) < -- Lazy mount

3. mount -a

umount: /mnt/nfs: device is busy when using any of the following commands:
 # mount -t nfs -o remount /mnt/nfs
 # umount /mnt/nfs
 # umount -f /mnt/nfs
 # umount -l /mnt/nfs
 # umount -lf /mnt/nfs 

lsof . |grep -i "deleted"   -  to find deleted files still occupying space inodes check
----------------------------------------------------------------------------------------------------------------

swap space increase request:

If swap is  LVM and have enough space available  in VG  the we can do it without  change ,also  if it is non-prod

for both PROD and  non prod we need to stop app/db before extending space 

--------------------------------------------------------------------------------------------------------------------------



Zabbix poller issues to bee assigned to mpenavar


esxi monitoring ticket to be assigned to     Andres Juarez, Daniel Prendas  Houcine	HAIDAOUI

dispatch to Area: CMS-TR-PHYS-INFRA           Sub Area: CMS-SQ-BLUEMIX-INFRA           Bin: CMS-SQ-BLUEMIX-INFRA

-------------------------------------------------------------------------------------------------------------------------
Swap space extension:

How to  add  swap  space  online  (without  downtime)
==>
1007  2022-11-08 14:16:13 lsscsi |grep sdi
1008  2022-11-08 14:20:10 lsblk
1009  2022-11-08 14:33:11 pvcreate  /dev/sdi
1010  2022-11-08 14:33:42 vgcreate  swapvg /dev/sdi
1013  2022-11-08 14:35:25 lvcreate  -L 15G swapvg -n swap_lv
1014  2022-11-08 14:35:54 mkswap /dev/swapvg/swap_lv
1015  2022-11-08 14:36:03 free  -h
1016  2022-11-08 14:36:35 swapon  /dev/swapvg/swap_lv
1017  2022-11-08 14:36:39 free  -h
1018  2022-11-08 14:36:50 history

To extend an LVM2 swap logical volume (assuming /dev/VolGroup00/LogVol01 is the volume you want to extend):
To chk the swap lv details cat /etc/fstab |grep -i swap  or lvdisplay |grep swap

lvdisplay <full lv path>          shows actual swap

    Disable swapping for the associated logical volume:

    # swapoff -v /dev/VolGroup00/LogVol01

    Resize the LVM2 logical volume by 256 MB:

    #lvextend /dev/VolGroup00/LogVol01 -L +256M

    Format the new swap space:

    # mkswap /dev/VolGroup00/LogVol01

    Enable the extended logical volume:

    # swapon -va

    Test that the logical volume has been extended properly:

    # cat /proc/swaps # free

519  2018-04-05 21:23:20 swapoff -v /dev/VolGroup/lv_swap
  520  2018-04-05 21:24:09 lvextend -L +8G /dev/VolGroup/lv_swap
  521  2018-04-05 21:24:25 mkswap /dev/VolGroup/lv_swap
  522  2018-04-05 21:25:11 swapon -va
  523  2018-04-05 21:25:22 free -g
   525  2018-04-05 21:25:49 lsblk
  526  2018-04-05 21:37:53 history
 
 $ swapon --show
NAME       TYPE       SIZE USED PRIO
/dev/sda5  partition    2G 1.3G   -1
/dev/sda4  partition    1G   0B   -2
/swapfile  file      1024M   0B   -3

swap concept
The kernel uses a memory management program that detects blocks, aka pages, of memory in which the contents have not been used recently. The memory management program swaps enough of these relatively infrequently used pages of memory out to a special partition on the hard drive specifically designated for “paging,” or swapping. This frees up RAM and makes room for more data to be entered into your spreadsheet. Those pages of memory swapped out to the hard drive are tracked by the kernel’s memory management code and can be paged back into RAM if they are needed.
 
 swap reduction
 
 https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/storage_administration_guide/s1-swap-removing
 
 or
 
 Comment out the swap entry in /etc/fstab.
#UUIDoftheswapdisk swap swap defaults 0 0
3. fdisk /dev/sda
Type p to list the partition in sda.
Type d to delete partition /dev/sda2 and press enter
Type 2 to select partition /dev/sda2 and press enterNow type p and press enter to confirm partition /dev/sda2 is removed.
Type n to create new partition /dev/sda2 and press enter
Type p to create primary parition and press enter
Press enter to select the first sector as default.
For last sector type +2G and press enter.
Now type p to confirm new partition /dev/sda2 is created.
Type t and press enter to change the partition type.
Type 82 and press enter to assign the parition type.
Type p and press enter to confirm the parition type is "Linux swap / Solaries".
Enter wq and press enter to save the changes.
4. Type partprobe and hit enter. (it might ask to reboot for the changes to reflect).
5. Type "mkswap /dev/sda2" and hit enter.
6. Remove # at the beginning of below line in /etc/fstab.UUIDoftheswapdisk swap swap defaults 0 0
7. swapon -a or swapon /dev/sda2
8. Type free -h to check if swap is listing correctly.
9. If the swap is still showing 50gb, a reboot is required for changes to reflect.
10. reboot and type free -h to confirm its reflecting 2gb as swap space
--------------------------------------------------------------------------------------------------------------------------

unable to login issue serviceid

[root@smslddevdl0 ibmrmalik]# cat /etc/security/serviceids
### ANY IDS LISTED IN THIS FILE WILL HAVE LOGIN DISABLED !!!sapadm
smdadm
daaadm
aoddba
tivmon
dl0adm
db2dl0
sapdl0
sapdl0db

comment any id if need tologin
----------------------------------------------------------------------------------------------------------------- 

Uploading file on redhat site for RCA


Uploading big sized logs to SuSE
Use filezilla and connect using below
user: anonymous
password: <your email address or case number>
 
FTP servers:
FTP EMEA	support-ftp.emea.suse.com/incoming/
FTP US	support-ftp.us.suse.com/incoming/

refer to psl chat dated 12 March 18


1. ftp dropbox.redhat.com 
2. User (origin-dropbox.redhat.com:(none)): anonymous
331 Please specify the password.
Password: 
Note: Password as your mail ID like ppankaj@us.ibm.com
3. literal pasv  
then cd incoming 
4. then put VMSSfilename.vmss (connect to ftp from the directory where u have teh file saved) 
 
ftp> put [filename]

 ftp> put /some/path/[filename] /incoming/[filename]

############################################
ID -> ibm-itdcloud
Password -> masterpiece

To open a support case ->xfs https://access.redhat.com/support/cases/
https://access.redhat.com/solutions/2112  <-- ref to upload vmss file or big size file on redhat portal
##################################################### 
Refer: How to provide large files to Red Hat Support (vmcore, rhev logcollector, large sosreports, heap dumps, large log files, etc.)
       https://access.redhat.com/solutions/2112

-------------------------------------------------------------------------------------------------------------

Open VPN ip
https://169.55.83.231 and https://169.53.7.5
169.55.68.86- WDC
169.53.7.5 - DAL


https://169.55.68.86/?src=connect 
https://169.53.7.5/?src=connect


connect to the openvpn via linux laptop
openvpn --config /etc/openvpn/client.ovpn --auth-user-pass    client.ovpn is saved in downloads folder
openvpn --config /home/rmalik/Downloads/client.ovpn --auth-user-pass

openvpn --config /etc/openvpn/OpenclientRM231.ovpn --auth-user-pass   Working as on 3rd Sept 2020

update-crypto-policies --set LEGACY  (adding this line made TLS error go)


ALways raise a SR for IAM refer SR0024475 and open SR only
for IAM team pls ping in #cms-sq-id-access-cont
IBM Internal -- CCP
Managed Apps - IAM

-------------------------------------------------------------------------------------------------------------
permissions:

RWX
421
rwx-7
rw-6
r-4
w-2
x-1

---------------------------------------------------------------------------------------------------------------------------------------

purple screen error on IPMI console purple screen is PSOD error

check following things -  
1- which vms are  hosted on this exi and check all from same customer  or different 
2- save above screen shot 
3- open ticket at  softlayer and attach the PSOD error

--------------------------------------------------------------------------------------------------------------------------------------------

If a VM in wiki has the esxi host as xyzhana(on SL) then fetch the private ip, root pw from password tab and then use this to connect to vsphere using vsphere client and u will see all VMs listed under that esxi host. To connect you need to have SL VPN connected

------------------------------------------------------------------------------------------------------------------------------------------------

Esxi memory ticket to Housine haidaoui@us.ibm.com   HAIDAOUI


----------------------------------

remove server from chef:
knife node delete X -y ; knife client delete X -y
---------------------------------------------------------------------

FInd the path of script in cronjob

crontab -l -u postman |grep script_name 

cd /var/spool/cron to chk which user is used to run that job.

cronjob to cleanup logs older than
0 0 * * * find /usr/sap/FSQUO/env/log/v4runtime/ -mindepth 1 -mtime +90 -delete


Non-root user can not run crontab, getting error 'Authentication token is no longer valid; new one required' in /var/log/messages 


Root Cause

    Password ageing for non-root user accounts causes them to expire, preventing services such as cron from running (as specified user).

Resolution
change pw

-------------------------------------------------------------------------

total server disk

df -h --total 

to check inodes space
 df -ih <FS path>
 
 list what folder has more inodes
 for i in /var/log/sudo-io/*; do echo $i; find $i |wc -l; done
 for i in *; do echo $i; find $i |wc -l; done
for i in .; do echo $i; find $i |wc -l; done
 delete old files inside
 
 
 to list deleted files
 lsof | grep deleted
lsof /var |grep -i deleted

 
 list inodes  ls -lai
 
 small script which will list the directories and the number of files on them.

#  for i in /*; do echo $i; find $i |wc -l; done

find . -xdev -type f | cut -d "/" -f 2 | sort | uniq -c | sort -n
 


This will find and remove any 0 length files in that file system, which are also consuming your inodes.

inodes full
https://www.interserver.net/tips/kb/solution-running-inodes/

Fetch the inodes count from below and cleanup
echo "Detailed Inodes usage for: $(pwd)" ; for d in `find -maxdepth 1 -type d |cut -d\/ -f2 |grep -xv . |sort`; do c=$(find $d |wc -l) ; printf "$c\t\t- $d\n" ; done ; printf "Total: \t\t$(find $(pwd) | wc -l)\n"

Wait for the command to complete its task and you should see list of directories with accurate file count on each folders and at the end total inode used.


Inodes on RHEL
https://access.redhat.com/solutions/2316

lsof | grep deleted


Check available inodes
 df -i

find inodes
$ for i in /*; do echo $i; find $i |wc -l; done

Find the dircetory with most no of inodes then use the below with that directory name

for i in /home/*; do echo $i; find $i |wc -l; done

To find teh folders with max files
find . -xdev -printf '%h\n' | sort | uniq -c | awk '{print $1 " " $2}' | sort -nr | head -n 5

delete the directory with most inodes
 rm -rf /home/bad_user/directory_with_lots_of_empty_files

find . -xdev -type f | cut -d "." -f 2 | sort | uniq -c | sort -n

for inodes in var search /var/log/sudo-io has the max filesdel old ones


You could clean this via:

# rm -rf /var/log/sudo-io/0[1-9A-Z] /var/log/sudo-io/00/0[1-9A-Z] 	 /var/log/sudo-io/00/00/B[5-9A-Z] /var/log/sudo-io/00/00/[C-Z]*

But I suggest do you:

# ls -1d /var/log/sudo-io/0[1-9A-Z] /var/log/sudo-io/00/0[1-9A-Z] 	 /var/log/sudo-io/00/00/B[5-9A-Z] /var/log/sudo-io/00/00/[C-Z]*

first to make sure you are not going to remove anything unexpected.

---------------------------------------------------------------------------

(OP1)CLDPROAPPP1- 10.198.0.75 
(EP1)CLDERPAPPP1-10.198.0.71
OD1 / CLDPROAPDD1 / 10.198.0.201
OQ1 / CLDPROAPDT1 / 10.198.0.217	instead of postman use OQ1adm
CLDERPAPPQ1	10.198.0.211	10.168.1.5
CLDERPAPPQ1
CLDERPAPPP1  odb2   10.198.0.71
ED1	CLDERPAPPD1 10.198.0.208
EQ1  	CLDERPAPPQ1 10.198.0.211
OD1  	CLDPROAPDD1 10.198.0.201
-------------------------------------------------------------------------------

################################################ PSOD ERROR ########################################################

chek following things -  
1- which vms are  hosted on this exi and check all from same customer  or different 
2- save PSOD Error screen shot 
3- open ticket at  softlayer and attach the PSOD error.

Note -- Don't try to reboot Esxi Host from ipmi console at your end let do this to Bluemix ( soft layer team )  ad bring back the esxi.
When you will open ipmi console there will be option ( power control ) -- click on POWER RESET. Monitor this screen closely.

Once reboot will be complete. You will see esxi screen.

In my case esxi host ( parhana-1024-18.xsportal.local ) and 3 VM's were unaccessiable on it.
parhana-1024-18.xsportal.local
(Paris 1)
Private IP: 10.127.235.182 

1-336840091 - smdbquaqw3 ( 10.78.24.40 ) -- parhana-1024-18.xsportal.local
1-336842231 - smdbdevdm1 (10.78.22.38 ) -- parhana-1024-18.xsportal.local
1-336842211 - smdbdevdu1 ( 10.78.22.54 )

You must login inside of esxi host by putty also click on vsphere client icon on your win kvm 
private ip 
root
passwd  < -- Password you have to fetch from the password TAB of Softlayer portal.

Check VM Status. If powered off so do it power on and try to access from putty after coming up.

New KVMs created in RHEL8.x are created in Gnome Boxes.
KVMs migrated from RHEL7 will appear in Virtual Machine Manager (VMM).
---------------------------------------------------------------------------------------------------------------------------
	
knife node show eccci0dev.imzcloud.ibmammsap.local	


------------------------------------------------------------------------------------------------------------------------

Zabbix agent status on SuSe

rczabbix-agentd status;uptime;date

uptime -p

systemctl status/start/restart 

service sssd stop/start/status

/sbin/service chef-client status

rcsssd status
rc and tab to get the list of services in SUSE

yum check-update  equivalent in SUSE is zypper list-updates 

yum search --all <rpm to search>


12.3.2. Listing packages with yum
To list information on all installed and available packages, use:

# yum list --all
To list all packages installed on your system, use:

# yum list --installed
To list all packages in all enabled repositories that are available to install, use:

# yum list --available


12.3.1. Searching packages with yum
To search for a package, use:

# yum search term
Replace term with a term related to the package.

Note that yum search command returns term matches within the name and summary of the packages. This makes the search faster and enables you to search for packages you do not know the name of, but for which you know a related term.

To include term matches within package descriptions, use:

# yum search --all term


12.3.3. Listing repositories with yum
To list all enabled repositories on your system, use:

# yum repolist
To list all disabled repositories on your system, use:

# yum repolist --disabled
To list both enabled and disabled repositories, use:

# yum repolist --all
To list additional information about the repositories, use:

# yum repoinfo

To enable a specific Red Hat repository:


[root@server ~]# subscription-manager repos --enable=rhel-6-server-optional-rpms
To disable a specific Red Hat repository:

[root@server ~]# subscription-manager repos --disable=rhel-6-server-optional-rpms

# subscription-manager remove --all
# subscription-manager unregister
# subscription-manager clean
# yum clean all
# rm -rf /var/cache/yum/*
Once done, try to register, attach subscription automatically & check the status:
Raw
# subscription-manager register
# subscription-manager attach --auto
# subscription-manager status

subscription-manager register --org="IBM_Managed_Applications" --activationkey="FMS_CMS3x_Key" --force

5) subscription-manager register --org="IBM_Managed_Applications" --activationkey="FMS3.x Daily Repos"    use to register RHEL in 2023
6. subscription-manager repos --enable "*"


yum-config-manager --enable *

Sandeep's steps
1.subscription-manager unregister
2.subscription-manager clean
3.yum clean all
4.subscription-manager attach
subscription-manager register --org="FMS_CMS3x" --activationkey="FMS_CMS3x_Key" --force


Error executing action `register` on resource 'rhsm_register[svad1srv0]'
try
subscription-manager clean
Always check dnsmasq service status and start it and only then run chef-client as it stops after upgrade

then chef-client


12.3.4. Displaying package information with yum
To display information about one or more packages, use:

# yum info package-name



12.3.5. Listing package groups with yum
To view the number of installed and available groups, use:

# yum group summary
To list all installed and available groups, use:

# yum group list
Note that you can filter the results by appending command line options for the yum group list command (--hidden, --available). For more available options see the man pages.

To list mandatory and optional packages contained in a particular group, use:

# yum group info group-name


https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_basic_system_settings/managing-software-packages_configuring-basic-system-settings


[root@oc0068885656 rmalik]# systemctl start besclient.service
[root@oc0068885656 rmalik]# systemctl status besclient.service
-------------------------------------------------------------------------------------------------------------------------

For CMS people, root access is based on IMZCloud AD groups. SAP Admins and Linux Admins have root access. AD groups can be added by IAM team on request with manager approval 

------------------------------------------------------------------------------------------------------------------------------

To chk if the server is physical or virtual

dmesg |grep "Hypervisor detected"

dmidcode

dmidecode -t system

The ‘dmesg‘ command displays the messages from the kernel ring buffer. A system passes multiple runlevel from where we can get lot of information like system architecture, cpu, attached device, RAM etc. When computer boots up, a kernel (core of an operating system) is loaded into memory. During that period number of messages are being displayed where we can see hardware devices detected by kernel.

----------------------------------------------------------------------------------------------------------------------------------------

Datastore migration

if during migration you see the compatibility fails with error 
Virtual machine is installing VMtools.

to get rid of the above, right click on VM and select guest and end VMWare tool install
after this is done migration compatibility will be success and u can migrate.

--------------------------------------------------------------------------------------------------------- 

RHEL 7.5

systemctl status zabbix-agent
systemctl enable zabbix-agent
ps -fu zabbix
egrep -v "^#|^$" /etc/zabbix/zabbix_agentd.conf

systemctl status sssd.service



top -M equivalent for RHEL 7.5 is 

top then f and then p


in SUSE
 systemctl status zabbix-agentd.service
 
 swap in SuSE
 top >> press F>> select swap by presssing d >> press q or esc

vmtools service
 systemctl status vmware-tools.service
--------------------------------------------------------------------------------------------------------------

patch update change

bring the apps down
sudo yum install screen

SuSE: Install the package update using either YaST or Zypper.


yum clean all
yum check-update
yum update
uname -a to get current kernel version 
reboot
check kernel version uname -a to get updated version
Update the VMtools vmware-config-tools.pl --default


/etc/yum.repos.d/redhat.repo

-------------------------------------------------------------------------------------------------------------------

FTP

Quick guide to SFTP and FTP setup

 

1. IAM creates id
2. OS team verifies home path for sftp user is path to be used for sftp
3. Path ownership should be sftpyhi:sapsys 

 

For install of FTP and SFTP:

1.  yum install vsftpd.x86_64

zypper -n install lftp    for SUSE
zypper -n install vsftpd

zypper in <package> or zypper up <package>
in = install
up = update

    Only security patches: zypper patch    security and recommended if only security then zypper patch -g security

    Full update: zypper up

List all available patches:
zypper list-patches

List only the security patches
zypper list-patches --category security

Install only the security patches
zypper patch --category security



2. sed -i -- 's/anonymous_enable=YES/anonymous_enable=NO/g' /etc/vsftpd/vsftpd.conf

3. service vsftpd restart

4. chkconfig vsftpd on

5. getenforce       Note:  if returns enable run next step

6.  setsebool -P allow_ftpd_full_access 1

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/SFTP%20-%20FTP%20setup

-------------------------------------------------------------------------------------------------------------------------------------

Please Note -- Whenever you get VM hung issue.
1 Take screen shot of console and confirm, if VM is really hung.
2. Take screen snap of VM from vsphere.
3. VM will be in hung state su put it into suspended mode. Once that will done.. click on summary -- click on host ...you will get databrowser. You will see .vmss has created.
create 1 new folder there with any name as your choice eg ( bakcup of vmss_file ) and move .vmss file into that folder.
so, after reboot .vmss will not be overwrite.


Query 4 :- Precautions needs to be taken at the time when taking console.

Solution -- IMPORTANT Before suspended to VM must create resource utilization file..

First ssh to ESXi host where the hung VM is located. Get root password from Softlayer portal
once you logged run this command from tmp folder
/tmp # esxtop –b –d 5 -n 100 > output-perf-statistics-file.csv
This csv file will have resource utilization on the ESX host at that time.

NOTE -- Doc reviewer, Kindly add more valid points, if need to follow.

-------------------------------------------------------------------------------------------------------------------------


https://w3.ibm.com/help/#/article/40920
https://w3.ibm.com/help/#/article/linux_install/overview?requestedTopicId=overview

SAS VPN certificate
https://w3-01.ibm.com/tools/vpn/enduser/userdevice.php
---------------------------------------------------------------------------------------------------------------------------

Linux server patching

 Pre-requisite steps : 
-If PHANA and VHANA servers listed, please contact Infra Team Squad members ahead of change.
-For applying RedHat Satellite subscriptions to non-Hana RHEL 6.x VMs only if new packages are not found on this customer VMs:
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/RedHat%20Satellite%20infra%20%26%20Chef%20recipe
d. OS team follow the wiki for applying upgrades/patching :
- Please use below wiki if listed server's requiring kernal upgrade and OS can be upgraded to RHEL6.9 :
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/OS Upgrade Procedure %28Linux%29
- Please use below wiki if listed server's requires ONLY Security patches/updates, no OS version will be upgraded :
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/LSSECFIXES(PATCHING)

HANA upgrade
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Hana%20upgrade%20from%206.5%20to%206.7

NOTE1: If server is HANA DB and OS version is 6.7 DO NOT TAKE patching action.
NOTE2: If server is a vhana and requires snapshot or a phana requires a reboot, please contact Infra Team squad, as their team only has access at ESXI level(vhanas) and consol access (phanas) if servers are not coming up.

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/RedHat%20Satellite%20infra%20%26%20Chef%20recipe

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/OS%20Upgrade%20Procedure%20(Linux)

This system is not registered with an entitlement server. You can use subscription-manager to register.
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/RedHat%20Satellite%20infra%20%26%20Chef%20recipe

If the above does not work, rebootstrap

Running the"/usr/bin/vmware-config-tools.pl -d" script and rebooting the server one final time before OS validation

for SAP HANA 1.0 systems where revision is 122.22 and newer => we can upgrade SLES12 SP2 to SLES12 SP4
for SAP HANA 1.0 systems where revision is 122.21 and below => we can patch SLES12 SP2 to latest versions in SP2
****** Once we got to the latest SP level as above then we ONLY APPLY LATEST SECURITY patches on that version ..   e.g  SLES SP2,   SLES SP4
for SAP HANA 2.0 systems where revision is 35 and newer => we can upgrade SLES12 SP2 to SLES12 SP4
for SAP HANA 2.0 systems where revision is 34 and below => we can patch SLES12 SP2 to latest versions in SP2
****** Once we got to the latest SP level as above then we ONLY APPLY LATEST SECURITY patches on that version ..   e.g  SLES SP2,   SLES SP4
RHEL HANA DB - 3.x only
We will ONLY patch the LATEST SECURITY patches on the SAME LEVEL...

----------------------------------------------------------------------------------------------------------------------------

sar -S -f /var/log/sa/saXX ( no of days ) swap info

refer chat with sandeep dated 14-05-18


sar -u -f /var/log/sa/sa01	Free CPU

sar -q -f /var/log/sa/sa01	CPU used

 sar -f sa18 -u  CPU in percentage
 
 sar -f sa18 -u 7200   cpu every 7200 seconds
 
 sar -f sa26 -r
 
 using "sar -u -f" for CPU and "sar -r -f" for memory
 
 https://www.2daygeek.com/linux-get-average-cpu-memory-utilization-from-sar-data-report/
 
 
 sar -r -f ->memory usage
 sar -u -f->CPU usage


convert binary sar into txt
sar -A -f /var/log/sa/sa20210702 > /tmp/sa20210702.out

 
process uer cpu and memory 
ps -eo user,pcpu,pmem | tail -n +2 | awk '{num[$1]++; cpu[$1] += $2; mem[$1] += $3} END{printf("NPROC\tUSER\tCPU\tMEM\n"); for (user in cpu) printf("%d\t%s\t%.2f\t%.2f\n",num[user], user, cpu[user], mem[user]) }' 
 
this gives the memory usage and reboot details
[root@PBBs4hqap00 log]$ sar -r   ->memory usage



Linux 2.6.32-754.24.3.el6.x86_64 (PBBs4hqap00)  01/03/2020      _x86_64_       (4 CPU)

06:25:51 PM       LINUX RESTART

06:33:22 PM       LINUX RESTART

06:40:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit
06:50:02 PM   6619464   9697384     59.43     83156   4620712  25164364     30.16
07:00:02 PM   6453552   9863296     60.45     88852   4686740  25176772     30.18
07:10:01 PM   6060364  10256484     62.86    180624   4780508  25205528     30.21
07:20:01 PM   5592792  10724056     65.72    192972   5099208  25235848     30.25
07:30:01 PM   5526576  10790272     66.13    198728   5103280  25244156     30.26
Average:      6050550  10266298     62.92    148866   4858090  25205334     30.21
[root@PBBs4hqap00 log]$ date
Fri Jan  3 19:36:43 +07 2020


Troubleshooting kernel hung
https://www.blackmoreops.com/2014/09/22/linux-kernel-panic-issue-fix-hung_task_timeout_secs-blocked-120-seconds-problem/


Solution for hung_task_timeout_secs
Explanation
By default Linux uses up to 40% of the available memory for file system caching. After this mark has been reached the file system flushes all outstanding data to disk causing all following IOs going synchronous. For flushing out this data to disk this there is a time limit of 120 seconds by default. In the case here the IO subsystem is not fast enough to flush the data withing 120 seconds. As IO subsystem responds slowly and more requests are served, System Memory gets filled up resulting in the above error, thus serving HTTP requests.

-----------------------------------------------------------------------------------------------------------------

1-337828870 raised for access to RDP VCS servers

----------------------------------------------------------------------------------------------------------------------

To empty a log file

> <filename.log>
# > access.log


# : > access.log
OR 
# true > access.log


# cat /dev/null > access.log


-----------------------------------------------------------------------------------------------------------------

 role of solman is - for maintaning all satelliite systems

--------------------------------------------------------------------------------------------------------------------
NTP ticket output

ntpq -pn;ntpstat;ntpdate;date

-----------------------------------------------------------------------------------------------------------------

- rootsh chef procedure is only for customers (send request to https://github.kyndryl.net/CMS/Platform-Support/issues )
- rootsh for CMS people is done by IAM with AD groups
so in both cases OS Team can't help

The approval and management of sudo rootsh has been moved to the IAM team.

https://github.ibm.com/CMS  for any type of issues


---------------------------------------------------------------------------------------------------------------

Linux CPU model


less /proc/cpuinfo

----------------------------------------------------------------------------------------------------------------

Area  CMS-TR-SAP-CLIENT
sub area CMS-SQ-SAP-TRIO-10
Performer SAP10
------------------------------------------------------------------------------------------------------------------

[root@clderpdtbp1 yum.repos.d]#  yum clean all
rpmdb: Thread/process 74444/140589792896928 failed: Thread died in Berkeley DB library
error: db3 error(-30974) from dbenv->failchk: DB_RUNRECOVERY: Fatal error, run database recovery
error: cannot open Packages index using db3 -  (-30974)
error: cannot open Packages database in /var/lib/rpm
CRITICAL:yum.main:

Error: rpmdb open failed

https://access.redhat.com/solutions/6903



fix is 

solution:
*******
1) tar cvzf rpmdb-backup.tar.gz /var/lib/rpm  // backup just in case
2) rm /var/lib/rpm/__db.00*
3) rpm –rebuilddb



# mkdir /var/lib/rpm/backup
# cp -a /var/lib/rpm/__db* /var/lib/rpm/backup/
# rm -f /var/lib/rpm/__db.[0-9][0-9]*
# rpm --quiet -qa
# rpm --rebuilddb 

-------------------------------------------------------------------------------------------


mount -t nfs 10.198.0.141:/usr/sap/EP1/HDB00/backup/data /EP1_BACKUP

check for NFS services on both servers if stopped start them





----------------------------------------------------------------------------------------------

Event log in windows for shut down and start up
run->eventvwr
Windows->system


Event ID 6005 will be labeled as “The event log service was started”. This is synonymous to system startup.

Event ID 6006 will be labeled as “The event log service was stopped”. This is synonymous to system shutdown.

Event id 1074 will give the user who shut down the windows server

---------------------------------------------------------------------------------------------------

Umount NFS device is busy


umount -f -l  <fs path>
----------------------------------------------------------------------------------------------------

ATnT calling


000117
Toll Free:    1-888-426-6840
passcode

----------------------------------------------------------------------------------------------------------
Windows local admin

admlocal , and password Set44now@

Administrator
coty@dm1n

----------------------------------------------------------------------------------------------------------

Paging file size in windows

1. Take Snapshot of the Server .
 
2. Bring Apps down with the help of  SAP team.

3. Go to the control panel and click System in the pop-up menu

4. Tap or click Advanced system settings. Administrator permission required You might be asked for an admin password or to confirm your choice.

5. On the Advanced tab, under Performance, tap or click Settings.

6. Tap or click the Advanced tab, and then, under Virtual memory, tap or click Change.

7. Clear the Automatically manage paging file size for all drives check box.

8. Under Drive [Volume Label], tap or click the drive that contains the paging file you want to change.

9. Tap or click Custom size, enter a new size in megabytes in the Initial size (MB) or Maximum size (MB) box, tap or click Set, and then tap or click OK.

10. After Windows reboot verfiy the Swap space after increase and provide the screenshot OS

---------------------------------------------------------------------------------------------------------------------

Copy folder from one to other location in WIndws

Use robocopy command

https://social.technet.microsoft.com/wiki/contents/articles/1073.robocopy-and-a-few-examples.aspx

https://www.computerhope.com/robocopy.htm

http://2clickfix.com/practical-robocopy-examples/

robocopy <source> <destination> 
ROBOCOPY "\\10.6.1.24\E$\FS-PRO" "E:\FS-PRO" /E /MIR /XX /SEC /copyall 
 



To delete a file/folder from WIndows DOS

robocopy /e /b /purge c:\empty c:\folder-to-delete



COPY folder in Linux

cp -v -p -R . /usr/sap/trans1

compare folders diff <folder 1>  <folder2>

--------------------------------------------------------------------------------------------------------------------
Use last -a to find the users login with date and time

-----------------------------------------------------------------------------------------------------------------

VMWare tools update manually

https://w3-connections.ibm.com/wikis/home?lang=en-gb#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/VMware%20tools%20manual%20upgrade%2C%20downgrade%2C%20uninstall%20%28Linux%20CLI%29

ls -l VMware-Tools-10.1.10-core-6082533.iso on chef regional server

latest version is 10.2.5.3619 (build-8068406)

for vhana systems only 9.4.0.25793 works
14. Reinstall vmware-tools as we have a new kernel AND double check for the correct version - 9.4.0.25793 (build-1280544). If you see a different version, please go to Vmware upgrade procedure and reinstall

(https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/vHana%20-%20VMware%20Tools%20Removal%20Tracking)

(https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/VMware%20tools%20manual%20upgrade%2C%20downgrade%2C%20uninstall%20(Linux%20CLI))

    vmware-config-tools.pl --default

    vmware-toolbox-cmd -v

search for the version from any server where the vmtools are current and running
vmware-toolbox-cmd -v


found the version of vmtools from working server, searched for the iso on chef regional server and then followed the steps in that wiki link 

 503  2018-11-13 14:58:57 vmware-uninstall-tools.pl
  504  2018-11-13 14:59:46 mkdir /mnt/vmware-tools
  505  2018-11-13 15:00:25 mount -o loop /tmp/VMware-Tools-10.1.10-core-6082533.iso /mnt/vmware-tools/
  506  2018-11-13 15:00:54 cp /mnt/vmware-tools/VMwareTools-10.1.10-6082533.tar.gz /tmp/
  507  2018-11-13 15:01:03 cd /tmp/
  509  2018-11-13 15:01:57  tar -xzvf VMwareTools-10.1.10-6082533.tar.gz
  510  2018-11-13 15:02:07 cd vmware-tools-distrib/
  511  2018-11-13 15:02:19 ./vmware-install.pl --default
  
  for HANA
503  2020-07-11 07:08:19 vmware-uninstall-tools.pl
  504  2020-07-11 07:10:03 mkdir /mnt/vmware-tools
  505  2020-07-11 07:10:29 mount -o loop /tmp/VMware-tools-linux-9.4.0-1280544.iso /mnt/vmware-tools/
  506  2020-07-11 07:10:51 cp /mnt/vmware-tools/VMwareTools-9.4.0-1280544.tar.gz /tmp/
  507  2020-07-11 07:11:02 cd /tmp
  508  2020-07-11 07:11:08 tar -xzvf VMwareTools-9.4.0-1280544.tar.gz
  509  2020-07-11 07:11:22 cd vmware-tools-distrib/
  510  2020-07-11 07:11:30 ./vmware-install.pl --default
  511  2020-07-11 07:55:24 /etc/vmware-tools/services.sh status
  512  2020-07-11 07:55:29 date
  513  2020-07-11 07:55:40 vmware-toolbox-cmd -v
  

mkdir /mnt/vmware-tools;mount -o loop /tmp/VMware-Tools-10.1.10-core-6082533.iso /mnt/vmware-tools/;cp /mnt/vmware-tools/VMwareTools-10.1.10-6082533.tar.gz /tmp/;cd /tmp/;tar -xzvf VMwareTools-10.1.10-6082533.tar.gz;cd vmware-tools-distrib/;./vmware-install.pl --default

steps to install VMtools on linux VM's.

Mount the VMtools CD from VCenter:

Righ-click on VM, point to guest and click on Install/Upgrade VMtools.
We will get two options:Interactive and Automatic Tools Upgrade.
Select Automatic if available and click OK. (This is update the VMtools and no further action is required by us).
If Automatic option is not available, then select Interactive Tools upgrade and click OK.
Then copy and paste the below commands to install from OS level.

sudo rootsh
vmware-uninstall-tools.pl
mkdir  /mnt/cdrom
mount -t iso9660 /dev/sr0 /mnt/cdrom
cd /tmp
rm -rf vmware*
rm -f VMware*
cp /mnt/cdrom/VM* /tmp
tar zxf VM*
cd vmware*
./vmware-install.pl --default
/etc/vmware-tools/services.sh status
cd /tmp
rm -f VMware*
rm -rf vmware*
----------------------------------------------------------------------------------------------------------------------------

Linux server created from snapshot/clone/from backup

Log in to your server via the KVM in your control panel
Remove the contents of /etc/udev/rules.d/70-persistent-net.rules

Open /etc/sysconfig/network/scripts/ifcfg-eth0, and change the contents to the following:

copy from original and edit the MAC adress found in vcenter of new server created from snapshot.


DEVICE=eth0
TYPE=Ethernet
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=dhcp
DNS1=8.8.8.8
NAME="System eth0"

Reboot your server



Windows cloning

if there is a domain join error, verify the routes of the working server with the cloned one
compare routes from old VM and new VM using route print command
check every route and then add one by one routes using command route /p add command
remove incorrect routes using route delete command

route print in WIndoes
ip route in Linux


-------------------------------------------------------------------------------------------------------------------------------

Updating/changing ip for linux

https://www.howtogeek.com/118337/stupid-geek-tricks-change-your-ip-address-from-the-command-line-in-linux/

-------------------------------------------------------------------------------------------------------------

To find files deleted from some specific folder 

find /home -type f -iname .*history -exec grep "rm\|mv" {} \;

Here are all other possibilities for grep and egrep command:
grep 'word1\|word2\|word3' /path/to/file
### Search all text files ###
grep 'word*' *.txt
### Search all python files for 'wordA' or 'wordB' ###
grep 'wordA*'\''wordB' *.py
grep -E 'word1|word2' *.doc
grep -e string1 -e string2 *.pl
egrep "word1|word2" *.c
### Show all the lines that do not match given pattern/words/strings ###
grep -v 'bar\|foo' /dir1/dir2/file1
egrep -v 'pattern1|pattern2' /path/to/file

-------------------------------------------------------------------------------------------------------------------

Leave apply
http://146.89.3.136:8080/CMS4SAP/applyonline_ps.jsp?empid=129
uid C-HRRJ897

--------------------------------------------------------------------------------------------------------------------

	Information Update - There are multiple changes: Automation Focal Training 
	Fri 06/29/2018 9:30 PM - 10:30 PM
	(Repeats)
	
	
	Attendance is required for Ravi Malik
	
	Chair:
	Patty Rich/Phoenix/Contr/IBM
	
	Location:
	https://ibm2.webex.com/meet/prich Access code:  858 242 266,    1-844-531-0958 United States of America Toll Free 000-800-0504054 India Toll Free Access code:  858 242 266 Host PIN: 9922 
	
	
----------------------------------------------------------------------------------------------------------------------------------------

 If you do not have MS Office installed on your VM /Laptop, please follow the steps below -
1) go to https://w3-01.ibm.com/download/standardsoftware/PC/lang_en/issiCatalogPC.html) search for Microsoft Office 365 ProPlus
3) Install

-------------------------------------------------------------------------------------------------------------------------------------
Shift link

http://146.89.3.136:8080/CMS4SAP/AMM_SAP_OS_TSM.jsp?iMonth=6&iYear=2018 
https://eisapp.persistent.co.in/eis/LMS/webui/LeaveReports/AttendanceTransaction.aspx 

---------------------------------------------------------------------------------------------------------------------------------

Linux last reboot details

Last command. Use the 'last reboot' command, which will display all the previous reboot date and time for the system. ...
Who command. Use the 'who -b' command which displays the last system reboot date and time.
egrep -i '(shut|reboot)' messages


Last reboot of Windows server
net statistics server from command prompt

/usr/bin/last -xF | egrep "reboot|shutdown|runlevel|system"

--------------------------------------------------------------------------------------------------------------------------------------

Swap space 

From your root userid, enter the command "swapon -s". This will show your allocated swap disk or disks

-----------------------------------------------------------------------------------------------------------------------------------------

CHMOD


    4 stands for "read",
    2 stands for "write",
    1 stands for "execute", and
    0 stands for "no permission."

------------------------------------------------------------------------------------------------------------------------------------1
Vcenter client install

https://kb.vmware.com/s/article/2089791
http://vsphereclient.vmware.com/vsphereclient/2/5/0/2/2/2/2/VMware-viclient-all-6.0.0-2502222.exe

---------------------------------------------------------------------------------------------------------------
root password change in single user mode

https://www.cyberciti.biz/faq/grub-boot-into-single-user-mode/

(5) Press the e key to edit kernel entry so that you can append single user mode
(6) Append the letter S (or word Single) to the end of the (kernel) line

Go into rescue mode->reboot and keep pressing up and down key to get the kernel selection page, select the latest version and press 'e' then again select the kernel version option and then press 'e' then add '<space> 1' at the end and then select b and it boots back in single user mode as root

rescue mode working https://www.novell.com/documentation/suse91/suselinux-adminguide/html/ch12s05.html
journalctl -xb  |grep -i error |less
vgchange -ay rootvg
lvscan
[root@sapapp19 ~]$ tune2fs -l /dev/rootvg/rootlv |grep state

The XFS equivalent for tune2fs -l is xfs_info

Filesystem state:         clean
check each fs  like this
if you see clean with error  run fsck
e2fsck -f -y and path rite
or
fsck.xfs /dev/roovg/lvname

fsck -p <path to check for error>


rd.break,  single, or init=/bin/bash


SuSE
Some filesystem defined in /etc/fstab failed to mount. You should get list of failed units with "systemctl --failed -l". Post this list here.
then repair with
btrfs check --repair /dev/sda6

FOR TATA servers on DR site with bootup issues
If the server goes in maintenance mode on the DR site perform these steps from the DR VC console:
Enter root pw to get to the prompt
run mount -o remount, rw /  
or mount /dev/pts -o remount
run journalctl -xb |grep -i error |less   and check out the error, it will point to the FS with error where we need to run FSCK to fix it
vgchange -ay
lvscan
tune2fs -l <problematic FS path found in logs above> |grep state
Filesystem state:         clean with error                      check each fs with state as clean with error
Run the below to run fsck to that FS and fix the errors
e2fsck -f -y <FS path>

Once fixed check the /etc/fstab and comment any FS with VG name having tempvg, even the ones with saptempvg and save and restart the VM



comment a section put /* and */


One liner to check for FS with errors (fsck error)
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done |less

 
Steps : -
0-  Ask  SAP  performer  to  stop  App/DB 
1- Take VM snapshot
2-  Take  backup  of  all  important  files  like we  do before  patching
3-  Take  backup of  /etc/fstab  file  and  modify  the  last  2  columns  from  0 0  to 1 1  (except  /  & /boot)
4-  Perform  the  patching   steps  on server
5- Reboot  server and  monitor  vm from vm console.
6- When  server  boots  up, check  FS  state using  below  command  - 
 
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done
 
 
 
 If  you  see  all  FS  are showing  "Clean" then  all  OK  (don't  need  to  take any  additional step)
 
7- after executing  above  command  if  you  find  any  FS  is  showing  "Clean  with  error" then  perform  below  steps  - 
 
umount  <mount  point  which is  having  error>
fsck  -y  <lvm path>
 
 
verify  the status  using  below  command  -
 
tune2fs -l  /dev/mapper/vg-lv-name |grep state
 



then it logs u with root
passwd command to change the root pw and then reboot

init=/bin/sh ( when you press  e  and come to kernel  line ...instead  of 1  or S  use  init=/bin/sh )
e2fsck -f -y /dev/mapper/vg00_root  < -- if that solution doesn't work so, run below 

Options, if required or could not fixed by above solution- to fix Readonly / fs
mount | grep root
mount -o remount,rw /
vi /etc/fstab and change the default values to 1 0 for root and 0 0 for all
exit
exit
reboot 



cat /etc/passwd

Each line represents one user and has seven (7) fields.

The fields are separated by : (colons) and each line includes the following information:

1. Username
2. The encrypted password (represented by x, located in the /etc/shadow file)
3. User ID number (known as UID)
4. User group ID (known as GID)
5. User full name
6. User home directory
7. The login shell (by default set to bin/bash)

-----------------------------------------------------------------------------------

Raising issue with GIT

https://github.kyndryl.net/CMS/Platform-Support/issues
https://github.kyndryl.net/CMS/Platform-Support/issues    -New Chef issue kyndryl


GIthub issue for Physical infra
https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/issues
 label:"SQ:Infra Mgmt 3.x Infra"

for datastore ext 
https://github.kyndryl.net/CMS/cms-opaas-api/issues

------------------------------------------------------------------------------------

I/O monitoring

iotop

iostat

-----------------------------------------------------------------------------------------
http://146.89.3.136:8080/CSR_ALLOCATION/

This portal has reminder/notification  feature
 1)  2 hrs before CSR start time
 2)  Just after Peformer assignment 
 3)  24  hrs before CSR start window.

-------------------------------------------------------------------------------------------------
SCORE link

http://146.89.3.26:8000/sap/bc/gui/sap/its/webgui?sap-theme=sap_tradeshow&sap-client=100&sap-language=EN 

SCORE Access 1-340979897 new ticket for SCORE 1-344103961

------------------------------------------------------------------------------------------------

IBM lotus notes on verse
https://mail.notes.na.collabserv.com/verse

New Verse link
https://gd.mail.ibm.com/verse
-------------------------------------------------------------------------------------------------

vmtools not running(current)

means teh service is stopped, login to the vm and 
/etc/vmware-tools/services.sh status
/etc/vmware-tools/services.sh start 

-----------------------------------------------------------------------------------------------------

NFS helper script
https://access.redhat.com/labs/nfshelper/#/

How to troubleshoot an NFS mount timeout?
https://access.redhat.com/solutions/1751813


NFS mount fails after reboot
https://access.redhat.com/solutions/2305321

NFS-shares are not marked with _netdev.

Without the _netdev option, entries within /etc/fstab may attempt to mount before networking is initialized causing the mount request to fail due to complete lack of connectivity. It is advised to make the necessary changes as below in /etc/fstab:
10.92.99.110:/usr/sap/trans /usr/sap/trans nfs rw,hard,intr,rsize=32768,wsize=32768,_netdev 1 2
10.70.111.46:/sftp/prd /usr/sap/sftp nfs defaults,_netdev 0 0


NFS configure in SuSE
https://www.howtoforge.com/setting-up-an-nfs-server-and-client-on-opensuse-12.2


creating a new NFS share

Server ip - 192.168.100
Client ip - 192.168.101

echo 'Y' > /sys/module/nfsd/parameters/nfs4_disable_idmapping  or in some cases  echo 'Y' >  /sys/module/nfs/parameters/nfs4_disable_idmapping

fstab NFS4
10.140.32.28:/usr/sap/trans	/usr/sap/trans	nfs4	defaults,intr 0 0 


1. Install the NFS in Server System
2. Start NFS service
service rpcbind start and service nfs start --- chkconfig rpcbind/portmap/nfs on
Make sure netfs service is enabled to start upon boot and is started upon bootup.

chkconfig netfs on will  enable to start upon boot and is started upon bootup


3.Create shared directories in server
mkdir /dir_sharing_nfs
chmod 755 /dir_sharing_nfs

4. export shared directory on NFS server

vi /etc/exports
/dir ip_of_client(rw,sync,no_root_squash)
dir_sharing_nfs 192.168.1.10(rw,sync,no_root_squash)

5. restart nfs service  using yast in SuSe NFS server on the server and client on the client 

############## CLIENT Part ###################
echo 'Y' > /sys/module/nfs/parameters/nfs4_disable_idmapping

1. find out that shares available on the remote server or NFS Server.
showmount -e ip_of_server
showmount -e 10.5.22.12

2.Mount shared Directories on NFS client
Create a mount to mount the directory which you shared on server. if you need to mount on existing dir so, u can use that.
mount -t nfs ip_of_server:/directory_path /on_mounted_point
mount -t nfs 192.168.0.100:/dir_sharing_nfs /usr/sap/idm
The above command will mount that shared directory in “/usr/sap/idm” on the client server. You can verify it 
3. verify 
mount |grep nfs

4. To mount NFS directory Permanent in client across reboot has to entry in /etc/fstab
vi /etc/fstab
ip_of_server:/directory_path /mount nfs defaults 0 0
10.250.17.49:/interfaces/HME /interfaces/HME nfs defaults 0 0

172.22.0.26:/sap_bobj/SFTP /sap_bobj/SFTP nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0
10.5.22.12:/idocs/dev /idocs nfs    rw,hard,intr,rsize=32768,wsize=32768    0       0

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/NFS%20Mounts%20for%20SAP%20team

---------------------------------------------------------------------------------------------------------------
B1 Sept Roster
https://ibm.box.com/s/58fm9smawmuh9l82wb68njbyx5yji2ny


B1 roster Dec_Jan
https://ibm.box.com/s/646o9ks50u2ekgdw2gblykhz2pdxofn6


B1 roster Feb-March
https://ibm.box.com/s/2s2j6snsk0qs7mr6d24x00t2kau1nf4i

June-July21
Link - https://ibm.box.com/s/vjc6q2jpe0jmc264ielu83orgk48za0r


April-May
https://ibm.box.com/s/plb75j4x3avikut3empyxgza4w0rhqzn

August roster
https://ibm.ent.box.com/s/y41ksnobsgl60rj1a2ov6uzzx5l5vf8a

Sept Oct
https://kyndryl.ent.box.com/s/vdh857u3mnzlbsbcqdspoxuzglz69unz

Nov-Dec
https://kyndryl.box.com/s/dh17hwqtcjc24qwqi3ybis31y49y7wem

JAn 2022 Roster
https://kyndryl.box.com/s/kl1ahshakzennqx9hgbvayp2h9izksxi

Shift roster link for March and April 22 : https://kyndryl.box.com/s/8kr2jc83sim5perw0z5xknfd3y5bnvf0

May22 https://kyndryl.box.com/s/nzmr21gfatio2d7vd7wvjon2ypz71n8i

A trio roster link on box
https://kyndryl.box.com/v/OS-Roster-A2-AP

July 2022 roster B
https://kyndryl.box.com/s/l6300vu59qmm4pgutsch1b6i8gsf1r0y

Sept
https://kyndryl.box.com/s/55ovhadrjq8tmkhsnvjjt46p6idg4hmq

Oct Nov roster B trio
https://kyndryl.sharepoint.com/:x:/t/MASAPTroopABCCollaboration/EcT60RBd9GZEmmw6aMvfVugBEo0iANKes71VqVqL7VDbpQ

Dec roster
https://kyndryl.sharepoint.com/:x:/r/teams/MASAPTroopABCCollaboration/Shared%20Documents/Tribe%20B%20%26%20C%20(AP%20-%20EMEA%20)%20Roster/Tribe%20B%20%26%20C%20-%20Change%20assignment%20Dec2022.xlsx?d=w568af71accf3423cad836b771b9812a6&csf=1&web=1&e=SU1cAO

Jan23 B trio
https://kyndryl.sharepoint.com/:x:/t/MASAPDispatchingB1B2-ABC/EWnw-V7HXUtOiLmhDlkHuYwBB2_eoA_YV7NDPfkeFX50Hg?e=ARZaM2

Feb23 roster B trio
https://kyndryl.sharepoint.com/:x:/r/teams/MASAPDispatchingB1B2-ABC/Shared%20Documents/Tribe%20B%20%26%20C%20-%20Change%20assignment%20Jan%20%26%20Feb%202023%20v2.0%20.xlsx?d=w07ac1c095b3f4688a4e3429b6238accd&csf=1&web=1&e=qJ64ux

March 23 B trio https://kyndryl.sharepoint.com/:x:/r/teams/MASAPDispatchingB1B2-ABC/Shared%20Documents/Tribe%20B%20%26%20C%20-%20Change%20assignment%20Feb%20%26%20Mar%202023%20v2.0%20.xlsx?d=w07ac1c095b3f4688a4e3429b6238accd&csf=1&web=1&e=DNMxUF


APril 2023  https://kyndryl.sharepoint.com/:x:/r/teams/MASAPDispatchingB1B2-ABC/_layouts/15/Doc.aspx?sourcedoc=%7B07AC1C09-5B3F-4688-A4E3-429B6238ACCD%7D&file=Tribe%20B%20%26%20C%20-%20Change%20assignment%20Mar%20%26%20April%202023%20v2.0%20.xlsx&_DSL=1&action=default&mobileredirect=true


A trio roster link updated as on Sept 2023
https://urldefense.proofpoint.com/v2/url?u=https-3A__kyndryl.sharepoint.com_teams_MASAPTroopA-2DSAP-2DAP-2DSquadLeadsInternalChannel_Shared-2520Documents_OS-2DAP-2DEMEA-2Dshift-2Droster-2D2023.xlsx-3Fd-3Dw2941d9b9cda34e93b0752d9f9adb3f66-26web-3D1&d=DwMBaQ&c=cCoa5WWAB7EEETJScYfkXg&r=vIjIucjD099LwkErW8Q0meDZylI2eeVkgKb-zfxyVn8&m=PZl5lD43EQ3ICcTwZNUXhBUctkNzujajvLZ_1cmh9Vi1lPyJINHn2kW_a9JEsIsq&s=iMvqd481BejiO9jwGXavVLcitQrBBiB6w2zlNY1-kEw&e=

May June July 23
https://kyndryl.sharepoint.com/:x:/r/teams/MASAPDispatchingB1B2-ABC/Shared%20Documents/Tribe%20B%20%26%20C%20-%20Change%20assignment%20Aug%202023%20v1.0%20%20(2).xlsx?d=w29ac5f4121ac442ba70a6904a4b08583&csf=1&web=1&e=nMke2f
-------------------------------------------------------------------------------------------------------------------

Check if server is virtual or physical


sudo dmidecode -s system-manufacturer   if physical then response will be Dell or Lenovo

CTUBWQB2DB01:/home/ibmrmalik # sudo dmidecode | grep Product
        Product Name: Lenovo System x3950 X6                               -[6241AC4]-
        Product Name: 00YA741
        Product Name: 00YA741


----------------------------------------------------------------------------------------------------------------------

Search server SCORE

http://146.89.3.136:8080/AssetMCO/preips.jsp

------------------------------------------------------------------------------------------------------------------------
Sybase db start error:

CT-LIBRARY error:
        ct_connect(): network packet layer: internal net library error: Net-Lib protocol driver call to connect two endpoints failed

start the Sybase DB first

-----------------------------------------------------------------------------------------------------------

Vyata server tickets to be routed to

pls assign to AMM-Network
subarea - Troubleshoot

SNOW queue for n/w  MA-ASGN-INF-3x-SEI-NWK-FW

--------------------------------------------------------------------------------------------------------------

SUncor 66.248.241.253

this is a tool server and has no impact to the customer as confirmed by Aravind.Shanmuganatha@ibm.com - Aravind Shanmuganatha/Canada/IBM:
Should be assigned to COLO team
--------------------------------------------------------------------------------------------------------------------
to check teh partitions in linux:

cat /proc/partitions

=---------------------------------------------------------------------------------------------------------

Installing rootsh


ibmrmalik@FRDAL13ASCS01:~> sudo su
FRDAL13ASCS01:/home/ibmrmalik # rpm -ivh http://146.89.140.152/3rdparty/AOD/rhel-6-server/RPMS/x86_64/rootsh-1.5.3-11.el6.x86_64.rpm

Retrieving http://146.89.140.152/3rdparty/AOD/rhel-6-server/RPMS/x86_64/rootsh-1.5.3-11.el6.x86_64.rpm
Preparing...                          ################################# [100%]
Updating / installing...
   1:rootsh-1.5.3-11.el6              ################################# [100%]
------------------------------------------------------------------------------------------------------------------------------------------
To cleanup folder files use logrotate

logrotate -f /etc/logrotate.conf



 use "lsof | grep delete" to find the deleted files, which still has handle open and kill them using the PID

----------------------------------------------------------------------------------------------------------------------------------------------
Upgrade:

Clear Yum Cache:yum clean all
 
Getting updates : yum check-update

Update the packages:  yum update

Reboot server: shutdown -r now

shutdown -r 2 "System is rebooting.  Please save your work and log off immediately."        shutdown after 2 min with a message displayed

shutdown -r now 'Kernel upgrade requires reboot'

You can also perform a scheduled reboot -- by specifying something other than now as the reboot time:

shutdown -r 22:00 'Work around kernel memory leak'

Check red hat release and version after update:

cat /etc/redhat-release ; uname -a

In case of kernel upgrade, Vmware tools needs to be reinstalled by running (otherwise it will not start up with the VM):

vmware-config-tools.pl --default
----------------------------------------------------------------------------------------------------------------------------------------

Change ticket SME approval

(CMS-SQ-SAP-TRIO-LIN) OS SME approves the change starting on 9th October 2018 @ 7AM PST for 192 hours


------------------------------------------------------------------------------------------------------------------------------------------

Zabbix console ip
http://169.55.192.126

-------------------------------------------------------------------------------------------------------------------------------------------

Dashboard

http://146.89.3.136:8080/AMM_Dashboard/BacklogsBINWise.jsp?bin=all&customer=all



---------------------------------------------------------------------------------------------------------------------------------------

RHEL 7.5 install

https://w3.ibm.com/help/#/article/40920
https://w3.ibm.com/help/#/article/linux_install/overview?requestedTopicId=overview

--------------------------------------------------------------------------------------------------------------

rpmdb corrupt

Synopsis:

If you see rpmdb errors during package management, like this:

rpmdb: Thread/process 277623/140429100390144 failed: Thread died in Berkeley DB library
error: db3 error(-30974) from dbenv->failchk: DB_RUNRECOVERY: Fatal error, run database recovery
error: cannot open Packages index using db3 -  (-30974)
error: cannot open Packages database in /var/lib/rpm
CRITICAL:yum.verbose.cli.yumcompletets:Yum Error: Error: rpmdb open failed

It means that rpmdb database is corrupted.

 

Solution:

Please follow these steps to backup and rebuild rpmdb database:

# mkdir /var/lib/rpm/backup
# cp -a /var/lib/rpm/__db* /var/lib/rpm/backup/
# rm -f /var/lib/rpm/__db.[0-9][0-9]*
# rpm --quiet -qa
# rpm --rebuilddb
# yum clean all


SuSE
[root@br3qsapas32 system]# cd /var/lib/rpm
[root@br3qsapas32 rpm]# rpm --rebuilddb
[root@br3qsapas32 rpm]#  rpm --initdb
[root@br3qsapas32 rpm]# rpm --rebuilddb

------------------------------------------------------------------------------------------------------------

Rerun HC scan

How to re-run the scan :-
1. Login to https://9.58.92.198/request/sod/sod.html
2. Fill the info as below for your email ID as requester and for your VM listed in your SR....see screen shot below.
3. You will receive an email with zip files, please check CSV file and results file and there should be no deviations or failed policy.
4. Please save the files and attach to your SR. Me and Melissa needs that clean scan file to submit in NCI(CIRATS) for closure. 
--------------------------------------------------------------------------------------------------------------------

Check routing table

ip route
route delete default gw IP Address
route add default gw 192.168.1.254 eth0

------------------------------------------------------------------------------------------------

Linux patching
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/Linux%20Upgrade%20Procedure

If a new kernel is installed as part of the patching process, the server is required to be rebooted. However additional steps are required if the server is a VMWARE virtual machine. 
The news steps require running the"/usr/bin/vmware-config-tools.pl -d" script and rebooting the server one final time before OS validation.Note: The “-d” optioncauses the script to take all default options andwill rebuild the initial ram diskto include VMwaretools drivers and hooks. After running the script successfully, a final reboot is required.


Patching via automation process April 2020
https://github.kyndryl.net/CMS/sap-ops-automation-docs/wiki/3.x-Patching-Process

Log in to SAP Operations Portal: https://sapops.containers.ciocloudservices.ibm.com. Choose the correct client CDIR.

-------------------------------------------------------------------------------------------------------

to check server reboot

egrep "reboot|shutdown" /var/log/messages
last
who
last reboot
last -x|grep shutdown
last -x|grep boot
egrep "reboot" /var/log/messages
cat /var/log/boot.log
egrep -i '(shut|reboot)' messages
egrep -i '(shut|reboot)' /var/log/messages
/usr/bin/last -xF | egrep "reboot|shutdown|runlevel|system"  gives the duration of server up
uptime | \
> perl -ne '/.*up +(?:(\d+) days?,? +)?(\d+):(\d+),.*/; $total=((($1*24+$2)*60+$3)*60);
> $now=time(); $now-=$total; $now=localtime($now); print $now,"\n";'


goto /tmp/  
ls -l kr*  
the imz id with the modified date is the date of reboot 

Server hung issues check the keywords in message logs, general cause trend micro, chef or Nagios.
"gsch_install_hook" means, some system call happened due to some modification on the libraries
Plugin-VFS_Filter

https://www.suse.com/support/kb/doc/?id=000019767      System freezes with a large number of tasks waiting for gsch_scan() to return
https://www.suse.com/support/kb/doc/?id=000019767      System freezes with a large number of tasks waiting for gsch_scan() to return


Commands :-

---------------------------------

last reboot

var/log# free -m

/var/log/boot.log | grep sig*

Journalctl -xe

Journalctl -b

Journaltl -k

Journalcrl -p err

Journalctl --dmesg

 journalctl --since "2022-06-06 00:00:00" --until "2022-06-06 23:59:59"  >>/tmp/journallogs_6June.txt
 
 https://www.linode.com/docs/guides/how-to-use-journalctl/
 
 
 journalctl --since "2018-08-30 14:10:10">>/tmp/journallogs.txt
 
 
 journalctl --until "2018-09-02 12:05:50">>/tmp/journallogs.txt


---------------------------------------------------------------------------------------------------------------

Script to collect list of all VMs from all DCs as hosted on esxi host is scheduled on new JumpServer 66.248.236.5

List of all the VMs is collected for each DC every 15 mins in CSV format and saved in "C:\Temp\VMlist_DONOTDELETE\vCenterReport\", here you will find folders for each DC with their respective VCenter IPs and CSV files containing VM names with their respective ESXi host and the VM's power state. 

This data can be used to get the list of VM's hosted on ESXi hosts during MCO's.

----------------------------------------------------------------------------------------------------------------------
crontab -l <user>

throws error 
Why is crontab command failing with error message "You (user) are not allowed to access to (crontab) because of pam configuration." on Red Hat Enterprise Linux 6 

crontab -l or
you also can check entries  here  - /var/spool/cron/postman 

this file will show  u same  entrie with command  - crontab -l -u postman 



run of any cron job is logged in

cat /var/log/cron |grep <Scriptname>

    Crontab command will fail if it is run as user whose password is expired. PAM will not allow to run cronjob as user if the password of that user is expired.

    To check whether password of user is expired or not, run following command:
    Raw

    # chage -l user

    If password is expired, new password will need to be set for the user in order to allow user to run cronjobs.
    To set password for user, run following command as root:
    Raw

    # passwd user

    After this, try to run command crontab -l or crontab -e as user.


Crontab to restart ay service once a day


    Login to your server with SSH
    Type crontab -l to display list of cron jobs,
    Type crontab -e to edit your crontab,
    Add 0 4 * * * /etc/init.d/mysqld restart to restart Mysql everyday at 4 AM,
    Add 0 5 * * * /etc/init.d/httpd restart to restart Apache everyday at 5 AM and
    Add 0 24 * * * /etc/init.d/httpd restart to restart Apache everyday at 12 AM
    Save your file,
    Recheck with crontab -l

every 20 min
*/20 * * * * /home/linuxuser/script.sh

Difference between “>” and “>>” in Linux
“>” and “>>” both are output (STDOUT) direction operators, however, they differ in the following ways.

The “>” Operator
“>” overwrites an already existing file or a new file is created providing the mentioned file name isn’t there in the directory. This means that while making changes in a file you need to overwrite certain any existing data, use the “>” operator.

every 30 min
*/30 * * * * /home/linuxuser/script.sh

# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday;
# │ │ │ │ │                                   7 is also Sunday on some systems)
# │ │ │ │ │
# │ │ │ │ │
# * * * * * <command to execute>
-------------------------------------------------------------------------------------------------------------------------------

processor details

cat /proc/cpuinfo | grep processor | wc -l
or
cat /proc/cpuinfo | grep processor | wc -l
or
grep processor /proc/cpuinfo
or

or
nproc --all

nmon processes take up cpu load
ps -ef |grep -i nmon

[root@MGGGBJPGTSX02 nmon_logs]$ pwd
/opt/nmon/nmon_logs



lscpu gives cpu info

lscpu | grep -E '^Thread|^Core|^Socket|^CPU\('

/proc/cpuinfo, grep processor /proc/cpuinfo | wc -l

load average
/proc/loadavg

-----------------------------------------------------------------------------------------------------

DNS info in resolve.config

cat /etc/dnsmasq.d/dns.conf

[root@AHECQ2SAP01 ibmrmalik]# cat /etc/resolv.conf
#
# This file is generated by Chef
# Do not edit, changes will be overwritten
#
search imzcloud.ibmammsap.local
nameserver 146.89.140.12
nameserver 146.89.140.13
------------------------------------------------------------------------------------------------------

install vnc

 yum install vnc*

----------------------------------------------------------------------------------------------------------
reading logs of gz files

zcat for cat to view compressed file
zgrep for grep to search inside the compressed file
zless for less, zmore for more, to view the file in pages
zdiff for diff to see the difference between two compressed files

The Linux zgrep command works just like the grep command, except it works on text files that have been compressed with the gzip command

cat /abc.gz |zgrep <text to search>

gunzip <gz file name> to unzip it and search for the logs

-------------------------------------------------------------------------------------------------------

Create directory and sub directory in one command

mkdir -p <path to create>

also can use
mkdir -p ~/rpmbuild/{BUILD,RPMS,SPECS,SOURCES,SRPMS}
-----------------------------------------------------------------------------------------------------------

duplicate / false alerts or face any issues with Service Now access/functionality, please bring them to Luis Salas' attention (Slack @lsalas)
https://ec.w3bmix.ibm.com/event.html?id=D96933ABEB1638BE8525830700770238


--------------------------------------------------------------------------------------------------------------------
1-339883841- [Summary: SAP SolMan Sys=WM1_WDC04AMMSOL04,MO=MS3PH103,Alert=Minimum CPU rate (MHz),Desc=A low CPU frequency is often the consequence of a CPU power-save mode. Make sure on OS side that no CPU runs in power-save mode.See SAP Note 1890444 - Slow HANA system due to C Date: 07/15/2018 Severity: Major TicketGroup: ApsSAPTechnical CustomerCode: ms3 InstanceId: WM1_WDC04AMMSOL04:MS3PH103:Minimum CPU rate (MHz) InstanceValue: Minimum CPU rate (MHz):MS3PH103 InstanceSituation: SAP Solman MAI Alert occurred ComponentType: Application Component: SAP SubComponent: Alert ApplId: MYSAP Node: ms3_WDC04AMMSOL04_ms3 NodeAlias: WDC04AMMSOL04 Manager: WDC04AMMSOL04 Agent: EIF Probe on ri3pa010 AlertKey: msd_solminbx_gsa2_msa_prod AlertGroup: ITM_SAP_MAI_ALERTS EventKey: USRD0P0MSDP:4053724:ms3]

- The hostname isn't provideded in the description. SAP team got it from the password file. In this case it is- mdcserverp1
- Login from the regional Chef to this server
- Check the config in the grub by running the command- cat /etc/default/grub | grep GRUB_CMDLINE_LINUX_DEFAULT. 
The values should not contain parameter "intel_idle.max_cstate=1 processor.max_cstate=1"

In this case it was-
mdcserverp1:~ # cat /etc/default/grub | grep GRUB_CMDLINE_LINUX_DEFAULT
GRUB_CMDLINE_LINUX_DEFAULT="ifconfig=bond0 splash=silent quiet showopts resume=/dev/system/swap showopts"

- If clearing event received and the above paramter is not set, then close else ask PDL/SAP team to look further.

------------------------------------------------------------------------------------------------------------------------------------
scp with recursive 

scp -r

rsync can be used for faster copy
https://askubuntu.com/questions/86822/how-can-i-copy-the-contents-of-a-folder-to-another-folder-in-a-different-directo

https://superuser.com/questions/193952/why-is-rsync-avz-faster-than-scp-r

rsync -avz source destination

copy stuff inside trans to trans_local
rsync -avz trans/* trans_local/


folder size du -sh <FS name>
-----------------------------------------------------------------------------------------------------------------------------

CISF mount

CIFS mount ip is not accessiable also not pinging from chef server.
CIFS mount is not mount but showing in mount command.
Tried to access RDP to 146.89.140.21 but couldn't access
Didn't find entry of CIFS mount in /etc/fstab.

For Windows server 2008 shares I can usually get away without it. In more recent versions like Windows Server 2016 it likely needs to be “vers=2.1″ or “vers=3.0″. However, my experience so far is limited to Fedora and a single network, so you might have to tweak the value some more.

iocharset=utf8 allows access to files with names in non-English languages. This doesn't work with shares of devices like the Buffalo Tera Station, or Windows machines that export their shares using ISO8895-15.

If there is any space in the server path, you need to replace it by \040, for example //servername/My\040Documents 

sec=ntlmssp,file_mode=0700,dir_mode=0700,comment=systemd.automount

[root@HKG02AMMCHEF01 ibmsgaur]# mount |grep -i cifs
//146.89.140.21/cms_sap_syb_db on /root/cms_sap_syb_db type cifs (rw)
[root@HKG02AMMCHEF01 ibmsgaur]#

[root@HKG02AMMCHEF01 ibmsgaur]# df -hT /root/cms_sap_syb_db
df: `/root/cms_sap_syb_db': Host is down
df: no file systems processed
[root@HKG02AMMCHEF01 ibmsgaur]#

146.89.140.21 is not pinging from Chef server also not able to do RDP to 146.89.140.21

[root@HKG02AMMCHEF01 ibmsgaur]# ping 146.89.140.21
PING 146.89.140.21 (146.89.140.21) 56(84) bytes of data.
From 100.64.22.65 icmp_seq=1 Destination Host Unreachable
From 100.64.22.65 icmp_seq=2 Destination Host Unreachable
From 100.64.22.65 icmp_seq=3 Destination Host Unreachable
From 100.64.22.65 icmp_seq=4 Destination Host Unreachable
^C
--- 146.89.140.21 ping statistics ---
6 packets transmitted, 0 received, +4 errors, 100% packet loss, time 5218ms
pipe 3
[root@HKG02AMMCHEF01 ibmsgaur]#
[root@HKG02AMMCHEF01 ibmsgaur]# cat /etc/fstab |grep -i cifs
[root@HKG02AMMCHEF01 ibmsgaur]#

[root@HKG02AMMCHEF01 ~]# umount /root/cms_sap_syb_db
You have mail in /var/mail/root
[root@HKG02AMMCHEF01 ~]# df -hT /root/cms_sap_syb_db
Filesystem           Type  Size  Used Avail Use% Mounted on
/dev/mapper/vg00-root
                     ext4   99G   21G   73G  22% /


Fsck order is to tell fsck what order to check the file systems, if set to "0" file system is ignored.

Often a source of confusion, there are only 3 options :

0 == do not check.
1 == check this partition first.
2 == check this partition(s) next
In practice, use "1" for your root partition, / and 2 for the rest. All partitions marked with a "2" are checked in sequence and you do not need to specify an order.

Use "0" to disable checking the file system at boot or for network shares.

You may also "tune" or set the frequency of file checks (default is every 30 mounts) but in general these checks are designed to maintain the integrity of your file system and thus you should strongly consider keeping the default settings.


-----------------------------------------------------------------------------------------------------------------------

ALl stopped services on any server

service --status-all |grep -i stopped


----------------------------------------------------------------------------------------------------------------------------

NTP in Windows

https://docs.microsoft.com/en-us/windows-server/networking/windows-time-service/windows-time-service-tools-and-settings

C:\Windows\system32>w32tm /query /status

w32tm /resync

-----------------------------------------------------------------------------------------------------

Error starting SAP apps post patching

RHEL 6	https://launchpad.support.sap.com/#/notes/2195019

The libstdc++ package that is required is delivered as compat-sap-c++ library.

    It is necessary to have the “Red Hat Enterprise Linux for SAP Solutions” or "Red Hat Enterprise Linux for SAP Business Applications" subscription instead of standard RHEL 6 subscription.
    You can just subscribe the system to the child channel and install the packages. For more information about about RHEL for SAP Applications, see SAP note 1631106, for more information about about RHEL for SAP Solutions see SAP note 2526952.
    Install compat-sap-c++ package (release compat-sap-c++-4.8.2-16.el6 or higher):
    # yum install compat-sap-c++.
    Create a symlink to compat library
    # mkdir /usr/sap/lib
    # ln -s /opt/rh/SAP/lib64/compat-sap-c++.so /usr/sap/lib/libstdc++.so.6
    Changing the file/directory ownership of /usr/sap/lib to sapadm:sapsys or <sid>adm:sapsys user:group is possible (chown command).
    Start SAP installation or update with SAP kernel 748 or higher.

This compat library is an additional library that is installled in parallel to the existing libstdc++.so.6. There is no reboot or restart required.

Technical Background: All SAP applications that need this compat library will use the compat library via the symlink. Other (older) SAP applications still continue to use the standard libstdc++.so.6 library.

Note: The compat-sap-c++-4.7 library (available via “Red Hat Enterprise Linux for SAP Solutions” subscription) also runs the current 748-753 kernels without issueing errors mentioned above. But this may change in future patch levels or in SAP kernel versions > 753. It is recommended to install compat-sap-c++-4.8.2-16.el6 or higher.

 

ln -s [/path/to/file] [/path/to/symlink]

/usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.15'  
Install compat-sap-c++ package (release compat-sap-c++-4.8.2-16.el6 or higher):
# yum install compat-sap-c++.
3. Create a symlink to compat library
# mkdir /usr/sap/lib
# ln -s /opt/rh/SAP/lib64/compat-sap-c++.so /usr/sap/lib/libstdc++.so.6
/usr/lib64/libstdc++.so.6

strings /usr/lib/libstdc++.so.6 | grep GLIBC
/sbin/ldconfig -p | grep stdc++

libstdc++ as "libstdc++33

rpm -V compat-sap-c++-4.8.2-16.el6 (Make Sure compat-sap-c++ OR the compat-sap-c++5 is installed)
Verify Symlink ls -l /usr/lib/libstdc++.so.6


  502  2020-04-09 15:02:53 yum install compat-sap-c++
  503  2020-04-09 15:03:25 mkdir /usr/sap/lib
  504  2020-04-09 15:03:33 cd /usr/sap/lib
  505  2020-04-09 15:03:40 ls -ltrh |grep -i libstdc
  506  2020-04-09 15:03:51 															
  507  2020-04-09 15:03:54 ls -ltrh |grep -i libstdc
  508  2020-04-09 15:04:00 cd /usr/lib64
  509  2020-04-09 15:04:04 ls -ltrh |grep -i libstdc
  510  2020-04-09 15:04:14 rm libstdc++.so.6
  511  2020-04-09 15:04:40 ln -s /opt/rh/SAP/lib64/compat-sap-c++.so /usr/lib64/libstdc++.so.6
  512  2020-04-09 15:04:46 ls -ltrh |grep -i libstdc

/usr/lib
/usr/lib64
/usr/sap/lib

[root@svad1srv0 SAP]$ ldconfig -p | grep libstdc
        libstdc++.so.6 (libc6,x86-64) => /usr/lib64/libstdc++.so.6
        libstdc++.so.6 (libc6) => /usr/lib/libstdc++.so.6
        libstdc++.so.5 (libc6,x86-64) => /usr/lib64/libstdc++.so.5
        libstdc++.so.5 (libc6) => /usr/lib/libstdc++.so.5


libstdc++33-3.3.3-12.15.x86_64
libstdc++6-9.2.1+r275327-1.3.9.x86_64

Path for log4j scanner
https://kyndryl.ent.box.com/s/jcn4h0cfrmmwlup7pwi8fr2k0g4fbjj5
./log4j2-scan: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by ./log4j2-scan)
525  mkdir ~/glibc214
  526  cd ~/glibc214
  527  wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz
  528  cd /tmp
  529  ls -ltr
  530  tar zxvf glibc-2.14.tar.gz
  531  cd glibc-2.14
  532  mkdir build
  533  cd build
  534  ../configure --prefix=/opt/glibc-2.14
  535  make -j4
  537  make install
  538  export LD_LIBRARY_PATH=/opt/glibc-2.14/lib
  539  cd /tmp
  540  ./log4j2-scan --exclude /sds /


in SUSE
zypper search libstdc++
zypper install libstdc++33
zypper up libstdc++6

[root@agesvepmhsrv1 ibmrmalik]$ find /usr/lib* -name libstdc++*
/usr/lib/vmware-tools/lib64/libstdc++.so.6
/usr/lib/vmware-tools/lib64/libstdc++.so.6/libstdc++.so.6
/usr/lib/vmware-tools/lib32/libstdc++.so.6
/usr/lib/vmware-tools/lib32/libstdc++.so.6/libstdc++.so.6
/usr/lib/libstdc++.so.6
/usr/lib/libstdc++.so.6.0.25
/usr/lib64/gcc/x86_64-suse-linux/4.8/32/libstdc++.a
/usr/lib64/gcc/x86_64-suse-linux/4.8/32/libstdc++.so
/usr/lib64/gcc/x86_64-suse-linux/4.8/libstdc++.a
/usr/lib64/gcc/x86_64-suse-linux/4.8/libstdc++.so
/usr/lib64/libstdc++.so.5
/usr/lib64/libstdc++.so.5.0.7
/usr/lib64/libstdc++.so.6
/usr/lib64/libstdc++.so.6.0.28


tsls4proddbdr:/home/ibmhjayadevappa #  rpm -q libgcc_s1 libstdc++6 libatomic1
libgcc_s1-9.3.1+git1296-1.7.2.x86_64
libstdc++6-9.3.1+git1296-1.7.2.x86_64
libatomic1-8.2.1+r264010-1.3.3.x86_64



SAP credentials notes
S0020228589	ibm@4321


S0015210101	TQ43HJS%

S0023093221
SAPibm#1

Changing the file/directory ownership of /usr/sap/lib to sapadm:sapsys or <sid>adm:sapsys user:group
is possible (chown command).

rm and unlink commands to remove symbolic link
Symbolic links can be removed with two commands: rm and unlink. You can use any one of the following commands to remove symbolic links.

rm: is the terminal command to remove each given file including symbolic links. Because a symbolic link is considered as a file on Linux, you can delete it with the rm command.
# rm linkfile
unlink: deletes a single specified file name including symbolic links.
# unlink linkfile

-----------------------------------------------------------------------------------------------------------

disk space issue

old deleted file handles

lsof | grep delete

--------------------------------------------------------------------------------------------------------

validating fstab entries


backup failing
mount -o rw,remount <path of the FS> <local mount point>

mount -o rw,remount /


ls: cannot access '.gvfs': Transport endpoint is not connected
run "fusermount -u ~/.gvfs"
check for any RO FS and fix

----------------------------------------------------------------------------------------------------------------

How to check the listening ports and applications on Linux:
Open a terminal application i.e. shell prompt.
Run any one of the following command: sudo lsof -i -P -n | grep LISTEN. sudo netstat -tulpn | grep LISTEN. sudo nmap -sTU -O IP-address-Here

Use the following commands corresponding to your OS to find the PID of the process that is already listening on the port:

Windows: netstat -aon | findstr <port number>
Linux:
      netstat -nap | grep <port number>
      ss -ntlp | grep <port number>
Linux/Unix: lsof -n -P -i :<port number>  or port range 

 ss -ltw | egrep "443|https"

[root@conspeccdbpdr ibmrmalik1]# lsof -n -P -i :40000-40099
COMMAND     PID   USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME
hdbnamese 46109 ecpadm   34u  IPv4  832221      0t0  TCP 127.0.0.1:40002 (LISTEN)
hdbnamese 46109 ecpadm   35u  IPv4  832222      0t0  TCP 10.139.0.15:40002 (LISTEN)
hdbnamese 46109 ecpadm   36u  IPv4  832223      0t0  TCP 10.76.0.15:40002 (LISTEN)
hdbnamese 46109 ecpadm   37u  IPv4  832224      0t0  TCP 10.65.223.237:40002 (LISTEN)
hdbnamese 46109 ecpadm   39u  IPv4  858013      0t0  TCP 10.76.0.15:40002->10.80.1.99:64292 (ESTABLISHED)
hdbnamese 46109 ecpadm   40u  IPv4  832241      0t0  TCP 10.76.0.15:59066->10.80.1.99:40002 (ESTABLISHED)
hdbnamese 46109 ecpadm   45u  IPv4  822564      0t0  TCP 10.76.0.15:60778->10.80.1.99:40001 (ESTABLISHED)
hdbnamese 46109 ecpadm   51u  IPv4  975789      0t0  TCP 10.76.0.15:40002->10.80.1.99:54738 (ESTABLISHED)
hdbnamese 46109 ecpadm   52u  IPv4  758448      0t0  TCP 10.76.0.15:60780->10.80.1.99:40001 (ESTABLISHED)
hdbnamese 46109 ecpadm   79u  IPv4 1039600      0t0  TCP 10.76.0.15:40002->10.80.1.99:55752 (ESTABLISHED)
hdbindexs 46580 ecpadm   34u  IPv4 1052723      0t0  TCP 10.76.0.15:63814->10.80.1.99:40040 (ESTABLISHED)



Packet drop
netstat -s


Check which shell u are in
echo $0
-----------------------------------------------------------------------------------------------------------------------
SQUADIFY 
http://rchgsa.ibm.com/projects/c/clientcloudsolutions/public/Squadify/Squad.html
above URL is for complete information for DPE / PDL as per customer


_-------------------------------------------------------------------------------------------------------------

Edward Coffman or Michael Borowiec   manage patching servers
-----------------------------------------------------------------------------------------------------------------
root pw expired imz not working

login to any server with local sapadm account 

[sapadm@brspsol041amm ~]$ su - root
Password:
You are required to change your password immediately (password aged)
Changing password for root.
(current) UNIX password:
New password:
BAD PASSWORD: The password is the same as the old one
New password:
Retype new password:
Last login: Wed Jan  9 11:08:34 -02 2019 from 146.89.143.22 on pts/0
[root@brspsol041amm ~]# passwd root
Changing password for user root.
New password:
Retype new password:
passwd: all authentication tokens updated successfully.


-------------------------------------------------------------------------------------------------------
Total memory

cat /proc/meminfo |grep -i MemTotal
free -hg
----------------------------------------------------------------------------------------------------------
Pacemaker cluster task

https://clusterlabs.org/pacemaker/doc/en-US/Pacemaker/1.1/html-single/Pacemaker_Explained/index.html

https://github.kyndryl.net/CMS/SAP_HANA_PDR/tree/development/MSAP-30_HANA_HA_Deployment/docs/Operations_Guide 

HANA operations guide
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/README.md

systemctl stop pacemaker     

To remove  cluster  from  maintenance  mode  do  ==> crm configure property maintenance-mode=false  

To start pacemaker cluster  ===> systemctl  start pacemaker     

And to add put crm configure property maintenance-mode=true 

crm configure show | grep maintenance-mode

OS patching Procedure for Pacemaker Cluster

SOP if DRBD is status is not uptodate.

 drbdadm status

https://github.kyndryl.net/CMS/SAP-Base/blob/master/CMAS%203x/SOPs/How%20to%20bring%20up%20DRBD%20resource%20going%20into%20standalone%20mode%20on%20standby%20node%20of%20cluster.md


Execute below command to stop ERS process on standby node
crm resource stop <grp_rsc_ers>

Execute below command to stop other resources on Standby node.
crm node standby node2

Stop and Start for Pacemaker cluster
https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/Start%20and%20Stop%20Procedure%20for%20pacemaker.md



https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/SAP_Application_%20Cluster_OS_Patching_Procedure.md

https://www.golinuxcloud.com/cleanup-failed-actions-pcs-status-cluster/    Linux pacemaker cluster
pcs status
pcs resource cleanup

https://www.unixarena.com/2016/01/rhel-7-pacemaker-cluster-node-management.html/
pcs property set maintenance-mode=true

4.4.5. Standby Mode
The following command puts the specified node into standby mode. The specified node is no longer able to host resources. Any resources currently active on the node will be moved to another node. If you specify the --all, this command puts all nodes into standby mode.

To set a node in standby mode:

pcs cluster standby <node>
maintenance-mode is for the whole cluster. Setting the cluster in maintenance mode will make the cluster not attempt to manage services anymore for whatever reason: the administrator of the cluster can now do actions without having the cluster interfering in any way.

4.8. Cluster Maintenance
In order to perform maintenance on the nodes of your cluster, you may need to stop or move the resources and services running on that cluster. Or you may need to stop the cluster software while leaving the services untouched. Pacemaker provides a variety of methods for performing system maintenance.
[...]
If you need to put the cluster in a state where no services will be started or stopped, you can set the maintenance-mode cluster property. Putting the cluster into maintenance mode automatically unmanages all resources.

------------------------------------------------------------------------
Tell the cluster to stop managing services. This is required to allow the services to remain active after the cluster shuts down.

# crm_attribute --name maintenance-mode --update true

 Allow the cluster to resume managing resources again:

# crm_attribute --name maintenance-mode --delete 
------------------------------------------------------------------------
ON servers with Pacemaker cluster after the apps are down, run the below to stop the resources

Stop cluster gracefully on both nodes (stopping all resources) -> /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --stop-pacemaker-both-gracefull

After patching, reboot the server and run the below to start the pacemaker and other resources

Start cluster along with resources  -> /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --start-pacemaker-both-maintenanceoff

Alternatively
 Start cluster along with resources  -> each node one at a time
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --start-pacemaker-currentnode-maintenanceoff
once all resource started (wait for 2 min )
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt/SapDbRecovery.sh -M --start-pacemaker-othernode-maintenanceoff


to failover the cluster non HANA
root user se from the server jispe se resource move karne hain

/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt
./SapDbRecovery.sh  -M --failover-scs-currentnode

saprecovery script
usme manage node mein sare option hain


1. Stop PAS/AAS
2. Stop cluster gracefully on both nodes (stopping all resources)
3. Patch both nodes
4. Start cluster along with resources
5. Start PAS/AAS


1. Once the activity completed - start the cluster service and move the cluster to manage state 2. change from standby to online 3. reregister from tsls4proddb to tsls4proddbh 4. Clear the failed count 5. Wait for sync to be complete and check the cluster status15

“crm node standby <nodename>” command, all resources on that node will moved to the
second node. Use “crm node online <nodename>” to bring the node back online. This is the suggested way to do a
failover test

Planned Cluster failover from Primary Node to Secondary Node
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/03a_Planned_Failover.md

Failover db form one node to other
Make primary as standby
STop pacemaker on the node that is primary(all resources move to secondary)
chk crm_mon -1Afr and see if the secondary has now become primary
Start pacemaker on the same node where it was stopped(now secondary)
register the new node
su - <SID>adm -c "hdbnsutil -sr_register --remoteHost=<PRIMARY_hostname> --remoteInstance=<instance_number> --replicationMode=sync --operationMode=logreplay --name=<SECONDARY_name>"

sid can be fetched from the banner at the login screen or ask SAP and the instance no can be fetched by logging into the node and su - sidadm
[root@tgyerpprddb1 ~]# su - pe1adm
pe1adm@tgyerpprddb1:/usr/sap/PE1/HDB00>
the number after HDB above is the instance no 00 in this example

check replication status with
python systemReplicationStatus.py
psaadm@br3psoldb40:/usr/sap/PSA/HDB84> cdpy; python systemReplicationStatus.py

for failback its viceversa

Failback
make 40(current primary) as standby, that will make all resources to 41(current secondary) and this will become promoted.
then re-register 40(former primary as secondary) as new secondary
clear failed actions if any
make the standby node online 

refer 
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/03a_Planned_Failover.md




about pacemaker
https://www.freenetst.it/tech/rh7cluster/

Validation script
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py

/usr/bin/python3.6 /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py


Sreejesh
Latest pacemaker validation script : /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation-3.1.5.tar 

Operation : Copy file to both node same location 
#cd /tmp
#cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation-3.x.x.tar /tmp 
move if any old version (Directory pacemaker_validation) 

Extract the tar file
#tar -xvf pacemaker_validation-3.x.x.tar
#cd pacemaker_validation

run the script from primary node
#./cluster_validation.py 
Results available on this path : /var/log/cluster_report/Fix :

DRBD error in validation script can be fixed with below:
https://github.kyndryl.net/CMS/BuildMigration/wiki/Pacemaker-validation-fix





For HANA
cd /opt/ibm/HDBHA/Operations/hanaconfigvalidation
HDBHA_HanaPostBuildValidation.sh


Validation script latest build 
https://github.kyndryl.net/CMS/BuildMigration/blob/master/Archive/pacemaker_validation-2.7.tar

[root@armfksap305d1 pacemaker_validation]$ pwd
/root/pacemaker_validation
[root@armfksap305d1 pacemaker_validation]$ 

fencing error
grep "Unable to connect/login to fencing device" /var/log/cluster/corosync.log

if above has error connecting then its a Infra issue for the service id vsphere.local\crmstnmgr

corosync logs 
"[CFG ] Config reload requested by"  
Above message means that the corosync configuration was manually reloaded, this is the usual operation after someone changes the configuration and wants to apply them.

egrep -i 'error|fail|warn|fatal|fence|timeout|time-out' corosync.log | grep -v "+++ OCF_FAILED_MASTER" | grep -v check_initrd_warning

grep -i "vol_prdersvg" corosync.log  also grep with Time or Timeout




check the content of the /var/lib/pacemaker/cib/ directory, only cib and cib-raw files should be in there, if you see any other file then must be deleted.
To be 100% sure, stop pacemaker on one node, then delete everything inside /var/lib/pacemaker/cib/, then start pacemaker again, this will trigger the sync of a clean cib file. Then do the same on the other node.

The nfs server: not responding messages typically mean a network related issue.  check for keywords like TOTEM, stonith, or fencing related messages in /var/log/messages

[TOTEM ] A processor failed, forming new configuration.
and what it exaclty means ...
It means that a node was declared lost and was removed from the cluster.
This happens either because the node stopped responding or it's network
connection that openais or corosync was using failed and it was not able
to talk to the other node(s) anymore.


 ipmitool sel elist -run for further logs might be relevant for HANA servers 

to see the configuration -
[root@pn4ushleccp1c ibmrmalik]$ crm configure show |grep vsphere.local
        params ipaddr=146.89.142.40 login="vsphere.local\crmstnmgr" ipport=443 ssl=1 ssl_insecure=1 passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60 \
        params ipaddr=146.89.142.40 login="vsphere.local\crmstnmgr" ipport=443 ssl=1 ssl_insecure=1 passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60 \


To check the connectivity
fence_vmware_soap --ssl-insecure -l "vsphere.local\crmstnmgr" -p '<passwd>' -a <vcenterip> -o list 

to get the pw for above
/usr/local/sbin/getpass.py -g crmstnmgr


crm_mon -1Afr
crm resource cleanup mountfs-inter
crm resource cleanup <error component found in the error in above command>

crm resource cleanup vcenter-fencing-bumsaps4p01p

Failed Fencing Actions:
* reboot of br3qscmdb37 failed: delegate=, client=crmd.3633, origin=br3qscmdb36,
    last-failed='Fri Nov 20 16:20:52 2020'
    
    stonith_admin --cleanup --history=br3qscmdb37   cleans up the above error in SuSE 

eg for the error below:

Failed Actions:
* vcenter-fencing-bumsappop01p_monitor_600000 on bumsappop02p 'unknown error' (1): call=392, status=Error, exitreason='',
    last-rc-change='Fri Oct  4 03:21:07 2019', queued=0ms, exec=5825ms

1019  2020-09-02 21:59:42 cat /etc/sysconfig/sbd | grep DEVICE
 1020  2020-09-02 22:00:28 sbd -d /dev/mapper/sbddisk1 message br3qgtsdb36 clear
 1021  2020-09-02 22:00:54 crm resource clear rsc_stonith-sbd
 1022  2020-09-02 22:01:08 crm resource cleanup rsc_stonith-sbd_monitor_15000
 1023  2020-09-02 22:01:15 crm resource cleanup rsc_stonith-sbd_monitor
 1024  2020-09-02 22:01:23 crm resource cleanup rsc_stonith-sbd
 1025  2020-09-02 22:01:45 crm_mon -1Afr
 
 
 
 Normal VM
  cat /etc/sysconfig/sbd | grep DEVICE
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
#SBD_DEVICE=""
SBD_DEVICE=/dev/mapper/sbddisk1

[root@ia1sp1db-ha ~]# sbd -d /dev/mapper/sbddisk1 list
0       ia1sp1db        clear
1       ia1sp1db-ha     reset   ia1sp1db

To cleanup sbd in Azure
 

SBD clear in Azure  https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/2.%20Azure/SOPs/Starting%20pacemaker%20on%20Azure%20Suse%20Nodes.md
Check the sbd disk details with

cat /etc/sysconfig/sbd | grep DEVICE
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
SBD_DEVICE="/dev/disk/by-id/scsi-3600140524afc78bfc674e70b6e80c6a0;/dev/disk/by-id/scsi-36001405336563ab664f4d1e9582d3c8e;/dev/disk/by-id/scsi-360014054d2d91a1ab364c9f9fdc4a350;"
[root@vhsmpcs1 ~]# uptime
 20:41pm  up 5 days  7:46,  1 user,  load average: 0.05, 0.26, 0.34
 Cleanup with the below, run from primary node and clear each sbd disk
 
[root@vhsmpcs1 ~]# sbd -d /dev/disk/by-id/scsi-3600140524afc78bfc674e70b6e80c6a0 message vhsmpcs2 clear
[root@vhsmpcs1 ~]# sbd -d /dev/disk/by-id/scsi-3600140524afc78bfc674e70b6e80c6a0 list
0       vhsmpcs1        clear
1       vhsmpcs2        clear   vhsmpcs1
[root@vhsmpcs1 ~]# sbd -d /dev/disk/by-id/scsi-36001405336563ab664f4d1e9582d3c8e list
0       vhsmpcs1        clear
1       vhsmpcs2        reset   vhsmpcs1


If sbd 3 disks not showing

iscsiadm -m discovery --type=st --portal=10.136.65.6:3260
iscsiadm -m node -T iqn.2006-04.nhshrd-1.local:nhshrd-1 --login --portal=10.136.65.6:3260
iscsiadm -m node -p 10.136.65.6:3260 --op=update --name=node.startup --value=automatic

[root@vhsjpcs2 log]# systemctl start pacemaker
A dependency job for pacemaker.service failed. See 'journalctl -xe' for details.
[root@vhsjpcs2 log]# cat /etc/sysconfig/sbd | grep DEVICE
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
SBD_DEVICE="/dev/disk/by-id/scsi-360014057e1e3a0128ce4b37b79e6c466;/dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00;/dev/disk/by-id/scsi-3600140594852f6a277648f49ff5000c1;"
[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-360014057e1e3a0128ce4b37b79e6c466 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1
[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1
sbd -d == Slots on disk /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 NOT dumped
sbd failed; please check the logs.
[root@vhsjpcs2 log]# sbd -d /dev/disk/by-id/scsi-3600140594852f6a277648f49ff5000c1 list
0       vhsjpcs1        clear
1       vhsjpcs2        reset   vhsjpcs1

run from the node that got rebooted and pacemaker not starting

[root@vhsjpcs2 send_targets]# sbd -d /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 message vhsjpcs2 clear
sbd failed; please check the logs.
[root@vhsjpcs2 send_targets]# sbd -d /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 message vhsjpcs2 clear
[root@vhsjpcs2 send_targets]# sbd -d /dev/disk/by-id/scsi-36001405670cdbc2d5684cdbaa5527a00 message  LOCAL clear


iscsi and iscsid services restart for sbd disk scanning are imp
Enable iscsi service

#systemctl enable iscsi
☞ Enable iscsid service

#systemctl enable iscsid.service

When a primary pacemaker node rebooted, sometimes pacemaker service does not start due to dependency failure, we need to clear the sbd disk message. During our last outage, seems there was a delay to start the cluster due to this.
#sbd -d /dev/mapper/sbddisk1 message torhdbsrv01 clear --------------------> (Mention the rebooted node name)  run from primary(running node)
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/9233786d3[…]2/.history/Operations_Guide/09_Cheatsheet_20181219144743.md
This covers about the clearing of sbd message - under section "After Primary (NODEA) was fenced"

https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/2.%20Azure/SOPs/Starting%20pacemaker%20on%20Azure%20Suse%20Nodes.md

https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/develop_robin_Baremetal/Operations_Guide/17_Azure_iSCSI_SBD_Operation.md

iscsi and iscsid services restart for sbd disk scanning are imp

checking sbd devices using the "sbd list" command

documentation for ISCSI configuration (https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Deployment_Guide/06_iSCSI_Multipath_configuration.md ) 

cd /etc/iscsi/
[root@ps2-s4p-db iscsi]# cat iscsid.conf | grep -v "#" | grep "startup"
node.startup = manual
[root@ps2-s4p-db-ha iscsi]# cat iscsid.conf | grep -v "#" | grep "startup"
node.startup = automatic


cleanup by using 
crm resource cleanup vcenter-fencing-bumsappop01p

Cleanup of Failed fencing action
Failed Fencing Actions:
* reboot of zffpdb002 failed: delegate=, client=crmd.23135, origin=zffpdb002-ha,
    last-failed='Sat Jun  5 14:13:27 2021'

stonith_admin --cleanup --history=br3qscmdb37   cleans up the above error in SuSE 


Vmware fencing error
I just copied the VCneter script again to both the server.
cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/fence_vmware_rest /usr/sbin/fence_vmware_rest
and cleaned the resources


cat /etc/sysconfig/sbd | grep DEVICE
sbd -d /dev/mapper/sbddisk1 message br3qgtsdb36 clear
crm resource clear rsc_stonith-sbd
crm resource cleanup rsc_stonith-sbd

HANA cluster slack
squad: sq-sap-enable-hana-rr

/var/log/messages|grep -i SAPHanaSR-mon

[root@hfchbphndb1vh ~]# sbd -d "/dev/mapper/sbddisk1" message list
sbd failed; please check the logs.
 
 [root@hfchbphndb1vh ~]# sbd -d "/dev/mapper/sbddisk1" list
0       hfchbphndb1v    clear
1       hfchbphndb1vh   clear



Non HANA cluster
Webex Recording: https://ibm.webex.com/recordingservice/sites/ibm/recording/playback/004c39f261954684aa7ac3f400bf3edd
Recording password: wJ3nux6C

https://ibm.webex.com/recordingservice/sites/ibm/recording/playback/a11a1c1170e049da9a34ed0570d760de (password: 6qPrmReN)
Slides from the presentation are at https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/SAP_HANA_HA_VMWARE_v20181210.pdf

HANA operations guide
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/README.md


Pacemaker logs
messages file and /var/log/cluster/corosync.log
pacemaker.log	/var/log/pacemaker.log
keywords like Pingack did not arrive in time   possible reason for timeout and cluster failover

https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/A_Linux_node_in_HA_Cluster_was_fenced_after_%22A_processor_failed%2C_forming_new_configuration%22_event
for fencing issue RCA ref

alternatively check
 /usr/local/ncpa/var/log/protocolfiles/
 to see the error details
 
 
there is pacemaker validation script in SDS which will show all the deviations  

/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation  

run_pacemaker_validation.py


/usr/bin/python3.6 /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py

Pacemaker cluster
 https://github.kyndryl.net/CMS/SAP-Base/wiki/SAP-Cluster-(Non-HANA)---Troubleshooting-Guide
 
 Slack for pacemaker issue
 #cms-suse-cluster
 
Pacemaker cluster script 

[root@pn8us7leccp3h pacemaker_mgmt]$ pwd
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_mgmt

[root@pn8us7leccp3h pacemaker_mgmt]$ ls -ltr
total 416
-rwxr-xr-x 1 saprouter saprouter   1050 Nov 26  2019 README.md
-rwxr-xr-x 1 saprouter saprouter 102203 Dec 10  2019 Document_DatabaseRecovery.md
-rwxr-xr-x 1 saprouter saprouter  86954 Dec 10  2019 Document_SapRecovery.md
-rwxr-xr-x 1 saprouter saprouter  24113 Dec 10  2019 AutomationLibrary.sh
-rwxr-xr-x 1 saprouter saprouter  85081 Dec 10  2019 DatabaseRecovery.sh
-rwxr-xr-x 1 saprouter saprouter  92405 Dec 10  2019 SapRecovery.sh	- use this with manage resource option on non db servers
-rwxr-xr-x 1 saprouter saprouter  22484 Dec 11  2019 SapDbRecovery.sh	use this with manage resource options on DB servers
 

HANA DB
Adam Zboril https://github.ibm.com/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/README.md
validation script here



7:36 PM
@sybille.kurz can help with it if any troubles
 
Check if SAP is running
ps -ef |grep dw   iu see no output means sap is stopped


SLES 12 SP2 Upgrade using Rolling Upgrade -> https://github.ibm.com/CMS/SAP-Base-
RR/blob/master/CMAS%203x/SOPs/SAP_Application_%20Cluster_OS_Patching_Procedure.md

SLES 12 SP2 to SP4 migration -> https://github.ibm.com/CMS/SAP-Base-
RR/blob/master/CMAS%203x/SOPs/PACEMAKER_CLUSTER_SP2_SP4_MIGRATION_STEPS.md


Resource migration
Use “crm resource migrate <resource_name> <node_name>” to migrate one resource to another node. Please note that there will be a
location constraint created. This might cause resource to failover during a restart OR another event. To remove that
location constraint, always make sure, the crm resource migrate command is followed by a “crm resource
unmigrate <resource_name>” command
• If you use command “crm node standby <nodename>” command, all resources on that node will moved to the
second node. Use “crm node online <nodename>” to bring the node back online. This is the suggested way to do a
failover test


/var/log/messages
/var/log/cluster/corosync.log
Journalctrl logs


How to extend file system managed by the cluster (Hana and Non-Hana)

https://github.ibm.com/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/Filesystem_extension_steps.md




In this case, the following message can be found in the logging data:
Split-Brain detected, dropping connection!
To resolve this situation, enter the following commands on the node which has data to be discarded:
drbdadm secondary r0
If the state is in WFconnection, disconnect first:
drbdadm disconnect r0
On the node which has the latest data enter the following:
drbdadm connect --discard-my-data r0

----------------------------------------------------------------------------------------------------
LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp.
 
Find the 'parent' entry in the /usr/local/ncpa/etc/ncpa.cfg file and connect to that server with wget or curl from the command line:

          wget --no-check-certificate   https://{nagios-passive-server-name-or-ip}/nrdp/

this will show you whether VM are able to connect agent server or not    
https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/MHAS%20Nagios/page/Linux%20Troubleshooting


Windows NSClient++ Servers
 
Login to the server and bring up the Services.msc window.
 
Make sure that the service is running:

    NSClient++

If it is not running, start it up and make sure it is set to 'Automatic' start.

If the service running, restart it.  Monitor the log file at c:\program files\nsclient++\nsclient.log for 10-15 minutes to make sure it is updating.  It will take about 10 minutes after restarting the service for the log file to show any new activity.

The NSClient++ process is 'nscp'.

Test connectivity Back to the Nagios XI server

On Linux or Windows, open a command prompt and execute the appropriate command to verify routes are in place for the 158.87.44.x and the 158.87.46.x networks:

WINDOWS

Find the 'address' entry in the c:\program files\nsclient++\nsclient.ini file and connect to that server with a browser:

         https://{nagios-passive-server-name-or-ip}/nrdp/
You should see a form for submitting Nagios check results. 
If you update the address, stop and restart the service to have the configuration change read in.

Check For Persistent Static Routes

On Linux or Windows, open a command prompt and execute the appropriate command to verify routes are in place for the 158.87.44.x and the 158.87.46.x networks:

WINDOWS

    netstat -rn|findstr 158.87.4

-------------------------------------------------------------------------------------------

Pacemaker service not starting
To find Device name
cat /etc/sysconfig/sbd | grep DEVICE

[root@br3qgtsdb36 ibmsgaur]$ cat /etc/sysconfig/sbd | grep DEVICE
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
SBD_DEVICE="/dev/mapper/sbddisk1"
[root@br3qgtsdb36 ibmsgaur]$

command to clear message  should be executed on service down node 
sbd -d /dev/mapper/sbddisk1 message br3qgtsdb37 clear


Then start pacemaker service


pacemaker error logs keywords
 
DB2(rsc_db2_cp4)[26506]:        2020/02/15_00:29:19 ERROR: 02/15/2020 00:29:19     0   0   SQL8000N  DB2START processing failed; a valid product license was not found. If you have licensed this product, ensure the license key is properly registered. You can register the license using the db2licm command. The license key can be obtained from your licensed product CD.
SQL1032N  No start database manager command was issued.  SQLSTATE=57019


PingAck did not arrive in time.

-----------------------------------------------------------------------
pacemaker node out of sync issue

chat with Nithya dated 28 Dec 19 and 8th Jan


NOn HANA cluster: Chandru, Dileep, Nithyanand
HANA Sairam Gadugoyyala, 


----------------------------------------------------------------------------------------------------------------
gvfs readonly issue

agesveqmhsrv1:/usr/sap/EQM/home # ls -ltr |grep -i .gvfs
ls: cannot access '.gvfs': Permission denied
d????????? ? ?      ?          ?            ? .gvfs 

umount /path/to/.gvfs
then test the permissions for .gvfs

--------------------------------------------------------------------------------
https://www.thegeekdiary.com/centos-rhel-how-to-collect-sosreport/
yum install sos
sosreport

TO share with RHEL

Equivalent in SuSE is supportconfig
supportconfig -ur


for BTRFS file system in SUSE use below for collecting supportconfig

mkdir -p /run/supportconfig/tmp
env TMPDIR=/run/supportconfig/tmp supportconfig -R /run/supportconfig/tmp -i DISK,BTRFS,BOOT



--------------------------------------------------------------------------------------
Physical infra bluemix slack
#cms-sq-phys-blx


Slack channel
cmas-sq-sap-pb-alerts for build
cms-sq-sap-proj-team  for projects

https://github.ibm.com/CMS/PhysInfra-Tribe-Tracker/issues
physical infra team work on Git issues	


-----------------------------------------------------------------------------------------

To disable cron to run on any system for some time, stop the crond service

--------------------------------------------------------------------------------------------
compare 2 files

sdiff bkp-route-eth2 route-eth2 

------------------------------------------------------------------------------------------------------

Hello team,
We are discontinuing the root user for access to the chef servers. Please use the "cmschefadmin" user instead. Your pub ssh keys should have been moved over, but if you have problems with access, please open a github issue to the Chef squad.

----------------------------------------------------------------------------------------------------------
display hidden files

ls -ltar
--------------------------------------------------------------------------------------------------------------

Requesting CIC for sev1
CIC/CIM - ##trm-sev1-hub  and #cicl

SNOW queue for Infra SQ-BLUEMIX-INFRA


On duty dev1 dpe
#cmas-dpe-onduty-sev1

for SAPHEC
https://gts-cmas.slack.com/messages/CCBBMFELE  #cmas-saphec-dpe
-------------------------------------------------------------------------------------------------------------

vHANA inventory


---------------------------------------------------------------------------------------------------------------

Q] Unable to  login server with  IMZ id and  getting below  error  message  in messages logs - 

Feb  4 16:57:47 TQAERPDEVH sssd[be[imzcloud.ibmammsap.local]]: GSSAPI Error: Unspecified GSS failure.  Minor code may provide more information (Server not found in Kerberos database)
Feb  4 16:57:47 TQAERPDEVH sssd[be[imzcloud.ibmammsap.local]]: GSSAPI Error: Unspecified GSS failure.  Minor code may provide more information (Server not found in Kerberos database)

Solution >>
1> # vi /etc/krb5.conf
Add  below  line  under  [libdefaults]
rdns  = false

--------------------------------------------------------------------------------------------------------------

cat /etc/group will list all user groups in the system

The syntax is as follows to find out if user exists in system:

getent passwd userNameHere
or
grep username /etc/passwd


The syntax is as follows to find out if group exists in system:

getent group groupNameHere


To add an existing user account to a group on your system, use the usermod command, replacing examplegroup with the name of the group you want to add the user to andexampleusername  with the name of the user you want to add.

usermod -a -G examplegroup exampleusername


------------------------------------------------------------------------------------------------

Bigfix on the below ip
169.60.136.233

https://github.kyndryl.net/CMS/cms-chef/wiki/BigFix-(bescient)-with-Chef-on-Linux-troubleshooting
https://github.kyndryl.net/CMS/cms-chef/wiki/BigFix-with-Chef-on-Windows-Troubleshooting


-----------------------------------------------------------------------------------------------------

SIngle user mode

kernel /vmlinuz-2.6.32-754.6.3.el6.x86_64 ro root=/dev/mapper/rootvg-rootlv rd_NO_LUKS rd_LVM_LV=rootvg/rootlv LANG=en_US.UTF-8 console=tty0 console=ttyS0,115200n8 elevator=deadline rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto rd_LVM_LV=rootvg/paging00  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet


rd.break in the end of teh kernel line

kernel /vmlinuz-2.6.32-754.6.3.el6.x86_64 ro root=/dev/mapper/rootvg-rootlv rd_NO_LUKS rd_LVM_LV=rootvg/rootlv    

remove other parameters just add single to this at the   

kernel /vmlinuz-2.6.32-754.6.3.el6.x86_64 ro root=/dev/mapper/rootvg-rootlv rd_NO_LUKS rd_LVM_LV=rootvg/rootlv   single

HANA access issue after reboot
vmxnet
fix  comment  one and only  line  in /etc.modprobe.d/vmxnet.conf


Linux SIngle user mode  https://www.thegeekdiary.com/centos-rhel-6-how-to-boot-into-single-user-mode/

SUSE Single user mode:

after getting into the kernel edit window, add init=/bin/bash and ctrl+x to move and get into single user mode.

The above line is to be added at the end of the linux /vmlinuz line

https://kerneltalks.com/howto/how-to-enter-single-user-mode-in-suse-12-linux/


press "e"  

and edit the grub  

change  ro to rw  

delete rhgb quiet  

add init=/bin/bash in last  


How To Boot into Single-User Mode in CentOS 8 / RHEL 8
To go into single-user mode, select the kernel and press e edit arguments of the kernel.
Go to the line that starts with linux using up and down arrow then delete the ro argument.
Add this rw init=/sysroot/bin/sh in the line.
---------------------------------------------------------------------------------------------------

All customers  hana servers  are  listed here  - --->  https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W1685fd698977_41e3_a38f_5c601e92ea41/page/3.X Deployment Updates (https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/W1685fd698977_41e3_a38f_5c601e92ea41/page/3.X Deployment Updates)


Our Wiki
here is our wiki link : https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W72605561971c_4c30_a312_e7f148a59f16 (https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/W72605561971c_4c30_a312_e7f148a59f16)  


----------------------------------------------------------------------------------------------------------------------------
ONly CMA and SUNCOR use TEM(Bigfix) for patching rest are still done via yum

If during patching you dont see any patches, just run

 [root@SSMCI000 tmp]# subscription-manager attach
Installed Product Current Status:
Product Name: Red Hat Software Collections (for RHEL Server)
Status:       Subscribed

Product Name: Red Hat Enterprise Linux Server
Status:       Subscribed

and then try you will see the patches via yum update



Naveen and team -
RHEL supplementary repo was added Thursday, but synchronization failed for some unknown reason. This caused repo configuration files to reflect the existence of supplementary repository, but caused "yum check-update" to fail because the repository was empty. We are attempting to delete the supplementary repo, but the synchronization jobs are taking a long time. 

If this issue arises during patching, you can simply disable the supplementary repository by doing the following, as root:

vi /etc/yum.repos.d/redhat.repo
and edit the [rhel-6-server-supplementary-rpms] stanza such that enabled=0 like so:
...
[rhel-6-server-supplementary-rpms]
metadata_expire = 1
sslclientcert = /etc/pki/entitlement/6548955138313708592.pem
baseurl = https://dal09ammcaps01.imzcloud.ibmammsap.local/pulp/repos/FMS_CMS3x/Library/content/dist/rhel/server/6/$releasever/$basearch/supplementary/os
ui_repoid_vars = releasever basearch
sslverify = 1
name = Red Hat Enterprise Linux 6 Server - Supplementary (RPMs)
sslclientkey = /etc/pki/entitlement/6548955138313708592-key.pem
gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release
enabled = 0
sslcacert = /etc/rhsm/ca/katello-server-ca.pem
gpgcheck = 1
...
Your patching should then proceed as normal.

Regards,

----------------------------------------------------------------------------------------------------

Reports inSNOW

NC All >> Filter >> click  on "AND" >> "OPENED" ON  "THIS MONTH" >> click on  AND >> select  "ASSIGNED TO"  PUT  ALL TEAM MEMBERS  NAME >> CLICK  ON  RUN
 
 ----------------------------------------------------------------------------------------------------------
 
 Set date manually when NTP offset does not refresh
 
 Date: 2012-04-19 15:55:00 00:00
Set date from the command line date +%Y%m%d -s "20120418"
Set time from the command line date +%T -s "11:14:00"
Set time and date from the command line date -s "19 APR 2012 11:14:00"


------------------------------------------------------------------------------------------------------------

if anyone face open vpn issue so, please create SNOW ticket and assigned to MA-ASGN-CIS-IAM   

also pinged to Dispatcher -- Suresh Raju  


----------------------------------------------------------------------------------------------------------------
If bootstrap fails at join domain, check the time and set it manually if the ntp sync does not work and then rerun bootstrap.

join ad domain error
https://github.kyndryl.net/CMS/cms-chef/wiki/Linux-Active-Directory-Troubleshooting

---------------------------------------------------------------------------------------------------------------------------------
root access users on any server

cat /etc/group | grep -i root

-----------------------------------------------------------------------------------------------------------------------------------
IMZ login issue
https://github.kyndryl.net/CMS/Platform-Support/wiki/Troubleshooting-IMZ-login-issues---Linux
https://github.kyndryl.net/CMS/cms-chef/wiki/Linux-Active-Directory-Troubleshooting

error in var log msg
GSSAPI Error: Unspecified GSS failure.  Minor code may provide more information (Server not found in Kerberos database)

Adding:

Raw
 rdns=false
to section

Raw
[libdefaults]
in /etc/krb5.conf solved the problem.

try clearing cache from /tmp
cleared  cache  from  /tmp  
 
rm -rf /tmp/krb*

 /tmp/krb* files were owned by root:root so those respective users were unable to login as each user's file needs to be owned by that respective user. Remove the files and have users attempt another login, thus regenerating the files with proper permissions.
 
 
chk logs and if they point to sssd.conf, replace with any old one and start sssd service /etc/sssd/sssd.conf


sudo su - sp1adm
sudo: unknown uid 82150: who are you?

check if sssd is stopped
 
if sssd cannot start try
1) Take a duplicate session and look at /var/log/sssd/sssd.log while starting the sssd
# tail -f /var/log/sssd/sssd.log

2) If you see “pidfile exists at /var/run/sssd.pid” then remove the file
# rm /var/run/sssd.pid

3) Try to start the sssd service and check status as well
# systemctl start sssd.service
# systemctl status sssd.service


sssd dead but pid file exists 
https://access.redhat.com/solutions/258943

Resolution

    Clear sssd cache so that it is rebuilt:

Raw

# service sssd stop
# rm -f /var/lib/sss/db/*
# rm -f /var/run/sssd.pid
# service sssd start

sssd service start fail
sssd: SSSD couldn't load the configuration database [5]: Input/output error.
check sssd.log

(Fri Dec  4 12:10:00:166007 2020) [sssd] [ldb] (0x0020): Failed to connect to '/var/lib/sss/db/config.ldb' with backend 'tdb': Unable to open tdb '/var/lib/sss/db/config.ldb': No such file or directory

copied those three db files from chef regional server and started sssd. 
copy files via winftp from chef regional to local and then to the target

alternatively uninstall and reinstall sssd

----------------------------------------------------------------------------------------

deleting files older than X days

To only list for verifying the files older than X days
find <folder path> -name "*.log" -type f -mtime <no of daye as +30> ls


find <folder path> -name "*.log" -type f -mtime <no of daye as +30> -exec rm -f {} \;

Delete command
find /path/to/files/ -type f -name '*.jpg' -mtime +30 -exec rm {} \;
Explanation
First part is the path where your files are located. Don’t use wildcard * if you have a lot of files because you will get Argument list too long error.
Second part -type is the file type f stands for files
Third part -name is limiting *,jpg files
Fourth part -mtime gets how many days the files older then will be listed. +30 is for files older then 30 days.
Fifth part -exec executes a command. In this case rm is the command, {} gets the filelist and \; closes the command



find /hana/shared/CHP/HDB00/backup/log -type f "*.log" -type f -mtime +1295> -exec rm -f {} \;
------------------------------------------------------------------------------------------------------------------------------

Chage to edit ulimit

OS engineer:
4. On host MGGGBJPSOLX02 backup /etc/security/limits.conf  file and change stack size of smpadm user from unlimited to value 8192 as per SAP Note 2488924 

5. Restart host MGGGBJPSOLX02.
Note: Check that "stack size" default value is set after the host restart.

append the limit.conf with 
jgdadm          hard    stack           8192 
save and reboot then su - <sapuser>
ulimit -s

https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-suse.html

TABLE 25.1: ulimit: SETTING RESOURCES FOR THE USER REPORT DOCUMENTATION BUG#
-m The maximum resident set size

-v The maximum amount of virtual memory available to the shell

-s The maximum size of the stack

-c The maximum size of core files created

-a All current limits are reported

EXAMPLE 25.3: ulimit: SETTINGS IN ~/.bashrc REPORT DOCUMENTATION BUG#
# Limits maximum resident set size (physical memory):
ulimit -m 98304

# Limits of virtual memory:
ulimit -v 98304

https://linuxhint.com/linux_ulimit_command/




------------------------------------------------------------------------------------------------------------------
Bootstrap the new way

Before running any chef cmd
export CHEF_ORG=<ORG CODE>
EXAMPLE- export CHEF_ORG=snc

To check
knife status -r | grep snchpijpa12.imzcloud.ibmammsap.local

To clean up
knife node delete -y snchpijpa12.imzcloud.ibmammsap.local ; knife client delete -y snchpijpa12.imzcloud.ibmammsap.local

To bootstrap
su - cmschefadmin
cd cms-chef
copy the id_rsa/id_dsa.pub key on the node /root/.ssh/authorized_keys
Generic command- rake bootstrap:cms3x[username,address,policy_name,policy_group,node_name,cms_site,ou]
username is root
address is the IMZ IP Address
Refer /home/cmschefadmin/cms-chef/opaas_orgs/opaas_stub.json  to get the policy_name,policy_group, OU
cms_site,ou are optional

example- 
rake bootstrap:cms3x[root,10.73.10.69,cms3x_cfg,production,snchpijpa12.imzcloud.ibmammsap.local,,]

To verify
knife status -r | grep snchpijpa12.imzcloud.ibmammsap.local
knife node show snchpijpa12.imzcloud.ibmammsap.local



-----------------------------------------------------------------------------------------------------------------------------

SuSE SIngle user mode

https://www.linuxtechi.com/login-to-single-user-mode-in-suse-linux/

Go into rescue mode.
init=/bin/sh ( when you press  e  and come to kernel  line ...instead  of 1  or S  use  init=/bin/sh )
e2fsck -f -y /dev/mapper/vg00_root  < -- if that solution doesn't work so, run below 

Go into rescue mode.
init=/bin/sh ( when you press  e  and come to kernel  line ...instead  of 1  or S  use  init=/bin/sh )
1. passwd root
2. e2fsck -f -y /dev/mapper/vg00_root  < -- if required --- LV path may be differ.
3. mount -o remount,rw / or mount -o rw,remount /
4. vi /etc/fstab and change the default values to 0 0 do not change for root entry.
exit
exit
reboot


umount the fs

umount -l    umount -f 
https://www.systutorials.com/force-linux-unmount-filesystem-reporting-device-busy/

then
fsck -y <lv path>
mount -o remount,rw /
then reboot

running fsck
https://www.tecmint.com/fsck-repair-file-system-errors-in-linux/

Option 2: Kill the processes using the filesystem and then unmount it ∞

If the reason is that processes are using the filesystem, we can kill the processes using the filesystem and then it will be fine to unmount it. Here, we introduce 2 common methods with 2 common tools.
Method 1: use lsof ∞

The following command finds out the processes accessing the partition/filesystem. You need to run the following command as root. Here, we use the mount point /mnt/data as an example.

linked process to any app

# lsof | grep '/mnt/data'

It will output lines like

bash  17622  user1 cwd   DIR    253,2  4096  2 /mnt/data

If you are sure that it is safe to kill the process, you may kill them by kill or kill -9. After the processes are killed, the filesystem will be able to be unmounted.
Method 2: use fuser ∞

You can find out the processes using a filesystem (e.g. /mnt/data) by

# fuser /mnt/data

fuser can also help you kill all processes using a filesystem at the same time by

# fuser -k /mnt/data

or

# fuser -k -9 /mnt/data

Then you can continue to umount the filesystem.

Lastly, if all above options and methods failed for you, you may try the final method reboot or SysRq or hardware resetting to reboot you Linux.


Options, if required or could not fixed by above solution.
mount | grep root
mount -o remount,rw /
vi /etc/fstab and change the default values to 1 0 do not change for root entry.
exit
exit
reboot 

Suse main bi init=/bin/bash 


FSCK explained
https://www.tecmint.com/fsck-repair-file-system-errors-in-linux/
https://linuxtechlab.com/linux-filesystem-errors-fsck-command-with-examples/

---------------------------------------------------------------------------------------------------------------------

Salt minion install

https://repo.saltstack.com/




BIgfix deploy help slack
#cms-gu-bigfix-deploy


CMA and SUncor are patched via Bigfix only

-------------------------------------------------------------------------------------------------------------

Check if servers are GPFS based

can you pls tell listed servers are GPFS based or not 

agesvedmhsrv1	10.6.1.179
agesvcqmhsrv1	10.6.2.72
agesvepmhsrv1	10.6.3.58 

gpfs installed or not

rpm -qa | grep gpfs

10:22:01 AM: Issue Details:
On SUSE Linux 12 patch level 1, 2 and 3 servers, the parameter DefaultTasksMax may be set to an incorrect value which may lead to a server hang.

How to determine Applicability
This issue is only applicable for GPFS based SUSE Linux 12 patch level
1, 2 and 3 with parameter DefaultTasksMax not set to infinity.

Run the following command  to determine the SUSE Linux version and patch level.
cat /etc/SuSE-release

Run the following command to find the value of parameter 
DefaultTasksMax:
systemctl show --property DefaultTasksMax

If system is GPFS based and the results are SUSE Linux version 12 patch level 1, 2 or 3 and the value of DefaultTasksMax is something other than the word 'infinity' then mark this as applicable. 

---------------------------------------------------------------------------------------------------------------------------

cms-Sq-sap-base

for CORESYNC or cluster related tickets

start corosync service with
systemctl start corosync.service


#nagios-portal-issues
NAgios issues


chef queue
SQ-CHEF-INFRA

Sev1 CIC  SEV1 in #cim-sev1-hub:
Infra Team pls ping in #cms-tr-phys-infra

------------------------------------------------------------------------------------------------------------------------------

Request to setup FTP

https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/W4bd546a87fc9_4881_b5c2_79a76bf49b1b/page/SFTP%20-%20FTP%20setup

Quick guide to SFTP and FTP setup

 

1. IAM creates id
2. OS team verifies home path for sftp user is path to be used for sftp
3. Path ownership should be sftpyhi:sapsys 

 

For install of FTP and SFTP:

1.  yum install vsftpd.x86_64

2. sed -i -- 's/anonymous_enable=YES/anonymous_enable=NO/g' /etc/vsftpd/vsftpd.conf

3. service vsftpd restart

4. chkconfig vsftpd on

5. getenforce       Note:  if returns enable run next step

6.  setsebool -P allow_ftpd_full_access 1

 
FOr FTP on SuSE

https://www.server-world.info/en/note?os=SUSE_Linux_Enterprise_12&p=ftp&f=1

 www:~ # zypper -n install vsftpd
www:~ # vi /etc/vsftpd.conf
# line 19: change

write_enable=YES
# line 36: uncomment

ls_recurse_enable=YES
# line 62,63: uncomment ( enable chroot )

chroot_local_user=YES
chroot_list_enable=YES
# line 65: uncomment ( chroot list )

chroot_list_file=/etc/vsftpd.chroot_list
# line 80: no anonymous

anonymous_enable=NO
# line 171,172: uncomment ( allow ascii mode )

ascii_upload_enable=YES
ascii_download_enable=YES
# line 184: change ( listen IPv4 )

listen=YES
# line 189: change ( turn to OFF if it's not need )

listen_ipv6=NO
# add follows to the end

# specify root directory ( if don't specify, users' home directory become FTP home directory)

local_root=public_html
# use local time

use_localtime=YES
www:~ # vi /etc/vsftpd.chroot_list
# add users you allow to move over their home directory

suse
www:~ # systemctl start vsftpd

www:~ # systemctl enable vsftpd 

Notes:

SFTP - is ftp over ssh -  so no need for package install

VSFTP - includes sftp, ftp and ftps    

--------------------------------------------------------------------------------------------------------------

Physical infra on call sheet link

http://130.103.53.95/Managed_Application/Infrastructure_Services/Infrastructure_Management_Tribe/Infra_Mgmt_3x_Infrastructure/Infra_Mgmt_3x_Infrastructure.asp

-------------------------------------------------------------------------------------------------------------------

Bigfix uninstall
cd /var/chef/cache/cookbooks
chef-client -z -o besclient::remove

cd /var/chef/cache/cookbooks ; chef-client -z -o besclient::remove

chef-client -z -o besclient::remove from /var/chef/cache/cookbooks
--------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------

Chef client alert

service chef-client status
chef-client 
echo $?


If chef-client fails for subscriptions chk dnsmasq service was down


cat /var/log/chef/client.log |grep -i "Chef Run complete" 
grep -i "chef run complete" /var/log/chef/client.log |tail -5;service chef-client status
---------------------------------------------------------------------------------------------------------------------

########################################################
Requirment -- copy only folder and subfolder skip all types of file
source /interface/PQ2/330/
destination /interface/PQ2/350/
Solution - 
cd /interface/PQ2/330/ && find . -type d -exec mkdir -p /interface/PQ2/350/{} \;
######################################################## 

Repair xfs file system

https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/xfsrepair

Repairing an XFS File System
To repair an XFS file system, use xfs_repair:

# xfs_repair /dev/device

The xfs_repair utility is highly scalable and is designed to repair even very large file systems with many inodes efficiently. Unlike other Linux file systems, xfs_repair does not run at boot time, even when an XFS file system was not cleanly unmounted. In the event of an unclean unmount, xfs_repair simply replays the log at mount time, ensuring a consistent file system.  


umount -l  
remount 
xfs_repair

Filesystem 	Description
ext2 	High performance for fixed disk and removable media
ext3 	Journaling version of ext2
ext4 	Supports larger files and file system sizes
vfat 	MS-DOS file system useful when sharing files between Windows and Linux
XFS 	High-performance journaling file system
Btrfs 	Addresses scalability requirements of large storage systems

to get the filesystem type for any unmountd lv check blkid for that lv path or name


----------------------------------------------------------------------------------------------------------------------

Service master CRITICAL: 0 master processes running (thresh 1:)
check for postfix service 

if it does not start

vi /etc/postfix/main.cf

ensure the below
inet_interfaces = all				uncomment this line
#inet_interfaces = $myhostname
#inet_interfaces = $myhostname, localhost
#inet_interfaces = localhost			comment this one

then try staring the postfix service

check logs at egrep '(warning|error|fatal|panic):' /var/log/maillog | more

sendmail alert also need postfix running

CS9101645 -Service master CRITICAL: 0 master processes running (thresh 1:)
Issue - [root@LONMAGERP0004 /]$ service postfix status
master dead but pid file exists
###############################################################################
Solution 1
service postfix stop
root@LONMAGERP0004 /]$ cat /etc/postfix/main.cf |grep -i inet_interfaces
# The inet_interfaces parameter specifies the network interface
inet_interfaces = all  <---UNCOMMENT THAT LINE
#inet_interfaces = $myhostname
#inet_interfaces = $myhostname, localhost
#inet_interfaces = localhost  < -- COMMENT THAT LINE
# the address list specified with the inet_interfaces parameter.
# receives mail on (see the inet_interfaces parameter).
# to $mydestination, $inet_interfaces or $proxy_interfaces.
# - destinations that match $inet_interfaces or $proxy_interfaces,
# unknown@[$inet_interfaces] or unknown@[$proxy_interfaces] is returned
You have mail in /var/mail/root
[root@LONMAGERP0004 /]$ 
Solution 2 
service postfix stop
\rm /var/spool/postfix/pid/master.pid
\rm /var/lock/subsys/postfix
service postfix start
Solution 3
tail -n 500 /var/log/maillog
killall sendmail < if sendmail install on same server so may uninstall or kill the process
killall sendmail-mta
netstat -pel | grep postfix
netstat -lnp |grep :25
If you found port is used by any process so, ask PDL to kill the process or change the port for same process.
service postfix start
REMOVE monitoring in Nagios config

 SendMail Monitoring for TATA SERVER.
#############################################
cd /usr/local/ncpa/etc/
cat /usr/local/ncpa/etc/base_processes.cmas
[root@tdpdcs4dapp1 etc]# cat base_processes.cmas |grep -i sendmail
* sendmail
[root@tdpdcs4dapp1 etc]#
Remove Senmail entry from file base_processes.cmas
--------------------------------------------------
cd ncpa.cfg.d/
[root@tdpdcs4dapp1 ibmsgaur]# cat /usr/local/ncpa/etc/ncpa.cfg.d/processes.cfg | grep sendmail
%HOSTNAME%|__SUSE__Service__CRITICAL__sendmail__ = /plugins/cmas_check_process.sh/sendmail
Remove sendmail entry from processes.cfg 
-------------------------------------------
Remove send mail entry from base_processes.cmas and processes.cfg files and save it. Restart nagios agent.
vi /usr/local/ncpa/etc/base_processes.cmas
vi /usr/local/ncpa/etc/ncpa.cfg.d/processes.cfg
systemctl restart ncpa_passive.service
systemctl restart ncpa_listener.service
############################################################################################

Postfix master dead but pid file exists

Tech Stuff >> Unix-Linux
Puppet logs showed:
puppet-agent[16302]: (/Stage[main]/Mail::Postfix/Service[postfix]/ensure) change from stopped to running failed: Could not start Service[postfix]: Execution of '/sbin/service postfix start' returned 1:  at /etc/puppet/modules/mail/manifests/postfix.pp:8

Status showed:
# service postfix status
master dead but pid file exists

Stop and start:
# service postfix stop
# service postfix status
master dead but pid file exists

Remove pid and lock files:
# \rm  /var/spool/postfix/pid/master.pid
# \rm /var/lock/subsys/postfix
# service postfix stop
# service postfix start
Starting postfix:                                          [  OK  ]
# service postfix status
master dead but pid file exists

check cat var/log/maillog
if error says
Sep 23 05:36:36 LONMAGERP0004 postfix/postfix-script[62369]: starting the Postfix mail system
Sep 23 05:36:36 LONMAGERP0004 postfix/master[62370]: fatal: bind 0.0.0.0 port 25: Address already in use

find the process using port 25

 netstat -lnp |grep :25
to check port used by what process

if sendmail then restart that if SAP then take appropriate action


CS9101645 -Service master CRITICAL: 0 master processes running (thresh 1:)
Issue - [root@LONMAGERP0004 /]$ service postfix status
master dead but pid file exists
###############################################################################
Solution 1
service postfix stop
root@LONMAGERP0004 /]$ cat /etc/postfix/main.cf |grep -i inet_interfaces
# The inet_interfaces parameter specifies the network interface
inet_interfaces = all  <---UNCOMMENT THAT LINE
#inet_interfaces = $myhostname
#inet_interfaces = $myhostname, localhost
#inet_interfaces = localhost  < -- COMMENT THAT LINE
# the address list specified with the inet_interfaces parameter.
# receives mail on (see the inet_interfaces parameter).
# to $mydestination, $inet_interfaces or $proxy_interfaces.
# - destinations that match $inet_interfaces or $proxy_interfaces,
# unknown@[$inet_interfaces] or unknown@[$proxy_interfaces] is returned
You have mail in /var/mail/root
[root@LONMAGERP0004 /]$ 
Solution 2 
service postfix stop
\rm /var/spool/postfix/pid/master.pid
\rm /var/lock/subsys/postfix
service postfix start
Solution 3
tail -n 500 /var/log/maillog
killall sendmail < if sendmail install on same server so may uninstall or kill the process
killall sendmail-mta
netstat -pel | grep postfix
netstat -lnp |grep :25
If you found port is used by any process, ask PDL to kill the process or change the port for same process.
service postfix start

pkill <name>  to kill all processes with app name

---------------------------------------------------------------------------------------------------------------------------

1- SL is like our vendor,  they sell us the baremetal servers
2- SL they have no idea what we support or what we authenticate.
3- they will check for physical issues only.  only hardware related issues or SL network issues ( dont confuse them with imz and CFN )
4-since they only see the hardware,  they do not care what OS we load onto them.
5- once we have the baremetal, we load them with ESXI which our team supports. 
6- the VMs inside the ESXI are your team responsability. 
7- phanas are yours from start to end.   you own all their support.    but when it comes to SL, they will only check hardware related issues. 
 
by saying this , we need to plesae understand :
-  stop asking DPEs, CICs, etc,  to contact us for phana issues.   phanas are 100% supported by your team.  even if its hardware.    SL only will support the hardware part.
for ESXI issues. 
- stop asking SL to fix your OS problems:  they dont support the vms inside the esxi. they are a cloud vendor, what happens with the vms , is not of their concern.
"Can you please go ahead and try running fsck to see if it helps. Please"
"FS related error on the LONMAGHAN0014 server hosted on this esxi. Unable to get on, No authentication working. Please check and fix ASAP"
 
this kind of requests to SL should be stopped.   if you dont know how to fix it, dont try to make another team do it for you .
 
again,  you dont support the ESXI server , and SL doest support the vms inside.  so, please stop trying to have SL team to fix your own issues.  
if you need to talk to SL about ESXIs servers you requests should come to us. 
if you need up to talk to SL bout phanas,  is for hardware related issues.  not to fix your OS problems.

------------------------------------------------------------------------------------------------------------------------------

Delete all lines in VI / VIM editor - Unix / Linux

    Go to command mode in the editor by pressing ESC key on the keyboard.
    Press gg. It will take to the first line of the file.
    Then press dG. This will delete from the first line to the last line.
    
------------------------------------------------------------------------------------------------------------------------------------

Hi Ravi, 

as we discussed, lets start SAP BASIS Cross Training for OS Team.

Introduction to SAP, SAP Basis
SAP HANA Architecture
SAP Architecture - ABAP, JAVA
SAP Start/Stop Procedure - Apps Server & HANA DB
Handling SAP Incidents in 3.x

Please join my WebEx link to from 20 May 2019 to 23 May 2019 @ 12:00 PM IST
https://ibm.webex.com/meet/sisageli

@ Blessen, Ravi : Feel free to add any additional topics.

----------------------------------------------------------------------------------------------------------------------------------------

Online learning with IBM id access
https://learning.oreilly.com/library/view/the-definitive-guide/9781430268208/

----------------------------------------------------------------------------------------------------------------------------------

brtfs FS extension

https://www.suse.com/support/kb/doc/?id=7018329

 btrfs filesystem resize +3G /
 
 btrfs filesystem resize max /mnt
 
 
 
 -----------------------------------------------------------------------------------------------------------------------------------
 
 Bigfix cleanup from WIn srver
 
 this utility do a uninstall and a clean in the server: http://software.bigfix.com/download/bes/95/util/BESRemove9.5.13.130.exe 
 
 All CROWN servers/agents must connect to this 10.68.200.27 and 10.68.200.28
 
 these last two must connect to mexico top relays 158.98.48.147 and .148 
 
 ----------------------------------------------------------------------------------------------------------------------------------------
 
 intranet pw reset
 
 The w3id Profile application allows you to create, reset, or update your w3id password in order to access many IBM websites and applications.
 https://w3idprofile.sso.ibm.com/password/createpwd_lookup_otp.wss
 
 
 
 https://w3idprofile.sso.ibm.com/password/changepwd.wss



User needs to reset their password which will immediately unlock your account using the "Forgot Password link" on the login page at: https://idaas.iam.ibm.com/idaas/mtfim/sps/authsvc?PolicyId=urn:ibm:security:authentication:asf:basicldapuser 

----------------------------------------------------------------------------------------------------------------------------------------------

HANA VM details


https://w3-connections.ibm.com/communities/service/html/communityview?communityUuid=d94692fc-4017-476f-be5d-db72cf4b2dc9#fullpageWidgetId=Wcde8da0280e8_4a4d_8885_7a3e5239e6dd&file=65fd7eb3-da54-4a35-9831-51048dcbfdde 

-----------------------------------------------------------------------------------------------------------------------------------------
Mapping server disk with VMWare disk scsi id
vmware disk mapping against the linux VM

https://www.virten.net/2015/08/match-linux-scsi-devices-sdx-to-virtual-disks-in-vmware/
You can also use PowerCLI to get a list of devices with their SCSI ID:

$vm="vcsa6.virten.lab"
$vmview = Get-View -ViewType VirtualMachine -Filter @{"Name" = $vm}

foreach ($VirtualSCSIController in ($vmview.Config.Hardware.Device | where {$_.DeviceInfo.Label -match "SCSI Controller"})) {
 foreach ($VirtualDiskDevice in ($vmview.Config.Hardware.Device | where {$_.ControllerKey -eq $VirtualSCSIController.Key})) {
 Write-Host SCSI" ("$($VirtualSCSIController.BusNumber):$($VirtualDiskDevice.UnitNumber)")" $VirtualDiskDevice.DeviceInfo.Label
 }
}
match-hard-disk-to-scsi-id-powercli


ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[/]' '{print $4,"- SCSI",$7}'

sda - SCSI 0:0:0:0
sdb - SCSI 0:0:1:0
sdc - SCSI 0:0:2:0
sdd - SCSI 0:0:3:0
sde - SCSI 0:0:4:0
sdf - SCSI 0:0:5:0
sdg - SCSI 0:0:6:0
sdh - SCSI 0:0:8:0
sdi - SCSI 0:0:9:0
sdj - SCSI 0:0:10:0
sdk - SCSI 0:0:11:0
sdl - SCSI 1:0:0:0
sdm - SCSI 1:0:5:0
sdo - SCSI 0:0:12:0


To determine the SCSI ID from device names enter ls -d /sys/block/sd*/device/scsi_device/*


match with the details in vcenterfor each disk attached.

-------------------------------------------------------------------------------------------------------------------------------

deleting lv vg from a VM
If the non-root LVM volume, Volume Group, and Physical Volume used for the LV are no longer required on the system, then it could be removed/deleted using following steps. If the LVM volume is containing any required data, then please make sure to take a backup of that data before proceeding with following steps:

In this example, we will be deleting “testlv” from the volume group “datavg”. The LV is mounted on the mount point /data01.

# df -hP | grep -i data01
/dev/mapper/datavg-testlv  976M  2.6M  907M   1% /data01

# lvs
  LV     VG     Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root   centos -wi-ao---- 17.47g
  swap   centos -wi-ao----  2.00g
  testlv datavg -wi-ao----  1.00g

1. Delete the entry of the mount point from the /etc/fstab :

# cat /etc/fstab
...
/dev/mapper/datavg-testlv            /data01              ext4    defaults        0 0
...

2. Unmount the mount point :

# umount /data01

3. Disable lvm :

# lvchange -an /dev/datavg/testlv

4. Delete lvm volume :

# lvremove /dev/datavg/testlv

5. Disable volume group :

# vgchange -an datavg

6. Delete volume group :

# vgremove datavg

7. Delete physical Volumes being used for the volume group “datavg” :

# pvremove /dev/sdb  /dev/sdc


To check if any mount point is locked by any process

    To free up busy mount point you can use fuser command with k option:
    k :- Send the SIGKILL signal to each process using each file.

# fuser -kcu /upload	be cautious this may dc ur sessiona nd stop sssd session
/upload: 20310c(root)

    Confirm that nobody is using the file system

# fuser -cu /upload
/upload:

--------------------------------------------------------------------------------------------
How to check if the disk attached is used or not

Check lsblk and find all disks without any branching/details of allocated lv

if u find any like below
sdl                                     8:176  0  136G  0 disk
sdm                                     8:192  0  136G  0 disk

check blkid /dev/sdl
if it returns uuid then u need to further check if they are being used anywhere

[root@havhav1008 ibmrmalik]# pvdisplay -m /dev/sdm
  --- Physical volume ---
  PV Name               /dev/sdm
  VG Name               psjdatavg
  PV Size               136.00 GiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              34815
  Free PE               34815
  Allocated PE          0
  PV UUID               FUDkBZ-g8oT-mp5J-6Xiu-pkKB-gLV1-G4rnag

  --- Physical Segments ---
  Physical extent 0 to 34814:
    FREE

following example deactivates the volume group my_volume_group.
# vgchange -a n my_volume_group

To remove a volume group that contains no logical volumes, use the vgremove command.
# vgremove officevg


If it shows Total PE and Free PE same or Allocated PE as 0 means it is unused.

use the vgreduce command to remove the physical volume.
vgreduce my_volume_group /dev/hda1

Remove all unused PVs from a VG.

       vgreduce -a|--all VG
           [ COMMON_OPTIONS ]

       —

       Remove all missing PVs from a VG.

       vgreduce --removemissing VG
           [    --mirrorsonly ]
           [ COMMON_OPTIONS ]



---------------------------------------------------------------------------------------------

scan disk for badsectors

1. Reboot VM in single user mode.
2. Unmount file system related to /dev/sdb which has 9 bad blocks and it has xfs file system.
3. Run file system check using following command:

xfs_check /dev/mapper/vghanadata-lv_hana_data
xfs_check  /dev/mapper/vghanadata-lv_usr_sap
xfs_check  /dev/mapper/vghanadata-lv_hana_shared


4. Repair file system using command:

xfs_repair /dev/mapper/vghanadata-lv_hana_data
xfs_repair  /dev/mapper/vghanadata-lv_usr_sap
xfs_repair  /dev/mapper/vghanadata-lv_hana_shared

Also using -L option in above command to force repair the file system.

--------------------------------------------------------------------------------------------------------------

to add routes

cat /etc/sysconfig/network-scripts/route-bond0 < -- To add routes
[root@wdc04ammtsm001 network-scripts]# cat /etc/sysconfig/network-scripts/route-bond0
10.148.24.128/26 dev bond0
10.148.59.128/26 dev bond0
10.0.0.0/14 via 10.148.74.129
161.26.0.0/16 via 10.148.74.129
10.65.33.224/27 via 10.148.74.129
10.65.11.0/26 via 10.148.74.129
10.120.102.17/32 via 10.148.74.129
10.65.0.0/16 via 10.148.74.129 


route add -net 192.168.3.0 gw 192.168.1.1 netmask 255.255.255.0 dev eth0

route add 146.89.142.119 gw 146.89.142.127 dev bond0


gateway when adding route  10.135.2.1

route print in WIndoes
ip route in Linux

to delete route
get teh output of ip route and route -n and get the details of ip netmask and gateway with the n/w adaptor details from the output of two commands
then use 
Adding route

ip route add 10.170.64.0/24 via 10.207.61.1     SUSE 12 Sp4 this format works

[root@MGGGBJPECCX01 ibmrmalik1]$ route del -net 158.87.44.0/23 gw 10.5.255.1 dev eth3
[root@MGGGBJPECCX01 ibmrmalik1]$ route del -net 158.87.46.0/23 gw 10.5.255.1 dev eth3
[root@MGGGBJPECCX01 ibmrmalik1]$ route add -net 158.87.46.0/23 gw 10.133.18.1 dev eth2
[root@MGGGBJPECCX01 ibmrmalik1]$ route add -net 158.87.44.0/23 gw 10.133.18.1 dev eth2
[root@MGGGBJPECCX01 ibmrmalik1]$ wget https://158.87.46.140/nrdp
--2021-06-04 15:20:17--  https://158.87.46.140/nrdp
Connecting to 158.87.46.140:443... connected.
ERROR: cannot verify 158.87.46.140’s certificate, issued by “/C=US/ST=MD/L=Dallas/O=IBM/OU=MHAS/CN=a0001v5rapp0201/emailAddress=hayesda@us.ibm.com”:
  Self-signed certificate encountered.
    ERROR: certificate common name “a0001v5rapp0201” doesn't match requested host name “158.87.46.140”.
To connect to 158.87.46.140 insecurely, use ‘--no-check-certificate’.


Deleting route

route del -net 192.168.3.0 gw 192.168.1.1 netmask 255.255.255.0 dev eth0

persistent route
Adding Persistent static route:
You need to edit 

route-eth0 file to define static routes for eth0 interface. This configuration will be persistent even after the server is rebooted.


In RHEL 8.2, you can use the route add command to add a permanent (persistent) route to the routing table. However, starting from RHEL 7 and onwards, it is generally recommended to use the NetworkManager or manual network configuration files for adding persistent routes, as the route add command is not the preferred method for configuring routes in modern Linux distributions.


Add the permanent route using the route add command, specifying the network address and the gateway address. Replace <NETWORK_ADDRESS> and <GATEWAY_ADDRESS> with the appropriate IP addresses:

sudo route add -net <NETWORK_ADDRESS> netmask <NETMASK> gw <GATEWAY_ADDRESS>


ifroute-eth1 file needs to be updated to make routes persistent

[root@hfcgrpappdb network]# cat ifcfg-eth1                  NOT THIS FILE
DEVICE=eth1
STARTMODE=onboot
USERCONTROL=no
BOOTPROTO=static
NETMASK=255.255.255.0
IPADDR=10.28.26.113


#NETMASK=255.255.254.0
#IPADDR=10.170.0.0


#NETMASK=255.255.254.0
#IPADDR=10.170.4.0


#NETMASK=255.255.254.0
#IPADDR=10.170.8.0
[root@hfcgrpappdb network]# cat ifroute-eth1                  ADD HERE
default  10.28.26.1 - eth1
10.170.0.0/23 10.28.26.1 - eth1
10.170.4.0/23 10.28.26.1 - eth1
10.170.8.0/23 10.28.26.1 - eth1
[root@hfcgrpappdb network]#



GATEWAY0=192.168.10.1 NETMASK0=255.255.255.0 ADDRESS0=192.168.100.0
GATEWAY1=10.64.34.1 NETMASK1= 255.255.255.240 ADDRESS1=10.64.34.10
Save and close the file. Restart networking:service network restart

ntwork test
cat /etc/sysconfig/network-scripts/ifcfg-eth0
cat /etc/sysconfig/network
cat /etc/resolv.conf
route
[root@spsvepapapp01 ibmrmalik]$ iptables -L


route  add  -net 10.250.17.248 netmask 255.255.255.248 gw 10.250.17.129
Net & netmask are  of  destination  server  ; gw  is  of  existing host.
ip route add 10.162.24.192/26 dev eth2
--------------------------------------------------------------------------------------------------------------------------
webex linux trg
https://persistent.webex.com/persistent/k2/j.php?MTID=t85add4f075801fbe696bdc9656b11649 

-----------------------------------------------------------------------------------------------------------------------------

like /etc/fstab we also have  /etc/mtab

to umount a FS in mtab, use  fusermount -u <FS>

then mount -a

---------------------------------------------------------------------------------------------------------------------

To check for any file which is filling up quickly 

lsof -t <file path and file name>

generates a PID

ps -ef |grep <PID recd above>

--------------------------------------------------------------------------------------------------------------------

Customer slack channel that the Customer is getting decommission. So we can ignore n close the alerts, if any. 
Central American Retail Sourcing (CA3)  - #scx-sap09-ca3

---------------------------------------------------------------------------------------------------------------

netstat -lnp | grep 25 or netstat -antplu |grep 22
netstat -tulpn | grep LISTEN
To find which application is listening on a particular port, run lsof in this form.
lsof -i :80
netstat -lntup | grep ":80" 
----------------------------------------------------------------------------------------------------------------

NCPA listener

Linux NCPA Servers
Check that the services are running

https://ibmmhas.service-now.com/kb_view.do?sysparm_article=KB0016174

Run the following commands on the server:

ps -ef | grep ncpa_
For step 1, you should see a listener service and a passive service.

For step 2, the last line must have the current date/time stamp at the beginning.  Within the last few lines you should see a 'Success' message for NRDP with the number of checks submitted.  That number is usually between 30 and 150.

If either of these fail, restart the services:

/sbin/service restart ncpa_listener
/sbin/service restart ncpa_passive
Check the logfile again and make sure you see a success message.  A typical run takes between 1 and two minutes.

cat /usr/local/ncpa/etc/ncpa.cfg |grep -i parent

tail -2 /usr/local/ncpa/var/log/ncpa_passive.log

or sh /usr/local/ncpa/plugins/cmas_check_ncpa_status.sh

if missing add the routes
158.87.44.0/23 via 10.207.61.1 dev eth0
158.87.46.0/23 via 10.207.61.1 dev eth0



/usr/local/ncpa/etc/   
base processes.cfg

comment the service


plz perform below steps on both nodes of the cluster ->
cd /usr/local/ncpa/etc/ncpa.cfg.d/
update file suse-pacemaker.cfg to remove the below 2 lines->
%HOSTNAME%|__SUSE__Service__CRITICAL__iscsid.service__ = /plugins/cmas_check_svc.sh/iscsid.service
%HOSTNAME%|__SUSE__Service__CRITICAL__sbd.service__ = /plugins/cmas_check_svc.sh/sbd.service
execute the command-> systemctl restart ncpa_passive


REMOVE SendMail Monitoring for a SERVER.
#############################################
cd /usr/local/ncpa/etc/
cat /usr/local/ncpa/etc/base_processes.cmas
[root@tdpdcs4dapp1 etc]# cat base_processes.cmas |grep -i sendmail
* sendmail
[root@tdpdcs4dapp1 etc]#
Remove Senmail entry from file base_processes.cmas


route -n

ip route get 158.87.44.154

get the route via which the ip to add is going and then based on that add the same 

route add 158.87.44.128 gw 10.6.2.255 dev net0
route add 158.87.46.128 gw 10.6.2.255 dev net0

route add -net 158.87.44.0 netmask 255.255.255.0 gw 10.6.2.255
route add -net 158.87.46.0 netmask  255.255.255.0 gw 10.6.2.255

ip route add 158.87.44.0/23 dev net0
ip route add 158.87.46.0/23 dev net0


158.87.44.0/23 via 10.6.1.1 dev eth0
158.87.46.0/23 via 10.6.1.1 dev eth0


Static route configuration can be stored per-interface in a /etc/syconfig/network-scripts/route-interface file. For example, fstatic routes for the em2 interface would be stored in the /etc/sysconfig/network-scripts/route-em2 file, for example:
# cat /etc/sysconfig/network-scripts/route-em2
192.168.2.0/24 via 192.168.1.32 dev em2
Once done, restart your network service (or restart the server):
# systemctl restart network


 pgrep -f ncpa               ------ it will provide only pids of ncpa
3)  kill -9 $(pgrep -f 'ncpa')  ------ killing all the PIDS in a single command 

If you notice that there are multiple ncpa_passive (or ncpa_posix_passive) processes running, one of the child processes may be hung.  You will want to kill the children of the ncpa_passive process, then kill the ncpa_passive process itself.  Once all of the relative processes have been killed, try restarting the service and tailing the /usr/local/ncpa/var/log/ncpa_passive.log to see that the run finishes.

Make sure that the services are set to start at boot time:

chkconfig --list ncpa_passive
chkconfig --list ncpa_listener
These should be set to 'on'.  If not, set them to on:

chkconfig ncpa_listener on
chkconfig ncpa_passive on
 
More Linux troubleshooting help available at 
 
https://w3-connections.ibm.com/wikis/home?lang=en-us#!/wiki/MHAS%20Nagios/page/Linux%20Troubleshooting

-----------------------------------------------------------------------------------------------------------------------------

copy entire directory  

cp -r <dir name>



To delete an user along with its home directory, the command is 
userdel -r username


-------------------------------------------------------------------------------------------------------------

lvremove 
http://kb.eclipseinc.com/kb/why-cant-i-remove-a-linux-logical-volume/

to remove vg
# vgchange -an [vg_name]
# vgremove [vg_name]

linux redbook
http://kb.eclipseinc.com/redbook/linux/ 


Locate the major/minor numbers for the logical volume you’re trying to remove (ie lvol0):

dmsetup info -c | grep lvol0
Take note of the 5th column, which indicates if a volume is “open,” and the 2nd and 3rd columns, which are the major and minor IDs, respectively. For example:

[root@eclipse ~]# dmsetup info -c | grep lvol5
datavg-lvol5         253  24 L--w    1    1      0 LVM-4WlscxDDEw5R9IvjgZYpu5FQeW9h835ADtQzXFr3cJ6SHEcgS4NFMxzaSKjUkedy
datavg-lvol5-cow     253  27 L--w    1    2      0 LVM-4WlscxDDEw5R9IvjgZYpu5FQeW9h835ADtQzXFr3cJ6SHEcgS4NFMxzaSKjUkedy-cow
Find any process attached to this volume by searching on the major and minor IDs discovered above:

lsof | grep "major,minor"
For example:

[root@eclipse ~]# lsof | grep "253,24"
beremote  14524      root   15r      BLK             253,24                1835186 /tmp/filehRrCD8 (deleted)
Shut down or kill any process still accessing the volume to continue unmounting and removal.

If no processes show as accessing the volume in lsof, check to make sure nothing is sharing the filesystem (i.e. rsync, nfs, or samba).

SAMBA share Linux folder accessed from WIndows(reverse of CIFS)	https://opensource.com/article/21/4/share-files-linux-windows
/etc/samba/smb.conf
------------------------------------------------------------------------------------------------------------------------------------------------

memory used up by deleted files
lsof |grep -i delete

-------------------------------------------------------------------------------------------------------------------------------

Action plan for CPU and memory add

once the SAP apps are stopped, 
Shut down the VMcache
Login to TOK vcenter web client
Search for the VM and right click on it to go to the edit settings
In the VIrtual Hardware tab, expand the arrow besides the CPU, 
Set the vCPU to required new vCPU value and check the "Enable Hot CPU add" - To enable adding CPU on the fly without downtime
Additionally expand the Memory drop down and check the Memory Hot Plug Enabled option - to add memory on the fly without downtime
Hit Ok to save the changes
Once the processing is done in the recent task section, start the VM from the vcenter 
Login to the system and verify the changes

---------------------------------------------------------------------------------------------------------------------------------------
kill sshd sessions

netstat -antp | grep sshd | grep -i ESTABLISHED | wc -l

ps -ef |grep -i sshd

to verify the sshd config
sshd -t

========================
1. cp /etc/ssh/ssh_config /etc/ssh/ssh_config_Today’s date.
2. SSH to the Linux server.
3. Switch to root
4. vi /etc/ssh/ssh_config


 lsof -i:30015
lsof -i -P -n | grep LISTEN
netstat -tulpn | grep LISTEN
netstat -lntu
ss -tulpn |grep -i 30015

---------------------------------------------------------------------------------------

To use SAP insight tool on linux laptop use

java -jar <jar file path>

--------------------------------------------------------------------------------------------
PIM tool for passwords

https://ispim.amm.ibmcloud.com/itim/self/Home.do

---------------------------------------
--------------------------------------------------------

#Link Find Your IBM Notes Mail Server :- https://w3.ibm.com/help/#/article/find_mail_server
#Link for notes setup :- https://w3.ibm.com/help/#/article/install_notes/notes_setup

--------------------------------------------------------------------------------------

NFS mounted FS has nobody nobody permission
on the NFS server,
echo 'Y' > /sys/module/nfsd/parameters/nfs4_disable_idmapping
then   exportfs -ra  -- to refresh nfs without restarting nfs service
if does not refresh then
nfs service restart

Disabling idmapping

By default, RHEL6.3 and newer NFS clients and servers disable idmapping when utilizing the AUTH_SYS/UNIX authentication flavor by enabling the following boolean statements:

NFS client server

# echo 'Y' > /sys/module/nfs/parameters/nfs4_disable_idmapping

NFS parent server

# echo 'Y' > /sys/module/nfsd/parameters/nfs4_disable_idmapping



dont ever   run  exportfs -r  or restart nfs  on any cluster  enabled  server

Mounting NFS with specific user
The export settings:
Code:

# cat /etc/exports
...
/mnt/galdb-bitsprod/database 192.168.x.x(rw,all_squash,anonuid=600,anongid=601)
...

The exported directory permissions:
Code:

# ll -d /mnt/galdb-bitsprod/database/
drwxrwxr-x 10 galaxy galaxy 4096 Jul 13 10:50 /mnt/galdb-bitsprod/database/


NFS config file  /etc/idmap.conf

#Domain = local.domain.edu
to
Domain=localdomain

1. make sure ids on host and client are identical
2. make sure the domain names are correctly set


So, for example, a typical idmapd.conf file might look like the following.  If this file is changed, idmapd must be restarted.
 
[General]
Verbosity=7
Pipefs-Directory=/var/lib/nfs/rpc_pipefs
Domain=localdomain
 
[Mapping]
Nobody-User=nobody
Nobody-Group=nobody
 
[Translation]
Method=nsswitch 

----------------------------------------------------------------------------------------------------

SuSE patching

zypper refresh - to refresh the repositories

zypper modifyrepo -d SLES12-SP1-12.1-0

You can re-enable it at any time with:

Code:

zypper modifyrepo -e SLES12-SP1-12.1-0

Note the "-d" to disable and "-e" to enable.
  	


How to list available updates on SUSE Enterprise Linux server

We need to see all applicable patches, run:
zypper lp
zypper list-updates
zypper list-updates | cut -s -d"|" -f3,4,5
zypper list-patches --category security


How to update installed packages with newer versions

Let us patch update Suse Enterprise Linux server, execute:
$ sudo zypper update


Check for any patch or CVE installed on a SUSE
zypper lp -a --cve=CVE-2016-10009

cut -d "|" -f 1-4 -s --output-delimiter " | " /var/log/zypp/history | grep -v " radd "

/var/log/zypp/history
logs in the above




Zypper commands
https://www.tecmint.com/zypper-commands-to-manage-suse-linux-package-management/

zypper command	Description	Example(s)
refresh, ref	Refresh all repositories.	zypper ref
refresh-services, refs	Refresh all services.	zypper refs
list-updates, lu	List available updates.	zypper lu
list-patches, lp	List needed patches.	zypper lp
update, up	Update installed packages with newer versions.	zypper up
ps	List running processes which might still use files and libraries deleted by recent upgrades.	zypper ps -s

rpm -qa --last     to check the patches last installed with dates


rpm upgrade option (rpm -U) or the rpm freshen option (rpm -F) to upgrade the existing software to a newer version.The rpm -U command can be used to install new packages or upgrade existing packages only if you did not previously install any language packages. The rpm -F command can update only packages that are already installed.

link for frequent commands on Suse https://www.tecmint.com/zypper-commands-to-manage-suse-linux-package-management/

SuSE SP2 to SP4
https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-update-online.html#sec-update-migr-zypper-onlinemigr



SLES 12 SP2 to SP4 Cluster migration Steps
https://github.ibm.com/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/PACEMAKER_CLUSTER_SP2_SP4_MIGRATION_STEPS.md



----------------------------------------------------------------------------------------------------------------------------

Untar a .tar file
tar -xvf yourfile.tar to extract the file to the current directory


1. To Create a Tar file:

tar -cv(z/j)f data.tar.gz (or data.tar.bz) <folder1_name> <folder2_name>

c = create v = verbose f= file name of new tar file

 
2. To compress tar file:

gzip data.tar

(or)

bzip2 data.tar (slower but more efficient compression)

 
3. To uncompress tar file

gunzip data.tar.gz

(or)

bunzip2 data.tar.bz2

 

4. To untar tar file

tar -xv(z/j)f data.tar.gz (or or data.tar.bz)

x = extract

--------------------------------------------------------------------------------------------------

Pi on internet

https://persistentsystems.sharepoint.com/sites/Pi/SitePages/Pi-Home.aspx

leave and attendance
https://eisapp.persistent.co.in/eis/LMS/WebUI/LeaveApplication/LeaveGrantingTransactions.aspx


----------------------------------------------------------------------------------------------------------

[root@dal09ammtsm001 tsm_client]# pwd
/tsmcode/tsm_client

for TSM related rpms


----------------------------------------------------------------------------------------------

https://cognitiveclass.ai/badges 
isme saare badges hai 
https://cognitiveclass.ai/badges/docker-essentials 
This is for docker 

PMP 
https://ibm.percipio.com/channels/6abd8c70-f917-11e6-aad2-6b3c03be7fe8

https://ibm.percipio.com/channels/b5b366c0-e71d-11e6-9b91-91c88fa1edb0


https://knowledgecenter.persistent.co.in/viewcourse/PMP
https://ehec.fa.em2.oraclecloud.com/hcmUI/faces/FuseWelcome?_afrLoop=8210051817107696&_afrWindowMode=0&_afrWindowId=null&_adf.ctrl-state=2d0h23qgc_320&_afrFS=16&_afrMT=screen&_afrMFW=1878&_afrMFH=948&_afrMFDW=1920&_afrMFDH=1080&_afrMFC=8&_afrMFCI=0&_afrMFM=0&_afrMFR=96&_afrMFG=0&_afrMFS=0&_afrMFO=0




1200 $ of credit   bf5af2b68ea0a68d1d90a52bee4707cd

Containers:

Foundation : https://gts-learn.w3bmix.ibm.com/#/learningplan/85258455005F9823
Intermediate: https://gts-learn.w3bmix.ibm.com/#/learningplan/85258455006AA069
Learning Plan for AHT - Voyage to Containers: https://gts-learn.w3bmix.ibm.com/#/learningplan/852583C500571933
Tech: Kubernetes and Application Containers:https://gts-learn.w3bmix.ibm.com/#/learningplan/852582B8005DF00C
https://cognitiveclass.ai/courses/kubernetes-course
https://cognitiveclass.ai/courses/get-started-with-microservices-istio-and-ibm-cloud-container-service


Udemy course
https://www.udemy.com/share/101tfGBUUSdF5bQXo=/

Docker:
Learning Plan for Tech: Using Docker (Skillsoft): https://gts-learn.w3bmix.ibm.com/#/learningplan/8525821E00747466

hub.docker.com
ravimalik3281
Rm@03021981

https://labs.play-with-docker.com/
https://ibm.percipio.com

AWS essentials
https://yourlearning.ibm.com/auth/#activity/LPB-8525821D00684C9F
https://gts-learn.w3bmix.ibm.com/#/learningPlan/8525821D005CE549

https://w3.ibm.com/w3publisher/udemy


Azure
https://gts-learn.w3bmix.ibm.com/#/learning/enrolled

https://yourlearning.ibm.com/activity/URL-5DD4D6F4996A


https://yourlearning.ibm.com/activity/URL-E6F4A8CD783B
--------------------------------------------------------------------------------------------------

LVM

[root@saphon1 ~]# lvcreate -L 60G honascsvg -n lv_HON_ip1
  Volume "honascsvg/lv_HON_ip1" is not active locally.
  Aborting. Failed to wipe start of new LV.
  
  updated  vg name  manually  in  lvm.conf  file /etc/lvm/lvm.conf
  refer https://www.thegeekdiary.com/volume-test_vg-lvol0-is-not-active-locally-error-while-running-lvcreate/
  
  
  
  vgcreate vg_NAME /dev/sdX (PV)
lvcreate -L 100G -n sap_migration_lv honappvg
mkfs.ext2/3/4 path of lvdisplay
XFS format a new LV  mkfs.xfs /dev/vg_xfs/xfs_db
mkdir /sybase
mount
vi /etc/fstab

-----------------------------------------------------------------------------------------------------------

HA status

[root@d185173001 ~]# hastatus -sum
-- SYSTEM STATE
-- System               State                Frozen
A  d185173001           RUNNING              0
A  d185173002           RUNNING              0
-- GROUP STATE
-- Group           System               Probed     AutoDisabled    State
B  db2fs           d185173001           Y          N               ONLINE
B  db2fs           d185173002           Y          N               OFFLINE
B  sapfs           d185173001           Y          N               OFFLINE
B  sapfs           d185173002           Y          N               ONLINE




Printer setup
https://docs.oracle.com/cd/E23824_01/html/821-1451/gllgm.html#glmge

https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/Adding-Printers-to-Linux-Machines

if printer down just do cupsenable <printer queue name>
To see if printer is ready lpq -P <printerprinter queue name>

cancel -a <queuename>   to clear the print jobs in the queue in one go and cancel {printerjobid} for one spcific job

check for any printer with short name
lpstat -t |grep gs15
lpstat -t|grep -i 149.223.90.58   (grep ip from SAP printer page to find the printer) 

[root@zffsappdb007 ibmrmalik]# lpstat -t|grep -i 149.223.90.58
device for gs15: lpd://149.223.90.58
[root@zffsappdb007 ibmrmalik]# lpstat -t |grep -i gs15
device for gs15: lpd://149.223.90.58
gs15 accepting requests since Mon Nov 16 12:26:41 2020
printer gs15 is idle.  enabled since Mon Nov 16 12:26:41 2020

TO create a new queue or delete existing queue

lpadmin -x <queue name>   to delete a queue

lpr -P NPI99930C /usr/share/cups/data/testprint    to send a test print

lpstat -W completed      to check if the print is recd successfully

ErrorLog /var/log/cups/error_log
AccessLog /var/log/cups/access_log
PageLog /var/log/cups/page_log

LPD default port for printer is 515

# lpadmin -p 922_SUNGB_ADB_P002 -v socket://149.223.90.58 -E    to create a new print queue where -p is the queue name and -v is the ip 
alternatively use
lpadmin -p 922_ -v socket://149.223.90.58:9600 -E     this is with specific port 9600    socket with 9100 and lpd with 515
# cupsaccept  922_SUNGB_ADB_P002    to start accepting the prints to this queue

lpstat -a  printers installed

lpadmin -p LD18 -v socket://149.223.199.175 -E

lpadmin -p NPIEAF805 -v socket://135.37.32.222 -E

device for JSSWLJ1980: socket://133.0.13.16
device for JSSWLJ1981: socket://133.0.13.17
device for NP115F221: socket://154.0.16.98
device for NP115F246: socket://154.0.16.97
device for NPI452EF5: socket://135.21.31.175
device for NPIB7165F: socket://133.0.13.21
device for npibe89c6: ipp://135.133.100.137/printers/NPIBE89C6
device for NPIEA1D5F: socket://135.37.32.224
device for NPIEAF805: socket://135.37.32.222
device for TSLJA08501: socket://10.152.112.46

lpadmin -p NP115F221 -v socket://154.0.16.98 -E
lpadmin -p JSSWLJ1980 -v socket://133.0.13.16 -E
lpadmin -p JSSWLJ1981 -v socket://133.0.13.17 -E
lpadmin -p NP115F221 -v socket://154.0.16.98 -E
lpadmin -p NPI452EF5 -v socket://135.21.31.175 -E
lpadmin -p NPIB7165F -v socket://133.0.13.21 -E
lpadmin -p npibe89c6 -v socket://135.133.100.137 -E
lpadmin -p NPIEA1D5F -v socket://135.37.32.224 -E
lpadmin -p NPIEAF805 -v socket://135.37.32.222 -E
lpadmin -p NP115F246 -v socket://154.0.16.97 -E






Printer queue logs for stuck queue

/var/log/cups/access_log for logs of printer grep with the queue name

To check jobs in any queue 
 lpstat -o |grep -i NPI450E44
 
 The question was how to kill all jobs. The simple way to kill all jobs:

lprm -
The complicated linux old-school way is below:

Command line:

lpstat -o
to view outstanding print jobs.

cancel -a {printer}
to cancel ALL jobs or ...

cancel {printerjobid}
to cancel 1 job.

1 - Add the print queue
#lpadmin -p BR07 -v socket://BR07:9100
 (Here BR07 is short name given by SAP Team)
2 - Add the printer IP to /etc/host file
< Printer shortname IP >
3 - Accept the print queue
#cupsenable <print queue name>
#cupsaccept <print queue name>
4 - telnet the IP and port and check the conectivity.
tenlet <print IP> 9100
substitute
"nc -zv 192.168.1.15 22"     "nc -zv IP port"

5 - check the print queue status.
lpstat -t |grep <queue name>
6 - Test print has to be given from SAP side.

cat /etc/cups/printers.conf |grep -i ErrorPolicy

lpadmin -p backupZ4 -v socket://backupZ4:9100 -o printer-error-policy=retry-job -E


lpadmin -p BR07 -v socket://BR07:9100
lpadmin -p BR07 -v socket://172.22.12.11:9100

SAP Team give the print queue short name



Check for printer config
 /etc/cups/cupsd.conf or /etc/cups/cups-files.conf   file for parameters set like print queue size etc


ErrorLog /var/log/cups/error_log
AccessLog /var/log/cups/access_log
PageLog /var/log/cups/page_log

If cupsservice gets disabled on any printer, check 
cat /etc/cups/printers.conf |grep -i ErrorPolicy
and ensure it is set to retry-job

:%s/ErrorPolicy stop-printer/ErrorPolicy retry-job/g

---------------------------------------------------------------------------------------

CPU load explained

https://scoutapm.com/blog/understanding-load-averages

The optimal CPU load average is equal to the number of CPUs on the server.
"100% utilization" mark is 1.00 on a single-core system, 2.00, on a dual-core, 4.00 on a quad-core, etc

top -b -d 2 -n 60   top CPU consuming process

us - Time spent in user space
sy - Time spent in kernel space
ni - Time spent running niced user processes (User defined priority)
id - Time spent in idle operations
wa - Time spent on waiting on IO peripherals (eg. disk)
hi - Time spent handling hardware interrupt routines. (Whenever a peripheral unit want attention form the CPU, it literally pulls a line, to signal the CPU to service it)
si - Time spent handling software interrupt routines. (a piece of code, calls an interrupt routine...)
st - Time spent on involuntary waits by virtual cpu while hypervisor is servicing another processor (stolen from a virtual machine)
----------------------------------------------------------------------------------------

DIsk expansion in a CLustered environment
https://github.kyndryl.net/CMS/SAP-Base/blob/master/CMAS%203x/SOPs/Filesystem_extension_steps.md

Make use of Non-HANA cluster operation scripts to be released soon in SDS as much as possible –scripts ready for all planned activities
SOPs for common tasks available here, more can be added on demand ->
https://github.kyndryl.net/CMS/SAP-Base/blob/master/CMAS%203x/SOPs/ReadMe.md
Do’s and Dont’s available here -> <https://github.ibm.com/CMS/SAP-Base/blob/master/CMAS%203x/Pacemaker/Do's%20and%20Dont's.md>

More information available in our Wiki here -> https://github.ibm.com/CMS/SAP-Base/wiki


https://github.kyndryl.net/CMS/SAP-Base/wiki


Disk extension for pacemaker cluster
https://github.kyndryl.net/CMS/SAP-Base/blob/master/CMAS%203x/Pacemaker/Expand%20existing%20disk%20for%20filesystem%20extend.md

https://github.kyndryl.net/CMS/SAP-Base/tree/master/CMAS%203x/Pacemaker

https://github.kyndryl.net/CMS/SAP-Base-RR/tree/master/CMAS%203x/Pacemaker
https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/CMAS%203x/Pacemaker/Add%20New%20disk%20for%20Filesystem%20extend.md

https://github.kyndryl.net/CMS/BuildMigration/wiki



Bringing the Cluster Online
Log in to an existing node.
Check if the service is already running:

systemctl status pacemaker

If not, start Pacemaker now:

systemctl start pacemaker

Repeat the steps above for each of the cluster nodes.

On one of the nodes, check the cluster status with the crm status command. If all nodes are online, the output should be similar to the following:

crm status
Last updated: Thu Jul  3 11:07:10 2014
Last change: Thu Jul  3 10:58:43 2014
Current DC: alice (175704363) - partition with quorum
2 Nodes configured
0 Resources configured

Online: [ alice bob ]

This output indicates that the cluster resource manager is started and is ready to manage resources. 


ERROR: "SuSE Pacemaker cluster setting "no-quorum-policy" may not be set correctly."

FIX: The parameter "no-quorum-policy=ignore" should be set to "no-quorum-policy=stop"


commands to put cluster in managed and unmanaged state
crm configure property maintenance-mode=true
crm configure property maintenance-mode=false

alternatively if the above gives error as 

[root@bumsappop01p ibmrmalik]# crm configure property maintenance-mode=false
ERROR: Warnings found during check: config may not be valid
Do you still want to commit (y/n)? n

use below

Tell the cluster to stop managing services. This is required to allow the services to remain active after the cluster shuts down.

# crm_attribute --name maintenance-mode --update true

 Allow the cluster to resume managing resources again:

# crm_attribute --name maintenance-mode --delete
-------------------------------------------------------------------------------------------------------------------

# chmod 4755 filename

(or):

# chmod u+s filename

for rwsr-xr-x

----------------------------------------------------------------------------------------------------------------------

Taleo
 PSL candidate management
https://ehec.login.em2.oraclecloud.com/oamfed/idp/samlv20


------------------------------------------------------------------------------------------------------------------------

https://scc.suse.com/launch

U- Asmitavadgave 
P- SuseSupport123

------------------------------------------------------------------------------------

Windows paging file

Issue is with monitoring setup of the pagefile as it is set to allocate the total disk for page file. The page file memory used is very low.
Initial size of the paging file should be 1.5 times of the paging file and max should be double of the initial size. Since the paging is not set as per the Microsoft standards, it is 100% 

1. Take Snapshot of the Server .
2. Bring Apps down with the help of  SAP team.
3. Go to the control panel and click System in the pop-up menu
4. Tap or click Advanced system settings. Administrator permission required You might be asked for an admin password or to confirm your choice.
5. On the Advanced tab, under Performance, tap or click Settings.
6. Tap or click the Advanced tab, and then, under Virtual memory, tap or click Change.
7. Clear the Automatically manage paging file size for all drives check box.
8. Under Drive [Volume Label], tap or click the drive that contains the paging file you want to change.
9. Tap or click Custom size, enter a new size in megabytes in the Initial size (MB) or Maximum size (MB) box, tap or click Set, and then tap or click OK.
10. After Windows reboot verify the Swap space after increase and provide the screen shot OS


To extend a disk in windows conver the disk to dynamic including the dsk 0 of OS drive.

------------------------------------------------------------------------------------------------------
The capacity portal is updated at least once a day and it will show VM to host mapping
https://cmas-capacity-manager.w3ibm.mybluemix.net



LogScanner Pacemaker Log Scanner Status CRITICAL: unable to send NRDP results: ERROR: error connecting to NRDP server at https://158.87.46.181/nrdp
 wget --no-check-certificate https://158.87.46.181/nrdp
 
 or 
 
 telnet 158.87.46.181 80
 
 also check
 
 ps -ef | grep -i ncpa_
 
 if multiple instances kill them and restart and then check the logs
 
 
 WIndows follow
https://ibmma.service-now.com/nav_to.do?uri=%2Fkb_view.do%3Fsysparm_article%3DKB0010973%26sysparm_stack%3D%26sysparm_view%3D
 
 ------------------------------------------------------------------------
 
 Docker
http://badges.mybluemix.net/badge/448ad2b4-85d6-496d-9165-f15872539e5f

https://cognitiveclass.ai/courses/docker-essentials

Kubernetes
http://badges.mybluemix.net/badge/b0ad0667-334a-4938-9421-10dc639fde59

------------------------------------------------------------------------------------------------
Any runtime issues can be fixed by below commands, it will not hamper anything on the system --

$ systemctl daemon-reexec


-------------------------------------------------------------------------------------------------

To check any port is listening 

 lsof -i -P -n | grep LISTEN |grep -i <port no>
 
 
 ----------------------------------------------------------------------
 
 chef-client failed, check and add the yum server entry for that site in etc hosts
 
 LON02AMMYUM01     146.89.140.88

----------------------------------------------------------------------------------------------------------

 How to troubleshoot kernel crashes, hangs, or reboots with kdump
  - https://access.redhat.com/solutions/6038 
  
  service kdump status
  systemctl status sysstat   for restarting sar services

---------------------------------------------------------------------------------------------------------

Below link is for how to do bulk resolves in Service Now .

https://ibmma.service-now.com/nav_to.do?uri=%2Fkb_view.do%3Fsys_kb_id%3Ddfcf4110db04c41c01869476db9619d2


CMDB update in SNOW
KB0012431
------------------------------------------------------------------------------------------------------------

Linux Patching

echo `date` > OS_upgrade.log
echo -e "\n\nuname -a results\n" >> OS_upgrade.log
uname -a >> OS_upgrade.log
echo -e "\n\nifconfig -a results\n" >> OS_upgrade.log
ifconfig -a >> OS_upgrade.log
echo -e "\n\netc/hosts result\n" >> OS_upgrade.log
cat /etc/hosts >> OS_upgrade.log
echo -e "\n\netc/fstab results\n" >> OS_upgrade.log
cat /etc/fstab >> OS_upgrade.log
echo -e "\n\ndf -h results\n" >> OS_upgrade.log
df -h >> OS_upgrade.log
echo -e "\n\netc/yum.conf results\n" >> OS_upgrade.log
cat /etc/yum.conf >> OS_upgrade.log
echo -e "\n\netc/grub.conf results\n" >> OS_upgrade.log
cat /etc/grub.conf >> OS_upgrade.log
echo -e "\n\netc/sysctl.conf results\n" >> OS_upgrade.log
cat /etc/sysctl.conf >> OS_upgrade.log
echo -e "\n\nrpm results\n" >> OS_upgrade.log
rpm -qa >> OS_upgrade.log
echo -e "\n\nyum history\n" >> OS_upgrade.logyum history >> OS_upgrade.log
echo -e "\n\nexports\n" >> OS_upgrade.log
cat /etc/exports >> OS_upgrade.log
echo -e "\n\nexports\n" >> OS_upgrade.log
exportfs >> OS_upgrade.log
mount >> OS_upgrade.log


RHEL 6.10 	2018-06-19 	2018-06-19 RHBA-2018:1856 	2.6.32-754
RHEL 6.9 	2017-03-21 	2017-03-21 RHSA-2017:0817 	2.6.32-696
RHEL 6.7 	2015-07-22 	2015-07-22 RHEA-2015:1423 	2.6.32-573
RHEL 6.6 	2014-10-14 	2014-10-13 RHEA-2014:1608 	2.6.32-504


6.10 to 7
https://github.ibm.com/CMS/BuildMigration/wiki/RHEL6-to-RHEL-7-Upgrade-Steps


cat /etc/redhat-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; timedatectl;cat /etc/exports 

Before taking a snapshot for  OS patch please take a screen shot of netstat -nr and match after OS patch complete
grep -i zone /etc/sysconfig/clock


Upgrade:


Clear Yum Cache:
yum clean all

Getting updates
yum check-update

Update the packages
yum update

For HANA where only security patches are to be patched use
yum  update --security    (make  sure  kernel  is  showing  573.26)

To Patch RHAT 6.7 with HANA make sure to have release --set=6.7
[root@acerosdevhana ibmgmorales]$ subscription-manager release --show
Release not set
[root@acerosdevhana ibmgmorales]$ subscription-manager release --set=6.7
Release set to: 6.7
[root@acerosdevhana ibmgmorales]$ subscription-manager release --show
Release: 6.7 

To unset a release bound to spme version
subscription-manager release --unset


subscription-manager list --available --all

 List the enabled repositories:

# subscription-manager repos --list-enabled



Reboot server
shutdown -r now

shutdown -rf now "CH#no"

shutdown -rf now
this command bypass FSCK

Check red hat release and version after update:
cat /etc/redhat-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;timedatectl

Checking for FS for any errors tobe fixed via FSCK
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done

Excluding packages from yum
https://access.redhat.com/solutions/10185

yum update --exclude=PACKAGENAME
yum update --exclude=kernel*


    To make permanent changes, edit the /etc/yum.conf file and following entries to it:

Raw

[main]
cachedir=/var/cache/yum/$basearch/$releasever
keepcache=0
debuglevel=2
logfile=/var/log/yum.log
exclude=kernel* redhat-release*                           <==== 

NOTE: If there are multiple package to be excluded then separate them using a single space or comma. Also, do not add multiple exclude= lines in the configuration file because yum only considers the last exclude entry.

To exclude 32 bit packages edit /etc/yum.conf file.

exclude=*.i?86 *.i686

VMWare tools upgrade

In case of kernel upgrade, Vmware tools needs to be reinstalled by running (otherwise it will not start up with the VM):
vmware-config-tools.pl --default

Check version   vmware-toolbox-cmd -v

service vmware-tools status

for RHEL 
 yum install open-vm-tools or yum update open-vm-tools

 ps -ef | grep vmtoo
root   30083 6031 0 07:36 pts/10  00:00:00 /usr/sbin/vmtoolsd
root   30378 6031 0 07:36 pts/10  00:00:00 grep vmtoo

[root@LONMAGERP0004 ~]$ status vmware-tools
vmware-tools start/running

SOP: KB0013637 VMware Tools update on Windows and Linux Servers.docx


PLEASE BE SURE TO CHECK TIMEZONE IS THE SAME AS BEFORE THE PATCH!!!!
PLEASE VALIDATE WITH SAP TEAM ALL MOUNTS AFTER REBOOTS

Rollback Plan:
In case, if we need to revert back do this:

Check yum history using “yum history”

ID | Login user | Date and time | Action(s) | Altered

This will give you such output, where you can determine ID, which has been applied as latest.

yum history undo <ID>

if you know there was a kernel upgrade ( for example from 6.7 to 6.9 )  a reboot is required!

Check red hat release and version after downgrade:

cat /etc/redhat-release ; uname -a


ONLY PATCHING SECURITY UPDATES
https://access.redhat.com/solutions/10021

Release related
https://access.redhat.com/solutions/238533

To display all updates that are security relevant, and get a reutrn code on whether there are security updates enter:
# yum check-update --security


To patch only security updates at same level
# yum update --security


SUSE PATCHING

cat /etc/os-release; uname -a; date; cat /etc/sysconfig/clock; cat /etc/fstab |grep -i nfs;sh /var/lib/zabbix/check_rw_mounts.sh

zypper locks;cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports; df -hT |grep -i nfs;df -hT |grep -i cifs;rpm -qa|grep -i ds_agent;rpm -qa|grep -i pacemaker_tool 

Compare the precheck.txt and postcheck.txt files using vimdiff command.
# vimdiff precheck.txt postcheck.txt


cat /etc/os-release; uname -a; date; timedatectl status; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh; cat /etc/exports; df -hT |grep -i nfs;df -hT |grep -i cifs


grep -i zone /etc/sysconfig/clock

cat /etc/os-release; uname -a; date; cat /etc/fstab |grep -i nfs; cat /etc/fstab |grep -i cifs; sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh;df -hT |grep -i nfs; cat /etc/mtab |grep -i sds;cat /etc/exports


Time zone capture
date in RHEL 6
timedatectl for RHEL 7 and 8 and SUSE

snapshot

Refresh the repositories
  # zypper ref
 
Install the latest packages for this release with no interaction
  # zypper --non-interactive up

If the goal is to upgrade an older OS release to the current supported version, the command will be slightly altered, by replacing the "update" option with the "distribution-update" option, as follows:

  # zypper --non-interactive dup
 
ONE LINER TO CHECK FOR FSCK ERRORS
Checking for FS for any errors to be fixed via FSCK
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done |less

Post reboot check the latest patches and the date when they were updated
rpm -qa --last

To check for any specific atch if installed
zypper patch-info SUSE-SLE-SAP-12-SP2-2020-854 |grep -i status


If you see an error like below
Retrieving: msodbcsql17-17.5.2.1-1.x86_64.rpm ..................................................................................................................[error]
Timeout exceeded when accessing 'https://packages.microsoft.com/sles/12/prod/msodbcsql17-17.5.2.1-1.x86_64.rpm'.

go to yast and disable the repo for microsoft and save rerun to proceed


additionally check uname -a,date and cat /etc/SuSE-release and compare it with the pre patch details

zypper list-updates
zypper list-patches
Upgrade SUSE to SP4 use command 'zypper migrate'


Validate if the server is already properly setup the software repositories as follow:
            # SUSEConnect -s

            [{"identifier":"SLES_SAP","version":"12.2","arch":"x86_64","status":"Registered"}]

If the server is not registered check the contents of /etc/SUSEConnect, if pointing to any generic SUSE URL, delete this file and run chef-client and it will register the server with correct SMT server. Should be an IBM site URL, with the SMT server name having IBM 3.x site and SMT like this:
            # cat /etc/SUSEConnect

            ---

            insecure: false

            url: https://che01ammsmt01.imzcloud.ibmammsap.local/center/regsvc

            language: en_US.UTF-8

The list of the others SMT servers are:
            che01ammsmt01.imzcloud.ibmammsap.local

            dal09ammsmt01.imzcloud.ibmammsap.local for WDC servers also

            hkg02ammsmt01.imzcloud.ibmammsap.local

            lon02ammsmt01.imzcloud.ibmammsap.local

            sao001ammsmt01.imzcloud.ibmammsap.local

            mon01ammsmt01.imzcloud.ibmammsap.local
            
            dal09ammsmt01.imzcloud.ibmammsap.local
			
			
			Hostname	 	 IP	current	proposed
dal09ammsmt01	SMT	146.89.140.46	Daily	quarterly
sao01ammsmt01	SMT	146.89.143.36	Daily	quarterly
lon02ammsmt01	SMT	146.89.140.125	Daily	daily
mon01ammsmt01	SMT	146.89.141.183	Daily	quarterly
hkg02ammsmt01	SMT	146.89.141.51	Daily	quarterly
che01ammsmt01	SMT	146.89.142.105	Daily	quarterly
fra02ammsmt01	SMT	146.89.140.211	Quarterly Locked	quarterly
dal13ammsmt01	SMT	146.89.142.216	Quarterly Locked	quarterly


If the registration still does not happen then it could be the issue with fingerprints that goes to the chef team to fix. Raise a git issue and get that fixed. Ensure the server shows as registered. The chef-client should finish successfully else you may need to get it fixed with help from chef team.
Do not add any repositories if you find are present in any SP4 server and missing here as they get added during the migration (SP2 to SP4). If you add them manually, the migration does not start and fails with the error similar to below:
            Adding service SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local: SUSE::Connect::ZypperError: Unexpected exception.

            [SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local:SLES12-SP4-Updates| http://che01ammsmt01.imzcloud.ibmammsap.local/repo/SUSE/Updates/SLE-SERVER/12-                 SP4/x86_64/update?credentials=SMT-http_CHE01AMMSMT01_imzcloud_ibmammsap_local] Repository already exists.

If you see the above you may need to remove that repo and then proceed.
Validate if the server have enough free disk space available before start the upgrade process. The “/var” file system should be has at least a 10% of free space.
Verify and confirm are you have a snapshot or full backup of it.
The pHanas are physical servers with a huge amount of RAM memory and storage due to these features the estimate time to patch it a single server could be take at least two hours since per a single reboot reboot it will takes a lot of time time in some scenarios.
Validate that the server is available via console (SoftLayer portal, IMM, Vmware Cosole).
Validate if you already had the Operating System root password.
Validate if the chef-client command runs without any errors.
Validate and configure (if needed) all the required repositories to be used during the planned activities.
Check with TSM when the last successful backup was taken.

how to apply patch on Hana SuSe 12.2
Step 1
running prechecks and confirm all backups running successful
Step 2
confirm SUSEConnect running fine and have direction to internal server of IBM
Step 3
use 'screen' to running following commands if you connect for ssh
for patch SUSE server use command 'zypper patch'
Step 4
Upgrade SUSE to SP4 use command 'zypper migrate'
Step 5
Proceed to restart server 'shutdown -r now'
Step 6
Please verify time zone if is different please go to step 6.1
verify in prechecks the correct time zone for example UTC
step 6.1
date
step 6.2
verify symbolic link
ls -la /etc/localtime
Step 6.3
remove symbolic link
sudo rm -rf /etc/localtime
step 6.4
create new symbolic link
sudo ln -s /usr/share/zoneinfo/America/UTC /etc/localtime
verify again with date
step 7
running post check and verify SP from SUS
cat /etc/os-release


refresh, ref 	Refresh all repositories. 	zypper ref
refresh-services, refs 	Refresh all services. 	zypper refs
list-updates, lu 	List available updates. 	zypper lu
list-patches, lp 	List needed patches. 	zypper lp
update, up 	Update installed packages with newer versions. 	zypper up
ps 	List running processes which might still use files and libraries deleted by recent upgrades. 	zypper ps -s

post patch

cat /etc/os-release ; uname -a ; date ; cat /etc/sysconfig/clock

vmware-config-tools.pl --default

VMtools/vmwaretools in SuSE
check and ensure latest version of vmtool is installed

refer for zypper commands
https://www.tecmint.com/zypper-commands-to-manage-suse-linux-package-management/


Patching SLES12 SP2 to SP4
https://blog.dbi-services.com/going-from-sles12-sp2-to-sles12-sp3-online/
https://kerneltalks.com/linux/how-to-upgrade-suse-12-sp1-to-sp3-or-sp4/

take a snapshot pre patching

Apply latest patch - zypper patch
Once all is patched make sure you have the zypper-migration-plugin installed on your system, if not install - zypper install zypper-migration-plugin
You can see list of service pack upgrades for your system.
You can see migration plugin gave us choice to jump from SP1 to SP2 or SP3 or SP4. Enter numeric against your choice and then it will upgrade related packages on your system
zypper migration
reboot


# uptime

Displays how long the server has been running since the previous reboot.

If the result is greater than 180 days, the engineer should reboot the server prior to applying the OS patches.  See Detailed Execution Steps.

It also displays load averages.  If greater than 2.xx is shown, rebooting the device may help.  Most devices will have a load average of 0.xx.

 

# date
Displays the current date and time zone.


# grep -i zone /etc/sysconfig/clock
Displays the system’s time zone configuration.  This file does not exist on RHEL 7 devices.
 

# ls -l /etc/localtime
Displays the file details for localtime.
 

# for i in $(grep -v ^# /etc/fstab | awk {'print $2'} | sort | grep -v ^swap$ ); do mountpoint -q $i || echo "$i not mounted" ; done
Displays any missing mountpoints.
 

# df -h
Displays volume sizes and free space.
 

# yum history
Displays the last x yum patching events.
 

# yum list updates
Displays packages ready for update.
 

# zypper repos
Displays zypper repositories for patching.
 

# zypper list-updates | cut -s -d"|" -f3,4,5
Displays list of available package updates.
 

# route -n
Displays active routes on the system.


# which salt-call
Displays program directory path.


# salt-call grains.item nodename host fqdn
Verifies connection to Salt Master and returns system host information.


For SuSE:

# uptime

To confirm server had a full reboot.

# date
# grep -i zone /etc/sysconfig/clock
# ls -l /etc/localtime
Compare with pre-check to verify date, time, and Time Zone didn’t change.
If Time Zone changed, change it to match pre-check results.

 

# df -h
Verify unused volume space.

# cut -d "|" -f 1-4 -s --output-delimiter " | " /var/log/zypp/history | grep -v " radd "
To display most recent zypper update history.

 
# zypper list-updates | cut -s -d"|" -f3,4,5
To display any package updates not completed by Salt.
Use zypper to manually update packages from output.


# salt-call ibm_inventory.get
Display post-patching package status.



Upgrade SUSE from 12 SP2 to 12 SP4	first done by Mihai Frant Albert (Trio B1 EMEA SAP Client - Linux AHT)

1.1) Take OS prechecks
1.2) zypper refresh; zypper in zypper-migration-plugin
1.3)zypper --no-refresh patch --updatestack-only
1.4) Check if kernel changes, then reboot if it is necessary

2) Execute the zypper migration to do the upgrade from 12.2 to 12.4

2.1) zypper migration
2.2) shutdown -rf now


#zypper migration
 Select 1 (SP4)
 Read and agree license agreement
3e) Re-initiate chef client
#cp -rp /etc/krb5.keytab /tmp/key_bkp_krb5
#service sssd stop; rm -rf /var/lib/sss/db/*;rm /etc/krb5.keytab;kdestroy;chef-client
3f) Set root login for emergency
#vi /etc/ssh/sshd_config
PermitRootLogin yes
#systemctl reload sshd
#cp -rp /etc/shadow /etc/shadow_CHG0153687
#passwd 
Use password : <any simple password, eg - ibm123#>
Reboot the server
#shutdown -rf now



IBM SOP for SuSE SP2 to SP4 upgrade	KB0013069
https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsys_kb_id%3Da255a5cf1bde0910204965f0b24bcb29

via yast

KB0015503
https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsys_kb_id%3Da89752261b1570108d1dc9d0604bcb91




SP2 to SP4 steps taken by Mihai in his first upgrade
zypper refresh; zypper in zypper-migration-plugin
zypper --no-refresh patch --updatestack-only
zypper migration
shutdown -rf now


Post update, the ssh login is slow and switching the id is also slow.
To fix it
After applying patch process for upgrading from SuSE 12 SP2 to SP4 the authentication process via SSH takes so long.
-This issue we already fix executing the follow commands:
service sssd stop;rm -rf /var/lib/sss/db/* ;rm -rf /etc/krb5.keytab ; kdestroy;chef-client; rm -rf /tmp/krb*

https://github.kyndryl.net/CMS/cms-chef/issues/3872
https://github.kyndryl.net/CMS/cms-chef/issues/4409


https://github.kyndryl.net/CMS/Platform-Support/issues/new/choose   for ansible issues
--------------------------------------------------------------------------------------------------------------------------------

SAP HANA HA Operation Guide:  https://github.ibm.com/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/README.md


------------------------------------------------------------------------------------------------------------------------------

COnfiguring threshold in Nagios

github link for nagios
https://github.kyndryl.net/cmas-nagios-dev/IBM_UNIX_Unified_Agent/issues  JasonYao



https://github.kyndryl.net/cmas-nagios-dev/IBM_UNIX_Unified_Agent/wiki/Agent:-FAQ

-------------------------------------------------------------------------------------------------------------------------------------
Zombie process

Find the zombie :

			ps axo stat,ppid,pid,comm | grep -w defunct

ps -ef |grep -i defunct

a@SERVER:~$ ps aux | grep 'Z'

What you get is Zombies and anything else with a Z in it, so you will also get the grep:

USER       PID     %CPU %MEM  VSZ    RSS TTY      STAT START   TIME COMMAND
usera      13572   0.0  0.0   7628   992 pts/2    S+   19:40   0:00 grep --color=auto Z
usera      93572   0.0  0.0   0      0   ??       Z    19:40   0:00 something
Find the zombie's parent:

a@SERVER:~$ pstree -p -s 93572



DEAD processes
ps aux --sort -rss

process id to process detail

ps -p <PID> -o comm=


Please note that processes that are in 'D' state, or 'uninterruptible sleep' are actually waiting for some IO operations or other kernel operations that modify the process's address space or memory content (for instance allocating memory or retrieving data from disk during a page fault).
These processes cannot be safely interrupted and will remain in this state until the operation completes successfully.
If the operation does not complete, a reboot would be necessary.

However, it would be expected to see processes going into the D state and then coming out of it on a pretty busy system.

Since you mentioned about a cifs related issue, we should address that first.

You can refer to the below article for more information regarding this:
https://urldefense.proofpoint.com/v2/url?u=https-3A__access.redhat.com_solutions_2972&d=DwICaQ&c=jf_iaSHvJObTbx-siA1ZOg&r=1Crn7OCYVmuFIhTF0TlyvcuPE6X2Ag26bLNYMD7wmUo&m=CQtfu91i0nm6vPi0PLWVCqY8YBhm-7Ytm2672QlF8VI&s=_XPP14KMT0rMUSVfPbf9yN3aN-qPafJoGLZWmmlmLfM&e= 



Is there a way to kill a process in the 'Z' or 'D' state without a reboot?
 SOLUTION VERIFIED - Updated April 8 2014 at 8:06 AM - English
Environment
Red Hat Enterprise Linux 4
Red Hat Enterprise Linux 5
Red Hat Enterprise Linux 6
Issue
Is there a way to kill a process in 'Z' (zombie) or 'D' (uninterruptible sleep) state without rebooting the system?
Resolution
Processes may exist in a number of states. These are reported by commands such as top and ps and indicate whether the process is running ('R'), sleeping ('S'), stopped ('T'), or in one of two special system states: zombie ('Z') and uninterruptible sleep ('D'). The zombie state is used during process termination - when a thread enters this state it is no longer running and only minimal context information is retained by the kernel.

Processes in either 'R' or 'S' state will respond to signals such as SIGTERM or SIGKILL, normally resulting in process termination. Processes in either the 'Z' or 'D' state will not respond to signals: in the case of processes in uninterruptible sleep, any signals sent while the task is blocked will be delivered to the process as soon as it returns to either the 'R' or the 'S' state (normally once IO or other kernel activity is complete).

For further information on process states and runtime properties refer to the documentation for the procfs virtual file system in man 8 proc.

The first process ID (PID 1) is always assigned to the init process. This is the process responsible (directly or indirectly) for starting all other processes on the system and manages changes to system run states (for example rebooting or shutting down the system). One of the supervisory roles played by the init process is the monitoring and cleaning up of orphaned zombie processes in the system:

Whenever a process exits, the kernel retains part of the process's context (the task_struct) in order to be able to report exit status and statistics information back to the creator of the process. Processes that are in this state are conventionally referred to as zombie processes and are indicated by the state identifier 'Z'. Programs that create new processes can use the wait(2) family of system calls in order to retrieve this state information.

In the case that a process exits before one or more of its children the child tasks become orphaned. In this situation the task_struct would be retained indefinitely, consuming kernel memory resources, and potentially limiting the number of additional processes (or threads) that can be started on the system.

To prevent this leading to resource problems and starvation these processes are 'adopted' by the init task. The init task periodically checks for the existence of these orphans and calls wait(2) in order to clean them up. Once this takes place the kernel is able to discard the process state information and free the memory that it was consuming.

If you see zombie processes with a parent different than init (can be inspected with ps -o <pid> command) persisting for a long time, it may be you encountered a bug. Contact the vendor who provided you with problematic program. Otherwise zombie processes should be cleaned up by init.

This is distinct from processes that are in 'D' state, or 'uninterruptible sleep'. This process state is used to suspend a process while operations that would prevent it continuing take place. This includes IO operations and other kernel operations that modify the process's address space or memory content (for instance allocating memory or retrieving data from disk during a page fault). These processes cannot be safely interrupted and will remain in this state until the operation either completes successfully or fails with an error.

If operations do not complete due to a hardware or software fault (for example network connectivity problems) it may not be possible to eliminate all processes in 'D' state without rebooting.

If large numbers of processes are in 'Z' or 'D' state, or if processes are remaining in 'Z' or 'D' states for excessive periods of time, this may indicate a functional or capacity problem with the system. Further analysis by Red Hat Global Support Services may be required to determine the root cause for such behaviour.

-------------------------------------------------------------------------------------------------------------

sssd.conf

cat /etc/sssd/sssd.conf



process id to process detail

ps -p <PID> -o comm=

-----------------------------------------------------------------------------------------------

User management


change the user's home directory:
usermod -d /newhome/username username
usermod is the command to edit an existing user.
-d (abbreviation for --home) will change the user's home directory.


Change the user's home directory + Move the contents of the user's current directory:
usermod -d -m /newhome/username username
-m (abbreviation for --move-home) will move the content from the user's current directory to the new directory.


edit in the /etc/passwd dirctory the new home directory

-----------------------------------------------------------------------------------------------------------

Compare 2 folders


There is no reason to write a script file, there are commands to do this without scripting.

The command diff will show you the differences:

 diff -r dir1/ dir2/ 
(-r = Recursively compare any subdirectories found, see the Manual) will print the list of the files which are located only in either directory.

If you also want to check whether files with the same name are also identical in content, then you should use

diff --brief -r dir1/ dir2/
(--brief = Output only whether files differ).

If you want to see the differences also for files which exist in only one directory, treating their counterparts as empty, you may use

diff --brief -Nr dir1/ dir2/
(-N = Treat absent files as empty).

If you want to carry out the operation, the command

cp -Rnl dir1/ dir2/
will do it for you. Notice that -R = copy directories recursively (again from the Manual), while -n = do not overwrite an existing file.

------------------------------------------------------------------------------------------------------------

umask for setting permission of any user

a user needs to have owner like access to any folder and subfoler. Even with the permission change with chmod the existing folder gets those permissions but the new files created gets the default permissions. To fix it, su - <user> then go to the /home/<user>/.bashrc and .profile files and add the umask 002 for 775 permission (umask is 777- the permission u want to set so in this case to set 775 the umask is 002)

Edit the file, save and test
https://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html 


https://linuxize.com/post/umask-command-in-linux/


To make the changes permanent, set the new umask value in a global configuration file like /etc/profile file which will affect all users or in a user’s shell configuration files such as ~/.profile, ~/.bashrc or ~/.zshrc, which will affect only the user. The user files have precedence over the global files.

To change the default umask value permanently for a specific user, you need to modify the .bashrc file in the user’s home directory. For example, to change the default umask for user bob, just add the following line at the end of the /home/bob/.bashrc file:

UMASK explained
https://geek-university.com/linux/set-the-default-permissions-for-newly-created-files/

https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_basic_system_settings/assembly_managing-file-permissions_configuring-basic-system-settings

-----------------------------------------------------------------------------------------------------------

SL escalation
 https://cloud.ibm.com/docs/get-support?topic=get-support-escalation


Physical infra
BHT team DOESN'T support the following activites:
- Login Issues on VMs
- IBM Cloud portal access or permissions
- Locating VMs (Hana/Non-Hana)
- VPN issues
- VM vmotioning
- Snapshot issues
- Vsphere client issues on your windows/jumpbox
- SRM replication (configuration/start/stop/pause)
Our main responsibilities are with the ESXi servers and to keep VMWare suite up and running.
The BHT team is only in AG region. After 5:00 PM EST please engage oncall for SEV1 issues.
This slack channel is not monitored after weekdays 5:00PM EST or on weekends.
----------------------------------------------------------------------------------------------------------

cat -b for displaying the file with line no

------------------------------------------------------------------

to check mounts 
mount -fav

---------------------------------------------------------------------------

DO not signoff the below user form Windows server in any circumstrances

----- Original message -----
From: Andre Luis de Andrade Frauches/Brazil/IBM
To: TR-SAP-TRIBE-B@WWPDL, TR-SAP-TRIBE-A@WWPDL, TR-SAP-TRIBE-C@WWPDL
Cc: Demian Bolduc/Wichita/IBM@IBMUS, Lim Diaz/Costa Rica/IBM@IBMCR, Russ D Johnson/Sacramento/IBM@IBMUS, Muhammad N Habib/Dubuque/IBM@IBMUS, Sarita Kumar/San Jose/IBM@IBMUS, Yogamoorthi Thirunavukkarasu/India/IBM@IBMIN, Lizbeth Vega/Costa Rica/IBM@IBM
Subject: Z0J - Farmoquimica: Important Advice on the Evolutio System on the IBMACT1 VM
Date: Thu, Dec 12, 2019 8:58 PM
 
Hi ALL

I'm sending this email just to get us all aligned.

In IBMACT1 VM Farmoquimica Z0J has a very important system that is started by a user called "evolutio". 
Due to characteristics of the current installation of this system, this user needs to be logged in to a session on TS and cannot be logged out under any circumstances. 

Please advise all teams that under no circumstances can we disconnect the "evolutio" user session on vm IBMACT1. 

The system needs that this user keep with the TS session.

Advise your teams , do not drop the session "evolutio", this session needs to be avaiable.
-----------------------------------------------------------------------------------------------------------

OS parameter

cat /proc/sys/net/ipv4/tcp_keepalive_time

---------------------------------------------------------------------------------------------------

Do It Yourself Password Resets (NEW) -  Approval has been given for trio leaders and OS administrators with root / administrator access to perform password resets for their team members and customers  instead of waiting  for a member of the IAM team to complete your ticket. If you would like to avoid the wait, please go to this link to see the process: https://apps.na.collabserv.com/wikis/home?lang=en-us#!/wiki/W985ab17cc25b_4a48_9605_7f6170f47722/page/Password%20Resets%20-%20Do%20it%20Yourself%20process   PLEASE FOLLOW THE DOCUMENTED PROCESS TO AVOID COMPLIANCE ISSUES!

---------------------------------------------------------------------------------------------------
Deleting older files greater than X days

find /hana/shared/CHP/HDB00/backup/log -type f "*.log" -type f -mtime +1295> -exec rm -f {} \;

----------------------------------------------------------------------------------------------------
HANA patching

SAP SLES / RHEL HANA DB Patching

Hello Team Linux Admin -

All of your are associated with SAP Segment Tribe A, B, C and could be involved in the upcoming Q1'2020 OS Patching.  

I wanted to ensure that you are all aware that something we will do in Q1 that we have not done before is include SLES HANA DB and RHEL HANA DB OS patching.

It is important that you all understand the following.

SLES HANA DB both 1.x & 3.x  

 
1.x add the following

 HANA 1.0 & HANA 2.0 - We can upgrade SLES12 SP2 and/or to latest versions in SP2


3.x add the following:

for SAP HANA 1.0 systems where revision is 122.22 and newer => we can upgrade SLES12 SP2 to SLES12 SP4
for SAP HANA 1.0 systems where revision is 122.21 and below => we can patch SLES12 SP2 to latest versions in SP2

****** Once we got to the latest SP level as above then we ONLY APPLY LATEST SECURITY patches on that version ..   e.g  SLES SP2,   SLES SP4

for SAP HANA 2.0 systems where revision is 35 and newer => we can upgrade SLES12 SP2 to SLES12 SP4
for SAP HANA 2.0 systems where revision is 34 and below => we can patch SLES12 SP2 to latest versions in SP2

****** Once we got to the latest SP level as above then we ONLY APPLY LATEST SECURITY patches on that version ..   e.g  SLES SP2,   SLES SP4

RLES HANA DB - 3.x only

We will ONLY patch the LATEST SECURITY patches on the SAME LEVEL...  

Thank you!!! Carrie

----------------------------------------------------------------------------------------------------------------------

Path to edit monitoring threshold

MOnitoing team quueeu in SNOW  MA-ASGN-INF-NAGIOS-MON

/usr/local/{framework}/etc/cmas_thresholds.cfg
or  usr/local/ncpa/etc


go through below directories where you will find respective *.cfg files with entries for alert check.. you just need to edit that entries as per your requirement and then restart the agent.

SLES on x86_64
/usr/local/ncpa/etc/*.d



SLES on POWER HANA
/usr/local/nagiosPA/etc/*.d


monitoring team contacts
Jason Yao/Annapolis/IBM@IBMUS
Vivek Bheeman/India/IBM@IBMMail

---------------------------------------------------------------------------------------------------------

symlink

https://linuxize.com/post/how-to-create-symbolic-links-in-linux-using-the-ln-command/
https://shapeshed.com/unix-ln/

https://www.unixtutorial.org/lrwxrwxrwx/

n the following example, we are creating a symbolic link named my_link.txt to a file named my_file.txt:

ln -s my_file.txt my_link.txt
To verify that the symlink was successfully created, use the ls command:

ls -l my_link.txt

lrwxrwxrwx 1 linuxize users  4 Nov  2 23:03  my_link.txt -> my_file.txt

For example, if you want to create a symbolic link from the /mnt/my_drive/movies directory to the ~/my_movies directory you would run:

ln -s /mnt/my_drive/movies ~/my_movies

If you try to create a symbolic link that already exists, the ln command will print an error message.


ln -s my_file.txt my_link.txt
ln: failed to create symbolic link 'my_link.txt': File exists
To overwrite the destination path of the symlink, use the -f (--force) option.

ln -sf my_file.txt my_link.txt
Removing Symlinks
To delete/remove symbolic links use either the unlink or rm command.

The syntax of the unlink is very simple:

unlink symlink_to_remove
Copy
Removing a symbolic link using the rm command is the same as when removing a file:

rm symlink_to_remove
Copy
No matter which command you use, when removing a symbolic link not append the / trailing slash at the end of its name.

If you delete or move the source file to a different location, the symbolic file will be left dangling (broken) and should be removed.

---------------------------------------------------------------------------------------------------------
add disk not possible on
for HANA Disk full and can't extend space so, below SAP not is useful
https://launchpad.support.sap.com/#/notes/1679938

https://answers.sap.com/questions/10170047/log-volume-is-full.html 

------------------------------------------------------------------------------------------------------------

Powercli to find snapshots and delete them

If you want a fast way to find snapshot in  your vCenter environment, you can use PowerCLI and run a command similar to this:

get-vm | get-snapshot | fl

If you want to remove them all:

get-vm | get-snapshot | remove-snapshot 

----------------------------------------------------------------------------------

Installing kdump
Verify the kexec-tools package is installed:

Raw
# rpm -q kexec-tools
If it is not installed, proceed to install it via yum:

Raw
# yum install kexec-tools


https://www.suse.com/support/kb/doc/?id=000016171

https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-tuning-kexec.html



-----------------------------------------------------------------------------------------
How Do You Troubleshoot the NFS Message About “Transaction order is cyclic”?

Problem scenario
You try to start the NFS service with a command like this: sudo systemctl start nfs.service

However you get an error like this:  "Failed to start nfs.service: Transaction order is cyclic.  See system logs for details.  See system logs and 'systemctl status nfs.service' for details."

Possible Solution #1
Modify the /etc/fstab file.  Is it corrupt?  You may need to remove recently added entries and reboot the server.

Possible Solution #2
You may want to look at the system file for nfs.service.  Was it recently modified?  You may want to add this stanza:
DefaultDependencies=no

-------------------------------------------------------------------------------------
VM search
http://146.89.3.136:8080/AssetMCO/mco.jsp 

https://capacity-manager.bluemix.net/search

------------------------------------------------------------------------------------

Salt Minion troubleshooting

https://ibmma.service-now.com/kb_view.do?sys_kb_id=d65e9ff8db544490e1969239db961942

Linux OS Patching using Ozone
https://ibmma.service-now.com/kb_view.do?sys_kb_id=cf488a2c1b118c940c5dca292a4bcb4c

------------------------------------------------------------------------------------------

Chef-client on HANA erver failed fix

'https://github.ibm.com/CMS/cms-sq-sap-hana-pe-automation_hana/wiki/Operations:-check-create-adjust-hana-users'

---------------------------------------------------------------------------------------------------------

Automation Patching

https://github.ibm.com/CMS/sap-ops-automation-docs/wiki/3.x-Patching-Process

slack for automated change
#cms-automation-script

-------------------------------------------------------------------------------------------------
defaults related to password aging are set in '/etc/login.defs' file

----------------------------------------------------------------------------------------
Task: Find out who is monopolizing or eating the CPUs

Finally, you need to determine which process is monopolizing or eating the CPUs. Following command will displays the top 10 CPU users on the Linux system.
# ps -eo pcpu,pid,user,args | sort -k 1 -r | head -10

OR
# ps -eo pcpu,pid,user,args | sort -r -k1 | less 

-----------------------------------------------------------------------------------

All user in a server

awk -F: '$3 > 500 {print $1}' /etc/passwd
--------------------------------------------------------------------

Login issue error say keytab issue sssd stopped not starting
copied the keytab file from another server


tsig error with server: tsig verify failure suse
 rm -rf /tmp/krb*


Issue with satellite
chef-client -n linuxad_auth   can be used a s workaround

----------------------------------------------------------------------------

NFS options

Client options include (defaults are listed first):
ro / rw :
a) ro : allow clients read only access to the share.
b) rw : allow clients read write access to the share.
sync / async :
a) sync : NFS server replies to request only after changes made by previous request are written to disk.
b) async : specifies that the server does not have to wait.
wdelay / no_wdelay
a) wdelay : NFS server delays committing write requests when it suspects another write request is imminent.
b) no_wdelay : use this option to disable to the delay. no_wdelay option can only be enabled if default sync option is enabled.
no_all_squash / all_squash :
a) no_all_squash : does not change the mapping of remote users.
b) all_squash : to squash all remote users including root.
root_squash / no_root_squash :
a) root_squash : prevent root users connected remotely from having root access. Effectively squashing remote root privileges.
b) no_root_squash : disable root squashing.

“mount.nfs: access denied by server while mounting” – how to resolve
https://www.thegeekdiary.com/mount-nfs-access-denied-by-server-while-mounting-how-to-resolve/

https://access.redhat.com/solutions/3773891



NFS mounted readonly

As Brian said, a parent export can override a child export. But you can solve this by adding priorities to your exports. So, using Brian's example, this would solve the problem:

/NFS_ROOT *(ro,fsid=2)
/NFS_ROOT/SHARE1 *(rw,fsid=1)

fsid=2  

NFS server ke /etc/exports main  

/Bank *(rw,sync,no_subtree_check,insecure,no_root_squash)  

Added fsid=2 parameter to above  

ref url
https://serverfault.com/questions/532760/why-is-an-nfs-server-mounted-as-rw-returning-read-only-filesystem-errors 
---------------------------------------------------------------------------------------

False alert

You can reach out to the FRUN ( Slack #sq-sap-c-monitoring ) team if you need help troubleshooting or think it's a false alert.

--------------------------------------------------------------------------------------------------------

Remove VM from protection group

On the Site Recovery home tab, select a site pair and click View Details.
    Select the Protection Groups tab, select a protection group, and on the right pane, click the Virtual Machines tab.
    Right-click a virtual machine and select Remove Protection.
    Click Yes to confirm the removal of protection from the virtual machine.   

---------------------------------------------------------------------------------------------------------------

Many a times we have noticed flood of  Ping Availability CRITICAL - x.x.x.x: rta nan, lost 100%  tickets

For such tickets, Please check if the VM/Server is pinging to the Nagios passive server.

For instance if the Nagios Passive server IP is 158.87.46.196, try pinging the IP from VM and if no response found let the network team know this.

Inorder to get the Nagios Passive server IP for a VM , search for the parent entry in /usr/local/ncpa/etc/ncpa.cfg
https://{nagios-passive-server-name-or-ip}/nrdp/

https://github.ibm.com/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/README.mdpacemaker
cat /usr/local/ncpa/etc/ncpa.cfg |grep -i parent


 C:\Program Files\NSClient++\ini   in \nsclient.ini file look for nagios ip

wget https://158.87.44.154/nrdp  if connects then close the ticket with uptime and date

this way you can find which passive node its connected and try to ping that IP from that VM if its not pinging then network team can help to troubleshoot.

Also make sure to verify that the VM is up and running.    

COntact Jannet David for help

for n/w contact in cmas-3x-nets-inc  nw team slack

SNOW assignment group for n/w MA-ASGN-INF-3x-SEI-NWK-FW

https://w3-connections.ibm.com/wikis/home?lang=en-us#%21/wiki/MHAS%20Nagios/page/Linux%20Troubleshooting
---------------------------------------------------------------------------------------------------------------

Listing all services and their status in linux
 service --status-all
  
Prole service is not starting, port being used.

Process using a port with pid - fuser 57321/tcp

agesvbq1hsrv1:/home/ibmrmalik # fuser 57321/tcp
57321/tcp:           24669
agesvbq1hsrv1:/home/ibmrmalik # ps -ef|grep 24669
root     12164 23188  0 15:49 pts/5    00:00:00 grep --color=auto 24669
bq1adm   24669   446 15  2019 ?        22-01:55:30 hdbnameserver

DB has to be restarted to fix it.


Engaged CICL OnCall personnels only via channel #cmas-globalcriticalincident-communicationleaders


KB on how to fix most common issues with HANA LOG backup failures.
 
A new section was added to cover when ProLE service gets hung and how to identify such behavior.
 
KB0012299


-----------------------------------------------------------------------------------------------------------

To Update the Password on PIM Tool: 
https://ispim.amm.ibmcloud.com/ispim/ui/#credVault
Login --> Manage Credentials --> Search for Resource Name & Login ID --> Select the row --> Click on 'EDIT'  

---------------------------------------------------------------------------------------------------------

AGEAS contact

"'John Luther Garcia'" <JohnLuther@troo.life>, = AGEAS end customer manger
 "Alok Chandak" <Alok.Chandak@msg-global.com>, = Application support manager  
 Satish Kumar Narayanasetti <Satish.Kumar.Narayanasetti@msg-global.com>
 Karen Samantha Robles <Karen.Samantha.Robles@msg-global.com>
 
 --------------------------------------------------------------------------------------------------
 
 salt minion error fix
 
    The Salt minion is not installed.
    The Salt minion is not running.
    The Salt minion is misconfigured.  A common misconfiguration is that the hostname of the minion does not match the name in ServiceNow.  This requires a custom grain to be set.
    The Salt minion cannot communicate with the Salt master.

If those four are not the problem then the Salt minion has not run inventory.  That can be fixed by running salt-call ibm_inventory.get as root on the minion.
 
-----------------------------------------------------------------------------------------------------------

Windows disk going offline as per the set group policy set

PS C:\Users\ibmsjaishankar> Get-StorageSetting | Select-Object NewDiskPolicy
NewDiskPolicy
-------------
OfflineShared
PS C:\Users\ibmsjaishankar> Set-StorageSetting -NewDiskPolicy OnlineAll
PS C:\Users\ibmsjaishankar> Get-StorageSetting | Select-Object NewDiskPolicy
NewDiskPolicy
-------------
OnlineAll
-----------------------------------------------------------------------------------------------------

Cluster basics

http://www.juliosblog.com/pacemaker-101-2/

the main difference immediately visible between putting all nodes in standby mode, and putting the cluster in maintenance mode, is that for the former case, it will stop all services, since there's no online node anymore, while for the later, services will stay as they were, started or not, on various nodes.
  
-----------------------------------------------------------------------------------------------------------
disk extension or addition in clustered server
refer the document for it

------------------------------------------------------------------------------------------------

File System Error Check ############################
Never run fsck on mounted partitions as it may damage the file system. Before attempting to check or repair file systems always unmount it first.
--------------------------------------------------------------------------------------------------
1. Umount to FS.
2. Run fsck
3. Once the file system is repaired, mount the partition

Repair Root File System

fsck cannot check the root file system on a running machine because it cannot be unmounted.

for root FS
Go into rescue mode.
init=/bin/sh ( when you press  e  and come to kernel  line ...instead  of 1  or S  use  init=/bin/sh )
e2fsck -f -y /dev/mapper/vg00_root  < -- if that solution doesn't work so, run below 

Options, if required or could not fixed by above solution.
mount | grep root
mount -o remount,rw /
mount -o rw,remount /
vi /etc/fstab and change the default values to 1 0 do not change for root entry.
exit
exit
reboot  

---------------------------------------------------------------------------------------------------

VMware backup fail  https://communities.vmware.com/thread/594423

quencing error

An error occurred while taking a snapshot: msg.snapshot.error-QUIESCINGERRO

login to the VM and uninstall the Volume Shadow Copy on VMware Tools from add remove and modify the instaled component
also start the virtual disk service(vds)

-----------------------------------------------------------------------------------

comment the line to 0 0 so, that reboot will done successfully and will skip to check during reboot 

-------------------------------------------------------------------------------------------------

chkconfig sshd on  to set to start the sssd service after booting for RHEL 6.x


netstat -antp | grep sshd | grep -i ESTABLISHED | wc -l

systemctl enable ssh  for RHEL 7.x

--------------------------------------------------------------------------------------------------
Statistics of a file
stat <file name>

[root@smdbdevd41 bin]$ stat dsm.sys
  File: `dsm.sys'
  Size: 2208            Blocks: 8          IO Block: 4096   regular file
Device: 803h/2051d      Inode: 925493      Links: 1
Access: (0775/-rwxrwxr-x)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2020-03-04 05:18:30.568814647 +0000
Modify: 2020-01-30 03:27:36.322976611 +0000
Change: 2020-01-30 03:27:36.329976429 +0000
-------------------------------------------------------------------------------------------

reset administrator pw for windows



Restart your computer and tap F8. Choose Safe Mode with Command Prompt. Try logging in there. If it still doesn't work, then go to step 15.

If you are able to login, once a command prompt pops up, type: net user administrator password /active:yes (you can specify whatever password you want for the administrator account.)

If you get a message saying "The command completed successfully", then restart your computer by typing shutdown -r

Boot up again pressing F8, but this time choose just Safe Mode.

You should be able to login as Administrator with the password you set in Step 2
----------------------------------------------------------------------------------------------

Cannot start a restored VM

An error was received from the ESX host while powering on VM bs5piprd_Restore.
Failed to start the virtual machine.
Cannot open the disk '/vmfs/volumes/4e3f8113-ca8bc3b7/bs5piprd_Restore/bs5piprd_Restore_11-000001.vmdk' or one of the snapshot disks it depends on.
-------------------------------------------------------------------------------------------------------
Direct root login
Enable root login over SSH:

    As root, edit the sshd_config file in /etc/ssh/sshd_config : nano /etc/ssh/sshd_config.
    Add a line in the Authentication section of the file that says PermitRootLogin yes . ...
    Save the updated /etc/ssh/sshd_config file.
    Restart the SSH server: service sshd restart.
    
	
Please keep in mind that  the  root password is excluded by default on SSH connections, so in order to work via SSH using rootyou would need to make a temporary change to  the folowing configuration  file   

/etc/ssh/sshd_config
then find and edit PermitRootLogin and set to yes as shown below


PermitRootLogin yes

 cat /etc/ssh/sshd_config | grep 'PermitRootLogin'
 sed -i 's/PermitRootLogin no/PermitRootLogin yes/g' /etc/ssh/sshd_config

 sed -i 's/PermitRootLogin yes/PermitRootLogin no/g' /etc/ssh/sshd_config


Then


service sshd restart

Be aware that this change in /etc/ssh/sshd_config will be reverted  20 to 30 minutes after  the server has joined the domain 
    ----------------------------------------------------------------------------------------------------------
    
    Login banner setting changes
    cd /etc/profile.d
    [root@svaq1srv0 profile.d]$ ls
colorls.csh  gnome-ssh-askpass.csh  lang.sh                    vim.csh
colorls.sh   gnome-ssh-askpass.sh   less.csh                   vim.sh
cvs.csh      IBMSAPmsg.sh           less.sh                    which2.sh
cvs.sh       IBMsinit.csh           qt.csh
glib2.csh    IBMsinit.sh            qt.sh
glib2.sh     lang.csh               udisks-bash-completion.sh
[root@svaq1srv0 profile.d]$ cat IBMSAPmsg.sh
export PS1="\[\e[1;36m\][\u@\h \W]\$ \[\e[m\]"
if [ ! -z "$SSH_CONNECTION" ]; then
echo "*******************************************************************************"
        printf '*    Server Type: \e[1;36m%-60s\e[m*\n' 'QA'
        printf '*       Hostname: \e[1;36m%-60s\e[m*\n' 'svaq1srv0'
        printf '*         CFN IP: \e[1;36m%-60s\e[m*\n' '10.70.110.18'
        printf '*         IFN IP: \e[1;36m%-60s\e[m*\n' '10.6.2.18'
        printf '*        SAP SID: \e[1;36m%-60s\e[m*\n' 'APQ'
echo "*******************************************************************************"

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Banner setup in SuSE
Edit the file /etc/ssh/sshd-banner to add the contents of your warning banner and save the file.

Edit  the file /etc/ssh/sshd_config. Add the following line to the end of the file:

Banner /etc/ssh/sshd-banner

Save the file and restart the sshd server with the command /etc/init.d/sshd restart

https://www.thegeekdiary.com/how-to-create-a-ssh-banner-in-centos-rhel-server/
In RHEL 7
Linux Login Banner on CentOS 6 / CentOS 7 / RHEl 7 / Oracle Linux 7

1. Create a /etc/mybanner file and fill it with your desired message as below

# vi /etc/mybanner

Save and Quit the mybanner file.


2. Edit /etc/ssh/sshd_config, to look like this Banner /etc/mybanner
113
114
115 # default banner path
116 Banner /etc/mybanner
117
118

3. Restart sshd service sshd restart

4 Test your session

-----------------------------
Banner setting

[root@npsv07 ibmsgaur]# cat /etc/profile.d/IBMSAPmsg.sh
export PS1="\[\e[0;93m\][\\u@\\h \\W]\\$\[\e[m\] "
if [ ! -z "$SSH_CONNECTION" ]; then
  printf '*    Server Type: \e[0;93m%-60s\e[m*\n' 'Development'
  printf '*       Hostname: \e[0;93m%-60s\e[m*\n' 'npsv07'
  printf '*         CFN IP: \e[0;93m%-60s\e[m*\n' '165.88.67.146'
  printf '*         IFN IP: \e[0;93m%-60s\e[m*\n' '10.151.0.146'
  printf '*        SAP SID: \e[0;93m%-60s\e[m*\n' 'GTD, JTD'
  echo "IMPORTANT NOTE: JTD ON THIS HOST DECOMMISSIONED - REF# CHG02388"                                     ---------------------edit the message in banner here
  echo '*******************************************************************************'
fi

----------------------------------------------------------------------------------------------------------

Linux disk mapping with scsi

ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[/]' '{print $4,"- SCSI",$7}' 

-----------------------------------------------------------------------------------------------------------

Unable to delete old VM snapshots

https://getsysadminblog.com/2017/04/21/how-to-fix-a-general-system-error-occurred-vim-fault-genericvmconfigfault-when-creating-or-removing-snapshots-in-vmware/

----------------------------------------------------------------------------------------------------

3x HANA servers exl

https://w3-connections.ibm.com/communities/service/html/communityview?communityUuid=d94692fc-4017-476f-be5d-db72cf4b2dc9


-----------------------------------------------------
Network
Madhusudhan Swamydass/India/Contr/IBM
Zubair Mohammed/US/Contr/IBM

---------------------------------------------------------
same can be used for any OS to boot form live CD

iso and rescue disks
jump server .5 E:\Linux_ISO
jump server .4 E:\ibmnrangarajan

New Jump server ips  
146.89.142.228 / 229

DAL13SAPJMP01.imzcloud.ibmammsap.local - 146.89.142.228  can now be accessed with 66.248.236.4

DAL13SAPJMP02.imzcloud.ibmammsap.local - 146.89.142.229 can now be accessed with 66.248.236.5


Recovery ISO on Chennai
[CHE01POOL1DS273]/systemrescuecd-x86-5.3.2.iso
[CHE01POOL1DS273]/ISO/systemrescuecd-x86-5.3.2.iso	
[CHE01POOL1DS274]/ISO/systemrescuecd-x86-5.3.2.iso
[CHE01POOL1DS322]/ISO/systemrescuecd-x86-5.3.2.iso
[CHE01POOL1DS345]/systemrescuecd-x86-5.3.2.iso

Recovery ISO in WDC
A0F0WDC04BCC215/ISO/systemrescuecd-x86-5.3.2.iso
[A0D4US026BCA102]/ISO/systemrescuecd-x86-5.3.2.iso
[A0ETUS016BCA192] ISO/systemrescuecd-x86-5.3.2.iso
A0DBUS026BCA101/ISO/systemrescuecd-x86-5.3.2.iso
A0DTUS026BCA013/ISO/systemrescuecd-x86-5.3.2.iso


Dal09
DAL09POOL1DS220/ISO/systemrescuecd-x86-5.3.2.iso
A0FAUS016BCC093/ISO/systemrescuecd-x86-5.3.2.iso
ammdal09custesx001_local/ISO/systemrescuecd-x86-5.3.2.iso
MS3US016BCC008/ISO/systemrescuecd-x86-5.3.2.iso
LZAUS016BCA095/ISO/systemrescuecd-x86-5.3.2.iso


Dal13
DAL13POOL1DS268/ISO/systemrescuecd-x86-5.3.2.iso
DAL13POOL1DS358/ISO/systemrescuecd-x86-5.3.2.iso
CTUDAL13BCB202_DR/ISO/systemrescuecd-x86-5.3.2.iso
DAL13POOL1POD1DSP455/ISO/systemrescuecd-x86-5.3.2.iso
DAL13POOL2POD1DSP472/ISO/systemrescuecd-x86-5.3.2.iso


LON02 -
A0HEUK016BCB222/ISO/systemrescuecd-x86-5.3.2.iso
A0HEUK016BCB202/ISO/systemrescuecd-x86-5.3.2.iso
AMMLON02TST17/ISO/systemrescuecd-x86-5.3.2.iso
AMMLON02TST16/ISO/systemrescuecd-x86-5.3.2.iso
AMMLON02TST15/ISO/systemrescuecd-x86-5.3.2.iso
[LON02POOL2DS259] systemrescuecd-x86-5.3.2.iso


Toronto
A0D3CA016BCA011/ISO/systemrescuecd-x86-5.3.2.iso
A0E3CA016BCA001/ISO/systemrescuecd-x86-5.3.2.iso
A0E3CA016BCA101/ISO/systemrescuecd-x86-5.3.2.iso
A0E3CA016BCA201/ISO/systemrescuecd-x86-5.3.2.iso
407CA016BCA154/ISO/systemrescuecd-x86-5.3.2.iso

Lon06
LON06TESTDSE162/ISO/systemrescuecd-x86-5.3.2.iso
LON06TESTDSE161/ISO/systemrescuecd-x86-5.3.2.iso
LON06TESTDSE163/ISO/systemrescuecd-x86-5.3.2.iso
LON06TESTDSE164/ISO/systemrescuecd-x86-5.3.2.iso
LON06TESTDSE165/ISO/systemrescuecd-x86-5.3.2.iso

Sao Paulo
AMMSAO01IMZDSP469/ISO/systemrescuecd-x86-5.3.2.iso
SAO01POOL1DSE146/ISO/systemrescuecd-x86-5.3.2.iso
CONSAO01PCA129/ISO/systemrescuecd-x86-5.3.2.iso
SAO01POOL1POD1DSP361/ISO/systemrescuecd-x86-5.3.2.iso
SAO01POOL1POD1DSP378/ISO/systemrescuecd-x86-5.3.2.iso


Paris
AMMPAR01IMZ235/ISO/systemrescuecd-x86-5.3.2.iso
AMMPAR01IMZ236/ISO/systemrescuecd-x86-5.3.2.iso
CI3PAR01BCA50/ISO/systemrescuecd-x86-5.3.2.iso
DASPAR01BCA152/ISO/systemrescuecd-x86-5.3.2.iso
PAR01POOL1POD1DS370DR/ISO/systemrescuecd-x86-5.3.2.iso


Montreal
A0E3MON01DR187/ISO/systemrescuecd-x86-5.3.2.iso
BRPMON01BCA44/ISO/systemrescuecd-x86-5.3.2.iso
MTSMON01BCA102/ISO/systemrescuecd-x86-5.3.2.iso


Frankfurt
A0CVDE016BCA136/ISO/systemrescuecd-x86-5.3.2.iso
A0D8DE016BCA142/ISO/systemrescuecd-x86-5.3.2.iso
A0GIDE016BCA125/ISO/systemrescuecd-x86-5.3.2.iso
FRA02POOL1DS211


TOK
TOK02POOL10DS1/ISO/systemrescuecd-x86-5.3.2.iso
TOK02POOL3DS2/systemrescuecd-x86-5.3.2.iso
TOK02POOL5DS2/systemrescuecd-x86-5.3.2.iso


SYD
SYD04POOL1DS1/ISO/systemrescuecd-x86-5.3.2.iso
SYD04POOL1DS2/systemrescuecd-x86-5.3.2.iso
SYD04POOL2DS1/systemrescuecd-x86-5.3.2.iso


Hong Kong
A0CTHK016BCA186/ISO/systemrescuecd-x86-5.3.2.iso
A0CTHK016BCA187/ISO/systemrescuecd-x86-5.3.2.iso
A0EAHK016BCA127]/ISO/systemrescuecd-x86-5.3.2.iso
[LBDHKG02BCA191]/ISO/systemrescuecd-x86-5.3.2.iso


AMMWDC04IMZDSP464 on WDC


A0CTSG016BCB106  A0EASG016BCB193	SNG01POOL1DS319 on SNG
SNG01POOL1DS290   SLES iso  SNG



Reinstalling the Boot Loader
In many cases, the GRUB boot loader can mistakenly be deleted, corrupted, or replaced by other operating systems.
The following steps detail the process on how GRUB is reinstalled on the master boot record:
Boot the system from an installation boot medium.
Type linux rescue at the installation boot prompt to enter the rescue environment.
Type chroot /mnt/sysimage to mount the root partition.
Type /sbin/grub-install bootpart to reinstall the GRUB boot loader, where bootpart is the boot partition (typically, /dev/sda).
Review the /boot/grub/grub.conf file, as additional entries may be needed for GRUB to control additional operating systems.
Reboot the system.


Booting into rescue mode
https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/installation_guide/ap-rescuemode

---------------------------------------------------------------------------

[root@SNG01AMMCHEF01 ~]# knife node show sjmdfpaa01.imzcloud.ibmammsap.local -a policy_linux_pass_max_age

------------------------------------------------------------------------------------------
ACcount getting locked when performing bulkload
I checked the pam configuration. I would suggest you to modify the pam_tally2 line in /etc/pam.d/system-auth and /etc/pam.d/password-auth file.

From:
auth    required    pam_tally2.so deny=5 unlock_time=3600

To:
auth    required    pam_tally2.so deny=5 unlock_time=3600 serialize

As per the man page,

serialize --

Serialize access to the tally file using locks. This option might be used only for non-multithreaded services because it depends on the fcntl locking of the tally file. Also it is a good idea to use this option only in such configurations where the time between auth phase and account or setcred phase is not dependent on the authenticating client. Otherwise the authenticating client will be able to prevent simultaneous authentications by the same user by
simply artificially prolonging the time the file record lock is held.


|| For the pam_tally module what should I be checking and where

The module "pam_tally.so" is deprecated. The module currently in use is "pam_tally2.so".

We see traces of module "pam_tally.so" in PAM file "/etc/pam.d/password-auth"

/etc/pam.d/password-auth
===
....
session     optional      pam_keyinit.so revoke
session     required      pam_limits.so
session     optional      pam_oddjob_mkhomedir.so umask=0077
session     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid
session     required      pam_unix.so
session     optional      pam_sss.so
auth required pam_tally.so deny=5            <<<<<<<<<------------------- "pam_tally.so"
===

The PAM order sequence is important. The "auth" stack should not be mentioned in "session" stack.

Kindly comment out the line as shown

/etc/pam.d/password-auth and /etc/pam.d/system-auth

/etc/pam.d/password-auth
===
....
session     optional      pam_keyinit.so revoke
session     required      pam_limits.so
session     optional      pam_oddjob_mkhomedir.so umask=0077
session     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid
session     required      pam_unix.so
session     optional      pam_sss.so
#auth required pam_tally.so deny=5            <<<<<<<<<------------------- Comment Out

----------------------------------------------------------------------------------------------------

checking kernel values

https://linoxide.com/how-tos/command-to-show-shared-memory-settings/

---------------------------------------------------------------------------------------------------

Files deleted/moved but space not released
https://kerneltalks.com/troubleshooting/space-is-not-released-after-deleting-files-in-linux/

------------------------------------------------------------------------------

3.x vHANA latest sheet

https://kyndryl.sharepoint.com/:x:/t/ManagedAppsApplicationPlatformServices-kyndryl-capacity-management-internal/Ebd9fwLP_ihAvZXKaxE7eBgB0dr1uwl_r2ys69TASlMnng

edited the file '3.x HANA Servers Tracker.xlsx'.

new link 
https://kyndryl.sharepoint.com/:x:/t/ManagedAppsApplicationPlatformServices-kyndryl-capacity-management-internal/Ebd9fwLP_ihAvZXKaxE7eBgB0dr1uwl_r2ys69TASlMnng

---------------------------------------------------------------------------------------
Patching change OS steps 

OS Engineer
-> Task-1:  OS:: Start-Communication
->Perform the VMware snapshot (involved servers) before scheduling the automation.
-> Schedule the patching, via automation through the following link: https://sapops.containers.ciocloudservices.ibm.com
SOP: 3.x Patching process: https://github.ibm.com/CMS/sap-ops-automation-docs/wiki/3.x-Patching-Process
->Execute the automation change immediately and check the changes notes with SAP engineer to confirm if process completed successfully/fails.
->Perform the post steps (customer communication and validation checks)
->If automation change fails continue the manual patching and mention the automation CH# in this change's notes.

-------------------------------------------------------------------------------------------------------

install unrar software

--------------- On 64-bit --------------- 
# cd /tmp
# wget https://www.rarlab.com/rar/rarlinux-x64-5.5.0.tar.gz
# tar -zxvf rarlinux-x64-5.5.0.tar.gz
# cd rar
# cp -v rar unrar /usr/local/bin/

--------------- On 32-bit --------------- 
# cd /tmp
# wget https://www.rarlab.com/rar/rarlinux-5.5.0.tar.gz
# tar -zxvf rarlinux-5.5.0.tar.gz
# cd rar
# cp -v rar unrar /usr/local/bin/


To open/extract a RAR file in current working directory, just use the following command with unrar e option.

# unrar e tecmint.rar

Alternatively
https://bayurimba.wordpress.com/2014/08/29/installing-unrar-on-rhel-6/

https://www.osetc.com/en/how-to-extract-rar-file-in-ubuntu-centos-rhel-linux.html

---------------------------------------------------------------------------------------------

To check if any FS is attached somewhere use

lsof -f | grep -i '\/mountpoint'

########################################### LSOF #####################################
 List processes using a mount point
 [root@bumsappod01t ibmsgaur]# lsof /usr/sap/trans
[root@bumsappod01t ibmsgaur]# lsof +D /usr/sap/trans/
==========================================================
  List opened files under a directory and sub directory
 #  crmlsof +D /var/log/
 lsof -t /var/log/syslog
 ===================================================
 List opened files based on process names
    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
  4173 root      20   0  562148  65356  12616 S 2.318 0.398   1679:09 BESClient
[root@bumsappod01t ibmsgaur]# lsof -c BESClient
#########################################################################################
List all open files by a specific process
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
54174 root      20   0  719m  48m 9.9m S  1.7  0.1   4724:31 BESClient
[root@sjmpxpaa01 tmp]$ lsof -p 54174
#########################################################################################
List processes which are listening on a particular port
lsof -i :25


Besclient is no longer required. It is replaced with AIC.
 Plz do NOT attempt to install besclient on any VMs in Managed Apps.
For ref. (#6799)

----------------------------------------------------------------------------------------------------
for devices to be added to ServiceNow or added to DNS it goes to ServiceNow, that is not correct.  To add a device to ServiceNow it goes to the CMDB team.  To add a device to DNS a ticket needs to go to the DNS team

--------------------------------------------------------------------------

Sandeeps prechec script

I have created script "prechecks_script.sh" on Singapore chef regional server and another file with name "servers" which containing list of servers. Output of script can be look in "prechecks_bkp.log"
 
NOTE :- We have to run script  ( prechecks_script_Dedicatedservers.sh ) manually on TATA server as, we don't have connectivity from chef regional server. eg Prechecks_script_dedicatedServer.sh > prechecks_bkp.log.

---------------------------------------------------------------------------------------------

SLAs as per SNOW

Response - P1 - 15 Min Resolution - P1 - 5 Hour
Response - P2 - 30 minutes Resolution - P2 - 8 Hours
Response - P2 - 3 Hours Resolution - P2 - 24 Hours
Response - P3 - 2 Business Days Resolution - P3 - 7 Business Days


---------------------------------------------------------------------------------
MCO slack  mcx-na-tech1

normal sev1 inf-na-tech1

-----------------------------------------------------------------------------------

Adding any VHANA host in normal VC
get the VHANA SL host details from 3x hana sheet in our example we take source esxi dal13-pod1-4tb-host16.imzcloud.ibmammsap.local
login to SL portal and find the root pw  from the password tab on the left pane
Login to normal site VC from Jump server and add this host, it will ask for hostname and cred, enter root cred here fetched in step above
if already managed it will throw an error that the "Host is already managed by ip add xx.xx.xx.xx" select no and exit without any changes
Take the ip from step above and open it in a new browser on Jump server(u dont need SL VPN and can connect with ur regular imz cred)
This VC on the new ip will have the SL host we had on SL



SEI jump server IP : 158.87.22.203
------------------------------------------------------------------------------------

RPO violation  Replication not active  do a migration


AG OS
werner.gomez@ibm.com
leorodri@cr.ibm.com
marcela.herrera@ibm.com

---------------------------------------------------------------------------------------

IMZ login issues

https://github.kyndryl.net/CMS/cms-chef/wiki/Linux-Active-Directory-Troubleshooting

---------------------------------------------------------------------------------------------

SAP portal login credentials

S0015210101
TQ43HJS!

--------------------------------------------------------------------------

/etc/mtab and /proc/mounts on Linux
shows the mounted FS

-----------------------------------------------------------------------
cd /boot has all Kernel files

listing page wise use |less

modinfo gives module information for the kernel drivers
/usr/lib/modules  or /lib/modules


lsmod pulles all modules
modinfo <modulename>

install a new module insmod <filename>
remove a module rmmod <filename>

modprobe to activate the hw for which module is installed and removed the h/s whose module is removed. It works without reboot


initrd is initialization ram disk


Grand Unified boot loader  GRUB


ip addr for ip address 

--------------------------------------------------------------------------------------------------

Checking for FS for any errors tobe fixed via FSCK
df -h |grep -v "tmpfs"|awk '{print $1}' > opt1.txt;for j in `cat opt1.txt`;do echo $j;tune2fs -l $j|grep state;done


install a gz file
tar -zxvf file. tar. gz.

-----------------------------------------------------------------------------------------

nmon daily report script
#NMON Daily report script
2 0 * * * /bin/sh /usr/local/bin/nmon.sh 1>/dev/null 2>/dev/null

https://www.ibm.com/support/knowledgecenter/ssw_aix_71/n_commands/nmon.html




################################ NMOM RPM LOCATION #############
cd /sds/sap/MSD_Software/SAP_Automation/Scripts/linux_utility/nmon
##############################################################

------------------------------------------------------------------------------------------
Auto restart service after reboot
autostart nfs service after reboot

[root@DLBDBWAP01 ibmrmalik]$ chkconfig nfs on
[root@DLBDBWAP01 ibmrmalik]$ chkconfig rpcbind on

disable the auto-start service then you can use the following commands

chkconfig httpd off

To check if any service is enabled/disabled
 systemctl list-unit-files | grep disabled |grep -i <servicename>

--------------------------------------------------------------------------------

CIFS mount

//Spsvopivapp01/oom/JPP /wts_oom_JPP cifs username=msg_jp1,passwd=Brguest#123,_netdev,uid=20000,gid=3050 0 0

giving gid and uid in fstab and then mounting ensures proper permissions.

--------------------------------------------------------------------------------------

Media error

	
/opt/MegaRAID/storcli/storcli64 /call show all | grep -iE "Sata|SAS" | grep -iE "Bad|Failed"

System MegaRAID OfLn Pdgd Dgrd

/opt/MegaRAID/storcli/storcli64 /call show all | grep -iE "OfLn|Pdgd|Dgrd" | grep -v "="

System MegaRAID Drive Media Errors 

/opt/MegaRAID/storcli/storcli64 /c0/eall/sall show all | grep "Media Error Count" | grep -v "Media Error Count = 0"


/opt/MegaRAID/storcli/storcli64 /call/eall/sall show all |grep -i error
/opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show all | grep -iE "det|cou|tem|SN|S.M|fir"

/opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show all | grep -iE "det|cou|tem|SN|S.M|fir"
 /opt/MegaRAID/storcli/storcli64 /c0 show all
 /opt/MegaRAID/storcli/storcli64 /call show all
 /opt/MegaRAID/storcli/storcli64 /c0 show TermLog | grep EVT
 
 /opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show rebuild
- /opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show copyback
- /opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show all | grep -iE "det|cou|tem|SN|S.M|fir"

/opt/lsi/storcli # ./storcli

/c0/e8/s18
/opt/MegaRAID/storcli/storcli64 /c0/e8/s18 /eall /sall show rebuild


/opt/MegaRAID/storcli/storcli64 /c0 /dall show
/opt/MegaRAID/storcli/storcli64 /c0 /vall show
/opt/MegaRAID/storcli/storcli64 /c0 /eall /sall show all | grep -iE "det|cou|tem|SN|S.M|fir"
/opt/MegaRAID/storcli/storcli64 /c0 show eventloginfo
/opt/MegaRAID/storcli/storcli64 /c0 show all

Physical Drives = 23

PD LIST :
=======

----------------------------------------------------------------------------------
EID:Slt DID State  DG       Size Intf Med SED PI SeSz Model               Sp Type
----------------------------------------------------------------------------------
8:0      19 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:1      22 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:2      11 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:3      18 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:4      12 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:5      40 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:6      14 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:7      41 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:8      34 Onln    0 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:9      39 Onln    1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:10     17 Failed  1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:11     27 Onln    1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:12     28 Onln    1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:13     38 UBad    - 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:14     36 Onln    1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:15     23 Onln    1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:16     33 Onln    1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:17     10 Onln    1 558.406 GB SAS  HDD N   N  512B ST3600057SS         U  -  
8:18     16 GHS     - 558.406 GB SAS  HDD N   N  512B ST3600057SS         D  -  
8:19     29 Onln    2 744.687 GB SATA SSD N   N  512B INTEL SSDSC2BA800G4 U  -  
8:20     31 Onln    2 744.687 GB SATA SSD N   N  512B INTEL SSDSC2BA800G4 U  -  
8:21     30 Onln    2 744.687 GB SATA SSD N   N  512B INTEL SSDSC2BA800G4 U  -  
8:22     32 GHS     - 744.687 GB SATA SSD N   N  512B INTEL SSDSC2BA800G4 U  -  
----------------------------------------------------------------------------------



to install the storcli commands

1.) Go to the /tmp directory.

# cd /tmp

2.) Download the storcli package.

# wget http://downloads.service.softlayer.com/lsitools/1.14.12_StorCLI.zip

3.) Unpack the location.

# unzip 1.14.12_StorCLI.zip

4.) Go to the Linux directory.

# cd /tmp/storcli_all_os/Linux

5.) Install the package.

# zypper install storcli-1.14.12-1.noarch.rpm

Once installed, run the storcli command to see if it works, example:

# /opt/MegaRAID/storcli/storcli64 /c0 show all

Please try this and let us know if you continue to have trouble.

--------------------------------------------------------------------------------------------------------

Pacemaker task

After the VCenter Upgrades in 3.x, the VCenter Fencing resources on non-Hana pacemaker clusters are failing. A cleanup of the resources does not fix the issue. To fix the issue you need to copy the latest resource agent from SDS by executing  the below command as root. This is an online task without any impact.

# cat /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/fence_vmware_soap > /usr/sbin/fence_vmware_soap


Please let me know if you have questions. Please circulate to the team and anyone else I might have missed.


 https://vpn.che01.softlayer.com
 
 
 Pacemaker SOPs
 
 https://github.ibm.com/CMS/SAP-Base-RR/tree/master/CMAS%203x/SOPs

Pacemaker tools update

Validation script - /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py

1 - Take the VM snapshot once Apps are stopped.

 ogypxn001 and ogypxn001-ha
 ogypxn002 and ogypxn002_h


2 - Stop the pacemaker service on the both nodes
# systemctl stop pacemaker

3 - Install  the latest pacemaker-tools version from the directory   "/sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker" .  Should be executed on issue node. 
        follow below steps.

   # cd /sds/sap/MSD_Software/SAP_Automation/Non-Hana/AMM/Pacemaker
   # rpm -Uvh pacemaker-tools-1.4-1.noarch.rpm

4 - Validate the RPM
 # rpm -qa |grep pacemaker-tools

5 -  Error : VMware Tool Update Status           : New version available                               [ FAILED ]


-------------------------------------------------------------------------------------

sudo access  sudo rootsh

When we receive service requests to create user id's we are in a confusion whether we do it or its done by IAM team.

If the request is to create local user id's then we should create the user id's on the server and give sudo access if requested.

We used to contact CHEF team to give user id's to sudo access, however, they do not give sudo access, as it is our task.

We have to add the user id's to /etc/sudoers.d/sudoer file. This file does not exit on the server, we have create one and add the user id's for sudo access.

ref server tslgldev
[root@tslgldev ibmrmalik]# cat /etc/sudoers.d/sudoers
%custapp ALL=(ALL) NOPASSWD:ALL,SUROOT,RESTRICTED_CMDS

%wheel ALL=(ALL:ALL) NOPASSWD:ALL

Adding user to wheel group
[root@tres4devapp ~]# gpasswd -a s4dadm wheel
Adding user s4dadm to group wheel

Removing user from wheel group
[root@tres4devapp ~]# gpasswd -d s4dadm wheel
Removing user s4dadm from group wheel



Open a terminal and enter: sudo visudo.
This will open the "/etc/sudoers" file

 992  2021-06-04 09:09:29 scp ibmbdayeh@10.143.69.186:/tmp/rootsh .
  993  2021-06-04 09:09:50 cp rootsh /usr/bin/
  994  2021-06-04 09:09:57 ll /usr/bin/rootsh
  995  2021-06-04 09:10:14 chmod 755 /usr/bin/rootsh
  996  2021-06-04 09:10:17 ll /usr/bin/rootsh
  997  2021-06-04 09:10:23 su - ibmmhussain
  998  2021-06-04 09:11:15 mkdir /var/log/rootsh/
  999  2021-06-04 09:11:19 ls -ltrhd /var/log/rootsh/
 1000  2021-06-04 09:11:28 su -  ibmmhussain
 1001  2021-06-04 09:12:51 history
dlthdehdb3:/home/ibmmhussain # ls -ltr |grep -i rootsh


--------------------------------------------------------------------------------------

Standard Operating Procedure (SOP)
SAP-Linux: IMZID authentication error on Linux Servers.
      MUST READ
   1. Change Preparation
There is a requirement or ticket that requires to access the client server.
IBM Security Privileged Identity Manager (PIM ) access to get the client server root password, or Infra chef server access to login to client server ( password less authentication).
      2. Change Considerations
Scenario: Linux servers - Unable to login to server. All IMZID password authentication failed.
      3. Known Complications
This SOP not applicable for below scenarios:
Server is hung state and not allowed to access.
Server is power off state.
sshd/sssd service is not running.
Users are locked /Inactive state.
      CHANGE EXECUTION
   4. Build Plan
1. Check the server status make make sure that server is UP.
Login to Console and check the status.
Ping the sever IP from Infra Chef Server.
 
2. Access the client server
- Use Any one method -
Login to chef server and access the client server via ssh. (password less authentication)
Access the sever via console using root password.
 
Root password can obtain from PIM Tool.
https://ispim.amm.ibmcloud.com/itim/self/Home.do
3 . Execute chef_client service.
Stop sssd service
# service sssd stop
# rm -rf /var/lib/sss/db/*
Remove /etc/krb5.keytab
# rm /etc/krb5.keytab
# kdestroy
# chef-client
verify the chef client logs.
4 – Validate the access using IMZID and confirm the access.
      5. Back-out Plan
Not Applicable.
      6. Post-test Plan
Validate the access using IMZID and confirm the access.
      7. Notification Plan
Update the incident /service request.
      End of document
      
      Do not start chef on OS1 servers
Check any backup for krb5.keytab
ls -lrt /etc/krb5.keytab*
Verrify the krb file sould have an entry "sapsnc@INT.OSRAM-LIGHT.COM". if not ask TSM to restore to /tmp
klist -k /etc/krb5.keytab_bkp
restore keytab file (Permission 644)
cp /etc/krb5.keytab_bkp /etc/krb5.keytab
or from tsm
/tmp/krb5.keytab /etc/krb5.keytab
check /var/chef/backup for chef modified files , and restore if need
restart sssd
systemctl stop sssd
systemctl start sssd
11:52 AM
Check first this ls -lrt /etc/krb5.keytab*
----------------------------------------------------
box location for the documents
https://ibm.ent.box.com/folder/116505444650


Change assignment link

Change in prog check

http://66.248.236.5:8080/CSR_ALLOCATION/
------------------------------------------

asignment group
MA-ASGN-SAP-LIN

-----------------------------------------------------------------------------

1.x access details


Forti Client IP details

Port 443 for all.

With SSL VPN
BLD - 146.89.45.198
EHN - 146.89.46.198

Without VPN
BLD - 192.86.36.252
EHN - 192.86.37.252

Mobipass	pin Ravi12

osadmin@ip
sudo su - root

https://w3.ibm.com/w3publisher/onboarding-process-b-tribe/07-request-accesses/7b-1-x-accesses

-----------------------------------------------------------

ITM server on one of IaaS requested by Jazril.
For reference please use link:
https://w3.ibm.com/w3publisher/hst-for-imt-france-public/ibm-tivoli-monitoring/requirements/endpoint




forticlient ips

146.89.44.198
129.33.53.252
146.89.45.198
192.86.36.252
192.86.37.252



System serial no
root:~# dmidecode -s system-serial-number
3Q1SXR2

------------------------------------------------------------

SAS VPN certificate
/home/rmalik/.cisco/certificates/client/rmalik-vpn-ca_cert.csr

/home/rmalik/.cisco/certificates/client/rmalik.pem
CA certificate: /home/rmalik/.cisco/certificates/client/rmalik-vpn-ca_cert.csr
User certificate /home/rmalik/.cisco/certificates/client/rmalik-vpn-user_cert.csr
Private key /home/rmalik/.cisco/certificates/client/private/rmalik-vpn-private_key.key

sasvpn.in.ibm.com

sasvpn.jp.ibm.com

AUto connects to 
https://mobile.us.ibm.com:15048/tools/vpn/enduser/userdevice.php?
use w3 cred




TSM backup failing
below is the command for error:  ls: cannot access '.gvfs': Transport endpoint is not connected
cd to path where the error is showing and run the below command.
fusermount -u ~/.gvfs

---------------------------------------------------------------------------
RHEL upgrade from 7.8 to 8.2/8.6

You can now go to RHEL 8.6 but:

lock the repo with 8.6.
#subscription-manager release --set=8.6

You can now go to RHEL 8.6 but:

lock the repo with 8.6.
#subscription-manager release --set=8.6

https://github.kyndryl.net/CMS/BuildMigration/wiki/Inplace-upgrade-RHEL7-to-RHEL8

If currently locked with 8.2, release and lock with 8.6 and patch the servers




you needs to change boot from legacy to UEFI and boot from created USB pen. You can choose option to preserve your data (make sure you have some backup for sure)
VPN cert will be created and delivered to your machine automatically

can I export my RHEL7 KVM into a .img or .iso file and then import it into boxes under RHEL8?

:yes:


You don't need to export them.
using vi, create a new file with this info in it:
[source]
name=QEMU System
type=libvirt
uri=qemu+unix:///system
save-on-quit=true
and save it as ~/.config/gnome-boxes/source/QEMU System
And you should now be able to run your VMs with Boxes. (edited)


'dsmadmc'  ie TSM admin console
 
 
wiki link for chef troubleshooting: https://github.kyndryl.net/CMS/cms-chef/wiki/Troubleshooting-CMS-Chef-Failures#general-chef-debugging-techniques


Internal IBM support
https://ibm.service-now.com/nav_to.do?uri=%2Fhome.do%3F

-------------------------------------------------------------

VCenter client download link

http://vsphereclient.vmware.com/vsphereclient/2/5/0/2/2/2/2/VMware-viclient-all-6.0.0-2502222.exe


Linux EMEA B1 B2 from Romania
Iulian Nae (Trio B2 EMEA - LINUX AHT)
Stefan ANICA (Trio B1 EMEA - Linux)


find all files with uid 70000 and change the same to cpaadm
find . -user 70000 -exec chown cpaadm {} \;

-----------------------------------------------------------------

corrupted yum cache

rm -fr /var/cache/yum/*
yum clean all 

------------------------------------------------------------

start any service after reboot

Next, make sure the service is started on boot and start the service.

# systemctl enable auditd
# systemctl start auditd

Enabling auditing on any server
for audit, you have to start/enable audit service..and define the rule in /etc/audit/audit.rules or /etc/audit/rules.d/audit.rules..means for which file system you have to enable audit etc
--------------------------------------------------------

fetch user list on any server
awk -F':' '{ print $1}' /etc/passwd >> /tmp/userall.txt

https://www.thegeekdiary.com/how-to-use-auditd-to-monitor-a-file-deletion-in-linux/

-------------------------------------------------------------------

swap using proce in Suse 12

paste this command on command prompt and then wait for 30 sec and then enter:
ps ax -o pid,args | grep -v '^ PID'|sed -e 's,^ *,,' > /tmp/ps_ax.output
echo -n >/tmp/results
for swappid in $(grep -l Swap /proc/[1-9]*/smaps ); do
swapusage=0
for x in $( grep Swap $swappid 2>/dev/null |grep -v '\W0 kB'|awk '{print $2}' ); do
let swapusage+=$x
done
pid=$(echo $swappid| cut -d' ' -f3|cut -d'/' -f3)
if ( [ $swapusage -ne 0 ] ); then
echo -ne "$swapusage kb\t\t" >>/tmp/results
egrep "^$pid " /tmp/ps_ax.output |sed -e 's,^[0-9]* ,,' >>/tmp/results
fi
done
echo "top swap using processes which are still running:"
sort -nr /tmp/results | head -n 10


Top 10 swap using processes
for file in /proc/*/status ; do awk '/VmSwap|Name/{printf $2 " " $3}END{ print ""}' $file; done | grep kB | sort -k 2 -n -r | head -n 10

Top 10 mem and CPU processesps -eo pmem,pcpu,rss,vsize,args --sort -rss | head -n 10
ps -eo pmem,pcpu,rss,vsize,args --sort -rss | head -n 10



------------------------------------------------------------------------------------------
DIsable snapshot taking ability
To resolve this issue:

    Power down the virtual machine.
    Right-click the virtual machine in the Web Client and click Edit Settings.
    Click the VM Options tab, under Advanced, select the Edit Configuration option.
    Search for a string name called snapshot.maxSnapshots and increase its value.
    Click OK to save the changes.
    Power on the virtual machine and create the required snapshot.

Caution: Only modify the snapshot.maxSnapshots parameter with the guidance of VMware technical support. Increasing the number of allowed snapshots beyond the maximum value of 32 is not supported.
 
Notes:

    If the snapshot.maxSnapshots value is not present, you may manually enter this configuration setting. In vSphere 6.7.x and 7.0.x, the setting is not listed by default.
    To disallow snapshots, set the snapshot.maxSnapshots value to 0.
    --------------------------------------------------------------------------------------------------------
    
    Pace maker cluster

In verification I noticed that cluster services were down on one of the node  

1:08:58 PM: Online: [ tbos4prdd2 ]
OFFLINE: [ tbos4prdd1 ]  

1:09:33 PM: while starting the cluster services, received error as "tbos4prdd1 systemd[1]: Dependency failed for Pacemaker High Availability Cluster Manager"  


solution

oot@tbos4prdd1 ibmschaskar]$ sbd -d /dev/mapper/sbddisk1  message LOCAL clear
[root@tbos4prdd1 ibmschaskar]$ systemctl start pacemaker.service  

first check #/etc/sysconfig/sbd|grep -i sbd_device   ...it was /dev/mapper/sbddisk1 in my case  

and the above commands must be run from the node where cluster is down


https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/02_DR_operations.md
    
    
    -
    ---------------------------------------------------------------------------------------------------
    
Joe Sande Organization All Hands Call (ILO_0003936)

Managed Applications Engineering & Delivery All Hands

Event Details:

    Presenters:  Joseph Sande/Raleigh/IBM, Brian Snitzer/Southbury/IBM, Naresh Nayar/Rochester/IBM, Wesley D Stevens/Lexington/IBM, Louise Trudeau/Canada/IBM, Suvojit Sinha/India/IBM, Sankaranarayanan Srinivasa/India/IBM@IBMIN, Debashree Sengupta7/US/IBM@IBM,                
    Event Date:   October 13, 2020                              
    Event Time: 8:30 AM - 9:30 AM ET  - check time in your location here 
    Duration:  1 hour                      
    Facilitator:  Marie Justine Caruncho/Philippines/IBM          

Enroll & add event to your calendar:
To receive a calendar invite for this session, follow this link and click "Enroll" on the right hand side: 

    Desktop / Laptop: Click here
    Note: You will need to have IBM MaaS360 browser 
    You may need to paste the regular link into the MaaS360 browser


Joining the live session
Simply follow the same link you used to enroll above, and click on the Join button.
We recommend you always join at least 15 minutes early (even if you're on another call)

    Desktop / Laptop users: Please ensure you have installed the WebEx Plugin which you will be prompted to do.
    You should also check your internet speed and choose the appropriate setting when joining WebEx
    Tablet / Phone users: Please ensure you have installed the WebEx Mobile app
    Enter this session number when prompted: 145 388 1393
    WebEx Password: learning


Accessing the playback
Simply follow the same link you used to enroll above, and replay link on the right hand side 

    The link will be available shortly after the live event has finished


Technical support
If you encounter any technical issues, please send us an email at vlt@us.ibm.com.

· If  you encounter any problems connecting to the session please refer to this troubleshooting guide: https://ibm.box.com/s/oz6h989589ho9xaqgc125vicinw5gp4k
*Especially for Linux Users

· It contains hints & tips, detailed troubleshooting steps to help get you into your event.

----------------------------------------------------------------------------------------------

RUn 
/usr/share/ibmregtool/ibmregtool.py

to open the regstration page after entitlement is approved
    
-----------------------------------------------------------------------------------------

 #trm-sev1-hub   issue with infra servers
 
 #inf-na-tech1  for further discussion
 
 -----------------------------------------------------------
 
 Generated SSH keys are stored by default in .ssh/ directory of home directory

    Private key permissions should be 600

    Public key permissions should be 644
    
    To use key-based authentication, public key must be copied to destination system

    Use ssh-copy-id

    Copies ~/.ssh/id_rsa.pub file by default
    
    
    View KB via command line
    redhat-support-tool kb 253273 | less
    
    --------------------------------------------------------------------
    
    [root@che01ammsol01 log]# yum history
Loaded plugins: changelog, enabled_repos_upload, langpacks, package_upload, product-id, search-disabled-repos, subscription-manager, tmprepo, verify,
              : versionlock
ID     | Login user               | Date and time    | Action(s)      | Altered
-------------------------------------------------------------------------------
    91 | System <unset>           | 2020-10-22 22:52 | Erase          |    6 EE
    90 | Mitul Patel <ibmmpatel2> | 2020-10-22 16:10 | I, O, U        | 1108 EE
    89 | Mitul Patel <ibmmpatel2> | 2020-10-22 16:06 | I, U           |    2
    88 | Mitul Patel <ibmmpatel2> | 2020-10-22 16:05 | Erase          |    1

--------------------------------------------------------------------------------------------------

Dr. Archa Thakore
I suggest you contact acclaim and they will merge it for you. Even my id got changed sometime back and that's how I got it done - use this admin@youracclaim.com

https://www.youracclaim.com/earner/earned
https://www.youracclaim.com/earner/settings/account   change the new email id as default


Has your IBM id or email changed due to a name, employee status or transfer within IBM? There are 2 steps to merge your previous training data with your new employee number, email and profile.  
 
Complete the Profile Link process at the YL SuperZero support page. If you have questions or problems completing the process at that page, please create a SuperZero support ticket from that page. 
After the profile link process is completed, to maintain your earned badges in Your Learning you will also need to set your new IBM email address as the your primary Acclaim email. 

How do you set your default Acclaim email address? If you had an Acclaim account prior to IBM or your IBM email address has changed, you might need to update your default email in your Acclaim profile. To have your public badges automatically display in Your Learning and BluePages, set your current IBM email address as default email address.
  
In Acclaim, go to your account settings. Add or select your IBM email address, complete the Verify address process, and then set the new email address as the primary default.  
  
Note: If the above Acclaim links have changed, search at support.youracclaim.com for "setting default email" instructions.

---------------------------------------------------------------------------------------------------------------------

Please get all the OS SMEs (and actually all OS engineers) to get this training.

1) Microsoft Azure  https:://docs.microsoft.com/en-us/learn/paths/azure-fundamentals/

2) Amazon Web Servies (AWS)   https://aws.amazon.com/certification/certified-cloud-practitioner/

3) Google Cloud (training options here: https://cloud.google.com/training)  -> free :  https://cloud.google.com/blog/topics/training-certifications/expanding-at-home-learning ($300 credit for free) 


Q: How do I schedule my exam in Azure Portal?
A: To schedule exam in Azure portal, we must complete the following steps
·      Associate your IBM id to MPN (https://ibm.seismic.com/Link/Content/DCaAnCj6OfoUSPsH8Y4R1wBw)


Use this Link https://examregistration.microsoft.com/MyProfile
and register here by filling mandatory fields only. Just save your profile here.
Once you are done, un check the box at MPN site and try associating it again. It should work !


AWS customers:
https://223436830868.signin.aws.amazon.com/console




IBM Azure customers 
Azure portal
https://portal.azure.com/#home

 https://portal.azure.com/#@ibm.onmicrosoft.com/resource/subscriptions/50cc6496-c69f-4153-8897-a824dd0b9c9a/resourceGroups

To: Ravi Venkataramani/India/IBM@IBM, Luis Alonso Salas/Costa Rica/IBM@IBM, Lori Nevarez/San Francisco/IBM@IBM, Demian Bolduc/Wichita/IBM@IBM, Blessen Babuji/India/IBM@IBM
From: Robert Stefan Bufu1/Romania/IBM
Date: 06/24/2021 09:38PM
Cc: Mike Dye/Annapolis/IBM@IBMMail
Subject: Fw: Azure and AWS accounts 24x7 support

In order to get access to SAP Azure customers, as we have now an IAM role for these accesses, can you please decide which OS engineers from your squads need to get access into Azure and instruct those members to :

1) Make sure they are aware on how to work Azure Portal operations
  - one good start is https://docs.microsoft.com/en-us/learn/paths/azure-fundamentals/ 
 - but they can also look into OS operations training (eg. good location for that is https://ibm-learning.udemy.com/organization/home/)

2) Each must personally request "AMM SAP Azure - Contributor" access from ISIM https://dalseal.amm.ibmcloud.com/itim/self/RequestAccess.do 
 First approval goes to People Manager, then it goes up the chain..  Once completed this should ensure that they get OS admin access to our Azure customer subscriptions, so login on https://portal.azure.com/  with w3 ID will give access to Microsoft Azure (CSP for SAP) subscription.

Robert Bufu


We had a OS hung for a Azure VM, and was able to trigger NMI interrupt on this hung VM from the Azure portal.
When a Azure VM is hung, we have an option to collect the coredump from the portal.
Do not reboot the VM, instead go to "Serial console" and select the "Send command" option on the top, and select "Send Non-Maskable Interrupt (NMI)" option.
This procedure will mount the root disk under temporary mount /mnt, then the dump triggered and will be stored under /mnt/var/crash.
Once the the server is up, we can then download the coredump from /var/crash and attach it to the SUSE vendor case for root cause analysis


------------------------------------------------------------------------------------------------------------

Create a dummyfile of 20MB

create a file with random data:

dd if=/dev/urandom of=output.dat  bs=1M  count=20

will create a file of 20Mb

-------------------------------------------------------------------------------------

Adding a path in PATH variable

https://www.techrepublic.com/article/how-to-add-directories-to-your-path-in-linux/

echo $PATH

then add the path using
export PATH=$PATH:<path to add>
test if showing in PATH variable with above command

above is temporarily and post reboot it will be gone. To make it permanent, add the same to the  .bash_profile also
--------------------------------------------------------------------------------------------------

/var/log full

/var/log/gdm old files cleanup, changethe permission then the cleanup works

----------------------------------------------------------------------------------------------

Access to 1.x servers

local terminal
user osadmin@ip
then sudo su - root

--------------------------------------------------------------------------------------------------
copying and configuring the Operations scripts


1. Create folder "/opt/ibm/HDBHA/Operations" if not exists

   mkdir -p /opt/ibm/HDBHA/Operations

2. change directory to /opt/ibm/HDBHA/Operations

   cd /opt/ibm/HDBHA/Operations

3. copy Operations scripts from SDS location to /opt/ibm/HDBHA/Operations

   cp -r /sds/sap/MSD_Software/SAP_Automation/HDBHA/Operations/* .

4. change directory to RecoverCluster

   cd /opt/ibm/HDBHA/Operations/RecoverCluster

5. create a symbolic link for Automation Library under RecoverCluster folder

   ln -s /opt/ibm/HDBHA/Operations/AutomationLibrary/HDBHA_AutomationLibrary.sh
 HDBHA_AutomationLibrary.sh

6. change directory to MaintainCluster folder

   cd /opt/ibm/HDBHA/Operations/MaintainCluster

7. create a symbolic link for Automation Library under MaintainCluster folder

   ln -s /opt/ibm/HDBHA/Operations/AutomationLibrary/HDBHA_AutomationLibrary.sh HDBHA_AutomationLibrary.sh

Make sure the scripts should be root:root and with permission -rwxr-xr-x

these are the steps for copying and configuring the Operations scripts

---------------------------------------------------------------------------------------

Hard links

Create Hard Links
To show hard link count, use ls -l

Count appears after permissions and before file owner

[root@server1 ~]# echo "Hello World" > newfile.txt
[root@server1 ~]# ls -l newfile.txt
-rw-r--r--. 1 root root 0 Mar 11 19:9 newfile.txt
To create hard link to file, use ln

ln expects existing file as first argument, followed by one or more hard links

Hard links can reside anywhere on same file system as existing file

Note: If you create a hard link, you cannot easily tell that a file is a hard link or where it links to



Soft link

Create Soft Links
Soft link: Special file that points to existing file or directory

Can point to file or directory on another file system

To create a soft, or symbolic, link, use ln -s

[root@server1 ~]# ln -s /root/newfile-link2.txt /tmp/newfile-symlink.txt
[root@server1 ~]# ls -l newfile-link2.txt /tmp/newfile-symlink.txt
lrwxrwxrwx. 1 root root 11 Mar 11 20:9 /tmp/newfile-symlink.txt -> /root/newfile-link2.txt
-rw-rw-r--. 1 root root 12 Mar 11 19:9 newfile-link2.txt



Superuser Access
Example: Configure sudo to allow user student to run usermod as root

[student@server1 ~]$ sudo usermod -L username
[sudo] password for student:password
All commands executed with sudo are logged in /var/log/secure

[student@server1 ~]$ sudo tail /var/log/secure
...
Feb 19 15:3:36 localhost sudo: student : TTY=pts/0 ; PWD=/home/student ; USER=root ; COMMAND=/sbin/usermod -L student
Feb 19 15:3:36 localhost usermod[16325]: lock user 'student' password
Feb 19 15:3:47 localhost sudo: student : TTY=pts/0 ; PWD=/home/student ; USER=root ; COMMAND=/bin/tail /var/log/secure



Problem
Bob now owns all files that Prince once owned

[root@server1~]# useradd Prince
[root@server1~]# ls -l /home
drwx------. 3 prince  prince    74 Feb  4 15:2 Prince
[root@server1~]# userdel Prince
[root@server1~]# ls -l /home
drwx------. 3    1000    1000   74 Feb  4 15:2 Prince
[root@server1~]# useradd Bob
[root@server1~]# ls -l /home
drwx------. 3 bob     bob       74 Feb  4 15:3 Bob
drwx------. 3 bob     bob       74 Feb  4 15:2 Prince
Solutions
Remove all unowned files when user that created them is deleted

Manually assign unowned files to different user

root can find unowned files and directories by running:

find / -nouser -o -nogroup 2> /dev/null 


By default, in Red Hat Enterprise Linux 7, users in the wheel group have access to run any command as root using the sudo utility.

Add a User to Multiple Groups at Once
Use the usermod command to specify multiple groups to add to:

sudo usermod –a –G new_group,new_group2,new_group3 user_name
Create a User and Add to Group
This is useful for creating a new user on the fly for a specific software application. Enter the following:

sudo useradd –G new_group new_user
Next, assign a password to the new user:

sudo passwd new_user
Change a Users Primary Group   usermod -g sapsys_ww ibmdrspandey
All previous commands have been used to manage the secondary groups a user belongs to. In most cases, a user’s primary group is the same as their username.


To change a users primary group, enter the command:

sudo usermod –g new_group user_name
The lower-case –g specifies the primary group. (Upper-case –G refers to a secondary group.) A user can only have one primary group, so the old primary group user_name won’t be primary anymore for this user.

How to Remove a User From a Group
The gpasswd tool is used for managing groups. To remove a user from a group:

sudo gpasswd –d user_name new_group



Special Permissions
sticky Permissions
Sets restriction on deletion of files

Only file owner and root can delete files in directory

Example: /tmp

[student@desktop1$ ls -ld /tmp
drwxrwxrwt. 39 root root 4096 Feb  8 20:2 /tmp
sticky permissions use t in place of x

If no owner execute permissions, T replaces x

-------------------------------------------------------------------------

PSL sharepoint

https://persistentsystems.sharepoint.com/sites/IBMCMS/Shared%20Documents/Forms/AllItems.aspx?FolderCTID=0x0120000A71CC221AB8064C9C2D8148C7377733&id=%2Fsites%2FIBMCMS%2FShared%20Documents%2FGeneral%2FCloud%20DU1%2FCMAS&viewid=b8e9a6d6%2D006e%2D4e99%2Da03e%2D58b6d140a95a

Cloud DU1 -> CMAS --> AMM_CQM

https://persistentsystems.sharepoint.com/sites/IBMCMS/Shared%20Documents/Forms/AllItems.aspx?FolderCTID=0x0120000A71CC221AB8064C9C2D8148C7377733&viewid=b8e9a6d6%2D006e%2D4e99%2Da03e%2D58b6d140a95a&id=%2Fsites%2FIBMCMS%2FShared%20Documents%2FGeneral%2FCloud%20DU1%2FCMAS%2FAMM%5FCQM


https://persistentsystems.sharepoint.com/:x:/r/sites/IBMCMS/_layouts/15/Doc.aspx?sourcedoc=%7[…]direct=true&cid=78ecb42d-ca6b-4052-a7ae-83a6465c1660

dsmc to get the site when inside the VM
check if backup is going
dsmc i /
dsmc = tsm client , That will take you to tsm client prompt
I = incremental backup
/ = tells the fs to backup , here its root


Gayathri Y yes if its appearing in ps -ef | grep dsm*
you can kill that
as it increases the load




9:45 AM
there if you find dsmadmc
9:45 AM
you can kill that

check SELinux status 
sestatus command


DR
[root@MGGDRDGTSX02 ibmrmalik]# ls -Z /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
lrwxrwxrwx root root ?                                /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint -> /opt/tivoli/tsm/tdp_hana/hdbbackint


Primary
[root@MGGGBJPGTSX02 ibmrmalik]$ ls -Z /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
lrwxrwxrwx. root root system_u:object_r:default_t:s0   /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint -> /opt/tivoli/tsm/tdp_hana/hdbbackint

chcon -h system_u:object_r:default_t:s0 /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint

ls --lcontext <file path>

To Apply selinux context :
ls --lcontext /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint [ls --lcontext <Filename>]
chcon -h system_u:object_r:default_t:s0 /usr/sap/EGP/SYS/global/hdb/opt/hdbbackint
ls --lcontext <Filename>


uname -m to get the architecture 32 or 64 bit


 https://knowledgecenter.persistent.co.in/ViewCourse/SS112  for 2.5 points
 
 -------------------------------------------------------------------------------------------------
 KVM starting error
 Error starting domain: internal error: /usr/libexec/qemu-bridge-helper --use-vnet --br=virbr0 --fd=29: failed to communicate with bridge helper: Transport endpoint is not connected
stderr=failed to get mtu of bridge `virbr0': No such device


Traceback (most recent call last):
  File "/usr/share/virt-manager/virtManager/asyncjob.py", line 75, in cb_wrapper
    callback(asyncjob, *args, **kwargs)
  File "/usr/share/virt-manager/virtManager/asyncjob.py", line 111, in tmpcb
    callback(*args, **kwargs)
  File "/usr/share/virt-manager/virtManager/object/libvirtobject.py", line 66, in newfn
    ret = fn(self, *args, **kwargs)
  File "/usr/share/virt-manager/virtManager/object/domain.py", line 1279, in startup
    self._backend.create()
  File "/usr/lib64/python3.6/site-packages/libvirt.py", line 1080, in create
    if ret == -1: raise libvirtError ('virDomainCreate() failed', dom=self)
libvirt.libvirtError: internal error: /usr/libexec/qemu-bridge-helper --use-vnet --br=virbr0 --fd=29: failed to communicate with bridge helper: Transport endpoint is not connected
stderr=failed to get mtu of bridge `virbr0': No such device

restart libvertd service
internal error: /usr/libexec/qemu-bridge-helper --use-vnet --br=virbr0 --fd=28: failed to communicate with bridge helper: Transport endpoint is not connected

systemctl restart libvirtd.service

refer https://nts.strzibny.name/qemu-bridge-helper-missing-virbr0-interface/ for more steps

rm /etc/firewalld/zones/trusted.xml
systemctl restart firewalld
systemctl restart libvirtd
virsh net-start default
-----------------------------------------------------------------

RHEL 6.7 to 6.10

Follow the build plan from the attached document: SAP-Linux_3.X_Redhat  Linux Patching in 3.x environment.odt

After patch and reboot the server. we found network interface card is missing.
Solution :-
Need to edit the below file /etc/modprobe.d/vmxnet3.conf before reboot the server its should not impact to the network card issue.(comment the line #options vmxnet3 disable_lro=1)
vi /etc/modprobe.d/vmxnet3.conf
 #options vmxnet3 disable_lro=1 



RHEL 6.x to 7.x

https://github.kyndryl.net/CMS/BuildMigration/wiki/RHEL6-to-RHEL-7-Upgrade-Steps

To check the ip addresses and status of interfaces
 ip -br address show
-----------------------------------------------------------------------------------------------

grub file to edit when getting into the single user mode
/boot/grub/grub.conf

---------------------------------------------------------------------------------------------------

CQM document shared documents
https://persistentsystems.sharepoint.com/sites/IBMCMS/Shared%20Documents/Forms/AllItems.aspx?FolderCTID=0x0120000A71CC221AB8064C9C2D8148C7377733&viewid=b8e9a6d6%2D006e%2D4e99%2Da03e%2D58b6d140a95a&id=%2Fsites%2FIBMCMS%2FShared%20Documents%2FGeneral%2FCloud%20DU1%2FCMAS%2FAMM%5FCQM




Change dashboard for ongoing change
 https://ibmma.service-now.com/nav_to.do?uri=%2F$pa_dashboard.do%3Fsysparm_dashboard%3D95eb859f1b49ecd0a279c995624bcb53
 
 ---------------------------------------------------------------------------------------------------
 
 Hardware logs
 
 dmesg |grep -i error
 
 -------------------------------------------------------------------------------------------------------
 WIndows drive extension
 If you need to extend a volume or partition on which database files reside using tools like Diskpart, you should back up all system and user databases and stop SQL Server services first. Also, once disk volumes are extended successfully, you should consider running DBCC CHECKDB command to ensure the physical integrity of all databases residing on the volume.
 
 
 Persistent HOliday calendar
 https://persistentsystems.sharepoint.com/sites/Pi/SitePages/Holiday-Viewall.aspx
 
 Right click on Dell Latitude not working
  dell latitude 3410 i7.. you can see right click of touch pad not working.. Dont do anything...just use two fingers for right click anywhere on touch pad 
  
  -------------------------------------------------------------------------
  
  autofs config file
  
   cat /etc/auto.nfs
   edit the sds source to be a yum server instead of sol and then restart autofs service to take it into effect
   
   hkg02ammyum01
   hkg02ammyum01
   ----------------------------------------------------------------------------------
   
   Impacted environment
   
   To add the Impacted Environment.

    Under the Impacted Environments tab of the ticket, click New and enter the SID impacted by this Sev (click on the magnifying glass to see available options).  
    Enter a summary of the issue in Short Description.
    Determine the proper number of SLA Impacting minutes (how long was the system actually unavailable for the client), and update the "SLA Impacted Minutes" field.  If none, enter a zero.  Do not leave this field blank
    If the SID isn't found in the 1st step, follow the instructions in Slides 3 & 4 of the presentation deck (link below).  
    Enter the DPEs name in the "SLA Minutes Approver" field.

See the presentation deck at https://ibm.box.com/s/9kcjrtbrfnzt99ht4z04o7d9k20ksnmt for more details.

-----------------------------------------------------------------------------------------------

Cluster patching

OS patching Procedure for Pacemaker Cluster
https://github.ibm.com/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/SAP_Application_%20Cluster_OS_Patching_Procedure.md

and

https://github.ibm.com/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/PACEMAKER_CLUSTER_SP2_SP4_MIGRATION_STEPS.md

make sure the cluster is in managed mode, and stop pacemaker on both nodes

Current Build Plan:
1 Put cluster into unmanaged mode
2 Bring down apps on node2 (node where ERS resides)
3 Perform SP4 Upgrade on node2
4 Bring back the cluster service UP after OS reboot
5 Start the apps back on node2
6 Put the cluster back into managed mode
7 Migrate ASCS from node1 to node2 and make sure that ASCS resource stays in node2 and does not move back to node1
8 Put cluster back into unmanaged mode
9 Bring down apps on node1
10 Perform SP4 Upgrade on node1
11 Bring back the cluster service UP after OS reboot
12 Bring up apps on node1
13. Put cluster back into managed mode


validation script 
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py

/usr/bin/python3.6 /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py


crm configure show >>/tmp/configure_backup
crm configure edit	and :wq to save	
commit(to save changes)


Cluster Configuration

Primitive corrections are to be done on any of the the cluster nodes
fence_vmware_soap:

cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/fence_vmware_rest /usr/sbin/fence_vmware_rest
chmod 755 /usr/sbin/fence_vmware_rest

Latest validation script
https://github.kyndryl.net/CMS/BuildMigration/blob/master/Archive

crm configure show >>/tmp/configure_backup
A quick text backup can be taken of your cluster configuration using the following command.
# crm configure show > /root/cib_backup.txt
To restore a cib from a backup file previously created.
# crm configure load replace /root/cib_backup.txt


or 
crm configure save /var/cluster_file


Link for primitive changes NEW

 https://github.kyndryl.net/CMS/SAP-Base-RR/tree/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4
 https://github.ibm.com/CMS/SAP-Base-RR/tree/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4

VMWare fencing https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/Vcenter%20Fencing.md

DB2  https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/SLES_12_SP4_DB2_CLUSTER_PRIMITIVES.md
ABAP https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/SLES_12_SP4_ABAP_CLUSTER_PRIMITIVES.md
JAVA https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/SLES_12_SP4_JAVA_CLUSTER_PRIMITIVES.md
Oracle https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/SLES_12_SP4_ORACLE_CLUSTER_PRIMITIVES.md
Sybase https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/SLES_12_SP4_SYBASE_CLUSTER_PRIMITIVES.md

Search for SAPInstance or order or group and update the SAP instance with uppar case name


SAP profile error Instance name in caps to be updated
# Start ASCS Application. 
primitive rsc_sap_B1U_ASCS00 SAPInstance \
        operations $id=rsc_sap_B1U_ASCS00-operations \
        op start interval=0 timeout=240 \
        op stop interval=0 timeout=240 \
        op monitor interval=11s on-fail=restart timeout=60s \
        params InstanceName=B1U_ASCS00_sdm-b1u-ascs START_PROFILE="/sapmnt/B1U/profile/B1U_ASCS00_sdm-b1u-ascs" AUTOMATIC_RECOVER=false \
        meta resource-stickiness=5000 failure-timeout=60 migration-threshold=1 priority=10
        
# Start ERS Application.        
primitive rsc_sap_B1U_ERS10 SAPInstance \
        operations $id=rsc_sap_B1U_ERS10-operations \
        op start interval=0 timeout=240s \
        op stop interval=0 timeout=240 \
        op monitor interval=11s timeout=120s \
        params InstanceName=B1U_ERS10_sdm-b1u-ers START_PROFILE="/sapmnt/B1U/profile/B1U_ERS10_sdm-b1u-ers" IS_ERS=true AUTOMATIC_RECOVER=false \
        meta priority=1000

group cross-mnt-fs mountfs-3rdPartySoftware_lv mountfs-interface_lv mountfs-sapmnt_lv mountfs-int_lv
group g-ers ip-ers vol_pg1ersvg fs-ers_lv rsc_sap_PG1_ERS02
group g-global ip-nfs vol_pg1globalvg fs-3rdPartySoftware_lv fs-interface_lv fs-sapmnt_lv export-3rdPartySoftware_lv export-interface_lv export-sapmnt_lv \
        meta target-role=Started
group g-scs ip-ascs vol_pg1ascsvg fs-ascs_lv rsc_sap_PG1_ASCS01
ms ms-drbd-ers DRBD2-res \
        meta master-node-max=1 clone-max=2 clone-node-max=1 globally-unique=false notify=true target-role=Started
ms ms-drbd-global DRBD0-res \
        meta master-node-max=1 clone-max=2 clone-node-max=1 globally-unique=false notify=true target-role=Started
ms ms-drbd-scs DRBD1-res \
        meta master-node-max=1 clone-max=2 clone-node-max=1 globally-unique=false notify=true target-role=Started
clone clone-crossmnt cross-mnt-fs \
        meta clone-max=2 target-role=Started
order all_order_crossmnt Mandatory: g-global:start clone-crossmnt symmetrical=false
order all_order_drbd Optional: ms-drbd-scs:promote ms-drbd-ers:promote symmetrical=false
order all_order_drbd_ascs Mandatory: ms-drbd-scs:promote g-scs:start symmetrical=true
order all_order_drbd_ers Mandatory: ms-drbd-ers:promote g-ers:start symmetrical=true
order all_order_nfs Mandatory: ms-drbd-global:promote g-global:start symmetrical=true
colocation ascs-deps 100: ms-drbd-scs:Master g-scs
colocation col_sap_no_both -5000: g-ers g-scs
colocation ers-deps 50: ms-drbd-ers:Master g-ers
colocation global-deps inf: g-global ms-drbd-global:Master
location loc-vcenter-fencing-lbupg1ap01 vcenter-fencing-lbupg1ap01 -inf: lbupg1ap01
location loc-vcenter-fencing-lbupg1ap01ha vcenter-fencing-lbupg1ap01ha -inf: lbupg1ap01ha
order rsc_fs_then_export_then_mount Optional: g-global clone-crossmnt rsc_sap_PG1_ASCS01:start rsc_sap_PG1_ERS02:stop symmetrical=false



validation script 
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py
backup of configure file b4 making primitive changes
crm configure show >>/tmp/configure_backup
crm configure edit	and :wq to save	
commit(to save changes)


/usr/bin/python3.6 /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py


https://github.kyndryl.net/CMS/BuildMigration/wiki/Step-by-step-DRBD-with-pacemaker-setup-for-SAP-NW

primitive ITM_POP_SYB systemd:koyagent \
        op start interval=0 timeout=100 on-fail=ignore \
        op stop interval=0 timeout=100 on-fail=ignore \
        op monitor interval=60 enabled=false on-fail=ignore timeout=100
primitive TSM_SYB systemd:dsmcad_syb \
        op start interval=0 timeout=100 on-fail=ignore \
        op stop interval=0 timeout=100 on-fail=ignore \
        op monitor interval=60 enabled=false on-fail=ignore timeout=100 \

Pacemaker training modules
https://w3.ibm.com/w3publisher/oswiki/pacemaker

Your Learning: https://ec.yourlearning.ibm.com/w3/series/10122066?layout=grid

Samuel portal link for cluster actions
https://sapops.containers.ciocloudservices.ibm.com/
New link https://samuel.sap.mgapp.ibm.com

https://samuel.sap.mgapp.ibm.com/SM9/servers

https://samuel.sap.mgapp.ibm.com/ALL/campaignOverview?id=623109e9155bc60cb7f87f91

#samuel-support





cat /etc/passkey
crmstnmgr:0lLXHrpVrGFIYT9v5gHoCwtCmL7OK_ANvfO4VbEH-wQ=$gAAAAABdsaHJ5yO0pGiqkoYVMJ0bLYoRstW8hbwZ6EZtVXEZvtEPATLpZq_cuGKM-XpNnj12KEAibtgP-OL6YXNVU5p-B2RnvV40-y11uRNmDt9d7py9S2M=
crmstnmgr:Ah1jjw3yFkC79FZxBsVToNJoCNz9NNwkyII6dV-AtCE=$gAAAAABeJ_qomH6CexZ32Lvefj_lxZhVI1ejhLVK3VcEkQgR6rZYp-Hm4JBI4-clbxUkxGfGT-4-B3ta7lEkC7S6Y4WWUIEWuQcq2udOXMJucZvULK4XFLg=


primitive vcenter-fencing-<HOSTNAME> stonith:fence_vmware_soap \
        params ipaddr=<VCENTER_IP> login="vsphere.local\crmstnmgr" ipport=443 ssl=1 ssl_insecure=1 passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60  shell_timeout=600 \
        op stop interval=0 timeout=20s \
        op start interval=0 on-fail=restart timeout=40s \
        op monitor interval=600s \
        meta maintenance=false
fence_vmware_rest:

primitive vcenter-fencing-<HOSTNAME> stonith:fence_vmware_rest \
       params ipaddr=<VCENTER_IP> login="vsphere.local\crmstnmgr" plug=<HOSTNAME> password_script="/usr/local/sbin/getpass.py -g crmstnmgr" shell_timeout=60 ssl=1 ssl_insecure=1 login_timeout=60 filter="filter.names=<HOSTNAME>"
       op stop interval=0 on-fail=ignore timeout=60s
       op start interval=0 on-fail=restart timeout=60s
       op monitor enabled=false on-fail=restart timeout=60s interval=0
       
       
       
primitive vcenter-fencing-node1 stonith:fence_vmware_rest
params ipaddr=146.89.142.92 login="vsphere.local\crmstnmgr" plug=ewmapp3-ha password_script="/usr/local/sbin/getpass.py -g crmstnmgr" shell_timeout=60 ssl=1 ssl_insecure=1 login_timeout=60 filter="filter.names=ewmapp3-ha"
op stop interval=0 on-fail=ignore timeout=60s
op start interval=0 on-fail=restart timeout=60s
op monitor enabled=false on-fail=restart timeout=60s interval=0


Non Hana cluster 

https://github.kyndryl.net/CMS/BuildMigration/wiki/Pacemaker-cheat-sheet	Nithya Wiki

https://github.kyndryl.net/CMS/SAP-Base-RR/wiki		Dileep's wiki       
       
https://github.kyndryl.net/CMS/SAP_Base-HA_Operation/wiki   Management script

https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/	SOPs

Add New disk to cluster volume
https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/CMAS%203x/Pacemaker/Add%20New%20disk%20for%20Filesystem%20extend.md

Adding and removing cross-mount NFS to Pacemaker non-HANA cluster
https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/Adding%20and%20Removing%20Cross-mount%20NFS%20to%20Pacemaker%20Non-Hana%20Cluster.md

https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/Filesystem_extension_steps.md

Note : SRM replication for DR(if enabled) should be stopped, otherwise extending disk will not work

Note : Disk can be extended upto a maximum size of 512 GB, suggest to add new disk if more space is needed

Put the cluster in maintenance mode before adding / removing primitives.

1. Kernel parameters settings change on primary node
#sysctl -w vm.dirty_bytes=629145600  >> /etc/sysctl.d/99-sysctl-hana.conf
#sysctl -w vm.dirty_background_bytes=314572800  >> /etc/sysctl.d/99-sysctl-hana.conf
#sysctl -w vm.drop_caches=3 >> /etc/sysctl.d/99-sysctl-hana.conf
#sysctl -w vm.dirty_ratio=0 >> /etc/sysctl.d/99-sysctl-hana.conf
#sysctl -w vm.dirty_background_ratio=0 >> /etc/sysctl.d/99-sysctl-hana.conf
2. Modify /etc/default/grub , add below elevator setting before "quite" in the kernel line - On both primary and HA nodes, but only primary node needs a reboot.
#elevator=noop
#grub2-mkconfig -o /boot/grub2/grub.cfg
#shutdown -fr now


tsls4proddbh:~ # cat /sys/block/sda/queue/scheduler
[noop] deadline cfq
You have mail in /var/spool/mail/root
tsls4proddbh:~ # cat /sys/block/sdb/queue/scheduler
[noop] deadline cfq
tsls4proddbh:~ # cat /sys/block/sdc/queue/scheduler
[noop] deadline cfq
tsls4proddbh:~ # cat /sys/block/sdd/queue/scheduler
[noop] deadline


just change  the disk  name

sda,sdb

on whatever  disk is  available with lsblk and run the command  cat /sys/block/sdX/queue/scheduler and change any cfq to noop

This change improves CPU performance

Validation script
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py

/usr/bin/python3.6 /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py


HANA DB validation script
/opt/ibm/HDBHA/Operations/hanaconfigvalidation/HDBHA_HanaPostBuildValidation.sh

In above SapDbRecovery.sh is one consolidated scrit that smartly figures out if the cluster is app or DB     ONLY FOR NON HANA
separate scripts for app and db are SapRecovery.sh and DatabaseRecovery.sh respectively but sugegsted to use SapDbRecovery

  		     1:  Recover Cluster                                     |                                                            |
|         |          2:  Maintain Cluster                                    |                                                            |
|         |          3:  Cluster Status                                      |                                                            |
|         |          4:  Exit   


Click each option to find, Recover cluster helps to fix any issues and works in most scenario.

Use “crmresource migrate <resource_name> <node_name>”to migrate one resource to another node.

if you use command “crm node standby <nodename>”  command, all resources on that node will moved to the second node. Use “crmnode online <nodename>” to bring the node back online. This is the suggested way to do a failover test


Viewing the Cluster History •“crmhistory”  commands displays the history of previous cluster actions. Below are some of the subcommands, but not all are listed. Use “help” subcommand to get details. “crmhistory” command can also be used for viewing recent events of nodes or resources 

Maintenance Mode–This option allows you to put all resources running on a specific node into maintenance state at once. •Putting a Node into Standby Mode–A node that is in standby mode can no longer run resources. Any resources running on the node will be moved away or stopped. You can use this option if you need to stop a node in a cluster while continuing to provide the services running on another node.•Putting a Resource into Maintenance Mode–When this mode is enabled for a resource, no monitoring operations will be triggered for the resource. •Putting a Resource into Unmanaged Mode–The is-managed meta attribute allows you to temporarily “release” a resource from being managed by the cluster stack. This means you can manually touch the service that is managed by this resource. However, the cluster will continue to monitor the resource and report any failures.


•Rebooting a Cluster Node While in Maintenance Mode•If the cluster or a node is in maintenance mode, you can stop or restart cluster resources, cluster will not attempt to restart them. If you stop the Pacemaker service on a node, all cluster resources will continue to run.•If you attempt to start Pacemaker services on a node while the cluster or node is in maintenance mode, Pacemaker will initiate a single one-shot monitor operation (a “probe”) for every resource to evaluate which resources are currently running on that node. However, it will take no further action other than determining the resources' status.


mportant log files
•/var/log/messages
•/var/log/cluster/corosync.log
•Journalctrllogs

How to extend file system managed by the cluster (Hana and Non-Hana) 
•https://github.ibm.com/CMS/SAP-Base-RR/blob/master/CMAS%203x/SOPs/Filesystem_extension_steps.md


•Node Crashes -Common root causes 
•When there is a problem with communication between nodes, one of the node will be fenced
•When pacemaker does not get  a response from a resource for the specified timeout, it restarts the resource on the current node 3 times . If the resource failed more than 3 times on the current node, pacemaker will initiate a failover.
•If a resource stop operation fails for any reason, the node will be fenced


•DRDB Devices Broken after Reboot 
•In cases when DRBD does not know which of the real devices holds the latest data, it changes to a split-brain condition. In this case, the respective DRBD subsystems come up as secondary and do not connect to each other. In this case, the following message can be found in the logging data:Split-Brain detected, dropping connection!
•To resolve this situation, enter the following commands on the node which has data to be discarded:
drbdadmsecondary r0
If the state is in WFconnection, disconnect first:
drbdadmdisconnect r0
On the node which has the latest data enter the following:
drbdadmconnect  --discard-my-data r0

That resolves the issue by overwriting one node's data with the peer's data, therefore getting a consistent view on both nodes.

HANA DB scripts and docs
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/README.md

Main github url for HANA DB cluster https://github.ibm.com/CMS/cms-sq-sap-hana-rr-hana_ha_documentation
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/tree/master/Operations_Guide

HANA DB cluster Operations guide 
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/tree/develop/Operations_Guide

HANA DB primitives
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/develop/Operations_Guide/13_ClusterResourcePrimitivesChange.md

Python script like SAPDBRecovery for HANA DB  HDBHA_HanaHAOpsPortal.py
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/develop/Operations_Guide/A00_HanaHAOpsPortalOperationsGuide.md

################## START RESOURCES ##########################
crm resource start rsc_stonith-sbd
crm resource start rsc_TSMTDP_EHP_HDB00
crm resource start rsc_ip_EHP_HDB00


# Resource Handling
crm resource stop <name>
crm resource start <name>
crm resource move <Resource_name> <nodename>

EG
crm resource move group-ORA zffpdb001   can be run from any node
After move is complete 
after move is complete
crm resource clear group-ORA

# Unmanaged Mode for single services
crm resource unmanage <name>
crm resource manage <name>


KB0015258
One note is that the cluster for the app and DB needs to remain / be set to maintenance mode.
KB0015258 - Procedure for cluster resources on ECP SAP system
KB0013664 - Procedure to stop / start ECP SAP System
KB0013680 - Customer Policies and Procedure document
HOSTNAME        IFN
armfksap303a1   10.7.102.57
armfksap303ap   10.7.102.59
armfksap404d1   10.7.102.91 -- DB Server
armfksap404db   10.7.102.38 -- DB Server
armfksdr404d1   10.14.105.221 (edited) -- DR Replication
Issue -- HANA DB went down, and after following KB0015258 application could not start on armfksap303a1  10.7.102.57.
Resources in DB cluster were stopped before and after start of DB.
NOTE -->> All Resources always should be up when handovering to team/customer else atlest inform them during handover resources are stopped and do we need to bring up ?
Cluster resources should be up on applications server as well.
 rsc_stonith-sbd        (stonith:external/sbd): Stopped (unmanaged)
 rsc_TSMTDP_EHP_HDB00   (systemd:dsmcad_hana):  Stopped (unmanaged)
 rsc_ip_EHP_HDB00       (ocf::heartbeat:IPaddr2):       Stopped (unmanaged)
 Master/Slave Set: msl_SAPHana_EHP_HDB00 [rsc_SAPHana_EHP_HDB00] (unmanaged)
     Stopped: [ armfksap404d1 armfksap404db ]
 Clone Set: cln_SAPHanaTopology_EHP_HDB00 [rsc_SAPHanaTopology_EHP_HDB00] (unmanaged)
     rsc_SAPHanaTopology_EHP_HDB00      (ocf::suse:SAPHanaTopology):    Started armfksap404db (unmanaged)
     Stopped: [ armfksap404d1 ]
######################################################################################
SAP team logged into armfksap303a1  10.7.102.57
Su - ecpadm
R3trans -X  <-- command 
Some SQL errors ( No route to host ( 10.244.102.184 :300411 )
grep 10.244.102.184 /etc/hosts
10.244.102.184 dbcls-arm-ehp.mondadori.it.dbc-arm-ehp
cluster resource rsc_ip_EHP_HDB00 has ip 10.244.102.184 and that ip used by application server.
Alternate solution -- 
can we try to move it back to manage, start IP resource and then move it back to maintance since it is unstable?
##########################################################################################
Points to be check
1.Each resource has assigned ip so, check ip has connectivity from same server and from application server vice versa
2.All resources should be always up when doing handover cluster to customer.
3.Resources can be start indivual.
############################################################################
################## START RESOURCES ##########################
crm resource start rsc_stonith-sbd
crm resource start rsc_TSMTDP_EHP_HDB00
crm resource start rsc_ip_EHP_HDB00



@sybille.kurz  @adam_zboril  from HANA DB cluster team
hana_validation_script    slack channel


[root@ewmapp3 ~]# systemctl stop pacemaker ; ssh ewmapp3-ha "systemctl stop pacemaker"
[root@ewmapp3 ~]# systemctl start pacemaker ; ssh ewmapp3-ha "systemctl start pacemaker"
-----------------------------------------------------------------------

no sound on dell latitude

sudo dnf install alsa-sof-firmware

------------------------------------------------------------------------------------------

whenever a chassi swap is done from SL, storage "may" need to be authorized again, mostly as FYI for another similar work
any NFS coming on the pHANA or vHANA needs to be checked on SL portal for authorisation.

When a chassis swap is performed on a server that has file/block storage.  It is essential to unauthorize and re-authorize the same ip's / servers to the file/block storage to restore the connections again.


---------------------------------------------------------------------------------------------------------------------
coredump location

find your core file in /var/cache/abrt, where abrt stores 

find / -name "*core. *"

----------------------------------------------------------------------------------------
threshold for any FS via Nagios
 /usr/local/ncpa/plugins/cmas_check_diskfree.sh /sapmnt/log
OK: Free 541873.99MB/97.42% (thresh @5.01:10%) | Total=556249.26;; FreeMB=541873.99mb;; FreePCT=97.42%;;@5.01:10;

---------------------------------------------------------------------------------------------------

1.x access
upload key to
https://sni-id.emea.ibm.com/cgi-bin/sshKeyManagement.pl


check LDAP id at 
https://itimde01.de.ibm.com/itim/self/ChangeAccount.do


LDAP groups for 1.x
https://sni-id.emea.ibm.com/cgi-bin/showGroupMembership.pl



ssh key generation https://www.adamdehaven.com/blog/how-to-generate-an-ssh-key-and-add-your-public-key-to-the-server-for-authentication/#check-for-existing-ssh-keys

local terminal
ssh-keygen -t rsa -b 2048
enter
enter
enter

cat .ssh/id_rsa.pub
copy keys and up load to link
--------------------------------------------------------------------------------------------------------------------------------

reinstall ncpa

To check if manually uninstall of Nagios agent and running chef will reinstall it

knife node show <nodename> -c /etc/chef/client.rb
You can find node name in /etc/chef/client.rb
cat /etc/chef/client.rb | grep node

set the policy with 
knife node policy set <nodename> production cms3x_chef_client -c /etc/chef/client.rb

[root@wa2bwpap02 ~]# knife node show "wa2bwpap02.imzcloud.ibmammsap.local" -c /etc/chef/client.rb
Node Name:   wa2bwpap02.imzcloud.ibmammsap.local
Policy Name:  cms3x_cfg
Policy Group: production
FQDN:        wa2bwpap02.wawa.com
IP:          10.150.6.10
Run List:    recipe[cms_chef_client::default], recipe[cms_sap_plugins::default], recipe[sap_base_pe_inspec::default], recipe[bag2attr::default], recipe[cms_ssh_keys::default], recipe[cmsd_itim::default], recipe[cms3x_cfg::default], recipe[fms-sudo::default], recipe[fms_lvm::default], recipe[cms_core_file_mgmt::default], recipe[fms_tsm_os::default], recipe[sap_hana_ohai::default], recipe[data_provider::default], recipe[cms3x_cfg::salt]
Recipes:     cms_chef_client::default, cms_sap_plugins::default, sap_base_pe_inspec::default, bag2attr::default, cms_ssh_keys::default, cmsd_itim::default, cms3x_cfg::default, fms-sudo::default, fms_lvm::default, cms_core_file_mgmt::default, fms_tsm_os::default, sap_hana_ohai::default, data_provider::default, cms3x_cfg::salt, chef-client::config, chef-client::default, chef-client::service, chef-client::systemd_service, chef-client::delete_validation, cms_chef_client::chef_gems, cms_chef_client::ohai, cms_chef_client::suse, audit::default, audit::inspec, cms_ssh_keys::add_ssh_keys, ibm_ssh_check::default, cmsd_itim::linux, cms3x_cfg::etc, cms3x_cfg::sysctl, cms3x_cfg::mtu, cms3x_cfg::selinux, cms_smt::client, smt::configure_client, cms3x_cfg::smt_repos, cms3x_cfg::resolver, resolver::default, timezone_iii::default, timezone_iii::suse, cms3x_cfg::autofs, cms3x_cfg::ntp, cms3x_cfg::linuxad_auth, linuxad_auth::default, fms-base::default, fms-base::disable_apparmor, fms-base::nonexpiry_optiond, fms-base::disable_auditd, fms-base::grub, fms-base::disable_iptables, fms-base::sudo_helper, cms3x_cfg::tscm, tscm::default, tscm::packages, sei_nagios::default, cms_chef_client_updater::default, cms_chef_client_updater::update_gems, cms_chef_client_updater::chef_client_updater, policy_all_deep_security::default, policy_all_deep_security::remove_sep, cms3x_cfg::iamlabel, cms3x_cfg::firewall, itcs104_bundle::default, itcs104_bundle::gems, policy_linux_directory_perms::default, policy_linux_entire_dir_perms::default, policy_linux_failed_login_retries::default, policy_linux_file_permissions::default, policy_linux_pam_default_deny_all::default, policy_linux_pass_max_age::default, policy_linux_pass_min_age::default, policy_linux_pass_min_len::default, policy_linux_password_history::default, itcs104_bundle::login_defs, itcs104_bundle::sshd_config, itcs104_bundle::logrotate, itcs104_bundle::ibmsinit, itcs104_bundle::syslog, itcs104_bundle::root_permissions, itcs104_bundle::serviceids_file, itcs104_bundle::full_path, itcs104_bundle::file_perms_linux, cms_core_file_mgmt::manage_core_limits, fms_tsm_os::tsm_client, sap_hana_ohai::install_sap_hana_ohai, sei_salt::default
Platform:    suse 12.4
Tags:

yes in cms3x_cfg policy it would work fine

check if chef client run was successful and only then will this succeed.

Backout
========
/usr/local/ncpa/scripts/remove-nagios-base.sh
backout the NCPA setup, you can run:
     rpm -e ncpa
     /bin/rm -rf /usr/local/ncpa
Then, remove the cron jobs from either:
    /etc/cron.d
    the root user's crontab file
Installation
=============
Step 1) Download ncpa agent
        https://github.ibm.com/cmas-nagios-dev/ProductionAgents/blob/master/UnifiedAgent%20-%20Linux-Unix/IBM_UNIX_Unified_Agent_v5.86.tar.gz
Step 2) Move the tar file to the /tmp directory of the end node, and extract the files.
         as root, do
         cd /tmp/
         gunzip < IBM_UNIX_Unified_Agent.*.tar.gz | tar xvf -
Step 3) cd /tmp/nagios-base/
        ### For initial INSTALL
       ./setup-nagios-base.sh --ibm {LowerCase_IBM_Hostname} 158.87.46.181
Step 4) check the vservice status
        service ncpa_listener status
        service ncpa_passive status
        ps -ef|grep ncpa_

------------------------------------------------------------------------------------------------------------

Delete files older than 90 days

find /path/to/directory/ -mindepth 1 -mtime +90 -delete
That's it, no separate rm call and you don't need to worry about file names.

Replace -delete with -depth -print to test this command before you run it (-delete implies -depth).

----------------------------------------------------------------------------------------------------------------

temporary connect to IBM n/w

Cisco anytime
Connect to Cisco AnyConnect via the temporary gateway(sasvpn03.pok.ibm.com/gettingstartedpok)

-----------------------------------------------------------------------------------------------------------------

new disk added shows here

cd /sys/class/scsi_disk/

if unable to scan, enter the scci id in below to scan explicitely
To rescan newly added disk use this command
echo 1 > /sys/class/scsi_disk/0\:0\:15\:0/device/rescan   "scsi_disk/0\:0\:15\:0 = Replace new disk scci label before executing above command ".

or use
scan newly added disk in VC
scan all controller
echo "- - -" | tee /sys/class/scsi_host/host*/scan   to scan any missing volumes

rescan-scsi-bus.sh -a

Post deleting the disk from VC to remove from the server

echo "1" > /sys/block/sdX/device/delete

for host in `ls /sys/class/scsi_host`; do echo "Scanning $host...Completed"; echo "- - -" > /sys/class/scsi_host/$host/scan; done


ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[:/]' '{print $4,"- SCSI",$8":"$9}'

ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[:/]' '{print $4,"- SCSI",$7":"$9}'



If the disk is removed from VC but still shows in the server then chk in cd /sys/class/scsi_disk/ for all disks and find the scsi id and delete it from vm
[root@ttactrl01 scsi_disk]# ls -ltr
total 0
lrwxrwxrwx. 1 root root 0 Feb 26 12:19 0:0:0:0 -> ../../devices/pci0000:00/0000:00:10.0/host0/target0:0:0/0:0:0:0/scsi_disk/0:0:0:0
lrwxrwxrwx. 1 root root 0 Feb 26 12:19 0:0:2:0 -> ../../devices/pci0000:00/0000:00:10.0/host0/target0:0:2/0:0:2:0/scsi_disk/0:0:2:0
lrwxrwxrwx. 1 root root 0 Feb 26 12:19 0:0:1:0 -> ../../devices/pci0000:00/0000:00:10.0/host0/target0:0:1/0:0:1:0/scsi_disk/0:0:1:0
lrwxrwxrwx. 1 root root 0 Feb 26 13:36 0:0:3:0 -> ../../devices/pci0000:00/0000:00:10.0/host0/target0:0:3/0:0:3:0/scsi_disk/0:0:3:0


[root@ttactrl01 scsi_disk]# echo 1 > /sys/class/scsi_disk/0\:0\:3\:0/device/delete
[root@ttactrl01 scsi_disk]# ls -ltr
total 0
lrwxrwxrwx. 1 root root 0 Feb 26 12:19 0:0:0:0 -> ../../devices/pci0000:00/0000:00:10.0/host0/target0:0:0/0:0:0:0/scsi_disk/0:0:0:0
lrwxrwxrwx. 1 root root 0 Feb 26 12:19 0:0:2:0 -> ../../devices/pci0000:00/0000:00:10.0/host0/target0:0:2/0:0:2:0/scsi_disk/0:0:2:0
lrwxrwxrwx. 1 root root 0 Feb 26 12:19 0:0:1:0 -> ../../devices/pci0000:00/0000:00:10.0/host0/target0:0:1/0:0:1:0/scsi_disk/0:0:1:0

checking lsblk also shows the disk removed


-----------------------------------------------------------------------------

Nagios server not connecting
Infra sev1 issues
#inf-global-tech1 

---------------------------------------------------------------------------
Better Linux Disk Caching & Performance with vm.dirty_ratio & vm.dirty_background_ratio

https://lonesysadmin.net/2013/12/22/better-linux-disk-caching-performance-vm-dirty_ratio/


-----------------------------------------------------------------------------------------------

Delete snapshot from brtfs filesystem


https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-snapper.html#sec-snapper-manage-delete

-------------------------------------------------------------------------------------------------------

mount: special device /dev/mapper/vg_01-lv_backupp1 does not exist

https://access.redhat.com/solutions/156363

-------------------------------------------------------------------------------------------------------

For Nagios alert validation:
You can also check real quick via the Nagios Portal, Kindly do take some time to get some credentials to the MHAS Nagios Portal.
Also share with the team where possible.
Link to the portal:
https://mhasportal.mhas.ibm.com/NagiosPortal/Login.jsp
Access requests process:
Kindly check on #nagiossupport slack channel.
https://ibm.enterprise.slack.com/files/W4T70P12T/F01725GBKC0/nagios_portal_access_form.xlsx


---------------------------------------------------------------------------------------------------------


https://kyndryl.ent.1password.com
ravi.malik@kyndryl.com
A3-BK78L3-FJZXKD-STECN-2VQL2-SM89J-YHH98
Aug2023&Oct2023



--------------------------------------------------------------------------------------------------------
Naios portal

MHAS Nagios Portal link :
https://146.89.173.200/NagiosPortal/src.do
Username :
ravi.malik@kyndryl.com

pw R@vi@03T@n@y@16



https://uat.us.ibm.com/iam/
SEi/MHAS username inavsc7c

pin 3281
chlorine88


pw Home204@HighBliss

-------------------------------------------------------
Build team SNOW group
SQ-SAP-BUILD-MON
IBM Managed Apps SNOW URL will be updated to new URL https://kyndrylcsm.service-now.com.
 The current plan is to make this change around 12:00 PM IST, 1:30 AM EST on the 16th November. Please update any bookmarks, favorites you may have to the new Kyndryl CSM url. we are sending out this communication to our end users:
You will login using your Kyndryl W3 Id SSO to the new URL https://kyndrylcsm.service-now.com .

--------------------------------------------------------------------------

 https://w3.ibm.com/w3publisher/onboarding-process-b-tribe/
A useful link for our daily access or support issues
New Hires Onboarding Process

-------------------------------------------------------------------------------------
Setfacl for giving special permission to a specific user

Specific permission to a user to a specific path only
setfacl -m u:user:permission /path/to/directory


If you face error “Operation not supported”, while tryin to give specific permission to a user using "setfacl"
Check if fs has 'acl' mount option enabled

tune2fs -l /dev/mapper/vg_name-lv_name | grep 'mount option'
note- it will give you below output, if it is not added
Default mount options:    (none)

If not then we have to add 'acl' mount option for that fs
tune2fs -o acl /dev/mapper/vg_name-lv_name
Check again if acl is added or not

tune2fs -l /dev/mapper/vg_name-lv_name | grep 'mount option'
once successful added it will show below output
option'
Default mount options: acl  
after that remount that fs
mount -t ext4 -o remount,acl /dev/mapper/vg_name-lv_name /path/directory
It will successfully moun that fs with acl option
After that run that setfacl command
setfacl -m u:username:r-x /path/directory


502  2021-03-24 16:45:54 setfacl -m u:msgkaren:rx /usr/sap/FSPRO
  503  2021-03-24 16:47:50 getfacl /usr/sap/FSPRO
  504  2021-03-24 16:50:21 setfacl -m u:msgkaren:rx /usr/sap/FSPRO
  505  2021-03-24 16:51:18 df -h |grep /usr/sap
  506  2021-03-24 16:51:27 df -h
  507  2021-03-24 16:52:46 setfacl -m u:msgkaren:rx /usr/sap/
  508  2021-03-24 16:53:05 df -h
  509  2021-03-24 16:54:26 tune2fs -l /dev/mapper/vg_app-lv_usrsap                  |grep 'mount option'
  510  2021-03-24 16:59:27 tune2fs -o acl /dev/mapper/vg_app-lv_usrsap
  511  2021-03-24 16:59:57 tune2fs -l /dev/mapper/vg_app-lv_usrsap                  |grep 'mount option'
  512  2021-03-24 17:00:38 setfacl -m u:msgkaren:rx /usr/sap/FSPRO
  513  2021-03-24 17:01:00 setfacl -m u:msgkaren:rx /usr/sap/
  514  2021-03-24 17:01:42 setfacl -m u:msgkaren:r-x /usr/sap/
  515  2021-03-24 17:03:01 cat /etc/redhat-release
  516  2021-03-24 17:04:47 getfacl /usr/sap/FSPRO
  517  2021-03-24 17:12:37 df -hT /usr/sap/
  518  2021-03-24 17:18:38 cat /etc/fstab
  519  2021-03-24 17:25:37 mount |grep /usr/sap/
  520  2021-03-24 17:26:05 df -hT /usr/sap/
  521  2021-03-24 17:26:33 mount |grep 'usrsap'
  522  2021-03-24 17:27:26 cat /etc/fstab
  523  2021-03-24 17:29:31 mount -t ext4 -o remount,acl /dev/mapper/vg_app-lv_usrsap /usr/sap
  524  2021-03-24 17:30:17 mount |grep 'usrsap'
  525  2021-03-24 17:30:48 setfacl -m u:msgkaren:r-x /usr/sap/FSPRO
  526  2021-03-24 17:31:25 su - msgkaren

----------------------------------------------------------------------------------------------------------------

Use shopt -s cdspell to correct the typos in the cd command
# cd /etc/mall
-bash: cd: /etc/mall: No such file or directory
# shopt -s cdspell
# cd /etc/mall
# pwd
/etc/mail
[Note: By mistake, when I typed mall instead of mail, cd
corrected it automatically]



grep "^Nov 10" messages.1    ^ for beginning of line matching

grep "terminating.$" messages	End of the line ( $)

grep "kernel: *." *

------------------------------------------------------------------------------------------
Change tasks for physical box  ref change for change tasks  CHG0198862

Prerequisites:
Non -prod
1. Take HANA DB backup to TSM and NFS directory mounted from other server..

For Pro  servers:- 
2. Take Production (Patching system) HANA DB backup to Quality system.
3 - Take QA HANA DB backup to Quality system.

4 - Make sure that NO hardware error
5 - Confirm with SL Team that required spare are readily available.


Implementation:

3. If DR is available, stop the replication

sapcontrol –nr <IN> -function StopSystem HDB
hdbnsutil -sr_unregister

4. Perform Firmware Upgrade

Stop the SAP Application and database.
Shutdown the server and power off the server from Softlayer portal.
Initiate the firmware upgrade from Softlayer portal.
IBM Softlayer Engineer monitor the transactions and provide timely update.
Validate the server once firmware Upgrade completed by Softlayer Team.
Start Database and Application and validate.

5. Configure replication to DR site if available from step 3.

hdbnsutil -sr_register --remoteHost= <Prod hostname> --remoteInstance=<IN> --mode=ASYNC –name=HANADR<SID>

sapcontrol –nr <IN> -function StartSystem HDB

Backout Plan:

Restore backup taken in step 2 to quality HANA and connect to production application servers

Option 1: MultiDB: Create a new tenant for prod and restore
Based on RAM availability stop quality tenant and start prod tenant only. 

Option 2: SingleDB: Restore to quality HANA database. 

Command to check MultiDB/SingleDB: 
# hdbnsutil -printSystemInformation

hdbnsutil -sr_state



Backout plan
Option1:-
Replace the faulty Hardware unit - Softlayer Team.

Option2:-
Rebuild the server with same hostname and IP and restore the Data from backup.

    1 - Basic OS build  ---→ Softlayer team
    2 - Access the server via SL Management IP and configure the network  -->IBM Provisioning Team
    3 - Execute the build script and install the DB and configure the server ---->IBM Provisioning Team
    4 - Bootstrap the server ( install IBM internal tool) -- IBM Provisioning Team
    5 - Restore the /etc from FS backup to alternate PATH and refer the below files and configure the  OS (IBM Provisioning Team/OS Team )
        /etc/fstab
        /etc/motd
        /etc/passwd
        /etc/group
        /etc/resolv.conf
        /etc/cron.d
        /etc/sysctl.d
        /etc/hosts
        /etc/shadow
6 - Restore the DB from DB backup ---> SAP Team
     7 - Install TDP and configure. --> IBM TSM
     8- Refer the installed rpm information ( attached the change) and install and configure the    additional interface drivers  and ODBC drivers  → Linux OS + SAP
9 - Restore the Apps filesystem from backup ( NFS directory) ( restore only missing files).

Option 3:-
Restore DB backup taken  to quality HANA and connect to production application servers

Option 4: MultiDB: Create a new tenant for prod and restore
Based on RAM availability stop quality tenant and start prod tenant only. 

Option 5: Single DB: Restore to quality HANA database. 

Command to check MultiDB/SingleDB: 
# hdbnsutil -printSystemInformation



Linux manual patching KB  KB0013247 - Linux Manual Patching
https://ibmma.service-now.com/kb_view.do?sys_kb_id=a25b21ee1bdd90542752b912cd4bcb41





backout plan(revert to snapshot)
1) Open vcenter URL (Select datacenter and use that IP)
2) Look for VM name
3) Click on "Actions"
3.1) Click on "Snapshots"
3.2) Click on "Manage Snapshots"
3.3) Click on Snapshot you took before the OS upgrade
3.4) Click on "Revert to"


Take snapshot task




SP2 to SP4 cluster
Put the cluster into maintenance mode (Unmanaged) before we start our upgrade activity.
crm configure property maintenance-mode=true
Ask Sap performer to stop application / DB.

Take adhoc vm Snapshot.
Take clean reboot one by one nodes before upgrade.

Update SP2 to current patch level for both nodes.

zypper update
reboot node once update completed.
Once VM is up we can proceed with SP4 Upgrade and reboot.
Execure Zypper command for migration

# zypper migration
Post upgrade Start cluster service on both node.
systemctl start pacemaker
Edit cluster vcenter fencing configuration with rest api method.
Vcenter Primitive
Error: Exception: 400: Too many virtual machines. Add more filter criteria to reduce the number.

Fix:

Copy fence_vmware_rest from sds to /usr/sbin/fence_vmware_rest

cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/fence_vmware_rest /usr/sbin/fence_vmware_rest
fence_vmware_soap:

primitive vcenter-fencing-<HOSTNAME> stonith:fence_vmware_soap \
        params ipaddr=<VCENTER_IP> login="vsphere.local\crmstnmgr" ipport=443 ssl=1 ssl_insecure=1 passwd_script="/usr/local/sbin/getpass.py -g crmstnmgr" login_timeout=60  shell_timeout=600 \
        op stop interval=0 timeout=20s \
        op start interval=0 on-fail=restart timeout=40s \
        op monitor interval=600s \
        meta maintenance=false
fence_vmware_rest:

primitive vcenter-fencing-<HOSTNAME> stonith:fence_vmware_rest \
       params ipaddr=<VCENTER_IP> login="vsphere.local\crmstnmgr" plug=<HOSTNAME> password_script="/usr/local/sbin/getpass.py -g crmstnmgr" shell_timeout=60 ssl=1 ssl_insecure=1 login_timeout=60 filter="filter.names=<HOSTNAME>" \
       op stop interval=0 on-fail=ignore timeout=60s \
       op start interval=0 on-fail=restart timeout=60s \
       op monitor enabled=false on-fail=restart timeout=60s interval=0
The above soap primitive will be modified as below.

Note: Below parameter addition and modifications are important.
primitive vcenter-fencing-<HOSTNAME> make sure primitive name should be updated with hostname and modify stonith:fence_vmware_soap to stonith:fence_vmware_rest
for parms section make sure ipaddr=<VCENTER_IP> vcenter ip is updated correct DC.
Add plug=<HOSTNAME> plug attribute with hostname (Note: This parameter need to add )
Modify shell_timeout=600 to shell_timeout=60
Add filter="filter.names=<HOSTNAME>" attribute with hostname. (Note: This parameter need to add )
Add op stop section with on-fail=ignore attribute. (Note: This parameter need to add )
Modify op stop section from timeout=20s to timeout=60s
Modify op start section from timeout=40s to timeout=60s
Add op monitor section with enabled=false attribute. (Note: This parameter need to add )
Make cluster managed and run validation to find any deviations if there is any deviations we need to fix that before handing it over to the sap validation.
Validation Script here -> /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/run_pacemaker_validation.py

/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation/cluster_validation.py
Sample Primitives available here -> https://github.ibm.com/CMS/SAP-Base-RR/tree/master/CMAS%203x/Pacemaker/Primitives/SLES%20SP4

Make changes accordingly

crm configure property maintenance-mode=false
Once every thing fine hand it over to SAP performer for application / DB validation.
After everything fine from validation stand point cleanup vm snap






#pacemaker_training_doubts slack channel for questions.

sh /usr/local/ncpa/plugins/cmas_check_ro_mounts.sh

##################### TSM TICKET FIX ###################
1.dsmc q fi
check the date either today's or yesterday's in output of dsmc q fi. If date is not as required then check for service and restart.
2.dsmc i
3. ps -ef | grep dsmc
if output is below then it's mean FS service not running.
[root@smdbsbxsu1 ~]$ ps -ef | grep dsmc
root     11550     1  0 Apr19 ?        00:00:04 /opt/tivoli/tsm/client/ba/bin/dsmcad -optfile=/opt/tivoli/tsm/client/ba/bin/dsm_hana.opt
root     37667 30737  0 04:14 pts/1    00:00:00 grep dsmc
4.cd /opt/tivoli/tsm/client/ba/bin
5. ls -l |grep rc.dsmcad
6. ./rc.dsmcad start  or systemctl status dsmcad.service
7.[root@smdbsbxsu1 bin]$ ps -ef | grep dsmc
root      1398     1  0 04:17 ?        00:00:00 /opt/tivoli/tsm/client/ba/bin/dsmcad
root      1783 30737  0 04:19 pts/1    00:00:00 grep dsmc
root     11550     1  0 Apr19 ?        00:00:04 /opt/tivoli/tsm/client/ba/bin/dsmcad -optfile=/opt/tivoli/tsm/client/ba/bin/dsm_hana.opt
8. dsmc q fi
####################################################### 
if dsmc db services are running for long stop and start it
dsmcad_db2 and dsmcad_db2log


ppl#ppldcprdccdb#Service dsmc check CRITICAL: dsmc process with pid 20759 running for 432800 seconds (Alert threshold is 432000 seconds.)
kill th pids
root      20759  20705 98 Jun04 ?        5-00:29:36 dsmc -se=tsm_hana      is required to run schedules

ppldcqasccdbs:/opt/tivoli/tsm/client/ba/bin # ps -ef |grep -i dsmc
root      21963      1  0 May27 ?        00:00:14 /usr/bin/dsmcad
root      21985      1  0 May27 ?        00:00:13 /usr/bin/dsmcad -OPTFILE=/opt/tivoli/tsm/client/ba/bin/dsm_hana.opt
root      28787 112133  0 07:05 pts/3    00:00:00 grep --color=auto -i dsmc
root      61801  61737 98 Jun04 ?        5-00:25:02 dsmc -se=tsm_hana
ppldcqasccdbs:/opt/tivoli/tsm/client/ba/bin # kill -9 61801
ppldcqasccdbs:/opt/tivoli/tsm/client/ba/bin # ps -ef |grep -i dsmc
root      21963      1  0 May27 ?        00:00:14 /usr/bin/dsmcad
root      21985      1  0 May27 ?        00:00:13 /usr/bin/dsmcad -OPTFILE=/opt/tivoli/tsm/client/ba/bin/dsm_hana.opt
root      37064 112133  0 07:10 pts/3    00:00:00 grep --color=auto -i dsmc



Check TSM server details at cat /opt/tivoli/tsm/client/ba/bin/dsm.sys

dsmc process failure in Samuel
[21-02 12:46] Sathvika KothakataVanam


[ibmskothakatavanam@sczprddb ~]$ ps -ef | grep dsmc
root        2785       1  0  2022 ?        00:05:51 /usr/bin/dsmcad -OPTFILE=/opt/tivoli/tsm/client/ba/bin/dsm.opt
root      371364       1  0 Jan15 ?        00:01:57 /usr/bin/dsmcad -OPTFILE=/opt/tivoli/tsm/client/ba/bin/dsm_oralog.opt
root     3559383 4124204  0 00:00 ?        00:00:00 /usr/bin/dsmc schedule /tmp/filecdi25y -optfile=/opt/tivoli/tsm/client/ba/bin/dsm_ora.opt
ibmskot+ 3763311 3763136  0 01:16 pts/58   00:00:00 grep --color=auto dsmc
root     4124204       1  0 Jan15 ?        00:01:54 /usr/bin/dsmcad -OPTFILE=/opt/tivoli/tsm/client/ba/bin/dsm_ora.opt
 

[21-02 12:46] Sathvika KothakataVanam

services will run where db is up

[21-02 12:46] Sathvika KothakataVanam

in ha not required 3 dsmscad here


OPAAS storage related issues

https://github.ibm.com/CMS/cms-opaas-api/issues


Cluster trainings
1. Pacemaker Training - this course is entry level and is aimed for both SAP and OS engineers with little to no knowledge of the pacemaker clusters:
 
https://ec.yourlearning.ibm.com/w3/playback/10130317


2. Pacemaker Automated Functions for HANA and Non-HANA Clusters using SAMUEL - this course explains how to use SAMUEL to perform daily activities that are performed on the pacemaker clusters easily and safely and is aimed for both SAP and OS engineers with any level of pacemaker clusters training:
 
https://ec.yourlearning.ibm.com/w3/playback/10176520


3.  Pacemaker 101 - this courses goes a big deeper on how a pacemaker cluster works and is an excellent pivotal point to deepen your overall pacemaker clusters knowledge and is aimed for both SAP and OS engineers:
 
https://ec.yourlearning.ibm.com/w3/playback/10122067



4. Hana HA Cluster: Training for Support Engineers - this course is aimed for OS engineers with knowledge and certain expertise on the HANA pacemaker clusters and is an important course to escalate your existing knowledge and will set the basis to go beyond your current level:
 
https://ec.yourlearning.ibm.com/w3/playback/10152826



5. Non-Hana HA Cluster: Training for Support Engineers - this course is aimed for OS engineers with knowledge and certain expertise on the Non-HANA pacemaker clusters and is an important course to escalate your existing knowledge and will set the basis to go beyond your current level:
 
https://ec.yourlearning.ibm.com/w3/playback/10133012


Linux Interview question

https://ibm-learning.udemy.com/course/linux-technical-interview-questions-and-answers/

-----------------------------------------------------------------------------------------------------------

gdm user process runninga nd increasing /var/log/gdm logs and filling up the FS.
fix is to stop the display-manager service and check logs should stop increasing

------------------------------------------------------------------------------------

root@qamhanau02# mmgetstate -aLs

 Node number  Node name       Quorum  Nodes up  Total nodes  GPFS state  Remarks    
------------------------------------------------------------------------------------
       1      gpfsnode01         1        1          1       active      quorum node

 Summary information 
---------------------
Number of nodes defined in the cluster:            1
Number of local nodes active in the cluster:       1
Number of remote nodes joined in this cluster:     0
Number of quorum nodes defined in the cluster:     1
Number of quorum nodes active in the cluster:      1
Quorum = 1, Quorum achieved

[~] 17:27:40
root@qamhanau02# uptime
 17:27pm  up 771 days 21:43,  3 users,  load average: 13.20, 12.80, 12.87
[~] 17:27:44
root@qamhanau02# mmlsdisk /dev/sapmntdata
disk         driver   sector     failure holds    holds                            storage
name         type       size       group metadata data  status        availability pool
------------ -------- ------ ----------- -------- ----- ------------- ------------ ------------
data01node01 nsd         512        1001 yes      yes   ready         up           system       
data02node01 nsd         512        1001 yes      yes   ready         up           system       
data03node01 nsd         512        1001 yes      yes   ready         up           system       
[~] 17:28:19
root@qamhanau02# 

-------------------------------------------------------------------------------------------------------

Sharing Linux NFS to a Windows box(opp of CIFS mapping)

https://www.rootusers.com/how-to-mount-an-nfs-share-in-windows-server-2016/

Mounting the NFS Share
 Make sure that the NFS Client is installed.
Open a Powershell command prompt.
Run the appropriate command for your situation:
Server OS: Install-WindowsFeature NFS-Client
Desktop OS: Enable-WindowsOptionalFeature -FeatureName ServicesForNFS-ClientOnly, ClientForNFS-Infrastructure -Online -NoRestart
Mount the share using the following command, after making the required modifications:
mount -o anon nfs.share.server.name:/share-name X:
Replace nfs.share.server.name with the name of the server the NFS share is on (eg. files.umn.edu)
Replace share-name with the name of the NFS share (eg. OIT-Test)
Replace X: with the desired drive letter.


---------------------------------------------------------------------------------------------------

Attach an iSCSI disk on SL and attach it to the server to mount and copy data

Copy the Export data to HDD

Step I
1) Copy Data from Source /exportfs to HDD1
2) Unmount HDD1 from ISCSI port
3) Mount HDD2 (ISCSI Port)
4) Copy Data from Source /Exportfs to HDD2
5) Unmount HDD2 from ISCSI Port
6) Mount HDD3 (ISCSI Port)
7) Copy Data from Source / Exportfs to HDD3
8) Unmount HDD3 from ISCSI port

To Mount ISCSI port on Source

https://cloud.ibm.com/docs/DataTransferService?topic=DataTransferService-mount-dts-linux

Source IP Source IP 10.134.3.16
Port 3260

Target HDD1 - 10.2.32.71
UserName - IBMDT393684-78
Password - va9qQwdcaV94

[root@bapeccv38 mnt]# df -hT /mnt
Filesystem     Type     Size  Used Avail Use% Mounted on
/dev/sdq1      fuseblk  1.9T  177G  1.7T  10% /mnt



HDD2 - Username - IBMDT393684-76
Password - fLzA2BDLVKEY


mount -t fuseblk /dev/sdq1 /mnt

HDD3 - Username - IBMDT393684-77
Password - kb4gZbJnE7Uz



mount.ntfs-3g /dev/sdq1 /mnt
rsync -avz /exportfs /mnt


139  2021-05-24 19:20:39 iscsiadm -m discovery -t sendtargets -p  10.2.32.71


[root@bapeccv38 ~]# iscsiadm -m discovery -t sendtargets -p  10.2.32.71
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-76
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-78

[root@bapeccv38 ~]# iscsiadm -m discovery -t sendtargets -p  10.2.32.71
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-76
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-77
10.2.32.71:3260,1 iqn.1994-05.com.redhat:7712241530:IBMDT393684-78



iscsiadm -m node -T [output from previous command, starting with IQN.] -p [IP address in StorageLayer] -l
 142  2021-05-24 19:21:40 iscsiadm -m node -T iqn.1994-05.com.redhat:7712241530:IBMDT393684-76 -p 10.2.32.71 -l


[root@bapeccv38 ~]# iscsiadm -m node -T iqn.1994-05.com.redhat:7712241530:IBMDT393684-77 -p 10.2.32.71 -l
Logging in to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-77, portal: 10.2.32.71,3260]
Login to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-76, portal: 10.2.32.71,3260] successful.


[root@bapeccv38 ~]# iscsiadm -m node -T iqn.1994-05.com.redhat:7712241530:IBMDT393684-77 -p 10.2.32.71 -l
Logging in to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-77, portal: 10.2.32.71,3260]
Login to [iface: default, target: iqn.1994-05.com.redhat:7712241530:IBMDT393684-77, portal: 10.2.32.71,3260] successful.

how to mount file storage (NFS) on Linux:

https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-mountingLinux

how to mount block storage (iscsi) on Linux:

https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-mountingRHEL8



--------------------------------------------------------------------------------------------



Mapping scsi number in vmware with the disk name in VM


[root@gknfioridev scsi_disk]$ lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     1.0   /dev/sdb
[0:0:2:0]    disk    VMware   Virtual disk     1.0   /dev/sdc
[0:0:3:0]    disk    VMware   Virtual disk     1.0   /dev/sdh
[0:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdd
[0:0:11:0]   disk    VMware   Virtual disk     1.0   /dev/sde
[1:0:0:0]    disk    VMware   Virtual disk     1.0   /dev/sdf
[1:0:5:0]    disk    VMware   Virtual disk     1.0   /dev/sdg

-------------------------------------------------------------------------------------------------------------

Keyring

How to reset gnome keyring password in RHEL7 ?
 SOLUTION VERIFIED - Updated January 18 2017 at 1:57 PM - English 
Environment
Red Hat Enterprise Linux 7
Issue
How to reset users gnome keyring password in RHEL7 if do not remember the old one?
Why root user is not able to login in GUI mode?
Resolution
Login as affected user and move below files from users home directory.
Raw
$ mkdir /tmp/backup/
$ mv .gnome .gnome2 .gconf .gconfd .metacity .cache .dbus .dmrc .mission-control /tmp/backup/
Logout/Login

----------------------------------------------------------------------------------------------------------------

CSR Calender Dashboard of Service now whenever there is a outage of CSR Portal.
https://ibmma.service-now.com/nav_to.do?uri=%2F$pa_dashboard.do%3Fsysparm_dashboard%3D0adb4323db9a18d4883d06e2ca9619b9


-------------------------------------------------------------------------------------------------------------
De-register and re-register SuSE
zypper list-updates
Permission to access 'https://smt-azure.susecloud.net/services/1212/repo/repoindex.xml?credentials=Advanced_Systems_Management_Module_x86_64' denied.

Fix
# /etc/SUSEConnect
---
insecure: false
url: https://smt-azure.susecloud.net
language: POSIX

According the configure above, your system registered to smt-azure.susecloud.net now. 

[root@ps2-s4x-db ~]#  cat /etc/SUSEConnect
---
insecure: false
url: https://smt-azure.susecloud.net
language: en_US.UTF-8

FOr Azure VMs connect with opaas team Deekshith Patnala

ensure the port 443 is open. work with n/w and then use below to register
/usr/sbin/registercloudguest --force-new



You need use your reg-code to register to scc.suse.com like below:
# SUSEConnect -d -r                                           // de-register from smt-azure
# SUSEConnect -r E8D46BBFE1AAF0            // register to scc.suse.com

SUSEConnect --cleanup

[root@ps2-s4p-db ibmrmalik1]# SUSEConnect -r E8D46BBFE1AAF0
Registering system to registration proxy https://smt-azure.susecloud.net

Announcing system to https://smt-azure.susecloud.net ...

Activating SLES_SAP 12.4 x86_64 ...
Error: Registration server returned 'Instance verification failed: No instance data supplied' (422)

# cat /etc/SUSEConnect
#---
insecure: false
url: https://scc.suse.com

Just change the content of /etc/SUSEConnect file, then retry.

SUSEConnect --cleanup

then try registering and it works




Thread: Timeout exceeded when accessing official repositories

Check your proxy setting in /etc/sysconfig/proxy, If there are values in it, erase them, even if you have the setting proxy=no

Register SUSE 

[root@mm3fiuws001 ~]# SUSEConnect -s
SSL verification failed: unable to get local issuer certificate
Certificate issuer: /C=US/ST=Texas/L=Dallas/O=3x/OU=MA/CN=YaST_Default_CA/emailAddress=roland.rebstock@kyndryl.com
Certificate subject: /C=US/ST=Texas/L=Dallas/O=3x/OU=MA/CN=DAL09AMMSMT01.imzcloud.ibmammsap.local/emailAddress=roland.rebstock@kyndryl.com
SUSEConnect error: OpenSSL::SSL::SSLError: SSL_connect returned=1 errno=0 state=error: certificate verify failed
[root@mm3fiuws001 ~]# cp /etc/SUSEConnect /tmp/
[root@mm3fiuws001 ~]# cp /root/cert_fingerprint /tmp
[root@mm3fiuws001 ~]# SUSEConnect --cleanup
[root@mm3fiuws001 ~]# telnet  dal09ammsmt01.imzcloud.ibmammsap.local 443
Trying 146.89.140.46...
Connected to dal09ammsmt01.imzcloud.ibmammsap.local.
Escape character is '^]'.
^C
Connection closed by foreign host.
[root@mm3fiuws001 ~]# SUSEConnect --de-register
Deregistration failed. Check if the system has been registered using the --status-text option or use the --regcode parameter to register it.
[root@mm3fiuws001 ~]# cat /root/cert_fingerprint
42:72:39:DD:19:B1:79:70:45:65:77:EA:1B:50:C6:0A:94:81:BC:14
[root@mm3fiuws001 ~]# /root/clientSetup4SMT.sh https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc --yes --fingerprint 67:CC:5F:BA:6D:56:2E:46:15:C5:71:D5:51:11:1F:8E:79:37:A4:C8
Client setup finished.
/root/clientSetup4SMT.sh https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc

/usr/bin/SUSEConnect --write-config --url https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc
Registering system to registration proxy https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc Announcing system to https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc ... Activating SLES_SAP 12.4 x86_64 ...
-> Adding service to system ... Successfully registered system [root@mm3fiuws001 ~]# /usr/bin/SUSEConnect --write-config --url https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc
Registering system to registration proxy https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc Updating system details on https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc ... Activating SLES_SAP 12.4 x86_64 ...
-> Adding service to system ... Successfully registered system [root@mm3fiuws001 ~]# SUSEConnect -s
[{"identifier":"SLES_SAP","version":"12.4","arch":"x86_64","status":"Registered"}]


Register Suse  Steps by Sreejesh
cat /etc/SUSEConnect  and check the smt server details
cp /etc/SUSEConnect /tmp/;cp /root/cert_fingerprint /tmp;SUSEConnect --de-register;SUSEConnect --cleanup;rm -f /etc/SUSEConnect;rm -rf /etc/zypp/credentials.d/*;rm -rf /etc/zypp/repos.d/*;rm -f /etc/zypp/services.d/*  
cd /root
wget http://che01ammsmt01.imzcloud.ibmammsap.local/repo/tools/clientSetup4SMT.sh 
chmod 777 new file
run that   with   "./clientSetup4SMT.sh.1 --host che01ammsmt01.imzcloud.ibmammsap.local/center/regsvc       --use the smt server from cat /etc/SUSEConnect file
Latest clientSetup4SMT script can be downloaded from wget http://lon02ammsmt01.imzcloud.ibmammsap.local/repo/tools/clientSetup4SMT.sh  
just answer yes to accept the certificate and your registered
che01ammsmt01.imzcloud.ibmammsap.local/center/regsvc
if below error
Error: Registration server returned 'DBERROR: Data too long for column 'TARGET' at row 1' (500)

https://mon01ammsmt01.imzcloud.ibmammsap.local/center/regsvc

cp /etc/SUSEConnect /root/;rm /etc/SUSEConnect;rm -f /etc/zypp/{repos,services,credentials}.d/*;rm -f /usr/lib/zypp/plugins/services/*

an SBD server, so python3 is not being in use, so I decided to change python3 for pointing /usr/bin/python3.4, that worked, and I could generated the quarter patch-list: https://samuel.sap.adai.kyndryl.com/PS2/buildInformation?id=65a06d87b6c8a253320b3e18&name=Overview
    

AZURE - Re-register the Suse OS
================================
#SUSEConnect --cleanup
cp /etc/SUSEConnect /root/SUSEConnect_backup;rm -f /etc/SUSEConnect;rm -rf /etc/zypp/credentials.d/*;rm -rf /etc/zypp/repos.d/*;rm -f /etc/zypp/services.d/*
/usr/sbin/registercloudguest --force-new


AWS SUSE register
AWS REPO ---
 # rm /etc/SUSEConnect
 # rm -f /etc/zypp/{repos,services,credentials}.d/*
 # rm -f /usr/lib/zypp/plugins/services/*
 # /usr/sbin/registercloudguest --force-new



remember change the root password before to take the Snap

Also disable the falcon sensor before the reboot



<https://teams.microsoft.com/l/message/19:pYJ4Ie2sMr25RohzMGFwKHg3k9R3JuCuYjwOs2gsOpA1@thread.tacv2/1690003719816?tenantId=f260df36-bc43-424c-8f44-c85226657b01&amp;groupId=8aefcc7d-0a41-4de5-81ee-93d7d4a07070&amp;parentMessageId=1690000434998&amp;teamName=pslteam&amp;channelName=General&amp;createdTime=1690003719816&amp;allowXTenantAccess=false>



check if link broken then relink
[root@wa2scqadb1 ~]# ls -ld /etc/products.d/baseproduct
lrwxrwxrwx 1 root root 13 Feb  3  2021 /etc/products.d/baseproduct -> SLES_SAP.prod
[root@wa2scqadb1 ~]# unlink SLES_SAP.prod

[root@wa2epqadb1 ~]# cd /etc/products.d/
[root@wa2epqadb1 products.d]# ls -ltr
total 4
lrwxrwxrwx 1 root root   13 Apr 22  2021 baseproduct -> SLES_SAP.prod
-rw-r--r-- 1 root root 2927 Aug  3  2021 SLES.prod
[root@wa2epqadb1 products.d]# unlink baseproduct

[root@wa2epqadb1 products.d]# ln -s SLES.prod baseproduct
[root@wa2epqadb1 products.d]# ls -ltr
total 4
-rw-r--r-- 1 root root 2927 Aug  3  2021 SLES.prod
lrwxrwxrwx 1 root root    9 Jun 13 00:14 baseproduct -> SLES.prod

relink  ln -s SLES.prod baseproduct


meeting with SUSE and they identified that the HA Module subscription was still attached to this server even after a SUSEConnect --un-register, SUSEConnect --cleanup.   The engineer from SUSE went into the YAST application and removed the module from the "installed software" section of yast.  The server was then re-registered back to the SMT and the issue was resolved and now a "zypper migration" can be completed.   I was informed by SUSE that the SAP HA License used to be a separate subscription but now its part the SAP Licensing so the old subscription which SUSE does not use anymore had to be manually removed 1st.

Migration didnt work for SLES 12 sp4 to sp5

Can't get available migrations from server: SUSE::Connect::ApiError: The requested products 'SUSE Linux Enterprise Server 12 SP4 x86_64' are not activated on the system.
'/usr/lib/zypper/commands/zypper-migration' exited with status

I could see add on repo also which had to be removed first via yast and then remove the patches it installed. Then check the symlink for baseproduct and relink it . Lastly unregister and reregister and it worked for me
yast2->installed add on products select and remove and then proceed as per the questionare

Start the registration now? [y/n] y
/usr/bin/SUSEConnect --write-config --url https://dal09ammsmt01.imzcloud.ibmammsap.local/
Registering system to registration proxy https://dal09ammsmt01.imzcloud.ibmammsap.local/



Announcing system to https://dal09ammsmt01.imzcloud.ibmammsap.local/ ...
Error: Registration server returned 'DBERROR: Data too long for column 'TARGET' at row 1' (500)

check if link broken then relink
[root@wa2scqadb1 ~]# ls -ld /etc/products.d/baseproduct
lrwxrwxrwx 1 root root 13 Feb  3  2021 /etc/products.d/baseproduct -> SLES_SAP.prod
[root@wa2scqadb1 ~]# unlink SLES_SAP.prod

[root@wa2epqadb1 ~]# cd /etc/products.d/
[root@wa2epqadb1 products.d]# ls -ltr
total 4
lrwxrwxrwx 1 root root   13 Apr 22  2021 baseproduct -> SLES_SAP.prod
-rw-r--r-- 1 root root 2927 Aug  3  2021 SLES.prod
[root@wa2epqadb1 products.d]# unlink baseproduct

[root@wa2epqadb1 products.d]# ln -s SLES.prod baseproduct
[root@wa2epqadb1 products.d]# ls -ltr
total 4
-rw-r--r-- 1 root root 2927 Aug  3  2021 SLES.prod
lrwxrwxrwx 1 root root    9 Jun 13 00:14 baseproduct -> SLES.prod



relink  ln -s SLES.prod baseproduct




there is a script under /root


Please follow these steps:

SUSEConnect --de-register
SUSEConnect --cleanup
rm -f /etc/SUSEConnect
rm -rf /etc/zypp/credentials.d/*
rm -rf /etc/zypp/repos.d/*
rm -f /etc/zypp/services.d/*
cd /root/
echo -e 'y\ny\'|./clientSetup4SMT.sh --host dal09ammsmt01.imzcloud.ibmammsap.local
SUSEConnect -list


Register a RHEL
yum clean all
rm -rf /var/cache/yum/*
subscription-manager unregister
subscription-manager clean
subscription-manager register --org="IBM_Managed_Applications" --activationkey="FMS3.x Daily Repos"
-------------------------------------------------------------------------------------------------------------

Z1L moved from cms to gts

GTS is taking care, contact @srinidhihv



-------------------------------------------------------------------------------------------------------------------------------------------

3.x vCenters (Shared vHana UMA) https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/wiki/3.x-vCenters-(Shared-vHana-UMA)



Kydryl
Ravi.Malik@ocean.ibm.com
Ravi Malik/AP/Contr/Ocean


Transition w3id (@ocean.ibm.com): Ravi.Malik@ocean.ibm.com
Initial password: gtmeh3ewb983430t



vcenter-fencing-aprpiprdd	(stonith:fence_vmware_soap):	Stopped
 vcenter-fencing-aprpiprdd-ha	(stonith:fence_vmware_soap):	FAILED aprpiprdd (Monitoring)
start vcenter fencing on both nodes

SuSE SP4 replace the rest file
cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/fence_vmware_rest /usr/sbin/fence_vmware_rest

SuSE SP2 replace the soap file
 cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/fence_vmware_soap /usr/sbin/fence_vmware_soap

op monitor enabled=false on-fail=restart timeout=60s interval=0 \  in the fencing section of cluster config

Kendryl

proposed pw R@vi@03Anj@li@30

cd /opt/kyndryl/reenroll/yum/

 rpm -Uvh *.rpm --force

ibm-ras-india.gpcloudservice.com

Kyndryl device setup
https://ibm.ent.box.com/s/0gxr0v7w29l1fte402usv0jj36ma427o

https://w3.ibm.com/kyndryl-transition-hub/

https://w3.ibm.com/kyndryl-transition-hub/mytransition

Kendryl

Transition w3id (@ocean.ibm.com): Ravi.Malik@ocean.ibm.com
password R@vi@03Anj@li@30

Kyndryl RHEL iso media location
https://ibm.ent.box.com/s/1480beubq18q7xhnxjzoquy5iudtsorg

lifeboat iso kyndryl image
https://kyndryl.ent.box.com/s/b9xrjsop1fw8l7gfoo0pqos46bctmfdg/folder/155557774708
https://kyndryl.ent.box.com/s/b9xrjsop1fw8l7gfoo0pqos46bctmfdg/folder/148723333742


Windows image
https://kyndryl.sharepoint.com/teams/WindowsPlatformEngineering/Shared%20Documents/Forms/AllItems.aspx?id=%2Fteams%2FWindowsPlatformEngineering%2FShared%20Documents%2FWindows%2010%20ISO%2FWindows10%5F21H2%2019044%2E2006%2Eiso&parent=%2Fteams%2FWindowsPlatformEngineering%2FShared%20Documents%2FWindows%2010%20ISO&p=true&ga=1

if above does not work, 
ibm.biz/linux-at-kyndryl-install-media then find the OS and version





w3 password reset link https://w3idprofile.sso.ibm.com/password/changepwd.wss

cd /opt/kyndryl/reenroll/yum/

 rpm -Uvh *.rpm --force

ibm-ras-india.gpcloudservice.com
AVTD5T744  kyndryl
AVSC7C744  IBM

Preparing for Kyndryl - Action Checklist	https://w3.ibm.com/kyndryl-it/it-action-checklist
Preparing for Kyndryl - Linux			https://w3.ibm.com/kyndryl-it/platforms/linux

If you are missing your Transition w3 ID (@ocean.ibm.com) password mail, go to this URL to reset your password: https://w3.ibm.com/password
If you are missing your Kyndryl Microsoft Account ID mail, go to this URL to reset your password: https://passwordreset.microsoftonline.com/
If you are missing your Kyndryl w3 ID email, got to this URL to reset your password: https://login.kyndryl.net/
If you don't know or can't remember what your new IDs are there's an awesome tool available that can retrieve all the IDs for you. The URL is: https://chatops-prod-int.extnet.ibm.com/mui/IBMToKyndryl

IBM Identity: Ravi.Malik@ibm.com

Kyndryl Identity: Ravi.Malik@kyndryl.com	K@r@n@25T@n@y@16

Transition Identity: Ravi.Malik@ocean.ibm.com

Notes ID: CN=Ravi Malik/OU=AP/OU=Contr/O=Ocean


cd /opt/kyndryl/reenroll/yum/

 rpm -Uvh *.rpm --force

Follow these steps to resolve the issue:
Open this file with the text editor of your choice: /opt/paloaltonetworks/globalprotect/pangps.xml
Under the <Settings> block add a new entry: <default-browser>yes</default-browser>. If the entry already exists, simply change the value from “no” to “yes”
Save the changes in the .XML file and reboot your Linux workstation for the changes to take effect
After the reboot try connection using the GlobalProtect client once more. Now the W3ID on ISV authentication should open in the default system browser, like Firefox. Continue with the authentication to establish the first connection using the GlobalProtect client.


Transition Notes ID:

Notes Name and Domain:
 Ravi Malik/AP/Contr/Ocean @ Ocean
User Shortname	 INAVTD5T
ID filename	INAVTD5T.ID
Notes password:	dfRL34!,LaoTSlL
	(Passwords are case sensitive and must be entered as shown)
Notes ID File	


Your Kyndryl email ID is: Ravi.Malik@kyndryl.com  used for mails and box folder access



Your Kyndryl w3id credentials
Your username and temporary password for your Kyndryl w3id are listed below. You must change your initial password after you log in for the first time with your temporary password.

Kyndryl w3id credentials
Username: Ravi.Malik@kyndryl.com
Temporary password: EURZN5?dEFPU6LPK

https://w3.ibm.com/help/#/article/kyndryl_id_2fa



Kyndryl system IDs:

Kyndryl w3id (kyndryluser@kyndryl.com)
Kyndryl Microsoft Account (kyndryluser@kyndryl.com)	pw ProKabbadi@123
IBM system IDs:

Transition w3id (kyndryluser@ocean.ibm.com)
Transition Notes ID (User Name/Geo/Ocean)


https://w3.ibm.com/kyndryl-it/apps-tools/box

W3 : - https://w3.ibm.com/ocean/home/
Workday : - https://wd5.myworkday.com/ibm/d/home.htmld
WebEx : - https://kyndryl.webex.com/webappng/sites/kyndryl/dashboard?siteurl=kyndryl&from_login=true
Travel@IBM : - https://w3.ibm.com/ocean/hr/web/travel/
Learning : - https://kyndryl.yourlearning.ibm.com/
Ask HR :  https://w3.kyndryl.net/hr/askhr/
Udemy : - https://kyndryl.udemy.com/
Slack : - https://kyndryl.enterprise.slack.com/?redir=%2Fr-t2264321203926%3Fredir%3D%252Fmessages
OWA : - https://outlook.live.com/mail/0/inbox
Help Desk : - https://help.ocean.ibm.com/help/#

----------------------------------------------------------------------------------------


PSL VPN GlobalProtect

Portal Address
hjvpn.persistent.com
ptvpn.persistent.com
ngvpn.persistent.com
usvpn.persistent.com

IBM

Americas: ibm-ras.gpcloudservice.com
EMEA: ibm-ras-emea.gpcloudservice.com
Asia Pacific: ibm-ras-apac.gpcloudservice.com
India: ibm-ras-india.gpcloudservice.com



-------------------------------------------------------------------------------------

MARIO training link: KB0014683
used during MCO
https://ibmma.service-now.com/nav_to.do?uri=%2Fkb_view.do%3Fsys_kb_id%3Da0cc8ef8db806810883d06e2ca9619b7

------------------------------------------------------------------------------------------

Network interface

[root@tslbwprddb ibmrmalik1]$ ip link show |grep -i  vlan0@bond0
8: vlan0@bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000


if state above shows state DOWN then 
ifconfig vlan0@bond0 up


https://www.2daygeek.com/enable-disable-up-down-nic-network-interface-port-linux/
------------------------------------------------------------------------------------------------

Check for nfs lock status

mount |grep -i lock
if u see local_lock=none means its not locked

----------------------------------------------------------------------------------------------

right click of mousepad in RHEL 8 not working
How do I enable right-click on the Touchpad for RHEL8.x?
Open the "Tweaks" tool, go to Keyboard & Mouse, and change Fingers to Area under "Mouse Click Emulation".

-----------------------------------------------------------------------------------------

root@conspeccdbpdr ibmsgaur1]# cat /etc/sysctl.conf|grep -i net.ipv4.ip_local_port_range
net.ipv4.ip_local_port_range = 52000 65499
[root@conspeccdbpdr ibmsgaur1]#
########################################
[root@conspeccdbpdr ibmsgaur1]# sysctl net.ipv4.ip_local_reserved_ports
net.ipv4.ip_local_reserved_ports = 4300-4399,5050,8000-8099,30000-39999,50000-51500,51513-51514,51613-51614,51713-51714,51813-51814,51913-51914,52013-52014,


-------------------------------------------------------------------------------------------------------

Identify n/w adaptor for imz ip jisme  last main M hai wo always  for  IMZ

-------------------------------------------------------------------------------------------------

yum command hangs, or is reporting 'Another process has the cert lock.'

Resolution
stop the rhsmcertd service
remove /var/run/rhsm/cert.pid file
start the rhsmcertd service
run the yum command

Register RHEL with this, working as of 2023
subscription-manager register --org="IBM_Managed_Applications" --activationkey="FMS3.x Daily Repos"

yum clean all
rm -rf /var/cache/yum/*
subscription-manager unregister
subscription-manager clean
subscription-manager register --org="IBM_Managed_Applications" --activationkey="FMS3.x Daily Repos"
-------------------------------------------------------------------------------------------------------------


Nameserver in the resolve.conf to point to localhost and it was to the google server 8.8.8.8

"telnet  sng01ammcaps01.ibmammsap.local 80"

[root@svcd1srv0 ~]$ telnet  sng01ammcaps01.ibmammsap.local 80
Trying 208.91.197.39...
Connected to sng01ammcaps01.ibmammsap.local.
Escape character is '^]'.

WHOA, wait, there is the answer

that is not the IP of the capsule

the capsule is  146.89.140.171


/etc/resolv.conf
#
# This file is generated by Chef
# Do not edit, changes will be overwritten
#
domain imzcloud.ibmammsap.local
search imzcloud.ibmammsap.local ibmammsap.local prdcloud.fms.ibmcloud.com eastwestageaslife.com
nameserver 127.0.0.1


for any capsule, its all on 3x infra  146.89

Issue was the resolution of the capsule server
[root@svcd1srv0 ~]$ nslookup sng01ammcaps01.ibmammsap.local
Server:         8.8.8.8
Address:        8.8.8.8#53
Non-authoritative answer:
Name:   sng01ammcaps01.ibmammsap.local.eastwestageaslife.com
Address: 208.91.197.39


working server had
[root@svcq1srv0 ~]$ cat /etc/resolv.conf
#
# This file is generated by Chef
# Do not edit, changes will be overwritten
#
domain imzcloud.ibmammsap.local
search imzcloud.ibmammsap.local ibmammsap.local prdcloud.fms.ibmcloud.com eastwestageaslife.com
nameserver 127.0.0.1

[root@svcd1srv0 ~]$ nslookup
> sng01ammcaps01
Server:         8.8.8.8
Address:        8.8.8.8#53
Non-authoritative answer:
Name:   sng01ammcaps01.eastwestageaslife.com
Address: 208.91.197.39

DNS

the nameserver in resolve.conf is   8.8.8.8

----------------------------------------------------------------------------------------------------

SuSe 12 booting issue
Troubleshooting boot issues (multipath with lvm)
https://www.suse.com/support/kb/doc/?id=000019115

mount rootdisk [ root ] # mount -o rw /<root-disk-or-volume> /mnt mount /boot find out if mountpoint /boot in rootdisk is mounted with another device. [ root ] # egrep -i "/boot" /mnt/etc/fstab Mount the boot device to /mnt/boot if separate filesystem for /boot is configured. [ root ] # mount /<device-for-boot> /mnt/boot Bind the rescue system's proc, sys and dev to /mnt before chroot. [ root ] # for i in dev proc run sys ; do mount --rbind /$i /mnt/$i ; done Chroot to /mnt [ root ] # chroot /mnt create a new one using the following commands : # dracut -f -a multipath lvm or # dracut --regenerate-all -f 

Rebuild grub config if the OS is SLES 12 and above. Refer: https://www.suse.com/support/kb/doc/?id=000018523 # grub2-mkcon08:51
Rebuild grub config if the OS is SLES 12 and above. Refer: https://www.suse.com/support/kb/doc/?id=000018523 # grub2-mkconfig -o /boot/grub2/grub.cfg # grub2-install /dev/sdX Exit chroot [ root ] #exit Reboot the server normally. # systemctl reboot


--------------------------------------------------------------------------------------------------------
After booting a phana after issue with booting up post patching, boot it with the old kernel 
then check
pHANA n/w 
ppldcqasccdbs:/home/ibmrmalik1 # ethtool bond0
Settings for bond0:
	Supported ports: [ ]
	Supported link modes:   Not reported
	Supported pause frame use: No
	Supports auto-negotiation: No
	Advertised link modes:  Not reported
	Advertised pause frame use: No
	Advertised auto-negotiation: No
	Speed: 20000Mb/s
	Duplex: Full
	Port: Other
	PHYAD: 0
	Transceiver: internal
	Auto-negotiation: off
	Link detected: yes
ppldcqasccdbs:/home/ibmrmali

the speed should be 20000 and not 10000, if it says 10000 then some n/w stuff is done by SL.
SL changed Port grouping from Basic to LACP after which the port speed showing correctly as 20k
----------------------------------------------------------------------------------------------------------------------------

Attach a SMB share on the IPMI console

https://ahelpme.com/servers/supermicro/mount-and-boot-iso-file-from-windows-share-in-supermicro-ipmi-virtual-media-cd-rom/

----------------------------------------------------------------------------------------------------------------------

SFAIL Hana db reregister the nodes

put the node in SFAIL in standby -run from that same server 
[root@jp0811zbe1011 AutomationTool]# crm node standby jp0811zbe1011

su - hp1adm -c "hdbnsutil -sr_register --remoteHost=br3qscmdb37 --remoteInstance=36 --replicationMode=sync --operationMode=logreplay --online --name=SITEA"

Node jp0811zbe1011: standby
Online: [ jp0811zbe1009 ]

run below from secondary(not in sync)
[root@jp0811zbe1011 AutomationTool]# su - hp1adm -c "hdbnsutil -sr_register --remoteHost=jp0811zbe1009 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay --name=<NODENAME A or B>"
adding site ...
nameserver jp0811zbe1011:30001 not responding.
collecting information ...
registered at 10.216.14.35 (jp0811zbe1009)
updating local ini files ...
done.


remote host is the one which is in sync
--name has the secondary node


make the standby node online

cleanup any errors and wait for the sync to complete and SFAIL to change

remote host is the one that is in sync

--name is for the sfail node NODE a or SITEA

Run below from the server that is standby(out of sync)
su - s4padm -c "hdbnsutil -sr_register --remoteHost=br3psoldb41 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --name=SITEB"  

for HANA with --online keyword 
su - uepadm -c "hdbnsutil -sr_register --remoteHost=mm3s4uep004n2 --remoteInstance=00 --replicationMode=sync --operationMode=logreplay -force_full_replica --online --name=NODEA"

To check HDB sync status run below from primary node
su - <sidadm>
cd /usr/sap/UEP/HDB00/exe/python_support
 python systemReplicationStatus.py
 
 
 
 su - pp1adm-c "hdbnsutil -sr_state"    To check HDB replication
 
 
 
 To register the HDB node (P->S and S->DR)
 https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/02_DR_operations.md

-------------------------------------------------------------------------------------

HANA DB resource manipulation/constraint error

After manual resource manipulation
crm configure show -> to search for any constrains created for the given resource (e.g. ban), on any node
crm resource clear rsc_ip_THA_HDB00 -> to remove found constrain (if any), on any node
crm resource restart rsc_ip_THA_HDB00 -> to restart the resource, on any node
crm status -> to check if cluster resources are correctly distributed (HDB Master, vIP and TSM have to be always on actual Primary). on any node

https://github.ibm.com/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/09_Cheatsheet.md
Operations_Guide/09_Cheatsheet.md

Redhat cluster / RHEL cluster commands

https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/develop/Operations_Guide/09_Cheatsheet.md

https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/high_availability_add-on_reference/s1-clusterstat-haar

pcs status

You can display a subset of information about the current status of the cluster with the following commands.
The following command displays the status of the cluster, but not the cluster resources.

pcs cluster status

The following command displays the status of the cluster resources.

pcs status resources


------------------------------------------------------------------

Azure certification


Dear Azure Certification Aspirant, Those who have nominated yourself for Azure - AZ900 certification strongly recommend to go ahead and schedule exam now by using the following url : https://docs.microsoft.com/en-us/learn/certifications/exams/az-900 Please refer this url https://w3.ibm.com/services/lighthouse/spaces/view/certification-acceleration-program/azure-faq for a Step by Step instructions on scheduling the exam. You need to rush for scheduling the examination as the slot is filling fast due to recent Reward program announcement of $100 bluepoints .Participants completing the certification between 9 Mar to 5 April 2021 will be rewarded. Do ensure to nominate yourself - https://w3.ibm.com/tools/cio/forms/secure/org/app/237b7fad-5a2e-45d4-8e86-c92eaa1bd23f/launch/index.html?form=F_MultiCloudDrive20211

For those who don't already know, you can claim free Microsoft Azure certification via the Microsoft ESI portal (Enterprise Skills Initiative).
...
Claim your Azure certification exam. Check out the instructions here.
https://ibm.seismic.com/Link/Content/DCleSUJBLFtUmpnwKu9zsneg

--------------------------------------------------------------------------------

move all vg and lv from one disk to other

1069  2021-08-24 12:42:00 pvs |grep -i rqaappvg
 1070  2021-08-24 12:50:31 cat /etc/fstab
 1071  2021-08-24 12:51:13 cd
 1072  2021-08-24 12:51:29 df -hT |grep -i rqaappvg_new
 1073  2021-08-24 12:51:39 umount /temprm/interface_RQA /temprm/home_sapadm
 1074  2021-08-24 12:51:54 umount /temprm/3rdPartySoftware_RQA /temprm/sapmnt_RQA /temprm/usr_sap /temprm/home_daaadm /temprm/home_rqaadm /temprm/sap_ccms /temprm/sap_trans /temprm/sap_RQA /temprm/sap_DAA
 1075  2021-08-24 12:52:00 df -hT |grep -i rqaappvg_new
 1076  2021-08-24 12:52:57 lvremove -f /dev/mapper/rqaappvg_new-rqaIntface_lv
 1077  2021-08-24 12:53:11 lvremove -f /dev/mapper/rqaappvg_new-sapadm_lv
 1078  2021-08-24 12:53:19 lvremove -f /dev/mapper/rqaappvg_new-rqa3rdprty_lv
 1079  2021-08-24 12:53:25 lvremove -f /dev/mapper/rqaappvg_new-rqasapmnt_lv
 1080  2021-08-24 12:53:31 lvremove -f /dev/mapper/rqaappvg_new-usrsap_lv
 1081  2021-08-24 12:53:38 lvremove -f /dev/mapper/rqaappvg_new-daaadm_lv
 1082  2021-08-24 12:53:44 lvremove -f /dev/mapper/rqaappvg_new-rqaadm_lv
 1083  2021-08-24 12:53:52 lvremove -f /dev/mapper/rqaappvg_new-usrsapccms_lv
 1084  2021-08-24 12:53:58 lvremove -f /dev/mapper/rqaappvg_new-usrtrans_lv
 1085  2021-08-24 12:54:04 lvremove -f /dev/mapper/rqaappvg_new-rqausrRQA_lv
 1086  2021-08-24 12:54:09 lvremove -f /dev/mapper/rqaappvg_new-usrsapdaa_lv
 1087  2021-08-24 12:54:18 df -hT |grep -i rqaappvg_new
 1088  2021-08-24 12:54:21 vgs
 1089  2021-08-24 12:54:39 vgchange -an rqaappvg_new
 1090  2021-08-24 12:55:16 vgremove rqaappvg_new
 1091  2021-08-24 12:55:20 vgs
 1092  2021-08-24 12:55:51 lsblk
 1093  2021-08-24 12:56:21 vgextend rqaappvg /dev/sdo
 1094  2021-08-24 12:56:35 vgs rqaappvg
 1095  2021-08-24 12:56:40 pvs |grep -i rqaappvg
 1096  2021-08-24 12:57:17 pvmove /dev/sdc /dev/sdo
 1097  2021-08-24 13:09:25 pvs |grep -i rqaappvg
 1098  2021-08-24 13:09:44 lvdisplay |grep -i rqaappvg
 1099  2021-08-24 13:09:51 \pvs
 1100  2021-08-24 13:09:53 pvs
 1101  2021-08-24 13:10:03 pvs|grep -i rqaappvg
 1102  2021-08-24 13:10:23 df -hT |grep -i rqaappvg
 1103  2021-08-24 13:10:57 vgreduce rqaappvg /dev/sdc
 1104  2021-08-24 13:11:02 df -hT |grep -i rqaappvg
 1105  2021-08-24 13:11:05 vgs
 1106  2021-08-24 13:11:58 lsblk
 1107  2021-08-24 13:12:11 blkid /dev/sdc
 1108  2021-08-24 13:12:54 lsblk |grep -i sdc
 1109  2021-08-24 13:13:01 lsblk |grep -i sdd
 1110  2021-08-24 13:13:23 df -hT /oracle/RQA/sapdata
 1111  2021-08-24 13:13:32 vgs rqalogvg
 1112  2021-08-24 13:13:45 df -hT /oracle/RQA/sapdata*
 1113  2021-08-24 13:13:53 vgs rqadatavg
 1114  2021-08-24 13:15:30 pvremove /dev/sdc
 1115  2021-08-24 13:15:40 blkid /dev/sdc
 1116  2021-08-24 13:15:46 lsblk
 1117  2021-08-24 13:15:52 lsblk |grep -i sdc
 1118  2021-08-24 13:16:58 lsblk
 1119  2021-08-24 13:20:12 history




CS8339437 raised for softlayer access to ocean id

-----------------------------------------------------------

persistent share point for CMAS
SharePoint Link to Kyndryl Documentation: https://persistentsystems.sharepoint.com/:f:/r/sites/IBMCMS/Shared%20Documents/General/Cloud%20DU1/CMAS/Kyndrly%20Transition?csf=1&web=1&e=vRZ4uE

-------------------------------------------------------------------------------------------

PHANA prepatching actions

ACTIONS - preventive actions
-----------------------------
Your request: prevent this issue from happening again. 

  (S1) Always capture one set of compressed Supportconfig files before patching.
  (S2) ALways mount ISO image file with matching OS.
       Note: even with ISO image mounted,  the default action is to boot from hardsisk.
  (S3) Backup root disk and other filesystems defined in /etc/fstab file.
  (S4) Reboot once to test that the host is bootable before patching.
  (S5) After successful rebooting, perform patching.
       Capture another set of comressed Supportconfig files.
       Backup GRUB related files under /boot , namely

          /boot/:
           directory grub2
           files    initrd* 
           files    vmlinuz*

  (S6) recreate GRUB related files and observe if there is any error reported. 

          # dracut -f -a  multipath lvm
       or   
          # dracut --regenerate-all -f

          # grub2-mkconfig -o /boot/grub2/grub.cfg
          # grub2-install /dev/sdX


  (S7) With ISO image ever readily mounted, if the problem still persists.
       Boot from ISO image to chroot and recreate GRUB related files again.

  mount rootdisk

    [ root ] # mount -o rw /<root-disk-or-volume>  /mnt

  mount /boot

    find out if mountpoint /boot in rootdisk is mounted with another device.

        [ root ] #  egrep -i "/boot"  /mnt/etc/fstab
                  
     Mount the boot device to /mnt/boot if separate filesystem for /boot is configured.

         [ root ] #  mount /<device-for-boot> /mnt/boot


  Bind the rescue system's proc, sys and dev to /mnt before chroot.
 
    [ root ] # for i in dev proc run sys ; do mount --rbind /$i /mnt/$i ; done

  Chroot to /mnt

     [ root ] # chroot /mnt

  create a new one using the following commands :
 
            # dracut -f -a  multipath lvm
       or  
            # dracut --regenerate-all -f

  Rebuild grub config if the OS is SLES 12 and above.
  Refer: https://www.suse.com/support/kb/doc/?id=000018523

          # grub2-mkconfig -o /boot/grub2/grub.cfg
          # grub2-install /dev/sdX

  Exit chroot 

      [ root ] # exit

  Reboot the server normally.

    # systemctl reboot 

------------------------------------------------------------------------------------------------------------- 
pacemaker service not starting in SuSE post reboot and patching

chk journalctl -xe

journalctl -r      Your logs will be displayed from oldest to newest. To reverse this order and display the newest messages at the top, use the -r flag:

if it says cannot start due to dependencies on sbd service then u have to clear the queue
refer the https://www.suse.com/support/kb/doc/?id=000019190

Situation
Starting pacemaker or openais service and it fails to start with a dependency error.
systemd[1]: Dependency failed for Pacemaker High Availability Cluster Manager.

Messages seen in SLES12 log after trying to start pacemaker.service and failing to start / join the cluster.
sbd: [34824]: WARN: Found fencing message - aborting start-up. Manual intervention required!
sbd: [34819]: WARN: Servant for pcmk (pid: 34826) has terminated
sbd: [34819]: WARN: Servant for <path to sbd device > (pid: 34824) has terminated
sbd.sh[34808]: sbd failed; please check the logs.
sbd.sh[34808]: SBD failed to start; aborting.
systemd[1]: sbd.service: Control process exited, code=exited status=1

Resolution
With the "start" mode option set in the /etc/sysconfig/sbd, you will need to manually clear the SBD slot before it will join.
Need to find out <SBD_DEVICE> which can be found in /etc/sysconfig/sbd file.
Syntax to be run on node that was previously fenced:
  Example: sbd -d <SBD_DEVICE>  message LOCAL clear

You may also issue the command from any node in cluster by specifying the node name instead of "LOCAL"
Syntax:  sbd -d <DEVICE_NAME> message <NODENAME> clear
  Example: sbd -d /dev/mapper/sbddisk1 message NODEA clear

Once the node slot is cleared, you should be able to start clustering. 
SLES114:  rcopenais start
SLES12+: systemctl start pacemaker.service

sbd -d /dev/mapper/sbddisk1 list0    ia1sp1db    clear
-----------------------------------------------------------------------------------------
sshpass to fetch VM details via script

sage: sshpass [-f|-d|-p|-e] [-hV] command parameters
   -f filename   Take password to use from file
   -d number     Use number as file descriptor for getting password
   -p password   Provide password as argument (security unwise)
   -e            Password is passed as env-var "SSHPASS"
   With no parameters - password will be taken from stdin

   -P prompt     Which string should sshpass search for to detect a password prompt
   -v            Be verbose about what you're doing
   -h            Show help (this screen)
   -V            Print version information
At most one of -f, -d, -p or -e should be used
----------------------------------------------------------------------------------------------

phana patching prechecks SNOW KB  KB0016625

-----------------------------------------------------------------------------------------------

SEI access related
https://w3.ibm.com/ocean/w3publisher/sei-iam/2fa-rsa/rsa-end-user-guide/steps-to-logon-jumphosts

------------------------------------------------------------------------------------------------

Steps to Stop HANA replication for BPA:
1. On DR (100.64.4.34 - tslbwprdhdbdr): (login as bpaadm)
HDB stop
2. On DR (100.64.4.34 - tslbwprdhdbdr): (login as bpaadm)
hdbnsutil -sr_unregister
3. On Primary (10.207.61.200 – TSLBWPRDDB): (login as bpaadm)
hdbnsutil -sr_disable
4. Stop HANA DB on TSLBWPRDDB (10.207.61.200 – TSLBWPRDDB): (login as bpaadm)
HDB stop

------------------------------------------------------------------------------------------------

Check and adjust HANA DB users
https://github.ibm.com/CMS/cms-sq-sap-hana-pe-automation_hana/wiki/Operations:-check-create-adjust-hana-users

Operations: check create adjust hana users
Robert Achim edited this page on May 26, 2020 · 9 revisions
The HANA automation tool has the capability to fix the user setup of AUTOMATION, BACKUP and DBUPDATE users. If needed, their names can be changed in the HDB.conf the configuration file.

More information about the HANA db users can be found in the SAP HANA cookbook wiki.

IMPORTANT:
THE SCRIPT MUST BE EXECUTED WITH root.
BEFORE USING THE TOOL, PLEASE MAKE SURE THAT THE HANA DATABASES ARE UP AND RUNNING!
Basic command:
/opt/ibm/HanaAutomationTool/HDBOPS.py --check-hana-users
Via the command above the HANA users' settings are checked against the database / HANA setup.
In this format, the operation is performed for all the SIDs that exist on the system where the command is executed.

There are two possible outcomes:

All SIDs have the users configured properly. In this case, no action is required from the user.
Some users are missing or misconfigured. In this case we are guided through the repair process.
Additional options:
--sid <SID_ID> execute the operation only for the tenants of the specified SAP system.
--sid <SID_ID> --tenant <tenant_ID> execute the operation only for this tenant and SAP system.
--sid <SID_ID> --tenant <tenant_ID> --tenant_password <system_password> also provide the SYSTEM user password required to fix some of the issues that can occur.

Only on single-container systems you can use this variant:
/opt/ibm/HanaAutomationTool/HDBOPS.py --check-hana-users --sid <SID_ID> --tenant_password <system_password>

Provisioning automation:
With the -x switch the script can be run in an unattended way, say as part of the provisioning automation:
/opt/ibm/HanaAutomationTool/HDBOPS.py -x --check-hana-users --sid <SID_ID> --tenant <tenant_ID> --tenant_password <password>

AUTOMATION user only:
With the -a switch the script will only check and fix the AUTOMATION user.
For example, the following command can be used to create the AUTOMATION user in batch mode in 1.x environments:
/opt/ibm/HanaAutomationTool/HDBOPS.py --check-hana-users -ax --sid <SID_ID> --tenant <tenant_ID> --tenant_password <password>

--------------------------------------------------------------------------------------------------------------------------------------------------------

SuSE disable auto restart of service
systemctl disable <service name>

to check if enabled/disabled
systemctl is-enabled <servicename>


to enable auto restart of servivce post reboot
systemctl enable <servicename>


There are several ways to reconfigure any service to start manual.

    insserv -r [service name]
    chkconfig [service name] off
    yast runlevel, then search for [service name] and disable it.
    (replace the [service name] with the actual name of the service).

------------------------------------------------------------------------------------------------------------

copy paste not working on KVM

 https://www.spice-space.org/download/windows/spice-guest-tools/spice-guest-tools-latest.exe

install this on kvm and copy paste will start to work

--------------------------------------------------------------------------------------------------------------------
Find a file in linux

find . -name thisfile.txt

--------------------------------------------------------------------------------------------------------------

To check ssh key length

To check what host keys are being used currently. Below are the observed outputs.

Raw
# sshd -T | grep -i protocol
protocol 2
# sshd -T | grep -i hostkey
hostkey /etc/ssh/ssh_host_rsa_key
hostkey /etc/ssh/ssh_host_dsa_key
To verify whether 1024 bits or 2048 bits keys are being used. (Both Public and Private)

Raw
# ssh-keygen -lf /etc/ssh/ssh_host_dsa_key
1024 8c:80:fd:12:73:bc:e6:7f:d4:10:ac:a8:ac:2b:4b:c1 /etc/ssh/ssh_host_dsa_key.pub (DSA)
# ssh-keygen -lf /etc/ssh/ssh_host_dsa_key.pub
1024 8c:80:fd:12:73:bc:e6:7f:d4:10:ac:a8:ac:2b:4b:c1 /etc/ssh/ssh_host_dsa_key.pub (DSA)
# ssh-keygen -lf /etc/ssh/ssh_host_rsa_key
2048 bb:2d:17:ba:99:a9:99:85:fd:a6:b3:ab:2f:89:e9:2f /etc/ssh/ssh_host_rsa_key.pub (RSA)
# ssh-keygen -lf /etc/ssh/ssh_host_rsa_key.pub
2048 bb:2d:17:ba:99:a9:99:85:fd:a6:b3:ab:2f:89:e9:2f /etc/ssh/ssh_host_rsa_key.pub (RSA)

----------------------------------------------------------------------------------------------------------------------

Find all logged in users in the past with timestamp

last | head -5 | tr -s " "

Task: Find Out Who Was Logged In At A Particular Time
To display the state of logins as of the specified time to determine easily who was logged in at a particular time specify that time with -t option and look for “still logged in”.
last -t YYYYMMDDHHMMSS
last -t 20091028231100 username




then use bash history to find the commands fired by the logged in users
# cat /home/<profile name uid>/.bash_history
User bash-history file

----------------------------------------------------------------------------------------
Tainted kernel

guide:  https://www.kernel.org/doc/html/latest/admin-guide/tainted-kernels.html to debug the tainted kernel and determine what caused the taint to occur

Determining the taint status of a running kernel.

The taint status of a running kernel can be determined by running

cat /proc/sys/kernel/tainted

When the output is 0, the kernel is not tainted, when the output is non-zero, the kernel is tainted.

The value will be a combined number of all applying kernel taint flags added (ORed) together. You can find a list of currently used kernel flags under:

/usr/src/linux/Documentation/sysctl/kernel.txt


When the kernel produces an error, a string detailing the taint status will be included.


https://www.suse.com/support/kb/doc/?id=000016321
------------------------------------------------------------------------------------------

Check open ports

Run any one of the following command on Linux to see open ports:
sudo lsof -i -P -n | grep LISTEN
sudo netstat -tulpn | grep LISTEN
sudo ss -tulpn | grep LISTEN
sudo lsof -i:22 ## see a specific port such as 22 ##
sudo nmap -sTU -O IP-address-Here

netstat -rn|grep first three subnet of ip

------------------------------------------------------------------------------------------------------

RHEL repos enable/disable

To see a list of available repositories:

    Raw

    [root@server ~]# subscription-manager repos --list

To enable a specific Red Hat repository:

    Raw

    [root@server ~]# subscription-manager repos --enable=rhel-6-server-optional-rpms

To disable a specific Red Hat repository:

    Raw

    [root@server ~]# subscription-manager repos --disable=rhel-6-server-optional-rpms

-----------------------------------------------------------------------------------------------------------------
PSL Credit point
Referring to our annual credit point policy, we wish to you inform you in the last quarter know how many points you have earned. Please visit the following link.


https://eisweb.persistent.co.in/eis/login.aspx?url=/eis/TrainingSystem/TMSWeb/Reports/CreditPointReportFY.aspx?flag=0



As policy guidelines:


    Employees at all locations (within India & outside India), all grades, between 1.3, to 11.x in Delivery Units and who have joined before 1st June of that year, are required to earn minimum 15 credit points in a year (January to December)


    All Employees from all locations (within India & outside India), from these BU/ Function/Track and who have joined after 1st June of that year, are recommended to earn minimum 10 credit points in that year (January to December).
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

upgrade Oracle Databases from Oracle 12c to Oracle 19 on Pacemaker Clusters, this new process is already documented on the following KBs:

 

OS Linux Steps for Pacemaker Clusters:

 

KB0016594 - Oracle upgrade: vers 12 to 19c – OS tasks on Pacemaker Clusters

https://ibmma.service-now.com/nav_to.do?uri=%2Fkb_view.do%3Fsysparm_article%3DKB0016594%26sysparm_stack%3D%26sysparm_view%3D

 

Oracle Steps:

 

KB0016585 - Initial proposal for Oracle Upgrade from 12.2.0.1 to 19c

https://ibmma.service-now.com/kb_view.do?sys_kb_id=d026f6bd1b1e7410a0176394604bcba0

------------------------------------------------------------------------------------------------------------

SFTP cipher issue

Algorithms have been enabled:

[root@spsvmplmapp01 ~]# nmap --script ssh2-enum-algos -sV -p 22 10.6.3.46

Starting Nmap 5.51 ( http://nmap.org ) at 2021-10-07 02:35 +08
Nmap scan report for spsvmplmapp01.imzcloud.ibmammsap.local (10.6.3.46)
Host is up (0.000052s latency).
PORT STATE SERVICE VERSION
22/tcp open ssh OpenSSH 5.3 (protocol 2.0)
| ssh2-enum-algos:
| kex_algorithms (4)
| diffie-hellman-group-exchange-sha256
| diffie-hellman-group-exchange-sha1
| diffie-hellman-group14-sha1
| diffie-hellman-group1-sha1
| server_host_key_algorithms (2)
| ssh-rsa
| ssh-dss
| encryption_algorithms (3)
| aes128-ctr
| aes192-ctr
| aes256-ctr
| mac_algorithms (6)
| hmac-sha1
| umac-64@openssh.com
| hmac-ripemd160
| hmac-sha2-256
| hmac-sha2-512
| hmac-ripemd160@openssh.com
| compression_algorithms (2)
| none
|_ zlib@openssh.com

https://access.redhat.com/discussions/2143791

https://access.redhat.com/solutions/1181463  
-----------------------------------------------

Answered my own issue, I believe, any willing to confirm?

The steps:

vi /etc/ssh/shh_config
Replace #Cyphers line with: Ciphers aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128
Replace #MACs line with: MACs hmac-sha1,umac-64@openssh.com,hmac-ripemd160
Esc --> : --> :wq
Note there will no longer be a # in front of Cyphers and MACs.

vi /etc/ssh/shhd_config
Look for the line "# Ciphers and keying" and "#RekeyLimit default none"
Below "#RekeyLimit default none" add: Ciphers aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128 MACs hmac-sha1,umac-64@openssh.com,hmac-ripemd160
Esc --> : --> :wq
From here you will need to restart the sshd service

systemctl stop sshd.service then systemclt start sshd.service (alternatively you can do: systemstl restart sshd.service) systemctl will not give you any verbose information that the service has been restarted. So I stop then run systemctl | grep sshd.service if it is present after running the stop command then it didn't stop.

To test the cypers, type #ssh -vv localhost Look for the listing of allowed ciphers. Nothing should be pointing to MD5 or CBC.


-------------------------------------

according to customer. HFC all phana is under moonlight 
ZEC is moonlight
ZEC , HFC, PRK are moonlight account


To get Moonlight account you will have to follow this KB How to Request for User Account: Personal, Application and Customer ID (sharepoint.com)  https://kyndryl.sharepoint.com/sites/sei-iam/SitePages/iam--end-users--create-user-id.aspx?OR=Teams-HL&CT=1694542355165&clickparams=eyJBcHBOYW1lIjoiVGVhbXMtRGVza3RvcCIsIkFwcFZlcnNpb24iOiIyNy8yMzA4MDQwODYzNiIsIkhhc0ZlZGVyYXRlZFVzZXIiOmZhbHNlfQ%3D%3D
To add privilege if you have existing Moonlight account you will have to follow this KB How to Add Privilege to User Account (sharepoint.com)  https://kyndryl.sharepoint.com/sites/sei-iam/SitePages/iam--end-users--change-profile.aspx?OR=Teams-HL&CT=1694584926274&clickparams=eyJBcHBOYW1lIjoiVGVhbXMtRGVza3RvcCIsIkFwcFZlcnNpb24iOiIyNy8yMzA4MDQwODYzNiIsIkhhc0ZlZGVyYXRlZFVzZXIiOmZhbHNlfQ%3D%3D
And here it shows how to track status of your requests and which approvals you are missing Track Your Request (sharepoint.com) https://kyndryl.sharepoint.com/sites/UAT/SitePages/track-your-request.aspx
------------------------------------------------------------------------------

SL VPN on local linux laptop

https://cloud.ibm.com/docs/iaas-vpn?topic=iaas-vpn-standalone-vpn-clients
install motion pro fro website for ur OS.
setup a profiel and connect

https://cloud.ibm.com/docs/iaas-vpn?topic=iaas-vpn-standalone-vpn-clients
-------------------------------------------------------------------------------------

To check swapiness
[root@tgps4hdevapp ibmrmalik]# cat /proc/sys/vm/swappiness
60
[root@tgps4hdevapp ibmrmalik]# sysctl vm.swappiness
vm.swappiness = 60
You have mail in /var/mail/root


Locate the vm.swappiness parameter and change its value. If this parameter does not exist, append the following line to the file:
vi /etc/sysctl.conf

/etc/sysctl.conf
vm.swappiness=1

[root@tgps4hdevapp ibmrmalik]# sysctl vm.swappiness
vm.swappiness = 60
You have mail in /var/mail/root
[root@tgps4hdevapp ibmrmalik]# free -gh
             total       used       free     shared    buffers     cached
Mem:           31G        28G       3.2G        13G       622M        21G
-/+ buffers/cache:       6.5G        24G
Swap:          47G        35M        47G
You have mail in /var/mail/root
1:08
see this
1:08
here the free + cached is considered as free
1:09
once this goes beyond the swapiness value set which is 60% it will use swap
1:09
does this explain
1:09
i just read more on how it works


A swappiness setting of zero means that the disk will be avoided unless absolutely necessary (you run out of memory), while a swappiness setting of 100 means that programs will be swapped to disk almost instantly.
-------------------------------------------------------------------------------------------------------------------------------------------------------------------

Script for fetching average Mem of any server for a month

#!/bin/sh
echo "+-------------------------------------------------------------------------------------------------------------------+"
echo "|Average:       kbmemfree kbmemused  %memused kbbuffers kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty  |"
echo "+-------------------------------------------------------------------------------------------------------------------+"
for file in `ls -tr /var/log/sa/sa* | grep -v sar`
do
dat=`sar -f $file | head -n 1 | awk '{print $4}'`
echo -n $dat
sar -r -f $file  | grep -i Average | sed "s/Average://"
done
echo "+-------------------------------------------------------------------------------------------------------------------+"



Average CPU

#!/bin/sh
echo "+----------------------------------------------------------------------------------+"
echo "|Average:         CPU     %user     %nice   %system   %iowait    %steal     %idle  |"
echo "+----------------------------------------------------------------------------------+"
for file in `ls -tr /var/log/sa/sa* | egrep -v "sar|xz"`
do
dat=`sar -f $file | head -n 1 | awk '{print $4}'`
echo -n $dat
sar -f $file  | grep -i Average | sed "s/Average://"
done
echo "+----------------------------------------------------------------------------------+"


#!/bin/sh
# ------------
# IO
# ------------
echo
echo "IO"
echo "============="
echo -n "           "
sar -r -f $file | head -3 | tail -1 | awk '{print substr($0,12,100)}'
for file in `ls -tr /var/log/sa/sa* | egrep -v "sar|xz"`
do
    dt=`sar -b -f $file | head -1 | awk '{print $4}'`
    echo -n $dt
    sar -b -f $file | tail -1 | sed "s/Average:  //"
done

# ------------
# NETWORK
# ------------
echo
echo "NETWORK"
echo "============="
echo -n "           "
sar -r -f $file | head -3 | tail -1 | awk '{print substr($0,12,100)}'
for file in `ls -tr /var/log/sa/sa* | egrep -v "sar|xz"`
do
    dt=`sar -n ALL -f $file | head -1 | awk '{print $4}'`
    echo -n $dt
    sar -n ALL -f $file | tail -1 | sed "s/Average:  //"
done

-------------------------------------------------------------------------------------------------------------------------------------

RHEL 6 to 7

Sreejesh has done it Ref changes


CHG0221802

CHG0221644

https://github.kyndryl.net/CMS/SAP-CLIENT-OSLINUX/blob/master/3.x_SOPs/RHEL%207%20Migration.md

Nithya's wiki   RHEL 6 to 8
https://github.kyndryl.net/CMS/BuildMigration/wiki

https://github.kyndryl.net/CMS/BuildMigration/wiki/RHEL6-to-RHEL-7-Upgrade-Steps

https://github.kyndryl.net/CMS/BuildMigration/wiki/Inplace-upgrade-RHEL7-to-RHEL8

-----------------------------------------------------------------------------------------------------------------

Chef main server -copy the public key in [root@fmsprdchef001 .ssh]# pwd
/root/.ssh
------------------------------------------------------------------------------------------------------

Kyndryl bluepages
https://w3.ibm.com/#/people/
-----------------------------------------------------------------------------------------------------------

NFS config on cluster

Wait for PDL to stop all the application servers.

 

Stop pacemaker on both nodes
#systemctl stop pacemaker (on both nodes)

Stop NFS server on both nodes
#systemctl stop nfs-server (on both nodes)

Modify NFSV4LEASETIME parameter in NFS configuration (on both nodes)

Current setting:
[root@node1 ~]# cat /etc/sysconfig/nfs  | grep NFSV4LEASETIME
NFSV4LEASETIME=""
[root@node1 ~]##vi /etc/sysconfig/nfs ====> navigate to the parameter NFSV4LEASETIME and add the value "15"
After adding it should show like ====> NFSV4LEASETIME="15"

10) Configure NFS_LEASETIME
Diagnostic:

cat /etc/sysconfig/nfs|grep -i ^NFSV4LEASETIME
NFSV4LEASETIME="15"
Solution:

sed -i 's/NFSV4LEASETIME=.*/NFSV4LEASETIME=\"15\"/g' /etc/sysconfig/nfs

 

Note1: If this parameter is not present in the NFS configuration file, please add the line NFSV4LEASETIME="15" in /etc/sysconfig/nfs
Note2: Make sure to update this setting on both nodes.

 

Start the NFS server on both nodes
#systemctl start nfs-server (on both nodes)

 

Start pacemaker on both nodes
#systemctl start pacemaker (on both nodes)

 

Wait for the cluster to completely start up and resources are in started state, then keep the cluster in maintenance mode
#crm configure property maintenance-mode=true

 

Make sure the cluster in in maintenance mode
#crm_mon -1Afr (should show unmanaged state)

 

Edit cluster configuration and add the leasetime parameter for all the export primitives
#crm config edit

 

Add the parameter """"wait_for_leasetime_on_stop=true"""" in "params" line for all the export primitives

 

=============================================================
Example

 

primitive export-interface_lv exportfs \
        params fsid=2 directory="/export/INTERFACE" options="rw,crossmnt,sync,no_root_squash" clientspec="*" \
        op start interval=0 timeout=60 \
        op stop interval=0 timeout=120 \
        op monitor interval=30s timeout=40s
After adding the parameter, it should be like below

 

primitive export-interface_lv exportfs \
        params fsid=2 directory="/export/INTERFACE" options="rw,crossmnt,sync,no_root_squash" clientspec="*" wait_for_leasetime_on_stop=true \
        op start interval=0 timeout=60 \
        op stop interval=0 timeout=120 \
        op monitor interval=30s timeout=40s

 

Keep the cluster back in managed mode and check if all resources are in started state
#crm configure property maintenance-mode=false
#crm_mon -1Afr
----------------------------------------------------------------------------------------------

chef-client failed

https://github.kyndryl.net/CMS/Platform-Support/wiki/Troubleshooting-IMZ-login-issues---Linux

https://github.kyndryl.net/CMS/cms-chef/wiki/Linux-Active-Directory-Troubleshooting

-------------------------------------------------------------------------------------------------------------

AD console
dsa.msc

------------------------------------------------------------------------------

ibmppankaj@hfcpr1app1 ~]$ sudo su -
>>> /etc/sudoers.d/010_STD_ALIAS_GLB: Alias "SUDOSUDO" already defined near line 20 <<<
>>> /etc/sudoers.d/010_STD_ALIAS_GLB: Alias "IBM_NONE_SA" already defined near line 64 <<<
>>> /etc/sudoers.d/010_STD_ALIAS_GLB: Alias "IBM_UNIX_SA_CMDS" already defined near line 69 <<<
>>> /etc/sudoers.d/010_STD_ALIAS_GLB: Alias "IBM_SHELLESCAPE_ALL" already defined near line 125 <<<
>>> /etc/sudoers.d/010_STD_ALIAS_GLB: Alias "IBM_NONE_EDITOR" already defined near line 138 <<<
sudo: parse error in /etc/sudoers.d/010_STD_ALIAS_GLB near line 20
sudo: no valid sudoers sources found, quitting
sudo: unable to initialize policy plugin

fix
get root access and remove all files under /etc/sudoers.d which start with number


---------------------------------------------------------------------------------------------------

Grub rescue

  355  2021-11-20 07:28:55 df -h
  356  2021-11-20 07:29:11 mkinitrd
  357  2021-11-20 07:32:03 vi /etc/lvm/lvm.conf
  358  2021-11-20 07:34:11 mkinitrd
  359  2021-11-20 07:35:40 reboot
  360  2021-11-20 07:35:44 exit
  361  2021-11-20 07:47:40 cat /etc/lvm/lvm.conf | grep -i lvmae
  362  2021-11-20 07:47:46 cat /etc/lvm/lvm.conf | grep -i lvmeatd
  363  2021-11-20 07:49:29 mount -a
  364  2021-11-20 07:49:49 df -h
  365  2021-11-20 07:50:06 cat /etc/fstab
  366  2021-11-20 07:50:22 df -h
  367  2021-11-20 07:50:28 mkinitrd
  368  2021-11-20 07:52:20 df -h
  369  2021-11-20 07:52:30 fdisk -l
  370  2021-11-20 07:52:38 fdisk -l | grep -i root
  371  2021-11-20 07:52:44 fdisk -l | grep -i system
  372  2021-11-20 07:53:30 grub2-install /dev/sda
  373  2021-11-20 07:55:16 grub2-mkconfig -o /boot/efi/EFI/sles/grub.cfg



whereis <commandname>     to get the absolute path from where the cmmand is being run


AWS sysops udemy
https://kyndryl.udemy.com/course/ultimate-aws-certified-sysops-administrator-associate/learn/lecture/27512496#overview

-------------------------------------------------------------------------------------------------------

[3:22 PM] Stopping HSR:
1. Stop DB on DR --> SAP  performer
2. Unregister HSR on DR  -----------> OS
- Login to tsls4proddbdr
- su - s4prdadm
- hdbnsutil –sr_unregister
3. Disable HSR on HA  -----------> OS
- Login  to  tsls4proddbh
- su  -s4prdadm
- hdbnsutil –sr_disable
4. Put HA on standby (this should stop the running DB on HA) -----------> OS
-  Login to  tsls4proddbh
- crm node standby tsls4proddbh (wait for the resource groups failover to complete)
5. Stop DB on HA (only if not stopped)   -----------> SAP  Performer
6. Put cluster on maintenance mode -----------> OS
   #crm configure property maintenance-mode=true
7. Unregister HSR on HA  -----------> OS
   - Login  to  node tsls4proddbh
   - su - s4prdadm
   - hdbnsutil –sr_unregister
8. Proceed with next steps (starting apps)
[3:22 PM] ===================
[3:22 PM] one  question
[3:23 PM] Can we  unregister  HSR  after  disabling it?
[3:23 PM] will confirm  SID,s later

--------------------------------------------------------------------------------------------

[root@ps2-s4p-db iscsi]# cat iscsid.conf | grep -v "#" | grep "startup"
node.startup = manual
[root@ps2-s4p-db-ha iscsi]# cat iscsid.conf | grep -v "#" | grep "startup"
node.startup = automatic

should be done and iscsi and iscsid services restarted


iscsiadm -m node --loginall all

[root@ps2-s4p-db iscsi]# sbd -d /dev/disk/by-id/scsi-360014054b5958b4db3b4acc914dbb499 -d /dev/disk/by-id/scsi-36001405eb62726ea5f54a3eb6b4ab0b4 -d /dev/disk/by-id/scsi-36001405b80858e9c1f34f239b617a0e5 list
0       ps2-s4p-db      clear   ps2-s4p-db-ha
1       ps2-s4p-db-ha   clear   ps2-s4p-db
0       ps2-s4p-db      clear   ps2-s4p-db-ha
1       ps2-s4p-db-ha   clear
0       ps2-s4p-db      clear   ps2-s4p-db-ha
1       ps2-s4p-db-ha   clear

--------------------------------------------------------------------------------------------------------------------------------
DRBD error


[root@saupg1scs02p ~]# drbdadm status
r0 role:Secondary
  disk:UpToDate
  saupg1scs01p role:Primary
    peer-disk:UpToDate

r1 role:Secondary
  disk:UpToDate
  saupg1scs01p connection:Connecting    -------------- error

r2 role:Primary
  disk:UpToDate
  saupg1scs01p role:Secondary
    peer-disk:UpToDate

The primary server will show r0/r1/r2 as primary and secondary will show same r0/r1/r2 as secondary
Status will be standalone
to fix, run the below.change the r0 r1 according to the not in sync drive name

CS11439516 == lbu#Resources DRBD CRITICAL: Role value Unknown found for resource r0 on host lbups1ap01ha
First command needs to be run only on Secondary node -
drbdadm  disconnect r0; drbdadm secondary r0; drbdadm connect r0 --discard-my-data;
######################################################################################
2nd Step -- Run below command only on primary node Primary Node
drbdadm  disconnect r0; drbdadm primary r0; drbdadm connect r0;
#################################################################




[root@saupg1scs02p ~]# crm_mon -1Afr
Stack: corosync
Current DC: saupg1scs02p (version 1.1.19+20181105.ccd6b5b10-3.28.1-1.1.19+20181105.ccd6b5b10) - partition with quorum
Last updated: Wed Dec  8 01:37:04 2021
Last change: Fri Dec  3 04:26:25 2021 by root via cibadmin on saupg1scs01p

2 nodes configured
30 resources configured

Online: [ saupg1scs01p saupg1scs02p ]

Full list of resources:

 Resource Group: g-ascs
     ip-pg1-ascs01      (ocf::heartbeat:IPaddr2):       Started saupg1scs01p
     vol_pg1ascsvg      (ocf::heartbeat:LVM):   Started saupg1scs01p
     fs-ascs01lv        (ocf::heartbeat:Filesystem):    Started saupg1scs01p
     rsc_sap_pg1_ascs01 (ocf::heartbeat:SAPInstance):   Started saupg1scs01p
 Resource Group: g-ers
     ip-pg1-ers03       (ocf::heartbeat:IPaddr2):       Started saupg1scs02p
     vol_pg1ersvg       (ocf::heartbeat:LVM):   Started saupg1scs02p
     fs-ers03lv (ocf::heartbeat:Filesystem):    Started saupg1scs02p
     rsc_sap_pg1_ers03  (ocf::heartbeat:SAPInstance):   Started saupg1scs02p
 Resource Group: g-nfs
     ip-pg1-nfs (ocf::heartbeat:IPaddr2):       Started saupg1scs01p
     vol_pg1globalvg    (ocf::heartbeat:LVM):   Started saupg1scs01p
     fs-sapmnt  (ocf::heartbeat:Filesystem):    Started saupg1scs01p
     export-sapmnt      (ocf::heartbeat:exportfs):      Started saupg1scs01p
     fs-interface       (ocf::heartbeat:Filesystem):    Started saupg1scs01p
     export-interface   (ocf::heartbeat:exportfs):      Started saupg1scs01p
     fs-3rdPartySoftware        (ocf::heartbeat:Filesystem):    Started saupg1scs01p
     export-3rdPartySoftware    (ocf::heartbeat:exportfs):      Started saupg1scs01p
 Master/Slave Set: ms-drbd-ascs [DRBD1-res]
     Masters: [ saupg1scs01p ]
     Slaves: [ saupg1scs02p ]
 Master/Slave Set: ms-drbd-ers [DRBD2-res]
     Masters: [ saupg1scs02p ]
     Slaves: [ saupg1scs01p ]
 Master/Slave Set: ms-drbd-global [DRBD0-res]
     Masters: [ saupg1scs01p ]
     Slaves: [ saupg1scs02p ]
 Clone Set: clone-crossmnt [cross-mnt-fs]
     Started: [ saupg1scs01p saupg1scs02p ]
 vcenter-fencing-saupg1scs01p   (stonith:fence_vmware_rest):    Started saupg1scs02p
 vcenter-fencing-saupg1scs02p   (stonith:fence_vmware_rest):    Started saupg1scs01p

Node Attributes:
* Node saupg1scs01p:
    + master-DRBD0-res                  : 10000
    + master-DRBD1-res                  : 10000
    + master-DRBD2-res                  : 10000
* Node saupg1scs02p:
    + master-DRBD0-res                  : 10000 
    + master-DRBD1-res                  : 1000   --------------------error
    + master-DRBD2-res                  : 10000
    + runs_ers_PG1                      : 1

Migration Summary:
* Node saupg1scs01p:
* Node saupg1scs02p:
[root@saupg1scs02p ~]#
10:03
1000 ---- must 10000
10:03
and drbdadm status   must uptodate for all resources
First on secondary node, then on primary node
on Secondary node
drbdadm  disconnect r1; drbdadm secondary r1; drbdadm connect r1 --discard-my-data
On primary node
drbdadm  disconnect r1; drbdadm primary r1; drbdadm connect r1

[root@armfksap303a1 ibmrmalik]$ drbdadm status
r0 role:Primary
  disk:UpToDate
  armfksap303ap role:Secondary
    peer-disk:UpToDate
r1 role:Primary
  disk:UpToDate
  armfksap303ap role:Secondary
    peer-disk:UpToDate
r2 role:Secondary
  disk:UpToDate
  armfksap303ap role:Primary
    peer-disk:UpToDate

here secondary is armfksap303ap role:Secondary
primary node is armfksap303a1

----------------------------------------------------------------------------------------------------

Restricting a Package to a Fixed Version Number with yum 
https://access.redhat.com/solutions/98873



How to install preupgrade assessment packages on an offline system for RHEL 6.10 to RHEL 7.9 upgrade ? 
https://access.redhat.com/solutions/6413651


Unable to get the login prompt on the console.
https://access.redhat.com/solutions/4094961
-----------------------------------------------------------------------------------------------------------
RAID setup

I believe the drive went into JBOD status as JBOD mode is likely enabled on the RAID Controller, and this was done automatically.
This should have started a copyback from the HDD6 hot-spare, but it appears this was not done automatically.
In order to start this copyback process, I will need you to run the following commands:
/opt/MegaRAID/storcli/storcli64 /c0 /e134 /s6 set good force
This will force the new drive from JBOD mode to UGOOD mode. I believe the copyback process should start automatically at this point, but if it doesn't, you can manually start it using the following command:
/opt/MegaRAID/storcli/storcli64 /c0/e134 /s10 start copyback target=134:6
Then, you may monitor the status of the copyback with the following command:
/opt/MegaRAID/storcli/storcli64 /c0/eall/sall show copyback
Please let us know when this is done and provide us with the output of the copyback so we can follow up and ensure it completes successfully.
Thank you,
Joseph R.
Data Center Shift Lead

----------------------------------------------------------------------------------------------------------------------

Global protect not connecting

still facing issue with VPN, then follow below steps.
Note: Before following below steps please clear cache and cookies.
Disconnected GP
Flushed gpd0 (check "ip a s", if there is any Ethernet port is assigned after disconnect)
Signed out from Global Protect
Reset Global Protect
Reconfigured Global Protect
Sign in Global Protect again.

--------------------------------------------------------------------------------

log4j vlnerability
Red Hat Recommendation:

In releases >=2.10, this behavior can be mitigated by setting either the
system property log4j2.formatMsgNoLookups or the environment variable
LOG4J_FORMAT_MSG_NO_LOOKUPS to true.

This parameter could be set a /etc/environment

-----------------------------------------------------------------------------------------------------
10) Troubleshooting
Known issues,
a) Yum update failed with transaction check error
If yum update reporting errors related to EL6 packages, cleanup el6 packages, for eg - python
rpm -qa &> /tmp/rpmqa.txt
cat /tmp/rpmqa.txt | grep el6|grep "python" &> /tmp/rpmold.txt 
IMPORTANT: check the packages in /tmp/rpmold.txt, if 3rd party or any app dependend, remove the package from the list before executing below command
for i in $(cat /tmp/rpmold.txt); do rpm -e $i --nodeps; done 
rpm -qa | grep el6 | wc -l

from that section only

just removed one by one rpm from rhel6.. but 3 are not.. that is all

---------------------------------------------------------------------------------------------------------

whereis <filename>

[root@ia2gp5db-dr ibmrmalik]# whereis ncpa.cfg
ncpa: /usr/local/ncpa

--------------------------------------------------------------------------------------------------------
 /tmp at 100% and no big files

You should use lsof /tmp to see currently opened file.

lsof -n | grep /tmp |grep deleted
lsof /tmp

If you delete a file, while a software still have a lock on it, you won't see it anymore, but it will still have hd space assigned to it.

--------------------------------------------------------------------------------------------------------------

To get a list of all usernames that are currently logged in, use the following:

$ who | cut -d' ' -f1 | sort | uniq

-----------------------------------------------------------------------------------------

single selinux=0 in linux 6.7 single user mode VHANA

selinux=0 will disable selinux and boot up

------------------------------------------------------------------------------------------

Change ip in linux

Edit the file
cat /etc/sysconfig/network-scripts/ifcfg-eth1
DEVICE=eth1
NM_CONTROLLED=no
ONBOOT=yes
HWADDR=00:0C:29:4B:A1:BE
TYPE=Ethernet
BOOTPROTO=none
IPADDR=10.210.1.8 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
GATEWAY=10.210.1.1
DEFROUTE=no
NETMASK=255.255.255.0
MTU=9000
[root@CI3S4HANAQA network-scripts]# 
[root@CI3S4HANAQA network-scripts]# 
[root@CI3S4HANAQA network-scripts]# cat /etc/sysconfig/network-scripts/ifcfg-eth2
DEVICE=eth2
NM_CONTROLLED=no
ONBOOT=yes
HWADDR=00:0C:29:4B:A1:C8
TYPE=Ethernet
BOOTPROTO=none
IPADDR=10.201.0.36 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
GATEWAY=10.201.0.1
DEFROUTE=yes
NETMASK=255.255.255.0
MTU=9000

------------------------------------------------------------------------------------------------------

SKip a false alert in Nagios check this file and make changes

cd /usr/local/ncpa/etc/checklog_filters.d
vi Syslog-ErrorStates.filt
add below line to exclude in first paragraph of existing file
-:1:*:sudo*iuxnes*
save it.

[root@ci3tmg-b4dapp checklog_filters.d]# pwd
/usr/local/ncpa/etc/checklog_filters.d
[root@ci3tmg-b4dapp checklog_filters.d]# ls
Syslog-Authentication.filt  Syslog-DStorage.filt  Syslog-ErrorStates.filt  Syslog-Hardware.filt  Syslog-Networking.filt  archive
[root@ci3tmg-b4dapp checklog_filters.d]# cat Syslog-ErrorStates.filt
# DO NOT REMOVE THE VERSION LINE
# VERSION=5.60
# 05-SEP-18
LOGFILE=%{syslog}
# These are messages about loading SCSI devices
-:1:*:major,minor=
-:1:*:name=.*,major=.*,minor=
-:1:*:Block layer SCSI generic.*loaded
-:1:*:sudo*iuxnes*
#
+:1:CRITICAL:jeopardy
+:1:CRITICAL:emerg
+:1:CRITICAL:crit
+:1:CRITICAL:critical
+:1:CRITICAL:major
+:1:FATAL:panic
[root@ci3tmg-b4dapp checklog_filters.d]#

----------------------------------------------------------------------------------------------

n/w test

CI: gltwddevas01 - IFN IP: 10.92.2.73


ping to target machine does work but this is not definitive as ping is disabled in many systems.
This is valid for when it works and when it does not work:

telnet did not work here either:


jose:~$ telnet 10.92.2.73 443
Trying 10.92.2.73...
telnet: connect to address 10.92.2.73: Connection refused
jose:~$


netstat did not report any connections/listening sockets on port 443:

[root@gltwddevas01 ~]# netstat -ltnp | grep -w ':443'
[root@gltwddevas01 ~]#




sshd test not fruitful either:


[root@gltwddevas01 ~]# sshd -t
[root@gltwddevas01 ~]#





lsof did report Established connections on port 443:

[root@gltwddevas01 ~]# lsof -i :443
COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME
java 270977 sccadmin 100u IPv4 1522265670 0t0 TCP gltwddevas01.gst.ibmcloud.local:64770->155.56.210.83:https (ESTABLISHED)
java 270977 sccadmin 121u IPv4 1782781655 0t0 TCP gltwddevas01.gst.ibmcloud.local:64878->155.56.210.83:https (ESTABLISHED)
java 270977 sccadmin 126u IPv4 354005282 0t0 TCP gltwddevas01.gst.ibmcloud.local:18762->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 133u IPv4 1662488005 0t0 TCP gltwddevas01.gst.ibmcloud.local:53638->ec2-52-23-189-23.compute-1.amazonaws.com:https (ESTABLISHED)
java 270977 sccadmin 142u IPv4 4032085696 0t0 TCP gltwddevas01.gst.ibmcloud.local:18930->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 143u IPv4 790431306 0t0 TCP gltwddevas01.gst.ibmcloud.local:sptx->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 145u IPv4 3473483412 0t0 TCP gltwddevas01.gst.ibmcloud.local:40406->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 148u IPv4 2207078476 0t0 TCP gltwddevas01.gst.ibmcloud.local:22026->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 149u IPv4 3886780061 0t0 TCP gltwddevas01.gst.ibmcloud.local:26242->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 150u IPv4 4180613756 0t0 TCP gltwddevas01.gst.ibmcloud.local:24210->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 151u IPv4 2074948455 0t0 TCP gltwddevas01.gst.ibmcloud.local:22028->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 156u IPv4 4147239419 0t0 TCP gltwddevas01.gst.ibmcloud.local:19138->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 157u IPv4 3886779087 0t0 TCP gltwddevas01.gst.ibmcloud.local:18952->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 159u IPv4 3425108990 0t0 TCP gltwddevas01.gst.ibmcloud.local:22126->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 167u IPv4 4182674410 0t0 TCP gltwddevas01.gst.ibmcloud.local:24324->155.56.210.84:https (ESTABLISHED)
[root@gltwddevas01 ~]#


but none in Listening:


[root@gltwddevas01 ~]# lsof -i :443 | grep LISTEN
[root@gltwddevas01 ~]#





interfaces are up:

[root@gltwddevas01 ~]# ip -br address show
lo UNKNOWN 127.0.0.1/8
eth0 UP 10.92.2.73/26
eth1 UP 10.40.2.73/26
[root@gltwddevas01 ~]#





[root@gltwddevas01 ~]# ip neighbor show
10.40.2.65 dev eth1 lladdr 00:10:db:ff:35:02 REACHABLE
10.92.2.65 dev eth0 lladdr 00:10:db:ff:35:03 REACHABLE
[root@gltwddevas01 ~]#






However, between host gltwddevas01 and gltwdprdas01, I did find 2 routes not installed:

10.40.2.64 * 255.255.255.192 U 0 0 0 eth1
10.92.2.64 * 255.255.255.192 U 0 0 0 eth0

(gltwddevas01 has them while gltwdprdas01 does not have them):



[root@gltwddevas01 ~]# netstat -r
Kernel IP routing table
Destination Gateway Genmask Flags MSS Window irtt Iface
default 10.40.2.65 0.0.0.0 UG 0 0 0 eth1
10.40.2.64 * 255.255.255.192 U 0 0 0 eth1
10.72.0.0 10.92.2.65 255.255.128.0 UG 0 0 0 eth0
10.90.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.92.2.64 * 255.255.255.192 U 0 0 0 eth0
10.130.2.0 10.92.2.65 255.255.255.0 UG 0 0 0 eth0
10.131.2.0 10.92.2.65 255.255.255.0 UG 0 0 0 eth0
10.148.6.176 10.92.2.65 255.255.255.248 UG 0 0 0 eth0
10.148.246.144 10.92.2.65 255.255.255.240 UG 0 0 0 eth0
10.149.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.170.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.176.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.177.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.183.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
20.1c.5177.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
146.89.140.0 10.92.2.65 255.255.252.0 UG 0 0 0 eth0
146.89.142.192 10.92.2.65 255.255.255.192 UG 0 0 0 eth0
146.89.168.0 10.92.2.65 255.255.248.0 UG 0 0 0 eth0
a0001p5rapp0012 10.92.2.65 255.255.255.255 UGH 0 0 0 eth0
158.87.22.192 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
158.87.44.0 10.92.2.65 255.255.254.0 UG 0 0 0 eth0
158.87.46.0 10.92.2.65 255.255.254.0 UG 0 0 0 eth0
80.bb.089f.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
20.73.7a9f.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
20.24.caa1.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
dal10seiadc001. 10.92.2.65 255.255.255.255 UGH 0 0 0 eth0
dal10seiadc002. 10.92.2.65 255.255.255.255 UGH 0 0 0 eth0
169.54.69.96 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
80.10.37a9.ip4. 10.92.2.65 255.255.255.240 UG 0 0 0 eth0
169.55.28.32 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.55.28.64 10.92.2.65 255.255.255.240 UG 0 0 0 eth0
e0.4f.37a9.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
e0.8e.37a9.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.55.192.96 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.55.254.64 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.60.136.128 10.92.2.65 255.255.255.192 UG 0 0 0 eth0
169.60.136.192 10.92.2.65 255.255.255.192 UG 0 0 0 eth0
[root@gltwddevas01 ~]#

--- 10.92.2.73 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 121.771/122.048/122.434/0.281 ms
jose:~$





telnet did not work here either:


jose:~$ telnet 10.92.2.73 443
Trying 10.92.2.73...
telnet: connect to address 10.92.2.73: Connection refused
jose:~$


netstat did not report any connections/listening sockets on port 443:

[root@gltwddevas01 ~]# netstat -ltnp | grep -w ':443'
[root@gltwddevas01 ~]#




sshd test not fruitful either:


[root@gltwddevas01 ~]# sshd -t
[root@gltwddevas01 ~]#





lsof did report Established connections on port 443:

[root@gltwddevas01 ~]# lsof -i :443
COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME
java 270977 sccadmin 100u IPv4 1522265670 0t0 TCP gltwddevas01.gst.ibmcloud.local:64770->155.56.210.83:https (ESTABLISHED)
java 270977 sccadmin 121u IPv4 1782781655 0t0 TCP gltwddevas01.gst.ibmcloud.local:64878->155.56.210.83:https (ESTABLISHED)
java 270977 sccadmin 126u IPv4 354005282 0t0 TCP gltwddevas01.gst.ibmcloud.local:18762->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 133u IPv4 1662488005 0t0 TCP gltwddevas01.gst.ibmcloud.local:53638->ec2-52-23-189-23.compute-1.amazonaws.com:https (ESTABLISHED)
java 270977 sccadmin 142u IPv4 4032085696 0t0 TCP gltwddevas01.gst.ibmcloud.local:18930->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 143u IPv4 790431306 0t0 TCP gltwddevas01.gst.ibmcloud.local:sptx->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 145u IPv4 3473483412 0t0 TCP gltwddevas01.gst.ibmcloud.local:40406->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 148u IPv4 2207078476 0t0 TCP gltwddevas01.gst.ibmcloud.local:22026->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 149u IPv4 3886780061 0t0 TCP gltwddevas01.gst.ibmcloud.local:26242->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 150u IPv4 4180613756 0t0 TCP gltwddevas01.gst.ibmcloud.local:24210->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 151u IPv4 2074948455 0t0 TCP gltwddevas01.gst.ibmcloud.local:22028->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 156u IPv4 4147239419 0t0 TCP gltwddevas01.gst.ibmcloud.local:19138->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 157u IPv4 3886779087 0t0 TCP gltwddevas01.gst.ibmcloud.local:18952->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 159u IPv4 3425108990 0t0 TCP gltwddevas01.gst.ibmcloud.local:22126->155.56.210.84:https (ESTABLISHED)
java 270977 sccadmin 167u IPv4 4182674410 0t0 TCP gltwddevas01.gst.ibmcloud.local:24324->155.56.210.84:https (ESTABLISHED)
[root@gltwddevas01 ~]#


but none in Listening:


[root@gltwddevas01 ~]# lsof -i :443 | grep LISTEN
[root@gltwddevas01 ~]#





interfaces are up:

[root@gltwddevas01 ~]# ip -br address show
lo UNKNOWN 127.0.0.1/8
eth0 UP 10.92.2.73/26
eth1 UP 10.40.2.73/26
[root@gltwddevas01 ~]#





[root@gltwddevas01 ~]# ip neighbor show
10.40.2.65 dev eth1 lladdr 00:10:db:ff:35:02 REACHABLE
10.92.2.65 dev eth0 lladdr 00:10:db:ff:35:03 REACHABLE
[root@gltwddevas01 ~]#






However, between host gltwddevas01 and gltwdprdas01, I did find 2 routes not installed:

10.40.2.64 * 255.255.255.192 U 0 0 0 eth1
10.92.2.64 * 255.255.255.192 U 0 0 0 eth0

(gltwddevas01 has them while gltwdprdas01 does not have them):



[root@gltwddevas01 ~]# netstat -r
Kernel IP routing table
Destination Gateway Genmask Flags MSS Window irtt Iface
default 10.40.2.65 0.0.0.0 UG 0 0 0 eth1
10.40.2.64 * 255.255.255.192 U 0 0 0 eth1
10.72.0.0 10.92.2.65 255.255.128.0 UG 0 0 0 eth0
10.90.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.92.2.64 * 255.255.255.192 U 0 0 0 eth0
10.130.2.0 10.92.2.65 255.255.255.0 UG 0 0 0 eth0
10.131.2.0 10.92.2.65 255.255.255.0 UG 0 0 0 eth0
10.148.6.176 10.92.2.65 255.255.255.248 UG 0 0 0 eth0
10.148.246.144 10.92.2.65 255.255.255.240 UG 0 0 0 eth0
10.149.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.170.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.176.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.177.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
10.183.0.0 10.92.2.65 255.255.0.0 UG 0 0 0 eth0
20.1c.5177.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
146.89.140.0 10.92.2.65 255.255.252.0 UG 0 0 0 eth0
146.89.142.192 10.92.2.65 255.255.255.192 UG 0 0 0 eth0
146.89.168.0 10.92.2.65 255.255.248.0 UG 0 0 0 eth0
a0001p5rapp0012 10.92.2.65 255.255.255.255 UGH 0 0 0 eth0
158.87.22.192 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
158.87.44.0 10.92.2.65 255.255.254.0 UG 0 0 0 eth0
158.87.46.0 10.92.2.65 255.255.254.0 UG 0 0 0 eth0
80.bb.089f.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
20.73.7a9f.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
20.24.caa1.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
dal10seiadc001. 10.92.2.65 255.255.255.255 UGH 0 0 0 eth0
dal10seiadc002. 10.92.2.65 255.255.255.255 UGH 0 0 0 eth0
169.54.69.96 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
80.10.37a9.ip4. 10.92.2.65 255.255.255.240 UG 0 0 0 eth0
169.55.28.32 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.55.28.64 10.92.2.65 255.255.255.240 UG 0 0 0 eth0
e0.4f.37a9.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
e0.8e.37a9.ip4. 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.55.192.96 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.55.254.64 10.92.2.65 255.255.255.224 UG 0 0 0 eth0
169.60.136.128 10.92.2.65 255.255.255.192 UG 0 0 0 eth0
169.60.136.192 10.92.2.65 255.255.255.192 UG 0 0 0 eth0
[root@gltwddevas01 ~]#

-------------------------------------------------------------------------------------------------------

permit root login

https://www.ibm.com/docs/en/db2/11.5?topic=installation-enable-disable-remote-root-login

-----------------------------------------------------------------------------------------------------

1/12/22 06:26:24.146 AM IST [ERROR] [main] [Manager] The EM failed to start. /tmp/librocksdbjni4305994262348157581.so: /tmp/librocksdbjni4305994262348157581.so: failed to map segment from shared object
1/12/22 06:26:24.166 AM IST [INFO] [main] [Manager] Shutting down the Isengard server


Fix
- Stop the EM
- sudo mount -o remount,exec /tmp
- Start the EM

https://community.broadcom.com/communities/community-home/digestviewer/viewthread?MID=762998
-------------------------------------------------------------------------------------------------------------------

Chef troubleshooting
 
https://github.kyndryl.net/CMS/Platform-Support/wiki/Troubleshooting-IMZ-login-issues---Linux

-------------------------------------------------------------------------------------------------------------------

##### CLUSTER REPORT COLLECT FOR REBOOT #############
1.hb_report -u root -f "2022/01/10 07:30" -t "2022/01/11 11:30" /tmp/hb_report_log
2.supportconfig
3.upload on https://www.ibm.com/mysupport/s/case/
############################## (

CloudAcademy

http://persistent-com.sso.cloudacademy.com/
Subdomain name is: persistent-com

#############################################################
Check and edit montoring spects

cd /usr/local/ncpa/etc/ncpa.cfg.d/
update file suse-pacemaker.cfg to remove the below 2 lines->
%HOSTNAME%|__SUSE__Service__CRITICAL__iscsid.service__ = /plugins/cmas_check_svc.sh/iscsid.service
%HOSTNAME%|__SUSE__Service__CRITICAL__sbd.service__ = /plugins/cmas_check_svc.sh/sbd.service
execute the command-> systemctl restart ncpa_passive

####################################################################33

tail: cannot watch `/var/log/messages': No space left on device
https://access.redhat.com/solutions/2087881

--------------------------------------------------------------------

chef rpm for RHEL 7
rpm -Uvh /sds/jenkins/software/linux/chef-13.9.4-1.el7.x86_64.rpm
---------------------------------------------------------------------------

Cluster NFS hung during failover
We have seen an issue with NFS resource getting hung during failover for some customers. We have analysed the issue in our test environment and found out that this happens when the source filesystems are unexported before the NFS filesystems are unmounted. Without the export, the unmount does not work. Suse has documented this scenario here -> https://www.suse.com/support/kb/doc/?id=000019414

The fix is to add NFSV4LEASETIME parameter at the OS level and wait_for_leasetime_on_stop=true for all exports.
Wait for PDL to stop all the application servers.

 

Stop pacemaker on both nodes
#systemctl stop pacemaker (on both nodes)

Stop NFS server on both nodes
#systemctl stop nfs-server (on both nodes)

Modify NFSV4LEASETIME parameter in NFS configuration (on both nodes)

Current setting:
[root@node1 ~]# cat /etc/sysconfig/nfs  | grep NFSV4LEASETIME
NFSV4LEASETIME=""
[root@node1 ~]##vi /etc/sysconfig/nfs ====> navigate to the parameter NFSV4LEASETIME and add the value "15"
After adding it should show like ====> NFSV4LEASETIME="15"

 

Note1: If this parameter is not present in the NFS configuration file, please add the line NFSV4LEASETIME="15" in /etc/sysconfig/nfs
Note2: Make sure to update this setting on both nodes.

 

Start the NFS server on both nodes
#systemctl start nfs-server (on both nodes)

 

Start pacemaker on both nodes
#systemctl start pacemaker (on both nodes)

 

Wait for the cluster to completely start up and resources are in started state, then keep the cluster in maintenance mode
#crm configure property maintenance-mode=true

 

Make sure the cluster in in maintenance mode
#crm_mon -1Afr (should show unmanaged state)

 

Edit cluster configuration and add the leasetime parameter for all the export primitives
#crm config edit

 

Add the parameter """"wait_for_leasetime_on_stop=true"""" in "params" line for all the export primitives

 

=============================================================
Example

 

primitive export-interface_lv exportfs \
        params fsid=2 directory="/export/INTERFACE" options="rw,crossmnt,sync,no_root_squash" clientspec="*" \
        op start interval=0 timeout=60 \
        op stop interval=0 timeout=120 \
        op monitor interval=30s timeout=40s
After adding the parameter, it should be like below

 

primitive export-interface_lv exportfs \
        params fsid=2 directory="/export/INTERFACE" options="rw,crossmnt,sync,no_root_squash" clientspec="*" wait_for_leasetime_on_stop=true \
        op start interval=0 timeout=60 \
        op stop interval=0 timeout=120 \
        op monitor interval=30s timeout=40s

 

Keep the cluster back in managed mode and check if all resources are in started state
#crm configure property maintenance-mode=false
#crm_mon -1Afr
---------------------------------------------------------------------------------

FTP service
vsftpd

=---------------------------------------------------------------------

chef rpm

upgrade the chef rpm also
 rpm -Uvh /sds/jenkins/software/linux/chef-13.9.4-1.el7.x86_64.rpm

for SuSE 
rpm -Uvh /sds/jenkins/software/linux/chef-14.13.11-1.sles12.x86_64.rpm

---------------------------------------------------------------------------------------

OS patching via Samuel
https://github.kyndryl.net/CMS/sap-ops-automation-docs/wiki/3.x-Patching-Process

Capability of Samuel
https://github.kyndryl.net/CMS/sap-ops-automation-docs/wiki/Automated-Patching-Documentation

--------------------------------------------------------------------------------------


Create local yum repo from iso

cd /etc/yum.repos.d
for file in $(ls /etc/yum.repos.d)
do
gzip -f9 ${file}
done
cd -
cat > /etc/yum.repos.d/rhel-dvd.repo << EOF
[dvd]
name=Red Hat Enterprise Linux Installation DVD
baseurl=file:///media/dvd                 -------replace with the actual path of the iso
enabled=1
gpgcheck=0
EOF

-----------------------------------------------------------------------------------------------------------
vhana issue with kernel 83

boot with old kernel (80)
verify if the latest kernel 83 is installed
rpm -qa |grep -i kernel


Rebuilding initrd
ls -lrt /boot
backup the initrd image initrd-4.12.14-95.83-default

to create initrd 
dracut -f /boot/initrd-4.12.14-95.83-default.test 4.12.14-95.83-default

rename  /initrd-4.12.14-95.83-default.test  to /initrd-4.12.14-95.83-default

check /etc/grub.d/grub.cfg
and verify if it is pointing to latest initrd image created in last step

reboot and test


Situation: On reboot VMs are not coming up after OS patching. Engineers go into single user mode and do the trouble shooting and try to start it back, but still getting hung in the next reboot. More than an hour was consumed and did not give any positive result.

Solution: We have followed the below approach and got the breakthrough in multiple occasions. First attempt recreate initrd img after booting with old kernel, most cases VM came with the new 83 kernel version.

Below are the steps performed to bring back the VM for HNO customer recently. (cmds mentioned is w.r.t 83 kernel)

1. Boot server with old kernel

2. Check the kernel Image and initrd

       cd /boot

       ls -lrt

3.  Backup the initrd image initrd-4.12.14-95.83-default

       mv initrd-4.12.14-95.83-default initrd-4.12.14-95.83-default_backup

4.  Create new initrd that for new kernel  83

       dracut -f /boot/initrd-4.12.14-95.83-default 4.12.14-95.83-default

5.   Verify grub.cfg that new initrd pointing to .83 kernel image

6.   If all good reboot the server with default (new kernel .83)

------------------------------------------------------------------------------------------------------
KB articles

KB0016773 - SAP-HowTo: Working a monitoring alert ticket
KB0016785 - SAP-HowTo: Working a customer submitted ticket
KB0017079 - SAP-HowTo: Working a change ticket
KB0015567 - SAP-HowTo: Writing a quality RCA
KB0010973   Nagios XI Cannot Verify NCPA/NRDP/NSClient Agent running
KB0016422   How to locate the recovery ISO for RHEL/SUSE in 3.x datacenters

KB0015567 - SAP-HowTo: Writing a quality RCA
KB0016773 - SAP-HowTo: Working a monitoring alert ticket
KB0016785 - SAP-HowTo: Working a customer submitted ticket
KB0017079 - SAP-HowTo: Working a change ticket
KB0017713 - SAP-HowTo: Working with SAP FocusedRun

------------------------------------------------------------------------------

TTA DR SSL VPN

TTA DR VPN
Please find the credentials of Tata-DR VPN.
 
Username : Kyn_RaviM
 
password: Tata@Dr$910

VPN ip 219.65.88.14

Port 4434

--------------------------------------------------------------------

Health check ssl vulnerability on Redhat
https://access.redhat.com/solutions/26833

----------------------------------------------------------------------------

chronyd time sync

check /etc/chrony.conf and look for the server name/ip
[root@sapapp31 ibmrmalik]# cat /etc/chrony.conf
# Auto-generated by Chef.
# Local modifications will be overwritten
# See https://cmschefmkt.rtp.raleigh.ibm.com/cookbooks/cms3x_cfg for details
#
server che01ammntp01.imzcloud.ibmammsap.local iburst
makestep 1.0 3
logchange 1.0
rtcsync
driftfile /var/lib/chrony/drift
logdir /var/log/chrony


if the time is not sync update the ntp url with ip as some time the dns resolution does not work.

if missing check and update
and restart chronyd.service

chronyc tracking      --command to check if the time is in sync
timedatectl

[root@dmsapmwqdb ncpa.cfg.d]# cat /var/lib/chrony/drift
          -37.348312             0.054454



to check NTP server details on windows run the below on a command prompt
w32tm /query /peers

--------------------------------------------------------------------------------

CIFS mapping issues post RHEL 6 to 7 upgrade

add sec=ntlm,vers=1.0 in the fstab entry and try to mount

------------------------------------------------------------------------------

Delayed login post upgrades
https://access.redhat.com/solutions/4685441

Feb 12 21:03:34 spsvmplmapp01 sshd[60731]: pam_sss(sshd:auth): authentication success; logname= uid=0 euid=0 tty=ssh ruser= rhost=127.0.0.1 user=ibmsgaur
Feb 12 21:03:34 spsvmplmapp01 sshd[60731]: debug1: do_pam_account: called
Feb 12 21:04:25 spsvmplmapp01 sssd[be[imzcloud.ibmammsap.local]]: Warning: user would have been denied GPO-based logon access if the ad_gpo_access_control option were set to enforcing mode.
Feb 12 21:04:25 spsvmplmapp01 sshd[60731]: debug3: PAM: do_pam_account pam_acct_mgmt = 0 (Success)


​ Resolution
    • To avoid this issue in future set following option under [domain] section of sssd.conf:
Raw
ad_gpo_access_control = disabled
    • Note: disabled - GPO-based access control rules are neither evaluated nor enforced.

--------------------------------------------------------------------------------------------------

Locations of the patching scripts and other material

https://kyndryl.ent.box.com/s/f4ce6i2pbi087lr8ar7bt9k6yimq1uko

-----------------------------------------------------------------------------------------

###########################################
REPO ERROR
http://146.89.140.24/mrepo/salt6server-x86_64/RPMS.latest/repodata/repomd.xml: [Errno 12] Timeout on http://146.89.140.24/mrepo/salt6server-x86_64/RPMS.latest/repodata/repomd.xml: (28, 'connect() timed out!')
Trying other mirror.
Error: Cannot retrieve repository metadata (repomd.xml) for repository: salt-repository. Please verify its path and try again
Solution -
cd /etc/yum.repos.d/
mv salt-repository.repo salt-repository.repo.back
yum list updates
################################################
OSCAR in RHEL

in RHEL 6
corntab

oscar service (os_check.service)

############# OSCAR Check #############
#0 * * * *  /usr/local/sap/scripts/os_check_and_fix_v1.0.py >/dev/null 2>&1
[root@penat15sl profile.d]$


remove the banner file under /etc/profile.d
IBM_OS_Check.sh


whereas in SUSE it is configured as a service 
systemctl status os_check.service

stopping and disabling the service and removing the banner from /etc/profile.d/

###########################################################

OSCAR deployments - Known issue with ftp/sftp connections (KB0016944)

This message was sent with High importance.
This message was sent with High importance.
Neil Langford
Thu 2/24/2022 9:52 PM
Team,

An issue has been identified regarding ftp/sftp connections to SAP servers where the OSCAR tool is deployed.
The issue presents itself typically with an error indicating that the maximum packet size has been reached.

If you experience this issue, follow the steps in the above referenced KB article to resolve the issue.

Thank you,
Neil

--------------------------------------------------------------------------------
Disable Nagios monitoring for services that are not relevant
sbd and iscsid service stopped in non hana cluster

plz perform below steps on both nodes of the cluster ->
cd /usr/local/ncpa/etc/ncpa.cfg.d/
update file suse-pacemaker.cfg to remove the below 2 lines->
%HOSTNAME%|__SUSE__Service__CRITICAL__iscsid.service__ = /plugins/cmas_check_svc.sh/iscsid.service
%HOSTNAME%|__SUSE__Service__CRITICAL__sbd.service__ = /plugins/cmas_check_svc.sh/sbd.service
execute the command-> systemctl restart ncpa_passive
------------------------------------------------------------------------------------------------------
Precheck script kept in downloads

./3xPrecheck_v2.sh ip.txt >> <filename>.txt

Ravi:Prechecks$ cat ip.txt 
10.138.10.84
10.138.10.71
10.138.10.65
10.138.10.69

-----------------------------------------------------------------------------------------------------------

Available Kernel 
sudo /usr/bin/zypper list-updates | grep "kernel-default"|awk '\''{print $1 "\t" $3 "\t" $5 "\t" $7 "\t" $9 "\t" $11}'\''|column -t

To grep multiple keywords with or
mount | egrep "nfs|nfs4|cifs" | egrep -v "sunrpc|nfsd"|awk '\''{print $3}'\''`
-------------------------------------------------------------------------------------------------------
increase font in terminal

Ctril+Shift and then press + key to increase font size

------------------------------------------------------------------------------------------------------------

For weekend changes, if extension required , Once you have an approval for change extension (documented in change) please fill out change extension template and post in the #change-support slack channel. Go ahead to complete the change within the extended window.

 

Change Support team does not provide weekend coverage.  Once the Change support team login in on weekday they will check and update Amended end date for those changes.

 

WINDOW EXTENSION TEMPLATE

•    Change:  <#>             

•    Summary: <change abstract>

•    Offering: <SAP, Oracle, Core>

•    Environment (Site/Location) and Client’s unique code:

•    Current "Scheduled End" Date/Time: <mm/dd/yyyy hh:mm ET (US Eastern Time)>

•    Requested "Scheduled End" Date/Time: <mm/dd/yyyy hh:mm ET (US Eastern Time)>

•    Reason for extending the window:  <Detailed reason for the delay>

•    Will the extension include Disruptive or Non-Disruptive activity?  <Disruptive / Non-Disruptive / Both>

•    If Disruptive/Both, then list impact and duration: <e.g., Splash page “X” hours, Degraded Service/Availability, Process Channels for [Site] for “Y” hours, etc.>

•    If Non-Disruptive, what activity is delayed: <e.g., Verification, etc.>

 

Please Note- If the change is extended multiple time, when closing the change it must be closed as unsuccessful - with multiple extension

---------------------------------------------------------------------------------------------------------------------------

CHG0234449 - SAP solution barematel server are under decom     DAL09AMMSOL01	146.89.140.30	146.89.140.30

---------------------------------------------------------------------------------------------------------------------------

MediAssist
https://portal.medibuddy.in/Home.aspx
014782@persistent  03021981

https://www.medibuddy.in/networkHospitals

----------------------------------------------------------------------------------------------------------
cd /etc/profile.d
mv IBM_OS_Check.sh IBM_OS_Check.sh_bkp

-------------------------------------------------------------------------------------------------------

/TRM in any kyndryl slack to involve trm

--------------------------------------------------------------------------------------------------

Change approval

/compliancechecker

Plan
- Execute per server KB SOPs based on OS
KB0014307: Suse LINUX OS Patching using zypper update in 3.x environment

KB0013493: RedHat LINUX OS Patching using YUM update in 3.x environment

----------------------------------------------------------------------------------------------------

The purpose is to delete files older than 5 days on the folder

Server : SAP Production S4P (grps4pap01)
Cron job script : /usr/bin/delete_old_files.sh

Add following Subdirectories:
/INTERFACE/S4P/OUT/POWERBI/MATDOC
/INTERFACE/S4P/OUT/POWERBI/ACCDOC 

FYI, below script content of /usr/bin/delete_old_files.sh . Please add lines for directory /INTERFACE/S4P/OUT/POWERBI/MATDOC & /INTERFACE/S4P/OUT/POWERBI/ACCDOC 

[1]cat  /usr/bin/delete_old_files.sh
#!bin/sh
find /INTERFACE/S4P/OUT/POWERBI/CUSTOMER -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/DELIVERY -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/DEMAND -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/OPERATION -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/PR -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/PRODUCTION -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/PURCHDOC -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/RESERVATION -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/SALESDOC -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/SLOC -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/SO_SCHEDULE -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/STOCK -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/VC -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/VENDOR -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/EXCRATE -type f -name '*.TXT' -mtime +5 -exec rm {} +
find /INTERFACE/S4P/OUT/POWERBI/BON_ORDER -type f -name '*.TXT' -mtime +5 -exec rm {} +

---------------------------------------------------------------------------------------------------------------
Non-HANA cluster validation script running steps

Run the AMM Non-HANA pacemaker validation script:
    • Run this command on BOTH NODES to copy the .tar file from NIM to local:
#cp /sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/pacemaker_validation-2.12.tar /tmp;tar -C /tmp -xvf /tmp/pacemaker_validation-2.12.tar; 
    • Go to the temporally folder on each node:
#cd /tmp/pacemaker_validation/
    • Run the NonHana pacemaker validation from one node (The script will login to each node and do the checks):
#python run_pacemaker_validation.py
    • Once finish remove the temporally folder from the tmp:
#rm -Rf /tmp/pacemaker_validation; rm -f /tmp/pacemaker_validation-2.12.tar;


/home/Ravi/Downloads/SOP Pacemaker Health Check Remediations-V2-6 (1).docx


Pacemaker Health check scripts

HANA validation Scripts
    • Login at OS level on NodeA with IMZ cloud user
    • Login at OS level on NodeB with IMZ cloud user
    • Run the AMM HANA pacemaker validation script on each node:
    • Relative path:
# cd /opt/ibm/HDBHA/Operations/hanaconfigvalidation
# ./HDBHA_HanaPostBuildValidation.sh
# Select option:
               1. Hana cluster configuration and os validation
               

-----------------------------------------------------------------------------------------------------------------

Canada Microsoft CSP access information

Username: ravi.malik@kynmpncacsp.onmicrosoft.com

password: Mar2022&May2022

-------------------------------------------------------------------------------------------------

non HANA ABAP or JAVA cluster if not starting resources check if nfs service is up else start it and enable it to start automatically

systemctl start nfs
systemctl enable nfs

refer 
https://github.kyndryl.net/CMS/SAP-Base-RR/tree/master/1.%20IBM%20Cloud/Pacemaker/Primitives   for anything thats not in validation script but is an issue

https://github.kyndryl.net/CMS/SAP-Base-RR/tree/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4

one node rebooting frequently
location loc_sap_B1U_failover_to_ers rsc_sap_B1U_ASCS00 \
        rule 2000: runs_ers_B1U eq 1
        
colocation app-deps 100: ms-drbd-scs:Master g-scs    line missing fom config


on node:
order rsc_fs_then_export_then_mount Optional: g-global clone-crossmnt symmetrical=false
Expected value:(eg,)
order rsc_fs_then_export_then_mount Optional: g-global clone-crossmnt rsc_sap_B1U_ASCS00:start rsc_sap_B1U_ERS10:stop symmetrical=false



these lines modified

order rsc_fs_then_export_then_mount Optional: g-global clone-crossmnt rsc_sap_TP1_ASCS01:start rsc_sap_TP1_ERS03:stop symmetrical=false
group g-ers ip-b1u-ers vol_b1uersvg fs-ers_lv rsc_sap_TP1_ERS03
group g-scs ip-b1u-ascs vol_b1uascsvg fs-ascs_lv rsc_sap_TP1_ASCS01
This line added
location loc_sap_TP1_failover_to_ers rsc_sap_TP1_ASCS01 \
        rule 2000: rsc_sap_TP1_ERS03 eq 1


and to fix DRBD I will run below commands
On secondary DRBD node:
drbdadm  disconnect r0; drbdadm secondary r0; drbdadm connect r0 --discard-my-data;
on Primary node:
drbdadm  disconnect r0; drbdadm primary r0; drbdadm connect r0;

above command to fix DRBD disk r0
we have to replace r0 by r1 to fix r1 resource

------------------------------------------------------------------------------------------------------------------------------

KB0013493 : RedHat LINUX OS Patching using YUM update in 3.x environment
KB0014307 : SUSE LINUX OS Patching using zypper update in 3.x environment
KB0017634 - SUSE LINUX OS Patching on Clusters - Full Downtime
KB0017635 - SUSE LINUX OS Patching on Clusters - Near Zero Downtime


------------------------------------------------------------------------------------------------------------------
to extend a filesystem in a non-hana cluster.

https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/SOPs/Filesystem_extension_steps.md

There are 3 possible scenarios:

     - Extend Filesystem where VG has free space
     - Expand existing disk for filesystem extend 
     - Add New disk for Filesystem extend


--------------------------------------------------------------------------------------------------------------------
YUm clean all frees up var FS but it fills up again
https://www.thegeekdiary.com/var-cache-yum-constantly-filling-files-system-in-centos-rhel/

--------------------------------------------------------------------------------------------------------------------

HANA patching

when you are working on patching the Hana servers, please collect details below which is very important to find the root cause of this issue, so that we can get a solution from SUSE to avoid this in future.

 

OS Engineer assigned to the change will have to perform this steps before the change. Added as part of Pre-check CTASK in change.

1. Collect limited supportconfig before patching - #supportconfig -i BOOT (we can do it before change window to save time)

2. Copy the most recent initrd, vmlinuz and grub.cfg files to somewhere else

#supportconfig -i BOOT

#cp /boot/initrd-4.12.14-95.93-default /root/initrd-4.12.14-95.93-default-before-update

#cp /boot/vmlinuz-4.12.14-95.93-default /root/vmlinuz-4.12.14-95.93-default-before-update

#cp /boot/grub2/grub.cfg /root/grub.cfg-before-update

 

OS Engineer assigned to the change perform this steps after patching before reboot. Added as part of OS Patching CTASK in change. 

3. Collect second supportconfig after patching but before reboot - #supportconfig -i BOOT

4. Copy the most recent initrd file to somewhere else (here, it should be the one installed recently)

#supportconfig -i BOOT

#cp /boot/initrd-4.12.14-95.93-default /root/initrd-4.12.14-95.93-default-after-update

#cp /boot/vmlinuz-4.12.14-95.93-default /root/vmlinuz-4.12.14-95.93-default-after-update

#cp /boot/grub2/grub.cfg /root/grub.cfg-after-update

 

 

**** Fix the boot issue here (either by booting into previous kernel, or recreate initrd from rescue mode) ****

 

5. Collect third supportconfig after fixing the issue and the server booted normally with latest kernel version - #supportconfig -i BOOT

6. Copy the most recent initrd file to somewhere else

#supportconfig -i BOOT

#cp /boot/initrd-4.12.14-95.93-default /root/initrd-4.12.14-95.93-default-after-fixed

#cp /boot/vmlinuz-4.12.14-95.93-default /root/vmlinuz-4.12.14-95.93-default-after-fixed

#cp /boot/grub2/grub.cfg /root/grub.cfg-after-fixed

 

This supportconfig with BOOT option takes about 2 to 3 minutes

 

Make sure to use the meaningful file names to differentiate when those were collected.

 

And, open a new SUSE case and upload all the files and refer the previous SUSE case number 00339754 where these details are requested.

------------------------------------------------------------------------------------------------------------------------
Exclude monitoring of Nagios
DIsable pacemaker monitoring from Nagios config file
Swati Biswas

/usr/local/ncpa/etc/   

base processes.cfg

comment the service


plz perform below steps on both nodes of the cluster ->
cd /usr/local/ncpa/etc/ncpa.cfg.d/
update file suse-pacemaker.cfg to remove the below 2 lines->
%HOSTNAME%|__SUSE__Service__CRITICAL__iscsid.service__ = /plugins/cmas_check_svc.sh/iscsid.service
%HOSTNAME%|__SUSE__Service__CRITICAL__sbd.service__ = /plugins/cmas_check_svc.sh/sbd.service
execute the command-> systemctl restart ncpa_passive


REMOVE SendMail Monitoring for a SERVER.
#############################################
cd /usr/local/ncpa/etc/
cat /usr/local/ncpa/etc/base_processes.cmas
[root@tdpdcs4dapp1 etc]# cat base_processes.cmas |grep -i sendmail
* sendmail
[root@tdpdcs4dapp1 etc]#
Remove Senmail entry from file base_processes.cmas
--------------------------------------------------
cd ncpa.cfg.d/
[root@tdpdcs4dapp1 ibmsgaur]# cat /usr/local/ncpa/etc/ncpa.cfg.d/processes.cfg | grep sendmail
%HOSTNAME%|__SUSE__Service__CRITICAL__sendmail__ = /plugins/cmas_check_process.sh/sendmail
Remove sendmail entry from processes.cfg 
-------------------------------------------
Remove send mail entry from base_processes.cmas and processes.cfg files and save it. Restart nagios agent.
vi /usr/local/ncpa/etc/base_processes.cmas
vi /usr/local/ncpa/etc/ncpa.cfg.d/processes.cfg
systemctl restart ncpa_passive.service
systemctl restart ncpa_listener.service


/usr/local/ncpa/etc/ncpa.cfg.d
############################################################################################


-------------------------------------------------------------------------------------------------------------------

Error: ti3s4pdb01 smbd[1459197]:  read_fd_with_timeout failed for client 0.0.0.0 read error = NT_STATUS_CONNECTION_RESET.

https://github.kyndryl.net/CMS/cms-opaas-api/issues/20453
Short Description :  Log Syslog-DStorage Found 2 errors
Issue :  Every Saturday, we are getting this kind of alerts whenever Nagios sees this error "NT_STATUS_CONNECTION_RESET" These errors are related to "smb-IMZCLOUD.service" (service configured as part of the AD join to imzcloud)
Action Taken : Since from 45days, We have been working with multiple teams/vendor (REDHAT/Ansible) to know the root cause of error message. But still we are working towards fixing the issue.
Work around : As a work around, Got suggestion from Nagios team/Ansible teams that we can exclude this error (since no impact due to this error) in Nagios filter to avoid the alerts which we can save lot of manual efforts. Last week, we followed the steps which are attached in thread and this week we have monitored and found that no alerts have been generated.
[11:37 AM] Path ---  /usr/local/ncpa/etc/checklog_filters.d
File ---  Syslog-DStorage.filt
Add the Entry --- -:0:*:NT_STATUS_CONNECTION_RESET

Restart the Nagios agents :

systemctl status ncpa_listener; systemctl status ncpa_passive
systemctl restart ncpa_listener; systemctl restart ncpa_passive
systemctl status ncpa_listener; systemctl status ncpa_passive


Expected Result:

[root@GSTTWSTLCKP01 ~]# grep -i NT_STATUS_CONNECTION_RESET /usr/local/ncpa/etc/checklog_filters.d/Syslog-DStorage.filt
-:0:*:NT_STATUS_CONNECTION_RESET

---------------------------------------------------------------------------------------------------------------------------

TTA-TATA-Steel-Limited-SAP-Handling_PO-Pingcheck-alerts_AND_Chennai-Scripts-Alert

https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0016458

ping to ip 176.0.5.58

------------------------------------------------------------------------------------------

###########################################
ERROR - [root@qlaqt1s4haap ibmsgaur]# passwd in003cn2
passwd: User not known to the underlying authentication module
passwd: password unchanged
-----------------------
cat /etc/pam.d/common-password
Solution Replace required word to sufficient.
password   requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password   required pam_pwhistory.so remember=8
password   optional pam_gnome_keyring.so use_authtok
#password   required pam_unix.so use_authtok nullok shadow try_first_pass sha512                        ##replace required with sufficent
password   sufficient pam_unix.so use_authtok nullok shadow try_first_pass sha512
password   required pam_sss.so use_authtok
[root@qlaqt1s4haap ibmsgaur]#
##############################################

Kyndry helpdesk

+91-80-4177-4888 (Toll)

+91-20-4011-5888 (Toll)

1-800-120-596-379 (Toll Free)

kyndryl.hdsk@kyndryl.com - helpdesk related

Monday - Friday 24 hours
Weekend support is available for severity 1 and outages only

-----------------------------------------------------------------------------------------------
1. Delete Files older Than 30 Days
First of all, list all files older than 30 days under /opt/backup directory.

find /opt/backup -type f -mtime +30 

Verify the file list and make sure no useful file is listed in above command. Once confirmed, you are good to go to delete those files with following command.

find /opt/backup -type f -mtime +30 -delete


2. Delete Files with Specific Extension
For the safe side, first do a dry run and list files matching the criteria.

find /var/log -name "*.log" -type f -mtime +30

Once the list is verified, delete those file by running the following command:

find /var/log -name "*.log" -type f -mtime +30 -delete 


3. Delete Old Directory Recursively

The below command will search all directories modified before 90 days under the /var/log directory.

find /var/log -type d -mtime +90

Here we can execute the rm command using -exec command line option. Find command output will be send to rm command as input.

find /var/log -type d -mtime +30 -exec rm -rf {} \;

---------------------------------------------------------------------------------------------------

SFTP user access to particular directory 

https://fedingo.com/how-to-restrict-sftp-users-to-specific-directory-in-linux/

https://www.techrepublic.com/article/how-to-restrict-server-users-to-a-specific-directory-in-linux/


Run the ‘setfacl’ command with below format to set ACL on the given file. In the below example we are going to give a rwx access to ‘magi’ user to the ‘/etc/apache2/apache2.conf’ file:

# setfacl -m u:magi:rwx /etc/apache2/apache2.conf
Details :

setfacl: Command
-m: modify the current ACL(s) of file(s)
u: Indicates a user
magi: Name of the user
rwx: Permissions which you want to set
/etc/apache2/apache2.conf: Name of the file


to check

getfacl /etc/apache2/apache2.conf

ACL permission set
https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/ch-access_control_lists
---------------------------------------------------------------------------------------------------------------------------------

datastore extension request is given via git ticket

https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/issues/7467

--------------------------------------------------------------------------------------------------------------
OPAAS url for adding disk, cpu mem modify

https://opaasui.managedapps.ibm.com/opaas-ui/welcome_parse.jsp

----------------------------------------------------------------------------------------------------------------
Password less authentication between servers

To setup ssh keys (I use rsa in this example) for this, the command to run as user root is:

    ssh-keygen -t rsa


which will create the following two keys in the /root/.ssh/ directory:

    id_rsa
    id_rsa.pub

 
The public key has to be copied over to another node :

    scp /root/.ssh/id_rsa.pub root@MY_OTHER_SERVER:/tmp/


and on this other server added to the authorized keys:

    cat /tmp/id_rsa.pub >> /root/.ssh/authorized_keys


After this it is possible for root to ssh without password from one server to the other. This should be done for each and every member server of the cluster.

-----------------------------------------------------------------------------------------------------------------------

Identify the app cluster
ASCS-ABAP
SCS-Java

primitive changes to order and group on all app servers in SP4

# Order Constrain for Group and primitives.        
order all_order_crossmnt Mandatory: g-global:start clone-crossmnt symmetrical=false
order all_order_drbd Optional: ms-drbd-scs:promote ms-drbd-ers:promote symmetrical=false
order all_order_drbd_app ms-drbd-scs:promote g-scs:start symmetrical=true
order all_order_drbd_ers ms-drbd-ers:promote g-ers:start symmetrical=true
order all_order_drbd_global ms-drbd-global:promote g-global:start symmetrical=true
order rsc_fs_then_export_then_mount Optional: g-global clone-crossmnt rsc_sap_EPJ_SCS11:start rsc_sap_EPJ_ERS12:stop symmetrical=false

# Colocation constrain for Groups
colocation app-deps 100: ms-drbd-scs:Master g-scs
colocation col_sap_rpa_no_both -5000: g-ers g-scs
colocation ers-deps 50: ms-drbd-ers:Master g-ers
colocation global-deps inf: ms-drbd-global:Master g-global

# Location constrain for SAP Application.
location loc_sap_EPJ_failover_to_ers rsc_sap_EPJ_SCS11 \
        rule 2000: runs_ers_EPJ eq 1



-----------------------------------------------------------------------------------------------------------------------------------------------

KB0016773 - SAP-HowTo: Working a monitoring alert ticket
KB0016785 - SAP-HowTo: Working a customer submitted ticket
KB0017079 - SAP-HowTo: Working a change ticket
KB0015567 - SAP-HowTo: Writing a quality RCA
KB0017713 - SAP-HowTo: Working with SAP FocusedRun
KB0012534 - SAP-HowTo: Change Management Process (SNOW)
KB0015500 - SAP-Linux: SuSE Linux Kdump configuration
KB0016905 - SLES 12SP2 to SLES15SP2 migration



KB0017578 SAP-Automation: SAMU-UEL Patch OS – Full Workflow
Perform manual patching as per KBs:
KB0013493 RedHat LINUX OS Patching using YUM update in 3.x environment
KB0014307 : SUSE LINUX OS Patching using zypper update in 3.x environment PROCEDURE FOR CLUSTERS:
KB0017634 - SUSE LINUX OS Patching on Clusters - Full Downtime 
KB0017635 - SUSE LINUX OS Patching on Clusters - Near Zero Downtime

The list of KB articles from the "SAP Managed Services" repository is as follows:

KB0017919 SAP-AIX: How to adjust the number of CPUs on a server using opaas portal | AIX
KB0012258 SAP-AIX: Simple AIX Filesystem Extension

KB0015216 SAP-ASE: Manage /sybase/<SID>/log_archive space issue
KB0015624 SAP-ASE: Using the Sybase command line interface (CLI) for database interactions

KB0017519 SAP-Automation:  Collect All Support Logs
KB0016944 SAP-Automation:  Operational System Checks and Self Repair (OSCAR)
KB0017226 SAP-Automation:  Pacemaker Cluster Steps from SAM-UEL
KB0017225 SAP-Automation:  Pre & Post Checks & Snaps from SAM-UEL
KB0017578 SAP-Automation:  SAMU-UEL Patch OS – Full Workflow
KB0015111 SAP-Automation:  SAP System Check
KB0016790 SAP-Automation:  Self-Healing with SAM-SIP
KB0012488 SAP-Automation: Automated SAP ABAP Parameter Update
KB0014076 SAP-Automation: Automated SAP Hostagent UPGRADE for Windows
KB0014069 SAP-Automation: Automated SAP Kernel UPGRADE for Windows
KB0017670 SAP-Automation: Creating a Pervasive Issue
KB0016825 SAP-Automation: SAMSIP Manage TSM Backup User
KB0014476 SAP-Automation: SAP Autovalidation  
KB0017674 SAP-Automation: SAP Start/Stop using Samuel
KB0017448 SAP-Automation: Working Pervasive Issues

KB0017702 Deploy / Undeploy XPI Inspector to collect traces for PI/PO Java environments in Linux

KB0018005 SAP Basis - Customer-WUR: Vertex updates
KB0017085 SAP Basis: Applying sap license through SAP GUI
KB0017057 SAP-Basis:  Graceful Shut Down and Start Up Procedures for ABAP Application Servers
KB0012345 SAP-Basis: Administration & Tools in Convergent Charging Systems
KB0016610 SAP-Basis: Basic Linux and AIX commands
KB0013515 SAP-Basis: Managing the IBM saprouter software
KB0014716 SAP-Basis: Patching the SAP kernel Unix
KB0016929 SAP-Basis: Remote client copy
KB0015539 SAP-Basis: SAP JAVA PI/PO/AEX Troubleshooting
KB0017467 SAP-Basis: SAP server software and configuration files
KB0015724 SAP-Basis: SAPDBA jobs not running correctly
KB0012487 SAP-Basis: Validating a SAP system
KB0016700 SAP-Java SUM generating a system component information XML

KB0016990 Solution for UME related issue in SAP java system --SAP-Basis: Java startup issue

KB0017986 SAP-Compliance:  AZURE Advisor Security Remediation
KB0017844 SAP-Compliance:  Managed Applications – SAP Remediation Processes

KB0013628 SAP-DB2: Database backup to TSM
KB0013576 SAP-DB2: Database procedures for SAP System refresh
KB0016961 SAP-DB2: DB2 Reorgs

KB0015683 SAP-EWA: Database - Maintenance Phases
KB0015685 SAP-EWA: Database Parameters for <DBSID>
KB0015682 SAP-EWA: SAP Application Release - Maintenance Phases
KB0015646 SAP-EWA: SAP HANA database: Support Package has run out of security maintenance
KB0015642 SAP-EWA: SAP HANA database: User SYSTEM is active and valid
KB0015643 SAP-EWA: SAP HANA network settings for System Replication is insecure
KB0015644 SAP-EWA: SAP HANA: Installed DBSL Version
KB0015684 SAP-EWA: SAP Kernel Release

KB0017210 SAP-FRUN:  Alert HDB_DATABASE_AVAILABILITY
KB0017212 SAP-FRUN:  FocusRun ABAP_INSTANCE_AVAILABILITY
KB0017254 SAP-FRUN:  FocusRun ABAP_SYSTEM_AVAILABILITY
KB0017253 SAP-FRUN:  KB FocusRun ABAP_INSTANCE_AVAILABILITY
KB0015528 SAP-FRUN: Alert ASE_SPACE_MANAGEMENT

KB0016123 SAP-HANA :Deactivating SYSTEM User
KB0014869 SAP-HANA:  No hdbuserstore entry found - Error : hdbconnectivity
KB0016296 SAP-HANA: DB Backup
KB0016298 SAP-HANA: DB Restore
KB0014520 SAP-HANA: Manage /sapmnt/log file system full

KB0016124 SAP-How-To: Create a Knowledge Base Article for SAP Stop and Start Procedure
KB0017534 SAP-HowTo: Creating an upgrade cost estimate
KB0015645 SAP-HowTo: Remediating Earlywatch Alert report alerts
KB0017079 SAP-HowTo: Working a change ticket
KB0016785 SAP-HowTo: Working a customer submitted ticket
KB0017080 SAP-HowTo: Working a customer submitted ticket
KB0016773 SAP-HowTo: Working a monitoring alert ticket
KB0017713 SAP-HowTo: Working with SAP FocusedRun
KB0015567 SAP-HowTo: Writing a quality RCA

KB0014307 SAP- LINUX: OS Patching using zypper  update in 3.x environment
KB0017607 SAP-Linux:  How to Expand the NFS Storage File system share from Softlayer
KB0017679 SAP-Linux:  Removing an Unused Disk from Linux Server
KB0017634 SAP-Linux:  SUSE LINUX OS Patching on Clusters - Full Downtime
KB0017635 SAP-Linux:  SUSE LINUX OS Patching on Clusters - Near Zero Downtime
KB0017466 SAP-Linux: Disk Utilization /sapmnt/log
KB0015500 SAP-Linux: SuSE Linux Kdump configuration

KB0012476 SAP-Oracle:  SAP ABAP Database User Unlock & Change Password
KB0017014 SAP-Oracle: Tablespace Fragmentation

KB0012418 SAP-Process:  SAP-Quarterly OS Patching Process
KB0012311 SAP-Process: Migrate & Create Service Now Knowledge Base Documents

KB0015287 SAP-Windows:  3x - Windows Patching Procedure
KB0017689 SAP-Windows:  In-Place Upgrade From  Windows Server 2012 R2 /2016 to Windows  Server 2019
KB0016305 SAP-Windows:  Vmware_Healthcheck script 2.0
KB0015373 SAP-Windows:  Windows Patching Procedures
KB0014171 SAP-Windows: Upgrading Symantec Endpoint




When Patching HANA servers;
- Collect second supportconfig after patching but before reboot - #supportconfig -i BOOT
-Copy the most recent initrd file to somewhere else (here, it should be the one installed recently)
#supportconfig -i BOOT
#cp /boot/initrd-4.12.14-95.93-default /root/initrd-4.12.14-95.93-default-after-update
#cp /boot/vmlinuz-4.12.14-95.93-default /root/vmlinuz-4.12.14-95.93-default-after-update
#cp /boot/grub2/grub.cfg /root/grub.cfg-after-update"

-----------------------------------------------------------------------------------------------------------


Roland Rebstock  manage repos

---------------------------------------------------------------------------

2FA setup
https://mysignins.microsoft.com/security-info

--------------------------------------------------------------------------------------------------
How to Restrict SFTP Users to Specific Directory in Linux

https://fedingo.com/how-to-restrict-sftp-users-to-specific-directory-in-linux/

-----------------------------------------------------------------------------------------------------

Nagios
Nagios is the monitoring tool used for monitoring of the operating system and is also used for some SAP application and database monitoring where such functionality does not exist in SAP FocusedRun.  The tool can be accessed using the following URL:
https://146.89.173.200/NagiosPortal/src.do

Notes:
To request an account for the Nagios Portal, submit a request to the Nagios team using the following:
Account – IBM Internal – CCP
Contract - CCP MHAS Infra Nagios
Assignment group – MA-ASGN-INF-NAGIOS-MON
Owner group – MA-ASGN-INF-NAGIOS-MON
---------------------------------------------------------------------------------------------------------------

Colocation monitoring ticket Pacemaker Colocation CRITICAL: Colocation Failure
refer https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/15_ClusterColocationChanges.md and verify the order and colocation sequence in the crm configure show and correct the same

Correct order
colocation col_saphana_ip_HHA_HDB00 inf: rsc_ip_HHA_HDB00:Started rsc_TSMTDP_HHA_HDB00:Started msl_SAPHana_HHA_HDB00:Master
order ord_SAPHana_HHA_HDB00 Optional: cln_SAPHanaTopology_HHA_HDB00 msl_SAPHana_HHA_HDB00

SLE HAE change of the TSM resource primitive to enable dsmcad_hana monitoring on the secondary node.
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/17_TSMResourceChanges.md


check the correct template also


Wrong will give such optsls4proddb:/usr/local/ncpa/plugins # ./ibm_check_pacemaker_colocation.sh
CRITICAL: Colocation Failure -  Master/Slave Set: msl_SAPHana_PRD_HDB00 [rsc_SAPHana_PRD_HDB00] - rsc_ip on tsls4proddbh, rsc_tsmtdp on tsls4proddbh

the correct should give like this
tsls4proddb:/usr/local/ncpa/plugins # ./ibm_check_pacemaker_colocation.sh
OK: This node is not master.  No checks performed.

cp /sds/sap/MSD_Software/SAP_Automation/HDBHA/Deployment/baremetal/monitoring/plugins/ibm_check_pacemaker_colocation.sh /usr/local/ncpa/plugins/

online process not disturbing the cluster

-------------------------------------------------------------------------------------------------------------------

Delay in login and sudo even with local user intermitantly

Please make a backup of /etc/pam.d/common-session
And then in that file, change the pam_unix.so entry from "required" to "sufficient".
We're changing this line: session required        pam_unix.so     try_first_pass  to this: session sufficient        pam_unix.so     try_first_pass  Let me know if that resolves the issue for local users.

ssh using time command , it took 13 minutes to log into ! 

$ time ssh ibmmmontero@10.139.8.16
Password: 
Last login: Fri May  6 14:43:27 2022 from 146.89.140.60
*    Server Type: Production                                                  *
*       Hostname: ogypxp021                                                   *
*         CFN IP: 10.25.8.26                                                  *
*         IFN IP: 10.139.8.16                                                 *
*        SAP SID: PXP                                                         *
*******************************************************************************
[ibmmmontero@ogypxp021 ~]$ logout
Connection to 10.139.8.16 closed.

real 13m22.068s
user 0m0.048s
sys 0m0.026s


Let’s try the following.

1. Edit /etc/ssh/sshd_config
There should be an entry for LogLevel.  By default it is commented out.  Uncomment it and change “INFO” to “DEBUG” like this:

LogLevel DEBUG
# systemctl restart sshd.service

2. Disable the chef-client just for reproducing the problem if possible.
# systemctl stop chef-client

3. Set debug_level = 9 in the /etc/sssd/sssd.conf (nss section, pam section, and domain/ section)

4. Restart sssd and clear caches
# systemctl stop sssd; rm -f /var/lib/sss/db/* ; systemctl start sssd;

5. Run the “date” command prior to replication.

6. Replicate issue one time with a local user or an AD user.  Let us know the user name.

7. Run the “date” command just after replication.

8. Generate supportconfig with the pam.txt file
# FORCE_OPTION_PAM=1 supportconfig -ur 00346364

9. Tarball /var/log/sssd/ logs
# tar zcvf /tmp/sssd-logs.tgz /var/log/sssd/*.log

10.Provide output from steps 3-5 and files from steps 6-7
 

If this happens with both local users and AD users, if possible, it would be very nice to have the above information repeated with step number 6 being the opposite.  In other words, one set with a local user failing, and another with an AD user failing.


Does this ever happen with the root user?  Or for that matter, does it happen for any users that are listed in the sssd filter_users?  Here is the entry for groups and users:


filter_groups = root

filter_users = ansible, at, bin, chrony, custsap, daaadm, daemon, ftp, ftpsecure, games, gdm, ibmdrarath, ibmdrhayson, ibmdrngranados, lp, mail, man, messagebus, news, nobody, nscd, ntp, openslp, orapxp, polkitd, postfix, pulse, pxpadm, root, rpc, rtkit, salt, sapadm, saprouter, scard, smdadm, srvGeoClue, sshd, statd, systemd-bus-proxy, systemd-timesync, timagent, uucp, uuidd, vnc, wwwrun

 
If the problem happens with any of these users then the authentication should not be trying to go to AD.  However, with the above instructions we will see it in the logs.

---------------------------------------------------------------------------------------------------------------------------------------------------------

cron to change permission and ownership in any folder for any incoming file

*/1 * * * * /bin/chown -R bc0adm:sapsys /usr/sap/CP0/cpids_admin/DataServicesAgent/file-exchange
*/1 * * * * /bin/chmod 775 /usr/sap/CP0/cpids_admin/DataServicesAgent/file-exchange/*

---------------------------------------------------------------------------------------------------------------------------------------

New user onboarding link

https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/Access

AWS and Azure ref ticket to IAM  CS11262041 created on 8th Jun

CMS IAM Wiki

https://kyndryl.sharepoint.com/sites/managedapps-iam
SEI IAM Wiki
https://kyndryl.sharepoint.com/sites/sei-iam
SEI - RSA
https://kyndryl.sharepoint.com/sites/sei-iam/SitePages/2fa-rsa.aspx



----------------------------------------------------------------------------------------------------------------------------------

https://w3.ibm.com/ocean/w3publisher/managed_apps_os_support_wiki/education/pacemaker/04-pacemaker-hana

------------------------------------------------------------------------------------------------------

Azure Snapshot

https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/Azure-snapshots

----------------------------------------------------------------------------------------------

nmon config

https://github.kyndryl.net/CMS/BuildMigration/wiki/Nmon-Tool

nmon report location 
Report location : /var/log/nmon/<hostname>*.nmon
-----------------------------------------------------------------------------------------------------

Before rebooting a hung VM



For VMware VMs:

When a VM is in hung state, go to Actions -> Power -> click Suspend -- wait for the task to complete. Once the task is completed, the .vmss file will be generated under the same datastore where VM is located. Copy the .vmss file to different datastore (this is the fastest way, if we download the file from DS, it will take more time and cause an extended outage). Once copy completed, reboot the VM as usual.

Then, download the .vmss file and upload to SUSE case.


For Azure VMs:

When a Azure VM is hung, we have an option to collect the coredump from the Azure portal itself.
Do not reboot the VM, instead go to "Serial console" from left pane and select the "Send command" option at the top, and select "Send Non-Maskable Interrupt (NMI)" option.
This procedure will mount the root disk under temporary mount /mnt, then the dump triggered and will be stored under /mnt/var/crash. Once completed, it will reboot the server automatically.
Once the server is up, we can then download the coredump from /var/crash and attach it to the SUSE vendor case for root cause analysis

Example: There is a server for HRM client having frequent OS hung issue, yesterday i have performed above procedure on the server, and able to find the root cause successfully using this coredump - SUSE case 00348213
 

For Physical server:

When the server is hung, do not reboot the server, instead go to IMM console -> Power Actions -> and select ‘Restart the Server with Non-maskable Interrupt (NMI)’ - This will generate coredump collection and reboot the server. Then upload the coredump from /var/crash to SUSE case to find root cause. 
-------------------------------------------------------------------------------------------------------------------------

Unable to see crontab

Question: I've received a new server and logon, trying to use Crontab but getting this error message:

You (your_logon) are not allowed to use this program (crontab)
See crontab(1) for more information

How can I fix?

 

Answer: It looks like you are experiencing a situation where only root can use crontab - but other logon accounts require some extra steps.

On Linux there are two files which control the access to crontab:

/etc/cron.allow

/etc/cron.deny

You will need to add the logon account to the /etc/cron.allow file. The way to add the logon account is to --su  to root and then :

echo jack > /etc/cron.allow

---------------------------------------------------------------------------------------------------------------------------------------
Top 10 CPU consuming processes

# ps axwwo %cpu,pid,user,cmd | sort -k 1 -r -n | head -11 | sed -e '/^%/d'

----------------------------------------------------------------------------------------------------------------------
Cluster DR script location to be run on the primary node of cluster 
3.x DR test script

https://github.kyndryl.net/CMS/BuildMigration/blob/master/3.x-Cluster-dr/README.md

The script is found in "/sds/sap/MSD_Software/SAP_Automation/Non-Hana/DR/3.x-Cluster-dr/.
In that step, you will run the 
[root@tgcs4hpapp-Production 3.x-Cluster-dr]$ ./gen_dr_config.py
DR Configuration File Path : /etc/dr.json
Script Path : /usr/local/bin/enable_dr_3.x.py
Enabled DR config Scheduler


Need to execute gen_dr_config.py on Primary Node
# ./gen_dr_config.py
DR Configuration File Path : /etc/dr.json
Script Path : /usr/local/bin/enable_dr_3.x.py     to be run in DR test server when the SRM is on



Enable DR should not be run on the prod server.


Location of the Script: /usr/local/bin/enable_dr_3.x.py
KB Article: https://github.kyndryl.net/CMS/BuildMigration/blob/master/3.x-Cluster-dr/README.md
---------------------------------------------------------------------------------------------------------------------------------
Below are the bastion hosts (or jump servers), we can connect using our imz credentials.
Bastion hosts
fmsapbas001|  169.60.136.184 |  AP
fmseubas001|  169.60.136.161 |  EU
fmslabas001 |  169.60.136.148 |  LA
fmsnabas001|  169.60.136.183 |  NA
if we are unable to login to the server and the root password is not working, please login to one of the bastion host above and do sudo root, then use the below command to ssh using anisble id, after which we can reset the root password.
ssh -i .ssh/ansible_rsa ansible@<IMZ_IP>

----------------------------------------------------------------------------------------------------------------------------------

Unable to login to the server, chef client is failing #2078
DNS result has no information for dal13ammadc001.imzcloud.ibmammsap.local

knife node show conspbw4hapq.imzcloud.ibmammsap.local -c /etc/chef/client.rb -a cms_chef_client.ohai_hints.cms.site 

[root@conspbw4hapq ~]$ knife node show conspbw4hapq.imzcloud.ibmammsap.local -c                             /etc/chef/client.rb -a cms_chef_client.ohai_hints.cms.site
conspbw4hapq.imzcloud.ibmammsap.local:
  cms_chef_client.ohai_hints.cms.site: dal13amm

when this was bootstrapped it has dal13amm as site which is wrong correct one is Sao Paulo

can you do                knife node edit conspbw4hapq.imzcloud.ibmammsap.local -c /etc/chef/client.rb

[root@conspbw4hapq ~]$ knife node edit conspbw4hapq.imzcloud.ibmammsap.local -c /etc/chef/client.rb
ERROR: You must set your EDITOR environment variable or configure your editor via knife.rb

to fix above run 
export EDITOR=$(which vi)

[root@conspbw4hapq ~]$ export EDITOR=$(which vi)
[root@conspbw4hapq ~]$

knife node edit conspbw4hapq.imzcloud.ibmammsap.local -c /etc/chef/client.rb

find the site showing dal13amm and change it to the correct site sao01amm

run chef-client twice and it should fix

---------------------------------------------------------------------------------------------------------------------------

Enable VM logging
https://kyndrylcsm.service-now.com/nav_to.do?uri=%2Fkb_view.do%3Fsysparm_article%3DKB0017982%26sysparm_stack%3D%26sysparm_view%3D

------------------------------------------------------------------------------------------------------------------------------

Option 1 : Automation -

Login to ->  https://samuel.sap.mgapp.ibm.com
Click on Left pane then select Servers
From the Search box select "Hostname" from drop down and next column enter the hostname, then apply
You will get Server Resources for the selected Server
Locate the Memory and click on edit
Modify the value with required size and apply

--------------------------------------------------------------------------------------------------------

RHEL 6 to 7 chef client upgrade

rpm -Uvh /sds/jenkins/software/linux/chef-13.9.4-1.el7.x86_64.rpm

----------------------------------------------------------------------------------------------------------
Poject Code: IBM-920, Project Contract: PC00007357 
-----------------------------------------------------------------------------------------------------

Post RHEL 6 to 8 upgrade SAP users unable to login with imz id

workaround:

[root@IA1FIODEVDB ~]$ vi /etc/sssd/sssd.conf
comment this below line and restart sssd service as only the OSLINUX group has access, alternatively the users should request for proper access to get onto the servers.

simple_allow_groups = AMM - OSLINUX Support (Global)

---------------------------------------------------------------------------------------

Chef failing with 
 Recipe Compile Error in /var/chef/cache/cookbooks/cms3x_cfg/recipes/default.rb
 
 
 Refer https://github.kyndryl.net/CMS/Platform-Support/wiki/OS-inplace-upgrades
Check and correct the policy for the correct OS version and rerun chef


Run knife command to set correct policy For Linux knife node policy set <nodename> production cms3x_chef_client -c /etc/chef/client.rb

------------------------------------------------------------------------------------------

New user onboarding link

https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/Access

AWS tasks
https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/AWS

https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/AWS-Snapshot
https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/AWS-EC2-Serial-console
https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/How-to-Encrypt-an-Unencrypted-disk-in-AWS
https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/Increase-Disk-size-on-AWS---Linux
https://github.kyndryl.net/CMS/AHT_EMEA_KB/wiki/AWS-How-to-reboot-instance

--------------------------------------------------------------------------------------------------

vcenter fencing stopped and not starting

After we have tried to start the vcenter fencing is not worked, Because getpass.py getting error. 

After we have installed the package  python3-cryptography-2.8-7.37.8.x86_64 on the server its  started the vcenter fencing on the nodes.

Please followup below steps to fix this issue.

[root@lnasv133 ~]# crm_mon -1Afr 
Stack: corosync
Current DC: lnasv133 (version 1.1.19+20181105.ccd6b5b10-3.31.1-1.1.19+20181105.ccd6b5b10) - partition with quorum
Last updated: Sun Jun 26 22:58:30 2022
Last change: Sun Jun 26 22:54:48 2022 by root via cibadmin on lnasv133-ha

2 nodes configured
34 resources configured

Online: [ lnasv133 lnasv133-ha ]

Full list of resources:

 vcenter-fencing-lnasv133	(stonith:fence_vmware_rest):	Stopped
 vcenter-fencing-lnasv133-ha	(stonith:fence_vmware_rest):	Stopped




[root@lnasv132-ha ~]# getpass.py -g crmstnmgr
Traceback (most recent call last):
  File "/usr/local/sbin/getpass.py", line 7, in <module>
    from cryptography.fernet import Fernet
ImportError: No module named 'cryptography'
[root@lnasv132-ha ~]# 


[root@lnasv133-ha fixes]# zypper install python3-cryptography-2.8-7.37.8.x86_64 
Refreshing service 'SMT-http_DAL09AMMSMT01_imzcloud_ibmammsap_local'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...

The following 9 NEW packages are going to be installed:
  python3-asn1crypto python3-cffi python3-cryptography python3-idna python3-packaging python3-pyasn1 python3-pycparser python3-pyparsing python3-setuptools

The following recommended package was automatically selected:
  python3-idna

9 new packages to install.
Overall download size: 1.9 MiB. Already cached: 0 B. After the operation, additional 11.5 MiB will be used.
Continue? [y/n/...? shows all options] (y): y
Retrieving package python3-pyasn1-0.1.9-4.6.1.noarch                                                                                                                   (1/9), 107.7 KiB (583.9 KiB unpacked)
-----------------------------

Latest vcersion of getpass.py available at 
/sds/sap/MSD_Software/SAP_Automation/Non-Hana/Operations/fixes/getpass.py
-----------------------------------------------------------------------------------

Required access - checklist
1. Softlayer accounts:
	a. 393684-AMM
	b. 1069101 - Moonlight
	c. 2264250 - WA2 WAWA
2. Azure portal access - https://w3.ibm.com/ocean/w3publisher/managedapps-iam/multicloud/kyndryl-azure-transition-snow
3. AWS portal access - https://w3.ibm.com/ocean/w3publisher/managedapps-iam/multicloud/aws
4. PIM tool to view passwords - https://ispim.amm.ibmcloud.com/itim/self/Home.do
5. Samuel - https://samuel.sap.mgapp.ibm.com/undefined/servers (for access ping in #samuel-support)
------------------------------------------------------------------------------------------------------------------

shifts
https://persistentsystems.sharepoint.com/:x:/r/sites/IBMCMS/_layouts/15/Doc.aspx?sourcedoc=%7[…]t_Persistent.xlsx&action=default&mobileredirect=true
----------------------------------------------------------------------------------------------------------------------

Shwetali's indent 

Project Code 100046
Resource Position Id 30907
Indent no 1260693



Pooja's Indent

Project  107469
Position id 37156
Indent id 1298669
Grade  5.1
 
------------------------------------------------------------------------------------------------------------------------
OPAAS UI link

The existing URL (https://opaasui.managedapps.ibm.com/opaas-ui/) is NO LONGER VALID.

Kindly note & Bookmark the updated URL >> https://prod.opaas.adai.kyndryl.com/ui/
--------------------------------------------------------------------------------------------------
Ansible troubleshooting guides

Linux: https://github.kyndryl.net/CMS/Platform-Support/wiki/AIC-ILMT-Configuration-and-FAQs  

Ansible connectivity wiki page to fix the connection issues: https://github.kyndryl.net/CMS/Platform-Support/wiki/Ansible-Connection-Troubleshooting 
In case the VMs/customer account is Retired or Decommissioned, please post on the team channel - https://teams.microsoft.com/l/channel/19%3aRqbyGeGoj3t7-mkmhPEj2sbTGFV64A2lvOOHS-S5Hb41%40thread.tacv2/General?groupId=9af9daef-996d-45ee-b4ae-6c073c03e800&tenantId=f260df36-bc43-424c-8f44-c85226657b01

Windows: https://github.kyndryl.net/CMS/cms-ansible/wiki/Ansible-on-Windows---Troubleshooting 



---------------------------------------------------------------------------------------------------

Local id for drtest

Local user for DR with sudo access

504  2022-04-30 21:33:13 useradd ibmdrksankar
  505  2022-04-30 21:33:24 useradd ibmdrspandey
  506  2022-04-30 21:33:32 useradd ibmdrajha
  507  2022-04-30 21:33:39 useradd ibmdrsprathipati
  508  2022-04-30 21:33:54 passwd ibmdrksankar
  509  2022-04-30 21:34:15 passwd ibmdrspandey
  510  2022-04-30 21:34:37 passwd ibmdrajha
  511  2022-04-30 21:34:54 passwd ibmdrsprathipati
  512  2022-04-30 21:35:19 usermod -g sapsys_ww ibmdrksankar
  513  2022-04-30 21:35:29 usermod -g sapsys_ww ibmdrspandey
  514  2022-04-30 21:35:37 usermod -g sapsys_ww ibmdrajha
  515  2022-04-30 21:35:43 usermod -g sapsys_ww ibmdrsprathipati
  
  
  Add an Existing User Account to a Group
To add an existing user account to a group on your system, use the usermod command, replacing examplegroup with the name of the group you want to add the user to andexampleusername  with the name of the user you want to add.

usermod -a -G examplegroup exampleusername
For example, to add the user geek to the group sudo , use the following command:

usermod -a -G sudo geek

---------------------------------------------------------------------------------------------


error: PAM: User account has expired for ibmvkarunagaran from 146.89.142.228

et the sssd.conf in /etc/sssd/sssd.conf comment the line #simple_allow_groups = AMM - OSLINUX Support (Global)

-------------------------------------------------------------------------------------------------------
In VI editor

Immediately after opening a file, type “gg” to move the cursor to the first line of the file, assuming it is not already there. Then type dG to delete all the lines or text in it.

dd to delete the current line

----------------------------------------------------------------------------------------------------------
grep multiple keywords

egrep "KDUMP_KEEP_OLD_DUMPS|KDUMP_SAVEDIR|KDUMP_DUMPLEVEL" /etc/sysconfig/kdump

--------------------------------------------------------------------------------------------------------

@rengasamy_sethurajan  for oscar script

-----------------------------------------------------------------------------------------------------
When patching HANA servers;
1. Collect limited supportconfig before patching - #supportconfig -i BOOT (we can do it before change window to save time)
2. Copy the most recent initrd, vmlinuz and grub.cfg files to somewhere else 
supportconfig -i BOOT
cp /boot/initrd-4.12.14-95.93-default /root/initrd-4.12.14-95.93-default-before-update
cp /boot/vmlinuz-4.12.14-95.93-default /root/vmlinuz-4.12.14-95.93-default-before-update
cp /boot/grub2/grub.cfg /root/grub.cfg-before-update

----------------------------------------------------------------------------------------------------------

Oracle cluster not starting the resources

Found the tags missing which I added
vgchange --addtag pacemaker ep1datavg
vgchange --addtag pacemaker ep1logvg
vgchange --addtag pacemaker ep1archvg

After the above did the cleanup but it was failing to start again.

Next error checked was :

[root@a2aeccprd1db ~]# getpass.py -g crmstnmgr
Traceback (most recent call last):
  File "/usr/local/sbin/getpass.py", line 7, in <module>
    from cryptography.fernet import Fernet
ImportError: No module named 'cryptography'

We had a network change on Dal and so the next fix we tried to update the cryptography didnt work well. This was to fix the fencing not starting.

[root@a2aeccprd2db ~]# zypper install python3-cryptography-2.8-7.37.8.x86_64
Refreshing service 'SMT-http_DAL09AMMSMT01_imzcloud_ibmammsap_local'.
Problem retrieving the repository index file for service 'SMT-http_DAL09AMMSMT01_imzcloud_ibmammsap_local':
Timeout exceeded when accessing 'http://dal09ammsmt01.imzcloud.ibmammsap.local/repo/repoindex.xml?cookies=0&credentials=SMT-http_DAL09AMMSMT01_imzcloud_ibmammsap_local'.
Check if the URI is valid and accessible.
Timeout exceeded when accessing 'http://dal09ammsmt01.imzcloud.ibmammsap.local/repo/SUSE/Updates/SLE-SAP/12-SP4/x86_64/update/repodata/repomd.xml?credentials=SMT-http_DAL09AMMSMT01_imzcloud_ibmammsap_local'.
Abort, retry, ignore? [a/r/i] (r):
Trying again...
Timeout exceeded when accessing 'http://dal09ammsmt01.imzcloud.ibmammsap.local/repo/SUSE/Updates/SLE-SAP/12-SP4/x86_64/update/repodata/repomd.xml?credentials=SMT-http_DAL09AMMSMT01_imzcloud_ibmammsap_local'.
Abort, retry, ignore? [a/r/i] (r):
Autoselecting 'r' after 7 seconds.


SInce the above didnt work , as a workaround, we had to edit the  getpass.py.

Later on checking we found, that someone had added drbd vg name in volume list which should not have been done. Corrected that too.

Later we found another error:
Jul 09 04:54:16 a2aeccprd1db Filesystem(fs-oracle_lv)[100196]: ERROR: There is one or more mounts mounted under /oracle.

Found the order was incorrect, fixed that manually too in config.

group group-fs-ep1 fs-ora19_lv fs-backup_lv fs-oracle_lv fs-oraep1_lv fs-oran_lv fs-mirrloga_lv fs-mirrlogb_lv fs-logarch_lv fs-oraloga_lv fs-oralogb_lv fs-sapbackup_lv fs-sapcheck_lv fs-sapdata1_lv fs-sapdata2_lv fs-sapdata3_lv fs-sapdata4_lv fs-sapdata99_lv fs-orareorg_lv fs-orasaptrc_lv fs-oracli_lv fs-orastg_lv \

VG entry in lvm.conf file was also seen that should have been removed. 


To test fencing connectivity
fence_vmware_rest -a 146.89.140.222 -l "vsphere.local\crmstnmgr" -p MDkyNGMxYzY1ZjEw@ -z -o list --ssl-insecure --filter="filter.names=sm9d185173005"



-----------------------------------------------------------------------------------------------------------
Healthcheck remediation

MA-SAP RHEL6 Healthcheck remediation automation is available now - https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0018314

MA-SAP Automation Test results - ​pptx icon Testing Overview for Remediation via CIS Playbook.pptx

MA-SAP Compliance Wiki and docs are on Teams now –

Join the team - https://teams.microsoft.com/l/team/19%3aTG5DG8KJordmfC7gPtQsiMcHniULpFa4zIYUBhx_WWk1%40thread.tacv2/conversations?groupId=b5f61b54-f91d-4cb9-9619-eba880ad603d&tenantId=f260df36-bc43-424c-8f44-c85226657b01

Wiki - MA SAP Compliance Landing Page

Remediation Catalog - ​Folder icon SAP MA Master Remediation Catalog

Use the General Channel for help, questions, feedback…etc.


The new SLES12 HC remediation automation is LIVE and here - https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0018157

---------------------------------------------------------------------------------------------------------------------------------------
CLuster node migration to cust specific resource pool  ref change CHG0249287

Build Plan
============

Login to Vcenter using new username and password, to make sure its working

Login to the server
cat /etc/passkey
getpass.py -a co5crmstnmgr -u jafpml%Btw9MbW@
cat /etc/passkey
getpass.py -l
getpass.py -g co5crmstnmgr

copy the file to the other node in the cluster
scp /etc/passkey root@pjew3100:/etc/

verify the file on other cluster node

Keep the cluster in maintenance mode
#crm configure property maintenance-mode=true

vmotion both cluster nodes to the new RP

modify the configuration with new username




Verification plan
===============
Validate the communication is happening from VM to Vcenter
fence_vmware_rest -a 146.89.140.222 -l "vsphere.local\bm1crmstnmgr" -p new_password -z -o list --ssl-insecure --filter="filter.names=bm1defrapx002"

The output show show the hostname

Exit maintenance mode
crm configure property maintenance-mode=false


Backout Plan
================
Migrate VM back to previous resource pool
--------------------------------------------------------------------------------------------

Registering a server to different 


rm -f /etc/SUSEConnect
SUSEConnect --cleanup
wget https://dal09ammsmt01.imzcloud.ibmammsap.local/repo/tools/clientSetup4SMT.sh
wget https://dal09ammsmt01.imzcloud.ibmammsap.local/smt.crt
openssl x509 -noout -in smt.crt -fingerprint -sha1 > /root/cert_fingerprint
/root/clientSetup4SMT.sh https://dal09ammsmt01.imzcloud.ibmammsap.local/center/regsvc --yes --fingerprint $(cat /root/cert_fingerprint)

-------------------------------------------------------------------------------------------------------------------------------
[root@IA1BPCDEVAPP init.d]$ fdisk -l /dev/sda
Disk /dev/sda: 42.9 GB, 42949672960 bytes
64 heads, 32 sectors/track, 40960 cylinders
Units = cylinders of 2048 * 512 = 1048576 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000b8d0d
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           2         501      512000   83  Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2             502       40960    41430016   8e  Linux LVM
Partition 2 does not end on cylinder boundary.
[root@IA1BPCDEVAPP init.d]$ echo 1 > /sys/block/sda/device/rescan
[root@IA1BPCDEVAPP init.d]$ fdisk -l /dev/sda
Disk /dev/sda: 103.1 GB, 103079215104 bytes
255 heads, 63 sectors/track, 12532 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000b8d0d
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          64      512000   83  Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2              64        5222    41430016   8e  Linux LVM
[root@IA1BPCDEVAPP init.d]$ fdisk /dev/sda
WARNING: DOS-compatible mode is deprecated. It's strongly recommended to
         switch off the mode (command 'c') and change display units to
         sectors (command 'u').
Command (m for help): p
Disk /dev/sda: 103.1 GB, 103079215104 bytes
255 heads, 63 sectors/track, 12532 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000b8d0d
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          64      512000   83  Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2              64        5222    41430016   8e  Linux LVM
Command (m for help): n
Command action
   e   extended
   p   primary partition (1-4)
p
Partition number (1-4): 3
First cylinder (5222-12532, default 5222):
Using default value 5222
Last cylinder, +cylinders or +size{K,M,G} (5222-12532, default 12532):
Using default value 12532
Command (m for help): p
Disk /dev/sda: 103.1 GB, 103079215104 bytes
255 heads, 63 sectors/track, 12532 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000b8d0d
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          64      512000   83  Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2              64        5222    41430016   8e  Linux LVM
/dev/sda3            5222       12532    58720250   83  Linux
Command (m for help): t
Partition number (1-4): 3
Hex code (type L to list codes): 8e
Changed system type of partition 3 to 8e (Linux LVM)
Command (m for help): p
Disk /dev/sda: 103.1 GB, 103079215104 bytes
255 heads, 63 sectors/track, 12532 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000b8d0d
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          64      512000   83  Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2              64        5222    41430016   8e  Linux LVM
/dev/sda3            5222       12532    58720250   8e  Linux LVM
Command (m for help): w
The partition table has been altered!
Calling ioctl() to re-read partition table.
WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
The kernel still uses the old table. The new table will be used at
the next reboot or after you run partprobe(8) or kpartx(8)
3:21
######################## END #####################

Checking syslog rotation period

/etc/logrotate.d/syslog

----------------------------------------------------------

Journalctl logs service
systemd-journald

log files generated in :/run/log/journal/

if logs are missing chk service uptime if its high it may need restart

-------------------------------------------------------------------------

Changing MTU

RedHat/CentOS

To set the MTU size in RedHat or CentOS you need to edit the appropriate network configuration file for you network device and add an entry for the MTU size. The name of the configuration file depends on the name of the network interface so for eth0 the filename is ifcfg-eth0.

Note – On RedHat or CentOS version 7.x you will also need to comment out any IPv6 options and modify the DHCP client configuration unless you are using a static IP address.
# nano /etc/sysconfig/network-scripts/ifcfg-eth0

NAME=eth0
DEVICE=eth0
#BOOTPROTO=dhcp
ONBOOT=yes
IPADDR=192.168.0.1
NETMASK=255.255.255.0
GATEWAY=192.168.0.254
#USERCTL=no
#NM_CONTROLLED=yes
MTU=1492

For this change to take effect you need to reboot or stop and restart the network.
# reboot

OR
# ifdown eth0
# ifup eth0
-----------------------------------------------------------------------------------
To find NFS consumers
To find what all NFS clients are connected to a NFS server
netstat | grep :nfs
ss -a|grep nfs
cat /var/lib/nfs/rmtab

or showmount -a localhost

------------------------------------------------------------------
RHEL 8 login issue

cat /etc/sssd/sssd.conf

----------------------------------------------------------------------------
alternative/substitute of telnet

"nc -zv 192.168.1.15 22"     "nc -zv IP port"

installation of telnet comes in Vulnerability report 

------------------------------------------------------------------------

NZDO script - documentation is here - https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/A05_NZDUpdateOSPatching.md

ds agent should be stopped b4 running REAR backup- Especially on HANA

https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/master/Operations_Guide/A05_NZDUpdateOSPatching.md

Pacemaker service should always be autostart disabled if not do it 

   

Reference for suse upgrade on pHana - fyi

https://github.kyndryl.net/CMS/BuildMigration/wiki/SLES-12-to-SLES-15-inplace-upgrade-pHANA



Rear backup procedure:

https://github.kyndryl.net/CMS/BuildMigration/wiki/ReaR-Backup



SN KB article for the upgrade - KB0016905


Sample config
REAR backup configuration - change NFS server and VG name accordingly for your server
 
OUTPUT=ISO
BACKUP=NETFS
BACKUP_OPTIONS="nfsvers=3,nolock"
BACKUP_URL=nfs://10.199.15.221/rearbackup
NETFS_KEEP_OLD_BACKUP_COPY=y
ONLY_INCLUDE_VG=("system")
GRUB_RESCUE=y
ISO_MKISOFS_BIN=/usr/bin/ebiso

To trigger rear backup
rear -d -D mkbackup



-----------------------------------------------------------------------------

SuSE 12 System Monitoring utilities
https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-util.html#sec-util-processes-iotop

vmstat  vmstat collects information about processes, memory, I/O, interrupts and CPU
dstat 	is a replacement for tools such as vmstat, iostat, netstat, or ifstat. dstat displays information about the system resources in real time

sar
to install sar -> zypper in sysstat


Device Load Information: iostat


Processor Activity Monitoring: mpstat

Processor Frequency Monitoring: turbostat

Task Monitoring: pidstat

Kernel Ring Buffer: dmesg  The Linux kernel keeps certain messages in a ring buffer


List of Open Files: lsof


 To check how many sshd processes are running, use the option -p together with the command pidof, which lists the process IDs of the given processes.

ps -p $(pidof sshd)


Table of Processes: top


A top-like I/O Monitor: iotop


Memory Usage: free

Detailed Memory Usage: /proc/meminfo

[root@szudvie01 ~]# grep MemTotal /proc/meminfo
MemTotal:        6562828 kB


Process Memory Usage: smaps

Exactly determining how much memory a certain process is consuming is not possible with standard tools like top or ps


Show the Network Usage of Processes: nethogs

File Properties: stat

User Accessing Files: fuser

Time Measurement with time
----------------------------------------------------------------------------------

Laptop OS version upgrade

https://www.redhat.com/en/blog/how-update-red-hat-enterprise-linux-tvia-minor-releases-and-extended-update-support

The initial state shows the RHEL 8.2 system not actually being tied to a specific release:

[root@bblasco82to84 ~]# subscription-manager release
Release not set

[root@bblasco82to84 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux release 8.2 (Ootpa)
Let’s check the installed and available kernel updates. Here you can see the installed RHEL 8.2 kernel, as well as a far newer 8.4 kernel available to be installed.

[root@bblasco82to84 ~]# dnf list kernel
Updating Subscription Management repositories.
This system is registered to Red Hat Subscription Management, but is not receiving updates. You can use subscription-manager to assign subscriptions.
Red Hat Enterprise Linux 8 for x86_64 - BaseOS (RPMs)                                                                      14 MB/s |  33 MB     00:02   
Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs)                                                                   18 MB/s |  31 MB     00:01   
Installed Packages
kernel.x86_64                                              4.18.0-193.el8                                                    @anaconda                   
Available Packages
kernel.x86_64                                              4.18.0-305.7.1.el8_4                                              rhel-8-for-x86_64-baseos-rpms
Now let’s run a full system update (quietly):

[root@bblasco82to84 ~]# dnf update -y --quiet
warning: /var/cache/dnf/rhel-8-for-x86_64-baseos-rpms-51b3b78d5698246b/packages/libsmbios-2.4.1-2.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID fd431d51: NOKEY
Importing GPG key 0xFD431D51:
Userid     : "Red Hat, Inc. (release key 2) <security@redhat.com>"
Fingerprint: 567E 347A D004 4ADE 55BA 8A5F 199E 2F91 FD43 1D51
From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release
Importing GPG key 0xD4082792:
Userid     : "Red Hat, Inc. (auxiliary key) <security@redhat.com>"
Fingerprint: 6A6A A7C9 7C88 90AE C6AE BFE2 F76F 66C3 D408 2792
From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release
The results show the system is updated to RHEL 8.4, with the latest update to the RHEL 8.4 kernel 4.18.0-305 activating on next boot:

[root@bblasco82to84 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux release 8.4 (Ootpa)

[root@bblasco82to84 ~]# dnf list kernel
Updating Subscription Management repositories.
Last metadata expiration check: 0:07:26 ago on Wed 30 Jun 2021 08:54:29 EDT.
Installed Packages
kernel.x86_64                                             4.18.0-193.el8                                                    @anaconda                    
kernel.x86_64                                             4.18.0-305.7.1.el8_4                                              @rhel-8-for-x86_64-baseos-rpms
So, no matter which minor release you started with, this process will pull down the latest packages available for RHEL 8 and update you to the latest minor RHEL release.
-------------------------------------------------------------------------------------------------------------------------

cluster patchig

How to handle Pacemaker cluster servers during OS patching

Hana clusters:

A. When there is full downtime on the cluster:

Make sure we have successful backups as a backout plan

1. put cluster in maintenance mode

2. 'crm cluster stop' on both nodes (first on secondary and then on primary)

3. 'HDB stop' on both nodes (first on secondary and then on primary)

4. Complete OS patching on both the servers

5. 'HDB start' on both nodes (first on primary and then on secondary ) + check of HANA replication. When HANA is synced go to next point

6. 'crm cluster start' on both nodes (first on primary and then on secondary )

7. check cluster status via 'crm_mon -1Afr'

8. Remove cluster from maintenance mode

9. Check cluster again - if it's stable 'crm_mon -1Afr'

10. Have PDL validate the database and the HSR replication status

--------------------------------------------------------------------------------------------

DRBD issue
https://scc.suse.com/support/cases/00196553

-----------------------------------------------------------------------------------------
hort Description : Log Syslog-DStorage Found 2 errors 
Issue : Every Saturday, we are getting this kind of alerts whenever Nagios sees this error "NT_STATUS_CONNECTION_RESET" These errors are related to "smb-IMZCLOUD.service" (service configured as part of the AD join to imzcloud) 
Action Taken : Since from 45days, We have been working with multiple teams/vendor (REDHAT/Ansible) to know the root cause of error message. But still we are working towards fixing the issue. 
Work around : As a work around, Got suggestion from Nagios team/Ansible teams that we can exclude this error (since no impact due to this error) in Nagios filter to avoid the alerts which we can save lot of manual efforts. Last week, we followed the steps which are attached in thread and this week we have monitored and found that no alerts have been generated. 
[11:37 AM] Path --- /usr/local/ncpa/etc/checklog_filters.d 
File --- Syslog-DStorage.filt 
Add the Entry --- -:0:*:NT_STATUS_CONNECTION_RESET 
 
Restart the Nagios agents : 
 
systemctl status ncpa_listener; systemctl status ncpa_passive 
systemctl restart ncpa_listener; systemctl restart ncpa_passive 
systemctl status ncpa_listener; systemctl status ncpa_passive 
 
Expected Result: 
 
[root@GSTTWSTLCKP01 ~]# grep -i NT_STATUS_CONNECTION_RESET /usr/local/ncpa/etc/checklog_filters.d/Syslog-DStorage.filt 
-:0:*:NT_STATUS_CONNECTION_RESET


--------------------------------------------------

[root@qlaqp1slmdb protocolfiles]# cat cmas_logscanner_checklog_filters.protocol-2022-08-27-08-08-46
CRITICAL Errors in messages (tag 7:CRITICAL_Syslog-ErrorStates)
Aug 27 07:07:10 qlaqp1slmdb sshd[4110194]: error: Protocol major versions differ: 2 vs. 9
Aug 27 07:07:12 qlaqp1slmdb sshd[4110502]: error: Protocol major versions differ: 2 vs. 1
Aug 27 07:07:14 qlaqp1slmdb sshd[4110517]: error: Protocol major versions differ: 2 vs. 1


[root@qlaqp1slmdb checklog_filters.d]# pwd
/usr/local/ncpa/etc/checklog_filters.d

-:1:*:Protocol major versions differ: 2

Add the above line in the alert to skip this check
[root@qlaqp1slmdb checklog_filters.d]# cat Syslog-ErrorStates.filt
# DO NOT REMOVE THE VERSION LINE
# VERSION=5.60
# 05-SEP-18
LOGFILE=%{syslog}
# These are messages about loading SCSI devices
-:1:*:major,minor=
-:1:*:name=.*,major=.*,minor=
-:1:*:Block layer SCSI generic.*loaded
#
+:1:CRITICAL:jeopardy
+:1:CRITICAL:emerg
+:1:CRITICAL:crit
+:1:CRITICAL:critical
+:1:CRITICAL:major
+:1:FATAL:panic
-:1:*:Protocol major versions differ: 2

restart nagios services
--------------------------------------------------------

CLuster OS patching

Hana clusters:

A. When there is full downtime on the cluster:

Make sure we have successful backups as a backout plan

1. put cluster in maintenance mode

2. 'crm cluster stop' on both nodes (first on secondary and then on primary)

3. 'HDB stop' on both nodes (first on secondary and then on primary)

4. Complete OS patching on both the servers

5. 'HDB start' on both nodes (first on primary and then on secondary ) + check of HANA replication. When HANA is synced go to next point

6. 'crm cluster start' on both nodes (first on primary and then on secondary )

7. check cluster status via 'crm_mon -1Afr'

8. Remove cluster from maintenance mode

9. Check cluster again - if it's stable 'crm_mon -1Afr'

10. Have PDL validate the database and the HSR replication status

----------------------------------------------------------------------------------------------------
NFS locks  NFS access issue

chkconfig --list |grep nfs

[root@CLDBOBIADWD1 ibmrmalik]# chkconfig --list |grep nfs
nfs             0:off   1:off   2:on    3:on    4:on    5:on    6:off
nfslock         0:off   1:off   2:off   3:on    4:on    5:on    6:off

0-6  runlevels are there

3-4-5 = should be  on 

chkconfig  nfs  on

-----------------------------------------------------------------------
Ansible scans ticket

https://github.kyndryl.net/CMS/Platform-Support/wiki/AIC-ILMT-Configuration-and-FAQs

check for the route  source 169.60.136.148

source 169.60.136.148
169.60.136.161
169.60.136.183
169.60.136.184

port 22, 5985, 5986


try telnet from the cust server where the ansible scans are not happening 
telnet to any of the above ips and check if the ports are open, else the ticket needs to go to firewall team to open the ports



Update the ticket as below and assign to MA-ASGN-INF-3x-SEI-NWK-FW
From bastion server, we are able to telnet using port 22, but other 2 ports are not connecting. Need Firewall team to open the required ports between 4 bastion servers and all the client servers.

Source: 4 Bastion servers below,
169.60.136.148
169.60.136.161
169.60.136.183
169.60.136.184

Destination: All the client servers in this ticket

Ports: 22, 5985 and 5986

-------------------------------------------------------------------------------------------
 var log filtering 
 
grep a log with time stamp and keyword

cat /var/log/messages |grep -i '"Sep  3 15:0"\|error'

search with bad keyword also
-------------------------------------------------------------------------------------------

Ozone results at
/usr/local/sap/log/os_check_full_result.txt

-----------------------------------------------------------------------------------------
Certification link Persistent

https://persistentsystems.sharepoint.com/:x:/r/sites/IBMCloudBU/_layouts/15/doc2.aspx?sourced[…]ct=trueThis&CID=93ce4229-9d47-fabe-68eb-6d2ea2730a71

https://persistentsystems.sharepoint.com/:x:/r/sites/IBMCMS/Shared%20Documents/General/Cloud%20DU1/CMAS/Time%20Sheets/Leave%20Tracker_CMAS_New%20Format.xlsx?d=w787eb26edc514727b99d7647199a0422&csf=1&web=1&e=1wqx2r
------------------------------------------------------------------------------------------
Short description: 8. OS Downgrde from SLES SP5 to SLES SP4
Description:
Login to Vcenter (146.89.141.160) and remove the root disk (96GB) ( IMPORTANT - donot delete delete the disk).
Disk Name - [MON01POOL1POD1DSP544] cd4ecpscs/cd4ecpscs.vmdk
1 - Rename the disk as cd4ecpscs/cd4ecpscs_old.vmdk
2 - Remove the root disk from the VM cd4ecpscs_restore230322 (IMPORTANT - donot delete delete the disk)
DISK name - [MON01POOL1POD1DSP544] cd4ecpscs_restore230322/cd4ecpscs_restore230322.vmdk
3 - Rename the disk cd4ecpscs_restore230322.vmdk as cd4ecpscs.vmdk
4 - Move the disk to " [MON01POOL1POD1DSP544] cd4ecpscs" diretcory ( datastore level)
5- Attach the disk to server cd4ecpscs (Add NEW DEVICE -> Existing Hard disk -> Browse the disk and attach. )
DISK name - [MON01POOL1POD1DSP544] cd4ecpscs/cd4ecpscs.vmdk

6 - Boot the server cd4ecpscs and validate ( Boot from single-user mode and comment the fstab entries and boot, in case of any boot failure)
7 - validate the patch level of the restored VM. ( Kernel, drbd and pacemaker version should be the same on both the cluster nodes)
----------------------------------------------------------------------------------------------------------------------------------------------
SuSE 12 to 15 upgrade

3. Proceed with OS upgrade from SLES-12-SP4 to SLES-12-SP5 and then to SLES-15-SP2 as described in KB0016905: https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0016905
4. Ansible team requires a 2-3 hours work. Github request #2563: https://github.kyndryl.net/CMS/Platform-Support/issues/2563 
---------------------------------------------------------------------------------------------------

HANA pacemaker on azure
KB0018680 How to manage iSCI / SBD on Azure Hana Clusters

--------------------------------------------------------------------------------------------------------------

https://teams.microsoft.com/l/team/19%3a1EJtuxJCKCDc1LOJ5Z29_7UVAbSyFHVRF_VHg-3M0IE1%40thread.tacv2/conversations?groupId=ef49303d-e8e5-4b9b-89cc-4ced39cc55da&tenantId=f260df36-bc43-424c-8f44-c85226657b01
IAM team meet link


Nagios Monitoring meet link
https://teams.microsoft.com/l/channel/19%3a7206378eda794c7fb47d305af54ffc36%40thread.tacv2/engage-osmon-nagios?groupId=ef49303d-e8e5-4b9b-89cc-4ced39cc55da&tenantId=f260df36-bc43-424c-8f44-c85226657b01

---------------------------------------------------------------------------------------------------------

Azure portal for raising ticket
URL: https://partner.microsoft.com/en-us/dashboard/commerce2/customers/list
Your CSP username:   ravi.malik@kynmpncacsp.onmicrosoft.com
password: Jun2022&Aug2022

Your access ID for this username:   172732769

Your contract ID for this username:   163527057

----------------------------------------------------------------------------------------------------------
Pacemaker validation fix

https://github.kyndryl.net/CMS/BuildMigration/wiki/Pacemaker-validation-fix

--------------------------------------------------------------------------------

DRBD
DRBD | Administration Guide | SUSE Linux Enterprise High Availability Extension 12 SP4
https://documentation.suse.com/sle-ha/12-SP4/html/SLE-HA-all/cha-ha-drbd.html

---------------------------------------------------------------------------------------------------
to check status as per Nagios check

 /usr/local/ncpa/plugins/cmas_check_process.sh chef-client
 
 ----------------------------------------------------------------------------------------------

Below are the steps to use REAR backup\restore on a physical server:


1. Follow below github link to install\configure\run rear backup
https://github.kyndryl.net/CMS/BuildMigration/wiki/ReaR-Backup


2. Incase of recovery needed. Use below steps to map the ISO using command line to the IMM of the server
    -- Make sure the IMM ip of the respective server is pingable from the NFS server (where we have taken the rear backup)
    -- Create a directory /tmp/lenovo on NFS server and copy the file "lnvgy_utl_lxce_onecli01t-3.5.1_sles_x86-64.tgz" (attaching here) to the NFS server under /tmp/lenovo and extract
    -- User below command to mount the ISO from the NFS server to the IMM of the required server
        #cd /tmp/lenovo/
        #tar -xzvf /tmp/lenovo/lnvgy_utl_lxce_onecli01t-3.5.1_sles_x86-64.tgz    
        #./rdmount -s 10.162.186.190 -d /path-to-file/filename.iso -l "username" -p "password" -w 443 ------- (it is IMM username\password from cloud portal)
        #./rdmount -q (make a note of the token number, this is required to unmount later)
3. Engage IBM cloud team to boot the server with DVD-ROM, as we do not have access
4. Once the server boot from DVD, you can see the rear initrd loading, and when prompted, enter root, and no password required
5. Make sure to check the disk mapping is correct #lsblk (incase the disk mapping is wrong, do not proceed further and immediately engage SMEs, need to modify the disk mapping configuration)
6. Enter "rear -d -v recover" - when prompted press "1" (to confirm the disk mapping is correct) and press enter 
7. Once completed, issue #reboot command
8. Server will reboot normally. Validate the server, filesystems, routes, timezone, etc....
9. Now, go to the NFS server, and run below command to unmap the ISO
    #./rdmount -q (make a note of the token number)
    #./rdumount Token_number
10. For additional information, go through the detailed steps in the github link from step1
------------------------------------------------------------------------------------------------------

    https://github.kyndryl.net/CMS/SAP-Base-RR/tree/master/1.%20IBM%20Cloud/Pacemaker/Primitives

    All primitives for SLES 12 SP4 and SP5 available 
--------------------------------------------------------------------------------------------------------

Ansible Connection Troubleshooting

https://github.kyndryl.net/CMS/Platform-Support/wiki/Ansible-Connection-Troubleshooting
--------------------------------------------------------------------------------------------------------
COmmands to create ansible user if missing

groupadd -g 128758 ansibleg

useradd  -u 128758 -d /home/ansible -g 128758 -c "897/F/^ANSIBLE//IM-Code-Owned,CD=20210131,RI=CS2764906,#FUNC#" -s /bin/bash ansible

------------------------------------------------------------------------------------------------------------

Lock a user-account-linux/

# usermod -L boby
or
 
 
# passwd -l boby

to verify 
passwd –status boby
boby *LK* 2020-05-01 0 45 7 -1 (Password set, SHA512 crypt.)           LK means its locked
--------------------------------------------------------------------------------------------------------------

Top 10 swap using processes
for file in /proc/*/status ; do awk '/VmSwap|Name/{printf $2 " " $3}END{ print ""}' $file; done | grep kB | sort -k 2 -n -r | head -n 10

Top 10 mem and CPU processesps -eo pmem,pcpu,rss,vsize,args --sort -rss | head -n 10
ps -eo pmem,pcpu,rss,vsize,args --sort -rss | head -n 10

------------------------------------------------------------------------------------------------------


Below you can find a new KB created to downgrade(scale down) a HANA solution in Azure.
This is a delicate procedure because there is a risk of data loss or corruption, but following the steps in an orderly manner will always work in a safe area.

KB: KB0018766 Scale down to Hana Solution.


Additionally, this is the list of currently KBs available in Azure, if you have any other not listed here please share it to add it to the list.

1 - KB0018596 Extend disk storage using Azure's portal
2 - KB0018597 Modify the VM T-shirt size ( Increase or decrease CPU and memory ) on Azure using Samuel's portal  
3 - KB0018605 Extend disk storage on Azure using Samuel's portal
4 - KB0018598 Modify the VM Size (CPU and memory) manually using Azure's portal
5 - KB0018599 Resize manually HANA VMs using Azure's Portal (Scale up)
6 - KB0018600 VM Redeployment on Azure
7 - KB0018601 Change password in Azure, get sudo access and login into the VM console (troubleshooting)
8 - KB0018602 Azure VM Image Backup and Restore Process in a Recovery Services Vault
9- KB0018752 - Azure Managed disks: Find and delete unattached disks – (David) 
10- KB0018766 Downgrade Hana Solution on Azure - OS Tasks (Scale down)

---------------------------------------------------------------------------------------------------------------

Open hw case with Lenovo
Steps to open case for hardware issues with Lenovo Support Team through chat support:

1.https://datacentersupport.lenovo.com/in/en/warrantylookup
2.Key in your System Serial number
3.Click “Contact Us” under Support Options
4.Click on “Chat with a support Agent
5.Do please provide the following information before the Chat window connects to
Support Team.
➢ First Name	Ravi
➢ Last Name		Malik
➢ Phone Number	+91 9881150150
➢ Email         ravi.malik@kyndryl.com
➢ Serial Number		J302BCNR
➢ Issue Description		We had a server reboot and we rasied a case to SuSE to find the cause, they pointed it as a hw issue and we need you guys to help us with the cause and its remediation so it does not reoccur.
[3094861.869164] {1}[Hardware Error]: Hardware error from APEI Generic Hardware Error Source: 4

[3094861.869165] {1}[Hardware Error]: event severity: fatal

[3094861.869165] {1}[Hardware Error]:  Error 0, type: fatal

[3094861.869165] {1}[Hardware Error]:   section_type: memory error

[3094861.869166] {1}[Hardware Error]:   node: 1 

[3094861.869166] Kernel panic - not syncing: Fatal hardware error!

➢ Inquiry Options
- The CHAT window will initiate once customer click on Submit.
Agent will open case and once case opended we will recieve the mail with full description of alert

How to raise a new case: https://datacentersupport.lenovo.com/au/en/solutions/ht505332

 Login to xClarity Controller.(default ID : USERID, PW : PASSW0RD (0 is zero)

-------------------------------------------------------------------------------------------------------------------------

Enable VM logging
KB0017982	Vmware vSphere Client - Enable VM monitoring	
Shutdown the VM
Go to VM then EDit setting then advance then enable logging

1- What is the retention period of the logs and how it will impact the datastore utilization.?
>> By default vmware.log files are rotated up to 10 files for each VM however this number can be changed, also we can specify a size when reached the files will be rotated. 
# By default logs are rotated when the VM is power off and powered on 

# Recent archived files are number vmware.log-n .
>> VMware.log files are stored in the same datastore as of the VM's .vmx file however given the size in KBs it should not affect the Datastore utilization .



2 - Is the logging enabled recommended for cluster VMs also? 
>> Any VM for which we might need an RCA in the time of an issue , we should enable Virtual machine logging.

3 - Is a server reboot/power off mandatory to enable the logs?
>> For Virtual machine log settings , a power off is required for VMs not for the Host

--------------------------------------------------------------------------------------------------------------------------------

[root@krrdbprd1 ~]# chage -l root
chage: PAM: Authentication service cannot retrieve authentication info

fix is recreate shadow file
recreated the shadow using pwconv

---------------------------------------------------------------------------------------------------------------------------------

phana in place OS upgrade 

-	Kyndryl can proceed to perform an in-place upgrade on the p-HANA. This will NOT impact or alter any services Kyndryl has with IBM Cloud as of today.
-	As a pre-requisite, Kyndryl needs to ensure all hardware is current and will support the higher OS & SAP versions. (e.g. CascadeLake hardware)
-	The SUSE licenses will continue as they are right now.
-	The SAP licensing will depend on the Product Availability Matrix of SAP.
-	The SAP Product Availability Matrix (PAM) is available here
o	https://userapps.support.sap.com/sap/support/pam
-	IBM Cloud recommends doing at least one firmware upgrade after the SLES upgrade is done to test all automation workflows.
-	All firmware upgrades will be supported by IBM Cloud.
-	All hardware support will remain intact as it is today.
-	IBM Cloud recommends sufficient lead time between Non-prod and Prod for sufficient testing. 
-	IBM Cloud has been requested to provide with an email listing all relevant points.
-	In the future in the event of a need, all support related to OS reloads will be supported by IBM Cloud, with approvals from the IBM Cloud management. OS reloads is a manual process.
------------------------------------------------------------------------------------------------------------------------------------

chage: PAM: Authentication token is no longer valid; new one required

Ensure the file contents are like this   password        sufficient      pam_unix.so use_authtok nullok shadow try_first_pass is uncommented or if missing add it
[root@mm3s4ued001 ~]# cat /etc/pam.d/common-password
#%PAM-1.0
#
# This file is autogenerated by pam-config. All changes
# will be overwritten.
#
# Password-related modules common to all services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define  the services to be
# used to change user passwords.
#
#password       requisite       pam_cracklib.so reject_username retry=3 minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0
password requisite pam_cracklib.so try_first_pass retry=3 minlen=15 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1
password        required        pam_pwhistory.so use_authtok remember=8
password        optional        pam_gnome_keyring.so use_authtok
password        sufficient      pam_unix.so use_authtok nullok shadow try_first_pass
password        required        pam_unix.so sha512 use_authtok nullok shadow try_first_pass
password        required        pam_sss.so use_authtok

-------------------------------------------------------------------------------------------------------------------------------------
files deleted but space not released.

lsof |grep -i deleted

search for processes holding big deleted files and restart it or kill that pid
-------------------------------------------------------------------------------------------------------
Nagios threshold
You can check the threshold values under this file cmas_thresholds.cfg (Path: /usr/local/ncpa/etc).

------------------------------------------------------------------------------------------------------------------

HANA pacemaker cluster on Suse  Putting HANA cluster in maintenance and taking out

If pacemaker version has below version or lower follow the below, for the newer version normal steps work fine.
1.1.19+20181105.ccd6b5b10-3.31.1-1.1.19+20181105.ccd6b5b10

pacemaker is not able to get information for MSL resource after maintenance flag is used on the cluster and then removed. It leads to HDB restart. SUSE confirmed the behaviour (there may be some fix in the future). So for now the HANA cluster maintenance procedure is following (on example from this system): 


1) Set cluster to maintenance mode and stop pacemaker on both nodes
1a) Set master slave resource to maintenance mode (COMMAND: crm resource maintenance msl_SAPHana_SP1_HDB00)
1b) Set IP resource to maintenance mode (COMMAND: crm resource maintenance rsc_ip_SP1_HDB00)
1c) Stop pacemaker using (COMMAND: crm cluster stop) on both the nodes (first on IA1SP1DB-HA and then on IA1SP1DB) 
 
2. Set cluster resources to managed mode:
2.1 Refresh clone resource (COMMAND: crm resource refresh cln_SAPHanaTopology_SP1_HDB00)
2.2 Refresh master slave resource (COMMAND: crm resource refresh msl_SAPHana_SP1_HDB00)
2.3 Validate the cluster state (COMMAND: crm_mon -1Afr) to check if hana_sp1_roles has on IA1SP1DB value 2:P:master1:master:worker:master and hana score attribute master-rsc_SAPHana_SP1_HDB00 has on IA1SP1DB value 150 or 5
2.4 Remove master slave resource from maintenance mode (COMMAND: crm resource maintenance msl_SAPHana_SP1_HDB00 false)
2.5 Remove IP resource from maintenance mode (COMMAND: crm resource maintenance rsc_ip_SP1_HDB00 false)

-------------------------------------------------------------------------------------------------------------------

ABAP primitives by Suresh

https://github.kyndryl.net/CMS/SAP-Base-RR/blob/master/1.%20IBM%20Cloud/Pacemaker/Primitives/SLES%20SP4/SLES_12_SP4_ABAP_CLUSTER_PRIMITIVES.md


[12:52] Suresh Jayamani
wait_for_leasetime_on_stop=true 

[12:52] Suresh Jayamani
we need to add this for exports 

------------------------------------------------------------

DPE assignment group
    CLIENT-EXPERIENCE

-------------------------------------------------------------------

RHEL 7 and 8 root pw resetThe kernel boot parameters appear.
KB0018318: SAP-Linux; How To Reset Root User Password on Red Hat 7 and Red Hat 8 (root password recovery)
https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsys_kb_id%3Dff832aa61b6819d048ea6394604bcbe3

    load_video
    set gfx_payload=keep
    insmod gzio
    linux ($root)/vmlinuz-4.18.0-80.e18.x86_64 root=/dev/mapper/rhel-root ro crash\
    kernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv/swap rhgb quiet
    initrd ($root)/initramfs-4.18.0-80.e18.x86_64.img $tuned_initrd/etc/ssh/sshd_config​_

    Go to the end of the line that starts with linux.

    linux ($root)/vmlinuz-4.18.0-80.e18.x86_64 root=/dev/mapper/rhel-root ro crash\
    kernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv/swap rhgb quiet

    Press Ctrl+e to jump to the end of the line.

    Add 
 rd.break 

 
 
to the end of the line that starts with linux.

    linux ($root)/vmlinuz-4.18.0-80.e18.x86_64 root=/dev/mapper/rhel-root ro crash\

    kernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv/swap rhgb quiet rd.break
	
	----------------------------------------------------------------------------------------------------
ASCS always on primary node so when need to identify which is primary chk ASCS-ABAP
ERS is always on secondary

Cluster Patching - ABAP Server ACTIVE - ACTIVE
wa2fipap01	ABAP  10.191.1.138   Primary 
wa2fipap01s	ABAP  10.191.1.135   Secondary 
--------------------------------
On pacemaker Non-Hana clusters – Document the node that has ASCS/SCS is running as primary. 
The node running the ERS resource group is secondary. 
Global (NFS) resource group should be running on the same node as the ASCS /SCS resource group.
ASCS = ( g-scs )on wa2fipap01
ERS = ( g-ers ) on wa2fipap01s
NFS = g-global running on wa2fipap01
=========================================
CHECK LOCATION CONSRAINTS BEFORE FAILOVER 
crm configure show | grep prefer
crm resource clear resource_name ( eg g-ascs )
===============================================
Failover Resource from Secondary to primary 
crm node standby wa2fipap01s	( Secondary Server ) 
Note - after every failover check replication status
CRITICAL -- Please take time and check if all resources moved to another node.. IF resources moved, only then put cluster into maintenance mode
================================================
Put the cluster into maintenance mode and stop the pacemaker service on NODE1:
crm configure property maintenance-mode=true  
=============================================
Stop Pacemaker on seconary node ( wa2fipap01s ) ( Stand by node ) 
systemctl stop pacemaker.service
============================================
             START PATCHING 
================================================= 
PATCH Secondary node ( wa2fipap01s )  in standby (NODE2)

Start Patching via yast or zypper update
Once completed 
===============================================
Start cluster service on NODE2
systemctl start pacemaker.service
===============================================
Remove Node 2( secondary )  from maintence mode 
crm configure property maintenance-mode=false
######################################3
Put back node in online mode:
crm node online NODE2
===============================================
Check drbdadm status  <-- If drbdadm not in sync , so can we start patching on Primary node ?
Check with SAP team if application working fine or not
=================== XXXX ====================
START WORK ON PRIMARY NODE 1 ( wa2fipap01 )
====================================================
Check Replication, the replication status should be ACTIVE.
======================================================
migrate the resources from NODE1 to the already patched node NODE2 ( ( wa2fipap01s ) 
crm node standby wa2fipap01
========================================================
After the failover:  On Non-Hana clusters, vlidate again the cluster replication. 
The replication status should be ACTIVE
=======================================================
Put the cluster into maintenance mode and stop the pacemaker service on NODE1:
crm configure property maintenance-mode=true       
=======================================================
STOP PACEMAKER SERVICES
systemctl stop pacemaker.service
=======================================================
START PATCHING VIA zypper update or yast 
As patching completed reboot, once up
========================================================
START CLUSTER SERVICES
systemctl start pacemaker
=======================================================
REMOVE CLUSTER FROM MAINTENANCE MODE 
crm configure property maintenance-mode=false
=========================================================
PUT BACK CLUSTER NODE 1 INTO ONLINE MODE
crm node online wa2fipap01
========================================================
Once i will bring node 1 to online so, will it become as primary or again do i need to put node -2 in standy
so that Node-1 will become primary, as it was before patching change. 

================= 
Command for migrating particular resources. You have to change resource name as per your server.
crm resource migrate resource_name
crm resource migrate group-vol-fip
crm resource migrate group-fs-fip
crm resource migrate group_Syb_fip	

-----------------------------------------------------------------------------------------------------------------------
HANA cluster maintenance mode shared by Adam Zboril

For Pacemaker 2.0 and Pacemaker 1.1 team can follow the below procedure

1.	crm resource maintenance <msl resource> ( put master slave resource to maintenance mode )
2.	crm resource maintenance <Ip resource> ( put Ip resource to maintenance mode )
3.	crm cluster stop ( stop the cluster )
4.	Perform the scheduled activity 
5.	crm cluster start ( start the cluster )
6.	crm resource refresh <clone resource> ( refresh clone resource )
7.	crm resource refresh <msl resource> ( refresh master slave resource )
8.	crm resource maintenance <msl resource> false ( remove master slave resource from maintenance mode )
9.	crm resource maintenance <ip resource> false ( remove ip resource from maintenance mode )
10.	Verify the cluster status

Only If pacemaker version is 1.1.19+20181105.ccd6b5b10-3.31.1-1.1.19+20181105.ccd6b5b10 then above procedure will not work and we need to follow below procedure. And it is recommended to upgrade this version to the latest version to avoid any unexpected issues in future.

1.	crm configure property maintenance-mode=true
2.	crm resource unmanage <msl resource>
3.	crm resource unmanage <ip resource>
4.	crm cluster stop
5.	perform the upgrade activity
6.	crm cluster start
7.	crm configure property maintenance-mode=false ( if it asks to unset the unmanaged flag for ip resource select no )
8.	crm resource cleanup <msl resource>
9.	crm resource manage <msl resource>
10.	crm resource manage <ip resource>
11.	verify the cluster status


---------------------------------------------------------------------------------------------------
Before patching DR servers/DR server patching

Production server consps4hdbp2 was OS patched in change ticket CHG0253788 between 09-15-2022 00:00:00 and 09-15-2022 02:00:00.
The corresponding disaster recovery server consps4hdbpdr was OS patched in change ticket CHG0253804 between 09-15-2022 03:00:00 and 09-15-2022 07:00:00.

This came to attention when a severity 1 monitoring alert ticket for "HANA replication down" was triggered for the production system when the disaster recovery server was taken down for OS patching.  This would not have happened if the production server and the disaster recovery server were patched at the same time in the same change ticket, but I know you have some thoughts that we should not do this.  However, OS patching the disaster recovery server an hour or so after the production server is almost the same as patching them at the same time, right?

To avoid the severity 1 ticket described above and assuming the disaster recovery servers are patched at a different time, we will have to add monitoring suppression of the production server during OS patching of the disaster recovery server.  This unfortunately comes with the risk that if anything happens to the production system during OS patching of the disaster recovery server, no monitoring alert tickets will be triggered.

You can see there are pros and cons whether OS patching production and disaster recovery in the same change window or in a different one.  What guidelines should the OS patching team be using the patch disaster recovery servers?  I believe in the past you have stated it should be a week after the production servers.  Whatever the guidelines are, we need to document them in the OS patching KB article and ensure they are followed.

------------------------------------------------------------------------------------------------------------------------------

rpm -qa --last | grep nfs-tools
1. Take Snapshot of the VM which has duplicate packages
2.Execute the below command
# yum check &> /tmp/yumcheck.out
The above command will take more then 45 minutes  to 1 Hour depends on number of packages installed on server and this will increase the CPU load 99% .
The progress can be monitored through the blow command
# tailf /tmp/yumcheck.out
3.Once Yum check completed .Execute the below command.
# grep duplicate /tmp/yumcheck.out | awk '{ print $NF }' | sort > /tmp/dups.txt
4.Open the /tmp/dups.txt
# vi /tmp/dups.txt
remove the numbers before the package name and save the file
5.Prepare the final list
#cat /tmp/dups.txt | sort > /tmp/removethese.txt
6.Check number of Packages
#wc -l /tmp/removethese.txt
7.Remove the duplicate packages
for i in  `cat /tmp/removethese.txt`; do  rpm -e $i --nodeps; done
8. if any packages has conflicts that can be re installed
# yum reinstall packagename
9.if required re create a inird images if you are re installing the Kernel packages .
10.Again Execute yum check
#yum check &> /tmp/yumfinal.out
The above command will take more then 45 minutes  to 1 Hour depends on number of packages installed on server and this will increase the CPU load 99% .
11.Once all duplicate and Conflict packages are cleaned reboot the server .
#reboot
12.Do the yum update to make sure future update works
#yum update
13. App/DB Validation .
---------------------------------------------------------------------------------------------------------------------------------------------------------

Samuel Opaas automation failures to be tagged to
https://github.kyndryl.net/CMS/MgdSAP-Tribe-Tracker/issues/23385

------------------------------------------------------------------------------------------------------------------

When restarting the corosync service on a SUSE Linux PaceMaker Cluster, the Cluster must be in set in unmanaged mode first. If not, the cluster will react resulting in a cluster failover.

---------------------------------------------------------------------------------------------------------------------

Windows last reboot time
systeminfo | find "System Boot Time"

LInux last reboot time

-------------------------------------------------------------------------------------------------------------------------------

VMWAre tools upgrade without a reboot
/s /v "/qn REBOOT=ReallySuppress"   in advanced option in the automatica upgrade option selection

---------------------------------------------------------------------------------------------------------------------------------

2.Disk addition through automation tools

3.AWS offering to our clients, and what is our scope of work (other than OS), and SOPs if there are any created already. Please find the below Gitlink
 
https://github.kyndryl.net/CMS/SAP-DevOps-Integration/tree/fazal/3.%20AWS
 

4.Enable VM Logging and kdump for the VMs during every patching. (OS SME to include these steps till change templates are updated)
Vmware vSphere Client - Enable VM monitoring(KB0017982)
Power off the VM before the patch
Enable VM Logging at VCenter
Power on the VM and patch the system
Configure kdump (with script that will be provided)
Reboot the system
 

5.If there is a requirement for snapshots on any change, there must be an approval from the following leads to create them.

Gerald Delgado (gerald.delgado.mora@kyndryl.com) Wed-Sat & Carlos Villalobos (carvilla@kyndryl.com) Sud-Wed - AG
Balaji Selvadurai (balaji.selvadurai@kyndryl.com) AP/EMEA (depending on rotation)
Murthy (mpuranap@kyndryl.com) AP/EMEA (depending on rotation)

--------------------------------------------------------------------------------------------------------------------------------------
[13:49] SAQUIB ALI SYED
2.Disk addition through automation tools
 
3.AWS offering to our clients, and what is our scope of work (other than OS), and SOPs if there are any created already. Please find the below Gitlink
 
https://github.kyndryl.net/CMS/SAP-DevOps-Integration/tree/fazal/3.%20AWS
 
4.Enable VM Logging and kdump for the VMs during every patching. (OS SME to include these steps till change templates are updated)
Vmware vSphere Client - Enable VM monitoring(KB0017982)
Power off the VM before the patch
Enable VM Logging at VCenter
Power on the VM and patch the system
Configure kdump (with script that will be provided)
Reboot the system
 
5.If there is a requirement for snapshots on any change, there must be an approval from the following leads to create them.
 
Gerald Delgado (gerald.delgado.mora@kyndryl.com) Wed-Sat & Carlos Villalobos (carvilla@kyndryl.com) Sud-Wed - AG
 
Balaji Selvadurai (balaji.selvadurai@kyndryl.com) AP/EMEA (depending on rotation)
 
Murthy (mpuranap@kyndryl.com) AP/EMEA (depending on rotation)

[13:50] SAQUIB ALI SYED
6.Plan for REAR backups instead of snapshot: Please go through the below plan and let me know if we all are in agreement with the below procedure and let me know incase of any modifications.
=========================================================================================================
1. Pre-Patching Verification
 
Verify SME approval of the patching CSR, by which certifies that the patching pre-check has been done.
Verify that a complete system backup was performed.
Verify that the /var filesystem contains at least 500 MB free space, by using "du" command.
Verify that the server can communicate with the YUM server by running “sudo yum check-update”.
Verify if the system console is available (via RSA, Serial Concentrator, VMware vCenter, and so on).
Verify sssd service enabled on startup. [#systemctl is-enabled sssd ] if not enabled enabled it [#systemctl enable  sssd]
Verify to find if any rootvg having 2 disks as tsm4ve snapshot will fail if initated for a restore. Plan to have a alternate backup (REAR) if 2 disk as part of rootvg.(Extend the first disk and migrate the entire data from second disk to first disk and plan for one backup atleast before patching)
verify to find /boot is having enough space incase of REAR backup is planned and grub include option is enabled.
Verify with TSM team to confirm TSM4VE backup and FS/DB backups exists and working as expected
SME to include a special instruction to confirm to proceed with snapshot backup or REAR backup based on the Datastore Freespace.
Note: Not to go with REARbackup for vhana if BTRFS is configured.
 
TSM Approval group to check and confirm backups are available before approving the change
 
Enable LVM snapper for Vhana and Phana
 
For Phana and Vhana:
====================
 
1.Ensure to validate DB backups and FS backups from TSM team.
 
2.Ensure to take REAR backup as an alternate backup method.

for btrfs file system on BIOS comment the 2 lines meant for UEFI 
Check if you are using UEFI or BIOS on Linux

The easiest way to find out if you are running UEFI or BIOS is to look for a folder /sys/firmware/efi. The folder will be missing if your system is using BIOS.
/sys/firmware/efi exists means system uses UEFI

Get password from vault or reset the root password with some kyndryl standard password.
Remount the /tmp with exec (mount -o remount,exec /tmp)
Stop ds_agent service before taking backup.
stop chef-client if it is implemented.


https://github.kyndryl.net/CMS/BuildMigration/wiki/Rear-Configuration-steps

che01 --> nfs://146.89.142.88/rearbackups 
lon02 --> nfs://146.89.140.88/rearbackups 
mon01 --> nfs://146.89.141.152/rearbackups 
sao01 --> nfs://146.89.143.23/rearbackups 
tor01 --> nfs://146.89.141.88/rearbackups 
dal13 --> nfs://146.89.142.214/rearbackups 
dal09 --> nfs://146.89.140.24/rearbackups 
fra02 --> nfs://146.89.140.216/rearbackups 
hkg02 --> nfs://146.89.141.24/rearbackups 
sng01 --> nfs://146.89.140.152/rearbackups 
wdc04 --> nfs://146.89.142.24/rearbackups 
par01 --> nfs://146.89.142.141/rearbackups 
lon06 --> nfs://146.89.143.158/rearbackups 
syd04 --> nfs://146.89.143.236/rearbackups 
tok02 --> nfs://146.89.168.36/rearbackups

rear config file content
# vi /etc/rear/local.conf

Remount the /tmp with exec (mount -o remount,exec /tmp)
Stop ds_agent service before taking backup


ls -ld /sys/firmware/efi     if present means uefi else bios

Ensure below is not present in the config file
GRUB_RESCUE_USER="unrestricted"
SECURE_BOOT_BOOTLOADER="/boot/efi/EFI/sles/shim.efi"

for xfs and ext
 
OUTPUT=ISO BACKUP=NETFS 
BACKUP_OPTIONS="nfsvers=4,nolock" 
BACKUP_URL=nfs://146.89.140.216/rearbackups
NETFS_KEEP_OLD_BACKUP_COPY=y 
ONLY_INCLUDE_VG=("VolGroup") 
GRUB_RESCUE=y

or

for xfs and ext

OUTPUT=ISO
BACKUP_URL=nfs://10.210.240.11/usr/sap/rear_backup
BACKUP_OPTIONS="nfsvers=4,nolock"
BACKUP=NETFS
GRUB_RESCUE=y
OUTPUT_URL=nfs://10.210.240.11/usr/sap/rear_backup
BACKUP_PROG_EXCLUDE=("${BACKUP_PROG_EXCLUDE[@]}" '/media' '/var/tmp' '/var/crash' '/swapfile'  '/var/log/tsm/dsmerror.log' '/var/log' '/var/spool/postfix' '/usr/sap/rear_backup')
NETFS_KEEP_OLD_BACKUP_COPY=y
EXCLUDE_MOUNTPOINTS=( '/sapmnt/data' '/sds' '/sapmnt/shared' '/sapmnt/log' )
BACKUP_PROG_INCLUDE=( "${BACKUP_PROG_INCLUDE[@]}" '/tmp/krb5*' )
EXCLUDE_RECREATE=( "${EXCLUDE_RECREATE[@]}" "fs:/usr/sap" "fs:/sapmnt/log" "fs:/sapmnt/data" "fs:/sapmnt/shared" )
USE_RESOLV_CONF=( "search imzcloud.ibmammsap.local" "nameserver 146.89.142.137" )
COPY_AS_IS+=( /usr/src/kernels/* /tmp/krb* )

or 

OUTPUT=ISO
BACKUP_URL=nfs://146.89.141.152/rearbackups
#BACKUP_OPTIONS="nfsvers=4,nolock"
BACKUP=NETFS
GRUB_RESCUE=n
BACKUP_PROG_EXCLUDE=("${BACKUP_PROG_EXCLUDE[@]}" '/media' '/var/tmp' '/var/crash' '/swapfile'  '/var/log/tsm/dsmerror.log' '/var/log' '/var/spool/postfix' '/sapmnt/log' '/.snapshots')
#NETFS_KEEP_OLD_BACKUP_COPY=
EXCLUDE_MOUNTPOINTS=( '/sds' '/sapmnt/log' '/sapmnt/shared' '/sapmnt/data' '/usr/sap')
EXCLUDE_VG=( 'sapdata saplog sapshared' )
BACKUP_PROG_INCLUDE=( "${BACKUP_PROG_INCLUDE[@]}" '/tmp/krb5*' '/tmp')
USE_RESOLV_CONF=( "search imzcloud.ibmammsap.local" "nameserver 146.89.140.10" )
COPY_AS_IS+=( /usr/src/kernels/* /tmp/krb* )r packages will never ship with a site.conf.
ISO_MKISOFS_BIN=/usr/bin/ebiso



BTRFS VHANA


OUTPUT=ISO
BACKUP=NETFS
BACKUP_OPTIONS="nfsvers=4,nolock"
#ISO_MKISOFS_BIN="/usr/bin/ebiso" 	# Enable ONLY IF UEFI Loader 		# comment if its BIOS
BACKUP_URL=nfs://146.89.140.152/rearbackups
NETFS_KEEP_OLD_BACKUP_COPY=yes
MODULES_LOAD=( autofs4 scsi_mod scsi_dh_alua scsi_dh_emc scsi_dh_rdac dm_mod dm_multipath sg drm_panel_orientation_quirks vmw_pvscsi vmxnet3 serio_raw libata crc32c_intel drm libahci ahci ttm ata_piix sd_mod fb_sys_fops sysimgblt sysfillrect syscopyarea drm_kms_helper vmwgfx ata_generic raid6_pq xor btrfs button ac pcc_cpufreq shpchp i2c_piix4 vmw_vmci joydev pcspkr cryptd vmw_balloon glue_helper crypto_simd aes_x86_64 aesni_intel pcbc libcrc32c ghash_clmulni_intel crc32_pclmul sb_edac xfs msr iscsi_boot_sysfs iscsi_ibft af_packet vsock vmw_vsock_vmci_transport binfmt_misc fscache sunrpc grace lockd nfs dns_resolver nfsv4 auth_rpcgss rpcsec_gss_krb5 tmhook x_tables ip_tables iptable_filter bmhook )
REQUIRED_PROGS=( "${REQUIRED_PROGS[@]}" snapper chattr lsattr )
COPY_AS_IS=( "${COPY_AS_IS[@]}" /usr/lib/snapper/installation-helper /etc/snapper/config-templates/default )
BACKUP_PROG_INCLUDE=( /var/lib/machines /srv /opt /var/spool /var/cache /var/lib/libvirt/images /var/tmp /var/lib/named /var/lib/mysql /var/lib/pgsql /tmp /var/log /var/lib/mariadb /usr/local /var/lib/mailman /home /var/opt /var/opt/BESClient )
POST_RECOVERY_SCRIPT=( 'if snapper --no-dbus -r $TARGET_FS_ROOT get-config | grep -q "^QGROUP.*[0-9]/[0-9]" ; then snapper --no-dbus -r $TARGET_FS_ROOT set-config QGROUP= ; snapper --no-dbus -r $TARGET_FS_ROOT setup-quota && echo snapper setup-quota done || echo snapper setup-quota failed ; else echo snapper setup-quota not used ; fi' )
ONLY_INCLUDE_VG=("system")
EXCLUDE_VG=( sapdata saplog sapshared )
BACKUP_PROG_EXCLUDE=( "${BACKUP_PROG_EXCLUDE[@]}" '/sapmnt/*' )

XFS vhana

OUTPUT=ISO
BACKUP_URL=nfs://146.89.168.36/rearbackups
#BACKUP_OPTIONS="nfsvers=4,nolock"
BACKUP=NETFS
GRUB_RESCUE=n
BACKUP_PROG_EXCLUDE=("${BACKUP_PROG_EXCLUDE[@]}" '/media' '/var/tmp' '/var/crash' '/swapfile'  '/var/log/tsm/dsmerror.log' '/var/log' '/var/spool/postfix' '/sapmnt/log' '/.snapshots')
#NETFS_KEEP_OLD_BACKUP_COPY=
EXCLUDE_MOUNTPOINTS=( '/sds' '/sapmnt/log' '/sapmnt/shared' '/sapmnt/data' '/usr/sap')
EXCLUDE_VG=( 'sapdata saplog sapshared' )
BACKUP_PROG_INCLUDE=( "${BACKUP_PROG_INCLUDE[@]}" '/tmp/krb5*' '/tmp')
USE_RESOLV_CONF=( "search imzcloud.ibmammsap.local" "nameserver 146.89.140.10" )
COPY_AS_IS+=( /usr/src/kernels/* /tmp/krb* )
ISO_MKISOFS_BIN=/usr/bin/ebiso


 rear -dv mkbackup   to take backup




grub rescue =unrestricted remove from conf

Make sure ds_agent and chef not running before starting the REAR backup.
 
If it's cluster , put the cluster in maintaince mode
 
Note: For vhana, REAR is not tested for BTRFS config. SME
 
Relax and recover Configuration(REAR) steps:https://github.kyndryl.net/CMS/BuildMigration/wiki/Rear-Configuration-steps
 
Restoring REAR steps:
====================
Follow below git link for the same:https://github.kyndryl.net/CMS/BuildMigration/wiki/ReaR-Backup
 
For Non-hana:
=============
 
Ensure to validate TSM4VE backups and FS backups by TSM team.
 
SME/PDL to decide if REAR backup is required or not based on the criticality of the vm
 
Relax and recover Configuration(REAR) steps:https://github.kyndryl.net/CMS/BuildMigration/wiki/Rear-Configuration-steps
 
Restoring REAR steps:
====================
Follow below git link for the same:https://github.kyndryl.net/CMS/BuildMigration/wiki/ReaR-Backup
=============================================================================
Initiating SAML single sign-on



CS12235209, CS12235318, CS12235637, CS12234648


curl -v -L -A SupportConfig -T "C:\Users\RaviMALIK\Downloads\Downloads/vmcore_armfksap404db_SR00495624.tar.xz" "https://support-ftp.us.suse.com/incoming/upload.php?appname=supportconfig&file=vmcore_armfksap404db_SR00495624.tar.xz"

---------------------------------------------------------------------------------------------------------------------------

How to use screen during OS patching:
=====================================

Open a new screen session and then click enter
#screen

Start the os patching with zypper

Once Patching is done, exit from this screen session by keeping push Ctrl on keyboard, then press A and then press D
#Ctrl+a Ctrl+d   ---> detaches from the screen session 

List current screen sessions active
#screen -list

If you need to return to the screen session, #screen -r SCREEN_SESSION 
#screen -r 110614.pts-123.saupo1scs01p – reattaches to the screen specified screen session

--------------------------------------------------------------------------------------------------------

I have some important news this week and will add to the wiki, but I also wanted it up front in the email so folks can see it when they read this:

1.	We have heard from Offering team that we will get SLES 12.5 support. So, customers will not have to go with the more expensive In Place Upgrade for SLES 12.4 to SLES 15.x, right away. Timeframe and process are TBD. There will be an announcement on this from the LCM Team soon.
2.	A couple issues where uncovered on the HC remediation automation for INEOS. I have provided the info here. It may not impact your customers as it is mainly around how the customer uses cron jobs but, best to get it out there so you can brief your customers on this potential impact to them when they do HC remediation. The KBs will be updated with these as well.
A:  The system environment variable TMOUT will be set to 900 seconds. This could impact customer operations. Interactive user’s could be logged off the system. This item will be included in the global exclusion P-RAM. But, in the interim, if this behavior is unacceptable to the customer (confirm with them) then add the rule to the exclusion list.
•	5.4.5 Ensure default user shell timeout is 900 seconds or less - /etc/bashrc
•	5.4.5 Ensure default user shell timeout is 900 seconds or less - /etc/profile

sles_cis_rule_5_4_5: false
B:  CIS rules 5.1.x for cron & pam remediation. If the customer uses cron jobs under their named users or under <sid>adm or other SAP users, then, post remediation there may be issues caused by the CIS rules for cron, pam.d or sssd. 
Rules affecting this situation are (suspected rules are):
•	5.1.1 Ensure cron daemon is enabled
•	5.1.2 Ensure permissions on /etc/crontab are configured
•	5.1.3 Ensure permissions on /etc/cron.hourly are configured
•	5.1.4 Ensure permissions on /etc/cron.daily are configured
•	5.1.5 Ensure permissions on /etc/cron.weekly are configured
•	5.1.6 Ensure permissions on /etc/cron.monthly are configured
•	5.1.7 Ensure permissions on /etc/cron.d are configured
•	5.1.8 Ensure at/cron is restricted to authorized users - cron.allow
•	5.1.8 Ensure at/cron is restricted to authorized users - cron.deny
•	5.1.8 Ensure at/cron is restricted to authorized users - at.allow
•	5.1.8 Ensure at/cron is restricted to authorized users - at.deny
Either work with customer to make the jobs work with the new security settings or add the above rules to the exclusion list. It is best to inform the customer of this and they will have to take steps to ensure:
•	The required user environment variables are added to /etc/security/pam_env.conf
---or---
•	Add the variables directly in the crontab 
•	PATH variable is added directly to the crontab file for the users(s) as pam activation will not allow PATH to pass to cron
•	Example:
cat /etc/crontab
SHELL=/bin/sh
PATH=/usr/bin:/usr/sbin:/sbin:/bin:/usr/lib/news/bin
MAILTO=root
---ADD REQUIRED VARS LIKE ABOVE---
#
# check scripts in cron.hourly, cron.daily, cron.weekly, and cron.monthly
#
-*/15 * * * *   root  test -x /usr/lib/cron/run-crons && /usr/lib/cron/run-crons >/dev/null 2>&1
---or---
•	Call the cron job via bash (or some other shell) with interactive flags to ensure the user environment is explicitly passed into cron for the job execution:
o	example test cronjob below, to test what variables are seen inside cron
o	use “-l” and “-c”
* * * * * BASH_ENV=~/.bashrc bash -l -c "printenv > /tmp/print_envs_result"

-----------------------------------------------------------------------------------------------------------------------------------
When pvs shows one disk as unknown and that stops you from extending the LV

ref https://www.golinuxcloud.com/fix-pvs-shows-unknown-device-redhat-linux/

[root@z0hqmcsdbap01 backup]# pvs
  WARNING: Couldn't find device with uuid y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  WARNING: VG cspdatavg is missing PV y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  PV         VG        Fmt  Attr PSize   PFree
  /dev/sda2  rootvg    lvm2 a--   95.50g   2.50g
  /dev/sdb   vgswap    lvm2 a--   48.00g      0
  /dev/sdc   cspappvg  lvm2 a--  256.00g 146.00g
  /dev/sdd   csplogvg  lvm2 a--   64.00g  54.00g
  /dev/sde   csparchvg lvm2 a--  128.00g      0
  /dev/sdf   cspdatavg lvm2 a--  256.00g 136.00g
  /dev/sdg   csparchvg lvm2 a--  256.00g      0
  /dev/sdh1  csparchvg lvm2 a--  256.00g 138.66g
  [unknown]  cspdatavg lvm2 a-m  256.00g 256.00g

[root@z0hqmcsdbap01 backup]# pvscan --cache
  pvscan[825131] PV /dev/sda2 online.
  pvscan[825131] PV /dev/sdb online.
  pvscan[825131] PV /dev/sdc online.
  pvscan[825131] PV /dev/sdd online.
  pvscan[825131] PV /dev/sde online.
  WARNING: Couldn't find device with uuid y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  pvscan[825131] PV /dev/sdf online.
  pvscan[825131] PV /dev/sdg online.
  pvscan[825131] PV /dev/sdh1 online.

[root@z0hqmcsdbap01 backup]# vgreduce cspdatavg --removemissing
  WARNING: Couldn't find device with uuid y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  WARNING: VG cspdatavg is missing PV y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  WARNING: Couldn't find device with uuid y1uI7X-HBWY-nTXI-mtcW-MgcH-qIud-ygZSa0.
  Wrote out consistent volume group cspdatavg.

---------------------------------------------------------------------------------------

ansible ILMT scan
ls -ltr /var/opt/ansible/GTS/ILMT/work/
/var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT <-- Script which needs to be run
cat /var/opt/ansible/GTS/ILMT/work/scanner_status.yml |grep -i true
ls -ltr /var/opt/ansible/GTS/ILMT/output

[09:17] Christophe Dentinger

# This file allows you for defining values of your custom computer properties.
# If the particular property was defined on the "Management: Computer Properties"
# panel, its value from this file will be displayed in the License Metric Tool
# server after the import of scan results data.
#
# Provide the properties in the YAML format, for example:
#
# Test Property 1: Property Value
AnsibleOrg: LBU

[09:18] Christophe Dentinger

this is likely the problem - the org IDs are in capital letters

[09:19] Christophe Dentinger

you will need to update those 2 files  to correct the org name in lower case

[09:20] Christophe Dentinger

/var/opt/ansible/GTS/ILMT/config/computer_properties.yml

/var/opt/ansible/GTS/CIT/work/computer_properties.yml

[09:20] Christophe Dentinger

then re-run SW scans:

[09:20] Christophe Dentinger

         /var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh
         /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT

[09:21] Christophe Dentinger

hopefully this should solve the problem


1- If problem reported is 'KO - Outdated scans' (Ansible fetch is recent but SW scans locally are older that 7 days), check first whether root password is expired,
	[root@aprlcdev ibmcokonkwo]# chage -l root
	Last password change                                    : May 08, 2022
	Password expires                                        : Aug 06, 2022
	Password inactive                                       : never
	Account expires                                         : never
	Minimum number of days between password change          : 1
	Maximum number of days between password change          : 90
	Number of days of warning before password expires       : 7
   if that is the case:
	1.1- Fix Expired root password
	1.2- Run HW & SW scans manually:
	     /var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh
	     /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT
	1.3- Either use Ansible playbook 'aic_cronjobs_update_linux' or move manually crontab instructions to Ansible user ID crontab to avoid this issue from re-appearing:
		1.3.1- needed to add "ansible" ID to /etc/cron.allow
		1.3.2- update of Ansible crontab with those instructions:
               		25,55 * * * * /usr/bin/sudo "/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh > /var/opt/ansible/GTS/ILMT/logs/crontab.log 2>/dev/null"
               		0 2 * * 6 /usr/bin/sudo /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT 2>/dev/null
		1.3.3- remove the instructions from root crontab (if present)
	Stop process here and check with requestor on next day whether 'outdated scans' problem is solved.

---------------------------------------------------------------------------------------------

Snapshots on VMWare Azure and AWS

On Vmware:

KB0018047 Linux: VMware Snapshot 
https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0018047

On Azure: 

KB0018602 - Azure VM Image Backup and Restore Process in a Recovery Services Vault
https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsys_kb_id%3Dbb1d97e21b16115048ea6394604bcb32

 On AWS: 

KB0018227 Take/delete Snapshot of VM (virtual machines) on AWS (Amazon Web Services)
https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0018227
-------------------------------------------------------------------------------------------------------

IMZ id locked, ping Vithawathi or ADINARAYANA MEDISHETTY or ma-infra-server and Senthil DS can help
ngage-ma-iam for IAM
------------------------------------------------------------------------------------------------------

To find the datastore is performance or endurance

Search the datastore and go to the summary tab
take the Foldername from there IBM02SV393684_220 in our case
IBM02SV393684_220/data01

open SL VPN go to Classic infrastructure storage->file storage and search for the datastore to find endurance or performance

----------------------------------------------------------------------------------------------------------------

Healthcheck remediation exclusions

without reboot option

comment all Non OS FS entries in fstab

for RHEL6 exclusion
-------------------
rhel6_cis_rule_6_1_10: false
rhel6_cis_rule_6_1_11: false

rhel8_cis_rule_6_1_10: false
rhel8_cis_rule_6_1_11: false


for Suse
sles_cis_rule_6_1_10: false
sles_cis_rule_6_1_11: false

add below rules to skip authorized_keys modification while executing CIS playbook(HC\VLU)
sles_cis_rule_AV_1_1_6:false
 
----------------------------------------------------------------------------------------------------------------------

Hello guys,


For those working data store tickets, please have in mind that if you migrate a VM from a DS to another, please inform Marcos Arroyo Vargas (marcos.arroyo.vargas@kyndryl.com) that you have migrated the VM because he needs to update the VCenters to clean up the space on the DS.

Something like


VM ctuboqr1af01

In VC wdc04 https://146.89.142.40/ui/

From WDC04POOL4POD4DSP599
To WDC04POOL4POD4DSP483



VM SAPPWR03

In VC wdc04 https://146.89.142.40/ui/

From WDC04POOL4POD4DSP599
To WDC04POOL4POD4DSP483

------------------------------------------------------------------------------------------------------------------------

Find and zip files older than x days
find . -mtime +365 -print -exec gzip {} \;

here the example is for 365 days or more

----------------------------------------------------------------------------------------------------------------------------
setting password policy explained in suse
https://forum.huawei.com/enterprise/en/the-way-to-change-password-complexity-settings-for-suse/thread/484619-881

--------------------------------------------------------------------------------------------------------------------------------
Human readable ls output
ls -lh

or 
ls --block-size=MB
ls --block-size=GB

k, M, G, and T suffixes (or no suffix for bytes) 


Troubleshooting IMZ login issues Linux · CMS/Platform-Support Wiki (kyndryl.net) 
https://github.kyndryl.net/CMS/Platform-Support/wiki/Troubleshooting-IMZ-login-issues---Linux

-----------------------------------------------------------------------------------------------------------

1.	For any support from the SAMUEL team during the change window, reach out to Teams channel- SAMUEL support and tag- SAMUEL_Patch_Support.


While doing the OS patching change review and approval, do run the OS, SAP pre-checks via SAMUEL, resolve issues and post the result link to the change log.

---------------------------------------------------------------------------------------------------------------------------------

Please go through the recorded training -   Training-New workflow template-13 Dec 2022-recording. Also refer to KB0017578 - SAP-Automation:  SAMU-UEL Patch OS – Full Workflow for more  details.

PLEASE NOTE - The change will automatically move from scheduled to implement status when the change window starts. Need to tag @SAMUEL_PATCH_SUPPORT in SAMUEL support teams channel for any help needed during the change window.( https://teams.microsoft.com/l/channel/19%3ad2034d6a8a1e499590d279b26b05bca7%40thread.tacv2/SAMUEL%2520Support?groupId=64bbd40c-a425-4fd9-afc6-67b6a3eb7ba7&tenantId=f260df36-bc43-424c-8f44-c85226657b01)

---------------------------------------------------------------------------------------------------------------------------------

1.	New Data Store / Extension Request 

Regarding data stores extension and creation request, we are working internally to find the best options for steady state teams to do the DS extensions\creations by ourselves. In the meantime, we have to do the following:

            a. First request to extend the DS to INFRA team

https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/issues

Example:
https://github.kyndryl.net/CMS/PhysInfra-Tribe-Tracker/issues/8262

b. Then, create another ticket to OPAAS team to update the information once INFRA has extended the DS. 

https://github.kyndryl.net/CMS/cms-opaas-api/issues/


2.	Virtual Machine Migration

When you migrate a VM from one DS to another, please proceed to send an email to marcos.arroyo.vargas@kyndryl.com or contact him via Teams informing about the migration performed.

------------------------------------------------------------------

Enable VMlogging and configure kdump if missing
Enable VM logging
https://kyndrylcsm.service-now.com/nav_to.do?uri=%2Fkb_view.do%3Fsysparm_article%3DKB0017982%26sysparm_stack%3D%26sysparm_view%3D

KB0015500 - SAP-Linux: SuSE Linux Kdump configuration

-------------------------------------------------------------------------------------------------------

to find who is logged in to any system run finger command

finger ibmrmalik on any linux

------------------------------------------------------------------------------------------------------------

For outdated pacemaker version upgrade and handle cluster maintenance
https://github.kyndryl.net/CMS/cms-sq-sap-hana-rr-hana_ha_documentation/blob/sairam_native_backup/Operations_Guide/A06_NZDClusterMaintenance_Manual.md


-----------------------------------------------------------------------------------------------------------------

Q] How to  add  swap  space  online  (without  downtime). If  you  want  to  extend  existing swap disk  then  need  downtime.
create a new swaplv in the vg and use that to mkswap and format as swap partition and only swapon to that lv

==>
1001  2023-02-01 12:11:39 pam_tally2 --reset
 1002  2023-02-01 12:11:43 chage -l root
 1003  2023-02-01 12:11:48 passwd root
 1004  2023-02-01 12:12:00 lsblk
 1005  2023-02-01 12:12:09 lsblk|grep -i swap
 1006  2023-02-01 12:12:14 vgs rootvg
 1007  2023-02-01 12:13:24 echo "- - -" | tee /sys/class/scsi_host/host*/scan
 1008  2023-02-01 12:13:38 lsblk
 1009  2023-02-01 12:13:42 vgs rootvg
 1010  2023-02-01 12:13:51 vgextend rootvg /dev/sdk
 1011  2023-02-01 12:13:55 vgs rootvg
 1012  2023-02-01 12:14:31 lvcreate -L 80G rootvg -n lvswap1
 1013  2023-02-01 12:14:41 lvdisplay |grep -i lvswap1
 1014  2023-02-01 12:14:46 mkswap /dev/rootvg/lvswap1
 1015  2023-02-01 12:14:49 free -gh
 1016  2023-02-01 12:14:55 swapon /dev/rootvg/lvswap1
 1017  2023-02-01 12:14:58 free -gh
 1018  2023-02-01 12:15:20 vi /etc/fstab
 
 --------------------------------------------------------------------------------------------------------------
yum repolist /yum check-update should respond with proper available redhat repo. If not getting the out put we should yum clean all;yum clean metadata; Then check whether again #yum repolist coming with proper repo.

-----------------------------------------------------------------------------------------------------------

add persistent routes via yast in Suse
The route can be added through yast2 lan ' in "Routing" via "Add" to "Routing Table", specifying option blackhole . Effectively it means the a line is added to /etc/sysconfig/network/routes or more specifically to /etc/sysconfig/network/ifroute- eth0 for interface eth0. 10.0.

https://superuser.com/questions/1534153/how-would-i-add-a-permanent-blackhole-route-in-sles-12#:~:text=The%20route%20can%20be%20added,ifroute%2D%20eth0%20for%20interface%20eth0.&text=10.0.,-0.1%20is%20the

-------------------------------------------------------------------------------------------------------------------

Works with RHEL 6.10

[root@WNXECCAPPD01 pam.d]$ passwd root
Changing password for user root.
passwd: Module is unknown

The following zypper is for fixing the issue when try to change password for local accounts:

# zypper in -y -f pam-config=1.1-1.43


replace the content of /etc/pam.d/system-auth with the below.

[root@WNXECCDBD01 ~]$ cat /etc/pam.d/system-auth
#%PAM-1.0
# This file is auto-generated.
# User changes will be destroyed the next time authconfig is run.
auth    required    pam_tally2.so deny=5 unlock_time=3600
auth        required      pam_env.so
#auth   required        pam_listfile.so item=user sense=deny file=/etc/security/serviceids onerr=succeed
auth        sufficient    pam_unix.so nullok try_first_pass
auth        requisite     pam_succeed_if.so uid >= 500 quiet
auth        sufficient    pam_sss.so use_first_pass
auth        required      pam_deny.so

account    required    pam_tally2.so
account required        pam_access.so
account     required      pam_unix.so
account     sufficient    pam_localuser.so
account     sufficient    pam_succeed_if.so uid < 500 quiet
account     [default=bad success=ok user_unknown=ignore] pam_sss.so
account     required      pam_permit.so

password    requisite     pam_cracklib.so try_first_pass retry=3 type= minlen=15 dcredit=-1 ucredit=0 lcredit=-1 ocredit=0 reject_username
password    sufficient    pam_unix.so shadow nullok try_first_pass use_authtok remember=8 sha512
password    sufficient    pam_sss.so use_authtok
password    required      pam_deny.so

session     optional      pam_keyinit.so revoke
session     required      pam_limits.so
session     optional      pam_oddjob_mkhomedir.so umask=0077
session     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid
session     required      pam_unix.so
session     optional      pam_sss.so



passwd: Authentication token manipulation error

try removing use_authtok from both /etc/pam.d/system-auth and password-auth

restart sshd service

-------------------------------------------------------------------------------------------------------------------------------

AWS Account :777019305455
Account Name: Home Control Singapore Pte Ltd – 
 ROLE: AWSCustomer-SAP-SupportTeams
Customer Code : HM8
           
SID	Host	IMZ	IFN
ECD CI             	eccci0dev  	10.198.2.10	172.28.28.10
ECD Hana DB  	hcsecchdb0dev	10.198.2.6	172.28.28.9
ECQ CI 	eccci0qas 	10.198.2.70	172.28.28.70
ECQ Hana DB        	hcsecchdb0dev	10.198.2.6	172.28.28
for Home Control (HC8).

Below Server is hosted in AWS Singapore DC . 
 
AWS Account :777019305455
Account Name: Home Control Singapore Pte Ltd – 
 ROLE: AWSCustomer-SAP-SupportTeams
Customer Code : HM8

SID	AWS VM	IFN	CFN
ECD CI	hm8eccci0dev	10.93.64.108	10.25.25.108
ECD Hana DB	hm8ecchdb0dev	10.93.64.107	10.25.25.117
ECQ CI	hm8eccci0qas 	10.93.64.52	10.25.25.12
ECQ Hana DB	hm8ecchdb0dev	10.93.64.107	10.25.25.117

-----------------------------------------------------------------------------------------

kdump automation script

def get_os_distribution():
    """Fetches the details of OS distribution"""
    try:
        exitcode, std_out, std_err = run_cmd('oslevel -s')
        os_distribution = ''
        if os.path.exists('/etc/redhat-release'):
            os_distribution = 'LINUX REDHAT'
        elif os.path.exists('/etc/SuSE-release'):
            os_distribution = 'LINUX SUSE'



/sds/sap/MSD_Software/SAP_Automation/Scripts/kdump/KdumpEnablement.py

kdump helper script generation wizard - https://access.redhat.com/labs/kdumphelper/wizard/

-------------------------------------------------------------------------------------------
Upgrade VM tools use automatic upgrade with below in advanced options to avoid reboot post upgrade

/s /v "/qn REBOOT=ReallySuppress"

----------------------------------------------------------------------------------------
To chk in btrfs filesystem: 
snapper list -a




Snapper utility
--------------

 

#btrfs subvolume list /
#snapper list -a
Create new snapshot
# snapper create --description "Snapshot for CHG0286147"
For files/directories changed between snapshot 309 and 312:
# snapper status 309..312
We can also show what files and directories have been changed from snapshot 312 going back to 309
# snapper status 312..309

 

To delete snapshot 314 for the default (root) configuration:
  # snapper delete 314
--------------------------------------------------------------------------------------------------

PingAck did not arrive in time
If you see 


Feb  8 14:16:14 br3pscmss46 ansible-ansible.legacy.command: Invoked with creates=None executable=None _uses_shell=True strip_empty_ends=True _raw_params=/sbin/ifdown all ; /sbin/ifup all removes=None argv=None warn=True chdir=None stdin_add_newline=True stdin=None
Feb  8 14:16:15 br3pscmss46 systemd[1]: Configuration file /etc/systemd/system/os_check.service is marked executable. Please remove executable permission bits. Proceeding anyway.
Feb  8 14:16:15 br3pscmss46 systemd[1]: Configuration file /etc/systemd/system/dsmcad.service is marked executable. Please remove executable permission bits. Proceeding anyway.
Feb  8 14:16:15 br3pscmss46 systemd[1]: Configuration file /usr/lib/systemd/system/smb-IMZCLOUD.service is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Feb  8 14:16:15 br3pscmss46 systemd[1]: Configuration file /usr/lib/systemd/system/besclient.service is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.697402] drbd r1 br3pscmss47: PingAck did not arrive in time.
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.697536] drbd r1 br3pscmss47: conn( Connected -> NetworkFailure ) peer( Secondary -> Unknown )
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.697541] drbd r1/0 drbd1 br3pscmss47: pdsk( UpToDate -> DUnknown ) repl( Established -> Off )
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.697565] drbd r1 br3pscmss47: ack_receiver terminated
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.697567] drbd r1 br3pscmss47: Terminating ack_recv thread
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.734575] drbd r1/0 drbd1: new current UUID: 35A7D080260280B7 weak: FFFFFFFFFFFFFFFE
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.736137] drbd r1 br3pscmss47: Connection closed
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.736247] drbd r1 br3pscmss47: conn( NetworkFailure -> Unconnected )
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.736257] drbd r1 br3pscmss47: Restarting receiver thread
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.736262] drbd r1 br3pscmss47: conn( Unconnected -> Connecting )
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.736286] drbd r1 tcp:br3pscmss47: bind before listen failed, err = -99
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.736357] drbd r1 br3pscmss47: Failed to initiate connection, err=-99
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.736372] drbd r1 br3pscmss47: conn( Connecting -> Disconnecting )
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.737277] drbd r1 br3pscmss47: Connection closed
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.737387] drbd r1 br3pscmss47: conn( Disconnecting -> StandAlone )
Feb  8 14:16:18 br3pscmss46 kernel: [7734898.737392] drbd r1 br3pscmss47: Terminating receiver thread

---------------------------------------------------------------------------------------------------------------------


[root@gknpeccprddb pacemaker_validation]$ csync2 -xv
Marking file as dirty: /etc/drbd.d/global_common.conf
Marking file as dirty: /etc/drbd.conf
Marking file as dirty: /etc/corosync/corosync.conf
Connecting to host gknpeccprddbh (SSL) ...
Connect to 10.255.80.165:30865 (gknpeccprddbh).
Updating /etc/corosync/corosync.conf on gknpeccprddbh ...
File is already up to date on peer.
Updating /etc/drbd.conf on gknpeccprddbh ...
File is already up to date on peer.
Updating /etc/drbd.d/global_common.conf on gknpeccprddbh ...
Updating /etc/samba/smb.conf on gknpeccprddbh ...
File stays in dirty state. Try again later...
Connection closed.
Finished with 1 errors.

--------------------------------------------------------------------------------------------------

Relax and recover Configuration (REAR) steps:
https://github.kyndryl.net/CMS/BuildMigration/wiki/Rear-Configuration-steps

https://github.kyndryl.net/CMS/BuildMigration/wiki/ReaR-Backup




----------------------------------------------------------------------------------------------

message logs, cron and secure logs not getting generated
https://access.redhat.com/solutions/3094721

--------------------------------------------------------------------------------------------------
COmment fstab for HC
Commenting  multiple lines of fstab

to comment lines 2 through 4 of bla.conf:
sed -i '2,4 s/^/#/' ip.txt

to uncomment
sed -i '/'#'/s/^#//g' ip.txt	working to uncomment



sed -i '11,23 s/^/#/' /etc/fstab      # comments lines 11 to 23 in fstab

to uncomment

sed -i '11,23 /s/^#//g' file

Yes, to comment line containing specific string with sed, simply do:

sed -i '/<pattern>/s/^/#/g' file
And to uncomment it:

sed -i '/<pattern>/s/^#//g' file
In your case:

sed -i '/2001/s/^/#/g' file    (to comment out)
sed -i '/2001/s/^#//g' file    (to uncomment)


---------------------------------------------------------------------------------------------------------------------------

Health check  Hugepage error
OS validation v1.180 executed time : February 24, 2023 06:52:06 (Refer to KB0016944 for remediation steps)
 SAR is not active in OS
 Current state is "[always] madvise never". Expected result is to disable THP
 
 -----------------------------------------------------------------------------------------------------------------------------
 
 Using screen for gaining access to any disconnected session
 
 screen -S RaviM     # RaviM could be any name for referring to the session
 
 to get back the sesssion
[root@bapv110100 ~]# screen -list
There are screens on:
        128135.RaviM    (Attached)
        107347.RaviM    (Attached)
2 Sockets in /var/run/screens/S-root.


to connect to any session use
screen -x 128135.RaviM    # name from the output above
-----------------------------------------------------------------------------------------------------------------------------

To set the latest version of python use below:

#python -V
#ls -l /usr/bin/python* --> to check if we have other(new) versions
#rm -rf /tmp/Python* 2>/dev/null --> to delete python version 2
#rm -f /usr/bin/python && ln -s /usr/bin/python3 /usr/bin/python 

in SUSE 12

[root@br3qgtsdb37 ~]$ rm /usr/bin/python3
[root@br3qgtsdb37 ~]$ ln -s /usr/local/python3/bin/python3.6 /usr/bin/python3


Ensure python is at the latest version
Check zypper locks/rhel 8 lock at 8.2

--------------------------------------------------------------------------------------------------------------

crons and message files not getting logged ,

check /etc/rsyslog and replace with older one /newer one if the existing is not working. restart rsyslog service and chk
----------------------------------------------------------------------------------------------------------------

nw team contact
Jayabal D   // Zubair mohammad1 // ramanujam.sakthivel@kyndryl.com
COMPANY:                  Internal Infrastructure -- CCP
Assignment Group:    MA-ASGN-INF-3x-SEI-NWK-FW
Network Incidents to ma-3x-nets-incidents
--------------------------------------------------------------------------------------------------------
 For SUSE Upgrade/Patch, check the connection with SMT:

# SUSEConnect -s → Status must be “Registered”

[root@mm3fiufd001 ~]# SUSEConnect -s
[{"identifier":"SLES_SAP","version":"12.4","arch":"x86_64","status":"Registered"}]

# cat /etc/SUSEConnect → Must be pointing to correct SMT: <DC_Name>AMMSMT01

[root@mm3fiufd001 ~]# cat /etc/SUSEConnect
---
insecure: false
url: https://DAL09AMMSMT01.imzcloud.ibmammsap.local/center/regsvc
language: POSIX


For Red Hat Upgrade/Patch, check the connection with the satellite:

# subscription-manager status → Overall Status must be: Current

[root@trecsdevdbap ~]# subscription-manager status
+-------------------------------------------+
   System Status Details
+-------------------------------------------+
Overall Status: Current


To Patch RHEL 8.X make sure to have release --set=8.6
[root@acerosdevhana ibmgmorales]$ subscription-manager release --show
Release not set
[root@acerosdevhana ibmgmorales]$ subscription-manager release --set=8.2
Release set to: 8.6
[root@acerosdevhana ibmgmorales]$ subscription-manager release --show
Release: 8.6

--------------------------------------------------------------------------------------------------------------------------------------

What to Do When Approval Cannot be Granted
If any of the items described above is missing or  if information is missing, proceed to add an internal note in the change (not in CTASKs) with missing details. 

Here an example:

This change cannot be approved for the following reasons:

There is no engineer assigned to change in header. Please assign the corresponding engineer before requesting approval.

The description of the change is not clear. Please make all corrections in description before requesting approval.

The change is scheduled for a long maintenance window which probably requires engineers from all regions (EMEA, AP & AG. There is no indication if OS/SAP engineers are required from other regions. That must be included in the change notes. If engineers are required, an email must be sent to corresponding DL "SQ-SAP-TRIO-B# Resource Request". If not required, please add a note in the change notes indicating the corresponding coverage.

The Affected CIs in the change does not match with the CIs in the description of Change/CTASK######. Please add missing CIs or add a note in the change notes with details about why CIs do not matches.

There are CTASKs missing the assigned engineer. Please add the corresponding engineer before requesting approval.

There is no CTASK for SAP in order to validate applications and/or database. It is required. Please create a new CTASK for SAP engineer (Group MA-ASGN-SAP-SAP).

The CTASK###### does not have a clear build plan of what exact work the OS engineer must perform. If help is needed to get the correct build plan, please open a Service Request and post it on corresponding channels "sq-sap-trio-b#" or "sq-sap-trio-a#" to get an SME provide the build plan.

The SAMUEL precheck is reporting failures. We have to fix them before approval.

---------------------------------------------------------------------------------------------------------------------------------------
For IA change approvals, special check for RHEL OS is locked at 8.2

Available packages
Updating Subscription Management repositories.

This system is registered to Red Hat Subscription Management, but is not receiving updates. You can use subscription-manager to assign subscriptions.

if above error then fix it first


contact Roland Rebstock for help
-----------------------------------------------------------------------------------------------------------------------------------------
Samuel precheck fail error in DB start

DB error in prechecks, PDL to check once before the change:-
"stdout_lines": ["", "Running 'test_db_password.sh' script..", "", "Creating SQL test script..", "", "Decrypting password..", "", "ERROR: Missing encrypted password. Please check the password entered in the Ops Portal.", "For more info, please check: https://w3.ibm.com/w3publisher/sapops/blog/7f487be0-fa82-11e9-b590-0b4c9f47a60d",

There was an issue with our public key fetching that is currently being addressed, and I have added the keys for the three failing servers manually. Would you mind retrying the requests? (reselect and make a new request)

--------------------------------------------------------------------------------------------------------------

RHEL 6 to 8
https://github.kyndryl.net/CMS/BuildMigration/wiki

https://github.kyndryl.net/CMS/BuildMigration/wiki/RHEL6-to-RHEL-7-Upgrade-Steps

https://github.kyndryl.net/CMS/BuildMigration/wiki/Inplace-upgrade-RHEL7-to-RHEL8

--------------------------------------------------------------------------------------------------------------

Job pacemaker.service/start failed with result 'dependency'.

Job corosync.service/start failed with result 'dependency'.

 cat /etc/sysconfig/sbd |grep -i device
# SBD_DEVICE specifies the devices to use for exchanging sbd messages
#SBD_DEVICE=""
# Watchdog device to use. If set to /dev/null, no watchdog device will
# This depends mostly on your storage latency; the majority of devices
# If your sbd device(s) reside on a multipath setup or iSCSI, this
SBD_DEVICE=/dev/mapper/sbddisk1


[root@hfchbphndb1vh ~]# sbd -d /dev/mapper/sbddisk1  message LOCAL clear

start pacemaker

---------------------------------------------------------------------------------------------------------------------

Manual precheck run

echo ========================= HOSTNAME =========================;hostname;echo ========================= OS RELEASE =========================; egrep -i 'red|SuSE'  /etc/*-release;echo ========================= KERNEL VERSION =========================; uname -a;echo ========================= DATE =========================;date;echo ========================= TIME ZONE CONFIG =========================;cat /etc/sysconfig/clock; /usr/bin/timedatectl; echo ========================= FILE SYSTEM READ WRITE STATUS =========================;grep -P "\sro[\s,]" /proc/mounts;echo ========================= MOUNTED FILE SYSTEM =========================;df -hT; echo ========================= /proc/mounts =========================; cat /proc/mounts; echo ========================= FSTAB ENTRIES =========================;cat /etc/fstab;echo ========================= EXPORTS FILE =========================; cat /etc/exports; echo ========================= SERVER IP =========================;ifconfig -a ;echo =========================; echo ========================= Routes =========================;netstat -rn; echo ========================= ROOT PASSWORD STATUS =========================;chage -l root;echo ========================= HOST FILE ENTRIES =========================;cat /etc/hosts;echo ========================= EXPORTS OUTPUT  =========================;cat /etc/exports;echo ========================= PHYSICAL VOLUME =========================;pvs;echo ========================= VOLUME GROUP =========================;vgs;echo ========================= LOGICAL VOLUME =========================;lvs; echo ========================= VGDISPLAY -V; vgdisplay -v;  echo ========================= CLUSTER info ==============; crm_mon -1Afr;  echo ========================= MEM and SWAP usage ================; free -h; swapon -s ============= SCSI Devices =====; lsscsi==========; echo ========================= NFS SHARES =========================; df -t nfs; grep nfs /etc/fstab; echo ========================= ROUTES =========================; netstat -rn; echo ========================= INTERFACES configuration=========================; ifconfig -a; cat /etc/sysconfig/network-scripts/ifcfg-*; echo ========================= KERNEL parameters, please see /tmp/kernel-parameters file=========================; sysctl -a  >> /tmp/kernel-parameters ; echo ========================= SSD conectivity =========================;service sssd status; systemctl list-unit-files --all |grep -l ssd; chkconfig --list |grep -l sssd ; echo ========================= UUID =========================; blkid; echo =========================/etc/hosts file =========================; cat /etc/hosts;echo ========================= REPOS status========================= ;  yum clean all; yum repolist; echo ========================= FS NOT mounted =========================; for i in $(grep -v ^# /etc/fstab | awk {'print $2'} | sort | grep -v ^swap$ ); do mountpoint -q $i || echo "$i   NOT mounted" ; done



rpm -qa --queryformat '%{NAME}\n' > installed-software.bak
systemctl --type=service |egrep -e "cups.service|vsftpd.service|postfix.service|dnsmasq.service"

cp /etc/security/limits.conf  backup

---------------------------------------------------------------------------------------------------------------------------------------

Near zero downtime patching  NZDT

HANA Node
					1	Standby the primary node
 	 	 	 	 	2	Perform Actvity on HANA primary ( Both OS patching and CIS remediation)
 	 	 	 	 	3	Attach back the Primary node back to cluster ( set the node back  online)
 	 	 	 	 	4	Wait for the HSR Sync
 	 	 	 	 	5	Set HA node standby
 	 	 	 	 	6	Perform Actvity on HANA HAN node ( Both OS patching and CIS remediation)
 	 	 	 	 	7	HSR registration
 	 	 	 	 	8	Attach back the HA node back to cluster ( set the node back  online)
 	 	 	 	 	9	Wait for the HSR Sync

App servers:
					1	Standby the ASCS node (primary node)	6 hours
 	 	 	 	 	2	Complete OS activities
 	 	 	 	 	3	Attach back the node by keeping it online
 	 	 	 	 	4	wait for the automatic ERS failover (ERS will be on the patched node)
 	 	 	 	 	5	Standby of HA node
 	 	 	 	 	6	Complete OS activities	 
 	 	 	 	 	7	Attach back the node by keeping it online	 
 	 	 	 	 	8	wait for the automatic ERS failover (ERS will be on the patched node)


	 	 	 	 	 	 
 	 	 	 	 	 	crm node standby node	 
 	 	 	 	 	 	crm node online node



For HANA


we should comment crontab entry that gets added to crontab post HC that will change permission under /var/log 

Hana cluster server:-
After Health check file permissions was changed 
#/var/log/HDBHA/  ==> all files/directory should be 755

#/var/log/HDBHA/state_monitor/state_monitor.log ==> should be 755

make a note of this, after HC for Hana server, we need to set this permissions otherwise we can;t start Hana 



Put cluster in unmanaged mode
SAP breaks replication and hands over to OS
put back the cluster in managed
OS to put the secondary cluster to standby so all resources move to primary and apps/db continue to run
stop pacemaker on the secondary node to be patched.
do a sanity reboot
chk if pacemaker service is auto started stop and disable auto start of service
patch the server and do ds agent, kdump etc and reboot
post validation by OS and then HO to SAP to replicate from primary to seconday
once above is done, put the cluster back to online and after confirmation failover the db/app from primary to patched secondary(make primary to standby so the patched secondary becomes primary) so as to vacate the original primary for patching.
now the patched secondary is primary and the original primary is secondary and available for patching.
DO the same steps as above to patch the second node.

---------------------------------------------------------------------------------------------------------------

configuring Azure recovery vault

https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsys_kb_id%3Dbb1d97e21b16115048ea6394604bcb32


----------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------------------------------------------

General Team, Mexico has stopped following daylight savings, and we will have to install tzdata package on RHEL servers to change timezone from CDT to CST.
 


yum update tzdata tzdata-java

-------------------------------------------------------------------------------------------------------------

Netcool team channel for no clear event recd

engage-evtmgmt-netcool

--------------------------------------------------------------------------------------------------------------

OS offerings in 3x and hyperscalers..

OS Support Image Matrix Enabled by the Orchestration Tribe · CMS/Platform-Support Wiki (kyndryl.net)
https://github.kyndryl.net/CMS/Platform-Support/wiki/OS-Support-Image-Matrix-Enabled-by-the-Orchestration-Tribe

----------------------------------------------------------------------------------------------------------------
Health Check\Vulnerability remediation from Samuel - Known issues:


1. Python version error - Make sure the python version is 2.7 or SLES12, and 3.6 for SLES15

2. Cryptography error - Install the python cryptography package "zypper in python3-cryptography"

3. THP (Transparent huge pages) error - Make sure to disable THP (steps can be found in KB KB0016944 - page no 38 in the attachment)

4. "btrfs command not found" error - Make sure the env variable for btrfs in grun.cfg is set"
    # echo $btrfs_relative_path (if the path is empty, set using below command)
    # export btrfs_relative_path=/usr/sbin/btrfs
    
5. Auditd deamon error - Make sure the auditd service is started, if not, enable the server and reboot the server 
    # systemctl enable auditd
	
	-------------------------------------------------------------------------------------------------------------
	
	b. On servers running RHEL 7 or SUSE 12 upwards, set the default gnome target to multi-user.

# systemctl get-default
graphical.target

# systemctl set-default multi-user.target

# systemctl isolate multi-user.target

# systemctl get-default 
multi-user.target
----------------------------------------------------------------------------------------------------------------------
Check NFS version on any LInux box


Check NFS server version using nfsstat command. Nfsstat command can be used as follows. nfsstat –s. -s : Print only server-side statistics. ...
Find NFS client version. This can be found as follows. nfsstat –c. -c, --client : Print only client-side statistics

------------------------------------------------------------------------------------------------------

IMZ login issue

OS AMM parameter was there in sass.conf, commented and restarted ghetto service to fix

------------------------------------------------------------------------------------------------------------------------

To unmount the filesystem you can use the commands lsof or fuser to find out what is using the filesystem, then you can kill the process in question, to unmount the filesystem.

lsof mount_point

fuser mount_point

---------------------------------------------------------------------------------------------------------------------

RHEL patching for RHEL 8.x-1

You can now go to RHEL 8.6 but:

lock the repo with 8.6.
#subscription-manager release --set=8.6

https://github.kyndryl.net/CMS/BuildMigration/wiki/Inplace-upgrade-RHEL7-to-RHEL8

If currently locked with 8.2, release and lock with 8.6 and patch the servers

Important note: Currently the RHEL repo is having 8.7 as latest. So, when patching RHEL8, please make sure to lock the version to 8.6 and then do "yum update"

#subscription-manager release --set=8.6

#subscription-manager release =================> to validate 

Also, if you find any servers with 8.7, please collect those details and share it here

RHEL registration RHEL 8 

subscription-manager status  
+-------------------------------------------+  
   System Status Details  
+-------------------------------------------+  
Overall Status: Current  
Show attached subscriptions

subscription-manager list --consumed

2. subscription-manager unregister
3. subscription-manager clean
rpm -qa|grep katello-ca-consumer
rpm -e katello-ca-consumer
4. rpm -iv http://sng01ammcaps002.imzcloud.ibmammsap.local/pub/katello-ca-consumer-latest.noarch.rpm  (uninstall and install again if required)
5) subscription-manager register --org="IBM_Managed_Applications" --activationkey="FMS3.x Daily Repos"
6. subscription-manager repos --enable "*"
7. yum clean all; yum clean metadata
8. checf-client
9. yum check-update
Important -  The 5th step will be different based on the OS version 
RHEL6 is EOL, only 1 key
-----------
subscription-manager register --org="IBM_Managed_Applications" --activationkey="FMS3.x Daily Repos"
RHEL7-
----------
Servers that are SAP  should be using the following Activation Key 
subscription-manager register --org="IBM_Managed_Applications" --activationkey="RHEL7 SAPApps Daily"
Servers that are SAP Hana should be using the following Activation Key
subscription-manager register --org="IBM_Managed_Applications" --activationkey="RHEL 7 SAP Hana Daily" 
Servers that are SAP  should be using the following Activation Key (Quarterly locked repo has to be used for OS patching)
subscription-manager register --org="IBM_Managed_Applications" --activationkey="RHEL7 SAP Hana Quarterly"
Servers that are SAP Hana should be using the following Activation Key (Quarterly locked repo has to be used for OS patching)
subscription-manager register --org="IBM_Managed_Applications" --activationkey="RHEL7 SAP Quarterly"
RHEL 8 
------------
Servers that are SAP  should be using the following Activation Key 
subscription-manager register --org="IBM_Managed_Applications" --activationkey="RHEL82SAPAPPS"
Servers that are SAP Hana should be using the following Activation Key
subscription-manager register --org="IBM_Managed_Applications" --activationkey="RHEL82SAPHANA"

-------------------------------------------------------------------------------------------------------

Validate HC b4 change approval

first  filter with    open NCI and blank
then  in  "kb number  " column  uncheck  cis  playbook  options
then  go  to  solutions  column and see  which one we  can  manually remediate
create  list of that

column c(severity-compliance)  
p(disposition type- select blanks leaving nci and pram) 
then filter F column for OS type and work on one OS at a time and 
COlumn D installed status only not decom or WIP etc
w column filter all that does not say remediates by CIS playbook
am column solution field


------------------------------------------------------------------------------------------------------

Interrupt the GRUB menu - select first option 4.18.0-305.25.1.el8_4.x86_64
Type 'e' to edit parameters 

GRUB PASSWORD 
username: root
password: Passw0rd   ---> 0 instead of o

1) add rd.break to the end of the line that starts with linux:				rd.break,  single, or init=/bin/bash
2) when the system boots, run the following command to remount the root filesystem in read-write mode:
mount -o remount,rw /sysroot

3) then run:
chroot /sysroot

4) change root password:
passwd   ---> recommended: CHANGE@kyndryl1 

5) instruct SELinux to relabel all files upon reboot:
touch /.autorelabel

Note that this may take some time during the next boot.

6) type exit to leave the chroot environment.
7) type exit to log out, note this will also reboot the system.



Reset the vm from vCenter VM Power options

Interrupt the GRUB menu - select first option 4.18.0-305.25.1.el8_4.x86_64
Type Enter 

3 - POSTSNAP 

Reference: KB0017225 SAP-Automation: Pre & Post Checks & Snaps from SAM-UEL



simple_allow_groups = AMM - OSLINUX Support (Global)

-------------------------------------------------------------------------------------------------

Zypper patching related commands
https://www.thegeekstuff.com/2015/04/zypper-examples/

--------------------------------------------------------------------------------------------
Putting individual resources in maintenance

1. Put entire cluster to maintenance mode using crm maintenance on
2. Put msl and ip resources to maintenance mode using below commands crm resource maintenance <msl resource> and crm resource maintenance <ip resource>
3. Validate the cluster status
4.  Stop cluster on both the nodes using crm cluster stop command first on secondary and then on primary node.
5. Perform validation on Hana database/application/replication after cluster has been stopped on both nodes.
6. Perform vMotion
7.  Perform validation on Hana database/application/replication after  VM vMotion task has been completed.
8.  Once done start the cluster on both the nodes using crm cluster start first on primary and then on secondary node.
9. Validate the Cluster state
10.a.  Ensure SAP Engineer is monitoring the system when maintenance mode is being removed.
10.b. Remove cluster from maintenance mode using crm maintenance off
10.c.  SAP Engineer - Validate DBs are running fine on both nodes and have not been restarted.
11. Refresh cln and msl resources
12. . Maker sure hana_<sid>_roles : 4:P:master1:master:worker:master attribute is present in the promoted node attirbutes and Set maintenance off on multi state resource and then on ip resource.
13. Remove msl and ip resources from maintenance mode using below commands crm resource maintenance <msl resource> false and crm resource maintenance <ip resource> false
14. verify the cluster status
15. Perform a final verification on Hana database/application & replication status.

------------------------------------------------------------------------------------------------------------

Display all didks attached in a VG

pvdisplay -C --separator '  |  ' -o pv_name,vg_name |grep -i zepdatavg

------------------------------------------------------------------------------------------------------------
Hana Cluster Maintenance Procedure Manual

https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsys_kb_id%3D21433aa747562d1098ccecff336d4399



pHANA SUSE upgrade NFS location to Chennai ISO template datastore
10.200.30.167:/IBM02SEV393684_318/data01/SLE-15-SP2-Full-x86_64-GM-Media.iso

Delve update profile
https://nam.delve.office.com/?u=f24cb0ab-8865-423e-aee3-e722f1427400&v=work

Delve is sunset which means it is no longer used for profile or contact details updating. I would recommend you reach out to drmshelp@us.ibm.com. Also, you can check with the IT team along with DRMS. Details have been shared below:
 
Contact via AskIT - Home (sharepoint.com) or below numbers.
India	
+91-80-4177-4888 (Toll)

+91-20-4011-5888 (Toll)

1-800-120-596-379 (Toll Free)



scsi mapping
[root@pn8us7leccp6 ~]# cat /proc/scsi/scsi
Attached devices:
Host: scsi0 Channel: 00 Id: 00 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi0 Channel: 00 Id: 01 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi0 Channel: 00 Id: 02 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi0 Channel: 00 Id: 03 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi0 Channel: 00 Id: 05 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi0 Channel: 00 Id: 08 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi0 Channel: 00 Id: 11 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi3 Channel: 00 Id: 00 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi3 Channel: 00 Id: 11 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi4 Channel: 00 Id: 00 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi4 Channel: 00 Id: 05 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi4 Channel: 00 Id: 11 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi3 Channel: 00 Id: 05 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02


controller 0,2 3 4 etc


/dev/sdk   cp6datavg   lvm2 a--  243.00g  243.00g	[3:0:5:0]    in the above is 
Host: scsi3 Channel: 00 Id: 05 Lun: 00
  Vendor: VMware   Model: Virtual disk     Rev: 1.0
  Type:   Direct-Access                    ANSI  SCSI revision: 02
  
  in VC Host: scsi3  will be 1 and Id: 05 means 5 so find the disk with 1:5
  
  host scsi0 is 0
  scsi3 is 1
  scsi4 is 2 and so on
  
  
  
  Please perform the following task during the change window

-Activate vmlogging ( https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0017982 )
-Unmount /sds PERMANENTLY after patching (https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0019647 )



Check LV allocation:
Use the lvs command to check which LVs are allocated on the PV you want to remove:

lvs -o +devices
This will show you the LVs and the PVs they are currently located on.


Old df -hT output to compare.

[root@xxxxxxx pre]# ls -l pre_filesystems.txt
-rwxr-xr-x 1 root root 1065 Jul 16 00:00 pre_filesystems.txt
[root@xxxxxx pre]# pwd
/usr/local/sap/log/pre



lvs -o +devices|grep  db2_YC4_log_dir_lv


Intake form for HC

column c(severity-compliance)  
p(disposition type- select all except PRAM) 
then filter F column for OS type and work on one OS at a time and 
COlumn D installed status only not decom or WIP etc
w column filter all that does not say remediates by CIS playbook
am column solution field


first  filter with    open NCI and blank
then  in  "kb number  " column  uncheck  cis  playbook  options
then  go  to  solutions  column and see  which one we  can  manually remediate
create  list of that

 
WIn+shift+s for capturing screenshot with details coming with hovering mouse
-------------------------------------------------------------------------------------------------

Post HC HANA server get a cronjob that changes var/log permission

Hana cluster server:-
After Health check file permissions was changed 
#/var/log/HDBHA/  ==> all files/directory should be 755

#/var/log/HDBHA/state_monitor/state_monitor.log ==> should be 755

make a note of this, after HC for Hana server, we need to set this permissions otherwise we can;t start Hana

*/10 * * * * find /var/log/* -type f -exec chmod g-wx,o-rwx '{}' + -o -type d -not -path /var/log/hist -not -path /var/log/sssd -exec chmod g-wx,o-rwx '{}' +

---------------------------------------------------------------------------------------------------

lsblk to find the disk to remove
blkid /dev/sdX to see if its part of any LVM
if it is then check pvdisplay -m /sdX to see if the disk is completely free and all Allocated PE shows 0
proceed to removing the PV from the VG : vgreduce [volume group] [physical volume]
remove the disk as pv :pvremove /dev/sdX
Run lsscsi to find the mapping for the disk to remove to get the ref for VC
Then remove the disk from the server first with 
echo "1" > /sys/block/sdX/device/delete
Carefully revalidate the disk no and scsi id as scsi id may change but the disk no stays same. AFter identifying, delete the disk from VC
ALso check for replication vi SRM, if configured, remove the deleted disk form there too



Aws -- unwanted disk removal when we have only one LV on one PV.

1. As per the ticket summary, comment the FS
2. umount the fs  (check if that is only one FS on the disk ) then only we can reclaim the disk . other wise, may not possible
3. make a note of disk and remove the vg and lv which is not required
4. Now the PV is free of vg/LV, use pvremove to remove the PV from LVM
5. use samuel to select and delete the disk.
----------------------------------------------------------------------------------------------------------

oscar tickets

/usr/bin/python /usr/local/sap/scripts/os_check_and_fix_v1.0.py

---------------------------------------------------------------------------------------------------

Ansible software scans

Possibly move SW scans instructions to ansible user ID crontab to avoid this problem in the future:
1- needed to add "ansible" ID to /etc/cron.allow
2- update of Ansible crontab with those instructions:
25,55 * * * * /usr/bin/sudo "/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh" > /var/opt/ansible/GTS/ILMT/logs/crontab.log 2>/dev/null
0 2 * * 6 /usr/bin/sudo /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT 2>/dev/null
3- remove the instructions from root crontab (if present)

manual scan pls just run /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT

software version check
cat /var/opt/ansible/GTS/ILMT/work/computer.yml

1- Fix Expired root password
	2- Run HW & SW scans manually:
	      /var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh
	     /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT
		 cat /var/opt/ansible/GTS/ILMT/work/scanner_status.yml |grep -i true
		ls -ltr /var/opt/ansible/GTS/ILMT/output
	3- Move crontab instructions to Ansible user ID crontab to avoid this issue from re-appearing:
	3.1- needed to add "ansible" ID to /etc/cron.allow
	3.2- update of Ansible crontab with those instructions:
25,55 * * * * /usr/bin/sudo "/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh" > /var/opt/ansible/GTS/ILMT/logs/crontab.log 2>/dev/null
0 2 * * 6 /usr/bin/sudo /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT 2>/dev/null
3.3- remove the instructions from root crontab (if present)
/var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT


ls -ltr /var/opt/ansible/GTS/ILMT/work/
/var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT <-- Script which needs to be run
cat /var/opt/ansible/GTS/ILMT/work/scanner_status.yml |grep -i true
ls -ltr /var/opt/ansible/GTS/ILMT/output



AnsibleOrg: LBU

this is likely the problem - the org IDs are in capital letters

you will need to update those 2 files :

/var/opt/ansible/GTS/ILMT/config/computer_properties.yml

/var/opt/ansible/GTS/CIT/work/computer_properties.yml

then re-run SW scans:

         /var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh
         /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT

hopefully this should solve the problem
----------------------------------------------------------------------------------------------------


 systemctl status
 
 [root@azlbwpapp01 ~]# systemctl status
● azlbwpapp01
    State: degraded
     Jobs: 0 queued
   Failed: 5 units
    Since: Sat 2023-04-22 22:27:31 CDT; 3 months 9 days ago
   CGroup: /
           ├─user.slice
           │ ├─user-193780.slice
           │ │ ├─user@193780.service
           │ │ │ └─init.scope
           │ │ │   ├─2326083 /usr/lib/syst
		   
		   
[root@azlbwpapp01 ~]# systemctl --failed
  UNIT                          LOAD   ACTIVE SUB    DESCRIPTION
● ds_agent.service              loaded failed failed LSB: Trend Micro Deep Security Agent
● logrotate.service             loaded failed failed Rotate log files
● rpc-svcgssd.service           loaded failed failed RPC security service for NFS server
● smb-IMZCLOUD.service          loaded failed failed Samba SMB Daemon
● suseconnect-keepalive.service loaded failed failed Run SUSEConnect --keepalive

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

5 loaded units listed. Pass --all to see loaded but inactive units, too.
To show all installed unit files use 'systemctl list-unit-files'.
[root@azlbwpapp01 ~]#


Normally, you'll need to read the journal/log to figure out what to do next about that failing item, by using journalctl -xe. If you just want to reset the units so the system "says" running with a green dot, you can run:

systemctl reset-failed

----------------------------------------------------------------------------------------------------------------------------------

extend an existing disk for a server and then extending VG and LV

Pause the replication
cluster in maintenace mode
Extend the disk in VC
rescan the disk  with echo 1 > /sys/block/sdX/device/rescan
use pvresize to increase the PV pvresize /dev/sdf
fdisk -l /dev/sdf
pvresize /dev/sdX  it updates the VG also
pvscan |grep -i prdappvg

 1002  2023-08-03 21:04:43 crm status
 1003  2023-08-03 21:04:49 crm configure property maintenance-mode=true
 1004  2023-08-03 21:04:53 crm status
 1005  2023-08-03 21:04:59 crm_mon -1Afr
 1006  2023-08-03 21:07:21 free -gh
 1007  2023-08-03 21:07:31 lscpu |grep -i cpu
 1008  2023-08-03 21:08:57 df -hT /usr/sap/PRD
 1009  2023-08-03 21:09:26 vgs prdappvg
 1010  2023-08-03 21:10:32 lvscan |grep -i prdappvg
 1011  2023-08-03 21:10:42 lsblk
 1012  2023-08-03 21:11:04 pvscan |grep -i prdappvg
 1013  2023-08-03 21:11:12 lsscsi sdf
 1014  2023-08-03 21:11:20 lsscsi |grep -i sdf
 1015  2023-08-03 21:15:06 echo "- - -" | tee /sys/class/scsi_host/host*/scan
 1016  2023-08-03 21:15:23 pvs |grep -i sdf
 1017  2023-08-03 21:16:21 echo 1 > /sys/block/sdf/device/rescan
 1018  2023-08-03 21:16:34 fdisk -l /dev/sdf
 1019  2023-08-03 21:16:54 pvresize /dev/sdf
 1020  2023-08-03 21:17:24 pvscan |grep -i prdappvg
 1021  2023-08-03 21:17:31 pvs
 1022  2023-08-03 21:18:39 df -hT /usr/sap/PRD
 1023  2023-08-03 21:18:54 lvextend -L +250G -r /dev/mapper/prdappvg-usrsapsid_lv
 1024  2023-08-03 21:18:58 df -hT /usr/sap/PRD



959  2023-08-03 21:09:51 vgs prdappvg
  960  2023-08-03 21:10:12 lvscan |grep -i prdappvg
  961  2023-08-03 21:13:16 pvscan |grep -i prdappvg
  962  2023-08-03 21:13:26 lsscsi |grep -i /dev/sdf
  963  2023-08-03 21:13:54 pvs
  964  2023-08-03 21:15:06 echo "- - -" | tee /sys/class/scsi_host/host*/scan
  965  2023-08-03 21:15:23 pvs |grep -i sdf
  966  2023-08-03 21:16:21 echo 1 > /sys/block/sdf/device/rescan
  967  2023-08-03 21:16:34 fdisk -l /dev/sdf
  968  2023-08-03 21:16:54 pvresize /dev/sdf
  969  2023-08-03 21:17:24 pvscan |grep -i prdappvg
  970  2023-08-03 21:17:31 pvs
  971  2023-08-03 21:17:55 df -hT /usr/sap/PRD
  972  2023-08-03 21:18:07 lvextend -L +250G /dev/mapper/prdappvg-usrsapsid_lv
  973  2023-08-03 21:18:18 xfs_growfs /usr/sap/PRD
  974  2023-08-03 21:18:23 df -hT /usr/sap/PRD
  
  -----------------------------------------------------------------------------------------------
  
  Hana cluster server:-
After Health check file permissions was changed 
#/var/log/HDBHA/  ==> all files/directory should be 755

#/var/log/HDBHA/state_monitor/state_monitor.log ==> should be 755

make a note of this, after HC for Hana server, we need to set this permissions otherwise we can;t start Hana 


Post HC comment the below in crontab for HANA servers and change the permissions as above

-------------------------------------------------------------------------------------------------------------------------

nw change for TSM issue

1. Take a backup of current configuration
#cp /etc/sysctl.conf /root/
2. Validate current settings
#sysctl -a | egrep "net.core.rmem_max|net.core.wmem_max|net.ipv4.tcp_rmem|net.ipv4.tcp_wmem|net.ipv4.tcp_tw_reuse"
3. Modify the settings using below steps
#vi /etc/sysctl.conf ----> add below in the end of the file and save
net.core.rmem_max = 8388608
net.core.wmem_max = 8388608
net.ipv4.tcp_rmem = 4096        87380   8388608
net.ipv4.tcp_wmem = 4096        65536   8388608
net.ipv4.tcp_tw_reuse = 1
4. Run below command to update the kernel with the modified parameters 
#sysctl -p
5. Validate the new parameters are applied
#sysctl -a | egrep "net.core.rmem_max|net.core.wmem_max|net.ipv4.tcp_rmem|net.ipv4.tcp_wmem|net.ipv4.tcp_tw_reuse"
---------------------------------------------------------------------------------------------------------------------

 After Samuel HC remediation, do manual remediation


For HC manual remediation ( after SAMUEL) 

Here are the script details:

Script location                  : /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix

Execution procedure      : python /sds/sap/MSD_Software/SAP_Automation/Scripts/HC_Fix/hc_remediation_linux_v6.py

zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt)   to patch from the file 


Autologout fix post patching and HC

vi /etc/profile.d/autologout.csh
[root@mm9ufqapp profile.d]# cat autologout.csh
# BEGIN ANSIBLE MANAGED
# Set session timeout - CIS ID 5.4.5
set -r autologout=15 


samuel.sap.mgapp.ibm.com -> samuel.sap.adai.kyndryl.com

 

e.g. old link in change - https://samuel.sap.mgapp.ibm.com/DA5/buildInformation?id=64a6e12946fac38e9f8c3b24

Retype and use this - https://samuel.sap.adai.kyndryl.com/DA5/buildInformation?id=64a6e12946fac38e9f8c3b24

 

-------------------------------------------------------------------------------------------------------------------
Session getting dc automatically
cat /etc/ssh/sshd_config |grep -i ClientAliveInterval

change to 900

------------------------------------------------------------------------------------------------------------------

lsblk op on Azure to get serial no 
 lsblk -o +serial


--------------------------------------------------------------------------------------------------------

Timesheet

 CTP/ GPSG resources to start claiming in https://webph0ap1.zweu.app.kyndryl.net/sap/bc/gui/sap/its/webgui?~transaction=CAT2# from the week of July 22nd , 2023 
 
 Personal No Ravi Malik 99945370
 Oklahoma City Public Schools - OK4 (AWS contract)   CUS/00045-0002.L.01
Certified IT Consultants â€“ CI3 - TMG - C31 (AWS contract)   CEG/00005-0002.L.01
SCHIBSTED NORGE AS - S5C (AWS contract) 
Adevinta ASA - ADE (AWS contract)
Home Control Singapore Pte Ltd - HM8 (AWS contract)             CSG/00006-0003.L.01
Andhra Paper Limited - AAP (AWS contract) - CIN/00136-0001.L.06
Pak Suzuki Motor Company Ltd (PSMCL) - PS2 (AZ contract)  
Allianz Life - AZ3 (AZ contract)  CUS/00411-0002.L.01 or CUS/00411-0003.L.01

 

 

AWS    US-WEST-2-AWS        MITSUBISHI MOTORS NORTH AMERICA INC    SAPB2    MM9                CUS/00661-0006.L.01
AWS    EU-CENTRAL-1-AWS    SIRMAN                    SAPB2    SN2
AWS    EU-CENTRAL-1-AWS    Polti                    SAPB2    PL0          CIT/00336-0004.L.01
AWS    EU-CENTRAL-1-AWS    Bocconi                    SAPB2    BN6  CIT/00302-0002.L.01
AWS    AP-SOUTHEAST-1-AWS    Breadtalk Singapore            SAPB2    BT1                CSG/00071-0001.L.01
AWS    AP-SOUTH-1-AWS        Dilip Buildcon Limited            SAPB2    DB1               CIN/00266-0004.L.01
AZ    westus2-AZ        Cenovus Energy                SAPB2    HOE        I found Husky Energy code, if it’s the same client then it’d be: CCA/00393-0001.L.01
AZ    japaneast-AZ        Mitsubishi Motors Corporation        SAPB2    MMC             CJP/03291-0001.L.01
AZ    eastasia-AZ        DEL MONTE PHILIPPINES, INC        SAPB2    DM2  CPH/00046-0001.L.01
AZ    canadaeast-AZ        Halifax Regional Municipality        SAPB2    HRM CCA/00350-0002.L.01
 
 CATS Tips:

To login to CATS, you need to be connected to Cisco AnyConnect VPN.
The Menu code is CAT2 (it takes you to a cover page with your employee ID and such).
To get to the time entry form, click “Enter Times” from along the top row.
Scroll left/right through different weeks by the “Data Entry Period” header.
The Transition Period was from July 22 through last Friday.  Weeks are Sat->Fri.
Copy/paste the “WBS Element” from the time code spreadsheets (links below).  It should find it and prepopulate a few other fields on the row (once you click Enter key).
For example, Activity Type Descr might populate to “Onsite (Base)”.  Generally, you should use the defaults.
Fill out the TaskLev by clicking on the cell, then the double square icon. 
Not all the fields need to be filled out, for example, Bill Code column.
Fill out hours.  BY DEFAULT, FRACTION OF HOURS USE A COMMA NOT A DECIMAL per European number formatting rules.
You can change your date and time formats under “More v” menu item > System > User Profile > User Data > Defaults tab.
For vacation time, or other time away, on the next blank row, click on the A/AType cell and the double square icon that appears (WBS Element is not needed).
 
 
https://webph0ap1.zweu.app.kyndryl.net/sap/bc/gui/sap/its/webgui?~transaction=CAT2#

MUS/01467-0001.L

I00A11

TT3 - CIN/00331-0005.L

TTA -CIN/00200-0008.L

TDP - CIN/00312-0006.L

Honda Cars - CIN/00031-0001.L

Bhushan Steel - CIN/00158-0002.L

document no for weekend shift 7015609

Claim Code Tips:

The old pooled codes can be found here:  ​docx icon ADAI Claim Help.docx -> follow the link on number 6.
The link on number 6 opens a spreadsheet, it has the pooled codes, and dev expense codes.
There is a link on that spreadsheet on row 16 that takes us to another spreadsheet with all the individual customer claim codes. 
REMEMBER:  Not just AnyCloud customers have direct claim codes.  The old IBM Cloud customers are starting to have those as well.  Please look for them and use them, too. 
They added a column on that spreadsheet called “Aliases” (Column D), which gives us more wordy customer names to make it easier to search for specific customers.
Ping the DPE if you are unsure you have the right claim code.
 

Dashboard Help:

Remember there is a Dashboard in SNOW that pulls up the tickets you’ve worked on that week to help remind you which all different claim codes you may need to use:
https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/%24pa_dashboard.do%3Fsysparm_dashboard%3D560ea2e61b88bd9409fdeb17624bcb97
 
 -------------------------------------------------------------------------------------------------------
 
 Azure DR test (ASR Azure SIte recovery)
 https://learn.microsoft.com/en-us/azure/site-recovery/exclude-disks-replication
 
 https://kyndryl.sharepoint.com/sites/SAPEnablementDevelopment/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2Fsites%2FSAPEnablementDevelopment%2FShared%20Documents%2FSAP%20Base%20RR1%2FAzure%2FDR&clickparams=eyJBcHBOYW1lIjoiVGVhbXMtRGVza3RvcCIsIkFwcFZlcnNpb24iOiIyNy8yMzA3MDMwNzM0NiIsIkhhc0ZlZGVyYXRlZFVzZXIiOmZhbHNlfQ%3D%3D&OR=Teams%2DHL&CT=1692599996752
 
 
 
 Product key activation windows
 
 C:\windows\system32>wmic path SoftwareLicensingService get OA3xOriginalProductKey
OA3xOriginalProductKey
CVBCR-NC6YH-RW7K3-86K8K-6CQGP

enter this in use a product key

----------------------------------------------------------------------------------------------------------------------
Prechange backup to save root pw and revert back post change


 
. Backup the /etc/passwd file and set a temporay root password on both nodes. (Default temporal password: kyndryl@1)
    # cp /etc/passwd /etc/passwd-backup-<change-number>
    # passwd root
	
	Set root password per KB0017634
	
	3. Copy the most recent initrd, vmlinuz and grub.cfg files to somewhere else

          # cp /boot/initrd-$(uname -r) /root/initrd-$(uname -r)-before-update.bkp

          # cp /boot/vmlinuz-$(uname -r) /root/vmlinuz-$(uname -r)-default-before-update.bkp

to fix 
switch to sidadm
[root@br3ssapas10 ~]$ su - sx4adm
set: $autologout is read-only.
%
		  
remove -r from vi /etc/profile.d/autologout.csh
-------------------------------------------------------------------------------------

Q] How to  add  swap  space  online  (without  downtime). If  you  want  to  extend  existing swap disk  then  need  downtime.
==>
1007  2022-11-08 14:16:13 lsscsi |grep sdi
1008  2022-11-08 14:20:10 lsblk
1009  2022-11-08 14:33:11 pvcreate  /dev/sdi
1010  2022-11-08 14:33:42 vgcreate  swapvg /dev/sdi
  1012  2022-11-08 14:34:52 vgs
1013  2022-11-08 14:35:25 lvcreate  -L 15G swapvg -n swap_lv
1014  2022-11-08 14:35:54 mkswap /dev/swapvg/swap_lv
1015  2022-11-08 14:36:03 free  -h
1016  2022-11-08 14:36:35 swapon  /dev/swapvg/swap_lv
1017  2022-11-08 14:36:39 free  -h
1018  2022-11-08 14:36:50 history


/usr/bin/mpstat -P ALL 1 3
https://www.suse.com/support/kb/doc/?id=000019587   SUSE kernel versions

untar a file tar -xvf <tar file>

search logs for reboot look for ?0.000000  look for time gap in logs

to view crashdump u need to have the crash utility installed  crash-7.2.1-8.19.2.x86_64

-----------------------------------------------------------------------------------------
To get Windows product kEY, windows activation watermark
wmic path SoftwareLicensingService get OA3xOriginalProductKey

Use the product key to enter the key manually to remove watermark




--------------------------------------------------------------------------------------
To find the shell  echo $0

default umask for the non-login shell is set in the /etc/bashrc configuration file.
The default umask for the login shell is set in the /etc/profile configuration file.


The preferred way of adding new rules to sudoers is by creating new files in the /etc/sudoers.d/ directory instead of entering rules directly to the /etc/sudoers file. This is because the contents of this directory are preserved during system updates. In addition, it is easier to fix any errors in the separate files than in the /etc/sudoers file. The system reads the files in the /etc/sudoers.d directory when it reaches the following line in the /etc/sudoers file:

#includedir /etc/sudoers.d
Note that the number sign # at the beginning of this line is part of the syntax and does not mean the line is a comment. The names of files in that directory must not contain a period . and must not end with a tilde ~.


Procedure

As root, open the /etc/sudoers file.

# visudo
The /etc/sudoers file defines the policies applied by the sudo command.

In the /etc/sudoers file, find the lines that grant sudo access to users in the administrative wheel group.

## Allows people in group wheel to run all commands
%wheel        ALL=(ALL)       ALL
Make sure the line that starts with %wheel does not have the # comment character before it.
Save any changes, and exit the editor.
Add users you want to grant sudo access to into the administrative wheel group.

 # usermod --append -G wheel <username>
Replace <username> with the name of the user.

------------------------------------------------------------------------------------------------------------
Hana Cluster Maintenance Procedure (Manual and using Automation)

To enter maintenance mode :

crm maintenance on
crm resource maintenance msl_SAPHana_QCM_HDB36
crm resource maintenance rsc_ip_QCM_HDB36

To take out of maintenance and make it managed:

crm maintenance off
crm resource refresh cln_SAPHanaTopology_QCM_HDB36
crm resource refresh msl_SAPHana_QCM_HDB36
crm resource maintenance msl_SAPHana_QCM_HDB36 false
crm resource maintenance rsc_ip_QCM_HDB36 false


https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_view.do%3Fsys_kb_id%3D21433aa747562d1098ccecff336d4399

KB0019470  Hana Cluster Maintenance Procedure (Manual and using Automation)

1. Put entire cluster to maintenance mode using crm maintenance on

 [root@sdmazha2dbb ~]# crm maintenance on
2. Put msl and ip resources to maintenance mode using below commands crm resource maintenance <msl resource> and crm resource maintenance <ip resource>

[root@sdmazha2dbb ~]# crm resource maintenance msl_SAPHana_HA2_HDB00
[root@sdmazha2dbb ~]# crm resource maintenance rsc_ip_HA2_HDB00


3. Stop cluster on both the nodes using crm cluster stop command first on secondary and then on primary node.

[root@sdmazha2dba ~]# crm cluster stop
INFO: Cluster services stopped
[root@sdmazha2dba ~]#
[root@sdmazha2dbb ~]# crm cluster stop
INFO: Cluster services stopped
[root@sdmazha2dbb ~]#


1. Put entire cluster to maintenance mode using crm maintenance on
2. Put msl and ip resources to maintenance mode using below commands crm resource maintenance <msl resource> and crm resource maintenance <ip resource>
3. Validate the cluster status
4.  Stop cluster on both the nodes using crm cluster stop command first on secondary and then on primary node.
-------------------------------------------------------------------------------------------------------

Id dsmcad is not running then chk if backup activated or not
rpm -qa|grep TIV

if no rpm its not

-------------------------------------------------------------------------------------------

Downgrade from 8.6 to 8.2:-
===========================	
1. Verify that the current OS version is Red Hat Enterprise Linux 8:
# cat /etc/redhat-release
Red Hat Enterprise Linux release 8.6 (Ootpa)

 

2. CMS offering is RHEL8.2 so we need to down grade it from RHEL8.4 to RHEL8.2.
Set subscription manager release to RHEL8.2
# subscription-manager release --set=8.2

 

Downgrade redhat-release and kernel
# yum downgrade redhat-release

 

Install Supported level of Kernel package for RHEL8.2 kernel which is 4.18.0-193.
# yum list kernel-4.18.0-193*
Available Packages
kernel.x86_64      4.18.0-193.28.1.el8_2   @rhel-8-for-x86_64-baseos-rpms

 

# yum install kernel-modules-4.18.0-193.28.1.el8_2.x86_64 kernel-devel-4.18.0-193.28.1.el8_2.x86_64 kernel-tools-4.18.0-193.28.1.el8_2.x86_64 kernel-headers-4.18.0-193.28.1.el8_2.x86_64 kernel-modules-extra-4.18.0-193.28.1.el8_2.x86_64 kernel-core-4.18.0-193.28.1.el8_2.x86_64 kernel-tools-libs-4.18.0-193.28.1.el8_2.x86_64 kernel-4.18.0-193.28.1.el8_2.x86_64

 

3. Reboot system and make sure system is booting with rhel 8.2.

-------------------------------------------------------------------------------
vcenter fencing stopped, install python3 cryptography

-------------------------------------------------------------------------------
Auth failure even after AD join

2. In IPA environment, generate/get a new keytab file for IPA client host from IPA server:

Raw
# service sssd stop; rm -rf /var/lib/sss/db/*
# kdestroy
# kinit admin
# mv /etc/krb5.keytab /etc/krb5.keytab.backup		skip this
# ipa-getkeytab -s ipa_server_hostname -p host/ipa_client_FQDN_hostname -k /etc/krb5.keytab   skip this
# service sssd start

------------------------------------------------------------------------------------------------

NFS util for RHEL 8.6 is 
[root@IA1BPCPRDAPP log]$ rpm -qa |grep -i nfs-util
nfs-utils-2.3.3-51.el8.x86_64


Post downgrading RHEL to 8.2 the nfs-util does not downgrade and that stops the nfs client toconnetc to nfs server and showmount -e stops working
ref https://access.redhat.com/solutions/6977746

Downgrade nfs-utils to nfs-utils-2.3.3-46 if a kernel less than 4.18.0-240 is installed.

get the rpm externally from http://rpmfind.net/linux/rpm2html/search.php?query=nfs-utils

and use yum downgrade /tmp/nfs-utils-2.3.3-46.el8.x86_64.rpm  and it will downgrade the nfs-utils version.

restart nfs-server service on the nfs source and it will allow to mount.

------------------------------------------------------------------------------------------------------------------

a workaround that should stop pacemaker from being started on reboot:

Stop the pacemaker service
Run `/usr/local/sap/scripts/os_config.py -r pre`

--------------------------------------------------------------------------------------------------------------------------------

If the precheck script is not working in Windows Subsystem for Linux, ensure u have Windows Subsystem for Linux and ubuntu installed
update it to latest available then install sshpass
install dos2unix 
then convert the ip file with dos2unix in unix readable format
then pass that converted ip file and it will work

------------------------------------------------------------------------------------------------------------------------
How to monitor permission, ownership or any other change to a particular directory or file - Red Hat Customer Portal

https://access.redhat.com/solutions/10107

------------------------------------------------------------------------------------------------------------

before HC

ls -ld /var/log/squid
ls -ld /var/log/HDBHA



https://bdoga.com/replacement-for-netstat/
SS stands for “Socket Statistics” and operates in a manner similar to netstat.
ss -lt
ss -ltp

------------------------------------------------------------------------------------------------
To check activity n a server:

cd /var/log/sudo-io/

ttyout karke folder hota hai

/var/log/sudo-io/ibmsshrivastava1/00/00/05

select the last folder as per the time to check

-----------------------------------------------------------------------------------------

SFTP issue

check  grep sftp /etc/ssh/sshd_config
Add 
[root@penap15sl log]$ diff /etc/ssh/sshd_config /etc/ssh/sshd_config.bck.092523
107,110d106
<
< # Jim Hardy 25 Sep 2023 CS14069510
< Subsystem sftp internal-sftp       check for this if missing
  

------------------------------------------------------------------------------------
df -hT with timeout value so it does not get hung

timeout 5 df -h


---------------------------------------------------------------------

nmon upgrade

2. nmon upgrade, if you found nmon is older verion(el6), pls uninstall and install new version.
#rpm -ev rpm_name
#cd /sds/sap/MSD_Software/SAP_Automation/Scripts/linux_utility/nmon
#rpm -ivh rpm_name  ==> you can see multiple rpm's, select OS verions based rpm's (we have different rpm's for SUSE and RedHat)
----------------------------------------------------------------------------------

Patch list path

[root@bt1h1qdb01 ~]# ll /usr/local/sap/log/patch/patch_list_*

-rwxr-xr-x 1 root root 10090 Oct 11 23:29 /usr/local/sap/log/patch/patch_list_Oct_11_2023.txt

content of patchlist
amazon-ssm-agent-3.1.1260.0-150000.5.17.1
apparmor-abstractions-3.0.4-150400.5.9.1
apparmor-docs-3.0.4-150400.5.9.1
apparmor-parser-3.0.4-150400.5.9.1
apparmor-profiles-3.0.4-150400.5.9.1
apparmor-utils-3.0.4-150400.5.9.1
audit-3.0.6-150400.4.13.1
bind-utils-9.16.44-150400.5.37.2


patch with file  zypper up $(cat /usr/local/sap/log/patch/patch_list_Aug_02_2023.txt)

Capture patchlist for any server
Step1: 

=====

De-register the existing repo from all BR3 client machines

# SUSEConnect --de-register
# SUSEConnect --cleanup
# rm -f /etc/SUSEConnect
# rm -rf /etc/zypp/credentials.d/*
# rm -rf /etc/zypp/repos.d/*
# rm -f /etc/zypp/services.d/*

 

Step2: 

=====

Re-register the DAL13 daily repo on all BR3 client machines

 

#wget http://146.89.142.216/repo/tools/clientSetup4SMT.sh
#chmod 755 clientSetup4SMT.sh
then
#./clientSetup4SMT.sh --host 146.89.142.216

                       (or)

 ./clientSetup4SMT.sh --host dal13ammsmt01.imzcloud.ibmammsap.local

step3:

=====

Collect the patches on every 1st week of every month for all environment.

zypper lu | awk '{print $5 "-" $9}' > /tmp/patchlist

step4:
======
Remove the top 5-6 unwanted lines which comes extra as part of merging.

fftstsaqib13:~ # head /tmp/patchlist
-
-
-
Name-|
-
bluez-5.48-150200.13.22.1

step5: 
======
Update the patching during the scheduled change window.

zypper up $(cat /tmp/patchlist)


-------------------------------------------------------------------------------------------------
Trend Micro antity virus update:
 
The existing on primise Treand Micro licenses are expired. currently the on prim servers need to migrate to cloud anti virus server which is currently running project and AV team currently working with DPE to check port opening.
 
what ever server currently having issue with trend micro (un supported module or any error) need to check the cloud proxy server connectivity and work with DPE/Trend micro teams to open ports and then try upgrade the software from cloud antiviru server.

--------------------------------------------------------------------------------------------------

pvdisplay -m |grep -i sdX

pvscan |grep -i sdX

------------------------------------------------------------

Azurue backup

Select VM - Backup - click on Recovery Services Vault -- Backup items -- Azure Virtual machine -- Select previous items and click on three dots ( ... ) right side and click on backup now

---------------------------------------------------------------------------------------

 WARNING: PV /dev/sdf in VG potarchvg is using an old PV header, modify the VG to update.
 
 https://www.suse.com/support/kb/doc/?id=000019878
 
 ------------------------------------------------------------------------------------------
 sudo delay fix
 
 Add the following parameters in [domain/] section in file /etc/sssd/sssd.conf:
 
ldap_referrals = False
ignore_group_members = True
 
Restart the sssd service and clear the cache:
 
systemctl stop sssd; sss_cache -E; rm -f /var/lib/sss/db/* ; systemctl start sssd
 
With this solutions is not required the modification of any SUDO rule (already tested)


[root@aappop0020 sssd]# grep -i ignore_group_members sssd.conf
ignore_group_members = True
[root@aappop0020 sssd]# grep -i ldap_referrals sssd.conf
ldap_referrals = false

---------------------------------------------------------------------------------------------------------------------

SUSE15 SP2 to SP4 upgrade prerequest.
make sure swap fs is updated in the fstab.(some server two swap fs, swap\paging00) if anyone swap is missing after OS upgrade activity, server is not booting up.
 
swapon -s  ==> you can see disk(both should be avaialble) 
lvscan |grep -i swap and lvscan |grep -i paging00 ==> validate them

-------------------------------------------------------------------------------------------------------
The below impact is seen under the Sybase DB system.

The issue has been logged under SAP CR 828603. Its description reads, "SAP Adaptive Server may fail to bootstrap and produce a core dump file during startup after having upgraded SUSE operating system glibc library to version 13.2 which includes library version libstdc++.so.6.0.32. The problem is not seen with library version libstdc++.so.6.0.30."

Please lock the package until a permanent remedy is available before upgrading to SUSE or downgrade the libstdc version after the completion of the upgrade.. Please refer to the following SAP note for further details.

Please communicate with OS SME’s in a weekly or daily meeting. If required, please ask the team to update the steps in KB.

Impacted Environment : SLES 12 SP5, SLES 15 SP4 and SLES 15 SP5
--------------------------------------------------------------------------------------------------------------------------

Nagios portal
 
https://146.89.173.200/NagiosPortal/src.do

------------------------------------------------------------------------------------------------
SUSE live lab environment
Course | Live Lab Environment SLE301v15 SUSE Linux Enterprise Server 15 Advanced Administration | SUSE Partner Labs (cleura.com)

https://apps.partner.suse.cleura.com/learning/course/course-v1:SUSE+sle301v15+2019_1/home

-------------------------------------------------------------------------------------------------
Claim codes:
https://kyndryl.sharepoint.com/sites/SAPOnboardingProcess

---------------------------------------------------------------------------------

Azure Backups (OS backup/restore)
https://github.kyndryl.net/CMS/SAP-DevOps-Integration/tree/main/2.%20Azure/AZURE%20OS%20Backup%20Recovery
 
AWS Backups (OS backup/restore)
https://github.kyndryl.net/CMS/SAP-DevOps-Integration/tree/main/3.%20AWS/AWS%20OS%20Backup%20Recovery
 
AWS – on demand backup (Application/DB FS backup/restore)
https://github.kyndryl.net/CMS/SAP-DevOps-Integration/tree/main/3.%20AWS/AWS%20FS%20Backup%20and%20Recovery

---------------------------------------------------------------------------
RHEL 8.6 upgrade sssd not starting and thus not allowing imz logins

3] Make sure the permissions of /etc/sssd/sssd.conf, /var/log/sssd directory are correct. These should look like :

Raw
# ls -ld /var/log/sssd
drwxr-x---. 2 sssd sssd 4096 Jan  4 11:45 /var/log/sssd

# ls -l /etc/sssd/sssd.conf
-rw-------. 1 root root 2030 Jun 11  2019 /etc/sssd/sssd.conf
4] Check if the sssd user is present on the system. i.e:

Raw
# grep -i sss /etc/passwd
sssd:x:991:987:User for sssd:/:/sbin/nologin
5] Check if any module is missing. Detailed information can be obtained by running SSSD in daemon mode with debug. i.e:

Raw
# sssd -d9 -i
6] Make sure that, local cache files are not corrupted. Recreated them as -

Raw
# service sssd stop ; rm -f /var/lib/sss/{db,mc}/* ; service sssd start


Refer https://access.redhat.com/solutions/4948551

------------------------------------------------------------------------------------------------------

send an email to the DPE (cc your manager and squad lead) with your email address, and worker ID which can be found either in CATS (see User id)

-------------------------------------------------------------------------------------------------
Ansible connectivity test

plz check server is telnet from with port 22
	169.60.136.183		dal13bastion01	(North America)
	169.60.136.161		fmseubas001	(Europe)
	169.60.136.148		fmseubas003	(Latin America)
	169.60.136.184		fmseubas002	(Asia Pacific)
	
user "opaasuser" and password "image@2019@CMAS"



----------------------------------------------------------------------------------------------------

Guild github
https://github.com/enterprises/kyndryl-emu/sso

then

https://github.com/kyndryl-global-delivery/CMS_MgdSAP-Tribe-Tracker/issues/28194#issuecomment-1810241596

------------------------------------------------------------------------

Corrective step-
Work with the appropriate OS engineers to resolve. See below-

Set vm.swappiness =2 on all steady state vhana DB servers. Set vm.swappiness =10 on all steady state non-hana servers.
How to determine applicability:
Applicable to all SLES12 and SLES 15, RHEL 7 and RHEL 8 SAP machines. 
Check the current value:
cat /proc/sys/vm/swappiness
cat /etc/sysctl.conf | grep -i swappiness

vm.swappiness=10

---------------------------------------------------------------------------------

status of all services in one go

service --status-all

-----------------------------------------------------------------------------

Ansible tower troubleshooting client upgrade for Ansible/AWS servers
site_kickstart_ip: 146.89.170.144
site_kickstart_protocol: https
 
Current COS proxies:
146.89.140.20     dal09
146.89.142.31     wdc04
146.89.142.168    par01
146.89.140.245    fra02
146.89.143.243    SYD04 
146.89.170.144 	  tok04
 
echo $no_proxy | grep 146.89.143.243

---------------------------------------------------------------------------

SYbase issue with libstdc version
3394455 - ASE segfault core dump after patching the gcc-runtime package libstdc++6 on SLES - SAP ASE | SAP Knowledge Base Article
After updating the gcc-runtime package libstdc++6 on SLES to version 13.2.1+git7813-150000.1.3.3, ASE databases would not start. Result was segmentation fault core dump, even when running simple version query.
userapps.support.sap.com


---------------------------------------------------------------------------------
mount filesystem in certain order one after the other
https://www.suse.com/support/kb/doc/?id=000021169

Please include this script as part of OS SME prechecks 
 
#!/bin/bash
# Get the mount points from df -h, excluding headers
mount_points=$(df -h | awk '{if(NR>1)print $6}')
# Check if the mount points are in order
is_ordered=$(printf '%s\n' "${mount_points[@]}" | sort -c)
# If the mount points are not in order, display a message
if [ $? -ne 0 ]; then
    echo "This system is having incorrect mount order."
else
    echo "The mount order appears to be correct."
fi


----------------------------------------------------------------------------

OS validation latest script location
https://github.kyndryl.net/CMS/managed-apps-cr-os/blob/main/os_validation.sh

-------------------------------------------------------------------------
Serial no of any windows machine  C:\Users\RaviMALIK>wmic bios get serialnumber
SerialNumber
1B7WC63

-------------------------------------------------------------------------------------
Cust on AWS with native backup, no dsmc process on these cust VMs


CDIR	Customer	Account	Type	Datacenter
HCI	Honda Cars India Limited	2.07489E+11	Resell - SPAM	Asia Pacific (Mumbai)
C31	CERTIFIED IT CONSULTANTS - CI3 - TMG	9.39077E+11	Resell - SPAM	Europe (Paris)
SN2	SIRMAN S.P.A	4.28008E+11	Resell - SPAM	Europe (Frankfurt)
PFC	Performance in Lighting S.P.A.	66514286668	Resell - SPAM	Europe (Frankfurt)
MLO	MIP Politecnico di Milano	7.77925E+11	Resell - SPAM	Europe (Frankfurt)
PL0	Polti	5.99197E+11	Resell - SPAM	Europe (Frankfurt)
BN6	Bocconi	34232877415	Resell - SPAM	Europe (Frankfurt)
PD1	Pikdare	39627055470	Resell - SPAM	Europe (Frankfurt)
AAP	Andhra Papers Limited	5.60224E+11	Resell - SPAM	Asia Pacific (Mumbai)


----------------------------------------------------------------------

patchlist on AWS and Azure 
run the samuel wkf to add the cronjob under ansible user then switch to ansible and run the command there that generates a file inside the /etc/zypp path

/etc/zypp then crontab entrythat fetchess the patchlist
or
/usr/local/sap/log/patch/

-----------------------------------------------------------------------------

SSL certificate expired error in repo

SSL verify false in /etc/yum.repo.d 

Change execution --If you find any repo issues, do not unregister the vm , instead you can disable sslverify and cotinue with the patching.
take the backup of /etc/yum.repos.d/redhat.repo
cp -p /etc/yum.repos.d/redhat.repo /etc/yum.repos.d/redhat.repo_bkup
 
vi /etc/yum.repos.d/redhat.repo
 
:%s/sslverify = 1/sslverify = 0/g
 
then save the file
 
they you can run yum check-update or yum update

----------------------------------------------------------------
Please include this script as part of OS SME prechecks 
 
#!/bin/bash
# Get the mount points from df -h, excluding headers
mount_points=$(df -h | awk '{if(NR>1)print $6}')
# Check if the mount points are in order
is_ordered=$(printf '%s\n' "${mount_points[@]}" | sort -c)
# If the mount points are not in order, display a message
if [ $? -ne 0 ]; then
    echo "This system is having incorrect mount order."
else
    echo "The mount order appears to be correct."
fi

--------------------------------------------------------------------
ILMT issue

rm -rf /var/opt/ansible/GTS/ILMT/work/scanner_status.yml 
rm -rf  /var/opt/ansible/GTS/CIT/work/cit_scanner_status.yml
-------------------------------------------
Entries add in Ansible user
3.1- need to add "ansible" ID to /etc/cron.allow

#Ansible: ILMT cronjob
25,55 * * * * sudo sh -c '/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh > /var/opt/ansible/GTS/ILMT/logs/crontab.log 2>/dev/null'
#Ansible: CIT cronjob
0 2 * * 6 sudo sh -c '/var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT 2>/dev/null'

To chk the ansible version 
cat /var/opt/ansible/GTS/ILMT/work/computer.yml

b4 upgrade
cd /var/tmp;mv computer.yml computer.yml_bkp;mv endpoint_id.txt endpoint_id.txt_bkp;ls -ltr comp*;ls -ltr endpoint_id.txt_bkp


Org name
/var/opt/ansible/GTS/ILMT/config/computer_properties.yml
/var/opt/ansible/GTS/CIT/work/computer_properties.yml

###################################
Kill CIT and ILMT process 
ps -ef |grep -i cit
ps -ef |grep -i ilmt
######################################
run below script
/var/opt/ansible/GTS/ILMT/bin/run_hw_CRON.sh ; /var/opt/ansible/GTS/CIT/scan_aic.sh /var/opt/ansible/GTS/ILMT
#######################################
Paste below output in ticket
cat /var/opt/ansible/GTS/ILMT/work/scanner_status.yml
cat /var/opt/ansible/GTS/CIT/work/cit_scanner_status.yml


---------------------------------------------------------------------------------

List of Proxy devices here >> https://kyndrylcsm.service-now.com/now/nav/ui/classic/params/target/kb_knowledge.do%3Fsys_id%3Dd00aa6791b182d9009fdeb17624bcb01

--------------------------------------------------------------------------------

Snapshot deletion error due to ami attached The snapshot snap-xxxxxxxx is currently in use by ami-xxxxxxxx"

https://repost.aws/knowledge-center/snapshot-in-use-error

Note: You can't delete public snapshots. If you try to delete a public snapshot, you receive an "unknown error occurred" message.

Before you attempt to delete an EBS snapshot, make sure that the AMI isn't currently in use. You can use AMIs with a variety of AWS services, such as Amazon Elastic Compute Cloud (Amazon EC2), AWS Auto Scaling, AWS CloudFormation, and more. If you delete an AMI that's used by another service or application, you can affect the function of that service or application.

If you no longer need the EBS snapshot or its associated AMI, first deregister the AMI. Then, delete the EBS snapshot:

Note the AMI ID in the error message.
Open the Amazon EC2 console, and from the navigation pane, choose AMIs.
Choose the AMI that you noted in the error message, and then choose Deregister AMI from the Actions menu.
Note: If you don’t see the AMI that you're looking for, check any other AWS Regions that you might have used.
Use the EC2 console or the AWS CLI to delete the EBS snapshot.

--------------------------------------------------------------------------------------

[11/8 1:45 PM] Murthy Puranapanda .
sssd delay problem fix
Add the following parameters in [domain/] section in file /etc/sssd/sssd.conf:
 
ldap_referrals = False
ignore_group_members = True
 
Restart the sssd service and clear the cache:
 
systemctl stop sssd; sss_cache -E; rm -f /var/lib/sss/db/* ; systemctl start sssd
 
With this solutions is not required the modification of any SUDO rule (already tested)


Alternatively run Samuel job to fix it
Retrofit AD Modification - SSSD
 
 Workday
https://wd5.myworkday.com/kyndryl/d/home.htmld

Gerald link for claim code/onboarding 
https://kyndryl.sharepoint.com/sites/SAPOnboardingProcess



CS14349299
tgpprdwebapp1
tgpprdmysqldb

----------------------------------------------------------------
CLuster fencing keywords

Requesting peer fencing (reboot)

-----------------------------------------------------------------

The scanner IPs are as follows:
10.170.90.137    a0001p1rapp0001   sl-wdc04

10.170.90.142    a0001v1rapp0001   sl-v-wdc04

10.72.112.5      a0001v5rapp6022   sl-lon06

10.90.9.228      a0001v5rapp7014   sl-fra04

146.89.170.135   a0001v5rapp9402   sl-tok04

10.176.184.199   a0001v1rapp0007   sl-dal10

 

158.87.45.83     a0001v1rapp0010   so-pok

158.87.47.83     a0001v1rapp0011   so-dal

 

100.65.48.5      eufz1scan2001   vpc-eu-fra

100.65.60.5      apsz1scan2001   vpc-ap-syd

100.65.56.5      aptz1scan2001   vpc-ap-tok

100.65.36.5      ussz1scan2001   vpc-us-south

100.65.40.5      usez1scan2001   vpc-us-east

 

169.55.192.122   fmsprdnscan001   cms3x-fms1

169.55.192.125   fmsprdnscan002   cms3x-fms2

 

We would have to analyze each unreachable IP by datacenter location, environment, and other factors to determine which scanner should be used. The scanners would need to reach the servers on their management port:
           Windows         tcp 445

           Linux/AIX         tcp 22

As a quick reference, these are the credentials used for Windows/Linux/AIX servers:
 

Linux/AIX
iuxnes - Linux local scan account typically used with SEI hosts and configured using salt or ansible. Uses ssh key to authenticate.
uxscan - IMZCloud domain account. Usually is configured when the server is added to the domain.

 

Windows
iwnnes - Windows local scan account typically used with SEI hosts and configured using salt. 
lsscan - IMZCloud domain account. Usually is configured when the server is added to the domain.
---------------------------------------------------------------------------------------------------------------------------------
reset imz pw from jump server

press ctrl+alt+end then select “Change a password”

------------------------------------------------------------------------------------------

mapped and reserved memory

[root@zffpdb001 ~]# vmware-toolbox-cmd stat raw text resources|egrep "reserved|guest.mem.mapped"|column -t|sed 's/^/\t\t/'
                vm.cpu.reserved     =  0
                guest.mem.reserved  =  246415360
                guest.mem.mapped    =  37703680
				
				
grep -i mapped /usr/local/sap/log/os_check_full_result.txt

vmware-toolbox-cmd stat raw text resources|egrep "reserved|guest.mem.mapped"|column -t|sed 's/^/\t\t/'


vmtoolsd service restart
os_check service restart

oscar script  /usr/bin/python /usr/local/sap/scripts/os_check_and_fix_v1.0.py

VMtool version
[root@zffpdb001 pre_post_result]# vmtoolsd --cmd "info-get guestinfo.vmtools.description"
open-vm-tools 12.3.0 build 22234872

------------------------------------------------------------------------------------------------------------

Use netcat instead of telnet for port open or not check

---------------------------------------------------------------------------------------------

check FS sequence in fstab   mount sequence check.sh is the script in downloads folder

#!/bin/bash
# Get the mount points from df -h, excluding headers
mount_points=$(df -h | awk '{if(NR>1)print $6}')
# Check if the mount points are in order
is_ordered=$(printf '%s\n' "${mount_points[@]}")
# If the mount points are not in order, display a message
if [ $? -ne 0 ]; then
    echo "This system is having incorrect mount order."
else
    echo "The mount order appears to be correct."
fi
-----------------------------------------------------------------------------

If a server is running "cron" instead of "crond", the fix is as follows:

Update file /usr/local/ncpa/etc/ncpa.cfg.d/processes.cfg by replacing /plugins/cmas_check_process.sh/'crond' with /plugins/cmas_check_process.sh/'cron'
Restart the Nagios agent with command "/sbin/service ncpa_passive restart"

------------------------------------------------------------------------------
FRUN Support Channel - https://teams.microsoft.com/l/channel/19%3a4ZcuC66jto8-7ZfPMfHeeknUJFcwJpJNSyXvBVOIU7c1%40thread.tacv2/General?groupId=e35f1515-63fd-456f-b049-44ce20fa1acf&tenantId=f260df36-bc43-424c-8f44-c85226657b01

 

SAMUEL Support Channel - https://teams.microsoft.com/l/channel/19%3ad2034d6a8a1e499590d279b26b05bca7%40thread.tacv2/SAMUEL%2520Support?groupId=64bbd40c-a425-4fd9-afc6-67b6a3eb7ba7&tenantId=f260df36-bc43-424c-8f44-c85226657b01

----------------------------------------------------------------------------------------

Please refer the KB https://kyndrylcsm.service-now.com/kb_view.do?sysparm_article=KB0019746
The locked patch repo ( monthly / quarterly ) has been created for all  AWS and Azure VMs. ( SUSE, RHEL and OEL).
The SAMUEL workflow also available for patch_list OS patching changes.
Incase any cluster VM or Samuel workflow failed, please use the right manual steps specified in the KB.
 
The SUSE patch list PATH - 
Monthly - /etc/zypp/month/Mmmm-patchlist
Quarterly - /etc/zypp/quarter/Qmmm-patchlist
 
The RHEL and OEL patch list PATH - 
Monthly - /etc/yum/month/Mmmm-patchlist
Quarterly - /etc/yum/quarter/Qmmm-patchlist
 
Moreover, incase any OS patching workflow failed, please open a Github case with platform team to investigate further.
SMEs - Please confirm the patch_list availability during the OS SME Approval.


----------------------------------------------------------------------------



To del a queue  lpadmin -x NPI600979;

echo "135.116.33.110     NPI450E44" >> /etc/hosts

printer add      lpadmin -p NPI450E44 -v lpd://135.116.33.110 -o printer-error-policy=retry-job -E;cupsenable NPI450E44;cupsaccept NPI450E44

lpadmin -x CanonDCD16B;lpadmin -p CanonDCD16B -v lpd://132.147.10.160 -o printer-error-policy=retry-job -E;cupsenable CanonDCD16B;cupsaccept CanonDCD16B

cat /etc/cups/printers.conf |grep -i ErrorPolicy

lpr -P NPI99930C /usr/share/cups/data/testprint    to send a test print

lpstat -W completed      to check if the print is recd successfully 

------------------------------------------------------------------------------



 1. AI Essentials - lnkd.in/dyEt4DGt
 2. ChatGPT Mastery -  lnkd.in/eiRtk-6q
 3. Google AI Magic - lnkd.in/eBQXfBe9
 4. Harvard AI Introduction -  lnkd.in/eu4mZaAG
 5. Microsoft AI Basics -  lnkd.in/eYNWzXUX
 6. Prompt Engineering Pro -  lnkd.in/eNi_YNSe
 7. Google's Ethical AI -  lnkd.in/eTrwSU89
 8. Machine Learning by Harvard - lnkd.in/eX28syMJ
 9. Language Models by LangChain -  lnkd.in/evZVJbNy
10. Bing Chat Applications -  lnkd.in/ejN-qrVy
11. Generative AI by Microsoft -  lnkd.in/dqjnzcCD
12. Amazon's AI Strategy - lnkd.in/dFhmsvZC
13. AI for Everyone - lnkd.in/eFx7zCz7
14. AWS AI Foundations -  lnkd.in/dEjN9PRm
-------------------------------------------------------------------------------------------------

How to login to Ansible bastions? ssh with user "opaasuser" and password "image@2019@CMAS"

if we are unable to login to the server and the root password is not working, please login to one of the bastion host above and do sudo root, then use the below command to ssh using anisble id, after which we can reset the root password.
ssh -i .ssh/ansible_rsa ansible@<IMZ_IP>

plz check server is telnet from with port 22
	169.60.136.183		dal13bastion01	(North America)
	169.60.136.161		fmseubas001	(Europe)
	169.60.136.148		fmseubas003	(Latin America)
	169.60.136.184		fmseubas002	(Asia Pacific)
	
user "opaasuser" and password "image@2019@CMAS"
--------------------------------------------------------------------------------------------

fra02 proxy , soon Trend micro team updates that kb
 
fra0201vrsprx02.imzcloud.ibmammsap.local	146.89.140.198
fra0401vrsprx01.imzcloud.ibmammsap.local	146.89.170.12
fra0501vrsprx02.imzcloud.ibmammsap.local	146.89.169.196
 


Raise a ticket to Azure AD team, follow this link
https://kyndryl.sharepoint.com/sites/AskIT/SitePages/Microsoft-Operational-ID-(Ops-ID)-Administration.aspx

------------------------------------------------------------------------------------------------------
AWS disk extension

IN case of AWS, modify the disk size from Samuel 
pvresize /dev/nvme1n1

854  2024-01-26 14:00:45 pvresize /dev/nvme1n1
  855  2024-01-26 14:00:55 pvs
  856  2024-01-26 14:01:53 vgs sapdata
  857  2024-01-26 14:02:15 df -hT /sapmnt/data
  858  2024-01-26 14:02:44 lvextend -L +60G /dev/mapper/sapdata-data
  859  2024-01-26 14:02:55 xfs_growfs /sapmnt/data
  860  2024-01-26 14:02:59 df -hT /sapmnt/data
  861  2024-01-26 14:03:50 history

---------------------------------------------------------------------------

few of customers implemented stripe volume for sapdata and logs. to identify those volumes, below command display whether it is stripe or linear
 
lvdisplay -m lvname
 
lvs --segments
 
lvs -a -o +devices

----------------------------------------------------------------------------------

Check pacemaker version
[ibmrguardado@pd1ecpapha-Production ~]$ rpm -qi pacemaker
Name        : pacemaker
Version     : 2.1.2+20211124.ada5c3b36

-----------------------------------------------------------------------------

>>>>>Unistall and reinstall is required or not ?
NOT required, and recommended the below
disable ds_agent /stop ds_agnet
patch the OS
reboot the server
enable the ds_agent and start it
 
>>>>>what if cloudone script is not working ?
 
Verify the proxy server for the patching change servers check whether proxy existis and able to connect
if that proxy does not work, then send case to AV team.
 
>>>>> How to recover it back after the uninstallation ?
 
No need to wait or extend change window and create case to AV team with the prob facing (whether it is proxy checked and not working during change window or any other problem)
 
 -----------------------------------------------------------------------------------
 
AWS temporary disk identification
hi team,  i am giving here example disk for temporary storage allocated from AWS and they are used for database fast restart. DONT TRY TO RECLIAM THEM.  
 
below command gives that serial number details
 
lsblk -o +SERIAL    # on aws vm
 
nvme9n1                  259:12   0  1.7T  0 disk                  AWS1599597C7F7241970
nvme8n1                  259:13   0  1.7T  0 disk                  AWS2272A6A6A5B64A544

---------------------------------------------------------------------------------------------------

Engineers are not required to uninstall and reinstall during the OS patching except below scenarios.

1.Only update the ds_aent if found the lower version (<20) during OS patching.
2.Only update the ds_agent if there is any kernel incompatability issue identified.
3.During OS upgrade -- Required to uninstall and install with the current suse version (SLES12-15).
4.Avoid Change window extension if there are any issues --Create a case with AV team and assign to MA-ASGN-S&R-ANTIVIRUS
5.ds_agent blocking all the ports if it's wrongly defined -- After patching if we see these kind of issues , work with AV team immediately by opening a case.
6.Follow the ds_agent stop process during the OS patching
disable ds_agent /stop ds_agnet

patch the OS

reboot the server

enable the ds_agent and start it

------------------------------------------------------------------------------------------------------------

/usr/local/ncpa/var/log/protocolfiles/custom_rsync_logscanner_checkrsynclog_filters.protocol

Check passwordless connectivity between nodes and fix that